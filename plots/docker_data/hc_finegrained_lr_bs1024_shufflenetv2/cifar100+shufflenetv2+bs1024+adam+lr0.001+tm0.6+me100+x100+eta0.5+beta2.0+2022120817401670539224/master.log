[Zeus Master] Job(cifar100,shufflenetv2,adam,0.6,bs1024~100) x 100
[Zeus Master] Batch sizes: [1024]
[Zeus Master] Learning rates: [0.006, 0.007, 0.008, 0.009]
[run job] Launching job with BS 1024: and LR: 0.006
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224', 'ZEUS_JOB_ID': 'rec00+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec00+try01.train.log'
2022-12-08 17:40:28,714 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 17:40:28,715 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 17:40:28,715 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 17:40:28,761 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 17:40:28,761 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 17:40:31,594 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 17:40:31,595 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 17:40:31,802 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:40:31.806 [ZeusMonitor] Monitor started.
2022-12-08 22:40:31.807 [ZeusMonitor] Running indefinitely. 2022-12-08 22:40:31.807 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:40:31.807 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e1+gpu0.power.log
2022-12-08 17:40:32,544 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 17:40:32,545 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 17:40:42,151 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 17:41:15,621 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 17:41:17,280 [ZeusDataLoader(train)] train epoch 1 done: time=45.68 energy=6781.57
2022-12-08 17:41:17,283 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 5.8632
Training Epoch: 0 [3072/50176]	Loss: 5.2699
Training Epoch: 0 [4096/50176]	Loss: 4.8855
Training Epoch: 0 [5120/50176]	Loss: 4.7573
Training Epoch: 0 [6144/50176]	Loss: 4.6781
Training Epoch: 0 [7168/50176]	Loss: 4.6426
Training Epoch: 0 [8192/50176]	Loss: 4.7275
Training Epoch: 0 [9216/50176]	Loss: 4.6437
Training Epoch: 0 [10240/50176]	Loss: 4.6414
Training Epoch: 0 [11264/50176]	Loss: 4.6721
Training Epoch: 0 [12288/50176]	Loss: 4.5973
Training Epoch: 0 [13312/50176]	Loss: 4.5862
Training Epoch: 0 [14336/50176]	Loss: 4.5620
Training Epoch: 0 [15360/50176]	Loss: 4.5414
Training Epoch: 0 [16384/50176]	Loss: 4.5028
Training Epoch: 0 [17408/50176]	Loss: 4.5458
Training Epoch: 0 [18432/50176]	Loss: 4.4966
Training Epoch: 0 [19456/50176]	Loss: 4.5342
Training Epoch: 0 [20480/50176]	Loss: 4.4832
Training Epoch: 0 [21504/50176]	Loss: 4.5200
Training Epoch: 0 [22528/50176]	Loss: 4.5125
Training Epoch: 0 [23552/50176]	Loss: 4.5563
Training Epoch: 0 [24576/50176]	Loss: 4.4795
Training Epoch: 0 [25600/50176]	Loss: 4.4510
Training Epoch: 0 [26624/50176]	Loss: 4.4510
Training Epoch: 0 [27648/50176]	Loss: 4.4488
Training Epoch: 0 [28672/50176]	Loss: 4.3745
Training Epoch: 0 [29696/50176]	Loss: 4.4119
Training Epoch: 0 [30720/50176]	Loss: 4.4485
Training Epoch: 0 [31744/50176]	Loss: 4.3951
Training Epoch: 0 [32768/50176]	Loss: 4.3704
Training Epoch: 0 [33792/50176]	Loss: 4.3347
Training Epoch: 0 [34816/50176]	Loss: 4.2917
Training Epoch: 0 [35840/50176]	Loss: 4.2593
Training Epoch: 0 [36864/50176]	Loss: 4.2441
Training Epoch: 0 [37888/50176]	Loss: 4.2790
Training Epoch: 0 [38912/50176]	Loss: 4.2264
Training Epoch: 0 [39936/50176]	Loss: 4.2756
Training Epoch: 0 [40960/50176]	Loss: 4.1909
Training Epoch: 0 [41984/50176]	Loss: 4.2077
Training Epoch: 0 [43008/50176]	Loss: 4.2196
Training Epoch: 0 [44032/50176]	Loss: 4.1797
Training Epoch: 0 [45056/50176]	Loss: 4.1827
Training Epoch: 0 [46080/50176]	Loss: 4.1264
Training Epoch: 0 [47104/50176]	Loss: 4.1664
Training Epoch: 0 [48128/50176]	Loss: 4.1285
Training Epoch: 0 [49152/50176]	Loss: 4.1425
Training Epoch: 0 [50176/50176]	Loss: 4.0654
2022-12-08 22:41:21.067 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:41:21,090 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.80 energy=537.92
2022-12-08 17:41:21,091 [ZeusDataLoader(train)] Up to epoch 1: time=49.48, energy=7319.49, cost=7988.92
2022-12-08 17:41:21,092 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0045, Accuracy: 0.0401
2022-12-08 17:41:21,252 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:41:21.256 [ZeusMonitor] Monitor started.
2022-12-08 22:41:21.256 [ZeusMonitor] Running indefinitely. 2022-12-08 22:41:21.256 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:41:21.256 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e2+gpu0.power.log
2022-12-08 17:41:22,006 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 17:41:22,006 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 17:41:30,321 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 17:42:04,854 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 17:42:06,574 [ZeusDataLoader(train)] train epoch 2 done: time=45.48 energy=6541.30
2022-12-08 17:42:06,578 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.0994
Training Epoch: 1 [2048/50176]	Loss: 4.0433
Training Epoch: 1 [3072/50176]	Loss: 4.1051
Training Epoch: 1 [4096/50176]	Loss: 4.0306
Training Epoch: 1 [5120/50176]	Loss: 4.0105
Training Epoch: 1 [6144/50176]	Loss: 4.0484
Training Epoch: 1 [7168/50176]	Loss: 3.9657
Training Epoch: 1 [8192/50176]	Loss: 3.9547
Training Epoch: 1 [9216/50176]	Loss: 4.0683
Training Epoch: 1 [10240/50176]	Loss: 4.0073
Training Epoch: 1 [11264/50176]	Loss: 4.0162
Training Epoch: 1 [12288/50176]	Loss: 3.9958
Training Epoch: 1 [13312/50176]	Loss: 3.9218
Training Epoch: 1 [14336/50176]	Loss: 4.0264
Training Epoch: 1 [15360/50176]	Loss: 3.9464
Training Epoch: 1 [16384/50176]	Loss: 3.9559
Training Epoch: 1 [17408/50176]	Loss: 3.9147
Training Epoch: 1 [18432/50176]	Loss: 3.8249
Training Epoch: 1 [19456/50176]	Loss: 3.9286
Training Epoch: 1 [20480/50176]	Loss: 3.8567
Training Epoch: 1 [21504/50176]	Loss: 3.8629
Training Epoch: 1 [22528/50176]	Loss: 3.8126
Training Epoch: 1 [23552/50176]	Loss: 3.8272
Training Epoch: 1 [24576/50176]	Loss: 3.8096
Training Epoch: 1 [25600/50176]	Loss: 3.8063
Training Epoch: 1 [26624/50176]	Loss: 3.8112
Training Epoch: 1 [27648/50176]	Loss: 3.7862
Training Epoch: 1 [28672/50176]	Loss: 3.7061
Training Epoch: 1 [29696/50176]	Loss: 3.8431
Training Epoch: 1 [30720/50176]	Loss: 3.7565
Training Epoch: 1 [31744/50176]	Loss: 3.7601
Training Epoch: 1 [32768/50176]	Loss: 3.7005
Training Epoch: 1 [33792/50176]	Loss: 3.8117
Training Epoch: 1 [34816/50176]	Loss: 3.7567
Training Epoch: 1 [35840/50176]	Loss: 3.7877
Training Epoch: 1 [36864/50176]	Loss: 3.7252
Training Epoch: 1 [37888/50176]	Loss: 3.7060
Training Epoch: 1 [38912/50176]	Loss: 3.7408
Training Epoch: 1 [39936/50176]	Loss: 3.7013
Training Epoch: 1 [40960/50176]	Loss: 3.7496
Training Epoch: 1 [41984/50176]	Loss: 3.6677
Training Epoch: 1 [43008/50176]	Loss: 3.7348
Training Epoch: 1 [44032/50176]	Loss: 3.6602
Training Epoch: 1 [45056/50176]	Loss: 3.6832
Training Epoch: 1 [46080/50176]	Loss: 3.6301
Training Epoch: 1 [47104/50176]	Loss: 3.6557
Training Epoch: 1 [48128/50176]	Loss: 3.6898
Training Epoch: 1 [49152/50176]	Loss: 3.6428
Training Epoch: 1 [50176/50176]	Loss: 3.6130
2022-12-08 22:42:10.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:42:10,392 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.81 energy=512.99
2022-12-08 17:42:10,393 [ZeusDataLoader(train)] Up to epoch 2: time=98.76, energy=14373.77, cost=15828.23
2022-12-08 17:42:10,394 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0036, Accuracy: 0.1147
2022-12-08 22:42:10.583 [ZeusMonitor] Monitor started.
2022-12-08 22:42:10.583 [ZeusMonitor] Running indefinitely. 2022-12-08 22:42:10.583 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:42:10.583 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e3+gpu0.power.log
2022-12-08 17:42:10,592 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:42:11,328 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 17:42:11,329 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 17:42:20,722 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 17:42:59,971 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 17:43:01,906 [ZeusDataLoader(train)] train epoch 3 done: time=51.50 energy=6243.61
2022-12-08 17:43:01,910 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.6010
Training Epoch: 2 [2048/50176]	Loss: 3.6103
Training Epoch: 2 [3072/50176]	Loss: 3.5408
Training Epoch: 2 [4096/50176]	Loss: 3.5474
Training Epoch: 2 [5120/50176]	Loss: 3.5615
Training Epoch: 2 [6144/50176]	Loss: 3.5118
Training Epoch: 2 [7168/50176]	Loss: 3.5781
Training Epoch: 2 [8192/50176]	Loss: 3.6333
Training Epoch: 2 [9216/50176]	Loss: 3.5512
Training Epoch: 2 [10240/50176]	Loss: 3.4561
Training Epoch: 2 [11264/50176]	Loss: 3.4487
Training Epoch: 2 [12288/50176]	Loss: 3.4830
Training Epoch: 2 [13312/50176]	Loss: 3.5397
Training Epoch: 2 [14336/50176]	Loss: 3.5475
Training Epoch: 2 [15360/50176]	Loss: 3.5429
Training Epoch: 2 [16384/50176]	Loss: 3.6258
Training Epoch: 2 [17408/50176]	Loss: 3.5708
Training Epoch: 2 [18432/50176]	Loss: 3.5620
Training Epoch: 2 [19456/50176]	Loss: 3.5041
Training Epoch: 2 [20480/50176]	Loss: 3.5126
Training Epoch: 2 [21504/50176]	Loss: 3.5501
Training Epoch: 2 [22528/50176]	Loss: 3.5103
Training Epoch: 2 [23552/50176]	Loss: 3.4881
Training Epoch: 2 [24576/50176]	Loss: 3.5544
Training Epoch: 2 [25600/50176]	Loss: 3.4901
Training Epoch: 2 [26624/50176]	Loss: 3.5318
Training Epoch: 2 [27648/50176]	Loss: 3.5128
Training Epoch: 2 [28672/50176]	Loss: 3.5095
Training Epoch: 2 [29696/50176]	Loss: 3.4310
Training Epoch: 2 [30720/50176]	Loss: 3.4492
Training Epoch: 2 [31744/50176]	Loss: 3.4235
Training Epoch: 2 [32768/50176]	Loss: 3.4655
Training Epoch: 2 [33792/50176]	Loss: 3.4868
Training Epoch: 2 [34816/50176]	Loss: 3.4430
Training Epoch: 2 [35840/50176]	Loss: 3.3876
Training Epoch: 2 [36864/50176]	Loss: 3.4032
Training Epoch: 2 [37888/50176]	Loss: 3.4732
Training Epoch: 2 [38912/50176]	Loss: 3.3762
Training Epoch: 2 [39936/50176]	Loss: 3.3504
Training Epoch: 2 [40960/50176]	Loss: 3.3681
Training Epoch: 2 [41984/50176]	Loss: 3.3494
Training Epoch: 2 [43008/50176]	Loss: 3.3577
Training Epoch: 2 [44032/50176]	Loss: 3.3083
Training Epoch: 2 [45056/50176]	Loss: 3.3707
Training Epoch: 2 [46080/50176]	Loss: 3.3618
Training Epoch: 2 [47104/50176]	Loss: 3.3058
Training Epoch: 2 [48128/50176]	Loss: 3.3387
Training Epoch: 2 [49152/50176]	Loss: 3.3245
Training Epoch: 2 [50176/50176]	Loss: 3.2574
2022-12-08 22:43:06.160 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:43:06,196 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.28 energy=481.81
2022-12-08 17:43:06,197 [ZeusDataLoader(train)] Up to epoch 3: time=154.54, energy=21099.19, cost=24071.91
2022-12-08 17:43:06,198 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0034, Accuracy: 0.1649
2022-12-08 17:43:06,414 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:43:06.417 [ZeusMonitor] Monitor started.
2022-12-08 22:43:06.417 [ZeusMonitor] Running indefinitely. 2022-12-08 22:43:06.417 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:43:06.417 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e4+gpu0.power.log
2022-12-08 17:43:07,189 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 17:43:07,189 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 17:43:32,248 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 17:45:15,743 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 17:45:18,135 [ZeusDataLoader(train)] train epoch 4 done: time=131.93 energy=13458.04
2022-12-08 17:45:18,138 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.2500
Training Epoch: 3 [2048/50176]	Loss: 3.2233
Training Epoch: 3 [3072/50176]	Loss: 3.2406
Training Epoch: 3 [4096/50176]	Loss: 3.3061
Training Epoch: 3 [5120/50176]	Loss: 3.2234
Training Epoch: 3 [6144/50176]	Loss: 3.2615
Training Epoch: 3 [7168/50176]	Loss: 3.2445
Training Epoch: 3 [8192/50176]	Loss: 3.2826
Training Epoch: 3 [9216/50176]	Loss: 3.2782
Training Epoch: 3 [10240/50176]	Loss: 3.2165
Training Epoch: 3 [11264/50176]	Loss: 3.2995
Training Epoch: 3 [12288/50176]	Loss: 3.2323
Training Epoch: 3 [13312/50176]	Loss: 3.3073
Training Epoch: 3 [14336/50176]	Loss: 3.2085
Training Epoch: 3 [15360/50176]	Loss: 3.1580
Training Epoch: 3 [16384/50176]	Loss: 3.2223
Training Epoch: 3 [17408/50176]	Loss: 3.1654
Training Epoch: 3 [18432/50176]	Loss: 3.2336
Training Epoch: 3 [19456/50176]	Loss: 3.1755
Training Epoch: 3 [20480/50176]	Loss: 3.1254
Training Epoch: 3 [21504/50176]	Loss: 3.1708
Training Epoch: 3 [22528/50176]	Loss: 3.0870
Training Epoch: 3 [23552/50176]	Loss: 3.1420
Training Epoch: 3 [24576/50176]	Loss: 3.1818
Training Epoch: 3 [25600/50176]	Loss: 3.0013
Training Epoch: 3 [26624/50176]	Loss: 3.2077
Training Epoch: 3 [27648/50176]	Loss: 3.1552
Training Epoch: 3 [28672/50176]	Loss: 3.0803
Training Epoch: 3 [29696/50176]	Loss: 3.1031
Training Epoch: 3 [30720/50176]	Loss: 3.0702
Training Epoch: 3 [31744/50176]	Loss: 3.0790
Training Epoch: 3 [32768/50176]	Loss: 3.0898
Training Epoch: 3 [33792/50176]	Loss: 2.9987
Training Epoch: 3 [34816/50176]	Loss: 3.0636
Training Epoch: 3 [35840/50176]	Loss: 3.0164
Training Epoch: 3 [36864/50176]	Loss: 3.0736
Training Epoch: 3 [37888/50176]	Loss: 3.1536
Training Epoch: 3 [38912/50176]	Loss: 3.1442
Training Epoch: 3 [39936/50176]	Loss: 3.0787
Training Epoch: 3 [40960/50176]	Loss: 2.9469
Training Epoch: 3 [41984/50176]	Loss: 3.0576
Training Epoch: 3 [43008/50176]	Loss: 2.9338
Training Epoch: 3 [44032/50176]	Loss: 2.9990
Training Epoch: 3 [45056/50176]	Loss: 2.9629
Training Epoch: 3 [46080/50176]	Loss: 3.0219
Training Epoch: 3 [47104/50176]	Loss: 2.9078
Training Epoch: 3 [48128/50176]	Loss: 3.1560
Training Epoch: 3 [49152/50176]	Loss: 2.9582
Training Epoch: 3 [50176/50176]	Loss: 2.9711
2022-12-08 22:45:21.925 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+lr0.0060000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 155.16304190626855, "150000": 146.66679122833526, "125000": 123.11079515402562, "100000": 102.24933636766599}, "train_throughput": {"175000": 1.1359478370950427, "150000": 1.1007655943504855, "125000": 0.9684575298543399, "100000": 0.3672341515196985}, "eval_power": {"175000": 137.48240735072176, "150000": 134.78162791311982, "125000": 112.630877961285}, "eval_throughput": {"175000": 2.6088153813743062, "150000": 2.6273896195624724, "125000": 2.337656921522037}, "optimal_pl": 175000}
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.83 energy=526.99
2022-12-08 17:45:21,983 [ZeusDataLoader(train)] Up to epoch 4: time=290.30, energy=35084.23, cost=42943.33
2022-12-08 17:45:21,984 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:45:21,984 [ZeusDataLoader(train)] Expected next epoch: time=337.27, energy=42304.30, cost=50663.15
2022-12-08 17:45:21,985 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0030, Accuracy: 0.2454
2022-12-08 17:45:22,194 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:45:22,195 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:45:22.209 [ZeusMonitor] Monitor started.
2022-12-08 22:45:22.209 [ZeusMonitor] Running indefinitely. 2022-12-08 22:45:22.209 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:45:22.209 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e5+gpu0.power.log
2022-12-08 17:46:06,545 [ZeusDataLoader(train)] train epoch 5 done: time=44.55 energy=6772.30
2022-12-08 17:46:06,549 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.0218
Training Epoch: 4 [2048/50176]	Loss: 2.9175
Training Epoch: 4 [3072/50176]	Loss: 2.8868
Training Epoch: 4 [4096/50176]	Loss: 2.9163
Training Epoch: 4 [5120/50176]	Loss: 2.8734
Training Epoch: 4 [6144/50176]	Loss: 2.9483
Training Epoch: 4 [7168/50176]	Loss: 2.8958
Training Epoch: 4 [8192/50176]	Loss: 2.9441
Training Epoch: 4 [9216/50176]	Loss: 2.9258
Training Epoch: 4 [10240/50176]	Loss: 2.9399
Training Epoch: 4 [11264/50176]	Loss: 2.9048
Training Epoch: 4 [12288/50176]	Loss: 2.9027
Training Epoch: 4 [13312/50176]	Loss: 2.8627
Training Epoch: 4 [14336/50176]	Loss: 2.9328
Training Epoch: 4 [15360/50176]	Loss: 2.8763
Training Epoch: 4 [16384/50176]	Loss: 2.7590
Training Epoch: 4 [17408/50176]	Loss: 2.8388
Training Epoch: 4 [18432/50176]	Loss: 2.8530
Training Epoch: 4 [19456/50176]	Loss: 2.8599
Training Epoch: 4 [20480/50176]	Loss: 2.8334
Training Epoch: 4 [21504/50176]	Loss: 2.8754
Training Epoch: 4 [22528/50176]	Loss: 2.8043
Training Epoch: 4 [23552/50176]	Loss: 2.7655
Training Epoch: 4 [24576/50176]	Loss: 2.7927
Training Epoch: 4 [25600/50176]	Loss: 2.7855
Training Epoch: 4 [26624/50176]	Loss: 2.7518
Training Epoch: 4 [27648/50176]	Loss: 2.8340
Training Epoch: 4 [28672/50176]	Loss: 2.7310
Training Epoch: 4 [29696/50176]	Loss: 2.8430
Training Epoch: 4 [30720/50176]	Loss: 2.8383
Training Epoch: 4 [31744/50176]	Loss: 2.7944
Training Epoch: 4 [32768/50176]	Loss: 2.8265
Training Epoch: 4 [33792/50176]	Loss: 2.7853
Training Epoch: 4 [34816/50176]	Loss: 2.7118
Training Epoch: 4 [35840/50176]	Loss: 2.8437
Training Epoch: 4 [36864/50176]	Loss: 2.7828
Training Epoch: 4 [37888/50176]	Loss: 2.9519
Training Epoch: 4 [38912/50176]	Loss: 2.7773
Training Epoch: 4 [39936/50176]	Loss: 2.7428
Training Epoch: 4 [40960/50176]	Loss: 2.7217
Training Epoch: 4 [41984/50176]	Loss: 2.6957
Training Epoch: 4 [43008/50176]	Loss: 2.7389
Training Epoch: 4 [44032/50176]	Loss: 2.7021
Training Epoch: 4 [45056/50176]	Loss: 2.7359
Training Epoch: 4 [46080/50176]	Loss: 2.8238
Training Epoch: 4 [47104/50176]	Loss: 2.8524
Training Epoch: 4 [48128/50176]	Loss: 2.7892
Training Epoch: 4 [49152/50176]	Loss: 2.7825
Training Epoch: 4 [50176/50176]	Loss: 2.8959
2022-12-08 22:46:10.305 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:46:10,320 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.76 energy=511.24
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Up to epoch 5: time=338.61, energy=42367.77, cost=50812.67
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Expected next epoch: time=385.58, energy=49587.84, cost=58532.48
2022-12-08 17:46:10,322 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0028, Accuracy: 0.2749
2022-12-08 17:46:10,563 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:46:10,564 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:46:10.578 [ZeusMonitor] Monitor started.
2022-12-08 22:46:10.578 [ZeusMonitor] Running indefinitely. 2022-12-08 22:46:10.578 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:46:10.578 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e6+gpu0.power.log
2022-12-08 17:46:54,973 [ZeusDataLoader(train)] train epoch 6 done: time=44.64 energy=6778.34
2022-12-08 17:46:54,977 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.5503
Training Epoch: 5 [2048/50176]	Loss: 2.6450
Training Epoch: 5 [3072/50176]	Loss: 2.7770
Training Epoch: 5 [4096/50176]	Loss: 2.6097
Training Epoch: 5 [5120/50176]	Loss: 2.6012
Training Epoch: 5 [6144/50176]	Loss: 2.6692
Training Epoch: 5 [7168/50176]	Loss: 2.5702
Training Epoch: 5 [8192/50176]	Loss: 2.5819
Training Epoch: 5 [9216/50176]	Loss: 2.5477
Training Epoch: 5 [10240/50176]	Loss: 2.6818
Training Epoch: 5 [11264/50176]	Loss: 2.7209
Training Epoch: 5 [12288/50176]	Loss: 2.5369
Training Epoch: 5 [13312/50176]	Loss: 2.6260
Training Epoch: 5 [14336/50176]	Loss: 2.5694
Training Epoch: 5 [15360/50176]	Loss: 2.6594
Training Epoch: 5 [16384/50176]	Loss: 2.5763
Training Epoch: 5 [17408/50176]	Loss: 2.6138
Training Epoch: 5 [18432/50176]	Loss: 2.5438
Training Epoch: 5 [19456/50176]	Loss: 2.6227
Training Epoch: 5 [20480/50176]	Loss: 2.6105
Training Epoch: 5 [21504/50176]	Loss: 2.5486
Training Epoch: 5 [22528/50176]	Loss: 2.6570
Training Epoch: 5 [23552/50176]	Loss: 2.6426
Training Epoch: 5 [24576/50176]	Loss: 2.6466
Training Epoch: 5 [25600/50176]	Loss: 2.5592
Training Epoch: 5 [26624/50176]	Loss: 2.5638
Training Epoch: 5 [27648/50176]	Loss: 2.5938
Training Epoch: 5 [28672/50176]	Loss: 2.6271
Training Epoch: 5 [29696/50176]	Loss: 2.5469
Training Epoch: 5 [30720/50176]	Loss: 2.5297
Training Epoch: 5 [31744/50176]	Loss: 2.6295
Training Epoch: 5 [32768/50176]	Loss: 2.6079
Training Epoch: 5 [33792/50176]	Loss: 2.5120
Training Epoch: 5 [34816/50176]	Loss: 2.5706
Training Epoch: 5 [35840/50176]	Loss: 2.6083
Training Epoch: 5 [36864/50176]	Loss: 2.4759
Training Epoch: 5 [37888/50176]	Loss: 2.4812
Training Epoch: 5 [38912/50176]	Loss: 2.5108
Training Epoch: 5 [39936/50176]	Loss: 2.5770
Training Epoch: 5 [40960/50176]	Loss: 2.4255
Training Epoch: 5 [41984/50176]	Loss: 2.5435
Training Epoch: 5 [43008/50176]	Loss: 2.5512
Training Epoch: 5 [44032/50176]	Loss: 2.5799
Training Epoch: 5 [45056/50176]	Loss: 2.6480
Training Epoch: 5 [46080/50176]	Loss: 2.4604
Training Epoch: 5 [47104/50176]	Loss: 2.5019
Training Epoch: 5 [48128/50176]	Loss: 2.5481
Training Epoch: 5 [49152/50176]	Loss: 2.5648
Training Epoch: 5 [50176/50176]	Loss: 2.5076
2022-12-08 22:46:58.792 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:46:58,821 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.84 energy=532.30
2022-12-08 17:46:58,821 [ZeusDataLoader(train)] Up to epoch 6: time=387.09, energy=49678.40, cost=58709.84
2022-12-08 17:46:58,821 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:46:58,822 [ZeusDataLoader(train)] Expected next epoch: time=434.06, energy=56898.47, cost=66429.66
2022-12-08 17:46:58,823 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0026, Accuracy: 0.3287
2022-12-08 17:46:59,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:46:59,043 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:46:59.045 [ZeusMonitor] Monitor started.
2022-12-08 22:46:59.045 [ZeusMonitor] Running indefinitely. 2022-12-08 22:46:59.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:46:59.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e7+gpu0.power.log
2022-12-08 17:47:43,115 [ZeusDataLoader(train)] train epoch 7 done: time=44.28 energy=6735.62
2022-12-08 17:47:43,119 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.4289
Training Epoch: 6 [2048/50176]	Loss: 2.3255
Training Epoch: 6 [3072/50176]	Loss: 2.4750
Training Epoch: 6 [4096/50176]	Loss: 2.4507
Training Epoch: 6 [5120/50176]	Loss: 2.3279
Training Epoch: 6 [6144/50176]	Loss: 2.4013
Training Epoch: 6 [7168/50176]	Loss: 2.3858
Training Epoch: 6 [8192/50176]	Loss: 2.3379
Training Epoch: 6 [9216/50176]	Loss: 2.4862
Training Epoch: 6 [10240/50176]	Loss: 2.4500
Training Epoch: 6 [11264/50176]	Loss: 2.3590
Training Epoch: 6 [12288/50176]	Loss: 2.4640
Training Epoch: 6 [13312/50176]	Loss: 2.3647
Training Epoch: 6 [14336/50176]	Loss: 2.3297
Training Epoch: 6 [15360/50176]	Loss: 2.2848
Training Epoch: 6 [16384/50176]	Loss: 2.3952
Training Epoch: 6 [17408/50176]	Loss: 2.3308
Training Epoch: 6 [18432/50176]	Loss: 2.4060
Training Epoch: 6 [19456/50176]	Loss: 2.3155
Training Epoch: 6 [20480/50176]	Loss: 2.4199
Training Epoch: 6 [21504/50176]	Loss: 2.4303
Training Epoch: 6 [22528/50176]	Loss: 2.3813
Training Epoch: 6 [23552/50176]	Loss: 2.3837
Training Epoch: 6 [24576/50176]	Loss: 2.3603
Training Epoch: 6 [25600/50176]	Loss: 2.3395
Training Epoch: 6 [26624/50176]	Loss: 2.4119
Training Epoch: 6 [27648/50176]	Loss: 2.3240
Training Epoch: 6 [28672/50176]	Loss: 2.2240
Training Epoch: 6 [29696/50176]	Loss: 2.3463
Training Epoch: 6 [30720/50176]	Loss: 2.2659
Training Epoch: 6 [31744/50176]	Loss: 2.2949
Training Epoch: 6 [32768/50176]	Loss: 2.2997
Training Epoch: 6 [33792/50176]	Loss: 2.3484
Training Epoch: 6 [34816/50176]	Loss: 2.3935
Training Epoch: 6 [35840/50176]	Loss: 2.3598
Training Epoch: 6 [36864/50176]	Loss: 2.4138
Training Epoch: 6 [37888/50176]	Loss: 2.4065
Training Epoch: 6 [38912/50176]	Loss: 2.3489
Training Epoch: 6 [39936/50176]	Loss: 2.4211
Training Epoch: 6 [40960/50176]	Loss: 2.3646
Training Epoch: 6 [41984/50176]	Loss: 2.3354
Training Epoch: 6 [43008/50176]	Loss: 2.3131
Training Epoch: 6 [44032/50176]	Loss: 2.3169
Training Epoch: 6 [45056/50176]	Loss: 2.3192
Training Epoch: 6 [46080/50176]	Loss: 2.4005
Training Epoch: 6 [47104/50176]	Loss: 2.2926
Training Epoch: 6 [48128/50176]	Loss: 2.3516
Training Epoch: 6 [49152/50176]	Loss: 2.3073
Training Epoch: 6 [50176/50176]	Loss: 2.3037
2022-12-08 22:47:46.878 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:47:46,914 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.79 energy=520.90
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Up to epoch 7: time=435.16, energy=56934.92, cost=66544.35
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Expected next epoch: time=482.13, energy=64154.99, cost=74264.17
2022-12-08 17:47:46,916 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0023, Accuracy: 0.3712
2022-12-08 17:47:47,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:47:47,139 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:47:47.141 [ZeusMonitor] Monitor started.
2022-12-08 22:47:47.141 [ZeusMonitor] Running indefinitely. 2022-12-08 22:47:47.141 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:47:47.141 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e8+gpu0.power.log
2022-12-08 17:48:31,061 [ZeusDataLoader(train)] train epoch 8 done: time=44.14 energy=6699.75
2022-12-08 17:48:31,065 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.2442
Training Epoch: 7 [2048/50176]	Loss: 2.1902
Training Epoch: 7 [3072/50176]	Loss: 2.1735
Training Epoch: 7 [4096/50176]	Loss: 2.1470
Training Epoch: 7 [5120/50176]	Loss: 2.2346
Training Epoch: 7 [6144/50176]	Loss: 2.1513
Training Epoch: 7 [7168/50176]	Loss: 2.2158
Training Epoch: 7 [8192/50176]	Loss: 2.1925
Training Epoch: 7 [9216/50176]	Loss: 2.0649
Training Epoch: 7 [10240/50176]	Loss: 2.0871
Training Epoch: 7 [11264/50176]	Loss: 2.1284
Training Epoch: 7 [12288/50176]	Loss: 2.2311
Training Epoch: 7 [13312/50176]	Loss: 2.1979
Training Epoch: 7 [14336/50176]	Loss: 2.2673
Training Epoch: 7 [15360/50176]	Loss: 2.1679
Training Epoch: 7 [16384/50176]	Loss: 2.1993
Training Epoch: 7 [17408/50176]	Loss: 2.2400
Training Epoch: 7 [18432/50176]	Loss: 2.1729
Training Epoch: 7 [19456/50176]	Loss: 2.1509
Training Epoch: 7 [20480/50176]	Loss: 2.1874
Training Epoch: 7 [21504/50176]	Loss: 2.2800
Training Epoch: 7 [22528/50176]	Loss: 2.2041
Training Epoch: 7 [23552/50176]	Loss: 2.1650
Training Epoch: 7 [24576/50176]	Loss: 2.1513
Training Epoch: 7 [25600/50176]	Loss: 2.1585
Training Epoch: 7 [26624/50176]	Loss: 2.2813
Training Epoch: 7 [27648/50176]	Loss: 2.2404
Training Epoch: 7 [28672/50176]	Loss: 2.1195
Training Epoch: 7 [29696/50176]	Loss: 2.1746
Training Epoch: 7 [30720/50176]	Loss: 2.1869
Training Epoch: 7 [31744/50176]	Loss: 2.2177
Training Epoch: 7 [32768/50176]	Loss: 2.0978
Training Epoch: 7 [33792/50176]	Loss: 2.2193
Training Epoch: 7 [34816/50176]	Loss: 2.2286
Training Epoch: 7 [35840/50176]	Loss: 2.1220
Training Epoch: 7 [36864/50176]	Loss: 2.0427
Training Epoch: 7 [37888/50176]	Loss: 2.0819
Training Epoch: 7 [38912/50176]	Loss: 2.1658
Training Epoch: 7 [39936/50176]	Loss: 2.2385
Training Epoch: 7 [40960/50176]	Loss: 2.2245
Training Epoch: 7 [41984/50176]	Loss: 2.1026
Training Epoch: 7 [43008/50176]	Loss: 2.0612
Training Epoch: 7 [44032/50176]	Loss: 2.0901
Training Epoch: 7 [45056/50176]	Loss: 2.1326
Training Epoch: 7 [46080/50176]	Loss: 2.1906
Training Epoch: 7 [47104/50176]	Loss: 2.0932
Training Epoch: 7 [48128/50176]	Loss: 2.1108
Training Epoch: 7 [49152/50176]	Loss: 2.2335
Training Epoch: 7 [50176/50176]	Loss: 2.0281
2022-12-08 22:48:34.841 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:48:34,867 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.79 energy=532.56
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Up to epoch 8: time=483.09, energy=64167.24, cost=74354.28
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Expected next epoch: time=530.06, energy=71387.31, cost=82074.10
2022-12-08 17:48:34,869 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0023, Accuracy: 0.3880
2022-12-08 17:48:35,070 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:48:35,071 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:48:35.073 [ZeusMonitor] Monitor started.
2022-12-08 22:48:35.073 [ZeusMonitor] Running indefinitely. 2022-12-08 22:48:35.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:48:35.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e9+gpu0.power.log
2022-12-08 17:49:19,074 [ZeusDataLoader(train)] train epoch 9 done: time=44.20 energy=6701.48
2022-12-08 17:49:19,079 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.1301
Training Epoch: 8 [2048/50176]	Loss: 2.1079
Training Epoch: 8 [3072/50176]	Loss: 2.0680
Training Epoch: 8 [4096/50176]	Loss: 2.0088
Training Epoch: 8 [5120/50176]	Loss: 1.9598
Training Epoch: 8 [6144/50176]	Loss: 2.0537
Training Epoch: 8 [7168/50176]	Loss: 2.0101
Training Epoch: 8 [8192/50176]	Loss: 2.0268
Training Epoch: 8 [9216/50176]	Loss: 2.0068
Training Epoch: 8 [10240/50176]	Loss: 2.0661
Training Epoch: 8 [11264/50176]	Loss: 2.0999
Training Epoch: 8 [12288/50176]	Loss: 2.0425
Training Epoch: 8 [13312/50176]	Loss: 2.0678
Training Epoch: 8 [14336/50176]	Loss: 2.0180
Training Epoch: 8 [15360/50176]	Loss: 2.0599
Training Epoch: 8 [16384/50176]	Loss: 2.0127
Training Epoch: 8 [17408/50176]	Loss: 2.1363
Training Epoch: 8 [18432/50176]	Loss: 2.0415
Training Epoch: 8 [19456/50176]	Loss: 2.0141
Training Epoch: 8 [20480/50176]	Loss: 1.9737
Training Epoch: 8 [21504/50176]	Loss: 1.9829
Training Epoch: 8 [22528/50176]	Loss: 2.0164
Training Epoch: 8 [23552/50176]	Loss: 2.0090
Training Epoch: 8 [24576/50176]	Loss: 2.0280
Training Epoch: 8 [25600/50176]	Loss: 2.0786
Training Epoch: 8 [26624/50176]	Loss: 2.0150
Training Epoch: 8 [27648/50176]	Loss: 1.9491
Training Epoch: 8 [28672/50176]	Loss: 2.0480
Training Epoch: 8 [29696/50176]	Loss: 1.9968
Training Epoch: 8 [30720/50176]	Loss: 2.0234
Training Epoch: 8 [31744/50176]	Loss: 2.0117
Training Epoch: 8 [32768/50176]	Loss: 1.9647
Training Epoch: 8 [33792/50176]	Loss: 2.0752
Training Epoch: 8 [34816/50176]	Loss: 2.0767
Training Epoch: 8 [35840/50176]	Loss: 2.0657
Training Epoch: 8 [36864/50176]	Loss: 2.0288
Training Epoch: 8 [37888/50176]	Loss: 2.0709
Training Epoch: 8 [38912/50176]	Loss: 1.9927
Training Epoch: 8 [39936/50176]	Loss: 2.1024
Training Epoch: 8 [40960/50176]	Loss: 2.0215
Training Epoch: 8 [41984/50176]	Loss: 2.0187
Training Epoch: 8 [43008/50176]	Loss: 2.0332
Training Epoch: 8 [44032/50176]	Loss: 2.0921
Training Epoch: 8 [45056/50176]	Loss: 2.0680
Training Epoch: 8 [46080/50176]	Loss: 1.9827
Training Epoch: 8 [47104/50176]	Loss: 2.0769
Training Epoch: 8 [48128/50176]	Loss: 1.9727
Training Epoch: 8 [49152/50176]	Loss: 2.0603
Training Epoch: 8 [50176/50176]	Loss: 2.0336
2022-12-08 22:49:22.875 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:49:22,897 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.81 energy=533.16
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Up to epoch 9: time=531.10, energy=71401.89, cost=82172.26
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Expected next epoch: time=578.07, energy=78621.96, cost=89892.08
2022-12-08 17:49:22,899 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0021, Accuracy: 0.4270
2022-12-08 17:49:23,111 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:49:23,112 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:49:23.125 [ZeusMonitor] Monitor started.
2022-12-08 22:49:23.126 [ZeusMonitor] Running indefinitely. 2022-12-08 22:49:23.126 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:49:23.126 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e10+gpu0.power.log
2022-12-08 17:50:07,050 [ZeusDataLoader(train)] train epoch 10 done: time=44.14 energy=6704.10
2022-12-08 17:50:07,053 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 1.9361
Training Epoch: 9 [2048/50176]	Loss: 1.9446
Training Epoch: 9 [3072/50176]	Loss: 1.9394
Training Epoch: 9 [4096/50176]	Loss: 1.8574
Training Epoch: 9 [5120/50176]	Loss: 1.9815
Training Epoch: 9 [6144/50176]	Loss: 1.8259
Training Epoch: 9 [7168/50176]	Loss: 1.9257
Training Epoch: 9 [8192/50176]	Loss: 1.8961
Training Epoch: 9 [9216/50176]	Loss: 1.8751
Training Epoch: 9 [10240/50176]	Loss: 1.8940
Training Epoch: 9 [11264/50176]	Loss: 1.9890
Training Epoch: 9 [12288/50176]	Loss: 1.9454
Training Epoch: 9 [13312/50176]	Loss: 1.8927
Training Epoch: 9 [14336/50176]	Loss: 1.9174
Training Epoch: 9 [15360/50176]	Loss: 1.9308
Training Epoch: 9 [16384/50176]	Loss: 1.9454
Training Epoch: 9 [17408/50176]	Loss: 1.8163
Training Epoch: 9 [18432/50176]	Loss: 1.9166
Training Epoch: 9 [19456/50176]	Loss: 1.8412
Training Epoch: 9 [20480/50176]	Loss: 1.8722
Training Epoch: 9 [21504/50176]	Loss: 1.8621
Training Epoch: 9 [22528/50176]	Loss: 1.8531
Training Epoch: 9 [23552/50176]	Loss: 1.8713
Training Epoch: 9 [24576/50176]	Loss: 1.9091
Training Epoch: 9 [25600/50176]	Loss: 1.8503
Training Epoch: 9 [26624/50176]	Loss: 1.8347
Training Epoch: 9 [27648/50176]	Loss: 1.9752
Training Epoch: 9 [28672/50176]	Loss: 1.9023
Training Epoch: 9 [29696/50176]	Loss: 1.9307
Training Epoch: 9 [30720/50176]	Loss: 1.7952
Training Epoch: 9 [31744/50176]	Loss: 1.9511
Training Epoch: 9 [32768/50176]	Loss: 1.8943
Training Epoch: 9 [33792/50176]	Loss: 1.7993
Training Epoch: 9 [34816/50176]	Loss: 1.9102
Training Epoch: 9 [35840/50176]	Loss: 1.8720
Training Epoch: 9 [36864/50176]	Loss: 1.8744
Training Epoch: 9 [37888/50176]	Loss: 1.8915
Training Epoch: 9 [38912/50176]	Loss: 1.9170
Training Epoch: 9 [39936/50176]	Loss: 1.8772
Training Epoch: 9 [40960/50176]	Loss: 1.8852
Training Epoch: 9 [41984/50176]	Loss: 1.8248
Training Epoch: 9 [43008/50176]	Loss: 1.9289
Training Epoch: 9 [44032/50176]	Loss: 1.8984
Training Epoch: 9 [45056/50176]	Loss: 1.8610
Training Epoch: 9 [46080/50176]	Loss: 1.8177
Training Epoch: 9 [47104/50176]	Loss: 1.8795
Training Epoch: 9 [48128/50176]	Loss: 1.8246
Training Epoch: 9 [49152/50176]	Loss: 1.8220
Training Epoch: 9 [50176/50176]	Loss: 1.8449
2022-12-08 22:50:10.821 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:50:10,851 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.79 energy=534.01
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Up to epoch 10: time=579.03, energy=78640.00, cost=89985.37
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Expected next epoch: time=626.00, energy=85860.07, cost=97705.19
2022-12-08 17:50:10,853 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0021, Accuracy: 0.4345
2022-12-08 17:50:11,034 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:50:11,035 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:50:11.039 [ZeusMonitor] Monitor started.
2022-12-08 22:50:11.039 [ZeusMonitor] Running indefinitely. 2022-12-08 22:50:11.039 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:50:11.039 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e11+gpu0.power.log
2022-12-08 17:50:55,009 [ZeusDataLoader(train)] train epoch 11 done: time=44.15 energy=6709.81
2022-12-08 17:50:55,013 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.7946
Training Epoch: 10 [2048/50176]	Loss: 1.8128
Training Epoch: 10 [3072/50176]	Loss: 1.7192
Training Epoch: 10 [4096/50176]	Loss: 1.8936
Training Epoch: 10 [5120/50176]	Loss: 1.7841
Training Epoch: 10 [6144/50176]	Loss: 1.8473
Training Epoch: 10 [7168/50176]	Loss: 1.7371
Training Epoch: 10 [8192/50176]	Loss: 1.7674
Training Epoch: 10 [9216/50176]	Loss: 1.7403
Training Epoch: 10 [10240/50176]	Loss: 1.6766
Training Epoch: 10 [11264/50176]	Loss: 1.9221
Training Epoch: 10 [12288/50176]	Loss: 1.7556
Training Epoch: 10 [13312/50176]	Loss: 1.8935
Training Epoch: 10 [14336/50176]	Loss: 1.9296
Training Epoch: 10 [15360/50176]	Loss: 1.8389
Training Epoch: 10 [16384/50176]	Loss: 1.8891
Training Epoch: 10 [17408/50176]	Loss: 1.8608
Training Epoch: 10 [18432/50176]	Loss: 1.7840
Training Epoch: 10 [19456/50176]	Loss: 1.8379
Training Epoch: 10 [20480/50176]	Loss: 1.7958
Training Epoch: 10 [21504/50176]	Loss: 1.7965
Training Epoch: 10 [22528/50176]	Loss: 1.8065
Training Epoch: 10 [23552/50176]	Loss: 1.7993
Training Epoch: 10 [24576/50176]	Loss: 1.7903
Training Epoch: 10 [25600/50176]	Loss: 1.7652
Training Epoch: 10 [26624/50176]	Loss: 1.7582
Training Epoch: 10 [27648/50176]	Loss: 1.7576
Training Epoch: 10 [28672/50176]	Loss: 1.8260
Training Epoch: 10 [29696/50176]	Loss: 1.8659
Training Epoch: 10 [30720/50176]	Loss: 1.7044
Training Epoch: 10 [31744/50176]	Loss: 1.8662
Training Epoch: 10 [32768/50176]	Loss: 1.7430
Training Epoch: 10 [33792/50176]	Loss: 1.7765
Training Epoch: 10 [34816/50176]	Loss: 1.8043
Training Epoch: 10 [35840/50176]	Loss: 1.8714
Training Epoch: 10 [36864/50176]	Loss: 1.8573
Training Epoch: 10 [37888/50176]	Loss: 1.7251
Training Epoch: 10 [38912/50176]	Loss: 1.7163
Training Epoch: 10 [39936/50176]	Loss: 1.8288
Training Epoch: 10 [40960/50176]	Loss: 1.6506
Training Epoch: 10 [41984/50176]	Loss: 1.6354
Training Epoch: 10 [43008/50176]	Loss: 1.8231
Training Epoch: 10 [44032/50176]	Loss: 1.7812
Training Epoch: 10 [45056/50176]	Loss: 1.6826
Training Epoch: 10 [46080/50176]	Loss: 1.6803
Training Epoch: 10 [47104/50176]	Loss: 1.8126
Training Epoch: 10 [48128/50176]	Loss: 1.7899
Training Epoch: 10 [49152/50176]	Loss: 1.8074
Training Epoch: 10 [50176/50176]	Loss: 1.8167
2022-12-08 22:50:58.779 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:50:58,821 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.80 energy=520.83
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Up to epoch 11: time=626.98, energy=85870.64, cost=97796.17
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Expected next epoch: time=673.95, energy=93090.71, cost=105515.98
2022-12-08 17:50:58,823 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0019, Accuracy: 0.4778
2022-12-08 17:50:58,992 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:50:58,993 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:50:58.996 [ZeusMonitor] Monitor started.
2022-12-08 22:50:58.997 [ZeusMonitor] Running indefinitely. 2022-12-08 22:50:58.997 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:50:58.997 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e12+gpu0.power.log
2022-12-08 17:51:42,949 [ZeusDataLoader(train)] train epoch 12 done: time=44.12 energy=6705.17
2022-12-08 17:51:42,952 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.5707
Training Epoch: 11 [2048/50176]	Loss: 1.6079
Training Epoch: 11 [3072/50176]	Loss: 1.6174
Training Epoch: 11 [4096/50176]	Loss: 1.8180
Training Epoch: 11 [5120/50176]	Loss: 1.7361
Training Epoch: 11 [6144/50176]	Loss: 1.5298
Training Epoch: 11 [7168/50176]	Loss: 1.5999
Training Epoch: 11 [8192/50176]	Loss: 1.6825
Training Epoch: 11 [9216/50176]	Loss: 1.6315
Training Epoch: 11 [10240/50176]	Loss: 1.7589
Training Epoch: 11 [11264/50176]	Loss: 1.6254
Training Epoch: 11 [12288/50176]	Loss: 1.6280
Training Epoch: 11 [13312/50176]	Loss: 1.7432
Training Epoch: 11 [14336/50176]	Loss: 1.5908
Training Epoch: 11 [15360/50176]	Loss: 1.7472
Training Epoch: 11 [16384/50176]	Loss: 1.7103
Training Epoch: 11 [17408/50176]	Loss: 1.6438
Training Epoch: 11 [18432/50176]	Loss: 1.6711
Training Epoch: 11 [19456/50176]	Loss: 1.6510
Training Epoch: 11 [20480/50176]	Loss: 1.7686
Training Epoch: 11 [21504/50176]	Loss: 1.7671
Training Epoch: 11 [22528/50176]	Loss: 1.6975
Training Epoch: 11 [23552/50176]	Loss: 1.7639
Training Epoch: 11 [24576/50176]	Loss: 1.6437
Training Epoch: 11 [25600/50176]	Loss: 1.6597
Training Epoch: 11 [26624/50176]	Loss: 1.6928
Training Epoch: 11 [27648/50176]	Loss: 1.6786
Training Epoch: 11 [28672/50176]	Loss: 1.6538
Training Epoch: 11 [29696/50176]	Loss: 1.7255
Training Epoch: 11 [30720/50176]	Loss: 1.6312
Training Epoch: 11 [31744/50176]	Loss: 1.6984
Training Epoch: 11 [32768/50176]	Loss: 1.7194
Training Epoch: 11 [33792/50176]	Loss: 1.7601
Training Epoch: 11 [34816/50176]	Loss: 1.8226
Training Epoch: 11 [35840/50176]	Loss: 1.7074
Training Epoch: 11 [36864/50176]	Loss: 1.6516
Training Epoch: 11 [37888/50176]	Loss: 1.7150
Training Epoch: 11 [38912/50176]	Loss: 1.6905
Training Epoch: 11 [39936/50176]	Loss: 1.7073
Training Epoch: 11 [40960/50176]	Loss: 1.6626
Training Epoch: 11 [41984/50176]	Loss: 1.6990
Training Epoch: 11 [43008/50176]	Loss: 1.7132
Training Epoch: 11 [44032/50176]	Loss: 1.6417
Training Epoch: 11 [45056/50176]	Loss: 1.7342
Training Epoch: 11 [46080/50176]	Loss: 1.6015
Training Epoch: 11 [47104/50176]	Loss: 1.7173
Training Epoch: 11 [48128/50176]	Loss: 1.7137
Training Epoch: 11 [49152/50176]	Loss: 1.6672
Training Epoch: 11 [50176/50176]	Loss: 1.6790
2022-12-08 22:51:46.722 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:51:46,770 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.81 energy=531.98
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Up to epoch 12: time=674.91, energy=93107.79, cost=105608.24
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Expected next epoch: time=721.88, energy=100327.86, cost=113328.06
2022-12-08 17:51:46,771 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0019, Accuracy: 0.4757
2022-12-08 17:51:46,997 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:51:46,998 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:51:47.000 [ZeusMonitor] Monitor started.
2022-12-08 22:51:47.000 [ZeusMonitor] Running indefinitely. 2022-12-08 22:51:47.000 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:51:47.000 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e13+gpu0.power.log
2022-12-08 17:52:30,927 [ZeusDataLoader(train)] train epoch 13 done: time=44.15 energy=6713.34
2022-12-08 17:52:30,931 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.6396
Training Epoch: 12 [2048/50176]	Loss: 1.5612
Training Epoch: 12 [3072/50176]	Loss: 1.6720
Training Epoch: 12 [4096/50176]	Loss: 1.5680
Training Epoch: 12 [5120/50176]	Loss: 1.5577
Training Epoch: 12 [6144/50176]	Loss: 1.6539
Training Epoch: 12 [7168/50176]	Loss: 1.6489
Training Epoch: 12 [8192/50176]	Loss: 1.4891
Training Epoch: 12 [9216/50176]	Loss: 1.6761
Training Epoch: 12 [10240/50176]	Loss: 1.5676
Training Epoch: 12 [11264/50176]	Loss: 1.7461
Training Epoch: 12 [12288/50176]	Loss: 1.5880
Training Epoch: 12 [13312/50176]	Loss: 1.5406
Training Epoch: 12 [14336/50176]	Loss: 1.5602
Training Epoch: 12 [15360/50176]	Loss: 1.5317
Training Epoch: 12 [16384/50176]	Loss: 1.5778
Training Epoch: 12 [17408/50176]	Loss: 1.5440
Training Epoch: 12 [18432/50176]	Loss: 1.6091
Training Epoch: 12 [19456/50176]	Loss: 1.5827
Training Epoch: 12 [20480/50176]	Loss: 1.6022
Training Epoch: 12 [21504/50176]	Loss: 1.7263
Training Epoch: 12 [22528/50176]	Loss: 1.5700
Training Epoch: 12 [23552/50176]	Loss: 1.6493
Training Epoch: 12 [24576/50176]	Loss: 1.5473
Training Epoch: 12 [25600/50176]	Loss: 1.6234
Training Epoch: 12 [26624/50176]	Loss: 1.6998
Training Epoch: 12 [27648/50176]	Loss: 1.5133
Training Epoch: 12 [28672/50176]	Loss: 1.6399
Training Epoch: 12 [29696/50176]	Loss: 1.6085
Training Epoch: 12 [30720/50176]	Loss: 1.5461
Training Epoch: 12 [31744/50176]	Loss: 1.5947
Training Epoch: 12 [32768/50176]	Loss: 1.6222
Training Epoch: 12 [33792/50176]	Loss: 1.5324
Training Epoch: 12 [34816/50176]	Loss: 1.5350
Training Epoch: 12 [35840/50176]	Loss: 1.6052
Training Epoch: 12 [36864/50176]	Loss: 1.6165
Training Epoch: 12 [37888/50176]	Loss: 1.6470
Training Epoch: 12 [38912/50176]	Loss: 1.5555
Training Epoch: 12 [39936/50176]	Loss: 1.6201
Training Epoch: 12 [40960/50176]	Loss: 1.5060
Training Epoch: 12 [41984/50176]	Loss: 1.6755
Training Epoch: 12 [43008/50176]	Loss: 1.5861
Training Epoch: 12 [44032/50176]	Loss: 1.6837
Training Epoch: 12 [45056/50176]	Loss: 1.5508
Training Epoch: 12 [46080/50176]	Loss: 1.6186
Training Epoch: 12 [47104/50176]	Loss: 1.5674
Training Epoch: 12 [48128/50176]	Loss: 1.5787
Training Epoch: 12 [49152/50176]	Loss: 1.6114
Training Epoch: 12 [50176/50176]	Loss: 1.5680
2022-12-08 22:52:34.669 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:52:34,704 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.77 energy=518.27
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Up to epoch 13: time=722.82, energy=100339.40, cost=113416.36
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Expected next epoch: time=769.79, energy=107559.47, cost=121136.18
2022-12-08 17:52:34,706 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0018, Accuracy: 0.4959
2022-12-08 17:52:34,927 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:52:34,928 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:52:34.942 [ZeusMonitor] Monitor started.
2022-12-08 22:52:34.942 [ZeusMonitor] Running indefinitely. 2022-12-08 22:52:34.942 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:52:34.942 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e14+gpu0.power.log
2022-12-08 17:53:18,910 [ZeusDataLoader(train)] train epoch 14 done: time=44.20 energy=6713.76
2022-12-08 17:53:18,914 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.5313
Training Epoch: 13 [2048/50176]	Loss: 1.5063
Training Epoch: 13 [3072/50176]	Loss: 1.5353
Training Epoch: 13 [4096/50176]	Loss: 1.4375
Training Epoch: 13 [5120/50176]	Loss: 1.4878
Training Epoch: 13 [6144/50176]	Loss: 1.5568
Training Epoch: 13 [7168/50176]	Loss: 1.4620
Training Epoch: 13 [8192/50176]	Loss: 1.4524
Training Epoch: 13 [9216/50176]	Loss: 1.4674
Training Epoch: 13 [10240/50176]	Loss: 1.6480
Training Epoch: 13 [11264/50176]	Loss: 1.4386
Training Epoch: 13 [12288/50176]	Loss: 1.5121
Training Epoch: 13 [13312/50176]	Loss: 1.5336
Training Epoch: 13 [14336/50176]	Loss: 1.4871
Training Epoch: 13 [15360/50176]	Loss: 1.5454
Training Epoch: 13 [16384/50176]	Loss: 1.4949
Training Epoch: 13 [17408/50176]	Loss: 1.5407
Training Epoch: 13 [18432/50176]	Loss: 1.4587
Training Epoch: 13 [19456/50176]	Loss: 1.5056
Training Epoch: 13 [20480/50176]	Loss: 1.5041
Training Epoch: 13 [21504/50176]	Loss: 1.5126
Training Epoch: 13 [22528/50176]	Loss: 1.4790
Training Epoch: 13 [23552/50176]	Loss: 1.5166
Training Epoch: 13 [24576/50176]	Loss: 1.4762
Training Epoch: 13 [25600/50176]	Loss: 1.5386
Training Epoch: 13 [26624/50176]	Loss: 1.6107
Training Epoch: 13 [27648/50176]	Loss: 1.5045
Training Epoch: 13 [28672/50176]	Loss: 1.5085
Training Epoch: 13 [29696/50176]	Loss: 1.4687
Training Epoch: 13 [30720/50176]	Loss: 1.4862
Training Epoch: 13 [31744/50176]	Loss: 1.5409
Training Epoch: 13 [32768/50176]	Loss: 1.4634
Training Epoch: 13 [33792/50176]	Loss: 1.6120
Training Epoch: 13 [34816/50176]	Loss: 1.6203
Training Epoch: 13 [35840/50176]	Loss: 1.6160
Training Epoch: 13 [36864/50176]	Loss: 1.5447
Training Epoch: 13 [37888/50176]	Loss: 1.5829
Training Epoch: 13 [38912/50176]	Loss: 1.4629
Training Epoch: 13 [39936/50176]	Loss: 1.4810
Training Epoch: 13 [40960/50176]	Loss: 1.5770
Training Epoch: 13 [41984/50176]	Loss: 1.4942
Training Epoch: 13 [43008/50176]	Loss: 1.4354
Training Epoch: 13 [44032/50176]	Loss: 1.5650
Training Epoch: 13 [45056/50176]	Loss: 1.4945
Training Epoch: 13 [46080/50176]	Loss: 1.4949
Training Epoch: 13 [47104/50176]	Loss: 1.4769
Training Epoch: 13 [48128/50176]	Loss: 1.5229
Training Epoch: 13 [49152/50176]	Loss: 1.4808
Training Epoch: 13 [50176/50176]	Loss: 1.6495
2022-12-08 22:53:22.651 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:53:22,672 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.75 energy=516.93
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Up to epoch 14: time=770.76, energy=107570.09, cost=121226.91
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Expected next epoch: time=817.73, energy=114790.16, cost=128946.72
2022-12-08 17:53:22,673 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0017, Accuracy: 0.5095
2022-12-08 17:53:22,888 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:53:22,889 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:53:22.903 [ZeusMonitor] Monitor started.
2022-12-08 22:53:22.903 [ZeusMonitor] Running indefinitely. 2022-12-08 22:53:22.903 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:53:22.903 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e15+gpu0.power.log
2022-12-08 17:54:07,040 [ZeusDataLoader(train)] train epoch 15 done: time=44.34 energy=6722.29
2022-12-08 17:54:07,052 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.3875
Training Epoch: 14 [2048/50176]	Loss: 1.4910
Training Epoch: 14 [3072/50176]	Loss: 1.4570
Training Epoch: 14 [4096/50176]	Loss: 1.5257
Training Epoch: 14 [5120/50176]	Loss: 1.3966
Training Epoch: 14 [6144/50176]	Loss: 1.4010
Training Epoch: 14 [7168/50176]	Loss: 1.3315
Training Epoch: 14 [8192/50176]	Loss: 1.3981
Training Epoch: 14 [9216/50176]	Loss: 1.3479
Training Epoch: 14 [10240/50176]	Loss: 1.3858
Training Epoch: 14 [11264/50176]	Loss: 1.3598
Training Epoch: 14 [12288/50176]	Loss: 1.4455
Training Epoch: 14 [13312/50176]	Loss: 1.4350
Training Epoch: 14 [14336/50176]	Loss: 1.3745
Training Epoch: 14 [15360/50176]	Loss: 1.4193
Training Epoch: 14 [16384/50176]	Loss: 1.3428
Training Epoch: 14 [17408/50176]	Loss: 1.4611
Training Epoch: 14 [18432/50176]	Loss: 1.4503
Training Epoch: 14 [19456/50176]	Loss: 1.4001
Training Epoch: 14 [20480/50176]	Loss: 1.3988
Training Epoch: 14 [21504/50176]	Loss: 1.4695
Training Epoch: 14 [22528/50176]	Loss: 1.4151
Training Epoch: 14 [23552/50176]	Loss: 1.4290
Training Epoch: 14 [24576/50176]	Loss: 1.4541
Training Epoch: 14 [25600/50176]	Loss: 1.5576
Training Epoch: 14 [26624/50176]	Loss: 1.3824
Training Epoch: 14 [27648/50176]	Loss: 1.3657
Training Epoch: 14 [28672/50176]	Loss: 1.5404
Training Epoch: 14 [29696/50176]	Loss: 1.4398
Training Epoch: 14 [30720/50176]	Loss: 1.4847
Training Epoch: 14 [31744/50176]	Loss: 1.4137
Training Epoch: 14 [32768/50176]	Loss: 1.5654
Training Epoch: 14 [33792/50176]	Loss: 1.4692
Training Epoch: 14 [34816/50176]	Loss: 1.4591
Training Epoch: 14 [35840/50176]	Loss: 1.4811
Training Epoch: 14 [36864/50176]	Loss: 1.5663
Training Epoch: 14 [37888/50176]	Loss: 1.4220
Training Epoch: 14 [38912/50176]	Loss: 1.4982
Training Epoch: 14 [39936/50176]	Loss: 1.4402
Training Epoch: 14 [40960/50176]	Loss: 1.4749
Training Epoch: 14 [41984/50176]	Loss: 1.5467
Training Epoch: 14 [43008/50176]	Loss: 1.4665
Training Epoch: 14 [44032/50176]	Loss: 1.4377
Training Epoch: 14 [45056/50176]	Loss: 1.5083
Training Epoch: 14 [46080/50176]	Loss: 1.4600
Training Epoch: 14 [47104/50176]	Loss: 1.4108
Training Epoch: 14 [48128/50176]	Loss: 1.4180
Training Epoch: 14 [49152/50176]	Loss: 1.4360
Training Epoch: 14 [50176/50176]	Loss: 1.4637
2022-12-08 22:54:11.423 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:54:11,467 [ZeusDataLoader(eval)] eval epoch 15 done: time=4.41 energy=561.95
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Up to epoch 15: time=819.51, energy=114854.33, cost=129134.05
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Expected next epoch: time=866.48, energy=122074.40, cost=136853.87
2022-12-08 17:54:11,469 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.4982
2022-12-08 17:54:11,703 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:54:11,704 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:54:11.706 [ZeusMonitor] Monitor started.
2022-12-08 22:54:11.706 [ZeusMonitor] Running indefinitely. 2022-12-08 22:54:11.706 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:54:11.706 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e16+gpu0.power.log
2022-12-08 17:54:55,733 [ZeusDataLoader(train)] train epoch 16 done: time=44.26 energy=6711.95
2022-12-08 17:54:55,737 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.4077
Training Epoch: 15 [2048/50176]	Loss: 1.3456
Training Epoch: 15 [3072/50176]	Loss: 1.3574
Training Epoch: 15 [4096/50176]	Loss: 1.3107
Training Epoch: 15 [5120/50176]	Loss: 1.3365
Training Epoch: 15 [6144/50176]	Loss: 1.3745
Training Epoch: 15 [7168/50176]	Loss: 1.3221
Training Epoch: 15 [8192/50176]	Loss: 1.4159
Training Epoch: 15 [9216/50176]	Loss: 1.3107
Training Epoch: 15 [10240/50176]	Loss: 1.3245
Training Epoch: 15 [11264/50176]	Loss: 1.3141
Training Epoch: 15 [12288/50176]	Loss: 1.4264
Training Epoch: 15 [13312/50176]	Loss: 1.2840
Training Epoch: 15 [14336/50176]	Loss: 1.3952
Training Epoch: 15 [15360/50176]	Loss: 1.3759
Training Epoch: 15 [16384/50176]	Loss: 1.4197
Training Epoch: 15 [17408/50176]	Loss: 1.3944
Training Epoch: 15 [18432/50176]	Loss: 1.3799
Training Epoch: 15 [19456/50176]	Loss: 1.3234
Training Epoch: 15 [20480/50176]	Loss: 1.3248
Training Epoch: 15 [21504/50176]	Loss: 1.2833
Training Epoch: 15 [22528/50176]	Loss: 1.4476
Training Epoch: 15 [23552/50176]	Loss: 1.3943
Training Epoch: 15 [24576/50176]	Loss: 1.3311
Training Epoch: 15 [25600/50176]	Loss: 1.3925
Training Epoch: 15 [26624/50176]	Loss: 1.3428
Training Epoch: 15 [27648/50176]	Loss: 1.3953
Training Epoch: 15 [28672/50176]	Loss: 1.3143
Training Epoch: 15 [29696/50176]	Loss: 1.3893
Training Epoch: 15 [30720/50176]	Loss: 1.3536
Training Epoch: 15 [31744/50176]	Loss: 1.3994
Training Epoch: 15 [32768/50176]	Loss: 1.3618
Training Epoch: 15 [33792/50176]	Loss: 1.3436
Training Epoch: 15 [34816/50176]	Loss: 1.4210
Training Epoch: 15 [35840/50176]	Loss: 1.3943
Training Epoch: 15 [36864/50176]	Loss: 1.3391
Training Epoch: 15 [37888/50176]	Loss: 1.3825
Training Epoch: 15 [38912/50176]	Loss: 1.3950
Training Epoch: 15 [39936/50176]	Loss: 1.3477
Training Epoch: 15 [40960/50176]	Loss: 1.4185
Training Epoch: 15 [41984/50176]	Loss: 1.4266
Training Epoch: 15 [43008/50176]	Loss: 1.4483
Training Epoch: 15 [44032/50176]	Loss: 1.3715
Training Epoch: 15 [45056/50176]	Loss: 1.3280
Training Epoch: 15 [46080/50176]	Loss: 1.3698
Training Epoch: 15 [47104/50176]	Loss: 1.3130
Training Epoch: 15 [48128/50176]	Loss: 1.4135
Training Epoch: 15 [49152/50176]	Loss: 1.3251
Training Epoch: 15 [50176/50176]	Loss: 1.3714
2022-12-08 22:54:59.529 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:54:59,550 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.80 energy=532.31
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Up to epoch 16: time=867.57, energy=122098.59, cost=136961.37
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Expected next epoch: time=914.54, energy=129318.66, cost=144681.18
2022-12-08 17:54:59,551 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0017, Accuracy: 0.5340
2022-12-08 17:54:59,767 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:54:59,768 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:54:59.770 [ZeusMonitor] Monitor started.
2022-12-08 22:54:59.770 [ZeusMonitor] Running indefinitely. 2022-12-08 22:54:59.770 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:54:59.770 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e17+gpu0.power.log
2022-12-08 17:55:43,747 [ZeusDataLoader(train)] train epoch 17 done: time=44.19 energy=6713.34
2022-12-08 17:55:43,750 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.3181
Training Epoch: 16 [2048/50176]	Loss: 1.2958
Training Epoch: 16 [3072/50176]	Loss: 1.3340
Training Epoch: 16 [4096/50176]	Loss: 1.3040
Training Epoch: 16 [5120/50176]	Loss: 1.2892
Training Epoch: 16 [6144/50176]	Loss: 1.2403
Training Epoch: 16 [7168/50176]	Loss: 1.2275
Training Epoch: 16 [8192/50176]	Loss: 1.2198
Training Epoch: 16 [9216/50176]	Loss: 1.3040
Training Epoch: 16 [10240/50176]	Loss: 1.2650
Training Epoch: 16 [11264/50176]	Loss: 1.3311
Training Epoch: 16 [12288/50176]	Loss: 1.2985
Training Epoch: 16 [13312/50176]	Loss: 1.2995
Training Epoch: 16 [14336/50176]	Loss: 1.3174
Training Epoch: 16 [15360/50176]	Loss: 1.3985
Training Epoch: 16 [16384/50176]	Loss: 1.2712
Training Epoch: 16 [17408/50176]	Loss: 1.2606
Training Epoch: 16 [18432/50176]	Loss: 1.4036
Training Epoch: 16 [19456/50176]	Loss: 1.2756
Training Epoch: 16 [20480/50176]	Loss: 1.2616
Training Epoch: 16 [21504/50176]	Loss: 1.3026
Training Epoch: 16 [22528/50176]	Loss: 1.3157
Training Epoch: 16 [23552/50176]	Loss: 1.3090
Training Epoch: 16 [24576/50176]	Loss: 1.3112
Training Epoch: 16 [25600/50176]	Loss: 1.3005
Training Epoch: 16 [26624/50176]	Loss: 1.2985
Training Epoch: 16 [27648/50176]	Loss: 1.3783
Training Epoch: 16 [28672/50176]	Loss: 1.3751
Training Epoch: 16 [29696/50176]	Loss: 1.2497
Training Epoch: 16 [30720/50176]	Loss: 1.2845
Training Epoch: 16 [31744/50176]	Loss: 1.3242
Training Epoch: 16 [32768/50176]	Loss: 1.3276
Training Epoch: 16 [33792/50176]	Loss: 1.3002
Training Epoch: 16 [34816/50176]	Loss: 1.3174
Training Epoch: 16 [35840/50176]	Loss: 1.3340
Training Epoch: 16 [36864/50176]	Loss: 1.3608
Training Epoch: 16 [37888/50176]	Loss: 1.2988
Training Epoch: 16 [38912/50176]	Loss: 1.2887
Training Epoch: 16 [39936/50176]	Loss: 1.3946
Training Epoch: 16 [40960/50176]	Loss: 1.3690
Training Epoch: 16 [41984/50176]	Loss: 1.3252
Training Epoch: 16 [43008/50176]	Loss: 1.2814
Training Epoch: 16 [44032/50176]	Loss: 1.3295
Training Epoch: 16 [45056/50176]	Loss: 1.4379
Training Epoch: 16 [46080/50176]	Loss: 1.3777
Training Epoch: 16 [47104/50176]	Loss: 1.3326
Training Epoch: 16 [48128/50176]	Loss: 1.3765
Training Epoch: 16 [49152/50176]	Loss: 1.3803
Training Epoch: 16 [50176/50176]	Loss: 1.3294
2022-12-08 22:55:47.519 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:55:47,558 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=534.53
2022-12-08 17:55:47,558 [ZeusDataLoader(train)] Up to epoch 17: time=915.55, energy=129346.45, cost=144784.11
2022-12-08 17:55:47,559 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:55:47,559 [ZeusDataLoader(train)] Expected next epoch: time=962.52, energy=136566.52, cost=152503.92
2022-12-08 17:55:47,560 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0017, Accuracy: 0.5397
2022-12-08 17:55:47,780 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:55:47,781 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:55:47.783 [ZeusMonitor] Monitor started.
2022-12-08 22:55:47.783 [ZeusMonitor] Running indefinitely. 2022-12-08 22:55:47.783 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:55:47.783 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e18+gpu0.power.log
2022-12-08 17:56:31,734 [ZeusDataLoader(train)] train epoch 18 done: time=44.17 energy=6704.75
2022-12-08 17:56:31,738 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.2242
Training Epoch: 17 [2048/50176]	Loss: 1.2283
Training Epoch: 17 [3072/50176]	Loss: 1.1286
Training Epoch: 17 [4096/50176]	Loss: 1.1694
Training Epoch: 17 [5120/50176]	Loss: 1.2834
Training Epoch: 17 [6144/50176]	Loss: 1.2865
Training Epoch: 17 [7168/50176]	Loss: 1.2012
Training Epoch: 17 [8192/50176]	Loss: 1.2032
Training Epoch: 17 [9216/50176]	Loss: 1.2336
Training Epoch: 17 [10240/50176]	Loss: 1.1846
Training Epoch: 17 [11264/50176]	Loss: 1.2270
Training Epoch: 17 [12288/50176]	Loss: 1.2005
Training Epoch: 17 [13312/50176]	Loss: 1.2212
Training Epoch: 17 [14336/50176]	Loss: 1.2209
Training Epoch: 17 [15360/50176]	Loss: 1.2020
Training Epoch: 17 [16384/50176]	Loss: 1.1846
Training Epoch: 17 [17408/50176]	Loss: 1.2602
Training Epoch: 17 [18432/50176]	Loss: 1.3139
Training Epoch: 17 [19456/50176]	Loss: 1.1774
Training Epoch: 17 [20480/50176]	Loss: 1.2165
Training Epoch: 17 [21504/50176]	Loss: 1.2823
Training Epoch: 17 [22528/50176]	Loss: 1.3638
Training Epoch: 17 [23552/50176]	Loss: 1.2973
Training Epoch: 17 [24576/50176]	Loss: 1.2766
Training Epoch: 17 [25600/50176]	Loss: 1.2623
Training Epoch: 17 [26624/50176]	Loss: 1.2170
Training Epoch: 17 [27648/50176]	Loss: 1.2633
Training Epoch: 17 [28672/50176]	Loss: 1.2640
Training Epoch: 17 [29696/50176]	Loss: 1.3234
Training Epoch: 17 [30720/50176]	Loss: 1.3204
Training Epoch: 17 [31744/50176]	Loss: 1.2242
Training Epoch: 17 [32768/50176]	Loss: 1.2257
Training Epoch: 17 [33792/50176]	Loss: 1.2944
Training Epoch: 17 [34816/50176]	Loss: 1.2616
Training Epoch: 17 [35840/50176]	Loss: 1.1783
Training Epoch: 17 [36864/50176]	Loss: 1.3252
Training Epoch: 17 [37888/50176]	Loss: 1.2606
Training Epoch: 17 [38912/50176]	Loss: 1.3420
Training Epoch: 17 [39936/50176]	Loss: 1.2992
Training Epoch: 17 [40960/50176]	Loss: 1.2832
Training Epoch: 17 [41984/50176]	Loss: 1.3034
Training Epoch: 17 [43008/50176]	Loss: 1.2828
Training Epoch: 17 [44032/50176]	Loss: 1.3166
Training Epoch: 17 [45056/50176]	Loss: 1.2772
Training Epoch: 17 [46080/50176]	Loss: 1.2006
Training Epoch: 17 [47104/50176]	Loss: 1.2394
Training Epoch: 17 [48128/50176]	Loss: 1.3045
Training Epoch: 17 [49152/50176]	Loss: 1.2869
Training Epoch: 17 [50176/50176]	Loss: 1.3325
2022-12-08 22:56:35.436 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:56:35,460 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.71 energy=518.75
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Up to epoch 18: time=963.43, energy=136569.95, cost=152585.36
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Expected next epoch: time=1010.40, energy=143790.02, cost=160305.17
2022-12-08 17:56:35,462 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0016, Accuracy: 0.5474
2022-12-08 17:56:35,722 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:56:35,723 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:56:35.733 [ZeusMonitor] Monitor started.
2022-12-08 22:56:35.733 [ZeusMonitor] Running indefinitely. 2022-12-08 22:56:35.733 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:56:35.733 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e19+gpu0.power.log
2022-12-08 17:57:19,729 [ZeusDataLoader(train)] train epoch 19 done: time=44.26 energy=6700.37
2022-12-08 17:57:19,732 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.1805
Training Epoch: 18 [2048/50176]	Loss: 1.1824
Training Epoch: 18 [3072/50176]	Loss: 1.2267
Training Epoch: 18 [4096/50176]	Loss: 1.1388
Training Epoch: 18 [5120/50176]	Loss: 1.1447
Training Epoch: 18 [6144/50176]	Loss: 1.1688
Training Epoch: 18 [7168/50176]	Loss: 1.1372
Training Epoch: 18 [8192/50176]	Loss: 1.1787
Training Epoch: 18 [9216/50176]	Loss: 1.1509
Training Epoch: 18 [10240/50176]	Loss: 1.1223
Training Epoch: 18 [11264/50176]	Loss: 1.2126
Training Epoch: 18 [12288/50176]	Loss: 1.1372
Training Epoch: 18 [13312/50176]	Loss: 1.2473
Training Epoch: 18 [14336/50176]	Loss: 1.2044
Training Epoch: 18 [15360/50176]	Loss: 1.2542
Training Epoch: 18 [16384/50176]	Loss: 1.1853
Training Epoch: 18 [17408/50176]	Loss: 1.2841
Training Epoch: 18 [18432/50176]	Loss: 1.2013
Training Epoch: 18 [19456/50176]	Loss: 1.2481
Training Epoch: 18 [20480/50176]	Loss: 1.1779
Training Epoch: 18 [21504/50176]	Loss: 1.2532
Training Epoch: 18 [22528/50176]	Loss: 1.2806
Training Epoch: 18 [23552/50176]	Loss: 1.1355
Training Epoch: 18 [24576/50176]	Loss: 1.1631
Training Epoch: 18 [25600/50176]	Loss: 1.1414
Training Epoch: 18 [26624/50176]	Loss: 1.0647
Training Epoch: 18 [27648/50176]	Loss: 1.1794
Training Epoch: 18 [28672/50176]	Loss: 1.1952
Training Epoch: 18 [29696/50176]	Loss: 1.2123
Training Epoch: 18 [30720/50176]	Loss: 1.2677
Training Epoch: 18 [31744/50176]	Loss: 1.2681
Training Epoch: 18 [32768/50176]	Loss: 1.2268
Training Epoch: 18 [33792/50176]	Loss: 1.2120
Training Epoch: 18 [34816/50176]	Loss: 1.1749
Training Epoch: 18 [35840/50176]	Loss: 1.2708
Training Epoch: 18 [36864/50176]	Loss: 1.2674
Training Epoch: 18 [37888/50176]	Loss: 1.1993
Training Epoch: 18 [38912/50176]	Loss: 1.2798
Training Epoch: 18 [39936/50176]	Loss: 1.2078
Training Epoch: 18 [40960/50176]	Loss: 1.2122
Training Epoch: 18 [41984/50176]	Loss: 1.2369
Training Epoch: 18 [43008/50176]	Loss: 1.2540
Training Epoch: 18 [44032/50176]	Loss: 1.2040
Training Epoch: 18 [45056/50176]	Loss: 1.1905
Training Epoch: 18 [46080/50176]	Loss: 1.2508
Training Epoch: 18 [47104/50176]	Loss: 1.2340
Training Epoch: 18 [48128/50176]	Loss: 1.1947
Training Epoch: 18 [49152/50176]	Loss: 1.2102
Training Epoch: 18 [50176/50176]	Loss: 1.2822
2022-12-08 22:57:23.515 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:57:23,568 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.83 energy=533.46
2022-12-08 17:57:23,568 [ZeusDataLoader(train)] Up to epoch 19: time=1011.52, energy=143803.78, cost=160409.66
2022-12-08 17:57:23,569 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:57:23,569 [ZeusDataLoader(train)] Expected next epoch: time=1058.49, energy=151023.85, cost=168129.48
2022-12-08 17:57:23,570 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0016, Accuracy: 0.5449
2022-12-08 17:57:23,801 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:57:23,802 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:57:23.804 [ZeusMonitor] Monitor started.
2022-12-08 22:57:23.816 [ZeusMonitor] Running indefinitely. 2022-12-08 22:57:23.816 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:57:23.816 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e20+gpu0.power.log
2022-12-08 17:58:07,726 [ZeusDataLoader(train)] train epoch 20 done: time=44.15 energy=6713.55
2022-12-08 17:58:07,730 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.0996
Training Epoch: 19 [2048/50176]	Loss: 1.1460
Training Epoch: 19 [3072/50176]	Loss: 1.1324
Training Epoch: 19 [4096/50176]	Loss: 1.1240
Training Epoch: 19 [5120/50176]	Loss: 1.0766
Training Epoch: 19 [6144/50176]	Loss: 1.1369
Training Epoch: 19 [7168/50176]	Loss: 1.0790
Training Epoch: 19 [8192/50176]	Loss: 1.1117
Training Epoch: 19 [9216/50176]	Loss: 1.1282
Training Epoch: 19 [10240/50176]	Loss: 1.1926
Training Epoch: 19 [11264/50176]	Loss: 1.1240
Training Epoch: 19 [12288/50176]	Loss: 1.1257
Training Epoch: 19 [13312/50176]	Loss: 1.0605
Training Epoch: 19 [14336/50176]	Loss: 1.1358
Training Epoch: 19 [15360/50176]	Loss: 1.1198
Training Epoch: 19 [16384/50176]	Loss: 1.1289
Training Epoch: 19 [17408/50176]	Loss: 1.2155
Training Epoch: 19 [18432/50176]	Loss: 1.1824
Training Epoch: 19 [19456/50176]	Loss: 1.1053
Training Epoch: 19 [20480/50176]	Loss: 1.1820
Training Epoch: 19 [21504/50176]	Loss: 1.0997
Training Epoch: 19 [22528/50176]	Loss: 1.2416
Training Epoch: 19 [23552/50176]	Loss: 1.1923
Training Epoch: 19 [24576/50176]	Loss: 1.1132
Training Epoch: 19 [25600/50176]	Loss: 1.1673
Training Epoch: 19 [26624/50176]	Loss: 1.1836
Training Epoch: 19 [27648/50176]	Loss: 1.1438
Training Epoch: 19 [28672/50176]	Loss: 1.0972
Training Epoch: 19 [29696/50176]	Loss: 1.2187
Training Epoch: 19 [30720/50176]	Loss: 1.1405
Training Epoch: 19 [31744/50176]	Loss: 1.2074
Training Epoch: 19 [32768/50176]	Loss: 1.1519
Training Epoch: 19 [33792/50176]	Loss: 1.1456
Training Epoch: 19 [34816/50176]	Loss: 1.1437
Training Epoch: 19 [35840/50176]	Loss: 1.1902
Training Epoch: 19 [36864/50176]	Loss: 1.2357
Training Epoch: 19 [37888/50176]	Loss: 1.1388
Training Epoch: 19 [38912/50176]	Loss: 1.2512
Training Epoch: 19 [39936/50176]	Loss: 1.1276
Training Epoch: 19 [40960/50176]	Loss: 1.1442
Training Epoch: 19 [41984/50176]	Loss: 1.2192
Training Epoch: 19 [43008/50176]	Loss: 1.2216
Training Epoch: 19 [44032/50176]	Loss: 1.1417
Training Epoch: 19 [45056/50176]	Loss: 1.1597
Training Epoch: 19 [46080/50176]	Loss: 1.1064
Training Epoch: 19 [47104/50176]	Loss: 1.1475
Training Epoch: 19 [48128/50176]	Loss: 1.1366
Training Epoch: 19 [49152/50176]	Loss: 1.1996
Training Epoch: 19 [50176/50176]	Loss: 1.0899
2022-12-08 22:58:11.463 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:58:11,472 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.73 energy=520.50
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Up to epoch 20: time=1059.40, energy=151037.82, cost=168216.40
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Expected next epoch: time=1106.37, energy=158257.89, cost=175936.22
2022-12-08 17:58:11,474 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0015, Accuracy: 0.5787
2022-12-08 17:58:11,709 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:58:11,710 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:58:11.711 [ZeusMonitor] Monitor started.
2022-12-08 22:58:11.712 [ZeusMonitor] Running indefinitely. 2022-12-08 22:58:11.712 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:58:11.712 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e21+gpu0.power.log
2022-12-08 17:58:55,722 [ZeusDataLoader(train)] train epoch 21 done: time=44.24 energy=6704.38
2022-12-08 17:58:55,727 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0224
Training Epoch: 20 [2048/50176]	Loss: 1.0808
Training Epoch: 20 [3072/50176]	Loss: 1.0784
Training Epoch: 20 [4096/50176]	Loss: 1.0036
Training Epoch: 20 [5120/50176]	Loss: 1.0109
Training Epoch: 20 [6144/50176]	Loss: 1.1248
Training Epoch: 20 [7168/50176]	Loss: 0.9923
Training Epoch: 20 [8192/50176]	Loss: 1.0411
Training Epoch: 20 [9216/50176]	Loss: 1.0218
Training Epoch: 20 [10240/50176]	Loss: 1.0074
Training Epoch: 20 [11264/50176]	Loss: 1.0735
Training Epoch: 20 [12288/50176]	Loss: 1.0426
Training Epoch: 20 [13312/50176]	Loss: 1.0474
Training Epoch: 20 [14336/50176]	Loss: 1.0875
Training Epoch: 20 [15360/50176]	Loss: 1.0762
Training Epoch: 20 [16384/50176]	Loss: 1.0763
Training Epoch: 20 [17408/50176]	Loss: 1.0636
Training Epoch: 20 [18432/50176]	Loss: 1.0809
Training Epoch: 20 [19456/50176]	Loss: 1.1109
Training Epoch: 20 [20480/50176]	Loss: 1.0559
Training Epoch: 20 [21504/50176]	Loss: 1.1329
Training Epoch: 20 [22528/50176]	Loss: 1.0699
Training Epoch: 20 [23552/50176]	Loss: 1.0487
Training Epoch: 20 [24576/50176]	Loss: 1.1285
Training Epoch: 20 [25600/50176]	Loss: 1.1319
Training Epoch: 20 [26624/50176]	Loss: 1.1022
Training Epoch: 20 [27648/50176]	Loss: 1.0101
Training Epoch: 20 [28672/50176]	Loss: 1.1882
Training Epoch: 20 [29696/50176]	Loss: 1.1234
Training Epoch: 20 [30720/50176]	Loss: 1.1323
Training Epoch: 20 [31744/50176]	Loss: 1.0599
Training Epoch: 20 [32768/50176]	Loss: 1.0561
Training Epoch: 20 [33792/50176]	Loss: 1.1001
Training Epoch: 20 [34816/50176]	Loss: 1.1536
Training Epoch: 20 [35840/50176]	Loss: 1.1016
Training Epoch: 20 [36864/50176]	Loss: 1.1570
Training Epoch: 20 [37888/50176]	Loss: 1.0958
Training Epoch: 20 [38912/50176]	Loss: 1.0626
Training Epoch: 20 [39936/50176]	Loss: 1.1221
Training Epoch: 20 [40960/50176]	Loss: 1.1705
Training Epoch: 20 [41984/50176]	Loss: 1.1143
Training Epoch: 20 [43008/50176]	Loss: 1.0879
Training Epoch: 20 [44032/50176]	Loss: 1.0745
Training Epoch: 20 [45056/50176]	Loss: 1.0779
Training Epoch: 20 [46080/50176]	Loss: 1.1198
Training Epoch: 20 [47104/50176]	Loss: 1.1569
Training Epoch: 20 [48128/50176]	Loss: 1.1203
Training Epoch: 20 [49152/50176]	Loss: 1.1748
Training Epoch: 20 [50176/50176]	Loss: 1.0981
2022-12-08 22:58:59.499 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:58:59,529 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.79 energy=532.95
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Up to epoch 21: time=1107.43, energy=158275.15, cost=176037.84
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Expected next epoch: time=1154.40, energy=165495.22, cost=183757.66
2022-12-08 17:58:59,531 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0016, Accuracy: 0.5700
2022-12-08 17:58:59,756 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:58:59,757 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:58:59.759 [ZeusMonitor] Monitor started.
2022-12-08 22:58:59.759 [ZeusMonitor] Running indefinitely. 2022-12-08 22:58:59.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:58:59.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e22+gpu0.power.log
2022-12-08 17:59:43,693 [ZeusDataLoader(train)] train epoch 22 done: time=44.15 energy=6711.78
2022-12-08 17:59:43,697 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0399
Training Epoch: 21 [2048/50176]	Loss: 0.9806
Training Epoch: 21 [3072/50176]	Loss: 1.0006
Training Epoch: 21 [4096/50176]	Loss: 1.0298
Training Epoch: 21 [5120/50176]	Loss: 1.0023
Training Epoch: 21 [6144/50176]	Loss: 0.9804
Training Epoch: 21 [7168/50176]	Loss: 0.9407
Training Epoch: 21 [8192/50176]	Loss: 1.0266
Training Epoch: 21 [9216/50176]	Loss: 1.0079
Training Epoch: 21 [10240/50176]	Loss: 0.9880
Training Epoch: 21 [11264/50176]	Loss: 0.9611
Training Epoch: 21 [12288/50176]	Loss: 0.9730
Training Epoch: 21 [13312/50176]	Loss: 1.0164
Training Epoch: 21 [14336/50176]	Loss: 1.0447
Training Epoch: 21 [15360/50176]	Loss: 1.0182
Training Epoch: 21 [16384/50176]	Loss: 1.0611
Training Epoch: 21 [17408/50176]	Loss: 1.0184
Training Epoch: 21 [18432/50176]	Loss: 0.9883
Training Epoch: 21 [19456/50176]	Loss: 0.9959
Training Epoch: 21 [20480/50176]	Loss: 0.9693
Training Epoch: 21 [21504/50176]	Loss: 1.0472
Training Epoch: 21 [22528/50176]	Loss: 1.1275
Training Epoch: 21 [23552/50176]	Loss: 1.0791
Training Epoch: 21 [24576/50176]	Loss: 1.0109
Training Epoch: 21 [25600/50176]	Loss: 1.0441
Training Epoch: 21 [26624/50176]	Loss: 1.1109
Training Epoch: 21 [27648/50176]	Loss: 1.0255
Training Epoch: 21 [28672/50176]	Loss: 1.0075
Training Epoch: 21 [29696/50176]	Loss: 1.1148
Training Epoch: 21 [30720/50176]	Loss: 1.0331
Training Epoch: 21 [31744/50176]	Loss: 1.0522
Training Epoch: 21 [32768/50176]	Loss: 1.0450
Training Epoch: 21 [33792/50176]	Loss: 1.0478
Training Epoch: 21 [34816/50176]	Loss: 1.0353
Training Epoch: 21 [35840/50176]	Loss: 1.0571
Training Epoch: 21 [36864/50176]	Loss: 0.9866
Training Epoch: 21 [37888/50176]	Loss: 1.1511
Training Epoch: 21 [38912/50176]	Loss: 1.0799
Training Epoch: 21 [39936/50176]	Loss: 1.1409
Training Epoch: 21 [40960/50176]	Loss: 1.0258
Training Epoch: 21 [41984/50176]	Loss: 1.0822
Training Epoch: 21 [43008/50176]	Loss: 1.0803
Training Epoch: 21 [44032/50176]	Loss: 1.1630
Training Epoch: 21 [45056/50176]	Loss: 1.1468
Training Epoch: 21 [46080/50176]	Loss: 1.0724
Training Epoch: 21 [47104/50176]	Loss: 1.0833
Training Epoch: 21 [48128/50176]	Loss: 1.1037
Training Epoch: 21 [49152/50176]	Loss: 1.1080
Training Epoch: 21 [50176/50176]	Loss: 1.1055
2022-12-08 22:59:47.496 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:59:47,518 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=530.56
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Up to epoch 22: time=1155.40, energy=165517.49, cost=183856.13
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Expected next epoch: time=1202.37, energy=172737.57, cost=191575.94
2022-12-08 17:59:47,520 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0016, Accuracy: 0.5694
2022-12-08 17:59:47,709 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:59:47,710 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:59:47.712 [ZeusMonitor] Monitor started.
2022-12-08 22:59:47.712 [ZeusMonitor] Running indefinitely. 2022-12-08 22:59:47.712 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:59:47.712 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e23+gpu0.power.log
2022-12-08 18:00:31,680 [ZeusDataLoader(train)] train epoch 23 done: time=44.15 energy=6714.30
2022-12-08 18:00:31,684 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.0335
Training Epoch: 22 [2048/50176]	Loss: 0.9933
Training Epoch: 22 [3072/50176]	Loss: 0.9267
Training Epoch: 22 [4096/50176]	Loss: 0.8679
Training Epoch: 22 [5120/50176]	Loss: 0.9504
Training Epoch: 22 [6144/50176]	Loss: 0.9654
Training Epoch: 22 [7168/50176]	Loss: 0.9683
Training Epoch: 22 [8192/50176]	Loss: 0.9384
Training Epoch: 22 [9216/50176]	Loss: 0.9612
Training Epoch: 22 [10240/50176]	Loss: 0.8947
Training Epoch: 22 [11264/50176]	Loss: 1.0249
Training Epoch: 22 [12288/50176]	Loss: 1.0416
Training Epoch: 22 [13312/50176]	Loss: 0.9002
Training Epoch: 22 [14336/50176]	Loss: 1.0010
Training Epoch: 22 [15360/50176]	Loss: 0.9499
Training Epoch: 22 [16384/50176]	Loss: 1.0314
Training Epoch: 22 [17408/50176]	Loss: 0.9944
Training Epoch: 22 [18432/50176]	Loss: 0.9724
Training Epoch: 22 [19456/50176]	Loss: 0.9960
Training Epoch: 22 [20480/50176]	Loss: 1.0318
Training Epoch: 22 [21504/50176]	Loss: 0.9837
Training Epoch: 22 [22528/50176]	Loss: 1.0781
Training Epoch: 22 [23552/50176]	Loss: 1.0445
Training Epoch: 22 [24576/50176]	Loss: 1.0372
Training Epoch: 22 [25600/50176]	Loss: 1.0175
Training Epoch: 22 [26624/50176]	Loss: 1.0459
Training Epoch: 22 [27648/50176]	Loss: 1.0001
Training Epoch: 22 [28672/50176]	Loss: 1.0635
Training Epoch: 22 [29696/50176]	Loss: 1.0396
Training Epoch: 22 [30720/50176]	Loss: 0.9764
Training Epoch: 22 [31744/50176]	Loss: 1.1101
Training Epoch: 22 [32768/50176]	Loss: 1.0497
Training Epoch: 22 [33792/50176]	Loss: 1.0000
Training Epoch: 22 [34816/50176]	Loss: 1.0321
Training Epoch: 22 [35840/50176]	Loss: 1.0423
Training Epoch: 22 [36864/50176]	Loss: 1.0666
Training Epoch: 22 [37888/50176]	Loss: 1.0257
Training Epoch: 22 [38912/50176]	Loss: 0.9271
Training Epoch: 22 [39936/50176]	Loss: 0.9677
Training Epoch: 22 [40960/50176]	Loss: 1.0539
Training Epoch: 22 [41984/50176]	Loss: 1.0871
Training Epoch: 22 [43008/50176]	Loss: 1.0093
Training Epoch: 22 [44032/50176]	Loss: 0.9508
Training Epoch: 22 [45056/50176]	Loss: 1.0206
Training Epoch: 22 [46080/50176]	Loss: 1.0015
Training Epoch: 22 [47104/50176]	Loss: 1.0008
Training Epoch: 22 [48128/50176]	Loss: 1.1575
Training Epoch: 22 [49152/50176]	Loss: 1.0768
Training Epoch: 22 [50176/50176]	Loss: 1.0437
2022-12-08 23:00:35.455 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:00:35,506 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.81 energy=533.72
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Up to epoch 23: time=1203.36, energy=172765.51, cost=191677.08
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Expected next epoch: time=1250.33, energy=179985.58, cost=199396.89
2022-12-08 18:00:35,507 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0018, Accuracy: 0.5539
2022-12-08 18:00:35,727 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:00:35,728 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:00:35.730 [ZeusMonitor] Monitor started.
2022-12-08 23:00:35.730 [ZeusMonitor] Running indefinitely. 2022-12-08 23:00:35.730 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:00:35.730 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e24+gpu0.power.log
2022-12-08 18:01:19,677 [ZeusDataLoader(train)] train epoch 24 done: time=44.16 energy=6702.96
2022-12-08 18:01:19,681 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 0.9594
Training Epoch: 23 [2048/50176]	Loss: 0.9093
Training Epoch: 23 [3072/50176]	Loss: 0.9103
Training Epoch: 23 [4096/50176]	Loss: 0.9519
Training Epoch: 23 [5120/50176]	Loss: 0.9176
Training Epoch: 23 [6144/50176]	Loss: 0.9061
Training Epoch: 23 [7168/50176]	Loss: 0.9425
Training Epoch: 23 [8192/50176]	Loss: 0.9394
Training Epoch: 23 [9216/50176]	Loss: 0.8686
Training Epoch: 23 [10240/50176]	Loss: 0.9025
Training Epoch: 23 [11264/50176]	Loss: 0.9677
Training Epoch: 23 [12288/50176]	Loss: 0.8823
Training Epoch: 23 [13312/50176]	Loss: 1.0299
Training Epoch: 23 [14336/50176]	Loss: 0.9018
Training Epoch: 23 [15360/50176]	Loss: 0.9059
Training Epoch: 23 [16384/50176]	Loss: 0.9938
Training Epoch: 23 [17408/50176]	Loss: 0.9755
Training Epoch: 23 [18432/50176]	Loss: 0.8884
Training Epoch: 23 [19456/50176]	Loss: 0.9360
Training Epoch: 23 [20480/50176]	Loss: 0.9351
Training Epoch: 23 [21504/50176]	Loss: 0.9434
Training Epoch: 23 [22528/50176]	Loss: 0.9429
Training Epoch: 23 [23552/50176]	Loss: 0.8839
Training Epoch: 23 [24576/50176]	Loss: 0.9654
Training Epoch: 23 [25600/50176]	Loss: 0.9264
Training Epoch: 23 [26624/50176]	Loss: 0.9329
Training Epoch: 23 [27648/50176]	Loss: 0.9228
Training Epoch: 23 [28672/50176]	Loss: 0.8807
Training Epoch: 23 [29696/50176]	Loss: 0.9471
Training Epoch: 23 [30720/50176]	Loss: 0.9477
Training Epoch: 23 [31744/50176]	Loss: 1.0028
Training Epoch: 23 [32768/50176]	Loss: 1.0035
Training Epoch: 23 [33792/50176]	Loss: 0.9763
Training Epoch: 23 [34816/50176]	Loss: 1.0167
Training Epoch: 23 [35840/50176]	Loss: 0.9678
Training Epoch: 23 [36864/50176]	Loss: 0.9211
Training Epoch: 23 [37888/50176]	Loss: 0.9571
Training Epoch: 23 [38912/50176]	Loss: 1.0435
Training Epoch: 23 [39936/50176]	Loss: 0.9775
Training Epoch: 23 [40960/50176]	Loss: 1.0609
Training Epoch: 23 [41984/50176]	Loss: 1.0160
Training Epoch: 23 [43008/50176]	Loss: 0.9981
Training Epoch: 23 [44032/50176]	Loss: 1.0281
Training Epoch: 23 [45056/50176]	Loss: 1.0014
Training Epoch: 23 [46080/50176]	Loss: 1.0655
Training Epoch: 23 [47104/50176]	Loss: 1.0163
Training Epoch: 23 [48128/50176]	Loss: 0.9543
Training Epoch: 23 [49152/50176]	Loss: 1.0085
Training Epoch: 23 [50176/50176]	Loss: 0.9549
2022-12-08 23:01:23.387 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:01:23,403 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.71 energy=515.10
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Up to epoch 24: time=1251.24, energy=179983.58, cost=199475.18
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Expected next epoch: time=1298.21, energy=187203.65, cost=207195.00
2022-12-08 18:01:23,404 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0015, Accuracy: 0.5776
2022-12-08 18:01:23,636 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:01:23,637 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:01:23.639 [ZeusMonitor] Monitor started.
2022-12-08 23:01:23.639 [ZeusMonitor] Running indefinitely. 2022-12-08 23:01:23.639 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:01:23.639 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e25+gpu0.power.log
2022-12-08 18:02:07,602 [ZeusDataLoader(train)] train epoch 25 done: time=44.19 energy=6716.01
2022-12-08 18:02:07,605 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8497
Training Epoch: 24 [2048/50176]	Loss: 0.8239
Training Epoch: 24 [3072/50176]	Loss: 0.8916
Training Epoch: 24 [4096/50176]	Loss: 0.8275
Training Epoch: 24 [5120/50176]	Loss: 0.8272
Training Epoch: 24 [6144/50176]	Loss: 0.8444
Training Epoch: 24 [7168/50176]	Loss: 0.9289
Training Epoch: 24 [8192/50176]	Loss: 0.8818
Training Epoch: 24 [9216/50176]	Loss: 0.8778
Training Epoch: 24 [10240/50176]	Loss: 0.9000
Training Epoch: 24 [11264/50176]	Loss: 0.8979
Training Epoch: 24 [12288/50176]	Loss: 0.8703
Training Epoch: 24 [13312/50176]	Loss: 0.8783
Training Epoch: 24 [14336/50176]	Loss: 0.9062
Training Epoch: 24 [15360/50176]	Loss: 0.8394
Training Epoch: 24 [16384/50176]	Loss: 0.8565
Training Epoch: 24 [17408/50176]	Loss: 0.9102
Training Epoch: 24 [18432/50176]	Loss: 0.9330
Training Epoch: 24 [19456/50176]	Loss: 0.9381
Training Epoch: 24 [20480/50176]	Loss: 0.9089
Training Epoch: 24 [21504/50176]	Loss: 0.9236
Training Epoch: 24 [22528/50176]	Loss: 0.8536
Training Epoch: 24 [23552/50176]	Loss: 0.9265
Training Epoch: 24 [24576/50176]	Loss: 0.8489
Training Epoch: 24 [25600/50176]	Loss: 0.9519
Training Epoch: 24 [26624/50176]	Loss: 0.9143
Training Epoch: 24 [27648/50176]	Loss: 0.9453
Training Epoch: 24 [28672/50176]	Loss: 0.9318
Training Epoch: 24 [29696/50176]	Loss: 0.8734
Training Epoch: 24 [30720/50176]	Loss: 0.9950
Training Epoch: 24 [31744/50176]	Loss: 1.0137
Training Epoch: 24 [32768/50176]	Loss: 0.9419
Training Epoch: 24 [33792/50176]	Loss: 0.9112
Training Epoch: 24 [34816/50176]	Loss: 1.0144
Training Epoch: 24 [35840/50176]	Loss: 0.9754
Training Epoch: 24 [36864/50176]	Loss: 0.9706
Training Epoch: 24 [37888/50176]	Loss: 0.9443
Training Epoch: 24 [38912/50176]	Loss: 1.0284
Training Epoch: 24 [39936/50176]	Loss: 0.9003
Training Epoch: 24 [40960/50176]	Loss: 0.9459
Training Epoch: 24 [41984/50176]	Loss: 0.9510
Training Epoch: 24 [43008/50176]	Loss: 0.9990
Training Epoch: 24 [44032/50176]	Loss: 0.8792
Training Epoch: 24 [45056/50176]	Loss: 0.9577
Training Epoch: 24 [46080/50176]	Loss: 0.9287
Training Epoch: 24 [47104/50176]	Loss: 1.0112
Training Epoch: 24 [48128/50176]	Loss: 1.0513
Training Epoch: 24 [49152/50176]	Loss: 0.9265
Training Epoch: 24 [50176/50176]	Loss: 0.9071
2022-12-08 23:02:11.347 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:02:11,394 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.78 energy=521.34
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Up to epoch 25: time=1299.21, energy=187220.93, cost=207291.12
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Expected next epoch: time=1346.18, energy=194441.00, cost=215010.94
2022-12-08 18:02:11,395 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0015, Accuracy: 0.5864
2022-12-08 18:02:11,624 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:02:11,625 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:02:11.627 [ZeusMonitor] Monitor started.
2022-12-08 23:02:11.627 [ZeusMonitor] Running indefinitely. 2022-12-08 23:02:11.627 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:02:11.627 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e26+gpu0.power.log
2022-12-08 18:02:55,653 [ZeusDataLoader(train)] train epoch 26 done: time=44.25 energy=6717.97
2022-12-08 18:02:55,657 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.7817
Training Epoch: 25 [2048/50176]	Loss: 0.8126
Training Epoch: 25 [3072/50176]	Loss: 0.7912
Training Epoch: 25 [4096/50176]	Loss: 0.7865
Training Epoch: 25 [5120/50176]	Loss: 0.8205
Training Epoch: 25 [6144/50176]	Loss: 0.8306
Training Epoch: 25 [7168/50176]	Loss: 0.8118
Training Epoch: 25 [8192/50176]	Loss: 0.8368
Training Epoch: 25 [9216/50176]	Loss: 0.9178
Training Epoch: 25 [10240/50176]	Loss: 0.7736
Training Epoch: 25 [11264/50176]	Loss: 0.8464
Training Epoch: 25 [12288/50176]	Loss: 0.7867
Training Epoch: 25 [13312/50176]	Loss: 0.7926
Training Epoch: 25 [14336/50176]	Loss: 0.8565
Training Epoch: 25 [15360/50176]	Loss: 0.8830
Training Epoch: 25 [16384/50176]	Loss: 0.8991
Training Epoch: 25 [17408/50176]	Loss: 0.8748
Training Epoch: 25 [18432/50176]	Loss: 0.8482
Training Epoch: 25 [19456/50176]	Loss: 0.7775
Training Epoch: 25 [20480/50176]	Loss: 0.8431
Training Epoch: 25 [21504/50176]	Loss: 0.8355
Training Epoch: 25 [22528/50176]	Loss: 0.9205
Training Epoch: 25 [23552/50176]	Loss: 0.8153
Training Epoch: 25 [24576/50176]	Loss: 0.8043
Training Epoch: 25 [25600/50176]	Loss: 0.8200
Training Epoch: 25 [26624/50176]	Loss: 0.8917
Training Epoch: 25 [27648/50176]	Loss: 0.8583
Training Epoch: 25 [28672/50176]	Loss: 0.9093
Training Epoch: 25 [29696/50176]	Loss: 0.8533
Training Epoch: 25 [30720/50176]	Loss: 0.9219
Training Epoch: 25 [31744/50176]	Loss: 0.8377
Training Epoch: 25 [32768/50176]	Loss: 0.8721
Training Epoch: 25 [33792/50176]	Loss: 0.8096
Training Epoch: 25 [34816/50176]	Loss: 0.8573
Training Epoch: 25 [35840/50176]	Loss: 0.8617
Training Epoch: 25 [36864/50176]	Loss: 0.8712
Training Epoch: 25 [37888/50176]	Loss: 0.8721
Training Epoch: 25 [38912/50176]	Loss: 0.8583
Training Epoch: 25 [39936/50176]	Loss: 0.8433
Training Epoch: 25 [40960/50176]	Loss: 0.8536
Training Epoch: 25 [41984/50176]	Loss: 0.8914
Training Epoch: 25 [43008/50176]	Loss: 0.9574
Training Epoch: 25 [44032/50176]	Loss: 0.9148
Training Epoch: 25 [45056/50176]	Loss: 0.9517
Training Epoch: 25 [46080/50176]	Loss: 0.9180
Training Epoch: 25 [47104/50176]	Loss: 0.9390
Training Epoch: 25 [48128/50176]	Loss: 0.9522
Training Epoch: 25 [49152/50176]	Loss: 0.8915
Training Epoch: 25 [50176/50176]	Loss: 0.9449
2022-12-08 23:02:59.410 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:02:59,453 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.79 energy=524.25
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Up to epoch 26: time=1347.24, energy=194463.15, cost=215115.46
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Expected next epoch: time=1394.21, energy=201683.22, cost=222835.27
2022-12-08 18:02:59,455 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0016, Accuracy: 0.5772
2022-12-08 18:02:59,671 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:02:59,672 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:02:59.674 [ZeusMonitor] Monitor started.
2022-12-08 23:02:59.674 [ZeusMonitor] Running indefinitely. 2022-12-08 23:02:59.674 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:02:59.674 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e27+gpu0.power.log
2022-12-08 18:03:43,658 [ZeusDataLoader(train)] train epoch 27 done: time=44.20 energy=6710.96
2022-12-08 18:03:43,662 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.7450
Training Epoch: 26 [2048/50176]	Loss: 0.7971
Training Epoch: 26 [3072/50176]	Loss: 0.8067
Training Epoch: 26 [4096/50176]	Loss: 0.7962
Training Epoch: 26 [5120/50176]	Loss: 0.8059
Training Epoch: 26 [6144/50176]	Loss: 0.7970
Training Epoch: 26 [7168/50176]	Loss: 0.7725
Training Epoch: 26 [8192/50176]	Loss: 0.7917
Training Epoch: 26 [9216/50176]	Loss: 0.7455
Training Epoch: 26 [10240/50176]	Loss: 0.8033
Training Epoch: 26 [11264/50176]	Loss: 0.7837
Training Epoch: 26 [12288/50176]	Loss: 0.8050
Training Epoch: 26 [13312/50176]	Loss: 0.7549
Training Epoch: 26 [14336/50176]	Loss: 0.7952
Training Epoch: 26 [15360/50176]	Loss: 0.7318
Training Epoch: 26 [16384/50176]	Loss: 0.7590
Training Epoch: 26 [17408/50176]	Loss: 0.7883
Training Epoch: 26 [18432/50176]	Loss: 0.8052
Training Epoch: 26 [19456/50176]	Loss: 0.7874
Training Epoch: 26 [20480/50176]	Loss: 0.7973
Training Epoch: 26 [21504/50176]	Loss: 0.8246
Training Epoch: 26 [22528/50176]	Loss: 0.8097
Training Epoch: 26 [23552/50176]	Loss: 0.8640
Training Epoch: 26 [24576/50176]	Loss: 0.8514
Training Epoch: 26 [25600/50176]	Loss: 0.8271
Training Epoch: 26 [26624/50176]	Loss: 0.8005
Training Epoch: 26 [27648/50176]	Loss: 0.8522
Training Epoch: 26 [28672/50176]	Loss: 0.8134
Training Epoch: 26 [29696/50176]	Loss: 0.8036
Training Epoch: 26 [30720/50176]	Loss: 0.9154
Training Epoch: 26 [31744/50176]	Loss: 0.8334
Training Epoch: 26 [32768/50176]	Loss: 0.8230
Training Epoch: 26 [33792/50176]	Loss: 0.8678
Training Epoch: 26 [34816/50176]	Loss: 0.9071
Training Epoch: 26 [35840/50176]	Loss: 0.8624
Training Epoch: 26 [36864/50176]	Loss: 0.8086
Training Epoch: 26 [37888/50176]	Loss: 0.7961
Training Epoch: 26 [38912/50176]	Loss: 0.8388
Training Epoch: 26 [39936/50176]	Loss: 0.9413
Training Epoch: 26 [40960/50176]	Loss: 0.8367
Training Epoch: 26 [41984/50176]	Loss: 0.8943
Training Epoch: 26 [43008/50176]	Loss: 0.9099
Training Epoch: 26 [44032/50176]	Loss: 0.8807
Training Epoch: 26 [45056/50176]	Loss: 0.8493
Training Epoch: 26 [46080/50176]	Loss: 0.9699
Training Epoch: 26 [47104/50176]	Loss: 0.9052
Training Epoch: 26 [48128/50176]	Loss: 0.8771
Training Epoch: 26 [49152/50176]	Loss: 0.8404
Training Epoch: 26 [50176/50176]	Loss: 0.8822
2022-12-08 23:03:47.401 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:03:47,420 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.75 energy=518.55
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Up to epoch 27: time=1395.19, energy=201692.65, cost=222925.37
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Expected next epoch: time=1442.16, energy=208912.72, cost=230645.19
2022-12-08 18:03:47,421 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0017, Accuracy: 0.5618
2022-12-08 18:03:47,597 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:03:47,598 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:03:47.602 [ZeusMonitor] Monitor started.
2022-12-08 23:03:47.602 [ZeusMonitor] Running indefinitely. 2022-12-08 23:03:47.602 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:03:47.602 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e28+gpu0.power.log
2022-12-08 18:04:31,552 [ZeusDataLoader(train)] train epoch 28 done: time=44.12 energy=6713.77
2022-12-08 18:04:31,556 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7124
Training Epoch: 27 [2048/50176]	Loss: 0.7896
Training Epoch: 27 [3072/50176]	Loss: 0.7285
Training Epoch: 27 [4096/50176]	Loss: 0.7905
Training Epoch: 27 [5120/50176]	Loss: 0.7588
Training Epoch: 27 [6144/50176]	Loss: 0.7686
Training Epoch: 27 [7168/50176]	Loss: 0.7025
Training Epoch: 27 [8192/50176]	Loss: 0.7771
Training Epoch: 27 [9216/50176]	Loss: 0.7713
Training Epoch: 27 [10240/50176]	Loss: 0.7586
Training Epoch: 27 [11264/50176]	Loss: 0.7957
Training Epoch: 27 [12288/50176]	Loss: 0.7240
Training Epoch: 27 [13312/50176]	Loss: 0.7602
Training Epoch: 27 [14336/50176]	Loss: 0.7217
Training Epoch: 27 [15360/50176]	Loss: 0.7337
Training Epoch: 27 [16384/50176]	Loss: 0.7919
Training Epoch: 27 [17408/50176]	Loss: 0.7034
Training Epoch: 27 [18432/50176]	Loss: 0.7688
Training Epoch: 27 [19456/50176]	Loss: 0.7390
Training Epoch: 27 [20480/50176]	Loss: 0.7222
Training Epoch: 27 [21504/50176]	Loss: 0.7552
Training Epoch: 27 [22528/50176]	Loss: 0.7204
Training Epoch: 27 [23552/50176]	Loss: 0.6827
Training Epoch: 27 [24576/50176]	Loss: 0.7502
Training Epoch: 27 [25600/50176]	Loss: 0.7779
Training Epoch: 27 [26624/50176]	Loss: 0.8067
Training Epoch: 27 [27648/50176]	Loss: 0.7930
Training Epoch: 27 [28672/50176]	Loss: 0.7989
Training Epoch: 27 [29696/50176]	Loss: 0.7726
Training Epoch: 27 [30720/50176]	Loss: 0.7547
Training Epoch: 27 [31744/50176]	Loss: 0.8990
Training Epoch: 27 [32768/50176]	Loss: 0.8071
Training Epoch: 27 [33792/50176]	Loss: 0.7952
Training Epoch: 27 [34816/50176]	Loss: 0.8327
Training Epoch: 27 [35840/50176]	Loss: 0.8870
Training Epoch: 27 [36864/50176]	Loss: 0.8047
Training Epoch: 27 [37888/50176]	Loss: 0.7683
Training Epoch: 27 [38912/50176]	Loss: 0.8412
Training Epoch: 27 [39936/50176]	Loss: 0.8537
Training Epoch: 27 [40960/50176]	Loss: 0.7968
Training Epoch: 27 [41984/50176]	Loss: 0.7996
Training Epoch: 27 [43008/50176]	Loss: 0.7352
Training Epoch: 27 [44032/50176]	Loss: 0.8457
Training Epoch: 27 [45056/50176]	Loss: 0.8160
Training Epoch: 27 [46080/50176]	Loss: 0.8516
Training Epoch: 27 [47104/50176]	Loss: 0.8853
Training Epoch: 27 [48128/50176]	Loss: 0.7799
Training Epoch: 27 [49152/50176]	Loss: 0.8724
Training Epoch: 27 [50176/50176]	Loss: 0.8675
2022-12-08 23:04:35.286 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:04:35,308 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=516.37
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Up to epoch 28: time=1443.05, energy=208922.79, cost=230728.69
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Expected next epoch: time=1490.02, energy=216142.86, cost=238448.51
2022-12-08 18:04:35,310 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0016, Accuracy: 0.5922
2022-12-08 18:04:35,539 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:04:35,540 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:04:35.542 [ZeusMonitor] Monitor started.
2022-12-08 23:04:35.542 [ZeusMonitor] Running indefinitely. 2022-12-08 23:04:35.542 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:04:35.542 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e29+gpu0.power.log
2022-12-08 18:05:19,507 [ZeusDataLoader(train)] train epoch 29 done: time=44.19 energy=6703.86
2022-12-08 18:05:19,510 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.6693
Training Epoch: 28 [2048/50176]	Loss: 0.7472
Training Epoch: 28 [3072/50176]	Loss: 0.7091
Training Epoch: 28 [4096/50176]	Loss: 0.7409
Training Epoch: 28 [5120/50176]	Loss: 0.7067
Training Epoch: 28 [6144/50176]	Loss: 0.7037
Training Epoch: 28 [7168/50176]	Loss: 0.6796
Training Epoch: 28 [8192/50176]	Loss: 0.7296
Training Epoch: 28 [9216/50176]	Loss: 0.7201
Training Epoch: 28 [10240/50176]	Loss: 0.6446
Training Epoch: 28 [11264/50176]	Loss: 0.6976
Training Epoch: 28 [12288/50176]	Loss: 0.6912
Training Epoch: 28 [13312/50176]	Loss: 0.6971
Training Epoch: 28 [14336/50176]	Loss: 0.7557
Training Epoch: 28 [15360/50176]	Loss: 0.7058
Training Epoch: 28 [16384/50176]	Loss: 0.7441
Training Epoch: 28 [17408/50176]	Loss: 0.7034
Training Epoch: 28 [18432/50176]	Loss: 0.6708
Training Epoch: 28 [19456/50176]	Loss: 0.7937
Training Epoch: 28 [20480/50176]	Loss: 0.7568
Training Epoch: 28 [21504/50176]	Loss: 0.7364
Training Epoch: 28 [22528/50176]	Loss: 0.7532
Training Epoch: 28 [23552/50176]	Loss: 0.7677
Training Epoch: 28 [24576/50176]	Loss: 0.6802
Training Epoch: 28 [25600/50176]	Loss: 0.7244
Training Epoch: 28 [26624/50176]	Loss: 0.7458
Training Epoch: 28 [27648/50176]	Loss: 0.8077
Training Epoch: 28 [28672/50176]	Loss: 0.7615
Training Epoch: 28 [29696/50176]	Loss: 0.7257
Training Epoch: 28 [30720/50176]	Loss: 0.7712
Training Epoch: 28 [31744/50176]	Loss: 0.7746
Training Epoch: 28 [32768/50176]	Loss: 0.7521
Training Epoch: 28 [33792/50176]	Loss: 0.7518
Training Epoch: 28 [34816/50176]	Loss: 0.7686
Training Epoch: 28 [35840/50176]	Loss: 0.7591
Training Epoch: 28 [36864/50176]	Loss: 0.8182
Training Epoch: 28 [37888/50176]	Loss: 0.7423
Training Epoch: 28 [38912/50176]	Loss: 0.7591
Training Epoch: 28 [39936/50176]	Loss: 0.7851
Training Epoch: 28 [40960/50176]	Loss: 0.8794
Training Epoch: 28 [41984/50176]	Loss: 0.8324
Training Epoch: 28 [43008/50176]	Loss: 0.7585
Training Epoch: 28 [44032/50176]	Loss: 0.7653
Training Epoch: 28 [45056/50176]	Loss: 0.8923
Training Epoch: 28 [46080/50176]	Loss: 0.7772
Training Epoch: 28 [47104/50176]	Loss: 0.8493
Training Epoch: 28 [48128/50176]	Loss: 0.7496
Training Epoch: 28 [49152/50176]	Loss: 0.8210
Training Epoch: 28 [50176/50176]	Loss: 0.7761
2022-12-08 23:05:23.281 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:05:23,338 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.82 energy=531.92
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Up to epoch 29: time=1491.06, energy=216158.57, cost=238547.29
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Expected next epoch: time=1538.03, energy=223378.64, cost=246267.11
2022-12-08 18:05:23,340 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0017, Accuracy: 0.5842
2022-12-08 18:05:23,556 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:05:23,557 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:05:23.559 [ZeusMonitor] Monitor started.
2022-12-08 23:05:23.559 [ZeusMonitor] Running indefinitely. 2022-12-08 23:05:23.559 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:05:23.559 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e30+gpu0.power.log
2022-12-08 18:06:07,505 [ZeusDataLoader(train)] train epoch 30 done: time=44.16 energy=6699.65
2022-12-08 18:06:07,508 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6528
Training Epoch: 29 [2048/50176]	Loss: 0.6546
Training Epoch: 29 [3072/50176]	Loss: 0.6957
Training Epoch: 29 [4096/50176]	Loss: 0.6626
Training Epoch: 29 [5120/50176]	Loss: 0.7179
Training Epoch: 29 [6144/50176]	Loss: 0.6633
Training Epoch: 29 [7168/50176]	Loss: 0.6729
Training Epoch: 29 [8192/50176]	Loss: 0.6619
Training Epoch: 29 [9216/50176]	Loss: 0.6752
Training Epoch: 29 [10240/50176]	Loss: 0.7096
Training Epoch: 29 [11264/50176]	Loss: 0.7153
Training Epoch: 29 [12288/50176]	Loss: 0.7113
Training Epoch: 29 [13312/50176]	Loss: 0.5941
Training Epoch: 29 [14336/50176]	Loss: 0.6862
Training Epoch: 29 [15360/50176]	Loss: 0.7840
Training Epoch: 29 [16384/50176]	Loss: 0.7116
Training Epoch: 29 [17408/50176]	Loss: 0.6887
Training Epoch: 29 [18432/50176]	Loss: 0.6681
Training Epoch: 29 [19456/50176]	Loss: 0.7805
Training Epoch: 29 [20480/50176]	Loss: 0.6738
Training Epoch: 29 [21504/50176]	Loss: 0.6913
Training Epoch: 29 [22528/50176]	Loss: 0.6337
Training Epoch: 29 [23552/50176]	Loss: 0.6434
Training Epoch: 29 [24576/50176]	Loss: 0.6831
Training Epoch: 29 [25600/50176]	Loss: 0.6930
Training Epoch: 29 [26624/50176]	Loss: 0.6666
Training Epoch: 29 [27648/50176]	Loss: 0.7301
Training Epoch: 29 [28672/50176]	Loss: 0.6122
Training Epoch: 29 [29696/50176]	Loss: 0.6726
Training Epoch: 29 [30720/50176]	Loss: 0.7491
Training Epoch: 29 [31744/50176]	Loss: 0.6827
Training Epoch: 29 [32768/50176]	Loss: 0.7728
Training Epoch: 29 [33792/50176]	Loss: 0.7123
Training Epoch: 29 [34816/50176]	Loss: 0.7590
Training Epoch: 29 [35840/50176]	Loss: 0.6961
Training Epoch: 29 [36864/50176]	Loss: 0.7172
Training Epoch: 29 [37888/50176]	Loss: 0.7310
Training Epoch: 29 [38912/50176]	Loss: 0.7000
Training Epoch: 29 [39936/50176]	Loss: 0.7301
Training Epoch: 29 [40960/50176]	Loss: 0.8089
Training Epoch: 29 [41984/50176]	Loss: 0.7027
Training Epoch: 29 [43008/50176]	Loss: 0.8009
Training Epoch: 29 [44032/50176]	Loss: 0.7514
Training Epoch: 29 [45056/50176]	Loss: 0.7614
Training Epoch: 29 [46080/50176]	Loss: 0.7278
Training Epoch: 29 [47104/50176]	Loss: 0.7479
Training Epoch: 29 [48128/50176]	Loss: 0.7938
Training Epoch: 29 [49152/50176]	Loss: 0.7501
Training Epoch: 29 [50176/50176]	Loss: 0.8736
2022-12-08 23:06:11.302 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:06:11,322 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.81 energy=534.53
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Up to epoch 30: time=1539.02, energy=223392.75, cost=246361.01
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Expected next epoch: time=1585.99, energy=230612.82, cost=254080.83
2022-12-08 18:06:11,324 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0016, Accuracy: 0.5872
2022-12-08 18:06:11,543 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:06:11,544 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:06:11.558 [ZeusMonitor] Monitor started.
2022-12-08 23:06:11.558 [ZeusMonitor] Running indefinitely. 2022-12-08 23:06:11.558 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:06:11.558 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e31+gpu0.power.log
2022-12-08 18:06:55,502 [ZeusDataLoader(train)] train epoch 31 done: time=44.17 energy=6709.65
2022-12-08 18:06:55,506 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7199
Training Epoch: 30 [2048/50176]	Loss: 0.6457
Training Epoch: 30 [3072/50176]	Loss: 0.6391
Training Epoch: 30 [4096/50176]	Loss: 0.6106
Training Epoch: 30 [5120/50176]	Loss: 0.6285
Training Epoch: 30 [6144/50176]	Loss: 0.6186
Training Epoch: 30 [7168/50176]	Loss: 0.6855
Training Epoch: 30 [8192/50176]	Loss: 0.6234
Training Epoch: 30 [9216/50176]	Loss: 0.6546
Training Epoch: 30 [10240/50176]	Loss: 0.6351
Training Epoch: 30 [11264/50176]	Loss: 0.7007
Training Epoch: 30 [12288/50176]	Loss: 0.6832
Training Epoch: 30 [13312/50176]	Loss: 0.6347
Training Epoch: 30 [14336/50176]	Loss: 0.6518
Training Epoch: 30 [15360/50176]	Loss: 0.6562
Training Epoch: 30 [16384/50176]	Loss: 0.6865
Training Epoch: 30 [17408/50176]	Loss: 0.6482
Training Epoch: 30 [18432/50176]	Loss: 0.6450
Training Epoch: 30 [19456/50176]	Loss: 0.6388
Training Epoch: 30 [20480/50176]	Loss: 0.6368
Training Epoch: 30 [21504/50176]	Loss: 0.6433
Training Epoch: 30 [22528/50176]	Loss: 0.6410
Training Epoch: 30 [23552/50176]	Loss: 0.6519
Training Epoch: 30 [24576/50176]	Loss: 0.6579
Training Epoch: 30 [25600/50176]	Loss: 0.6728
Training Epoch: 30 [26624/50176]	Loss: 0.6763
Training Epoch: 30 [27648/50176]	Loss: 0.6992
Training Epoch: 30 [28672/50176]	Loss: 0.7025
Training Epoch: 30 [29696/50176]	Loss: 0.6764
Training Epoch: 30 [30720/50176]	Loss: 0.6817
Training Epoch: 30 [31744/50176]	Loss: 0.6316
Training Epoch: 30 [32768/50176]	Loss: 0.6788
Training Epoch: 30 [33792/50176]	Loss: 0.7306
Training Epoch: 30 [34816/50176]	Loss: 0.8009
Training Epoch: 30 [35840/50176]	Loss: 0.7248
Training Epoch: 30 [36864/50176]	Loss: 0.7167
Training Epoch: 30 [37888/50176]	Loss: 0.6978
Training Epoch: 30 [38912/50176]	Loss: 0.7941
Training Epoch: 30 [39936/50176]	Loss: 0.7001
Training Epoch: 30 [40960/50176]	Loss: 0.7374
Training Epoch: 30 [41984/50176]	Loss: 0.7349
Training Epoch: 30 [43008/50176]	Loss: 0.7650
Training Epoch: 30 [44032/50176]	Loss: 0.7013
Training Epoch: 30 [45056/50176]	Loss: 0.7236
Training Epoch: 30 [46080/50176]	Loss: 0.7042
Training Epoch: 30 [47104/50176]	Loss: 0.7407
Training Epoch: 30 [48128/50176]	Loss: 0.7097
Training Epoch: 30 [49152/50176]	Loss: 0.7549
Training Epoch: 30 [50176/50176]	Loss: 0.7920
2022-12-08 23:06:59.218 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:06:59,232 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.72 energy=514.73
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Up to epoch 31: time=1586.91, energy=230617.13, cost=254163.46
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Expected next epoch: time=1633.88, energy=237837.20, cost=261883.28
2022-12-08 18:06:59,234 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0016, Accuracy: 0.5945
2022-12-08 18:06:59,471 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:06:59,471 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:06:59.485 [ZeusMonitor] Monitor started.
2022-12-08 23:06:59.485 [ZeusMonitor] Running indefinitely. 2022-12-08 23:06:59.486 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:06:59.486 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e32+gpu0.power.log
2022-12-08 18:07:43,362 [ZeusDataLoader(train)] train epoch 32 done: time=44.12 energy=6706.49
2022-12-08 18:07:43,365 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.5903
Training Epoch: 31 [2048/50176]	Loss: 0.5276
Training Epoch: 31 [3072/50176]	Loss: 0.5981
Training Epoch: 31 [4096/50176]	Loss: 0.5375
Training Epoch: 31 [5120/50176]	Loss: 0.5933
Training Epoch: 31 [6144/50176]	Loss: 0.5897
Training Epoch: 31 [7168/50176]	Loss: 0.6174
Training Epoch: 31 [8192/50176]	Loss: 0.5979
Training Epoch: 31 [9216/50176]	Loss: 0.6301
Training Epoch: 31 [10240/50176]	Loss: 0.6105
Training Epoch: 31 [11264/50176]	Loss: 0.5859
Training Epoch: 31 [12288/50176]	Loss: 0.6629
Training Epoch: 31 [13312/50176]	Loss: 0.6316
Training Epoch: 31 [14336/50176]	Loss: 0.5549
Training Epoch: 31 [15360/50176]	Loss: 0.6031
Training Epoch: 31 [16384/50176]	Loss: 0.6119
Training Epoch: 31 [17408/50176]	Loss: 0.6137
Training Epoch: 31 [18432/50176]	Loss: 0.6263
Training Epoch: 31 [19456/50176]	Loss: 0.6085
Training Epoch: 31 [20480/50176]	Loss: 0.6468
Training Epoch: 31 [21504/50176]	Loss: 0.6620
Training Epoch: 31 [22528/50176]	Loss: 0.6140
Training Epoch: 31 [23552/50176]	Loss: 0.6922
Training Epoch: 31 [24576/50176]	Loss: 0.6043
Training Epoch: 31 [25600/50176]	Loss: 0.6429
Training Epoch: 31 [26624/50176]	Loss: 0.6753
Training Epoch: 31 [27648/50176]	Loss: 0.6359
Training Epoch: 31 [28672/50176]	Loss: 0.5948
Training Epoch: 31 [29696/50176]	Loss: 0.6266
Training Epoch: 31 [30720/50176]	Loss: 0.6221
Training Epoch: 31 [31744/50176]	Loss: 0.7017
Training Epoch: 31 [32768/50176]	Loss: 0.6769
Training Epoch: 31 [33792/50176]	Loss: 0.6377
Training Epoch: 31 [34816/50176]	Loss: 0.7037
Training Epoch: 31 [35840/50176]	Loss: 0.6876
Training Epoch: 31 [36864/50176]	Loss: 0.6856
Training Epoch: 31 [37888/50176]	Loss: 0.6802
Training Epoch: 31 [38912/50176]	Loss: 0.7466
Training Epoch: 31 [39936/50176]	Loss: 0.7449
Training Epoch: 31 [40960/50176]	Loss: 0.6565
Training Epoch: 31 [41984/50176]	Loss: 0.6467
Training Epoch: 31 [43008/50176]	Loss: 0.6415
Training Epoch: 31 [44032/50176]	Loss: 0.6365
Training Epoch: 31 [45056/50176]	Loss: 0.7423
Training Epoch: 31 [46080/50176]	Loss: 0.7074
Training Epoch: 31 [47104/50176]	Loss: 0.6517
Training Epoch: 31 [48128/50176]	Loss: 0.7233
Training Epoch: 31 [49152/50176]	Loss: 0.6604
Training Epoch: 31 [50176/50176]	Loss: 0.6446
2022-12-08 23:07:47.154 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:07:47,176 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.80 energy=531.34
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Up to epoch 32: time=1634.83, energy=237854.96, cost=261975.50
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Expected next epoch: time=1681.80, energy=245075.03, cost=269695.32
2022-12-08 18:07:47,177 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5854
2022-12-08 18:07:47,395 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:07:47,396 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:07:47.410 [ZeusMonitor] Monitor started.
2022-12-08 23:07:47.410 [ZeusMonitor] Running indefinitely. 2022-12-08 23:07:47.410 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:07:47.410 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e33+gpu0.power.log
2022-12-08 18:08:31,403 [ZeusDataLoader(train)] train epoch 33 done: time=44.22 energy=6722.75
2022-12-08 18:08:31,407 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.5499
Training Epoch: 32 [2048/50176]	Loss: 0.5190
Training Epoch: 32 [3072/50176]	Loss: 0.6031
Training Epoch: 32 [4096/50176]	Loss: 0.5740
Training Epoch: 32 [5120/50176]	Loss: 0.6003
Training Epoch: 32 [6144/50176]	Loss: 0.5678
Training Epoch: 32 [7168/50176]	Loss: 0.5855
Training Epoch: 32 [8192/50176]	Loss: 0.6146
Training Epoch: 32 [9216/50176]	Loss: 0.5492
Training Epoch: 32 [10240/50176]	Loss: 0.5245
Training Epoch: 32 [11264/50176]	Loss: 0.5399
Training Epoch: 32 [12288/50176]	Loss: 0.5779
Training Epoch: 32 [13312/50176]	Loss: 0.5718
Training Epoch: 32 [14336/50176]	Loss: 0.6590
Training Epoch: 32 [15360/50176]	Loss: 0.5396
Training Epoch: 32 [16384/50176]	Loss: 0.5564
Training Epoch: 32 [17408/50176]	Loss: 0.6288
Training Epoch: 32 [18432/50176]	Loss: 0.5427
Training Epoch: 32 [19456/50176]	Loss: 0.5633
Training Epoch: 32 [20480/50176]	Loss: 0.5591
Training Epoch: 32 [21504/50176]	Loss: 0.6277
Training Epoch: 32 [22528/50176]	Loss: 0.6860
Training Epoch: 32 [23552/50176]	Loss: 0.6434
Training Epoch: 32 [24576/50176]	Loss: 0.5424
Training Epoch: 32 [25600/50176]	Loss: 0.6656
Training Epoch: 32 [26624/50176]	Loss: 0.5543
Training Epoch: 32 [27648/50176]	Loss: 0.5234
Training Epoch: 32 [28672/50176]	Loss: 0.5445
Training Epoch: 32 [29696/50176]	Loss: 0.6231
Training Epoch: 32 [30720/50176]	Loss: 0.5704
Training Epoch: 32 [31744/50176]	Loss: 0.6023
Training Epoch: 32 [32768/50176]	Loss: 0.6288
Training Epoch: 32 [33792/50176]	Loss: 0.6258
Training Epoch: 32 [34816/50176]	Loss: 0.6429
Training Epoch: 32 [35840/50176]	Loss: 0.5803
Training Epoch: 32 [36864/50176]	Loss: 0.6161
Training Epoch: 32 [37888/50176]	Loss: 0.5974
Training Epoch: 32 [38912/50176]	Loss: 0.6036
Training Epoch: 32 [39936/50176]	Loss: 0.6332
Training Epoch: 32 [40960/50176]	Loss: 0.6424
Training Epoch: 32 [41984/50176]	Loss: 0.5978
Training Epoch: 32 [43008/50176]	Loss: 0.6846
Training Epoch: 32 [44032/50176]	Loss: 0.6250
Training Epoch: 32 [45056/50176]	Loss: 0.6090
Training Epoch: 32 [46080/50176]	Loss: 0.7008
Training Epoch: 32 [47104/50176]	Loss: 0.6731
Training Epoch: 32 [48128/50176]	Loss: 0.6389
Training Epoch: 32 [49152/50176]	Loss: 0.6575
Training Epoch: 32 [50176/50176]	Loss: 0.7060
2022-12-08 23:08:35.161 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:08:35,174 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=512.67
2022-12-08 18:08:35,174 [ZeusDataLoader(train)] Up to epoch 33: time=1682.81, energy=245090.38, cost=269791.12
2022-12-08 18:08:35,174 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-08 18:08:35,175 [ZeusDataLoader(train)] Training done.
2022-12-08 18:08:35,175 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec00+try01+bs1024+lr0.0060000.train.json: {"energy": 245090.3820494143, "time": 1682.810654917026, "cost": 269791.12332994695, "num_epochs": 33, "reached": true}
Validation Epoch: 32, Average loss: 0.0016, Accuracy: 0.6007

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 245090.3820494143, 'time': 1682.810654917026, 'cost': 269791.12332994695, 'num_epochs': 33, 'reached': True}
[run job; power] power_stats={'job_id': 'rec00+try01', 'train_power': {'175000': 155.16304190626855, '150000': 146.66679122833526, '125000': 123.11079515402562, '100000': 102.24933636766599}, 'train_throughput': {'175000': 1.1359478370950427, '150000': 1.1007655943504855, '125000': 0.9684575298543399, '100000': 0.3672341515196985}, 'eval_power': {'175000': 137.48240735072176, '150000': 134.78162791311982, '125000': 112.630877961285}, 'eval_throughput': {'175000': 2.6088153813743062, '150000': 2.6273896195624724, '125000': 2.337656921522037}, 'optimal_pl': 175000}
[Zeus Master] cost=269791.12332994695

[Zeus Master] Reached target metric in 1 try.
[run job] Launching job with BS 1024: and LR: 0.007
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224', 'ZEUS_JOB_ID': 'rec01+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.007']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec01+try01.train.log'
2022-12-08 18:08:39,858 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 18:08:39,859 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 18:08:39,859 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 18:08:39,904 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 18:08:39,904 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 18:08:42,103 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 18:08:42,104 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 18:08:42,328 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:08:42.338 [ZeusMonitor] Monitor started.
2022-12-08 23:08:42.338 [ZeusMonitor] Running indefinitely. 2022-12-08 23:08:42.339 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:08:42.339 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e1+gpu0.power.log
2022-12-08 18:08:43,077 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 18:08:43,077 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 18:08:51,915 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 18:09:25,483 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 18:09:27,154 [ZeusDataLoader(train)] train epoch 1 done: time=45.04 energy=6743.27
2022-12-08 18:09:27,157 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 6.2084
Training Epoch: 0 [3072/50176]	Loss: 5.3752
Training Epoch: 0 [4096/50176]	Loss: 4.8500
Training Epoch: 0 [5120/50176]	Loss: 4.8618
Training Epoch: 0 [6144/50176]	Loss: 4.6811
Training Epoch: 0 [7168/50176]	Loss: 4.6684
Training Epoch: 0 [8192/50176]	Loss: 4.6609
Training Epoch: 0 [9216/50176]	Loss: 4.9546
Training Epoch: 0 [10240/50176]	Loss: 4.7752
Training Epoch: 0 [11264/50176]	Loss: 4.7819
Training Epoch: 0 [12288/50176]	Loss: 4.7401
Training Epoch: 0 [13312/50176]	Loss: 4.6616
Training Epoch: 0 [14336/50176]	Loss: 4.7886
Training Epoch: 0 [15360/50176]	Loss: 4.6083
Training Epoch: 0 [16384/50176]	Loss: 4.6100
Training Epoch: 0 [17408/50176]	Loss: 4.5892
Training Epoch: 0 [18432/50176]	Loss: 4.5370
Training Epoch: 0 [19456/50176]	Loss: 4.6054
Training Epoch: 0 [20480/50176]	Loss: 4.5554
Training Epoch: 0 [21504/50176]	Loss: 4.5090
Training Epoch: 0 [22528/50176]	Loss: 4.5044
Training Epoch: 0 [23552/50176]	Loss: 4.5493
Training Epoch: 0 [24576/50176]	Loss: 4.4991
Training Epoch: 0 [25600/50176]	Loss: 4.4806
Training Epoch: 0 [26624/50176]	Loss: 4.4571
Training Epoch: 0 [27648/50176]	Loss: 4.4551
Training Epoch: 0 [28672/50176]	Loss: 4.4053
Training Epoch: 0 [29696/50176]	Loss: 4.4745
Training Epoch: 0 [30720/50176]	Loss: 4.4823
Training Epoch: 0 [31744/50176]	Loss: 4.4855
Training Epoch: 0 [32768/50176]	Loss: 4.4259
Training Epoch: 0 [33792/50176]	Loss: 4.4311
Training Epoch: 0 [34816/50176]	Loss: 4.4062
Training Epoch: 0 [35840/50176]	Loss: 4.3986
Training Epoch: 0 [36864/50176]	Loss: 4.3851
Training Epoch: 0 [37888/50176]	Loss: 4.4058
Training Epoch: 0 [38912/50176]	Loss: 4.3534
Training Epoch: 0 [39936/50176]	Loss: 4.3585
Training Epoch: 0 [40960/50176]	Loss: 4.3208
Training Epoch: 0 [41984/50176]	Loss: 4.3215
Training Epoch: 0 [43008/50176]	Loss: 4.3139
Training Epoch: 0 [44032/50176]	Loss: 4.3289
Training Epoch: 0 [45056/50176]	Loss: 4.3232
Training Epoch: 0 [46080/50176]	Loss: 4.2399
Training Epoch: 0 [47104/50176]	Loss: 4.2525
Training Epoch: 0 [48128/50176]	Loss: 4.2300
Training Epoch: 0 [49152/50176]	Loss: 4.2164
Training Epoch: 0 [50176/50176]	Loss: 4.1452
2022-12-08 23:09:31.031 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:09:31,057 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.89 energy=535.69
2022-12-08 18:09:31,058 [ZeusDataLoader(train)] Up to epoch 1: time=48.93, energy=7278.96, cost=7921.27
2022-12-08 18:09:31,059 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0042, Accuracy: 0.0324
2022-12-08 18:09:31,300 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:09:31.303 [ZeusMonitor] Monitor started.
2022-12-08 23:09:31.303 [ZeusMonitor] Running indefinitely. 2022-12-08 23:09:31.303 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:09:31.303 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e2+gpu0.power.log
2022-12-08 18:09:32,006 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 18:09:32,007 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 18:09:40,347 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 18:10:14,951 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 18:10:16,669 [ZeusDataLoader(train)] train epoch 2 done: time=45.60 energy=6539.91
2022-12-08 18:10:16,672 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.1814
Training Epoch: 1 [2048/50176]	Loss: 4.1363
Training Epoch: 1 [3072/50176]	Loss: 4.1511
Training Epoch: 1 [4096/50176]	Loss: 4.0860
Training Epoch: 1 [5120/50176]	Loss: 4.0833
Training Epoch: 1 [6144/50176]	Loss: 4.1175
Training Epoch: 1 [7168/50176]	Loss: 4.0155
Training Epoch: 1 [8192/50176]	Loss: 4.0262
Training Epoch: 1 [9216/50176]	Loss: 4.1400
Training Epoch: 1 [10240/50176]	Loss: 4.0604
Training Epoch: 1 [11264/50176]	Loss: 4.0967
Training Epoch: 1 [12288/50176]	Loss: 4.0769
Training Epoch: 1 [13312/50176]	Loss: 3.9818
Training Epoch: 1 [14336/50176]	Loss: 4.0635
Training Epoch: 1 [15360/50176]	Loss: 4.0218
Training Epoch: 1 [16384/50176]	Loss: 4.0672
Training Epoch: 1 [17408/50176]	Loss: 4.0316
Training Epoch: 1 [18432/50176]	Loss: 3.9999
Training Epoch: 1 [19456/50176]	Loss: 4.0002
Training Epoch: 1 [20480/50176]	Loss: 3.9745
Training Epoch: 1 [21504/50176]	Loss: 3.9980
Training Epoch: 1 [22528/50176]	Loss: 3.9429
Training Epoch: 1 [23552/50176]	Loss: 3.9338
Training Epoch: 1 [24576/50176]	Loss: 3.8988
Training Epoch: 1 [25600/50176]	Loss: 3.9156
Training Epoch: 1 [26624/50176]	Loss: 3.9441
Training Epoch: 1 [27648/50176]	Loss: 3.9333
Training Epoch: 1 [28672/50176]	Loss: 3.8500
Training Epoch: 1 [29696/50176]	Loss: 3.9632
Training Epoch: 1 [30720/50176]	Loss: 3.8988
Training Epoch: 1 [31744/50176]	Loss: 3.9339
Training Epoch: 1 [32768/50176]	Loss: 3.8482
Training Epoch: 1 [33792/50176]	Loss: 3.9186
Training Epoch: 1 [34816/50176]	Loss: 3.9120
Training Epoch: 1 [35840/50176]	Loss: 3.9066
Training Epoch: 1 [36864/50176]	Loss: 3.8646
Training Epoch: 1 [37888/50176]	Loss: 3.8638
Training Epoch: 1 [38912/50176]	Loss: 3.8383
Training Epoch: 1 [39936/50176]	Loss: 3.8562
Training Epoch: 1 [40960/50176]	Loss: 3.9166
Training Epoch: 1 [41984/50176]	Loss: 3.8131
Training Epoch: 1 [43008/50176]	Loss: 3.8154
Training Epoch: 1 [44032/50176]	Loss: 3.7950
Training Epoch: 1 [45056/50176]	Loss: 3.8313
Training Epoch: 1 [46080/50176]	Loss: 3.7561
Training Epoch: 1 [47104/50176]	Loss: 3.8415
Training Epoch: 1 [48128/50176]	Loss: 3.8155
Training Epoch: 1 [49152/50176]	Loss: 3.8049
Training Epoch: 1 [50176/50176]	Loss: 3.7781
2022-12-08 23:10:20.496 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:10:20,524 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.84 energy=507.47
2022-12-08 18:10:20,524 [ZeusDataLoader(train)] Up to epoch 2: time=98.38, energy=14326.34, cost=15771.48
2022-12-08 18:10:20,525 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0038, Accuracy: 0.0966
2022-12-08 18:10:20,717 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:10:20.722 [ZeusMonitor] Monitor started.
2022-12-08 23:10:20.722 [ZeusMonitor] Running indefinitely. 2022-12-08 23:10:20.722 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:10:20.722 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e3+gpu0.power.log
2022-12-08 18:10:21,477 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 18:10:21,477 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 18:10:30,880 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 18:11:10,158 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 18:11:12,107 [ZeusDataLoader(train)] train epoch 3 done: time=51.57 energy=6243.76
2022-12-08 18:11:12,110 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.7059
Training Epoch: 2 [2048/50176]	Loss: 3.7793
Training Epoch: 2 [3072/50176]	Loss: 3.6657
Training Epoch: 2 [4096/50176]	Loss: 3.6920
Training Epoch: 2 [5120/50176]	Loss: 3.6988
Training Epoch: 2 [6144/50176]	Loss: 3.6880
Training Epoch: 2 [7168/50176]	Loss: 3.7287
Training Epoch: 2 [8192/50176]	Loss: 3.8329
Training Epoch: 2 [9216/50176]	Loss: 3.7006
Training Epoch: 2 [10240/50176]	Loss: 3.6340
Training Epoch: 2 [11264/50176]	Loss: 3.6313
Training Epoch: 2 [12288/50176]	Loss: 3.6619
Training Epoch: 2 [13312/50176]	Loss: 3.6387
Training Epoch: 2 [14336/50176]	Loss: 3.6731
Training Epoch: 2 [15360/50176]	Loss: 3.6858
Training Epoch: 2 [16384/50176]	Loss: 3.7394
Training Epoch: 2 [17408/50176]	Loss: 3.6872
Training Epoch: 2 [18432/50176]	Loss: 3.6401
Training Epoch: 2 [19456/50176]	Loss: 3.6435
Training Epoch: 2 [20480/50176]	Loss: 3.6292
Training Epoch: 2 [21504/50176]	Loss: 3.6762
Training Epoch: 2 [22528/50176]	Loss: 3.6361
Training Epoch: 2 [23552/50176]	Loss: 3.5979
Training Epoch: 2 [24576/50176]	Loss: 3.6884
Training Epoch: 2 [25600/50176]	Loss: 3.6287
Training Epoch: 2 [26624/50176]	Loss: 3.6613
Training Epoch: 2 [27648/50176]	Loss: 3.6403
Training Epoch: 2 [28672/50176]	Loss: 3.6424
Training Epoch: 2 [29696/50176]	Loss: 3.5734
Training Epoch: 2 [30720/50176]	Loss: 3.5659
Training Epoch: 2 [31744/50176]	Loss: 3.5875
Training Epoch: 2 [32768/50176]	Loss: 3.5987
Training Epoch: 2 [33792/50176]	Loss: 3.6160
Training Epoch: 2 [34816/50176]	Loss: 3.5962
Training Epoch: 2 [35840/50176]	Loss: 3.5174
Training Epoch: 2 [36864/50176]	Loss: 3.5564
Training Epoch: 2 [37888/50176]	Loss: 3.6195
Training Epoch: 2 [38912/50176]	Loss: 3.5350
Training Epoch: 2 [39936/50176]	Loss: 3.4724
Training Epoch: 2 [40960/50176]	Loss: 3.5219
Training Epoch: 2 [41984/50176]	Loss: 3.4973
Training Epoch: 2 [43008/50176]	Loss: 3.5150
Training Epoch: 2 [44032/50176]	Loss: 3.4936
Training Epoch: 2 [45056/50176]	Loss: 3.5228
Training Epoch: 2 [46080/50176]	Loss: 3.5374
Training Epoch: 2 [47104/50176]	Loss: 3.4909
Training Epoch: 2 [48128/50176]	Loss: 3.4749
Training Epoch: 2 [49152/50176]	Loss: 3.4872
Training Epoch: 2 [50176/50176]	Loss: 3.4459
2022-12-08 23:11:16.363 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:11:16,418 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.30 energy=482.72
2022-12-08 18:11:16,418 [ZeusDataLoader(train)] Up to epoch 3: time=154.25, energy=21052.82, cost=24023.63
2022-12-08 18:11:16,419 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0035, Accuracy: 0.1416
2022-12-08 18:11:16,650 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:11:16.673 [ZeusMonitor] Monitor started.
2022-12-08 23:11:16.673 [ZeusMonitor] Running indefinitely. 2022-12-08 23:11:16.673 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:11:16.673 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e4+gpu0.power.log
2022-12-08 18:11:17,409 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 18:11:17,409 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 18:11:42,441 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 18:13:26,306 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 18:13:26,306 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 18:13:26,306 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 18:13:26,309 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 18:13:28,400 [ZeusDataLoader(train)] train epoch 4 done: time=131.97 energy=13420.28
2022-12-08 18:13:28,404 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.3849
Training Epoch: 3 [2048/50176]	Loss: 3.3439
Training Epoch: 3 [3072/50176]	Loss: 3.4046
Training Epoch: 3 [4096/50176]	Loss: 3.4460
Training Epoch: 3 [5120/50176]	Loss: 3.4194
Training Epoch: 3 [6144/50176]	Loss: 3.4230
Training Epoch: 3 [7168/50176]	Loss: 3.4411
Training Epoch: 3 [8192/50176]	Loss: 3.4520
Training Epoch: 3 [9216/50176]	Loss: 3.3547
Training Epoch: 3 [10240/50176]	Loss: 3.4104
Training Epoch: 3 [11264/50176]	Loss: 3.4303
Training Epoch: 3 [12288/50176]	Loss: 3.3929
Training Epoch: 3 [13312/50176]	Loss: 3.4732
Training Epoch: 3 [14336/50176]	Loss: 3.3703
Training Epoch: 3 [15360/50176]	Loss: 3.3413
Training Epoch: 3 [16384/50176]	Loss: 3.3845
Training Epoch: 3 [17408/50176]	Loss: 3.3394
Training Epoch: 3 [18432/50176]	Loss: 3.4149
Training Epoch: 3 [19456/50176]	Loss: 3.3310
Training Epoch: 3 [20480/50176]	Loss: 3.3363
Training Epoch: 3 [21504/50176]	Loss: 3.3304
Training Epoch: 3 [22528/50176]	Loss: 3.2863
Training Epoch: 3 [23552/50176]	Loss: 3.3362
Training Epoch: 3 [24576/50176]	Loss: 3.3276
Training Epoch: 3 [25600/50176]	Loss: 3.2012
Training Epoch: 3 [26624/50176]	Loss: 3.3850
Training Epoch: 3 [27648/50176]	Loss: 3.3486
Training Epoch: 3 [28672/50176]	Loss: 3.2717
Training Epoch: 3 [29696/50176]	Loss: 3.2500
Training Epoch: 3 [30720/50176]	Loss: 3.3263
Training Epoch: 3 [31744/50176]	Loss: 3.3274
Training Epoch: 3 [32768/50176]	Loss: 3.2855
Training Epoch: 3 [33792/50176]	Loss: 3.1703
Training Epoch: 3 [34816/50176]	Loss: 3.2628
Training Epoch: 3 [35840/50176]	Loss: 3.1908
Training Epoch: 3 [36864/50176]	Loss: 3.2412
Training Epoch: 3 [37888/50176]	Loss: 3.2695
Training Epoch: 3 [38912/50176]	Loss: 3.3162
Training Epoch: 3 [39936/50176]	Loss: 3.2703
Training Epoch: 3 [40960/50176]	Loss: 3.1697
Training Epoch: 3 [41984/50176]	Loss: 3.2451
Training Epoch: 3 [43008/50176]	Loss: 3.1206
Training Epoch: 3 [44032/50176]	Loss: 3.1949
Training Epoch: 3 [45056/50176]	Loss: 3.1859
Training Epoch: 3 [46080/50176]	Loss: 3.2363
Training Epoch: 3 [47104/50176]	Loss: 3.1250
Training Epoch: 3 [48128/50176]	Loss: 3.3419
Training Epoch: 3 [49152/50176]	Loss: 3.1442
Training Epoch: 3 [50176/50176]	Loss: 3.1874
2022-12-08 23:13:32.220 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:13:32,247 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 18:13:32,248 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+lr0.0070000.power.json: {"job_id": "rec01+try01", "train_power": {"175000": 154.93794950427161, "150000": 146.4595246293473, "125000": 122.94562865927668, "100000": 101.85536570738996}, "train_throughput": {"175000": 1.1325596419460637, "150000": 1.098530462919081, "125000": 0.9677647927574697, "100000": 0.36591614626940633}, "eval_power": {"175000": 137.03434588938902, "150000": 132.0541042630539, "125000": 112.28836933117594}, "eval_throughput": {"175000": 2.6093336140479835, "150000": 2.602200455521512, "125000": 2.326169550549045}, "optimal_pl": 175000}
2022-12-08 18:13:32,248 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.83 energy=525.17
2022-12-08 18:13:32,248 [ZeusDataLoader(train)] Up to epoch 4: time=290.06, energy=34998.27, cost=42879.03
2022-12-08 18:13:32,248 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:13:32,248 [ZeusDataLoader(train)] Expected next epoch: time=337.15, energy=42226.80, cost=50614.30
2022-12-08 18:13:32,249 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0032, Accuracy: 0.2002
2022-12-08 18:13:32,502 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:13:32,503 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:13:32.517 [ZeusMonitor] Monitor started.
2022-12-08 23:13:32.517 [ZeusMonitor] Running indefinitely. 2022-12-08 23:13:32.517 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:13:32.517 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e5+gpu0.power.log
2022-12-08 18:14:16,281 [ZeusDataLoader(train)] train epoch 5 done: time=44.02 energy=6685.52
2022-12-08 18:14:16,285 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.2108
Training Epoch: 4 [2048/50176]	Loss: 3.1362
Training Epoch: 4 [3072/50176]	Loss: 3.0568
Training Epoch: 4 [4096/50176]	Loss: 3.1002
Training Epoch: 4 [5120/50176]	Loss: 3.0739
Training Epoch: 4 [6144/50176]	Loss: 3.1319
Training Epoch: 4 [7168/50176]	Loss: 3.0859
Training Epoch: 4 [8192/50176]	Loss: 3.1107
Training Epoch: 4 [9216/50176]	Loss: 3.1155
Training Epoch: 4 [10240/50176]	Loss: 3.0632
Training Epoch: 4 [11264/50176]	Loss: 3.0644
Training Epoch: 4 [12288/50176]	Loss: 3.0849
Training Epoch: 4 [13312/50176]	Loss: 3.0380
Training Epoch: 4 [14336/50176]	Loss: 3.1464
Training Epoch: 4 [15360/50176]	Loss: 3.0635
Training Epoch: 4 [16384/50176]	Loss: 2.9309
Training Epoch: 4 [17408/50176]	Loss: 3.0764
Training Epoch: 4 [18432/50176]	Loss: 3.0929
Training Epoch: 4 [19456/50176]	Loss: 3.0734
Training Epoch: 4 [20480/50176]	Loss: 3.0559
Training Epoch: 4 [21504/50176]	Loss: 3.0524
Training Epoch: 4 [22528/50176]	Loss: 2.9542
Training Epoch: 4 [23552/50176]	Loss: 2.9755
Training Epoch: 4 [24576/50176]	Loss: 2.9848
Training Epoch: 4 [25600/50176]	Loss: 2.9603
Training Epoch: 4 [26624/50176]	Loss: 2.9693
Training Epoch: 4 [27648/50176]	Loss: 3.0250
Training Epoch: 4 [28672/50176]	Loss: 3.0020
Training Epoch: 4 [29696/50176]	Loss: 3.0378
Training Epoch: 4 [30720/50176]	Loss: 2.9539
Training Epoch: 4 [31744/50176]	Loss: 2.9588
Training Epoch: 4 [32768/50176]	Loss: 2.9958
Training Epoch: 4 [33792/50176]	Loss: 2.9870
Training Epoch: 4 [34816/50176]	Loss: 2.9527
Training Epoch: 4 [35840/50176]	Loss: 3.0458
Training Epoch: 4 [36864/50176]	Loss: 2.9445
Training Epoch: 4 [37888/50176]	Loss: 3.1548
Training Epoch: 4 [38912/50176]	Loss: 2.9671
Training Epoch: 4 [39936/50176]	Loss: 2.9898
Training Epoch: 4 [40960/50176]	Loss: 2.9358
Training Epoch: 4 [41984/50176]	Loss: 2.8818
Training Epoch: 4 [43008/50176]	Loss: 2.9045
Training Epoch: 4 [44032/50176]	Loss: 2.8910
Training Epoch: 4 [45056/50176]	Loss: 2.9133
Training Epoch: 4 [46080/50176]	Loss: 2.9819
Training Epoch: 4 [47104/50176]	Loss: 3.0205
Training Epoch: 4 [48128/50176]	Loss: 2.9539
Training Epoch: 4 [49152/50176]	Loss: 2.9844
Training Epoch: 4 [50176/50176]	Loss: 3.0594
2022-12-08 23:14:20.067 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:14:20,083 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.79 energy=512.72
2022-12-08 18:14:20,083 [ZeusDataLoader(train)] Up to epoch 5: time=337.87, energy=42196.51, cost=50661.79
2022-12-08 18:14:20,083 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:14:20,083 [ZeusDataLoader(train)] Expected next epoch: time=384.97, energy=49425.05, cost=58397.06
2022-12-08 18:14:20,084 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0029, Accuracy: 0.2507
2022-12-08 18:14:20,283 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:14:20,284 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:14:20.288 [ZeusMonitor] Monitor started.
2022-12-08 23:14:20.288 [ZeusMonitor] Running indefinitely. 2022-12-08 23:14:20.288 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:14:20.288 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e6+gpu0.power.log
2022-12-08 18:15:04,279 [ZeusDataLoader(train)] train epoch 6 done: time=44.19 energy=6694.42
2022-12-08 18:15:04,283 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.7774
Training Epoch: 5 [2048/50176]	Loss: 2.8280
Training Epoch: 5 [3072/50176]	Loss: 2.9354
Training Epoch: 5 [4096/50176]	Loss: 2.8096
Training Epoch: 5 [5120/50176]	Loss: 2.7744
Training Epoch: 5 [6144/50176]	Loss: 2.8533
Training Epoch: 5 [7168/50176]	Loss: 2.7798
Training Epoch: 5 [8192/50176]	Loss: 2.7771
Training Epoch: 5 [9216/50176]	Loss: 2.7808
Training Epoch: 5 [10240/50176]	Loss: 2.8853
Training Epoch: 5 [11264/50176]	Loss: 2.9088
Training Epoch: 5 [12288/50176]	Loss: 2.6976
Training Epoch: 5 [13312/50176]	Loss: 2.7566
Training Epoch: 5 [14336/50176]	Loss: 2.7639
Training Epoch: 5 [15360/50176]	Loss: 2.8405
Training Epoch: 5 [16384/50176]	Loss: 2.7848
Training Epoch: 5 [17408/50176]	Loss: 2.8402
Training Epoch: 5 [18432/50176]	Loss: 2.7150
Training Epoch: 5 [19456/50176]	Loss: 2.7670
Training Epoch: 5 [20480/50176]	Loss: 2.8569
Training Epoch: 5 [21504/50176]	Loss: 2.7605
Training Epoch: 5 [22528/50176]	Loss: 2.8139
Training Epoch: 5 [23552/50176]	Loss: 2.8224
Training Epoch: 5 [24576/50176]	Loss: 2.8027
Training Epoch: 5 [25600/50176]	Loss: 2.7952
Training Epoch: 5 [26624/50176]	Loss: 2.7311
Training Epoch: 5 [27648/50176]	Loss: 2.7481
Training Epoch: 5 [28672/50176]	Loss: 2.7585
Training Epoch: 5 [29696/50176]	Loss: 2.7095
Training Epoch: 5 [30720/50176]	Loss: 2.6991
Training Epoch: 5 [31744/50176]	Loss: 2.7542
Training Epoch: 5 [32768/50176]	Loss: 2.7370
Training Epoch: 5 [33792/50176]	Loss: 2.6574
Training Epoch: 5 [34816/50176]	Loss: 2.6576
Training Epoch: 5 [35840/50176]	Loss: 2.8134
Training Epoch: 5 [36864/50176]	Loss: 2.7026
Training Epoch: 5 [37888/50176]	Loss: 2.6623
Training Epoch: 5 [38912/50176]	Loss: 2.6366
Training Epoch: 5 [39936/50176]	Loss: 2.7841
Training Epoch: 5 [40960/50176]	Loss: 2.5956
Training Epoch: 5 [41984/50176]	Loss: 2.7394
Training Epoch: 5 [43008/50176]	Loss: 2.7018
Training Epoch: 5 [44032/50176]	Loss: 2.7434
Training Epoch: 5 [45056/50176]	Loss: 2.8450
Training Epoch: 5 [46080/50176]	Loss: 2.6831
Training Epoch: 5 [47104/50176]	Loss: 2.6909
Training Epoch: 5 [48128/50176]	Loss: 2.7305
Training Epoch: 5 [49152/50176]	Loss: 2.7220
Training Epoch: 5 [50176/50176]	Loss: 2.6875
2022-12-08 23:15:08.057 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:15:08,082 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.79 energy=528.70
2022-12-08 18:15:08,082 [ZeusDataLoader(train)] Up to epoch 6: time=385.85, energy=49419.63, cost=58471.29
2022-12-08 18:15:08,082 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:15:08,082 [ZeusDataLoader(train)] Expected next epoch: time=432.94, energy=56648.17, cost=66206.56
2022-12-08 18:15:08,084 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0027, Accuracy: 0.2998
2022-12-08 18:15:08,340 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:15:08,341 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:15:08.343 [ZeusMonitor] Monitor started.
2022-12-08 23:15:08.343 [ZeusMonitor] Running indefinitely. 2022-12-08 23:15:08.343 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:15:08.343 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e7+gpu0.power.log
2022-12-08 18:15:52,293 [ZeusDataLoader(train)] train epoch 7 done: time=44.20 energy=6710.21
2022-12-08 18:15:52,296 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.6039
Training Epoch: 6 [2048/50176]	Loss: 2.5797
Training Epoch: 6 [3072/50176]	Loss: 2.7083
Training Epoch: 6 [4096/50176]	Loss: 2.5883
Training Epoch: 6 [5120/50176]	Loss: 2.5871
Training Epoch: 6 [6144/50176]	Loss: 2.5465
Training Epoch: 6 [7168/50176]	Loss: 2.6191
Training Epoch: 6 [8192/50176]	Loss: 2.5939
Training Epoch: 6 [9216/50176]	Loss: 2.7077
Training Epoch: 6 [10240/50176]	Loss: 2.6729
Training Epoch: 6 [11264/50176]	Loss: 2.5359
Training Epoch: 6 [12288/50176]	Loss: 2.6457
Training Epoch: 6 [13312/50176]	Loss: 2.5758
Training Epoch: 6 [14336/50176]	Loss: 2.5756
Training Epoch: 6 [15360/50176]	Loss: 2.5147
Training Epoch: 6 [16384/50176]	Loss: 2.5881
Training Epoch: 6 [17408/50176]	Loss: 2.5192
Training Epoch: 6 [18432/50176]	Loss: 2.6169
Training Epoch: 6 [19456/50176]	Loss: 2.4589
Training Epoch: 6 [20480/50176]	Loss: 2.6399
Training Epoch: 6 [21504/50176]	Loss: 2.6198
Training Epoch: 6 [22528/50176]	Loss: 2.5474
Training Epoch: 6 [23552/50176]	Loss: 2.5285
Training Epoch: 6 [24576/50176]	Loss: 2.5598
Training Epoch: 6 [25600/50176]	Loss: 2.4630
Training Epoch: 6 [26624/50176]	Loss: 2.6078
Training Epoch: 6 [27648/50176]	Loss: 2.5435
Training Epoch: 6 [28672/50176]	Loss: 2.3941
Training Epoch: 6 [29696/50176]	Loss: 2.5492
Training Epoch: 6 [30720/50176]	Loss: 2.4931
Training Epoch: 6 [31744/50176]	Loss: 2.5209
Training Epoch: 6 [32768/50176]	Loss: 2.4631
Training Epoch: 6 [33792/50176]	Loss: 2.5576
Training Epoch: 6 [34816/50176]	Loss: 2.5207
Training Epoch: 6 [35840/50176]	Loss: 2.4969
Training Epoch: 6 [36864/50176]	Loss: 2.5559
Training Epoch: 6 [37888/50176]	Loss: 2.5710
Training Epoch: 6 [38912/50176]	Loss: 2.5734
Training Epoch: 6 [39936/50176]	Loss: 2.5196
Training Epoch: 6 [40960/50176]	Loss: 2.5055
Training Epoch: 6 [41984/50176]	Loss: 2.4924
Training Epoch: 6 [43008/50176]	Loss: 2.4479
Training Epoch: 6 [44032/50176]	Loss: 2.4684
Training Epoch: 6 [45056/50176]	Loss: 2.4919
Training Epoch: 6 [46080/50176]	Loss: 2.5591
Training Epoch: 6 [47104/50176]	Loss: 2.4854
Training Epoch: 6 [48128/50176]	Loss: 2.4834
Training Epoch: 6 [49152/50176]	Loss: 2.4018
Training Epoch: 6 [50176/50176]	Loss: 2.5233
2022-12-08 23:15:56.134 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:15:56,155 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.85 energy=528.27
2022-12-08 18:15:56,155 [ZeusDataLoader(train)] Up to epoch 7: time=433.90, energy=56658.11, cost=66295.02
2022-12-08 18:15:56,156 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:15:56,156 [ZeusDataLoader(train)] Expected next epoch: time=480.99, energy=63886.64, cost=74030.29
2022-12-08 18:15:56,157 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0025, Accuracy: 0.3338
2022-12-08 18:15:56,363 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:15:56,364 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:15:56.368 [ZeusMonitor] Monitor started.
2022-12-08 23:15:56.368 [ZeusMonitor] Running indefinitely. 2022-12-08 23:15:56.368 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:15:56.368 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e8+gpu0.power.log
2022-12-08 18:16:40,332 [ZeusDataLoader(train)] train epoch 8 done: time=44.17 energy=6702.47
2022-12-08 18:16:40,337 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.4136
Training Epoch: 7 [2048/50176]	Loss: 2.3444
Training Epoch: 7 [3072/50176]	Loss: 2.3488
Training Epoch: 7 [4096/50176]	Loss: 2.3558
Training Epoch: 7 [5120/50176]	Loss: 2.4152
Training Epoch: 7 [6144/50176]	Loss: 2.3508
Training Epoch: 7 [7168/50176]	Loss: 2.3857
Training Epoch: 7 [8192/50176]	Loss: 2.3237
Training Epoch: 7 [9216/50176]	Loss: 2.2556
Training Epoch: 7 [10240/50176]	Loss: 2.3276
Training Epoch: 7 [11264/50176]	Loss: 2.2821
Training Epoch: 7 [12288/50176]	Loss: 2.3976
Training Epoch: 7 [13312/50176]	Loss: 2.3424
Training Epoch: 7 [14336/50176]	Loss: 2.4351
Training Epoch: 7 [15360/50176]	Loss: 2.3690
Training Epoch: 7 [16384/50176]	Loss: 2.3298
Training Epoch: 7 [17408/50176]	Loss: 2.4368
Training Epoch: 7 [18432/50176]	Loss: 2.3087
Training Epoch: 7 [19456/50176]	Loss: 2.3615
Training Epoch: 7 [20480/50176]	Loss: 2.4097
Training Epoch: 7 [21504/50176]	Loss: 2.3845
Training Epoch: 7 [22528/50176]	Loss: 2.3922
Training Epoch: 7 [23552/50176]	Loss: 2.3622
Training Epoch: 7 [24576/50176]	Loss: 2.3425
Training Epoch: 7 [25600/50176]	Loss: 2.3610
Training Epoch: 7 [26624/50176]	Loss: 2.3814
Training Epoch: 7 [27648/50176]	Loss: 2.3947
Training Epoch: 7 [28672/50176]	Loss: 2.3058
Training Epoch: 7 [29696/50176]	Loss: 2.3554
Training Epoch: 7 [30720/50176]	Loss: 2.3356
Training Epoch: 7 [31744/50176]	Loss: 2.3855
Training Epoch: 7 [32768/50176]	Loss: 2.2368
Training Epoch: 7 [33792/50176]	Loss: 2.3312
Training Epoch: 7 [34816/50176]	Loss: 2.3478
Training Epoch: 7 [35840/50176]	Loss: 2.2657
Training Epoch: 7 [36864/50176]	Loss: 2.2392
Training Epoch: 7 [37888/50176]	Loss: 2.2513
Training Epoch: 7 [38912/50176]	Loss: 2.3782
Training Epoch: 7 [39936/50176]	Loss: 2.4030
Training Epoch: 7 [40960/50176]	Loss: 2.3933
Training Epoch: 7 [41984/50176]	Loss: 2.2255
Training Epoch: 7 [43008/50176]	Loss: 2.2897
Training Epoch: 7 [44032/50176]	Loss: 2.2811
Training Epoch: 7 [45056/50176]	Loss: 2.3186
Training Epoch: 7 [46080/50176]	Loss: 2.3684
Training Epoch: 7 [47104/50176]	Loss: 2.2877
Training Epoch: 7 [48128/50176]	Loss: 2.2809
Training Epoch: 7 [49152/50176]	Loss: 2.4077
Training Epoch: 7 [50176/50176]	Loss: 2.2977
2022-12-08 23:16:44.136 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:16:44,179 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.83 energy=538.85
2022-12-08 18:16:44,179 [ZeusDataLoader(train)] Up to epoch 8: time=481.90, energy=63899.43, cost=74115.60
2022-12-08 18:16:44,179 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:16:44,179 [ZeusDataLoader(train)] Expected next epoch: time=528.99, energy=71127.97, cost=81850.88
2022-12-08 18:16:44,180 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0028, Accuracy: 0.3096
2022-12-08 18:16:44,376 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:16:44,377 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:16:44.381 [ZeusMonitor] Monitor started.
2022-12-08 23:16:44.381 [ZeusMonitor] Running indefinitely. 2022-12-08 23:16:44.381 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:16:44.381 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e9+gpu0.power.log
2022-12-08 18:17:28,366 [ZeusDataLoader(train)] train epoch 9 done: time=44.18 energy=6728.20
2022-12-08 18:17:28,369 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.3270
Training Epoch: 8 [2048/50176]	Loss: 2.3080
Training Epoch: 8 [3072/50176]	Loss: 2.2197
Training Epoch: 8 [4096/50176]	Loss: 2.1794
Training Epoch: 8 [5120/50176]	Loss: 2.1071
Training Epoch: 8 [6144/50176]	Loss: 2.1854
Training Epoch: 8 [7168/50176]	Loss: 2.2280
Training Epoch: 8 [8192/50176]	Loss: 2.2709
Training Epoch: 8 [9216/50176]	Loss: 2.1800
Training Epoch: 8 [10240/50176]	Loss: 2.1587
Training Epoch: 8 [11264/50176]	Loss: 2.2179
Training Epoch: 8 [12288/50176]	Loss: 2.2020
Training Epoch: 8 [13312/50176]	Loss: 2.2523
Training Epoch: 8 [14336/50176]	Loss: 2.1607
Training Epoch: 8 [15360/50176]	Loss: 2.2464
Training Epoch: 8 [16384/50176]	Loss: 2.1609
Training Epoch: 8 [17408/50176]	Loss: 2.2818
Training Epoch: 8 [18432/50176]	Loss: 2.2420
Training Epoch: 8 [19456/50176]	Loss: 2.1632
Training Epoch: 8 [20480/50176]	Loss: 2.1310
Training Epoch: 8 [21504/50176]	Loss: 2.1355
Training Epoch: 8 [22528/50176]	Loss: 2.1862
Training Epoch: 8 [23552/50176]	Loss: 2.1961
Training Epoch: 8 [24576/50176]	Loss: 2.2516
Training Epoch: 8 [25600/50176]	Loss: 2.1593
Training Epoch: 8 [26624/50176]	Loss: 2.1786
Training Epoch: 8 [27648/50176]	Loss: 2.1027
Training Epoch: 8 [28672/50176]	Loss: 2.2570
Training Epoch: 8 [29696/50176]	Loss: 2.1676
Training Epoch: 8 [30720/50176]	Loss: 2.1705
Training Epoch: 8 [31744/50176]	Loss: 2.0903
Training Epoch: 8 [32768/50176]	Loss: 2.1380
Training Epoch: 8 [33792/50176]	Loss: 2.2167
Training Epoch: 8 [34816/50176]	Loss: 2.2103
Training Epoch: 8 [35840/50176]	Loss: 2.2033
Training Epoch: 8 [36864/50176]	Loss: 2.1442
Training Epoch: 8 [37888/50176]	Loss: 2.1874
Training Epoch: 8 [38912/50176]	Loss: 2.1560
Training Epoch: 8 [39936/50176]	Loss: 2.2565
Training Epoch: 8 [40960/50176]	Loss: 2.1580
Training Epoch: 8 [41984/50176]	Loss: 2.1937
Training Epoch: 8 [43008/50176]	Loss: 2.1556
Training Epoch: 8 [44032/50176]	Loss: 2.2622
Training Epoch: 8 [45056/50176]	Loss: 2.1939
Training Epoch: 8 [46080/50176]	Loss: 2.1346
Training Epoch: 8 [47104/50176]	Loss: 2.1907
Training Epoch: 8 [48128/50176]	Loss: 2.1126
Training Epoch: 8 [49152/50176]	Loss: 2.1514
Training Epoch: 8 [50176/50176]	Loss: 2.1763
2022-12-08 23:17:32.160 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:17:32,196 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.82 energy=533.29
2022-12-08 18:17:32,196 [ZeusDataLoader(train)] Up to epoch 9: time=529.89, energy=71160.92, cost=81945.90
2022-12-08 18:17:32,196 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:17:32,196 [ZeusDataLoader(train)] Expected next epoch: time=576.99, energy=78389.45, cost=89681.18
2022-12-08 18:17:32,197 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0023, Accuracy: 0.3908
2022-12-08 18:17:32,433 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:17:32,433 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:17:32.435 [ZeusMonitor] Monitor started.
2022-12-08 23:17:32.435 [ZeusMonitor] Running indefinitely. 2022-12-08 23:17:32.435 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:17:32.435 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e10+gpu0.power.log
2022-12-08 18:18:16,324 [ZeusDataLoader(train)] train epoch 10 done: time=44.12 energy=6714.85
2022-12-08 18:18:16,327 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.0757
Training Epoch: 9 [2048/50176]	Loss: 2.1121
Training Epoch: 9 [3072/50176]	Loss: 2.1024
Training Epoch: 9 [4096/50176]	Loss: 2.0130
Training Epoch: 9 [5120/50176]	Loss: 2.1344
Training Epoch: 9 [6144/50176]	Loss: 1.9923
Training Epoch: 9 [7168/50176]	Loss: 2.0831
Training Epoch: 9 [8192/50176]	Loss: 2.0657
Training Epoch: 9 [9216/50176]	Loss: 2.0048
Training Epoch: 9 [10240/50176]	Loss: 2.0213
Training Epoch: 9 [11264/50176]	Loss: 2.1315
Training Epoch: 9 [12288/50176]	Loss: 2.0538
Training Epoch: 9 [13312/50176]	Loss: 2.0455
Training Epoch: 9 [14336/50176]	Loss: 2.1000
Training Epoch: 9 [15360/50176]	Loss: 2.1183
Training Epoch: 9 [16384/50176]	Loss: 2.1026
Training Epoch: 9 [17408/50176]	Loss: 1.9683
Training Epoch: 9 [18432/50176]	Loss: 2.0562
Training Epoch: 9 [19456/50176]	Loss: 2.0155
Training Epoch: 9 [20480/50176]	Loss: 2.0482
Training Epoch: 9 [21504/50176]	Loss: 2.0566
Training Epoch: 9 [22528/50176]	Loss: 1.9418
Training Epoch: 9 [23552/50176]	Loss: 1.9974
Training Epoch: 9 [24576/50176]	Loss: 2.0566
Training Epoch: 9 [25600/50176]	Loss: 1.9585
Training Epoch: 9 [26624/50176]	Loss: 2.0411
Training Epoch: 9 [27648/50176]	Loss: 2.1225
Training Epoch: 9 [28672/50176]	Loss: 2.0851
Training Epoch: 9 [29696/50176]	Loss: 2.0156
Training Epoch: 9 [30720/50176]	Loss: 1.9378
Training Epoch: 9 [31744/50176]	Loss: 2.0740
Training Epoch: 9 [32768/50176]	Loss: 2.0132
Training Epoch: 9 [33792/50176]	Loss: 1.9755
Training Epoch: 9 [34816/50176]	Loss: 2.0646
Training Epoch: 9 [35840/50176]	Loss: 2.0207
Training Epoch: 9 [36864/50176]	Loss: 2.0176
Training Epoch: 9 [37888/50176]	Loss: 2.0154
Training Epoch: 9 [38912/50176]	Loss: 2.0451
Training Epoch: 9 [39936/50176]	Loss: 2.0462
Training Epoch: 9 [40960/50176]	Loss: 2.0603
Training Epoch: 9 [41984/50176]	Loss: 1.9259
Training Epoch: 9 [43008/50176]	Loss: 2.0392
Training Epoch: 9 [44032/50176]	Loss: 2.0247
Training Epoch: 9 [45056/50176]	Loss: 1.9022
Training Epoch: 9 [46080/50176]	Loss: 2.0674
Training Epoch: 9 [47104/50176]	Loss: 1.9954
Training Epoch: 9 [48128/50176]	Loss: 1.9599
Training Epoch: 9 [49152/50176]	Loss: 1.9539
Training Epoch: 9 [50176/50176]	Loss: 1.8930
2022-12-08 23:18:20.059 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:18:20,074 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.74 energy=513.00
2022-12-08 18:18:20,074 [ZeusDataLoader(train)] Up to epoch 10: time=577.75, energy=78388.77, cost=89747.27
2022-12-08 18:18:20,074 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:18:20,075 [ZeusDataLoader(train)] Expected next epoch: time=624.84, energy=85617.31, cost=97482.55
2022-12-08 18:18:20,076 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0021, Accuracy: 0.4210
2022-12-08 18:18:20,320 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:18:20,321 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:18:20.335 [ZeusMonitor] Monitor started.
2022-12-08 23:18:20.335 [ZeusMonitor] Running indefinitely. 2022-12-08 23:18:20.335 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:18:20.335 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e11+gpu0.power.log
2022-12-08 18:19:04,323 [ZeusDataLoader(train)] train epoch 11 done: time=44.24 energy=6719.62
2022-12-08 18:19:04,326 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.9452
Training Epoch: 10 [2048/50176]	Loss: 1.9003
Training Epoch: 10 [3072/50176]	Loss: 1.8598
Training Epoch: 10 [4096/50176]	Loss: 1.9867
Training Epoch: 10 [5120/50176]	Loss: 1.8834
Training Epoch: 10 [6144/50176]	Loss: 1.9015
Training Epoch: 10 [7168/50176]	Loss: 1.8988
Training Epoch: 10 [8192/50176]	Loss: 1.8249
Training Epoch: 10 [9216/50176]	Loss: 1.9179
Training Epoch: 10 [10240/50176]	Loss: 1.8057
Training Epoch: 10 [11264/50176]	Loss: 2.0308
Training Epoch: 10 [12288/50176]	Loss: 1.9242
Training Epoch: 10 [13312/50176]	Loss: 1.9726
Training Epoch: 10 [14336/50176]	Loss: 2.0215
Training Epoch: 10 [15360/50176]	Loss: 1.9717
Training Epoch: 10 [16384/50176]	Loss: 2.0258
Training Epoch: 10 [17408/50176]	Loss: 1.9879
Training Epoch: 10 [18432/50176]	Loss: 1.8779
Training Epoch: 10 [19456/50176]	Loss: 1.9210
Training Epoch: 10 [20480/50176]	Loss: 1.8657
Training Epoch: 10 [21504/50176]	Loss: 1.9405
Training Epoch: 10 [22528/50176]	Loss: 1.9380
Training Epoch: 10 [23552/50176]	Loss: 1.8877
Training Epoch: 10 [24576/50176]	Loss: 1.9369
Training Epoch: 10 [25600/50176]	Loss: 1.9199
Training Epoch: 10 [26624/50176]	Loss: 1.8666
Training Epoch: 10 [27648/50176]	Loss: 1.8886
Training Epoch: 10 [28672/50176]	Loss: 2.0045
Training Epoch: 10 [29696/50176]	Loss: 2.0112
Training Epoch: 10 [30720/50176]	Loss: 1.8487
Training Epoch: 10 [31744/50176]	Loss: 1.9910
Training Epoch: 10 [32768/50176]	Loss: 1.8406
Training Epoch: 10 [33792/50176]	Loss: 1.9030
Training Epoch: 10 [34816/50176]	Loss: 1.9039
Training Epoch: 10 [35840/50176]	Loss: 2.0261
Training Epoch: 10 [36864/50176]	Loss: 1.9271
Training Epoch: 10 [37888/50176]	Loss: 1.8213
Training Epoch: 10 [38912/50176]	Loss: 1.8447
Training Epoch: 10 [39936/50176]	Loss: 1.9844
Training Epoch: 10 [40960/50176]	Loss: 1.7681
Training Epoch: 10 [41984/50176]	Loss: 1.7972
Training Epoch: 10 [43008/50176]	Loss: 1.9344
Training Epoch: 10 [44032/50176]	Loss: 1.9322
Training Epoch: 10 [45056/50176]	Loss: 1.8248
Training Epoch: 10 [46080/50176]	Loss: 1.7964
Training Epoch: 10 [47104/50176]	Loss: 1.9286
Training Epoch: 10 [48128/50176]	Loss: 1.8753
Training Epoch: 10 [49152/50176]	Loss: 1.9067
Training Epoch: 10 [50176/50176]	Loss: 1.9519
2022-12-08 23:19:08.057 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:19:08,080 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.75 energy=514.33
2022-12-08 18:19:08,081 [ZeusDataLoader(train)] Up to epoch 11: time=625.73, energy=85622.72, cost=97562.84
2022-12-08 18:19:08,081 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:19:08,081 [ZeusDataLoader(train)] Expected next epoch: time=672.83, energy=92851.26, cost=105298.12
2022-12-08 18:19:08,082 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0020, Accuracy: 0.4449
2022-12-08 18:19:08,336 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:19:08,337 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:19:08.339 [ZeusMonitor] Monitor started.
2022-12-08 23:19:08.339 [ZeusMonitor] Running indefinitely. 2022-12-08 23:19:08.339 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:19:08.339 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e12+gpu0.power.log
2022-12-08 18:19:52,289 [ZeusDataLoader(train)] train epoch 12 done: time=44.20 energy=6705.01
2022-12-08 18:19:52,293 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.6812
Training Epoch: 11 [2048/50176]	Loss: 1.7674
Training Epoch: 11 [3072/50176]	Loss: 1.7384
Training Epoch: 11 [4096/50176]	Loss: 1.8963
Training Epoch: 11 [5120/50176]	Loss: 1.8863
Training Epoch: 11 [6144/50176]	Loss: 1.6834
Training Epoch: 11 [7168/50176]	Loss: 1.7223
Training Epoch: 11 [8192/50176]	Loss: 1.7730
Training Epoch: 11 [9216/50176]	Loss: 1.7618
Training Epoch: 11 [10240/50176]	Loss: 1.8555
Training Epoch: 11 [11264/50176]	Loss: 1.7640
Training Epoch: 11 [12288/50176]	Loss: 1.7504
Training Epoch: 11 [13312/50176]	Loss: 1.8752
Training Epoch: 11 [14336/50176]	Loss: 1.7156
Training Epoch: 11 [15360/50176]	Loss: 1.8195
Training Epoch: 11 [16384/50176]	Loss: 1.8072
Training Epoch: 11 [17408/50176]	Loss: 1.7909
Training Epoch: 11 [18432/50176]	Loss: 1.7887
Training Epoch: 11 [19456/50176]	Loss: 1.7586
Training Epoch: 11 [20480/50176]	Loss: 1.8683
Training Epoch: 11 [21504/50176]	Loss: 1.8747
Training Epoch: 11 [22528/50176]	Loss: 1.8324
Training Epoch: 11 [23552/50176]	Loss: 1.8376
Training Epoch: 11 [24576/50176]	Loss: 1.8009
Training Epoch: 11 [25600/50176]	Loss: 1.7541
Training Epoch: 11 [26624/50176]	Loss: 1.7335
Training Epoch: 11 [27648/50176]	Loss: 1.7686
Training Epoch: 11 [28672/50176]	Loss: 1.7869
Training Epoch: 11 [29696/50176]	Loss: 1.8593
Training Epoch: 11 [30720/50176]	Loss: 1.7375
Training Epoch: 11 [31744/50176]	Loss: 1.7964
Training Epoch: 11 [32768/50176]	Loss: 1.8180
Training Epoch: 11 [33792/50176]	Loss: 1.8225
Training Epoch: 11 [34816/50176]	Loss: 1.8738
Training Epoch: 11 [35840/50176]	Loss: 1.8019
Training Epoch: 11 [36864/50176]	Loss: 1.7695
Training Epoch: 11 [37888/50176]	Loss: 1.8281
Training Epoch: 11 [38912/50176]	Loss: 1.8641
Training Epoch: 11 [39936/50176]	Loss: 1.8077
Training Epoch: 11 [40960/50176]	Loss: 1.7392
Training Epoch: 11 [41984/50176]	Loss: 1.8328
Training Epoch: 11 [43008/50176]	Loss: 1.8570
Training Epoch: 11 [44032/50176]	Loss: 1.8036
Training Epoch: 11 [45056/50176]	Loss: 1.9110
Training Epoch: 11 [46080/50176]	Loss: 1.6999
Training Epoch: 11 [47104/50176]	Loss: 1.8099
Training Epoch: 11 [48128/50176]	Loss: 1.7866
Training Epoch: 11 [49152/50176]	Loss: 1.7470
Training Epoch: 11 [50176/50176]	Loss: 1.8515
2022-12-08 23:19:56.089 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:19:56,115 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.81 energy=528.77
2022-12-08 18:19:56,115 [ZeusDataLoader(train)] Up to epoch 12: time=673.74, energy=92856.51, cost=105380.78
2022-12-08 18:19:56,115 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:19:56,115 [ZeusDataLoader(train)] Expected next epoch: time=720.84, energy=100085.04, cost=113116.06
2022-12-08 18:19:56,116 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0020, Accuracy: 0.4631
2022-12-08 18:19:56,313 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:19:56,314 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:19:56.318 [ZeusMonitor] Monitor started.
2022-12-08 23:19:56.318 [ZeusMonitor] Running indefinitely. 2022-12-08 23:19:56.318 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:19:56.318 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e13+gpu0.power.log
2022-12-08 18:20:40,327 [ZeusDataLoader(train)] train epoch 13 done: time=44.20 energy=6716.21
2022-12-08 18:20:40,332 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.7051
Training Epoch: 12 [2048/50176]	Loss: 1.7045
Training Epoch: 12 [3072/50176]	Loss: 1.6908
Training Epoch: 12 [4096/50176]	Loss: 1.6588
Training Epoch: 12 [5120/50176]	Loss: 1.6363
Training Epoch: 12 [6144/50176]	Loss: 1.7137
Training Epoch: 12 [7168/50176]	Loss: 1.7581
Training Epoch: 12 [8192/50176]	Loss: 1.6260
Training Epoch: 12 [9216/50176]	Loss: 1.7246
Training Epoch: 12 [10240/50176]	Loss: 1.7249
Training Epoch: 12 [11264/50176]	Loss: 1.8198
Training Epoch: 12 [12288/50176]	Loss: 1.6882
Training Epoch: 12 [13312/50176]	Loss: 1.6673
Training Epoch: 12 [14336/50176]	Loss: 1.7350
Training Epoch: 12 [15360/50176]	Loss: 1.6175
Training Epoch: 12 [16384/50176]	Loss: 1.6883
Training Epoch: 12 [17408/50176]	Loss: 1.6214
Training Epoch: 12 [18432/50176]	Loss: 1.7076
Training Epoch: 12 [19456/50176]	Loss: 1.6820
Training Epoch: 12 [20480/50176]	Loss: 1.6877
Training Epoch: 12 [21504/50176]	Loss: 1.7931
Training Epoch: 12 [22528/50176]	Loss: 1.6430
Training Epoch: 12 [23552/50176]	Loss: 1.7003
Training Epoch: 12 [24576/50176]	Loss: 1.6050
Training Epoch: 12 [25600/50176]	Loss: 1.7295
Training Epoch: 12 [26624/50176]	Loss: 1.7602
Training Epoch: 12 [27648/50176]	Loss: 1.6269
Training Epoch: 12 [28672/50176]	Loss: 1.7737
Training Epoch: 12 [29696/50176]	Loss: 1.6752
Training Epoch: 12 [30720/50176]	Loss: 1.6335
Training Epoch: 12 [31744/50176]	Loss: 1.6777
Training Epoch: 12 [32768/50176]	Loss: 1.7315
Training Epoch: 12 [33792/50176]	Loss: 1.6640
Training Epoch: 12 [34816/50176]	Loss: 1.6467
Training Epoch: 12 [35840/50176]	Loss: 1.6319
Training Epoch: 12 [36864/50176]	Loss: 1.6707
Training Epoch: 12 [37888/50176]	Loss: 1.7616
Training Epoch: 12 [38912/50176]	Loss: 1.6161
Training Epoch: 12 [39936/50176]	Loss: 1.7295
Training Epoch: 12 [40960/50176]	Loss: 1.5701
Training Epoch: 12 [41984/50176]	Loss: 1.7874
Training Epoch: 12 [43008/50176]	Loss: 1.6958
Training Epoch: 12 [44032/50176]	Loss: 1.7678
Training Epoch: 12 [45056/50176]	Loss: 1.6195
Training Epoch: 12 [46080/50176]	Loss: 1.7296
Training Epoch: 12 [47104/50176]	Loss: 1.6429
Training Epoch: 12 [48128/50176]	Loss: 1.6430
Training Epoch: 12 [49152/50176]	Loss: 1.6839
Training Epoch: 12 [50176/50176]	Loss: 1.6051
2022-12-08 23:20:44.062 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:20:44,076 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.74 energy=515.92
2022-12-08 18:20:44,077 [ZeusDataLoader(train)] Up to epoch 13: time=721.68, energy=100088.63, cost=113191.45
2022-12-08 18:20:44,077 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:20:44,077 [ZeusDataLoader(train)] Expected next epoch: time=768.78, energy=107317.17, cost=120926.72
2022-12-08 18:20:44,078 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0019, Accuracy: 0.4737
2022-12-08 18:20:44,329 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:20:44,330 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:20:44.331 [ZeusMonitor] Monitor started.
2022-12-08 23:20:44.332 [ZeusMonitor] Running indefinitely. 2022-12-08 23:20:44.332 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:20:44.332 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e14+gpu0.power.log
2022-12-08 18:21:28,284 [ZeusDataLoader(train)] train epoch 14 done: time=44.20 energy=6712.96
2022-12-08 18:21:28,287 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.5402
Training Epoch: 13 [2048/50176]	Loss: 1.6090
Training Epoch: 13 [3072/50176]	Loss: 1.6366
Training Epoch: 13 [4096/50176]	Loss: 1.5218
Training Epoch: 13 [5120/50176]	Loss: 1.5847
Training Epoch: 13 [6144/50176]	Loss: 1.6343
Training Epoch: 13 [7168/50176]	Loss: 1.5537
Training Epoch: 13 [8192/50176]	Loss: 1.5785
Training Epoch: 13 [9216/50176]	Loss: 1.5678
Training Epoch: 13 [10240/50176]	Loss: 1.7477
Training Epoch: 13 [11264/50176]	Loss: 1.5592
Training Epoch: 13 [12288/50176]	Loss: 1.6109
Training Epoch: 13 [13312/50176]	Loss: 1.6290
Training Epoch: 13 [14336/50176]	Loss: 1.5885
Training Epoch: 13 [15360/50176]	Loss: 1.5893
Training Epoch: 13 [16384/50176]	Loss: 1.6398
Training Epoch: 13 [17408/50176]	Loss: 1.6165
Training Epoch: 13 [18432/50176]	Loss: 1.5550
Training Epoch: 13 [19456/50176]	Loss: 1.6398
Training Epoch: 13 [20480/50176]	Loss: 1.5720
Training Epoch: 13 [21504/50176]	Loss: 1.6004
Training Epoch: 13 [22528/50176]	Loss: 1.5607
Training Epoch: 13 [23552/50176]	Loss: 1.6442
Training Epoch: 13 [24576/50176]	Loss: 1.5893
Training Epoch: 13 [25600/50176]	Loss: 1.5983
Training Epoch: 13 [26624/50176]	Loss: 1.7210
Training Epoch: 13 [27648/50176]	Loss: 1.5777
Training Epoch: 13 [28672/50176]	Loss: 1.5949
Training Epoch: 13 [29696/50176]	Loss: 1.5590
Training Epoch: 13 [30720/50176]	Loss: 1.5908
Training Epoch: 13 [31744/50176]	Loss: 1.6348
Training Epoch: 13 [32768/50176]	Loss: 1.5453
Training Epoch: 13 [33792/50176]	Loss: 1.6524
Training Epoch: 13 [34816/50176]	Loss: 1.7301
Training Epoch: 13 [35840/50176]	Loss: 1.7333
Training Epoch: 13 [36864/50176]	Loss: 1.6605
Training Epoch: 13 [37888/50176]	Loss: 1.6529
Training Epoch: 13 [38912/50176]	Loss: 1.5301
Training Epoch: 13 [39936/50176]	Loss: 1.5353
Training Epoch: 13 [40960/50176]	Loss: 1.6524
Training Epoch: 13 [41984/50176]	Loss: 1.6303
Training Epoch: 13 [43008/50176]	Loss: 1.5395
Training Epoch: 13 [44032/50176]	Loss: 1.6446
Training Epoch: 13 [45056/50176]	Loss: 1.5847
Training Epoch: 13 [46080/50176]	Loss: 1.5257
Training Epoch: 13 [47104/50176]	Loss: 1.6156
Training Epoch: 13 [48128/50176]	Loss: 1.6361
Training Epoch: 13 [49152/50176]	Loss: 1.5238
Training Epoch: 13 [50176/50176]	Loss: 1.7254
2022-12-08 23:21:32.096 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:21:32,133 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.84 energy=528.83
2022-12-08 18:21:32,133 [ZeusDataLoader(train)] Up to epoch 14: time=769.72, energy=107330.43, cost=121015.31
2022-12-08 18:21:32,134 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:21:32,134 [ZeusDataLoader(train)] Expected next epoch: time=816.81, energy=114558.96, cost=128750.58
2022-12-08 18:21:32,135 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0021, Accuracy: 0.4477
2022-12-08 18:21:32,331 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:21:32,332 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:21:32.336 [ZeusMonitor] Monitor started.
2022-12-08 23:21:32.336 [ZeusMonitor] Running indefinitely. 2022-12-08 23:21:32.336 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:21:32.336 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e15+gpu0.power.log
2022-12-08 18:22:16,333 [ZeusDataLoader(train)] train epoch 15 done: time=44.19 energy=6714.31
2022-12-08 18:22:16,336 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.4710
Training Epoch: 14 [2048/50176]	Loss: 1.6056
Training Epoch: 14 [3072/50176]	Loss: 1.5887
Training Epoch: 14 [4096/50176]	Loss: 1.6088
Training Epoch: 14 [5120/50176]	Loss: 1.4989
Training Epoch: 14 [6144/50176]	Loss: 1.4614
Training Epoch: 14 [7168/50176]	Loss: 1.4049
Training Epoch: 14 [8192/50176]	Loss: 1.5149
Training Epoch: 14 [9216/50176]	Loss: 1.4437
Training Epoch: 14 [10240/50176]	Loss: 1.4773
Training Epoch: 14 [11264/50176]	Loss: 1.4659
Training Epoch: 14 [12288/50176]	Loss: 1.5047
Training Epoch: 14 [13312/50176]	Loss: 1.4987
Training Epoch: 14 [14336/50176]	Loss: 1.4581
Training Epoch: 14 [15360/50176]	Loss: 1.5341
Training Epoch: 14 [16384/50176]	Loss: 1.4157
Training Epoch: 14 [17408/50176]	Loss: 1.5684
Training Epoch: 14 [18432/50176]	Loss: 1.4984
Training Epoch: 14 [19456/50176]	Loss: 1.4817
Training Epoch: 14 [20480/50176]	Loss: 1.5201
Training Epoch: 14 [21504/50176]	Loss: 1.5709
Training Epoch: 14 [22528/50176]	Loss: 1.4734
Training Epoch: 14 [23552/50176]	Loss: 1.5320
Training Epoch: 14 [24576/50176]	Loss: 1.5449
Training Epoch: 14 [25600/50176]	Loss: 1.5981
Training Epoch: 14 [26624/50176]	Loss: 1.4647
Training Epoch: 14 [27648/50176]	Loss: 1.4498
Training Epoch: 14 [28672/50176]	Loss: 1.6448
Training Epoch: 14 [29696/50176]	Loss: 1.5464
Training Epoch: 14 [30720/50176]	Loss: 1.5289
Training Epoch: 14 [31744/50176]	Loss: 1.5139
Training Epoch: 14 [32768/50176]	Loss: 1.6369
Training Epoch: 14 [33792/50176]	Loss: 1.5947
Training Epoch: 14 [34816/50176]	Loss: 1.5692
Training Epoch: 14 [35840/50176]	Loss: 1.5427
Training Epoch: 14 [36864/50176]	Loss: 1.6012
Training Epoch: 14 [37888/50176]	Loss: 1.5446
Training Epoch: 14 [38912/50176]	Loss: 1.6050
Training Epoch: 14 [39936/50176]	Loss: 1.5245
Training Epoch: 14 [40960/50176]	Loss: 1.5454
Training Epoch: 14 [41984/50176]	Loss: 1.6784
Training Epoch: 14 [43008/50176]	Loss: 1.6119
Training Epoch: 14 [44032/50176]	Loss: 1.5101
Training Epoch: 14 [45056/50176]	Loss: 1.6011
Training Epoch: 14 [46080/50176]	Loss: 1.4852
Training Epoch: 14 [47104/50176]	Loss: 1.4894
Training Epoch: 14 [48128/50176]	Loss: 1.5306
Training Epoch: 14 [49152/50176]	Loss: 1.5236
Training Epoch: 14 [50176/50176]	Loss: 1.5649
2022-12-08 23:22:20.074 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:22:20,108 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.76 energy=514.59
2022-12-08 18:22:20,108 [ZeusDataLoader(train)] Up to epoch 15: time=817.67, energy=114559.33, cost=128825.60
2022-12-08 18:22:20,108 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:22:20,108 [ZeusDataLoader(train)] Expected next epoch: time=864.77, energy=121787.86, cost=136560.87
2022-12-08 18:22:20,109 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.5086
2022-12-08 18:22:20,360 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:22:20,361 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:22:20.363 [ZeusMonitor] Monitor started.
2022-12-08 23:22:20.363 [ZeusMonitor] Running indefinitely. 2022-12-08 23:22:20.363 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:22:20.363 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e16+gpu0.power.log
2022-12-08 18:23:04,352 [ZeusDataLoader(train)] train epoch 16 done: time=44.23 energy=6703.85
2022-12-08 18:23:04,356 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.5137
Training Epoch: 15 [2048/50176]	Loss: 1.4187
Training Epoch: 15 [3072/50176]	Loss: 1.4570
Training Epoch: 15 [4096/50176]	Loss: 1.4401
Training Epoch: 15 [5120/50176]	Loss: 1.4134
Training Epoch: 15 [6144/50176]	Loss: 1.4649
Training Epoch: 15 [7168/50176]	Loss: 1.3837
Training Epoch: 15 [8192/50176]	Loss: 1.4733
Training Epoch: 15 [9216/50176]	Loss: 1.4307
Training Epoch: 15 [10240/50176]	Loss: 1.4402
Training Epoch: 15 [11264/50176]	Loss: 1.4109
Training Epoch: 15 [12288/50176]	Loss: 1.5212
Training Epoch: 15 [13312/50176]	Loss: 1.3629
Training Epoch: 15 [14336/50176]	Loss: 1.4543
Training Epoch: 15 [15360/50176]	Loss: 1.4954
Training Epoch: 15 [16384/50176]	Loss: 1.5082
Training Epoch: 15 [17408/50176]	Loss: 1.4825
Training Epoch: 15 [18432/50176]	Loss: 1.5122
Training Epoch: 15 [19456/50176]	Loss: 1.4350
Training Epoch: 15 [20480/50176]	Loss: 1.4351
Training Epoch: 15 [21504/50176]	Loss: 1.3732
Training Epoch: 15 [22528/50176]	Loss: 1.5392
Training Epoch: 15 [23552/50176]	Loss: 1.4729
Training Epoch: 15 [24576/50176]	Loss: 1.3722
Training Epoch: 15 [25600/50176]	Loss: 1.4863
Training Epoch: 15 [26624/50176]	Loss: 1.4505
Training Epoch: 15 [27648/50176]	Loss: 1.5367
Training Epoch: 15 [28672/50176]	Loss: 1.3788
Training Epoch: 15 [29696/50176]	Loss: 1.4421
Training Epoch: 15 [30720/50176]	Loss: 1.4614
Training Epoch: 15 [31744/50176]	Loss: 1.4676
Training Epoch: 15 [32768/50176]	Loss: 1.4383
Training Epoch: 15 [33792/50176]	Loss: 1.3840
Training Epoch: 15 [34816/50176]	Loss: 1.5259
Training Epoch: 15 [35840/50176]	Loss: 1.4561
Training Epoch: 15 [36864/50176]	Loss: 1.3569
Training Epoch: 15 [37888/50176]	Loss: 1.4536
Training Epoch: 15 [38912/50176]	Loss: 1.4094
Training Epoch: 15 [39936/50176]	Loss: 1.4288
Training Epoch: 15 [40960/50176]	Loss: 1.5065
Training Epoch: 15 [41984/50176]	Loss: 1.4783
Training Epoch: 15 [43008/50176]	Loss: 1.4996
Training Epoch: 15 [44032/50176]	Loss: 1.4196
Training Epoch: 15 [45056/50176]	Loss: 1.3836
Training Epoch: 15 [46080/50176]	Loss: 1.4462
Training Epoch: 15 [47104/50176]	Loss: 1.4229
Training Epoch: 15 [48128/50176]	Loss: 1.5177
Training Epoch: 15 [49152/50176]	Loss: 1.3811
Training Epoch: 15 [50176/50176]	Loss: 1.4491
2022-12-08 23:23:08.092 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:23:08,133 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.77 energy=516.05
2022-12-08 18:23:08,133 [ZeusDataLoader(train)] Up to epoch 16: time=865.67, energy=121779.23, cost=136635.70
2022-12-08 18:23:08,133 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:23:08,133 [ZeusDataLoader(train)] Expected next epoch: time=912.77, energy=129007.76, cost=144370.97
2022-12-08 18:23:08,134 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0018, Accuracy: 0.4923
2022-12-08 18:23:08,387 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:23:08,388 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:23:08.390 [ZeusMonitor] Monitor started.
2022-12-08 23:23:08.390 [ZeusMonitor] Running indefinitely. 2022-12-08 23:23:08.390 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:23:08.390 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e17+gpu0.power.log
2022-12-08 18:23:52,389 [ZeusDataLoader(train)] train epoch 17 done: time=44.25 energy=6703.73
2022-12-08 18:23:52,394 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.3829
Training Epoch: 16 [2048/50176]	Loss: 1.3727
Training Epoch: 16 [3072/50176]	Loss: 1.3746
Training Epoch: 16 [4096/50176]	Loss: 1.3755
Training Epoch: 16 [5120/50176]	Loss: 1.3469
Training Epoch: 16 [6144/50176]	Loss: 1.3620
Training Epoch: 16 [7168/50176]	Loss: 1.3099
Training Epoch: 16 [8192/50176]	Loss: 1.3105
Training Epoch: 16 [9216/50176]	Loss: 1.3569
Training Epoch: 16 [10240/50176]	Loss: 1.3142
Training Epoch: 16 [11264/50176]	Loss: 1.3991
Training Epoch: 16 [12288/50176]	Loss: 1.3501
Training Epoch: 16 [13312/50176]	Loss: 1.3481
Training Epoch: 16 [14336/50176]	Loss: 1.3767
Training Epoch: 16 [15360/50176]	Loss: 1.4085
Training Epoch: 16 [16384/50176]	Loss: 1.3310
Training Epoch: 16 [17408/50176]	Loss: 1.3407
Training Epoch: 16 [18432/50176]	Loss: 1.4450
Training Epoch: 16 [19456/50176]	Loss: 1.4184
Training Epoch: 16 [20480/50176]	Loss: 1.3258
Training Epoch: 16 [21504/50176]	Loss: 1.3513
Training Epoch: 16 [22528/50176]	Loss: 1.3712
Training Epoch: 16 [23552/50176]	Loss: 1.3848
Training Epoch: 16 [24576/50176]	Loss: 1.3759
Training Epoch: 16 [25600/50176]	Loss: 1.3512
Training Epoch: 16 [26624/50176]	Loss: 1.3420
Training Epoch: 16 [27648/50176]	Loss: 1.4185
Training Epoch: 16 [28672/50176]	Loss: 1.5205
Training Epoch: 16 [29696/50176]	Loss: 1.3331
Training Epoch: 16 [30720/50176]	Loss: 1.3605
Training Epoch: 16 [31744/50176]	Loss: 1.4001
Training Epoch: 16 [32768/50176]	Loss: 1.4440
Training Epoch: 16 [33792/50176]	Loss: 1.3820
Training Epoch: 16 [34816/50176]	Loss: 1.3782
Training Epoch: 16 [35840/50176]	Loss: 1.3739
Training Epoch: 16 [36864/50176]	Loss: 1.4246
Training Epoch: 16 [37888/50176]	Loss: 1.3467
Training Epoch: 16 [38912/50176]	Loss: 1.3812
Training Epoch: 16 [39936/50176]	Loss: 1.4733
Training Epoch: 16 [40960/50176]	Loss: 1.4265
Training Epoch: 16 [41984/50176]	Loss: 1.4367
Training Epoch: 16 [43008/50176]	Loss: 1.3827
Training Epoch: 16 [44032/50176]	Loss: 1.4664
Training Epoch: 16 [45056/50176]	Loss: 1.5165
Training Epoch: 16 [46080/50176]	Loss: 1.4406
Training Epoch: 16 [47104/50176]	Loss: 1.4298
Training Epoch: 16 [48128/50176]	Loss: 1.4765
Training Epoch: 16 [49152/50176]	Loss: 1.5111
Training Epoch: 16 [50176/50176]	Loss: 1.4212
2022-12-08 23:23:56.200 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:23:56,235 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.83 energy=533.87
2022-12-08 18:23:56,235 [ZeusDataLoader(train)] Up to epoch 17: time=913.75, energy=129016.82, cost=144461.33
2022-12-08 18:23:56,235 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:23:56,235 [ZeusDataLoader(train)] Expected next epoch: time=960.84, energy=136245.36, cost=152196.61
2022-12-08 18:23:56,237 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0032, Accuracy: 0.4532
2022-12-08 18:23:56,485 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:23:56,486 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:23:56.488 [ZeusMonitor] Monitor started.
2022-12-08 23:23:56.488 [ZeusMonitor] Running indefinitely. 2022-12-08 23:23:56.488 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:23:56.488 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e18+gpu0.power.log
2022-12-08 18:24:40,482 [ZeusDataLoader(train)] train epoch 18 done: time=44.24 energy=6720.60
2022-12-08 18:24:40,485 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.3685
Training Epoch: 17 [2048/50176]	Loss: 1.3111
Training Epoch: 17 [3072/50176]	Loss: 1.2084
Training Epoch: 17 [4096/50176]	Loss: 1.2997
Training Epoch: 17 [5120/50176]	Loss: 1.3899
Training Epoch: 17 [6144/50176]	Loss: 1.2943
Training Epoch: 17 [7168/50176]	Loss: 1.3131
Training Epoch: 17 [8192/50176]	Loss: 1.3011
Training Epoch: 17 [9216/50176]	Loss: 1.3419
Training Epoch: 17 [10240/50176]	Loss: 1.2964
Training Epoch: 17 [11264/50176]	Loss: 1.3073
Training Epoch: 17 [12288/50176]	Loss: 1.2594
Training Epoch: 17 [13312/50176]	Loss: 1.3424
Training Epoch: 17 [14336/50176]	Loss: 1.3594
Training Epoch: 17 [15360/50176]	Loss: 1.3403
Training Epoch: 17 [16384/50176]	Loss: 1.2620
Training Epoch: 17 [17408/50176]	Loss: 1.3620
Training Epoch: 17 [18432/50176]	Loss: 1.4265
Training Epoch: 17 [19456/50176]	Loss: 1.2698
Training Epoch: 17 [20480/50176]	Loss: 1.3118
Training Epoch: 17 [21504/50176]	Loss: 1.3313
Training Epoch: 17 [22528/50176]	Loss: 1.4192
Training Epoch: 17 [23552/50176]	Loss: 1.3523
Training Epoch: 17 [24576/50176]	Loss: 1.3813
Training Epoch: 17 [25600/50176]	Loss: 1.3430
Training Epoch: 17 [26624/50176]	Loss: 1.3189
Training Epoch: 17 [27648/50176]	Loss: 1.3022
Training Epoch: 17 [28672/50176]	Loss: 1.3629
Training Epoch: 17 [29696/50176]	Loss: 1.3729
Training Epoch: 17 [30720/50176]	Loss: 1.4270
Training Epoch: 17 [31744/50176]	Loss: 1.2944
Training Epoch: 17 [32768/50176]	Loss: 1.2893
Training Epoch: 17 [33792/50176]	Loss: 1.3679
Training Epoch: 17 [34816/50176]	Loss: 1.3366
Training Epoch: 17 [35840/50176]	Loss: 1.2517
Training Epoch: 17 [36864/50176]	Loss: 1.4350
Training Epoch: 17 [37888/50176]	Loss: 1.2913
Training Epoch: 17 [38912/50176]	Loss: 1.3887
Training Epoch: 17 [39936/50176]	Loss: 1.3562
Training Epoch: 17 [40960/50176]	Loss: 1.3146
Training Epoch: 17 [41984/50176]	Loss: 1.3926
Training Epoch: 17 [43008/50176]	Loss: 1.3504
Training Epoch: 17 [44032/50176]	Loss: 1.3754
Training Epoch: 17 [45056/50176]	Loss: 1.3365
Training Epoch: 17 [46080/50176]	Loss: 1.2416
Training Epoch: 17 [47104/50176]	Loss: 1.2572
Training Epoch: 17 [48128/50176]	Loss: 1.3679
Training Epoch: 17 [49152/50176]	Loss: 1.3440
Training Epoch: 17 [50176/50176]	Loss: 1.3826
2022-12-08 23:24:44.236 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:24:44,257 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.76 energy=519.29
2022-12-08 18:24:44,257 [ZeusDataLoader(train)] Up to epoch 18: time=961.75, energy=136256.71, cost=152281.25
2022-12-08 18:24:44,257 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:24:44,257 [ZeusDataLoader(train)] Expected next epoch: time=1008.84, energy=143485.25, cost=160016.53
2022-12-08 18:24:44,258 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0017, Accuracy: 0.5319
2022-12-08 18:24:44,511 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:24:44,512 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:24:44.514 [ZeusMonitor] Monitor started.
2022-12-08 23:24:44.514 [ZeusMonitor] Running indefinitely. 2022-12-08 23:24:44.514 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:24:44.514 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e19+gpu0.power.log
2022-12-08 18:25:28,460 [ZeusDataLoader(train)] train epoch 19 done: time=44.19 energy=6717.53
2022-12-08 18:25:28,464 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.1889
Training Epoch: 18 [2048/50176]	Loss: 1.2925
Training Epoch: 18 [3072/50176]	Loss: 1.2309
Training Epoch: 18 [4096/50176]	Loss: 1.1878
Training Epoch: 18 [5120/50176]	Loss: 1.2441
Training Epoch: 18 [6144/50176]	Loss: 1.2276
Training Epoch: 18 [7168/50176]	Loss: 1.1850
Training Epoch: 18 [8192/50176]	Loss: 1.2926
Training Epoch: 18 [9216/50176]	Loss: 1.2028
Training Epoch: 18 [10240/50176]	Loss: 1.1899
Training Epoch: 18 [11264/50176]	Loss: 1.2283
Training Epoch: 18 [12288/50176]	Loss: 1.1892
Training Epoch: 18 [13312/50176]	Loss: 1.3064
Training Epoch: 18 [14336/50176]	Loss: 1.2690
Training Epoch: 18 [15360/50176]	Loss: 1.3195
Training Epoch: 18 [16384/50176]	Loss: 1.2324
Training Epoch: 18 [17408/50176]	Loss: 1.2993
Training Epoch: 18 [18432/50176]	Loss: 1.2916
Training Epoch: 18 [19456/50176]	Loss: 1.2831
Training Epoch: 18 [20480/50176]	Loss: 1.2399
Training Epoch: 18 [21504/50176]	Loss: 1.3231
Training Epoch: 18 [22528/50176]	Loss: 1.3235
Training Epoch: 18 [23552/50176]	Loss: 1.1846
Training Epoch: 18 [24576/50176]	Loss: 1.2362
Training Epoch: 18 [25600/50176]	Loss: 1.2337
Training Epoch: 18 [26624/50176]	Loss: 1.1847
Training Epoch: 18 [27648/50176]	Loss: 1.2899
Training Epoch: 18 [28672/50176]	Loss: 1.3014
Training Epoch: 18 [29696/50176]	Loss: 1.2424
Training Epoch: 18 [30720/50176]	Loss: 1.3264
Training Epoch: 18 [31744/50176]	Loss: 1.3273
Training Epoch: 18 [32768/50176]	Loss: 1.2749
Training Epoch: 18 [33792/50176]	Loss: 1.3157
Training Epoch: 18 [34816/50176]	Loss: 1.2132
Training Epoch: 18 [35840/50176]	Loss: 1.3504
Training Epoch: 18 [36864/50176]	Loss: 1.2826
Training Epoch: 18 [37888/50176]	Loss: 1.2562
Training Epoch: 18 [38912/50176]	Loss: 1.2790
Training Epoch: 18 [39936/50176]	Loss: 1.3318
Training Epoch: 18 [40960/50176]	Loss: 1.2538
Training Epoch: 18 [41984/50176]	Loss: 1.2811
Training Epoch: 18 [43008/50176]	Loss: 1.3035
Training Epoch: 18 [44032/50176]	Loss: 1.2592
Training Epoch: 18 [45056/50176]	Loss: 1.2775
Training Epoch: 18 [46080/50176]	Loss: 1.3020
Training Epoch: 18 [47104/50176]	Loss: 1.2901
Training Epoch: 18 [48128/50176]	Loss: 1.2994
Training Epoch: 18 [49152/50176]	Loss: 1.2637
Training Epoch: 18 [50176/50176]	Loss: 1.3814
2022-12-08 23:25:32.182 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:25:32,199 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.73 energy=518.09
2022-12-08 18:25:32,200 [ZeusDataLoader(train)] Up to epoch 19: time=1009.67, energy=143492.33, cost=160092.07
2022-12-08 18:25:32,200 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:25:32,200 [ZeusDataLoader(train)] Expected next epoch: time=1056.76, energy=150720.86, cost=167827.35
2022-12-08 18:25:32,201 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0016, Accuracy: 0.5491
2022-12-08 18:25:32,447 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:25:32,448 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:25:32.450 [ZeusMonitor] Monitor started.
2022-12-08 23:25:32.450 [ZeusMonitor] Running indefinitely. 2022-12-08 23:25:32.450 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:25:32.450 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e20+gpu0.power.log
2022-12-08 18:26:16,459 [ZeusDataLoader(train)] train epoch 20 done: time=44.25 energy=6727.79
2022-12-08 18:26:16,463 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.1715
Training Epoch: 19 [2048/50176]	Loss: 1.1955
Training Epoch: 19 [3072/50176]	Loss: 1.1416
Training Epoch: 19 [4096/50176]	Loss: 1.1964
Training Epoch: 19 [5120/50176]	Loss: 1.1962
Training Epoch: 19 [6144/50176]	Loss: 1.1959
Training Epoch: 19 [7168/50176]	Loss: 1.1766
Training Epoch: 19 [8192/50176]	Loss: 1.1714
Training Epoch: 19 [9216/50176]	Loss: 1.2208
Training Epoch: 19 [10240/50176]	Loss: 1.2073
Training Epoch: 19 [11264/50176]	Loss: 1.1918
Training Epoch: 19 [12288/50176]	Loss: 1.1954
Training Epoch: 19 [13312/50176]	Loss: 1.1794
Training Epoch: 19 [14336/50176]	Loss: 1.2507
Training Epoch: 19 [15360/50176]	Loss: 1.2142
Training Epoch: 19 [16384/50176]	Loss: 1.1854
Training Epoch: 19 [17408/50176]	Loss: 1.2420
Training Epoch: 19 [18432/50176]	Loss: 1.2854
Training Epoch: 19 [19456/50176]	Loss: 1.1476
Training Epoch: 19 [20480/50176]	Loss: 1.2338
Training Epoch: 19 [21504/50176]	Loss: 1.1502
Training Epoch: 19 [22528/50176]	Loss: 1.3113
Training Epoch: 19 [23552/50176]	Loss: 1.2972
Training Epoch: 19 [24576/50176]	Loss: 1.1755
Training Epoch: 19 [25600/50176]	Loss: 1.2171
Training Epoch: 19 [26624/50176]	Loss: 1.2495
Training Epoch: 19 [27648/50176]	Loss: 1.1472
Training Epoch: 19 [28672/50176]	Loss: 1.1825
Training Epoch: 19 [29696/50176]	Loss: 1.2565
Training Epoch: 19 [30720/50176]	Loss: 1.2068
Training Epoch: 19 [31744/50176]	Loss: 1.2014
Training Epoch: 19 [32768/50176]	Loss: 1.2707
Training Epoch: 19 [33792/50176]	Loss: 1.2199
Training Epoch: 19 [34816/50176]	Loss: 1.1742
Training Epoch: 19 [35840/50176]	Loss: 1.2095
Training Epoch: 19 [36864/50176]	Loss: 1.2641
Training Epoch: 19 [37888/50176]	Loss: 1.1940
Training Epoch: 19 [38912/50176]	Loss: 1.2884
Training Epoch: 19 [39936/50176]	Loss: 1.1262
Training Epoch: 19 [40960/50176]	Loss: 1.1104
Training Epoch: 19 [41984/50176]	Loss: 1.2817
Training Epoch: 19 [43008/50176]	Loss: 1.2484
Training Epoch: 19 [44032/50176]	Loss: 1.2219
Training Epoch: 19 [45056/50176]	Loss: 1.2204
Training Epoch: 19 [46080/50176]	Loss: 1.1588
Training Epoch: 19 [47104/50176]	Loss: 1.2262
Training Epoch: 19 [48128/50176]	Loss: 1.1285
Training Epoch: 19 [49152/50176]	Loss: 1.2746
Training Epoch: 19 [50176/50176]	Loss: 1.1510
2022-12-08 23:26:20.189 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:26:20,210 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.74 energy=518.41
2022-12-08 18:26:20,210 [ZeusDataLoader(train)] Up to epoch 20: time=1057.66, energy=150738.52, cost=167914.14
2022-12-08 18:26:20,210 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:26:20,211 [ZeusDataLoader(train)] Expected next epoch: time=1104.75, energy=157967.06, cost=175649.41
2022-12-08 18:26:20,212 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0016, Accuracy: 0.5526
2022-12-08 18:26:20,408 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:26:20,409 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:26:20.413 [ZeusMonitor] Monitor started.
2022-12-08 23:26:20.413 [ZeusMonitor] Running indefinitely. 2022-12-08 23:26:20.413 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:26:20.413 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e21+gpu0.power.log
2022-12-08 18:27:04,398 [ZeusDataLoader(train)] train epoch 21 done: time=44.18 energy=6707.45
2022-12-08 18:27:04,402 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0998
Training Epoch: 20 [2048/50176]	Loss: 1.1220
Training Epoch: 20 [3072/50176]	Loss: 1.1688
Training Epoch: 20 [4096/50176]	Loss: 1.0611
Training Epoch: 20 [5120/50176]	Loss: 1.1181
Training Epoch: 20 [6144/50176]	Loss: 1.1594
Training Epoch: 20 [7168/50176]	Loss: 1.0994
Training Epoch: 20 [8192/50176]	Loss: 1.0903
Training Epoch: 20 [9216/50176]	Loss: 1.0740
Training Epoch: 20 [10240/50176]	Loss: 1.0639
Training Epoch: 20 [11264/50176]	Loss: 1.1258
Training Epoch: 20 [12288/50176]	Loss: 1.1242
Training Epoch: 20 [13312/50176]	Loss: 1.0960
Training Epoch: 20 [14336/50176]	Loss: 1.1549
Training Epoch: 20 [15360/50176]	Loss: 1.1272
Training Epoch: 20 [16384/50176]	Loss: 1.2066
Training Epoch: 20 [17408/50176]	Loss: 1.1320
Training Epoch: 20 [18432/50176]	Loss: 1.1106
Training Epoch: 20 [19456/50176]	Loss: 1.1719
Training Epoch: 20 [20480/50176]	Loss: 1.0846
Training Epoch: 20 [21504/50176]	Loss: 1.1689
Training Epoch: 20 [22528/50176]	Loss: 1.1204
Training Epoch: 20 [23552/50176]	Loss: 1.0896
Training Epoch: 20 [24576/50176]	Loss: 1.1575
Training Epoch: 20 [25600/50176]	Loss: 1.1953
Training Epoch: 20 [26624/50176]	Loss: 1.1878
Training Epoch: 20 [27648/50176]	Loss: 1.1288
Training Epoch: 20 [28672/50176]	Loss: 1.2274
Training Epoch: 20 [29696/50176]	Loss: 1.1119
Training Epoch: 20 [30720/50176]	Loss: 1.1530
Training Epoch: 20 [31744/50176]	Loss: 1.1391
Training Epoch: 20 [32768/50176]	Loss: 1.1588
Training Epoch: 20 [33792/50176]	Loss: 1.1200
Training Epoch: 20 [34816/50176]	Loss: 1.2031
Training Epoch: 20 [35840/50176]	Loss: 1.1357
Training Epoch: 20 [36864/50176]	Loss: 1.1615
Training Epoch: 20 [37888/50176]	Loss: 1.1715
Training Epoch: 20 [38912/50176]	Loss: 1.1768
Training Epoch: 20 [39936/50176]	Loss: 1.1642
Training Epoch: 20 [40960/50176]	Loss: 1.1816
Training Epoch: 20 [41984/50176]	Loss: 1.1708
Training Epoch: 20 [43008/50176]	Loss: 1.1120
Training Epoch: 20 [44032/50176]	Loss: 1.1006
Training Epoch: 20 [45056/50176]	Loss: 1.1856
Training Epoch: 20 [46080/50176]	Loss: 1.1331
Training Epoch: 20 [47104/50176]	Loss: 1.1782
Training Epoch: 20 [48128/50176]	Loss: 1.1579
Training Epoch: 20 [49152/50176]	Loss: 1.1821
Training Epoch: 20 [50176/50176]	Loss: 1.1945
2022-12-08 23:27:08.198 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:27:08,224 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.81 energy=536.23
2022-12-08 18:27:08,224 [ZeusDataLoader(train)] Up to epoch 21: time=1105.65, energy=157982.20, cost=175735.14
2022-12-08 18:27:08,224 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:27:08,224 [ZeusDataLoader(train)] Expected next epoch: time=1152.74, energy=165210.73, cost=183470.42
2022-12-08 18:27:08,225 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0016, Accuracy: 0.5452
2022-12-08 18:27:08,421 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:27:08,422 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:27:08.423 [ZeusMonitor] Monitor started.
2022-12-08 23:27:08.424 [ZeusMonitor] Running indefinitely. 2022-12-08 23:27:08.424 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:27:08.424 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e22+gpu0.power.log
2022-12-08 18:27:52,440 [ZeusDataLoader(train)] train epoch 22 done: time=44.21 energy=6723.28
2022-12-08 18:27:52,443 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0559
Training Epoch: 21 [2048/50176]	Loss: 1.0197
Training Epoch: 21 [3072/50176]	Loss: 1.0901
Training Epoch: 21 [4096/50176]	Loss: 1.0913
Training Epoch: 21 [5120/50176]	Loss: 1.0501
Training Epoch: 21 [6144/50176]	Loss: 1.0072
Training Epoch: 21 [7168/50176]	Loss: 0.9879
Training Epoch: 21 [8192/50176]	Loss: 1.0568
Training Epoch: 21 [9216/50176]	Loss: 1.0941
Training Epoch: 21 [10240/50176]	Loss: 1.0718
Training Epoch: 21 [11264/50176]	Loss: 1.0576
Training Epoch: 21 [12288/50176]	Loss: 1.0560
Training Epoch: 21 [13312/50176]	Loss: 1.0636
Training Epoch: 21 [14336/50176]	Loss: 1.1856
Training Epoch: 21 [15360/50176]	Loss: 1.0276
Training Epoch: 21 [16384/50176]	Loss: 1.1028
Training Epoch: 21 [17408/50176]	Loss: 1.0437
Training Epoch: 21 [18432/50176]	Loss: 1.0348
Training Epoch: 21 [19456/50176]	Loss: 1.1073
Training Epoch: 21 [20480/50176]	Loss: 1.0547
Training Epoch: 21 [21504/50176]	Loss: 1.0771
Training Epoch: 21 [22528/50176]	Loss: 1.1770
Training Epoch: 21 [23552/50176]	Loss: 1.1599
Training Epoch: 21 [24576/50176]	Loss: 1.0686
Training Epoch: 21 [25600/50176]	Loss: 1.1068
Training Epoch: 21 [26624/50176]	Loss: 1.1474
Training Epoch: 21 [27648/50176]	Loss: 1.0923
Training Epoch: 21 [28672/50176]	Loss: 1.0766
Training Epoch: 21 [29696/50176]	Loss: 1.1460
Training Epoch: 21 [30720/50176]	Loss: 1.0776
Training Epoch: 21 [31744/50176]	Loss: 1.1391
Training Epoch: 21 [32768/50176]	Loss: 1.0970
Training Epoch: 21 [33792/50176]	Loss: 1.0759
Training Epoch: 21 [34816/50176]	Loss: 1.0285
Training Epoch: 21 [35840/50176]	Loss: 1.0987
Training Epoch: 21 [36864/50176]	Loss: 1.0460
Training Epoch: 21 [37888/50176]	Loss: 1.1689
Training Epoch: 21 [38912/50176]	Loss: 1.1306
Training Epoch: 21 [39936/50176]	Loss: 1.1655
Training Epoch: 21 [40960/50176]	Loss: 1.0732
Training Epoch: 21 [41984/50176]	Loss: 1.1072
Training Epoch: 21 [43008/50176]	Loss: 1.1419
Training Epoch: 21 [44032/50176]	Loss: 1.1607
Training Epoch: 21 [45056/50176]	Loss: 1.1260
Training Epoch: 21 [46080/50176]	Loss: 1.1032
Training Epoch: 21 [47104/50176]	Loss: 1.1719
Training Epoch: 21 [48128/50176]	Loss: 1.1231
Training Epoch: 21 [49152/50176]	Loss: 1.1338
Training Epoch: 21 [50176/50176]	Loss: 1.1316
2022-12-08 23:27:56.215 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:27:56,266 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=536.90
2022-12-08 18:27:56,266 [ZeusDataLoader(train)] Up to epoch 22: time=1153.67, energy=165242.38, cost=183566.99
2022-12-08 18:27:56,266 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:27:56,266 [ZeusDataLoader(train)] Expected next epoch: time=1200.76, energy=172470.91, cost=191302.26
2022-12-08 18:27:56,267 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0016, Accuracy: 0.5561
2022-12-08 18:27:56,519 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:27:56,520 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:27:56.522 [ZeusMonitor] Monitor started.
2022-12-08 23:27:56.522 [ZeusMonitor] Running indefinitely. 2022-12-08 23:27:56.522 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:27:56.522 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e23+gpu0.power.log
2022-12-08 18:28:40,516 [ZeusDataLoader(train)] train epoch 23 done: time=44.24 energy=6717.32
2022-12-08 18:28:40,519 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.0633
Training Epoch: 22 [2048/50176]	Loss: 1.0092
Training Epoch: 22 [3072/50176]	Loss: 0.9406
Training Epoch: 22 [4096/50176]	Loss: 0.9376
Training Epoch: 22 [5120/50176]	Loss: 1.0290
Training Epoch: 22 [6144/50176]	Loss: 1.0038
Training Epoch: 22 [7168/50176]	Loss: 1.0857
Training Epoch: 22 [8192/50176]	Loss: 1.0740
Training Epoch: 22 [9216/50176]	Loss: 1.0129
Training Epoch: 22 [10240/50176]	Loss: 0.9714
Training Epoch: 22 [11264/50176]	Loss: 1.0666
Training Epoch: 22 [12288/50176]	Loss: 1.0581
Training Epoch: 22 [13312/50176]	Loss: 0.9151
Training Epoch: 22 [14336/50176]	Loss: 1.0213
Training Epoch: 22 [15360/50176]	Loss: 0.9825
Training Epoch: 22 [16384/50176]	Loss: 1.0421
Training Epoch: 22 [17408/50176]	Loss: 0.9792
Training Epoch: 22 [18432/50176]	Loss: 1.0131
Training Epoch: 22 [19456/50176]	Loss: 1.0282
Training Epoch: 22 [20480/50176]	Loss: 1.0950
Training Epoch: 22 [21504/50176]	Loss: 1.0387
Training Epoch: 22 [22528/50176]	Loss: 1.0846
Training Epoch: 22 [23552/50176]	Loss: 1.0805
Training Epoch: 22 [24576/50176]	Loss: 1.0482
Training Epoch: 22 [25600/50176]	Loss: 1.0715
Training Epoch: 22 [26624/50176]	Loss: 1.0872
Training Epoch: 22 [27648/50176]	Loss: 1.0502
Training Epoch: 22 [28672/50176]	Loss: 1.0784
Training Epoch: 22 [29696/50176]	Loss: 1.0879
Training Epoch: 22 [30720/50176]	Loss: 1.0422
Training Epoch: 22 [31744/50176]	Loss: 1.1841
Training Epoch: 22 [32768/50176]	Loss: 1.0809
Training Epoch: 22 [33792/50176]	Loss: 1.0891
Training Epoch: 22 [34816/50176]	Loss: 1.0655
Training Epoch: 22 [35840/50176]	Loss: 1.0631
Training Epoch: 22 [36864/50176]	Loss: 1.0491
Training Epoch: 22 [37888/50176]	Loss: 1.0557
Training Epoch: 22 [38912/50176]	Loss: 1.0295
Training Epoch: 22 [39936/50176]	Loss: 1.0863
Training Epoch: 22 [40960/50176]	Loss: 1.1186
Training Epoch: 22 [41984/50176]	Loss: 1.1167
Training Epoch: 22 [43008/50176]	Loss: 1.0335
Training Epoch: 22 [44032/50176]	Loss: 1.0411
Training Epoch: 22 [45056/50176]	Loss: 1.0800
Training Epoch: 22 [46080/50176]	Loss: 1.0322
Training Epoch: 22 [47104/50176]	Loss: 1.0356
Training Epoch: 22 [48128/50176]	Loss: 1.1731
Training Epoch: 22 [49152/50176]	Loss: 1.1423
Training Epoch: 22 [50176/50176]	Loss: 1.0119
2022-12-08 23:28:44.279 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:28:44,306 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.78 energy=514.84
2022-12-08 18:28:44,306 [ZeusDataLoader(train)] Up to epoch 23: time=1201.68, energy=172474.53, cost=191384.61
2022-12-08 18:28:44,307 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:28:44,307 [ZeusDataLoader(train)] Expected next epoch: time=1248.78, energy=179703.06, cost=199119.89
2022-12-08 18:28:44,308 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0016, Accuracy: 0.5632
2022-12-08 18:28:44,511 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:28:44,512 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:28:44.516 [ZeusMonitor] Monitor started.
2022-12-08 23:28:44.516 [ZeusMonitor] Running indefinitely. 2022-12-08 23:28:44.516 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:28:44.516 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e24+gpu0.power.log
2022-12-08 18:29:28,659 [ZeusDataLoader(train)] train epoch 24 done: time=44.34 energy=6724.62
2022-12-08 18:29:28,663 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.0036
Training Epoch: 23 [2048/50176]	Loss: 0.9785
Training Epoch: 23 [3072/50176]	Loss: 0.9732
Training Epoch: 23 [4096/50176]	Loss: 0.9778
Training Epoch: 23 [5120/50176]	Loss: 0.9390
Training Epoch: 23 [6144/50176]	Loss: 1.0341
Training Epoch: 23 [7168/50176]	Loss: 1.0045
Training Epoch: 23 [8192/50176]	Loss: 0.9558
Training Epoch: 23 [9216/50176]	Loss: 0.9666
Training Epoch: 23 [10240/50176]	Loss: 0.9542
Training Epoch: 23 [11264/50176]	Loss: 1.0056
Training Epoch: 23 [12288/50176]	Loss: 0.9394
Training Epoch: 23 [13312/50176]	Loss: 1.0193
Training Epoch: 23 [14336/50176]	Loss: 1.0132
Training Epoch: 23 [15360/50176]	Loss: 0.9250
Training Epoch: 23 [16384/50176]	Loss: 1.0045
Training Epoch: 23 [17408/50176]	Loss: 1.0194
Training Epoch: 23 [18432/50176]	Loss: 0.9341
Training Epoch: 23 [19456/50176]	Loss: 0.9510
Training Epoch: 23 [20480/50176]	Loss: 0.9650
Training Epoch: 23 [21504/50176]	Loss: 1.0005
Training Epoch: 23 [22528/50176]	Loss: 1.0048
Training Epoch: 23 [23552/50176]	Loss: 0.9273
Training Epoch: 23 [24576/50176]	Loss: 0.9937
Training Epoch: 23 [25600/50176]	Loss: 1.0208
Training Epoch: 23 [26624/50176]	Loss: 0.9999
Training Epoch: 23 [27648/50176]	Loss: 0.9637
Training Epoch: 23 [28672/50176]	Loss: 1.0067
Training Epoch: 23 [29696/50176]	Loss: 1.0010
Training Epoch: 23 [30720/50176]	Loss: 1.0656
Training Epoch: 23 [31744/50176]	Loss: 1.0540
Training Epoch: 23 [32768/50176]	Loss: 1.0531
Training Epoch: 23 [33792/50176]	Loss: 1.0009
Training Epoch: 23 [34816/50176]	Loss: 1.1028
Training Epoch: 23 [35840/50176]	Loss: 1.0295
Training Epoch: 23 [36864/50176]	Loss: 1.0026
Training Epoch: 23 [37888/50176]	Loss: 1.0275
Training Epoch: 23 [38912/50176]	Loss: 1.0483
Training Epoch: 23 [39936/50176]	Loss: 1.0614
Training Epoch: 23 [40960/50176]	Loss: 1.0751
Training Epoch: 23 [41984/50176]	Loss: 1.0493
Training Epoch: 23 [43008/50176]	Loss: 1.0065
Training Epoch: 23 [44032/50176]	Loss: 1.0379
Training Epoch: 23 [45056/50176]	Loss: 1.0387
Training Epoch: 23 [46080/50176]	Loss: 1.0955
Training Epoch: 23 [47104/50176]	Loss: 1.0628
Training Epoch: 23 [48128/50176]	Loss: 1.0234
Training Epoch: 23 [49152/50176]	Loss: 1.0257
Training Epoch: 23 [50176/50176]	Loss: 1.0298
2022-12-08 23:29:32.468 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:29:32,488 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.82 energy=531.95
2022-12-08 18:29:32,488 [ZeusDataLoader(train)] Up to epoch 24: time=1249.84, energy=179731.10, cost=199226.88
2022-12-08 18:29:32,488 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:29:32,489 [ZeusDataLoader(train)] Expected next epoch: time=1296.94, energy=186959.64, cost=206962.15
2022-12-08 18:29:32,490 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0016, Accuracy: 0.5713
2022-12-08 18:29:32,730 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:29:32,731 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:29:32.745 [ZeusMonitor] Monitor started.
2022-12-08 23:29:32.745 [ZeusMonitor] Running indefinitely. 2022-12-08 23:29:32.745 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:29:32.745 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e25+gpu0.power.log
2022-12-08 18:30:16,679 [ZeusDataLoader(train)] train epoch 25 done: time=44.18 energy=6718.63
2022-12-08 18:30:16,682 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8451
Training Epoch: 24 [2048/50176]	Loss: 0.8425
Training Epoch: 24 [3072/50176]	Loss: 0.9493
Training Epoch: 24 [4096/50176]	Loss: 0.9203
Training Epoch: 24 [5120/50176]	Loss: 0.8884
Training Epoch: 24 [6144/50176]	Loss: 0.8860
Training Epoch: 24 [7168/50176]	Loss: 0.9105
Training Epoch: 24 [8192/50176]	Loss: 0.9179
Training Epoch: 24 [9216/50176]	Loss: 0.9254
Training Epoch: 24 [10240/50176]	Loss: 0.9322
Training Epoch: 24 [11264/50176]	Loss: 0.9004
Training Epoch: 24 [12288/50176]	Loss: 0.8929
Training Epoch: 24 [13312/50176]	Loss: 0.9039
Training Epoch: 24 [14336/50176]	Loss: 0.9494
Training Epoch: 24 [15360/50176]	Loss: 0.8999
Training Epoch: 24 [16384/50176]	Loss: 0.8710
Training Epoch: 24 [17408/50176]	Loss: 1.0060
Training Epoch: 24 [18432/50176]	Loss: 0.9572
Training Epoch: 24 [19456/50176]	Loss: 0.9888
Training Epoch: 24 [20480/50176]	Loss: 0.9675
Training Epoch: 24 [21504/50176]	Loss: 0.9379
Training Epoch: 24 [22528/50176]	Loss: 0.9325
Training Epoch: 24 [23552/50176]	Loss: 0.9858
Training Epoch: 24 [24576/50176]	Loss: 0.8611
Training Epoch: 24 [25600/50176]	Loss: 0.9389
Training Epoch: 24 [26624/50176]	Loss: 0.9479
Training Epoch: 24 [27648/50176]	Loss: 1.0122
Training Epoch: 24 [28672/50176]	Loss: 0.9612
Training Epoch: 24 [29696/50176]	Loss: 0.9192
Training Epoch: 24 [30720/50176]	Loss: 0.9737
Training Epoch: 24 [31744/50176]	Loss: 1.0017
Training Epoch: 24 [32768/50176]	Loss: 0.9812
Training Epoch: 24 [33792/50176]	Loss: 0.9667
Training Epoch: 24 [34816/50176]	Loss: 1.0322
Training Epoch: 24 [35840/50176]	Loss: 1.0250
Training Epoch: 24 [36864/50176]	Loss: 0.9934
Training Epoch: 24 [37888/50176]	Loss: 0.9459
Training Epoch: 24 [38912/50176]	Loss: 0.9972
Training Epoch: 24 [39936/50176]	Loss: 0.9482
Training Epoch: 24 [40960/50176]	Loss: 0.9909
Training Epoch: 24 [41984/50176]	Loss: 1.0001
Training Epoch: 24 [43008/50176]	Loss: 1.0395
Training Epoch: 24 [44032/50176]	Loss: 0.8801
Training Epoch: 24 [45056/50176]	Loss: 0.9416
Training Epoch: 24 [46080/50176]	Loss: 1.0039
Training Epoch: 24 [47104/50176]	Loss: 1.0539
Training Epoch: 24 [48128/50176]	Loss: 1.1512
Training Epoch: 24 [49152/50176]	Loss: 0.9916
Training Epoch: 24 [50176/50176]	Loss: 0.9652
2022-12-08 23:30:20.428 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:30:20,452 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.76 energy=516.29
2022-12-08 18:30:20,453 [ZeusDataLoader(train)] Up to epoch 25: time=1297.79, energy=186966.02, cost=207039.31
2022-12-08 18:30:20,453 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:30:20,453 [ZeusDataLoader(train)] Expected next epoch: time=1344.88, energy=194194.55, cost=214774.58
2022-12-08 18:30:20,454 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0016, Accuracy: 0.5779
2022-12-08 18:30:20,698 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:30:20,699 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:30:20.701 [ZeusMonitor] Monitor started.
2022-12-08 23:30:20.701 [ZeusMonitor] Running indefinitely. 2022-12-08 23:30:20.701 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:30:20.701 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e26+gpu0.power.log
2022-12-08 18:31:04,686 [ZeusDataLoader(train)] train epoch 26 done: time=44.22 energy=6720.59
2022-12-08 18:31:04,689 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.8258
Training Epoch: 25 [2048/50176]	Loss: 0.8273
Training Epoch: 25 [3072/50176]	Loss: 0.8548
Training Epoch: 25 [4096/50176]	Loss: 0.8547
Training Epoch: 25 [5120/50176]	Loss: 0.8593
Training Epoch: 25 [6144/50176]	Loss: 0.8920
Training Epoch: 25 [7168/50176]	Loss: 0.8788
Training Epoch: 25 [8192/50176]	Loss: 0.9181
Training Epoch: 25 [9216/50176]	Loss: 0.9429
Training Epoch: 25 [10240/50176]	Loss: 0.8561
Training Epoch: 25 [11264/50176]	Loss: 0.9496
Training Epoch: 25 [12288/50176]	Loss: 0.8845
Training Epoch: 25 [13312/50176]	Loss: 0.8537
Training Epoch: 25 [14336/50176]	Loss: 0.8786
Training Epoch: 25 [15360/50176]	Loss: 0.8942
Training Epoch: 25 [16384/50176]	Loss: 0.9432
Training Epoch: 25 [17408/50176]	Loss: 0.9121
Training Epoch: 25 [18432/50176]	Loss: 0.9474
Training Epoch: 25 [19456/50176]	Loss: 0.8750
Training Epoch: 25 [20480/50176]	Loss: 0.8645
Training Epoch: 25 [21504/50176]	Loss: 0.8572
Training Epoch: 25 [22528/50176]	Loss: 0.9356
Training Epoch: 25 [23552/50176]	Loss: 0.8713
Training Epoch: 25 [24576/50176]	Loss: 0.9101
Training Epoch: 25 [25600/50176]	Loss: 0.8621
Training Epoch: 25 [26624/50176]	Loss: 0.9133
Training Epoch: 25 [27648/50176]	Loss: 0.9095
Training Epoch: 25 [28672/50176]	Loss: 0.9507
Training Epoch: 25 [29696/50176]	Loss: 0.9293
Training Epoch: 25 [30720/50176]	Loss: 0.9686
Training Epoch: 25 [31744/50176]	Loss: 0.9190
Training Epoch: 25 [32768/50176]	Loss: 0.9280
Training Epoch: 25 [33792/50176]	Loss: 0.8353
Training Epoch: 25 [34816/50176]	Loss: 0.8750
Training Epoch: 25 [35840/50176]	Loss: 0.9310
Training Epoch: 25 [36864/50176]	Loss: 0.9478
Training Epoch: 25 [37888/50176]	Loss: 0.9293
Training Epoch: 25 [38912/50176]	Loss: 0.9039
Training Epoch: 25 [39936/50176]	Loss: 0.9424
Training Epoch: 25 [40960/50176]	Loss: 0.9277
Training Epoch: 25 [41984/50176]	Loss: 0.9570
Training Epoch: 25 [43008/50176]	Loss: 1.0006
Training Epoch: 25 [44032/50176]	Loss: 0.9556
Training Epoch: 25 [45056/50176]	Loss: 0.9979
Training Epoch: 25 [46080/50176]	Loss: 0.9919
Training Epoch: 25 [47104/50176]	Loss: 1.0245
Training Epoch: 25 [48128/50176]	Loss: 1.0250
Training Epoch: 25 [49152/50176]	Loss: 0.9738
Training Epoch: 25 [50176/50176]	Loss: 0.9377
2022-12-08 23:31:08.471 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:31:08,527 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.83 energy=532.40
2022-12-08 18:31:08,527 [ZeusDataLoader(train)] Up to epoch 26: time=1345.84, energy=194219.01, cost=214870.38
2022-12-08 18:31:08,527 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:31:08,528 [ZeusDataLoader(train)] Expected next epoch: time=1392.94, energy=201447.55, cost=222605.66
2022-12-08 18:31:08,529 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0017, Accuracy: 0.5499
2022-12-08 18:31:08,765 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:31:08,766 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:31:08.792 [ZeusMonitor] Monitor started.
2022-12-08 23:31:08.792 [ZeusMonitor] Running indefinitely. 2022-12-08 23:31:08.792 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:31:08.792 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e27+gpu0.power.log
2022-12-08 18:31:52,715 [ZeusDataLoader(train)] train epoch 27 done: time=44.18 energy=6729.51
2022-12-08 18:31:52,719 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.7741
Training Epoch: 26 [2048/50176]	Loss: 0.8593
Training Epoch: 26 [3072/50176]	Loss: 0.8596
Training Epoch: 26 [4096/50176]	Loss: 0.8295
Training Epoch: 26 [5120/50176]	Loss: 0.8540
Training Epoch: 26 [6144/50176]	Loss: 0.8068
Training Epoch: 26 [7168/50176]	Loss: 0.8110
Training Epoch: 26 [8192/50176]	Loss: 0.8737
Training Epoch: 26 [9216/50176]	Loss: 0.8559
Training Epoch: 26 [10240/50176]	Loss: 0.8216
Training Epoch: 26 [11264/50176]	Loss: 0.8200
Training Epoch: 26 [12288/50176]	Loss: 0.8736
Training Epoch: 26 [13312/50176]	Loss: 0.8287
Training Epoch: 26 [14336/50176]	Loss: 0.8207
Training Epoch: 26 [15360/50176]	Loss: 0.8062
Training Epoch: 26 [16384/50176]	Loss: 0.7984
Training Epoch: 26 [17408/50176]	Loss: 0.8264
Training Epoch: 26 [18432/50176]	Loss: 0.8571
Training Epoch: 26 [19456/50176]	Loss: 0.8645
Training Epoch: 26 [20480/50176]	Loss: 0.8088
Training Epoch: 26 [21504/50176]	Loss: 0.8198
Training Epoch: 26 [22528/50176]	Loss: 0.7940
Training Epoch: 26 [23552/50176]	Loss: 0.8642
Training Epoch: 26 [24576/50176]	Loss: 0.8615
Training Epoch: 26 [25600/50176]	Loss: 0.8813
Training Epoch: 26 [26624/50176]	Loss: 0.9000
Training Epoch: 26 [27648/50176]	Loss: 0.9112
Training Epoch: 26 [28672/50176]	Loss: 0.8421
Training Epoch: 26 [29696/50176]	Loss: 0.8741
Training Epoch: 26 [30720/50176]	Loss: 0.9845
Training Epoch: 26 [31744/50176]	Loss: 0.9001
Training Epoch: 26 [32768/50176]	Loss: 0.8766
Training Epoch: 26 [33792/50176]	Loss: 0.9292
Training Epoch: 26 [34816/50176]	Loss: 0.9069
Training Epoch: 26 [35840/50176]	Loss: 0.9055
Training Epoch: 26 [36864/50176]	Loss: 0.8586
Training Epoch: 26 [37888/50176]	Loss: 0.8726
Training Epoch: 26 [38912/50176]	Loss: 0.8954
Training Epoch: 26 [39936/50176]	Loss: 0.9505
Training Epoch: 26 [40960/50176]	Loss: 0.9103
Training Epoch: 26 [41984/50176]	Loss: 0.9089
Training Epoch: 26 [43008/50176]	Loss: 0.9431
Training Epoch: 26 [44032/50176]	Loss: 0.9695
Training Epoch: 26 [45056/50176]	Loss: 0.8740
Training Epoch: 26 [46080/50176]	Loss: 0.9192
Training Epoch: 26 [47104/50176]	Loss: 0.9496
Training Epoch: 26 [48128/50176]	Loss: 0.9492
Training Epoch: 26 [49152/50176]	Loss: 0.9183
Training Epoch: 26 [50176/50176]	Loss: 0.9176
2022-12-08 23:31:56.481 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:31:56,500 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.77 energy=512.65
2022-12-08 18:31:56,501 [ZeusDataLoader(train)] Up to epoch 27: time=1393.79, energy=201461.16, cost=222687.18
2022-12-08 18:31:56,501 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:31:56,501 [ZeusDataLoader(train)] Expected next epoch: time=1440.89, energy=208689.70, cost=230422.45
2022-12-08 18:31:56,502 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0016, Accuracy: 0.5767
2022-12-08 18:31:56,750 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:31:56,751 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:31:56.753 [ZeusMonitor] Monitor started.
2022-12-08 23:31:56.753 [ZeusMonitor] Running indefinitely. 2022-12-08 23:31:56.753 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:31:56.753 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e28+gpu0.power.log
2022-12-08 18:32:40,693 [ZeusDataLoader(train)] train epoch 28 done: time=44.18 energy=6703.28
2022-12-08 18:32:40,696 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7894
Training Epoch: 27 [2048/50176]	Loss: 0.8153
Training Epoch: 27 [3072/50176]	Loss: 0.7717
Training Epoch: 27 [4096/50176]	Loss: 0.8233
Training Epoch: 27 [5120/50176]	Loss: 0.7839
Training Epoch: 27 [6144/50176]	Loss: 0.8122
Training Epoch: 27 [7168/50176]	Loss: 0.7517
Training Epoch: 27 [8192/50176]	Loss: 0.7743
Training Epoch: 27 [9216/50176]	Loss: 0.8376
Training Epoch: 27 [10240/50176]	Loss: 0.7816
Training Epoch: 27 [11264/50176]	Loss: 0.7798
Training Epoch: 27 [12288/50176]	Loss: 0.8090
Training Epoch: 27 [13312/50176]	Loss: 0.7904
Training Epoch: 27 [14336/50176]	Loss: 0.7483
Training Epoch: 27 [15360/50176]	Loss: 0.7750
Training Epoch: 27 [16384/50176]	Loss: 0.7957
Training Epoch: 27 [17408/50176]	Loss: 0.8000
Training Epoch: 27 [18432/50176]	Loss: 0.8731
Training Epoch: 27 [19456/50176]	Loss: 0.7991
Training Epoch: 27 [20480/50176]	Loss: 0.7624
Training Epoch: 27 [21504/50176]	Loss: 0.8290
Training Epoch: 27 [22528/50176]	Loss: 0.7755
Training Epoch: 27 [23552/50176]	Loss: 0.7612
Training Epoch: 27 [24576/50176]	Loss: 0.7643
Training Epoch: 27 [25600/50176]	Loss: 0.8216
Training Epoch: 27 [26624/50176]	Loss: 0.8562
Training Epoch: 27 [27648/50176]	Loss: 0.8371
Training Epoch: 27 [28672/50176]	Loss: 0.8442
Training Epoch: 27 [29696/50176]	Loss: 0.8332
Training Epoch: 27 [30720/50176]	Loss: 0.8333
Training Epoch: 27 [31744/50176]	Loss: 0.8869
Training Epoch: 27 [32768/50176]	Loss: 0.8436
Training Epoch: 27 [33792/50176]	Loss: 0.8247
Training Epoch: 27 [34816/50176]	Loss: 0.9483
Training Epoch: 27 [35840/50176]	Loss: 0.9124
Training Epoch: 27 [36864/50176]	Loss: 0.8171
Training Epoch: 27 [37888/50176]	Loss: 0.8784
Training Epoch: 27 [38912/50176]	Loss: 0.8274
Training Epoch: 27 [39936/50176]	Loss: 0.8596
Training Epoch: 27 [40960/50176]	Loss: 0.8919
Training Epoch: 27 [41984/50176]	Loss: 0.8737
Training Epoch: 27 [43008/50176]	Loss: 0.8877
Training Epoch: 27 [44032/50176]	Loss: 0.8472
Training Epoch: 27 [45056/50176]	Loss: 0.8820
Training Epoch: 27 [46080/50176]	Loss: 0.8935
Training Epoch: 27 [47104/50176]	Loss: 0.9179
Training Epoch: 27 [48128/50176]	Loss: 0.8848
Training Epoch: 27 [49152/50176]	Loss: 0.8892
Training Epoch: 27 [50176/50176]	Loss: 0.9412
2022-12-08 23:32:44.471 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:32:44,489 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.78 energy=527.85
2022-12-08 18:32:44,489 [ZeusDataLoader(train)] Up to epoch 28: time=1441.76, energy=208692.29, cost=230499.81
2022-12-08 18:32:44,489 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:32:44,489 [ZeusDataLoader(train)] Expected next epoch: time=1488.85, energy=215920.83, cost=238235.08
2022-12-08 18:32:44,490 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0016, Accuracy: 0.5699
2022-12-08 18:32:44,736 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:32:44,737 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:32:44.741 [ZeusMonitor] Monitor started.
2022-12-08 23:32:44.741 [ZeusMonitor] Running indefinitely. 2022-12-08 23:32:44.741 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:32:44.741 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e29+gpu0.power.log
2022-12-08 18:33:28,704 [ZeusDataLoader(train)] train epoch 29 done: time=44.20 energy=6706.18
2022-12-08 18:33:28,707 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.7053
Training Epoch: 28 [2048/50176]	Loss: 0.8133
Training Epoch: 28 [3072/50176]	Loss: 0.7245
Training Epoch: 28 [4096/50176]	Loss: 0.7801
Training Epoch: 28 [5120/50176]	Loss: 0.7486
Training Epoch: 28 [6144/50176]	Loss: 0.7086
Training Epoch: 28 [7168/50176]	Loss: 0.7070
Training Epoch: 28 [8192/50176]	Loss: 0.7495
Training Epoch: 28 [9216/50176]	Loss: 0.7371
Training Epoch: 28 [10240/50176]	Loss: 0.7334
Training Epoch: 28 [11264/50176]	Loss: 0.7714
Training Epoch: 28 [12288/50176]	Loss: 0.7715
Training Epoch: 28 [13312/50176]	Loss: 0.7303
Training Epoch: 28 [14336/50176]	Loss: 0.8140
Training Epoch: 28 [15360/50176]	Loss: 0.7436
Training Epoch: 28 [16384/50176]	Loss: 0.8232
Training Epoch: 28 [17408/50176]	Loss: 0.7817
Training Epoch: 28 [18432/50176]	Loss: 0.7159
Training Epoch: 28 [19456/50176]	Loss: 0.7875
Training Epoch: 28 [20480/50176]	Loss: 0.7439
Training Epoch: 28 [21504/50176]	Loss: 0.7854
Training Epoch: 28 [22528/50176]	Loss: 0.8277
Training Epoch: 28 [23552/50176]	Loss: 0.8260
Training Epoch: 28 [24576/50176]	Loss: 0.7431
Training Epoch: 28 [25600/50176]	Loss: 0.8104
Training Epoch: 28 [26624/50176]	Loss: 0.7518
Training Epoch: 28 [27648/50176]	Loss: 0.8357
Training Epoch: 28 [28672/50176]	Loss: 0.7892
Training Epoch: 28 [29696/50176]	Loss: 0.7954
Training Epoch: 28 [30720/50176]	Loss: 0.8439
Training Epoch: 28 [31744/50176]	Loss: 0.8560
Training Epoch: 28 [32768/50176]	Loss: 0.7970
Training Epoch: 28 [33792/50176]	Loss: 0.7899
Training Epoch: 28 [34816/50176]	Loss: 0.7808
Training Epoch: 28 [35840/50176]	Loss: 0.8111
Training Epoch: 28 [36864/50176]	Loss: 0.8586
Training Epoch: 28 [37888/50176]	Loss: 0.8250
Training Epoch: 28 [38912/50176]	Loss: 0.8328
Training Epoch: 28 [39936/50176]	Loss: 0.8043
Training Epoch: 28 [40960/50176]	Loss: 0.8626
Training Epoch: 28 [41984/50176]	Loss: 0.8385
Training Epoch: 28 [43008/50176]	Loss: 0.8200
Training Epoch: 28 [44032/50176]	Loss: 0.7987
Training Epoch: 28 [45056/50176]	Loss: 0.9697
Training Epoch: 28 [46080/50176]	Loss: 0.7956
Training Epoch: 28 [47104/50176]	Loss: 0.8247
Training Epoch: 28 [48128/50176]	Loss: 0.8116
Training Epoch: 28 [49152/50176]	Loss: 0.8626
Training Epoch: 28 [50176/50176]	Loss: 0.8319
2022-12-08 23:33:32.477 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:33:32,528 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.81 energy=529.92
2022-12-08 18:33:32,529 [ZeusDataLoader(train)] Up to epoch 29: time=1489.77, energy=215928.39, cost=238319.38
2022-12-08 18:33:32,529 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:33:32,529 [ZeusDataLoader(train)] Expected next epoch: time=1536.87, energy=223156.92, cost=246054.66
2022-12-08 18:33:32,530 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0016, Accuracy: 0.5844
2022-12-08 18:33:32,763 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:33:32,764 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:33:32.766 [ZeusMonitor] Monitor started.
2022-12-08 23:33:32.766 [ZeusMonitor] Running indefinitely. 2022-12-08 23:33:32.766 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:33:32.766 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e30+gpu0.power.log
2022-12-08 18:34:16,762 [ZeusDataLoader(train)] train epoch 30 done: time=44.22 energy=6728.36
2022-12-08 18:34:16,765 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6746
Training Epoch: 29 [2048/50176]	Loss: 0.6836
Training Epoch: 29 [3072/50176]	Loss: 0.7028
Training Epoch: 29 [4096/50176]	Loss: 0.7141
Training Epoch: 29 [5120/50176]	Loss: 0.7727
Training Epoch: 29 [6144/50176]	Loss: 0.7334
Training Epoch: 29 [7168/50176]	Loss: 0.7050
Training Epoch: 29 [8192/50176]	Loss: 0.6721
Training Epoch: 29 [9216/50176]	Loss: 0.7528
Training Epoch: 29 [10240/50176]	Loss: 0.6615
Training Epoch: 29 [11264/50176]	Loss: 0.7679
Training Epoch: 29 [12288/50176]	Loss: 0.7998
Training Epoch: 29 [13312/50176]	Loss: 0.6241
Training Epoch: 29 [14336/50176]	Loss: 0.7017
Training Epoch: 29 [15360/50176]	Loss: 0.8013
Training Epoch: 29 [16384/50176]	Loss: 0.7113
Training Epoch: 29 [17408/50176]	Loss: 0.8021
Training Epoch: 29 [18432/50176]	Loss: 0.7138
Training Epoch: 29 [19456/50176]	Loss: 0.8065
Training Epoch: 29 [20480/50176]	Loss: 0.7380
Training Epoch: 29 [21504/50176]	Loss: 0.7199
Training Epoch: 29 [22528/50176]	Loss: 0.6394
Training Epoch: 29 [23552/50176]	Loss: 0.6963
Training Epoch: 29 [24576/50176]	Loss: 0.7795
Training Epoch: 29 [25600/50176]	Loss: 0.7429
Training Epoch: 29 [26624/50176]	Loss: 0.7289
Training Epoch: 29 [27648/50176]	Loss: 0.7660
Training Epoch: 29 [28672/50176]	Loss: 0.6889
Training Epoch: 29 [29696/50176]	Loss: 0.6856
Training Epoch: 29 [30720/50176]	Loss: 0.7805
Training Epoch: 29 [31744/50176]	Loss: 0.7666
Training Epoch: 29 [32768/50176]	Loss: 0.8201
Training Epoch: 29 [33792/50176]	Loss: 0.7881
Training Epoch: 29 [34816/50176]	Loss: 0.7830
Training Epoch: 29 [35840/50176]	Loss: 0.6835
Training Epoch: 29 [36864/50176]	Loss: 0.7489
Training Epoch: 29 [37888/50176]	Loss: 0.7792
Training Epoch: 29 [38912/50176]	Loss: 0.8252
Training Epoch: 29 [39936/50176]	Loss: 0.7848
Training Epoch: 29 [40960/50176]	Loss: 0.7899
Training Epoch: 29 [41984/50176]	Loss: 0.7571
Training Epoch: 29 [43008/50176]	Loss: 0.8496
Training Epoch: 29 [44032/50176]	Loss: 0.7997
Training Epoch: 29 [45056/50176]	Loss: 0.8143
Training Epoch: 29 [46080/50176]	Loss: 0.8267
Training Epoch: 29 [47104/50176]	Loss: 0.8061
Training Epoch: 29 [48128/50176]	Loss: 0.8557
Training Epoch: 29 [49152/50176]	Loss: 0.8177
Training Epoch: 29 [50176/50176]	Loss: 0.8675
2022-12-08 23:34:20.539 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:34:20,594 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.82 energy=531.97
2022-12-08 18:34:20,594 [ZeusDataLoader(train)] Up to epoch 30: time=1537.82, energy=223188.71, cost=246153.31
2022-12-08 18:34:20,595 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:34:20,595 [ZeusDataLoader(train)] Expected next epoch: time=1584.91, energy=230417.25, cost=253888.58
2022-12-08 18:34:20,596 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0017, Accuracy: 0.5721
2022-12-08 18:34:20,793 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:34:20,794 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:34:20.798 [ZeusMonitor] Monitor started.
2022-12-08 23:34:20.798 [ZeusMonitor] Running indefinitely. 2022-12-08 23:34:20.798 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:34:20.798 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e31+gpu0.power.log
2022-12-08 18:35:04,803 [ZeusDataLoader(train)] train epoch 31 done: time=44.20 energy=6720.44
2022-12-08 18:35:04,806 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7396
Training Epoch: 30 [2048/50176]	Loss: 0.6810
Training Epoch: 30 [3072/50176]	Loss: 0.7531
Training Epoch: 30 [4096/50176]	Loss: 0.7011
Training Epoch: 30 [5120/50176]	Loss: 0.6845
Training Epoch: 30 [6144/50176]	Loss: 0.6594
Training Epoch: 30 [7168/50176]	Loss: 0.6801
Training Epoch: 30 [8192/50176]	Loss: 0.6787
Training Epoch: 30 [9216/50176]	Loss: 0.7142
Training Epoch: 30 [10240/50176]	Loss: 0.6864
Training Epoch: 30 [11264/50176]	Loss: 0.6796
Training Epoch: 30 [12288/50176]	Loss: 0.7169
Training Epoch: 30 [13312/50176]	Loss: 0.6976
Training Epoch: 30 [14336/50176]	Loss: 0.6990
Training Epoch: 30 [15360/50176]	Loss: 0.6764
Training Epoch: 30 [16384/50176]	Loss: 0.6935
Training Epoch: 30 [17408/50176]	Loss: 0.6847
Training Epoch: 30 [18432/50176]	Loss: 0.6516
Training Epoch: 30 [19456/50176]	Loss: 0.6675
Training Epoch: 30 [20480/50176]	Loss: 0.6673
Training Epoch: 30 [21504/50176]	Loss: 0.6675
Training Epoch: 30 [22528/50176]	Loss: 0.6568
Training Epoch: 30 [23552/50176]	Loss: 0.6630
Training Epoch: 30 [24576/50176]	Loss: 0.7299
Training Epoch: 30 [25600/50176]	Loss: 0.7184
Training Epoch: 30 [26624/50176]	Loss: 0.7188
Training Epoch: 30 [27648/50176]	Loss: 0.6966
Training Epoch: 30 [28672/50176]	Loss: 0.7823
Training Epoch: 30 [29696/50176]	Loss: 0.7393
Training Epoch: 30 [30720/50176]	Loss: 0.7195
Training Epoch: 30 [31744/50176]	Loss: 0.6815
Training Epoch: 30 [32768/50176]	Loss: 0.6741
Training Epoch: 30 [33792/50176]	Loss: 0.7123
Training Epoch: 30 [34816/50176]	Loss: 0.7937
Training Epoch: 30 [35840/50176]	Loss: 0.7501
Training Epoch: 30 [36864/50176]	Loss: 0.7073
Training Epoch: 30 [37888/50176]	Loss: 0.7332
Training Epoch: 30 [38912/50176]	Loss: 0.7399
Training Epoch: 30 [39936/50176]	Loss: 0.7052
Training Epoch: 30 [40960/50176]	Loss: 0.7561
Training Epoch: 30 [41984/50176]	Loss: 0.7680
Training Epoch: 30 [43008/50176]	Loss: 0.7958
Training Epoch: 30 [44032/50176]	Loss: 0.7618
Training Epoch: 30 [45056/50176]	Loss: 0.7867
Training Epoch: 30 [46080/50176]	Loss: 0.7333
Training Epoch: 30 [47104/50176]	Loss: 0.7393
Training Epoch: 30 [48128/50176]	Loss: 0.7557
Training Epoch: 30 [49152/50176]	Loss: 0.7709
Training Epoch: 30 [50176/50176]	Loss: 0.8313
2022-12-08 23:35:08.606 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:35:08,640 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.83 energy=537.12
2022-12-08 18:35:08,641 [ZeusDataLoader(train)] Up to epoch 31: time=1585.84, energy=230446.28, cost=253984.17
2022-12-08 18:35:08,641 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:35:08,641 [ZeusDataLoader(train)] Expected next epoch: time=1632.94, energy=237674.81, cost=261719.45
2022-12-08 18:35:08,642 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0017, Accuracy: 0.5860
2022-12-08 18:35:08,843 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:35:08,844 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:35:08.848 [ZeusMonitor] Monitor started.
2022-12-08 23:35:08.848 [ZeusMonitor] Running indefinitely. 2022-12-08 23:35:08.848 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:35:08.848 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e32+gpu0.power.log
2022-12-08 18:35:52,811 [ZeusDataLoader(train)] train epoch 32 done: time=44.16 energy=6709.49
2022-12-08 18:35:52,815 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.6163
Training Epoch: 31 [2048/50176]	Loss: 0.5778
Training Epoch: 31 [3072/50176]	Loss: 0.6654
Training Epoch: 31 [4096/50176]	Loss: 0.5875
Training Epoch: 31 [5120/50176]	Loss: 0.6303
Training Epoch: 31 [6144/50176]	Loss: 0.6175
Training Epoch: 31 [7168/50176]	Loss: 0.6490
Training Epoch: 31 [8192/50176]	Loss: 0.6330
Training Epoch: 31 [9216/50176]	Loss: 0.6253
Training Epoch: 31 [10240/50176]	Loss: 0.6620
Training Epoch: 31 [11264/50176]	Loss: 0.6159
Training Epoch: 31 [12288/50176]	Loss: 0.6411
Training Epoch: 31 [13312/50176]	Loss: 0.6673
Training Epoch: 31 [14336/50176]	Loss: 0.5913
Training Epoch: 31 [15360/50176]	Loss: 0.5906
Training Epoch: 31 [16384/50176]	Loss: 0.6577
Training Epoch: 31 [17408/50176]	Loss: 0.6722
Training Epoch: 31 [18432/50176]	Loss: 0.6743
Training Epoch: 31 [19456/50176]	Loss: 0.6311
Training Epoch: 31 [20480/50176]	Loss: 0.6882
Training Epoch: 31 [21504/50176]	Loss: 0.7393
Training Epoch: 31 [22528/50176]	Loss: 0.6772
Training Epoch: 31 [23552/50176]	Loss: 0.7288
Training Epoch: 31 [24576/50176]	Loss: 0.6380
Training Epoch: 31 [25600/50176]	Loss: 0.6817
Training Epoch: 31 [26624/50176]	Loss: 0.7043
Training Epoch: 31 [27648/50176]	Loss: 0.7160
Training Epoch: 31 [28672/50176]	Loss: 0.6701
Training Epoch: 31 [29696/50176]	Loss: 0.6973
Training Epoch: 31 [30720/50176]	Loss: 0.6233
Training Epoch: 31 [31744/50176]	Loss: 0.7017
Training Epoch: 31 [32768/50176]	Loss: 0.7222
Training Epoch: 31 [33792/50176]	Loss: 0.6566
Training Epoch: 31 [34816/50176]	Loss: 0.7073
Training Epoch: 31 [35840/50176]	Loss: 0.7154
Training Epoch: 31 [36864/50176]	Loss: 0.7359
Training Epoch: 31 [37888/50176]	Loss: 0.7066
Training Epoch: 31 [38912/50176]	Loss: 0.7211
Training Epoch: 31 [39936/50176]	Loss: 0.7921
Training Epoch: 31 [40960/50176]	Loss: 0.7014
Training Epoch: 31 [41984/50176]	Loss: 0.7558
Training Epoch: 31 [43008/50176]	Loss: 0.6461
Training Epoch: 31 [44032/50176]	Loss: 0.6834
Training Epoch: 31 [45056/50176]	Loss: 0.8009
Training Epoch: 31 [46080/50176]	Loss: 0.7484
Training Epoch: 31 [47104/50176]	Loss: 0.6675
Training Epoch: 31 [48128/50176]	Loss: 0.7534
Training Epoch: 31 [49152/50176]	Loss: 0.7324
Training Epoch: 31 [50176/50176]	Loss: 0.7253
2022-12-08 23:35:56.524 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:35:56,544 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.72 energy=515.51
2022-12-08 18:35:56,544 [ZeusDataLoader(train)] Up to epoch 32: time=1633.72, energy=237671.28, cost=261786.23
2022-12-08 18:35:56,544 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=7228.53
2022-12-08 18:35:56,544 [ZeusDataLoader(train)] Expected next epoch: time=1680.82, energy=244899.81, cost=269521.51
2022-12-08 18:35:56,545 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5844
2022-12-08 18:35:56,790 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:35:56,791 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:35:56.793 [ZeusMonitor] Monitor started.
2022-12-08 23:35:56.793 [ZeusMonitor] Running indefinitely. 2022-12-08 23:35:56.793 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:35:56.793 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e33+gpu0.power.log
2022-12-08 18:36:40,766 [ZeusDataLoader(train)] train epoch 33 done: time=44.21 energy=6703.70
2022-12-08 18:36:40,770 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.6052
Training Epoch: 32 [2048/50176]	Loss: 0.5783
Training Epoch: 32 [3072/50176]	Loss: 0.6436
Training Epoch: 32 [4096/50176]	Loss: 0.6197
Training Epoch: 32 [5120/50176]	Loss: 0.6594
Training Epoch: 32 [6144/50176]	Loss: 0.6506
Training Epoch: 32 [7168/50176]	Loss: 0.6393
Training Epoch: 32 [8192/50176]	Loss: 0.6045
Training Epoch: 32 [9216/50176]	Loss: 0.5574
Training Epoch: 32 [10240/50176]	Loss: 0.5598
Training Epoch: 32 [11264/50176]	Loss: 0.6009
Training Epoch: 32 [12288/50176]	Loss: 0.6451
Training Epoch: 32 [13312/50176]	Loss: 0.6041
Training Epoch: 32 [14336/50176]	Loss: 0.6447
Training Epoch: 32 [15360/50176]	Loss: 0.5809
Training Epoch: 32 [16384/50176]	Loss: 0.5692
Training Epoch: 32 [17408/50176]	Loss: 0.6110
Training Epoch: 32 [18432/50176]	Loss: 0.6701
Training Epoch: 32 [19456/50176]	Loss: 0.6077
Training Epoch: 32 [20480/50176]	Loss: 0.6239
Training Epoch: 32 [21504/50176]	Loss: 0.6279
Training Epoch: 32 [22528/50176]	Loss: 0.6614
Training Epoch: 32 [23552/50176]	Loss: 0.6685
Training Epoch: 32 [24576/50176]	Loss: 0.6387
Training Epoch: 32 [25600/50176]	Loss: 0.6688
Training Epoch: 32 [26624/50176]	Loss: 0.5906
Training Epoch: 32 [27648/50176]	Loss: 0.6033
Training Epoch: 32 [28672/50176]	Loss: 0.6142
Training Epoch: 32 [29696/50176]	Loss: 0.6653
Training Epoch: 32 [30720/50176]	Loss: 0.5818
Training Epoch: 32 [31744/50176]	Loss: 0.6754
Training Epoch: 32 [32768/50176]	Loss: 0.6534
Training Epoch: 32 [33792/50176]	Loss: 0.6388
Training Epoch: 32 [34816/50176]	Loss: 0.6821
Training Epoch: 32 [35840/50176]	Loss: 0.6369
Training Epoch: 32 [36864/50176]	Loss: 0.6755
Training Epoch: 32 [37888/50176]	Loss: 0.6065
Training Epoch: 32 [38912/50176]	Loss: 0.6253
Training Epoch: 32 [39936/50176]	Loss: 0.6517
Training Epoch: 32 [40960/50176]	Loss: 0.6239
Training Epoch: 32 [41984/50176]	Loss: 0.6462
Training Epoch: 32 [43008/50176]	Loss: 0.7230
Training Epoch: 32 [44032/50176]	Loss: 0.7354
Training Epoch: 32 [45056/50176]	Loss: 0.6255
Training Epoch: 32 [46080/50176]	Loss: 0.7148
Training Epoch: 32 [47104/50176]	Loss: 0.6668
Training Epoch: 32 [48128/50176]	Loss: 0.6765
Training Epoch: 32 [49152/50176]	Loss: 0.7349
Training Epoch: 32 [50176/50176]	Loss: 0.7004
2022-12-08 23:36:44.536 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:36:44,555 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.78 energy=529.71
2022-12-08 18:36:44,556 [ZeusDataLoader(train)] Up to epoch 33: time=1681.71, energy=244904.69, cost=269602.06
2022-12-08 18:36:44,556 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-08 18:36:44,556 [ZeusDataLoader(train)] Training done.
2022-12-08 18:36:44,556 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec01+try01+bs1024+lr0.0070000.train.json: {"energy": 244904.68639563024, "time": 1681.7110675940203, "cost": 269602.0616122919, "num_epochs": 33, "reached": true}
Validation Epoch: 32, Average loss: 0.0016, Accuracy: 0.6021

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 244904.68639563024, 'time': 1681.7110675940203, 'cost': 269602.0616122919, 'num_epochs': 33, 'reached': True}
[run job; power] power_stats={'job_id': 'rec01+try01', 'train_power': {'175000': 154.93794950427161, '150000': 146.4595246293473, '125000': 122.94562865927668, '100000': 101.85536570738996}, 'train_throughput': {'175000': 1.1325596419460637, '150000': 1.098530462919081, '125000': 0.9677647927574697, '100000': 0.36591614626940633}, 'eval_power': {'175000': 137.03434588938902, '150000': 132.0541042630539, '125000': 112.28836933117594}, 'eval_throughput': {'175000': 2.6093336140479835, '150000': 2.602200455521512, '125000': 2.326169550549045}, 'optimal_pl': 175000}
[Zeus Master] cost=269602.0616122919

[Zeus Master] Reached target metric in 1 try.
[run job] Launching job with BS 1024: and LR: 0.008
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224', 'ZEUS_JOB_ID': 'rec02+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.008']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec02+try01.train.log'
2022-12-08 18:36:49,880 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 18:36:49,881 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 18:36:49,881 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 18:36:49,926 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 18:36:49,926 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 18:36:52,175 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 18:36:52,176 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 18:36:52,424 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:36:52.427 [ZeusMonitor] Monitor started.
2022-12-08 23:36:52.427 [ZeusMonitor] Running indefinitely. 2022-12-08 23:36:52.427 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:36:52.427 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e1+gpu0.power.log
2022-12-08 18:36:53,167 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 18:36:53,167 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 18:37:01,960 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 18:37:35,507 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 18:37:37,173 [ZeusDataLoader(train)] train epoch 1 done: time=44.99 energy=6739.93
2022-12-08 18:37:37,176 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 6.5609
Training Epoch: 0 [3072/50176]	Loss: 5.4589
Training Epoch: 0 [4096/50176]	Loss: 4.8740
Training Epoch: 0 [5120/50176]	Loss: 4.9515
Training Epoch: 0 [6144/50176]	Loss: 4.7686
Training Epoch: 0 [7168/50176]	Loss: 4.7694
Training Epoch: 0 [8192/50176]	Loss: 4.8981
Training Epoch: 0 [9216/50176]	Loss: 5.6788
Training Epoch: 0 [10240/50176]	Loss: 5.1294
Training Epoch: 0 [11264/50176]	Loss: 4.8662
Training Epoch: 0 [12288/50176]	Loss: 4.6394
Training Epoch: 0 [13312/50176]	Loss: 4.7853
Training Epoch: 0 [14336/50176]	Loss: 4.7435
Training Epoch: 0 [15360/50176]	Loss: 4.7046
Training Epoch: 0 [16384/50176]	Loss: 4.7112
Training Epoch: 0 [17408/50176]	Loss: 4.6787
Training Epoch: 0 [18432/50176]	Loss: 4.6695
Training Epoch: 0 [19456/50176]	Loss: 4.6661
Training Epoch: 0 [20480/50176]	Loss: 4.6287
Training Epoch: 0 [21504/50176]	Loss: 4.6132
Training Epoch: 0 [22528/50176]	Loss: 4.6057
Training Epoch: 0 [23552/50176]	Loss: 4.5908
Training Epoch: 0 [24576/50176]	Loss: 4.5807
Training Epoch: 0 [25600/50176]	Loss: 4.5838
Training Epoch: 0 [26624/50176]	Loss: 4.5740
Training Epoch: 0 [27648/50176]	Loss: 4.5796
Training Epoch: 0 [28672/50176]	Loss: 4.5391
Training Epoch: 0 [29696/50176]	Loss: 4.5473
Training Epoch: 0 [30720/50176]	Loss: 4.5346
Training Epoch: 0 [31744/50176]	Loss: 4.5334
Training Epoch: 0 [32768/50176]	Loss: 4.5139
Training Epoch: 0 [33792/50176]	Loss: 4.5023
Training Epoch: 0 [34816/50176]	Loss: 4.4634
Training Epoch: 0 [35840/50176]	Loss: 4.4623
Training Epoch: 0 [36864/50176]	Loss: 4.4515
Training Epoch: 0 [37888/50176]	Loss: 4.4539
Training Epoch: 0 [38912/50176]	Loss: 4.4331
Training Epoch: 0 [39936/50176]	Loss: 4.4583
Training Epoch: 0 [40960/50176]	Loss: 4.4334
Training Epoch: 0 [41984/50176]	Loss: 4.4364
Training Epoch: 0 [43008/50176]	Loss: 4.4188
Training Epoch: 0 [44032/50176]	Loss: 4.4139
Training Epoch: 0 [45056/50176]	Loss: 4.4026
Training Epoch: 0 [46080/50176]	Loss: 4.3715
Training Epoch: 0 [47104/50176]	Loss: 4.3945
Training Epoch: 0 [48128/50176]	Loss: 4.3869
Training Epoch: 0 [49152/50176]	Loss: 4.3907
Training Epoch: 0 [50176/50176]	Loss: 4.3718
2022-12-08 23:37:40.897 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:37:40,908 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.72 energy=515.81
2022-12-08 18:37:40,908 [ZeusDataLoader(train)] Up to epoch 1: time=48.71, energy=7255.75, cost=7890.20
2022-12-08 18:37:40,909 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0043, Accuracy: 0.0254
2022-12-08 18:37:41,157 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:37:41.159 [ZeusMonitor] Monitor started.
2022-12-08 23:37:41.160 [ZeusMonitor] Running indefinitely. 2022-12-08 23:37:41.160 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:37:41.160 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e2+gpu0.power.log
2022-12-08 18:37:41,847 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 18:37:41,847 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 18:37:50,187 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 18:38:24,777 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 18:38:26,497 [ZeusDataLoader(train)] train epoch 2 done: time=45.58 energy=6544.72
2022-12-08 18:38:26,501 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.3727
Training Epoch: 1 [2048/50176]	Loss: 4.3116
Training Epoch: 1 [3072/50176]	Loss: 4.3159
Training Epoch: 1 [4096/50176]	Loss: 4.3315
Training Epoch: 1 [5120/50176]	Loss: 4.3138
Training Epoch: 1 [6144/50176]	Loss: 4.3117
Training Epoch: 1 [7168/50176]	Loss: 4.2865
Training Epoch: 1 [8192/50176]	Loss: 4.2208
Training Epoch: 1 [9216/50176]	Loss: 4.3047
Training Epoch: 1 [10240/50176]	Loss: 4.2650
Training Epoch: 1 [11264/50176]	Loss: 4.2541
Training Epoch: 1 [12288/50176]	Loss: 4.2240
Training Epoch: 1 [13312/50176]	Loss: 4.1624
Training Epoch: 1 [14336/50176]	Loss: 4.2142
Training Epoch: 1 [15360/50176]	Loss: 4.1625
Training Epoch: 1 [16384/50176]	Loss: 4.2214
Training Epoch: 1 [17408/50176]	Loss: 4.1651
Training Epoch: 1 [18432/50176]	Loss: 4.1082
Training Epoch: 1 [19456/50176]	Loss: 4.1620
Training Epoch: 1 [20480/50176]	Loss: 4.1036
Training Epoch: 1 [21504/50176]	Loss: 4.0947
Training Epoch: 1 [22528/50176]	Loss: 4.0633
Training Epoch: 1 [23552/50176]	Loss: 4.0437
Training Epoch: 1 [24576/50176]	Loss: 4.0357
Training Epoch: 1 [25600/50176]	Loss: 4.0500
Training Epoch: 1 [26624/50176]	Loss: 4.0164
Training Epoch: 1 [27648/50176]	Loss: 4.0375
Training Epoch: 1 [28672/50176]	Loss: 3.9834
Training Epoch: 1 [29696/50176]	Loss: 4.0577
Training Epoch: 1 [30720/50176]	Loss: 3.9652
Training Epoch: 1 [31744/50176]	Loss: 3.9846
Training Epoch: 1 [32768/50176]	Loss: 3.9437
Training Epoch: 1 [33792/50176]	Loss: 3.9938
Training Epoch: 1 [34816/50176]	Loss: 3.9999
Training Epoch: 1 [35840/50176]	Loss: 3.9885
Training Epoch: 1 [36864/50176]	Loss: 3.9635
Training Epoch: 1 [37888/50176]	Loss: 3.9365
Training Epoch: 1 [38912/50176]	Loss: 3.9690
Training Epoch: 1 [39936/50176]	Loss: 3.9386
Training Epoch: 1 [40960/50176]	Loss: 4.0184
Training Epoch: 1 [41984/50176]	Loss: 3.9177
Training Epoch: 1 [43008/50176]	Loss: 3.9117
Training Epoch: 1 [44032/50176]	Loss: 3.8606
Training Epoch: 1 [45056/50176]	Loss: 3.9374
Training Epoch: 1 [46080/50176]	Loss: 3.8764
Training Epoch: 1 [47104/50176]	Loss: 3.9267
Training Epoch: 1 [48128/50176]	Loss: 3.9243
Training Epoch: 1 [49152/50176]	Loss: 3.9262
Training Epoch: 1 [50176/50176]	Loss: 3.8944
2022-12-08 23:38:30.355 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:38:30,374 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.86 energy=506.42
2022-12-08 18:38:30,374 [ZeusDataLoader(train)] Up to epoch 2: time=98.16, energy=14306.89, cost=15742.21
2022-12-08 18:38:30,375 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0039, Accuracy: 0.0701
2022-12-08 18:38:30,629 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:38:30.632 [ZeusMonitor] Monitor started.
2022-12-08 23:38:30.632 [ZeusMonitor] Running indefinitely. 2022-12-08 23:38:30.632 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:38:30.632 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e3+gpu0.power.log
2022-12-08 18:38:31,383 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 18:38:31,383 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 18:38:40,762 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 18:39:20,027 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 18:39:21,962 [ZeusDataLoader(train)] train epoch 3 done: time=51.58 energy=6231.36
2022-12-08 18:39:21,965 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.8237
Training Epoch: 2 [2048/50176]	Loss: 3.8796
Training Epoch: 2 [3072/50176]	Loss: 3.8318
Training Epoch: 2 [4096/50176]	Loss: 3.7921
Training Epoch: 2 [5120/50176]	Loss: 3.7861
Training Epoch: 2 [6144/50176]	Loss: 3.8107
Training Epoch: 2 [7168/50176]	Loss: 3.8501
Training Epoch: 2 [8192/50176]	Loss: 3.8752
Training Epoch: 2 [9216/50176]	Loss: 3.8154
Training Epoch: 2 [10240/50176]	Loss: 3.7522
Training Epoch: 2 [11264/50176]	Loss: 3.7656
Training Epoch: 2 [12288/50176]	Loss: 3.7342
Training Epoch: 2 [13312/50176]	Loss: 3.7305
Training Epoch: 2 [14336/50176]	Loss: 3.7595
Training Epoch: 2 [15360/50176]	Loss: 3.8406
Training Epoch: 2 [16384/50176]	Loss: 3.8436
Training Epoch: 2 [17408/50176]	Loss: 3.8051
Training Epoch: 2 [18432/50176]	Loss: 3.7735
Training Epoch: 2 [19456/50176]	Loss: 3.7887
Training Epoch: 2 [20480/50176]	Loss: 3.7395
Training Epoch: 2 [21504/50176]	Loss: 3.7991
Training Epoch: 2 [22528/50176]	Loss: 3.7670
Training Epoch: 2 [23552/50176]	Loss: 3.7087
Training Epoch: 2 [24576/50176]	Loss: 3.7891
Training Epoch: 2 [25600/50176]	Loss: 3.7485
Training Epoch: 2 [26624/50176]	Loss: 3.7674
Training Epoch: 2 [27648/50176]	Loss: 3.7273
Training Epoch: 2 [28672/50176]	Loss: 3.7549
Training Epoch: 2 [29696/50176]	Loss: 3.6764
Training Epoch: 2 [30720/50176]	Loss: 3.6942
Training Epoch: 2 [31744/50176]	Loss: 3.6965
Training Epoch: 2 [32768/50176]	Loss: 3.6962
Training Epoch: 2 [33792/50176]	Loss: 3.7547
Training Epoch: 2 [34816/50176]	Loss: 3.7336
Training Epoch: 2 [35840/50176]	Loss: 3.6518
Training Epoch: 2 [36864/50176]	Loss: 3.6617
Training Epoch: 2 [37888/50176]	Loss: 3.7896
Training Epoch: 2 [38912/50176]	Loss: 3.6487
Training Epoch: 2 [39936/50176]	Loss: 3.5910
Training Epoch: 2 [40960/50176]	Loss: 3.6326
Training Epoch: 2 [41984/50176]	Loss: 3.6743
Training Epoch: 2 [43008/50176]	Loss: 3.6914
Training Epoch: 2 [44032/50176]	Loss: 3.5751
Training Epoch: 2 [45056/50176]	Loss: 3.6054
Training Epoch: 2 [46080/50176]	Loss: 3.6463
Training Epoch: 2 [47104/50176]	Loss: 3.6046
Training Epoch: 2 [48128/50176]	Loss: 3.5709
Training Epoch: 2 [49152/50176]	Loss: 3.6165
Training Epoch: 2 [50176/50176]	Loss: 3.5645
2022-12-08 23:39:26.170 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:39:26,185 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.21 energy=484.27
2022-12-08 18:39:26,185 [ZeusDataLoader(train)] Up to epoch 3: time=153.95, energy=21022.52, cost=23981.59
2022-12-08 18:39:26,186 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0036, Accuracy: 0.1261
2022-12-08 18:39:26,449 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 23:39:26.451 [ZeusMonitor] Monitor started.
2022-12-08 23:39:26.452 [ZeusMonitor] Running indefinitely. 2022-12-08 23:39:26.452 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:39:26.452 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e4+gpu0.power.log
2022-12-08 18:39:27,209 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 18:39:27,209 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 18:39:52,095 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 18:41:35,707 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 18:41:35,707 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 18:41:35,707 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 18:41:35,710 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 18:41:38,096 [ZeusDataLoader(train)] train epoch 4 done: time=131.87 energy=13455.37
2022-12-08 18:41:38,107 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.4952
Training Epoch: 3 [2048/50176]	Loss: 3.4863
Training Epoch: 3 [3072/50176]	Loss: 3.5551
Training Epoch: 3 [4096/50176]	Loss: 3.5752
Training Epoch: 3 [5120/50176]	Loss: 3.5508
Training Epoch: 3 [6144/50176]	Loss: 3.5268
Training Epoch: 3 [7168/50176]	Loss: 3.5774
Training Epoch: 3 [8192/50176]	Loss: 3.5459
Training Epoch: 3 [9216/50176]	Loss: 3.5303
Training Epoch: 3 [10240/50176]	Loss: 3.5463
Training Epoch: 3 [11264/50176]	Loss: 3.5467
Training Epoch: 3 [12288/50176]	Loss: 3.5223
Training Epoch: 3 [13312/50176]	Loss: 3.5239
Training Epoch: 3 [14336/50176]	Loss: 3.4896
Training Epoch: 3 [15360/50176]	Loss: 3.4849
Training Epoch: 3 [16384/50176]	Loss: 3.5094
Training Epoch: 3 [17408/50176]	Loss: 3.4532
Training Epoch: 3 [18432/50176]	Loss: 3.4896
Training Epoch: 3 [19456/50176]	Loss: 3.4936
Training Epoch: 3 [20480/50176]	Loss: 3.4440
Training Epoch: 3 [21504/50176]	Loss: 3.5033
Training Epoch: 3 [22528/50176]	Loss: 3.4346
Training Epoch: 3 [23552/50176]	Loss: 3.4511
Training Epoch: 3 [24576/50176]	Loss: 3.5007
Training Epoch: 3 [25600/50176]	Loss: 3.4015
Training Epoch: 3 [26624/50176]	Loss: 3.5323
Training Epoch: 3 [27648/50176]	Loss: 3.4895
Training Epoch: 3 [28672/50176]	Loss: 3.4126
Training Epoch: 3 [29696/50176]	Loss: 3.4325
Training Epoch: 3 [30720/50176]	Loss: 3.4579
Training Epoch: 3 [31744/50176]	Loss: 3.4446
Training Epoch: 3 [32768/50176]	Loss: 3.3749
Training Epoch: 3 [33792/50176]	Loss: 3.3107
Training Epoch: 3 [34816/50176]	Loss: 3.3998
Training Epoch: 3 [35840/50176]	Loss: 3.3200
Training Epoch: 3 [36864/50176]	Loss: 3.4074
Training Epoch: 3 [37888/50176]	Loss: 3.4280
Training Epoch: 3 [38912/50176]	Loss: 3.4413
Training Epoch: 3 [39936/50176]	Loss: 3.4125
Training Epoch: 3 [40960/50176]	Loss: 3.3271
Training Epoch: 3 [41984/50176]	Loss: 3.3527
Training Epoch: 3 [43008/50176]	Loss: 3.2397
Training Epoch: 3 [44032/50176]	Loss: 3.2833
Training Epoch: 3 [45056/50176]	Loss: 3.3139
Training Epoch: 3 [46080/50176]	Loss: 3.3349
Training Epoch: 3 [47104/50176]	Loss: 3.3023
Training Epoch: 3 [48128/50176]	Loss: 3.4297
Training Epoch: 3 [49152/50176]	Loss: 3.3231
Training Epoch: 3 [50176/50176]	Loss: 3.3624
2022-12-08 23:41:42.167 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:41:42,214 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 18:41:42,214 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+lr0.0080000.power.json: {"job_id": "rec02+try01", "train_power": {"175000": 154.89953148785654, "150000": 146.71964346885522, "125000": 122.82062575056527, "100000": 101.98676264846775}, "train_throughput": {"175000": 1.133277720351713, "150000": 1.0989740762460123, "125000": 0.9681039581727158, "100000": 0.3668091756560675}, "eval_power": {"175000": 128.0308069670569, "150000": 131.06058502963776, "125000": 115.01601627718911}, "eval_throughput": {"175000": 2.444335818105813, "150000": 2.587981317609751, "125000": 2.3750444149937446}, "optimal_pl": 175000}
2022-12-08 18:41:42,214 [ZeusDataLoader(eval)] eval epoch 4 done: time=4.09 energy=523.79
2022-12-08 18:41:42,214 [ZeusDataLoader(train)] Up to epoch 4: time=289.91, energy=35001.67, cost=42867.91
2022-12-08 18:41:42,215 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:41:42,215 [ZeusDataLoader(train)] Expected next epoch: time=337.24, energy=42222.92, cost=50619.77
2022-12-08 18:41:42,216 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0034, Accuracy: 0.1719
2022-12-08 18:41:42,536 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:41:42,537 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:41:42.539 [ZeusMonitor] Monitor started.
2022-12-08 23:41:42.539 [ZeusMonitor] Running indefinitely. 2022-12-08 23:41:42.539 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:41:42.539 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e5+gpu0.power.log
2022-12-08 18:42:26,327 [ZeusDataLoader(train)] train epoch 5 done: time=44.10 energy=6693.36
2022-12-08 18:42:26,331 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.3479
Training Epoch: 4 [2048/50176]	Loss: 3.2454
Training Epoch: 4 [3072/50176]	Loss: 3.2534
Training Epoch: 4 [4096/50176]	Loss: 3.2191
Training Epoch: 4 [5120/50176]	Loss: 3.2302
Training Epoch: 4 [6144/50176]	Loss: 3.2602
Training Epoch: 4 [7168/50176]	Loss: 3.2570
Training Epoch: 4 [8192/50176]	Loss: 3.2602
Training Epoch: 4 [9216/50176]	Loss: 3.2607
Training Epoch: 4 [10240/50176]	Loss: 3.1910
Training Epoch: 4 [11264/50176]	Loss: 3.2237
Training Epoch: 4 [12288/50176]	Loss: 3.2093
Training Epoch: 4 [13312/50176]	Loss: 3.2103
Training Epoch: 4 [14336/50176]	Loss: 3.2911
Training Epoch: 4 [15360/50176]	Loss: 3.2145
Training Epoch: 4 [16384/50176]	Loss: 3.1503
Training Epoch: 4 [17408/50176]	Loss: 3.2117
Training Epoch: 4 [18432/50176]	Loss: 3.2370
Training Epoch: 4 [19456/50176]	Loss: 3.2128
Training Epoch: 4 [20480/50176]	Loss: 3.1801
Training Epoch: 4 [21504/50176]	Loss: 3.1919
Training Epoch: 4 [22528/50176]	Loss: 3.1203
Training Epoch: 4 [23552/50176]	Loss: 3.1912
Training Epoch: 4 [24576/50176]	Loss: 3.1170
Training Epoch: 4 [25600/50176]	Loss: 3.1213
Training Epoch: 4 [26624/50176]	Loss: 3.1110
Training Epoch: 4 [27648/50176]	Loss: 3.2079
Training Epoch: 4 [28672/50176]	Loss: 3.0982
Training Epoch: 4 [29696/50176]	Loss: 3.2290
Training Epoch: 4 [30720/50176]	Loss: 3.1909
Training Epoch: 4 [31744/50176]	Loss: 3.1514
Training Epoch: 4 [32768/50176]	Loss: 3.1549
Training Epoch: 4 [33792/50176]	Loss: 3.0805
Training Epoch: 4 [34816/50176]	Loss: 3.0806
Training Epoch: 4 [35840/50176]	Loss: 3.1830
Training Epoch: 4 [36864/50176]	Loss: 3.1471
Training Epoch: 4 [37888/50176]	Loss: 3.3034
Training Epoch: 4 [38912/50176]	Loss: 3.0685
Training Epoch: 4 [39936/50176]	Loss: 3.1219
Training Epoch: 4 [40960/50176]	Loss: 3.0832
Training Epoch: 4 [41984/50176]	Loss: 3.0523
Training Epoch: 4 [43008/50176]	Loss: 3.0872
Training Epoch: 4 [44032/50176]	Loss: 2.9990
Training Epoch: 4 [45056/50176]	Loss: 3.0603
Training Epoch: 4 [46080/50176]	Loss: 3.1172
Training Epoch: 4 [47104/50176]	Loss: 3.1641
Training Epoch: 4 [48128/50176]	Loss: 3.1180
Training Epoch: 4 [49152/50176]	Loss: 3.0725
Training Epoch: 4 [50176/50176]	Loss: 3.1745
2022-12-08 23:42:30.075 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:42:30,092 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.75 energy=512.47
2022-12-08 18:42:30,093 [ZeusDataLoader(train)] Up to epoch 5: time=337.76, energy=42207.51, cost=50658.14
2022-12-08 18:42:30,093 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:42:30,093 [ZeusDataLoader(train)] Expected next epoch: time=385.09, energy=49428.75, cost=58410.01
2022-12-08 18:42:30,094 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0030, Accuracy: 0.2347
2022-12-08 18:42:30,362 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:42:30,363 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:42:30.365 [ZeusMonitor] Monitor started.
2022-12-08 23:42:30.365 [ZeusMonitor] Running indefinitely. 2022-12-08 23:42:30.365 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:42:30.365 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e6+gpu0.power.log
2022-12-08 18:43:14,276 [ZeusDataLoader(train)] train epoch 6 done: time=44.17 energy=6708.88
2022-12-08 18:43:14,279 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.9428
Training Epoch: 5 [2048/50176]	Loss: 3.0334
Training Epoch: 5 [3072/50176]	Loss: 3.0820
Training Epoch: 5 [4096/50176]	Loss: 2.9716
Training Epoch: 5 [5120/50176]	Loss: 2.9532
Training Epoch: 5 [6144/50176]	Loss: 3.0059
Training Epoch: 5 [7168/50176]	Loss: 2.9142
Training Epoch: 5 [8192/50176]	Loss: 3.0029
Training Epoch: 5 [9216/50176]	Loss: 2.9509
Training Epoch: 5 [10240/50176]	Loss: 2.9890
Training Epoch: 5 [11264/50176]	Loss: 3.0606
Training Epoch: 5 [12288/50176]	Loss: 2.8621
Training Epoch: 5 [13312/50176]	Loss: 2.9241
Training Epoch: 5 [14336/50176]	Loss: 2.9345
Training Epoch: 5 [15360/50176]	Loss: 3.0467
Training Epoch: 5 [16384/50176]	Loss: 2.9309
Training Epoch: 5 [17408/50176]	Loss: 2.9937
Training Epoch: 5 [18432/50176]	Loss: 2.9313
Training Epoch: 5 [19456/50176]	Loss: 2.9633
Training Epoch: 5 [20480/50176]	Loss: 2.9158
Training Epoch: 5 [21504/50176]	Loss: 2.8469
Training Epoch: 5 [22528/50176]	Loss: 2.9903
Training Epoch: 5 [23552/50176]	Loss: 3.0014
Training Epoch: 5 [24576/50176]	Loss: 2.9101
Training Epoch: 5 [25600/50176]	Loss: 2.9507
Training Epoch: 5 [26624/50176]	Loss: 2.9033
Training Epoch: 5 [27648/50176]	Loss: 2.8880
Training Epoch: 5 [28672/50176]	Loss: 2.9158
Training Epoch: 5 [29696/50176]	Loss: 2.8968
Training Epoch: 5 [30720/50176]	Loss: 2.8567
Training Epoch: 5 [31744/50176]	Loss: 2.8812
Training Epoch: 5 [32768/50176]	Loss: 2.9253
Training Epoch: 5 [33792/50176]	Loss: 2.8569
Training Epoch: 5 [34816/50176]	Loss: 2.8617
Training Epoch: 5 [35840/50176]	Loss: 2.9755
Training Epoch: 5 [36864/50176]	Loss: 2.7801
Training Epoch: 5 [37888/50176]	Loss: 2.8435
Training Epoch: 5 [38912/50176]	Loss: 2.8201
Training Epoch: 5 [39936/50176]	Loss: 2.9207
Training Epoch: 5 [40960/50176]	Loss: 2.7913
Training Epoch: 5 [41984/50176]	Loss: 2.8664
Training Epoch: 5 [43008/50176]	Loss: 2.8549
Training Epoch: 5 [44032/50176]	Loss: 2.8561
Training Epoch: 5 [45056/50176]	Loss: 2.9361
Training Epoch: 5 [46080/50176]	Loss: 2.8074
Training Epoch: 5 [47104/50176]	Loss: 2.8431
Training Epoch: 5 [48128/50176]	Loss: 2.8609
Training Epoch: 5 [49152/50176]	Loss: 2.8861
Training Epoch: 5 [50176/50176]	Loss: 2.8317
2022-12-08 23:43:18.004 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:43:18,022 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.73 energy=514.68
2022-12-08 18:43:18,022 [ZeusDataLoader(train)] Up to epoch 6: time=385.67, energy=49431.07, cost=58461.86
2022-12-08 18:43:18,023 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:43:18,023 [ZeusDataLoader(train)] Expected next epoch: time=433.00, energy=56652.31, cost=66213.73
2022-12-08 18:43:18,024 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0028, Accuracy: 0.2656
2022-12-08 18:43:18,282 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:43:18,283 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:43:18.285 [ZeusMonitor] Monitor started.
2022-12-08 23:43:18.285 [ZeusMonitor] Running indefinitely. 2022-12-08 23:43:18.285 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:43:18.285 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e7+gpu0.power.log
2022-12-08 18:44:02,245 [ZeusDataLoader(train)] train epoch 7 done: time=44.21 energy=6716.60
2022-12-08 18:44:02,249 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.7490
Training Epoch: 6 [2048/50176]	Loss: 2.7388
Training Epoch: 6 [3072/50176]	Loss: 2.8353
Training Epoch: 6 [4096/50176]	Loss: 2.7847
Training Epoch: 6 [5120/50176]	Loss: 2.6622
Training Epoch: 6 [6144/50176]	Loss: 2.7322
Training Epoch: 6 [7168/50176]	Loss: 2.7706
Training Epoch: 6 [8192/50176]	Loss: 2.7210
Training Epoch: 6 [9216/50176]	Loss: 2.8270
Training Epoch: 6 [10240/50176]	Loss: 2.7503
Training Epoch: 6 [11264/50176]	Loss: 2.7496
Training Epoch: 6 [12288/50176]	Loss: 2.7962
Training Epoch: 6 [13312/50176]	Loss: 2.7388
Training Epoch: 6 [14336/50176]	Loss: 2.6940
Training Epoch: 6 [15360/50176]	Loss: 2.6253
Training Epoch: 6 [16384/50176]	Loss: 2.7416
Training Epoch: 6 [17408/50176]	Loss: 2.6940
Training Epoch: 6 [18432/50176]	Loss: 2.7550
Training Epoch: 6 [19456/50176]	Loss: 2.6294
Training Epoch: 6 [20480/50176]	Loss: 2.7718
Training Epoch: 6 [21504/50176]	Loss: 2.7961
Training Epoch: 6 [22528/50176]	Loss: 2.6917
Training Epoch: 6 [23552/50176]	Loss: 2.6965
Training Epoch: 6 [24576/50176]	Loss: 2.6981
Training Epoch: 6 [25600/50176]	Loss: 2.6333
Training Epoch: 6 [26624/50176]	Loss: 2.7197
Training Epoch: 6 [27648/50176]	Loss: 2.7295
Training Epoch: 6 [28672/50176]	Loss: 2.5435
Training Epoch: 6 [29696/50176]	Loss: 2.6894
Training Epoch: 6 [30720/50176]	Loss: 2.6895
Training Epoch: 6 [31744/50176]	Loss: 2.6571
Training Epoch: 6 [32768/50176]	Loss: 2.6571
Training Epoch: 6 [33792/50176]	Loss: 2.6758
Training Epoch: 6 [34816/50176]	Loss: 2.7017
Training Epoch: 6 [35840/50176]	Loss: 2.6636
Training Epoch: 6 [36864/50176]	Loss: 2.6960
Training Epoch: 6 [37888/50176]	Loss: 2.7183
Training Epoch: 6 [38912/50176]	Loss: 2.7014
Training Epoch: 6 [39936/50176]	Loss: 2.6992
Training Epoch: 6 [40960/50176]	Loss: 2.6737
Training Epoch: 6 [41984/50176]	Loss: 2.6313
Training Epoch: 6 [43008/50176]	Loss: 2.6134
Training Epoch: 6 [44032/50176]	Loss: 2.6431
Training Epoch: 6 [45056/50176]	Loss: 2.6261
Training Epoch: 6 [46080/50176]	Loss: 2.7008
Training Epoch: 6 [47104/50176]	Loss: 2.5921
Training Epoch: 6 [48128/50176]	Loss: 2.6704
Training Epoch: 6 [49152/50176]	Loss: 2.5596
Training Epoch: 6 [50176/50176]	Loss: 2.6145
2022-12-08 23:44:06.015 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:44:06,037 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.78 energy=530.49
2022-12-08 18:44:06,037 [ZeusDataLoader(train)] Up to epoch 7: time=433.66, energy=56678.16, cost=66284.67
2022-12-08 18:44:06,037 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:44:06,037 [ZeusDataLoader(train)] Expected next epoch: time=480.99, energy=63899.40, cost=74036.53
2022-12-08 18:44:06,039 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0027, Accuracy: 0.2957
2022-12-08 18:44:06,235 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:44:06,236 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:44:06.238 [ZeusMonitor] Monitor started.
2022-12-08 23:44:06.238 [ZeusMonitor] Running indefinitely. 2022-12-08 23:44:06.238 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:44:06.238 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e8+gpu0.power.log
2022-12-08 18:44:50,211 [ZeusDataLoader(train)] train epoch 8 done: time=44.16 energy=6704.78
2022-12-08 18:44:50,215 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.5706
Training Epoch: 7 [2048/50176]	Loss: 2.5368
Training Epoch: 7 [3072/50176]	Loss: 2.4830
Training Epoch: 7 [4096/50176]	Loss: 2.4832
Training Epoch: 7 [5120/50176]	Loss: 2.5321
Training Epoch: 7 [6144/50176]	Loss: 2.5444
Training Epoch: 7 [7168/50176]	Loss: 2.5367
Training Epoch: 7 [8192/50176]	Loss: 2.5021
Training Epoch: 7 [9216/50176]	Loss: 2.4010
Training Epoch: 7 [10240/50176]	Loss: 2.4803
Training Epoch: 7 [11264/50176]	Loss: 2.4362
Training Epoch: 7 [12288/50176]	Loss: 2.4804
Training Epoch: 7 [13312/50176]	Loss: 2.4719
Training Epoch: 7 [14336/50176]	Loss: 2.6037
Training Epoch: 7 [15360/50176]	Loss: 2.5075
Training Epoch: 7 [16384/50176]	Loss: 2.5123
Training Epoch: 7 [17408/50176]	Loss: 2.5592
Training Epoch: 7 [18432/50176]	Loss: 2.4921
Training Epoch: 7 [19456/50176]	Loss: 2.5144
Training Epoch: 7 [20480/50176]	Loss: 2.5130
Training Epoch: 7 [21504/50176]	Loss: 2.5727
Training Epoch: 7 [22528/50176]	Loss: 2.4916
Training Epoch: 7 [23552/50176]	Loss: 2.4811
Training Epoch: 7 [24576/50176]	Loss: 2.4509
Training Epoch: 7 [25600/50176]	Loss: 2.4996
Training Epoch: 7 [26624/50176]	Loss: 2.5470
Training Epoch: 7 [27648/50176]	Loss: 2.5492
Training Epoch: 7 [28672/50176]	Loss: 2.4421
Training Epoch: 7 [29696/50176]	Loss: 2.5049
Training Epoch: 7 [30720/50176]	Loss: 2.4451
Training Epoch: 7 [31744/50176]	Loss: 2.4985
Training Epoch: 7 [32768/50176]	Loss: 2.3915
Training Epoch: 7 [33792/50176]	Loss: 2.5314
Training Epoch: 7 [34816/50176]	Loss: 2.5097
Training Epoch: 7 [35840/50176]	Loss: 2.3894
Training Epoch: 7 [36864/50176]	Loss: 2.3160
Training Epoch: 7 [37888/50176]	Loss: 2.3872
Training Epoch: 7 [38912/50176]	Loss: 2.4953
Training Epoch: 7 [39936/50176]	Loss: 2.5112
Training Epoch: 7 [40960/50176]	Loss: 2.5039
Training Epoch: 7 [41984/50176]	Loss: 2.4125
Training Epoch: 7 [43008/50176]	Loss: 2.4061
Training Epoch: 7 [44032/50176]	Loss: 2.3434
Training Epoch: 7 [45056/50176]	Loss: 2.4706
Training Epoch: 7 [46080/50176]	Loss: 2.4447
Training Epoch: 7 [47104/50176]	Loss: 2.3437
Training Epoch: 7 [48128/50176]	Loss: 2.3659
Training Epoch: 7 [49152/50176]	Loss: 2.4949
Training Epoch: 7 [50176/50176]	Loss: 2.3867
2022-12-08 23:44:53.984 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:44:54,006 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.78 energy=525.25
2022-12-08 18:44:54,006 [ZeusDataLoader(train)] Up to epoch 8: time=481.61, energy=63908.19, cost=74094.93
2022-12-08 18:44:54,006 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:44:54,006 [ZeusDataLoader(train)] Expected next epoch: time=528.94, energy=71129.43, cost=81846.79
2022-12-08 18:44:54,007 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0027, Accuracy: 0.3080
2022-12-08 18:44:54,213 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:44:54,214 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:44:54.218 [ZeusMonitor] Monitor started.
2022-12-08 23:44:54.218 [ZeusMonitor] Running indefinitely. 2022-12-08 23:44:54.218 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:44:54.218 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e9+gpu0.power.log
2022-12-08 18:45:38,201 [ZeusDataLoader(train)] train epoch 9 done: time=44.18 energy=6709.47
2022-12-08 18:45:38,204 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.4435
Training Epoch: 8 [2048/50176]	Loss: 2.4197
Training Epoch: 8 [3072/50176]	Loss: 2.3966
Training Epoch: 8 [4096/50176]	Loss: 2.2833
Training Epoch: 8 [5120/50176]	Loss: 2.2257
Training Epoch: 8 [6144/50176]	Loss: 2.3041
Training Epoch: 8 [7168/50176]	Loss: 2.3206
Training Epoch: 8 [8192/50176]	Loss: 2.3088
Training Epoch: 8 [9216/50176]	Loss: 2.2151
Training Epoch: 8 [10240/50176]	Loss: 2.2666
Training Epoch: 8 [11264/50176]	Loss: 2.3196
Training Epoch: 8 [12288/50176]	Loss: 2.3344
Training Epoch: 8 [13312/50176]	Loss: 2.3231
Training Epoch: 8 [14336/50176]	Loss: 2.3006
Training Epoch: 8 [15360/50176]	Loss: 2.3700
Training Epoch: 8 [16384/50176]	Loss: 2.2883
Training Epoch: 8 [17408/50176]	Loss: 2.3499
Training Epoch: 8 [18432/50176]	Loss: 2.3200
Training Epoch: 8 [19456/50176]	Loss: 2.2506
Training Epoch: 8 [20480/50176]	Loss: 2.2396
Training Epoch: 8 [21504/50176]	Loss: 2.2263
Training Epoch: 8 [22528/50176]	Loss: 2.2886
Training Epoch: 8 [23552/50176]	Loss: 2.2528
Training Epoch: 8 [24576/50176]	Loss: 2.3340
Training Epoch: 8 [25600/50176]	Loss: 2.2788
Training Epoch: 8 [26624/50176]	Loss: 2.3022
Training Epoch: 8 [27648/50176]	Loss: 2.2438
Training Epoch: 8 [28672/50176]	Loss: 2.3001
Training Epoch: 8 [29696/50176]	Loss: 2.2818
Training Epoch: 8 [30720/50176]	Loss: 2.2706
Training Epoch: 8 [31744/50176]	Loss: 2.2775
Training Epoch: 8 [32768/50176]	Loss: 2.2288
Training Epoch: 8 [33792/50176]	Loss: 2.3817
Training Epoch: 8 [34816/50176]	Loss: 2.3105
Training Epoch: 8 [35840/50176]	Loss: 2.3340
Training Epoch: 8 [36864/50176]	Loss: 2.2939
Training Epoch: 8 [37888/50176]	Loss: 2.2771
Training Epoch: 8 [38912/50176]	Loss: 2.2586
Training Epoch: 8 [39936/50176]	Loss: 2.3385
Training Epoch: 8 [40960/50176]	Loss: 2.2707
Training Epoch: 8 [41984/50176]	Loss: 2.2718
Training Epoch: 8 [43008/50176]	Loss: 2.2942
Training Epoch: 8 [44032/50176]	Loss: 2.3590
Training Epoch: 8 [45056/50176]	Loss: 2.3253
Training Epoch: 8 [46080/50176]	Loss: 2.2091
Training Epoch: 8 [47104/50176]	Loss: 2.3317
Training Epoch: 8 [48128/50176]	Loss: 2.1727
Training Epoch: 8 [49152/50176]	Loss: 2.3131
Training Epoch: 8 [50176/50176]	Loss: 2.2553
2022-12-08 23:45:41.997 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:45:42,040 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.83 energy=533.37
2022-12-08 18:45:42,041 [ZeusDataLoader(train)] Up to epoch 9: time=529.62, energy=71151.03, cost=81917.39
2022-12-08 18:45:42,041 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:45:42,041 [ZeusDataLoader(train)] Expected next epoch: time=576.95, energy=78372.27, cost=89669.26
2022-12-08 18:45:42,042 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0023, Accuracy: 0.3766
2022-12-08 18:45:42,302 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:45:42,303 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:45:42.305 [ZeusMonitor] Monitor started.
2022-12-08 23:45:42.305 [ZeusMonitor] Running indefinitely. 2022-12-08 23:45:42.305 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:45:42.305 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e10+gpu0.power.log
2022-12-08 18:46:26,219 [ZeusDataLoader(train)] train epoch 10 done: time=44.17 energy=6713.41
2022-12-08 18:46:26,223 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.1574
Training Epoch: 9 [2048/50176]	Loss: 2.1566
Training Epoch: 9 [3072/50176]	Loss: 2.1950
Training Epoch: 9 [4096/50176]	Loss: 2.1446
Training Epoch: 9 [5120/50176]	Loss: 2.2591
Training Epoch: 9 [6144/50176]	Loss: 2.0872
Training Epoch: 9 [7168/50176]	Loss: 2.2391
Training Epoch: 9 [8192/50176]	Loss: 2.1818
Training Epoch: 9 [9216/50176]	Loss: 2.1778
Training Epoch: 9 [10240/50176]	Loss: 2.1751
Training Epoch: 9 [11264/50176]	Loss: 2.2629
Training Epoch: 9 [12288/50176]	Loss: 2.1853
Training Epoch: 9 [13312/50176]	Loss: 2.0897
Training Epoch: 9 [14336/50176]	Loss: 2.2158
Training Epoch: 9 [15360/50176]	Loss: 2.1849
Training Epoch: 9 [16384/50176]	Loss: 2.1617
Training Epoch: 9 [17408/50176]	Loss: 2.0814
Training Epoch: 9 [18432/50176]	Loss: 2.2285
Training Epoch: 9 [19456/50176]	Loss: 2.1429
Training Epoch: 9 [20480/50176]	Loss: 2.1248
Training Epoch: 9 [21504/50176]	Loss: 2.1590
Training Epoch: 9 [22528/50176]	Loss: 2.1106
Training Epoch: 9 [23552/50176]	Loss: 2.0905
Training Epoch: 9 [24576/50176]	Loss: 2.1375
Training Epoch: 9 [25600/50176]	Loss: 2.1076
Training Epoch: 9 [26624/50176]	Loss: 2.1045
Training Epoch: 9 [27648/50176]	Loss: 2.1920
Training Epoch: 9 [28672/50176]	Loss: 2.1879
Training Epoch: 9 [29696/50176]	Loss: 2.1759
Training Epoch: 9 [30720/50176]	Loss: 2.0751
Training Epoch: 9 [31744/50176]	Loss: 2.1549
Training Epoch: 9 [32768/50176]	Loss: 2.1177
Training Epoch: 9 [33792/50176]	Loss: 2.0943
Training Epoch: 9 [34816/50176]	Loss: 2.2008
Training Epoch: 9 [35840/50176]	Loss: 2.0812
Training Epoch: 9 [36864/50176]	Loss: 2.1663
Training Epoch: 9 [37888/50176]	Loss: 2.1381
Training Epoch: 9 [38912/50176]	Loss: 2.1576
Training Epoch: 9 [39936/50176]	Loss: 2.0980
Training Epoch: 9 [40960/50176]	Loss: 2.1417
Training Epoch: 9 [41984/50176]	Loss: 2.0291
Training Epoch: 9 [43008/50176]	Loss: 2.1836
Training Epoch: 9 [44032/50176]	Loss: 2.1212
Training Epoch: 9 [45056/50176]	Loss: 2.0484
Training Epoch: 9 [46080/50176]	Loss: 2.0463
Training Epoch: 9 [47104/50176]	Loss: 2.1103
Training Epoch: 9 [48128/50176]	Loss: 2.0858
Training Epoch: 9 [49152/50176]	Loss: 2.0828
Training Epoch: 9 [50176/50176]	Loss: 1.9905
2022-12-08 23:46:30.052 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:46:30,073 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.84 energy=534.05
2022-12-08 18:46:30,074 [ZeusDataLoader(train)] Up to epoch 10: time=577.63, energy=78398.49, cost=89742.03
2022-12-08 18:46:30,074 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:46:30,074 [ZeusDataLoader(train)] Expected next epoch: time=624.96, energy=85619.73, cost=97493.89
2022-12-08 18:46:30,075 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0025, Accuracy: 0.3473
2022-12-08 18:46:30,329 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:46:30,330 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:46:30.332 [ZeusMonitor] Monitor started.
2022-12-08 23:46:30.332 [ZeusMonitor] Running indefinitely. 2022-12-08 23:46:30.332 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:46:30.332 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e11+gpu0.power.log
2022-12-08 18:47:14,252 [ZeusDataLoader(train)] train epoch 11 done: time=44.17 energy=6711.54
2022-12-08 18:47:14,258 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 2.0406
Training Epoch: 10 [2048/50176]	Loss: 1.9901
Training Epoch: 10 [3072/50176]	Loss: 1.9961
Training Epoch: 10 [4096/50176]	Loss: 2.1087
Training Epoch: 10 [5120/50176]	Loss: 1.9613
Training Epoch: 10 [6144/50176]	Loss: 2.0566
Training Epoch: 10 [7168/50176]	Loss: 1.9590
Training Epoch: 10 [8192/50176]	Loss: 1.9099
Training Epoch: 10 [9216/50176]	Loss: 2.0256
Training Epoch: 10 [10240/50176]	Loss: 1.9404
Training Epoch: 10 [11264/50176]	Loss: 2.1038
Training Epoch: 10 [12288/50176]	Loss: 2.0135
Training Epoch: 10 [13312/50176]	Loss: 2.1166
Training Epoch: 10 [14336/50176]	Loss: 2.1087
Training Epoch: 10 [15360/50176]	Loss: 2.0684
Training Epoch: 10 [16384/50176]	Loss: 2.0913
Training Epoch: 10 [17408/50176]	Loss: 2.1137
Training Epoch: 10 [18432/50176]	Loss: 1.9709
Training Epoch: 10 [19456/50176]	Loss: 2.0160
Training Epoch: 10 [20480/50176]	Loss: 2.0017
Training Epoch: 10 [21504/50176]	Loss: 2.0390
Training Epoch: 10 [22528/50176]	Loss: 2.0317
Training Epoch: 10 [23552/50176]	Loss: 2.0328
Training Epoch: 10 [24576/50176]	Loss: 2.0053
Training Epoch: 10 [25600/50176]	Loss: 1.9681
Training Epoch: 10 [26624/50176]	Loss: 1.9717
Training Epoch: 10 [27648/50176]	Loss: 2.0028
Training Epoch: 10 [28672/50176]	Loss: 2.0779
Training Epoch: 10 [29696/50176]	Loss: 2.1335
Training Epoch: 10 [30720/50176]	Loss: 1.9491
Training Epoch: 10 [31744/50176]	Loss: 2.0740
Training Epoch: 10 [32768/50176]	Loss: 1.9405
Training Epoch: 10 [33792/50176]	Loss: 1.9853
Training Epoch: 10 [34816/50176]	Loss: 2.0252
Training Epoch: 10 [35840/50176]	Loss: 2.1107
Training Epoch: 10 [36864/50176]	Loss: 2.0533
Training Epoch: 10 [37888/50176]	Loss: 1.9044
Training Epoch: 10 [38912/50176]	Loss: 1.9980
Training Epoch: 10 [39936/50176]	Loss: 2.1149
Training Epoch: 10 [40960/50176]	Loss: 1.9121
Training Epoch: 10 [41984/50176]	Loss: 1.9026
Training Epoch: 10 [43008/50176]	Loss: 2.0380
Training Epoch: 10 [44032/50176]	Loss: 2.0042
Training Epoch: 10 [45056/50176]	Loss: 1.9547
Training Epoch: 10 [46080/50176]	Loss: 1.8579
Training Epoch: 10 [47104/50176]	Loss: 2.0059
Training Epoch: 10 [48128/50176]	Loss: 2.0064
Training Epoch: 10 [49152/50176]	Loss: 2.0441
Training Epoch: 10 [50176/50176]	Loss: 2.0167
2022-12-08 23:47:18.085 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:47:18,118 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.85 energy=534.52
2022-12-08 18:47:18,119 [ZeusDataLoader(train)] Up to epoch 11: time=625.65, energy=85644.56, cost=97566.89
2022-12-08 18:47:18,119 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:47:18,119 [ZeusDataLoader(train)] Expected next epoch: time=672.98, energy=92865.80, cost=105318.75
2022-12-08 18:47:18,120 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0021, Accuracy: 0.4209
2022-12-08 18:47:18,372 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:47:18,373 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:47:18.375 [ZeusMonitor] Monitor started.
2022-12-08 23:47:18.375 [ZeusMonitor] Running indefinitely. 2022-12-08 23:47:18.375 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:47:18.375 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e12+gpu0.power.log
2022-12-08 18:48:02,330 [ZeusDataLoader(train)] train epoch 12 done: time=44.20 energy=6722.17
2022-12-08 18:48:02,333 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.8626
Training Epoch: 11 [2048/50176]	Loss: 1.8860
Training Epoch: 11 [3072/50176]	Loss: 1.8808
Training Epoch: 11 [4096/50176]	Loss: 2.0291
Training Epoch: 11 [5120/50176]	Loss: 1.9978
Training Epoch: 11 [6144/50176]	Loss: 1.7627
Training Epoch: 11 [7168/50176]	Loss: 1.7599
Training Epoch: 11 [8192/50176]	Loss: 1.8739
Training Epoch: 11 [9216/50176]	Loss: 1.8879
Training Epoch: 11 [10240/50176]	Loss: 1.9910
Training Epoch: 11 [11264/50176]	Loss: 1.9027
Training Epoch: 11 [12288/50176]	Loss: 1.9055
Training Epoch: 11 [13312/50176]	Loss: 2.0010
Training Epoch: 11 [14336/50176]	Loss: 1.8103
Training Epoch: 11 [15360/50176]	Loss: 1.9123
Training Epoch: 11 [16384/50176]	Loss: 1.8938
Training Epoch: 11 [17408/50176]	Loss: 1.8750
Training Epoch: 11 [18432/50176]	Loss: 1.8849
Training Epoch: 11 [19456/50176]	Loss: 1.8458
Training Epoch: 11 [20480/50176]	Loss: 1.9988
Training Epoch: 11 [21504/50176]	Loss: 1.9854
Training Epoch: 11 [22528/50176]	Loss: 1.9407
Training Epoch: 11 [23552/50176]	Loss: 1.9659
Training Epoch: 11 [24576/50176]	Loss: 1.9217
Training Epoch: 11 [25600/50176]	Loss: 1.9086
Training Epoch: 11 [26624/50176]	Loss: 1.8004
Training Epoch: 11 [27648/50176]	Loss: 1.8816
Training Epoch: 11 [28672/50176]	Loss: 1.9119
Training Epoch: 11 [29696/50176]	Loss: 1.9521
Training Epoch: 11 [30720/50176]	Loss: 1.9046
Training Epoch: 11 [31744/50176]	Loss: 1.8823
Training Epoch: 11 [32768/50176]	Loss: 1.9051
Training Epoch: 11 [33792/50176]	Loss: 1.9125
Training Epoch: 11 [34816/50176]	Loss: 1.9448
Training Epoch: 11 [35840/50176]	Loss: 1.9133
Training Epoch: 11 [36864/50176]	Loss: 1.8493
Training Epoch: 11 [37888/50176]	Loss: 1.9506
Training Epoch: 11 [38912/50176]	Loss: 1.9133
Training Epoch: 11 [39936/50176]	Loss: 1.8883
Training Epoch: 11 [40960/50176]	Loss: 1.8474
Training Epoch: 11 [41984/50176]	Loss: 1.9259
Training Epoch: 11 [43008/50176]	Loss: 1.9395
Training Epoch: 11 [44032/50176]	Loss: 1.9193
Training Epoch: 11 [45056/50176]	Loss: 1.9567
Training Epoch: 11 [46080/50176]	Loss: 1.8041
Training Epoch: 11 [47104/50176]	Loss: 1.9116
Training Epoch: 11 [48128/50176]	Loss: 1.8852
Training Epoch: 11 [49152/50176]	Loss: 1.8319
Training Epoch: 11 [50176/50176]	Loss: 1.9489
2022-12-08 23:48:06.118 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:48:06,141 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.80 energy=514.34
2022-12-08 18:48:06,141 [ZeusDataLoader(train)] Up to epoch 12: time=673.65, energy=92881.06, cost=105384.94
2022-12-08 18:48:06,141 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:48:06,141 [ZeusDataLoader(train)] Expected next epoch: time=720.98, energy=100102.30, cost=113136.81
2022-12-08 18:48:06,142 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0027, Accuracy: 0.3356
2022-12-08 18:48:06,402 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:48:06,402 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:48:06.412 [ZeusMonitor] Monitor started.
2022-12-08 23:48:06.413 [ZeusMonitor] Running indefinitely. 2022-12-08 23:48:06.413 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:48:06.413 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e13+gpu0.power.log
2022-12-08 18:48:50,530 [ZeusDataLoader(train)] train epoch 13 done: time=44.38 energy=6709.98
2022-12-08 18:48:50,534 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.7862
Training Epoch: 12 [2048/50176]	Loss: 1.7517
Training Epoch: 12 [3072/50176]	Loss: 1.8506
Training Epoch: 12 [4096/50176]	Loss: 1.7962
Training Epoch: 12 [5120/50176]	Loss: 1.6731
Training Epoch: 12 [6144/50176]	Loss: 1.7907
Training Epoch: 12 [7168/50176]	Loss: 1.8805
Training Epoch: 12 [8192/50176]	Loss: 1.6884
Training Epoch: 12 [9216/50176]	Loss: 1.8419
Training Epoch: 12 [10240/50176]	Loss: 1.7553
Training Epoch: 12 [11264/50176]	Loss: 1.9231
Training Epoch: 12 [12288/50176]	Loss: 1.7671
Training Epoch: 12 [13312/50176]	Loss: 1.7352
Training Epoch: 12 [14336/50176]	Loss: 1.8225
Training Epoch: 12 [15360/50176]	Loss: 1.6952
Training Epoch: 12 [16384/50176]	Loss: 1.7419
Training Epoch: 12 [17408/50176]	Loss: 1.7404
Training Epoch: 12 [18432/50176]	Loss: 1.7567
Training Epoch: 12 [19456/50176]	Loss: 1.7794
Training Epoch: 12 [20480/50176]	Loss: 1.8304
Training Epoch: 12 [21504/50176]	Loss: 1.8587
Training Epoch: 12 [22528/50176]	Loss: 1.7336
Training Epoch: 12 [23552/50176]	Loss: 1.8273
Training Epoch: 12 [24576/50176]	Loss: 1.7455
Training Epoch: 12 [25600/50176]	Loss: 1.8600
Training Epoch: 12 [26624/50176]	Loss: 1.8540
Training Epoch: 12 [27648/50176]	Loss: 1.7361
Training Epoch: 12 [28672/50176]	Loss: 1.8301
Training Epoch: 12 [29696/50176]	Loss: 1.8159
Training Epoch: 12 [30720/50176]	Loss: 1.7816
Training Epoch: 12 [31744/50176]	Loss: 1.7821
Training Epoch: 12 [32768/50176]	Loss: 1.8269
Training Epoch: 12 [33792/50176]	Loss: 1.7308
Training Epoch: 12 [34816/50176]	Loss: 1.8022
Training Epoch: 12 [35840/50176]	Loss: 1.7643
Training Epoch: 12 [36864/50176]	Loss: 1.8104
Training Epoch: 12 [37888/50176]	Loss: 1.8295
Training Epoch: 12 [38912/50176]	Loss: 1.6985
Training Epoch: 12 [39936/50176]	Loss: 1.8881
Training Epoch: 12 [40960/50176]	Loss: 1.7172
Training Epoch: 12 [41984/50176]	Loss: 1.8966
Training Epoch: 12 [43008/50176]	Loss: 1.7856
Training Epoch: 12 [44032/50176]	Loss: 1.8783
Training Epoch: 12 [45056/50176]	Loss: 1.7297
Training Epoch: 12 [46080/50176]	Loss: 1.8126
Training Epoch: 12 [47104/50176]	Loss: 1.7376
Training Epoch: 12 [48128/50176]	Loss: 1.7285
Training Epoch: 12 [49152/50176]	Loss: 1.7642
Training Epoch: 12 [50176/50176]	Loss: 1.7365
2022-12-08 23:48:54.366 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:48:54,395 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.85 energy=531.04
2022-12-08 18:48:54,396 [ZeusDataLoader(train)] Up to epoch 13: time=721.88, energy=100122.08, cost=113225.73
2022-12-08 18:48:54,396 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:48:54,396 [ZeusDataLoader(train)] Expected next epoch: time=769.21, energy=107343.32, cost=120977.60
2022-12-08 18:48:54,397 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0020, Accuracy: 0.4578
2022-12-08 18:48:54,599 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:48:54,600 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:48:54.604 [ZeusMonitor] Monitor started.
2022-12-08 23:48:54.604 [ZeusMonitor] Running indefinitely. 2022-12-08 23:48:54.604 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:48:54.604 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e14+gpu0.power.log
2022-12-08 18:49:38,625 [ZeusDataLoader(train)] train epoch 14 done: time=44.22 energy=6721.60
2022-12-08 18:49:38,628 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.6607
Training Epoch: 13 [2048/50176]	Loss: 1.6761
Training Epoch: 13 [3072/50176]	Loss: 1.7285
Training Epoch: 13 [4096/50176]	Loss: 1.6237
Training Epoch: 13 [5120/50176]	Loss: 1.6967
Training Epoch: 13 [6144/50176]	Loss: 1.6828
Training Epoch: 13 [7168/50176]	Loss: 1.6311
Training Epoch: 13 [8192/50176]	Loss: 1.6384
Training Epoch: 13 [9216/50176]	Loss: 1.6941
Training Epoch: 13 [10240/50176]	Loss: 1.7803
Training Epoch: 13 [11264/50176]	Loss: 1.6194
Training Epoch: 13 [12288/50176]	Loss: 1.6865
Training Epoch: 13 [13312/50176]	Loss: 1.6974
Training Epoch: 13 [14336/50176]	Loss: 1.6880
Training Epoch: 13 [15360/50176]	Loss: 1.6881
Training Epoch: 13 [16384/50176]	Loss: 1.6848
Training Epoch: 13 [17408/50176]	Loss: 1.6735
Training Epoch: 13 [18432/50176]	Loss: 1.6457
Training Epoch: 13 [19456/50176]	Loss: 1.6817
Training Epoch: 13 [20480/50176]	Loss: 1.6689
Training Epoch: 13 [21504/50176]	Loss: 1.7080
Training Epoch: 13 [22528/50176]	Loss: 1.6670
Training Epoch: 13 [23552/50176]	Loss: 1.7357
Training Epoch: 13 [24576/50176]	Loss: 1.6907
Training Epoch: 13 [25600/50176]	Loss: 1.6932
Training Epoch: 13 [26624/50176]	Loss: 1.7735
Training Epoch: 13 [27648/50176]	Loss: 1.6649
Training Epoch: 13 [28672/50176]	Loss: 1.7142
Training Epoch: 13 [29696/50176]	Loss: 1.7088
Training Epoch: 13 [30720/50176]	Loss: 1.7109
Training Epoch: 13 [31744/50176]	Loss: 1.7384
Training Epoch: 13 [32768/50176]	Loss: 1.6169
Training Epoch: 13 [33792/50176]	Loss: 1.7467
Training Epoch: 13 [34816/50176]	Loss: 1.8102
Training Epoch: 13 [35840/50176]	Loss: 1.8271
Training Epoch: 13 [36864/50176]	Loss: 1.7080
Training Epoch: 13 [37888/50176]	Loss: 1.7824
Training Epoch: 13 [38912/50176]	Loss: 1.6175
Training Epoch: 13 [39936/50176]	Loss: 1.6950
Training Epoch: 13 [40960/50176]	Loss: 1.6677
Training Epoch: 13 [41984/50176]	Loss: 1.7463
Training Epoch: 13 [43008/50176]	Loss: 1.6347
Training Epoch: 13 [44032/50176]	Loss: 1.7643
Training Epoch: 13 [45056/50176]	Loss: 1.6927
Training Epoch: 13 [46080/50176]	Loss: 1.6501
Training Epoch: 13 [47104/50176]	Loss: 1.7082
Training Epoch: 13 [48128/50176]	Loss: 1.7111
Training Epoch: 13 [49152/50176]	Loss: 1.6177
Training Epoch: 13 [50176/50176]	Loss: 1.8394
2022-12-08 23:49:42.372 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:49:42,389 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.75 energy=514.81
2022-12-08 18:49:42,389 [ZeusDataLoader(train)] Up to epoch 14: time=769.85, energy=107358.49, cost=121041.39
2022-12-08 18:49:42,389 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:49:42,389 [ZeusDataLoader(train)] Expected next epoch: time=817.18, energy=114579.73, cost=128793.26
2022-12-08 18:49:42,390 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0021, Accuracy: 0.4581
2022-12-08 18:49:42,639 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:49:42,640 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:49:42.642 [ZeusMonitor] Monitor started.
2022-12-08 23:49:42.642 [ZeusMonitor] Running indefinitely. 2022-12-08 23:49:42.642 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:49:42.642 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e15+gpu0.power.log
2022-12-08 18:50:26,605 [ZeusDataLoader(train)] train epoch 15 done: time=44.21 energy=6723.44
2022-12-08 18:50:26,608 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.5586
Training Epoch: 14 [2048/50176]	Loss: 1.6423
Training Epoch: 14 [3072/50176]	Loss: 1.6316
Training Epoch: 14 [4096/50176]	Loss: 1.7124
Training Epoch: 14 [5120/50176]	Loss: 1.5668
Training Epoch: 14 [6144/50176]	Loss: 1.6185
Training Epoch: 14 [7168/50176]	Loss: 1.5581
Training Epoch: 14 [8192/50176]	Loss: 1.6196
Training Epoch: 14 [9216/50176]	Loss: 1.5383
Training Epoch: 14 [10240/50176]	Loss: 1.5797
Training Epoch: 14 [11264/50176]	Loss: 1.5939
Training Epoch: 14 [12288/50176]	Loss: 1.6405
Training Epoch: 14 [13312/50176]	Loss: 1.6312
Training Epoch: 14 [14336/50176]	Loss: 1.5757
Training Epoch: 14 [15360/50176]	Loss: 1.5826
Training Epoch: 14 [16384/50176]	Loss: 1.5207
Training Epoch: 14 [17408/50176]	Loss: 1.6674
Training Epoch: 14 [18432/50176]	Loss: 1.6133
Training Epoch: 14 [19456/50176]	Loss: 1.5524
Training Epoch: 14 [20480/50176]	Loss: 1.6382
Training Epoch: 14 [21504/50176]	Loss: 1.6613
Training Epoch: 14 [22528/50176]	Loss: 1.5819
Training Epoch: 14 [23552/50176]	Loss: 1.6082
Training Epoch: 14 [24576/50176]	Loss: 1.6267
Training Epoch: 14 [25600/50176]	Loss: 1.6704
Training Epoch: 14 [26624/50176]	Loss: 1.5703
Training Epoch: 14 [27648/50176]	Loss: 1.5288
Training Epoch: 14 [28672/50176]	Loss: 1.7004
Training Epoch: 14 [29696/50176]	Loss: 1.6098
Training Epoch: 14 [30720/50176]	Loss: 1.6083
Training Epoch: 14 [31744/50176]	Loss: 1.5871
Training Epoch: 14 [32768/50176]	Loss: 1.7279
Training Epoch: 14 [33792/50176]	Loss: 1.6684
Training Epoch: 14 [34816/50176]	Loss: 1.6361
Training Epoch: 14 [35840/50176]	Loss: 1.6680
Training Epoch: 14 [36864/50176]	Loss: 1.7580
Training Epoch: 14 [37888/50176]	Loss: 1.6178
Training Epoch: 14 [38912/50176]	Loss: 1.6732
Training Epoch: 14 [39936/50176]	Loss: 1.6482
Training Epoch: 14 [40960/50176]	Loss: 1.6602
Training Epoch: 14 [41984/50176]	Loss: 1.7177
Training Epoch: 14 [43008/50176]	Loss: 1.6652
Training Epoch: 14 [44032/50176]	Loss: 1.6125
Training Epoch: 14 [45056/50176]	Loss: 1.6755
Training Epoch: 14 [46080/50176]	Loss: 1.6055
Training Epoch: 14 [47104/50176]	Loss: 1.5527
Training Epoch: 14 [48128/50176]	Loss: 1.6133
Training Epoch: 14 [49152/50176]	Loss: 1.6313
Training Epoch: 14 [50176/50176]	Loss: 1.6787
2022-12-08 23:50:30.348 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:50:30,387 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.77 energy=513.83
2022-12-08 18:50:30,388 [ZeusDataLoader(train)] Up to epoch 15: time=817.83, energy=114595.76, cost=128857.92
2022-12-08 18:50:30,388 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:50:30,388 [ZeusDataLoader(train)] Expected next epoch: time=865.16, energy=121817.00, cost=136609.78
2022-12-08 18:50:30,389 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.5038
2022-12-08 18:50:30,641 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:50:30,642 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:50:30.643 [ZeusMonitor] Monitor started.
2022-12-08 23:50:30.644 [ZeusMonitor] Running indefinitely. 2022-12-08 23:50:30.644 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:50:30.644 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e16+gpu0.power.log
2022-12-08 18:51:14,672 [ZeusDataLoader(train)] train epoch 16 done: time=44.27 energy=6718.59
2022-12-08 18:51:14,675 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.6088
Training Epoch: 15 [2048/50176]	Loss: 1.5098
Training Epoch: 15 [3072/50176]	Loss: 1.5342
Training Epoch: 15 [4096/50176]	Loss: 1.5097
Training Epoch: 15 [5120/50176]	Loss: 1.5144
Training Epoch: 15 [6144/50176]	Loss: 1.5275
Training Epoch: 15 [7168/50176]	Loss: 1.4897
Training Epoch: 15 [8192/50176]	Loss: 1.5686
Training Epoch: 15 [9216/50176]	Loss: 1.5704
Training Epoch: 15 [10240/50176]	Loss: 1.5381
Training Epoch: 15 [11264/50176]	Loss: 1.5316
Training Epoch: 15 [12288/50176]	Loss: 1.6055
Training Epoch: 15 [13312/50176]	Loss: 1.5016
Training Epoch: 15 [14336/50176]	Loss: 1.5384
Training Epoch: 15 [15360/50176]	Loss: 1.6014
Training Epoch: 15 [16384/50176]	Loss: 1.6032
Training Epoch: 15 [17408/50176]	Loss: 1.5559
Training Epoch: 15 [18432/50176]	Loss: 1.5443
Training Epoch: 15 [19456/50176]	Loss: 1.5125
Training Epoch: 15 [20480/50176]	Loss: 1.4662
Training Epoch: 15 [21504/50176]	Loss: 1.4688
Training Epoch: 15 [22528/50176]	Loss: 1.6281
Training Epoch: 15 [23552/50176]	Loss: 1.5585
Training Epoch: 15 [24576/50176]	Loss: 1.4942
Training Epoch: 15 [25600/50176]	Loss: 1.5110
Training Epoch: 15 [26624/50176]	Loss: 1.5467
Training Epoch: 15 [27648/50176]	Loss: 1.5718
Training Epoch: 15 [28672/50176]	Loss: 1.4543
Training Epoch: 15 [29696/50176]	Loss: 1.5722
Training Epoch: 15 [30720/50176]	Loss: 1.5200
Training Epoch: 15 [31744/50176]	Loss: 1.5597
Training Epoch: 15 [32768/50176]	Loss: 1.5365
Training Epoch: 15 [33792/50176]	Loss: 1.4800
Training Epoch: 15 [34816/50176]	Loss: 1.6052
Training Epoch: 15 [35840/50176]	Loss: 1.5520
Training Epoch: 15 [36864/50176]	Loss: 1.5396
Training Epoch: 15 [37888/50176]	Loss: 1.5629
Training Epoch: 15 [38912/50176]	Loss: 1.4760
Training Epoch: 15 [39936/50176]	Loss: 1.5818
Training Epoch: 15 [40960/50176]	Loss: 1.5613
Training Epoch: 15 [41984/50176]	Loss: 1.5926
Training Epoch: 15 [43008/50176]	Loss: 1.5828
Training Epoch: 15 [44032/50176]	Loss: 1.5095
Training Epoch: 15 [45056/50176]	Loss: 1.5139
Training Epoch: 15 [46080/50176]	Loss: 1.5776
Training Epoch: 15 [47104/50176]	Loss: 1.4997
Training Epoch: 15 [48128/50176]	Loss: 1.5410
Training Epoch: 15 [49152/50176]	Loss: 1.4349
Training Epoch: 15 [50176/50176]	Loss: 1.4930
2022-12-08 23:51:18.482 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:51:18,534 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.85 energy=533.34
2022-12-08 18:51:18,534 [ZeusDataLoader(train)] Up to epoch 16: time=865.95, energy=121847.69, cost=136694.68
2022-12-08 18:51:18,534 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:51:18,534 [ZeusDataLoader(train)] Expected next epoch: time=913.28, energy=129068.93, cost=144446.55
2022-12-08 18:51:18,535 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0018, Accuracy: 0.5110
2022-12-08 18:51:18,793 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:51:18,794 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:51:18.796 [ZeusMonitor] Monitor started.
2022-12-08 23:51:18.796 [ZeusMonitor] Running indefinitely. 2022-12-08 23:51:18.796 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:51:18.796 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e17+gpu0.power.log
2022-12-08 18:52:02,847 [ZeusDataLoader(train)] train epoch 17 done: time=44.30 energy=6719.48
2022-12-08 18:52:02,852 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.4852
Training Epoch: 16 [2048/50176]	Loss: 1.4973
Training Epoch: 16 [3072/50176]	Loss: 1.5083
Training Epoch: 16 [4096/50176]	Loss: 1.4837
Training Epoch: 16 [5120/50176]	Loss: 1.4992
Training Epoch: 16 [6144/50176]	Loss: 1.4087
Training Epoch: 16 [7168/50176]	Loss: 1.4383
Training Epoch: 16 [8192/50176]	Loss: 1.3715
Training Epoch: 16 [9216/50176]	Loss: 1.4630
Training Epoch: 16 [10240/50176]	Loss: 1.4029
Training Epoch: 16 [11264/50176]	Loss: 1.4620
Training Epoch: 16 [12288/50176]	Loss: 1.4601
Training Epoch: 16 [13312/50176]	Loss: 1.4543
Training Epoch: 16 [14336/50176]	Loss: 1.4841
Training Epoch: 16 [15360/50176]	Loss: 1.5050
Training Epoch: 16 [16384/50176]	Loss: 1.4799
Training Epoch: 16 [17408/50176]	Loss: 1.4723
Training Epoch: 16 [18432/50176]	Loss: 1.5782
Training Epoch: 16 [19456/50176]	Loss: 1.4751
Training Epoch: 16 [20480/50176]	Loss: 1.4498
Training Epoch: 16 [21504/50176]	Loss: 1.4660
Training Epoch: 16 [22528/50176]	Loss: 1.4577
Training Epoch: 16 [23552/50176]	Loss: 1.5093
Training Epoch: 16 [24576/50176]	Loss: 1.5107
Training Epoch: 16 [25600/50176]	Loss: 1.4812
Training Epoch: 16 [26624/50176]	Loss: 1.4726
Training Epoch: 16 [27648/50176]	Loss: 1.5247
Training Epoch: 16 [28672/50176]	Loss: 1.5160
Training Epoch: 16 [29696/50176]	Loss: 1.4255
Training Epoch: 16 [30720/50176]	Loss: 1.4923
Training Epoch: 16 [31744/50176]	Loss: 1.5208
Training Epoch: 16 [32768/50176]	Loss: 1.5170
Training Epoch: 16 [33792/50176]	Loss: 1.4676
Training Epoch: 16 [34816/50176]	Loss: 1.4997
Training Epoch: 16 [35840/50176]	Loss: 1.5623
Training Epoch: 16 [36864/50176]	Loss: 1.5238
Training Epoch: 16 [37888/50176]	Loss: 1.4466
Training Epoch: 16 [38912/50176]	Loss: 1.4650
Training Epoch: 16 [39936/50176]	Loss: 1.5760
Training Epoch: 16 [40960/50176]	Loss: 1.5600
Training Epoch: 16 [41984/50176]	Loss: 1.4995
Training Epoch: 16 [43008/50176]	Loss: 1.4568
Training Epoch: 16 [44032/50176]	Loss: 1.4996
Training Epoch: 16 [45056/50176]	Loss: 1.5826
Training Epoch: 16 [46080/50176]	Loss: 1.5066
Training Epoch: 16 [47104/50176]	Loss: 1.5066
Training Epoch: 16 [48128/50176]	Loss: 1.5538
Training Epoch: 16 [49152/50176]	Loss: 1.5631
Training Epoch: 16 [50176/50176]	Loss: 1.4545
2022-12-08 23:52:06.647 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:52:06,699 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.84 energy=528.48
2022-12-08 18:52:06,699 [ZeusDataLoader(train)] Up to epoch 17: time=914.09, energy=129095.65, cost=144531.10
2022-12-08 18:52:06,699 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:52:06,699 [ZeusDataLoader(train)] Expected next epoch: time=961.42, energy=136316.89, cost=152282.96
2022-12-08 18:52:06,701 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0017, Accuracy: 0.5232
2022-12-08 18:52:06,957 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:52:06,958 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:52:06.960 [ZeusMonitor] Monitor started.
2022-12-08 23:52:06.972 [ZeusMonitor] Running indefinitely. 2022-12-08 23:52:06.972 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:52:06.972 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e18+gpu0.power.log
2022-12-08 18:52:51,005 [ZeusDataLoader(train)] train epoch 18 done: time=44.30 energy=6712.20
2022-12-08 18:52:51,009 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.3765
Training Epoch: 17 [2048/50176]	Loss: 1.3819
Training Epoch: 17 [3072/50176]	Loss: 1.2645
Training Epoch: 17 [4096/50176]	Loss: 1.3161
Training Epoch: 17 [5120/50176]	Loss: 1.4565
Training Epoch: 17 [6144/50176]	Loss: 1.4136
Training Epoch: 17 [7168/50176]	Loss: 1.3318
Training Epoch: 17 [8192/50176]	Loss: 1.3620
Training Epoch: 17 [9216/50176]	Loss: 1.4344
Training Epoch: 17 [10240/50176]	Loss: 1.3083
Training Epoch: 17 [11264/50176]	Loss: 1.3366
Training Epoch: 17 [12288/50176]	Loss: 1.3886
Training Epoch: 17 [13312/50176]	Loss: 1.3521
Training Epoch: 17 [14336/50176]	Loss: 1.3553
Training Epoch: 17 [15360/50176]	Loss: 1.3716
Training Epoch: 17 [16384/50176]	Loss: 1.3877
Training Epoch: 17 [17408/50176]	Loss: 1.4542
Training Epoch: 17 [18432/50176]	Loss: 1.4844
Training Epoch: 17 [19456/50176]	Loss: 1.3362
Training Epoch: 17 [20480/50176]	Loss: 1.4131
Training Epoch: 17 [21504/50176]	Loss: 1.4510
Training Epoch: 17 [22528/50176]	Loss: 1.4900
Training Epoch: 17 [23552/50176]	Loss: 1.3723
Training Epoch: 17 [24576/50176]	Loss: 1.4598
Training Epoch: 17 [25600/50176]	Loss: 1.4082
Training Epoch: 17 [26624/50176]	Loss: 1.4221
Training Epoch: 17 [27648/50176]	Loss: 1.4140
Training Epoch: 17 [28672/50176]	Loss: 1.4554
Training Epoch: 17 [29696/50176]	Loss: 1.4542
Training Epoch: 17 [30720/50176]	Loss: 1.5078
Training Epoch: 17 [31744/50176]	Loss: 1.4099
Training Epoch: 17 [32768/50176]	Loss: 1.3580
Training Epoch: 17 [33792/50176]	Loss: 1.4710
Training Epoch: 17 [34816/50176]	Loss: 1.4294
Training Epoch: 17 [35840/50176]	Loss: 1.3123
Training Epoch: 17 [36864/50176]	Loss: 1.4649
Training Epoch: 17 [37888/50176]	Loss: 1.4239
Training Epoch: 17 [38912/50176]	Loss: 1.5082
Training Epoch: 17 [39936/50176]	Loss: 1.4890
Training Epoch: 17 [40960/50176]	Loss: 1.4115
Training Epoch: 17 [41984/50176]	Loss: 1.5108
Training Epoch: 17 [43008/50176]	Loss: 1.4163
Training Epoch: 17 [44032/50176]	Loss: 1.4883
Training Epoch: 17 [45056/50176]	Loss: 1.4485
Training Epoch: 17 [46080/50176]	Loss: 1.3501
Training Epoch: 17 [47104/50176]	Loss: 1.3847
Training Epoch: 17 [48128/50176]	Loss: 1.4271
Training Epoch: 17 [49152/50176]	Loss: 1.4338
Training Epoch: 17 [50176/50176]	Loss: 1.4558
2022-12-08 23:52:54.803 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:52:54,845 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.83 energy=530.69
2022-12-08 18:52:54,845 [ZeusDataLoader(train)] Up to epoch 18: time=962.22, energy=136338.53, cost=152363.21
2022-12-08 18:52:54,845 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:52:54,845 [ZeusDataLoader(train)] Expected next epoch: time=1009.54, energy=143559.77, cost=160115.07
2022-12-08 18:52:54,846 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0019, Accuracy: 0.4804
2022-12-08 18:52:55,040 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:52:55,041 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:52:55.045 [ZeusMonitor] Monitor started.
2022-12-08 23:52:55.045 [ZeusMonitor] Running indefinitely. 2022-12-08 23:52:55.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:52:55.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e19+gpu0.power.log
2022-12-08 18:53:39,041 [ZeusDataLoader(train)] train epoch 19 done: time=44.19 energy=6709.53
2022-12-08 18:53:39,044 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.3323
Training Epoch: 18 [2048/50176]	Loss: 1.3730
Training Epoch: 18 [3072/50176]	Loss: 1.3475
Training Epoch: 18 [4096/50176]	Loss: 1.3463
Training Epoch: 18 [5120/50176]	Loss: 1.3277
Training Epoch: 18 [6144/50176]	Loss: 1.3324
Training Epoch: 18 [7168/50176]	Loss: 1.3123
Training Epoch: 18 [8192/50176]	Loss: 1.3502
Training Epoch: 18 [9216/50176]	Loss: 1.3174
Training Epoch: 18 [10240/50176]	Loss: 1.3071
Training Epoch: 18 [11264/50176]	Loss: 1.3396
Training Epoch: 18 [12288/50176]	Loss: 1.3009
Training Epoch: 18 [13312/50176]	Loss: 1.3674
Training Epoch: 18 [14336/50176]	Loss: 1.3414
Training Epoch: 18 [15360/50176]	Loss: 1.4386
Training Epoch: 18 [16384/50176]	Loss: 1.3669
Training Epoch: 18 [17408/50176]	Loss: 1.4119
Training Epoch: 18 [18432/50176]	Loss: 1.3649
Training Epoch: 18 [19456/50176]	Loss: 1.3965
Training Epoch: 18 [20480/50176]	Loss: 1.3436
Training Epoch: 18 [21504/50176]	Loss: 1.4045
Training Epoch: 18 [22528/50176]	Loss: 1.3970
Training Epoch: 18 [23552/50176]	Loss: 1.2743
Training Epoch: 18 [24576/50176]	Loss: 1.2914
Training Epoch: 18 [25600/50176]	Loss: 1.2928
Training Epoch: 18 [26624/50176]	Loss: 1.2139
Training Epoch: 18 [27648/50176]	Loss: 1.3572
Training Epoch: 18 [28672/50176]	Loss: 1.3580
Training Epoch: 18 [29696/50176]	Loss: 1.3918
Training Epoch: 18 [30720/50176]	Loss: 1.4165
Training Epoch: 18 [31744/50176]	Loss: 1.4606
Training Epoch: 18 [32768/50176]	Loss: 1.3684
Training Epoch: 18 [33792/50176]	Loss: 1.3978
Training Epoch: 18 [34816/50176]	Loss: 1.3197
Training Epoch: 18 [35840/50176]	Loss: 1.4642
Training Epoch: 18 [36864/50176]	Loss: 1.4128
Training Epoch: 18 [37888/50176]	Loss: 1.2872
Training Epoch: 18 [38912/50176]	Loss: 1.4065
Training Epoch: 18 [39936/50176]	Loss: 1.3857
Training Epoch: 18 [40960/50176]	Loss: 1.3667
Training Epoch: 18 [41984/50176]	Loss: 1.3735
Training Epoch: 18 [43008/50176]	Loss: 1.3505
Training Epoch: 18 [44032/50176]	Loss: 1.3812
Training Epoch: 18 [45056/50176]	Loss: 1.3470
Training Epoch: 18 [46080/50176]	Loss: 1.3695
Training Epoch: 18 [47104/50176]	Loss: 1.3660
Training Epoch: 18 [48128/50176]	Loss: 1.3299
Training Epoch: 18 [49152/50176]	Loss: 1.3484
Training Epoch: 18 [50176/50176]	Loss: 1.3852
2022-12-08 23:53:42.851 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:53:42,883 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.83 energy=529.09
2022-12-08 18:53:42,883 [ZeusDataLoader(train)] Up to epoch 19: time=1010.23, energy=143577.15, cost=160183.86
2022-12-08 18:53:42,883 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:53:42,883 [ZeusDataLoader(train)] Expected next epoch: time=1057.56, energy=150798.39, cost=167935.72
2022-12-08 18:53:42,884 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0017, Accuracy: 0.5224
2022-12-08 18:53:43,130 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:53:43,131 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:53:43.133 [ZeusMonitor] Monitor started.
2022-12-08 23:53:43.133 [ZeusMonitor] Running indefinitely. 2022-12-08 23:53:43.133 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:53:43.133 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e20+gpu0.power.log
2022-12-08 18:54:27,497 [ZeusDataLoader(train)] train epoch 20 done: time=44.60 energy=6776.97
2022-12-08 18:54:27,500 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.2241
Training Epoch: 19 [2048/50176]	Loss: 1.2721
Training Epoch: 19 [3072/50176]	Loss: 1.2142
Training Epoch: 19 [4096/50176]	Loss: 1.2821
Training Epoch: 19 [5120/50176]	Loss: 1.2538
Training Epoch: 19 [6144/50176]	Loss: 1.2617
Training Epoch: 19 [7168/50176]	Loss: 1.2272
Training Epoch: 19 [8192/50176]	Loss: 1.2317
Training Epoch: 19 [9216/50176]	Loss: 1.2522
Training Epoch: 19 [10240/50176]	Loss: 1.3418
Training Epoch: 19 [11264/50176]	Loss: 1.3300
Training Epoch: 19 [12288/50176]	Loss: 1.2912
Training Epoch: 19 [13312/50176]	Loss: 1.2978
Training Epoch: 19 [14336/50176]	Loss: 1.3138
Training Epoch: 19 [15360/50176]	Loss: 1.2896
Training Epoch: 19 [16384/50176]	Loss: 1.2840
Training Epoch: 19 [17408/50176]	Loss: 1.3697
Training Epoch: 19 [18432/50176]	Loss: 1.2722
Training Epoch: 19 [19456/50176]	Loss: 1.1878
Training Epoch: 19 [20480/50176]	Loss: 1.3307
Training Epoch: 19 [21504/50176]	Loss: 1.2335
Training Epoch: 19 [22528/50176]	Loss: 1.4234
Training Epoch: 19 [23552/50176]	Loss: 1.3984
Training Epoch: 19 [24576/50176]	Loss: 1.2286
Training Epoch: 19 [25600/50176]	Loss: 1.2631
Training Epoch: 19 [26624/50176]	Loss: 1.3585
Training Epoch: 19 [27648/50176]	Loss: 1.2358
Training Epoch: 19 [28672/50176]	Loss: 1.3194
Training Epoch: 19 [29696/50176]	Loss: 1.3542
Training Epoch: 19 [30720/50176]	Loss: 1.3510
Training Epoch: 19 [31744/50176]	Loss: 1.3467
Training Epoch: 19 [32768/50176]	Loss: 1.3775
Training Epoch: 19 [33792/50176]	Loss: 1.3060
Training Epoch: 19 [34816/50176]	Loss: 1.3237
Training Epoch: 19 [35840/50176]	Loss: 1.3205
Training Epoch: 19 [36864/50176]	Loss: 1.3145
Training Epoch: 19 [37888/50176]	Loss: 1.2900
Training Epoch: 19 [38912/50176]	Loss: 1.3570
Training Epoch: 19 [39936/50176]	Loss: 1.2637
Training Epoch: 19 [40960/50176]	Loss: 1.2496
Training Epoch: 19 [41984/50176]	Loss: 1.3649
Training Epoch: 19 [43008/50176]	Loss: 1.3410
Training Epoch: 19 [44032/50176]	Loss: 1.3109
Training Epoch: 19 [45056/50176]	Loss: 1.2926
Training Epoch: 19 [46080/50176]	Loss: 1.2889
Training Epoch: 19 [47104/50176]	Loss: 1.3319
Training Epoch: 19 [48128/50176]	Loss: 1.2169
Training Epoch: 19 [49152/50176]	Loss: 1.3830
Training Epoch: 19 [50176/50176]	Loss: 1.2842
2022-12-08 23:54:31.331 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:54:31,355 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.85 energy=533.27
2022-12-08 18:54:31,356 [ZeusDataLoader(train)] Up to epoch 20: time=1058.68, energy=150887.39, cost=168078.35
2022-12-08 18:54:31,356 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:54:31,356 [ZeusDataLoader(train)] Expected next epoch: time=1106.01, energy=158108.64, cost=175830.21
2022-12-08 18:54:31,357 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0017, Accuracy: 0.5371
2022-12-08 18:54:31,604 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:54:31,605 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:54:31.607 [ZeusMonitor] Monitor started.
2022-12-08 23:54:31.607 [ZeusMonitor] Running indefinitely. 2022-12-08 23:54:31.607 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:54:31.607 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e21+gpu0.power.log
2022-12-08 18:55:16,124 [ZeusDataLoader(train)] train epoch 21 done: time=44.76 energy=6806.51
2022-12-08 18:55:16,127 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.2095
Training Epoch: 20 [2048/50176]	Loss: 1.2392
Training Epoch: 20 [3072/50176]	Loss: 1.2355
Training Epoch: 20 [4096/50176]	Loss: 1.1389
Training Epoch: 20 [5120/50176]	Loss: 1.1911
Training Epoch: 20 [6144/50176]	Loss: 1.2580
Training Epoch: 20 [7168/50176]	Loss: 1.1921
Training Epoch: 20 [8192/50176]	Loss: 1.2019
Training Epoch: 20 [9216/50176]	Loss: 1.1751
Training Epoch: 20 [10240/50176]	Loss: 1.1878
Training Epoch: 20 [11264/50176]	Loss: 1.2472
Training Epoch: 20 [12288/50176]	Loss: 1.1917
Training Epoch: 20 [13312/50176]	Loss: 1.1665
Training Epoch: 20 [14336/50176]	Loss: 1.2383
Training Epoch: 20 [15360/50176]	Loss: 1.2394
Training Epoch: 20 [16384/50176]	Loss: 1.3126
Training Epoch: 20 [17408/50176]	Loss: 1.2234
Training Epoch: 20 [18432/50176]	Loss: 1.2835
Training Epoch: 20 [19456/50176]	Loss: 1.3259
Training Epoch: 20 [20480/50176]	Loss: 1.1968
Training Epoch: 20 [21504/50176]	Loss: 1.2874
Training Epoch: 20 [22528/50176]	Loss: 1.2471
Training Epoch: 20 [23552/50176]	Loss: 1.1387
Training Epoch: 20 [24576/50176]	Loss: 1.2817
Training Epoch: 20 [25600/50176]	Loss: 1.3212
Training Epoch: 20 [26624/50176]	Loss: 1.2531
Training Epoch: 20 [27648/50176]	Loss: 1.1714
Training Epoch: 20 [28672/50176]	Loss: 1.3261
Training Epoch: 20 [29696/50176]	Loss: 1.2132
Training Epoch: 20 [30720/50176]	Loss: 1.2321
Training Epoch: 20 [31744/50176]	Loss: 1.2620
Training Epoch: 20 [32768/50176]	Loss: 1.2634
Training Epoch: 20 [33792/50176]	Loss: 1.2262
Training Epoch: 20 [34816/50176]	Loss: 1.2802
Training Epoch: 20 [35840/50176]	Loss: 1.1811
Training Epoch: 20 [36864/50176]	Loss: 1.2662
Training Epoch: 20 [37888/50176]	Loss: 1.2005
Training Epoch: 20 [38912/50176]	Loss: 1.2470
Training Epoch: 20 [39936/50176]	Loss: 1.2577
Training Epoch: 20 [40960/50176]	Loss: 1.3298
Training Epoch: 20 [41984/50176]	Loss: 1.2782
Training Epoch: 20 [43008/50176]	Loss: 1.2056
Training Epoch: 20 [44032/50176]	Loss: 1.1399
Training Epoch: 20 [45056/50176]	Loss: 1.2393
Training Epoch: 20 [46080/50176]	Loss: 1.2207
Training Epoch: 20 [47104/50176]	Loss: 1.3225
Training Epoch: 20 [48128/50176]	Loss: 1.2460
Training Epoch: 20 [49152/50176]	Loss: 1.3243
Training Epoch: 20 [50176/50176]	Loss: 1.2882
2022-12-08 23:55:19.988 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:55:20,015 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.88 energy=541.06
2022-12-08 18:55:20,015 [ZeusDataLoader(train)] Up to epoch 21: time=1107.32, energy=158234.96, cost=176007.84
2022-12-08 18:55:20,015 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:55:20,015 [ZeusDataLoader(train)] Expected next epoch: time=1154.65, energy=165456.21, cost=183759.71
2022-12-08 18:55:20,016 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0017, Accuracy: 0.5259
2022-12-08 18:55:20,276 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:55:20,277 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:55:20.279 [ZeusMonitor] Monitor started.
2022-12-08 23:55:20.279 [ZeusMonitor] Running indefinitely. 2022-12-08 23:55:20.279 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:55:20.279 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e22+gpu0.power.log
2022-12-08 18:56:04,679 [ZeusDataLoader(train)] train epoch 22 done: time=44.65 energy=6787.83
2022-12-08 18:56:04,682 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.1557
Training Epoch: 21 [2048/50176]	Loss: 1.1344
Training Epoch: 21 [3072/50176]	Loss: 1.1732
Training Epoch: 21 [4096/50176]	Loss: 1.2098
Training Epoch: 21 [5120/50176]	Loss: 1.1165
Training Epoch: 21 [6144/50176]	Loss: 1.1445
Training Epoch: 21 [7168/50176]	Loss: 1.0880
Training Epoch: 21 [8192/50176]	Loss: 1.1651
Training Epoch: 21 [9216/50176]	Loss: 1.1657
Training Epoch: 21 [10240/50176]	Loss: 1.1280
Training Epoch: 21 [11264/50176]	Loss: 1.1346
Training Epoch: 21 [12288/50176]	Loss: 1.1333
Training Epoch: 21 [13312/50176]	Loss: 1.1544
Training Epoch: 21 [14336/50176]	Loss: 1.1972
Training Epoch: 21 [15360/50176]	Loss: 1.1489
Training Epoch: 21 [16384/50176]	Loss: 1.2013
Training Epoch: 21 [17408/50176]	Loss: 1.1298
Training Epoch: 21 [18432/50176]	Loss: 1.1363
Training Epoch: 21 [19456/50176]	Loss: 1.2138
Training Epoch: 21 [20480/50176]	Loss: 1.2018
Training Epoch: 21 [21504/50176]	Loss: 1.2186
Training Epoch: 21 [22528/50176]	Loss: 1.2671
Training Epoch: 21 [23552/50176]	Loss: 1.2380
Training Epoch: 21 [24576/50176]	Loss: 1.1718
Training Epoch: 21 [25600/50176]	Loss: 1.2146
Training Epoch: 21 [26624/50176]	Loss: 1.2360
Training Epoch: 21 [27648/50176]	Loss: 1.1912
Training Epoch: 21 [28672/50176]	Loss: 1.1401
Training Epoch: 21 [29696/50176]	Loss: 1.2544
Training Epoch: 21 [30720/50176]	Loss: 1.1843
Training Epoch: 21 [31744/50176]	Loss: 1.2140
Training Epoch: 21 [32768/50176]	Loss: 1.2265
Training Epoch: 21 [33792/50176]	Loss: 1.1742
Training Epoch: 21 [34816/50176]	Loss: 1.1431
Training Epoch: 21 [35840/50176]	Loss: 1.2230
Training Epoch: 21 [36864/50176]	Loss: 1.1617
Training Epoch: 21 [37888/50176]	Loss: 1.3046
Training Epoch: 21 [38912/50176]	Loss: 1.2286
Training Epoch: 21 [39936/50176]	Loss: 1.2483
Training Epoch: 21 [40960/50176]	Loss: 1.2012
Training Epoch: 21 [41984/50176]	Loss: 1.2144
Training Epoch: 21 [43008/50176]	Loss: 1.2422
Training Epoch: 21 [44032/50176]	Loss: 1.2820
Training Epoch: 21 [45056/50176]	Loss: 1.2149
Training Epoch: 21 [46080/50176]	Loss: 1.2343
Training Epoch: 21 [47104/50176]	Loss: 1.2823
Training Epoch: 21 [48128/50176]	Loss: 1.2441
Training Epoch: 21 [49152/50176]	Loss: 1.2386
Training Epoch: 21 [50176/50176]	Loss: 1.2359
2022-12-08 23:56:08.468 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:56:08,501 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=536.53
2022-12-08 18:56:08,501 [ZeusDataLoader(train)] Up to epoch 22: time=1155.78, energy=165559.33, cost=183910.56
2022-12-08 18:56:08,501 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:56:08,501 [ZeusDataLoader(train)] Expected next epoch: time=1203.11, energy=172780.57, cost=191662.42
2022-12-08 18:56:08,502 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0017, Accuracy: 0.5335
2022-12-08 18:56:08,775 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:56:08,776 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:56:08.778 [ZeusMonitor] Monitor started.
2022-12-08 23:56:08.778 [ZeusMonitor] Running indefinitely. 2022-12-08 23:56:08.778 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:56:08.778 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e23+gpu0.power.log
2022-12-08 18:56:52,671 [ZeusDataLoader(train)] train epoch 23 done: time=44.16 energy=6703.69
2022-12-08 18:56:52,674 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.1833
Training Epoch: 22 [2048/50176]	Loss: 1.1434
Training Epoch: 22 [3072/50176]	Loss: 1.1101
Training Epoch: 22 [4096/50176]	Loss: 0.9956
Training Epoch: 22 [5120/50176]	Loss: 1.0924
Training Epoch: 22 [6144/50176]	Loss: 1.1465
Training Epoch: 22 [7168/50176]	Loss: 1.1217
Training Epoch: 22 [8192/50176]	Loss: 1.2005
Training Epoch: 22 [9216/50176]	Loss: 1.1457
Training Epoch: 22 [10240/50176]	Loss: 1.0664
Training Epoch: 22 [11264/50176]	Loss: 1.1789
Training Epoch: 22 [12288/50176]	Loss: 1.1829
Training Epoch: 22 [13312/50176]	Loss: 1.0314
Training Epoch: 22 [14336/50176]	Loss: 1.1017
Training Epoch: 22 [15360/50176]	Loss: 1.1030
Training Epoch: 22 [16384/50176]	Loss: 1.1343
Training Epoch: 22 [17408/50176]	Loss: 1.0922
Training Epoch: 22 [18432/50176]	Loss: 1.1032
Training Epoch: 22 [19456/50176]	Loss: 1.1472
Training Epoch: 22 [20480/50176]	Loss: 1.1768
Training Epoch: 22 [21504/50176]	Loss: 1.1212
Training Epoch: 22 [22528/50176]	Loss: 1.2524
Training Epoch: 22 [23552/50176]	Loss: 1.1749
Training Epoch: 22 [24576/50176]	Loss: 1.1420
Training Epoch: 22 [25600/50176]	Loss: 1.1321
Training Epoch: 22 [26624/50176]	Loss: 1.2298
Training Epoch: 22 [27648/50176]	Loss: 1.1671
Training Epoch: 22 [28672/50176]	Loss: 1.1905
Training Epoch: 22 [29696/50176]	Loss: 1.2225
Training Epoch: 22 [30720/50176]	Loss: 1.1029
Training Epoch: 22 [31744/50176]	Loss: 1.2413
Training Epoch: 22 [32768/50176]	Loss: 1.1542
Training Epoch: 22 [33792/50176]	Loss: 1.1936
Training Epoch: 22 [34816/50176]	Loss: 1.1827
Training Epoch: 22 [35840/50176]	Loss: 1.1436
Training Epoch: 22 [36864/50176]	Loss: 1.1116
Training Epoch: 22 [37888/50176]	Loss: 1.1526
Training Epoch: 22 [38912/50176]	Loss: 1.0867
Training Epoch: 22 [39936/50176]	Loss: 1.1597
Training Epoch: 22 [40960/50176]	Loss: 1.1576
Training Epoch: 22 [41984/50176]	Loss: 1.2348
Training Epoch: 22 [43008/50176]	Loss: 1.1911
Training Epoch: 22 [44032/50176]	Loss: 1.1003
Training Epoch: 22 [45056/50176]	Loss: 1.1709
Training Epoch: 22 [46080/50176]	Loss: 1.1157
Training Epoch: 22 [47104/50176]	Loss: 1.1189
Training Epoch: 22 [48128/50176]	Loss: 1.2705
Training Epoch: 22 [49152/50176]	Loss: 1.2085
Training Epoch: 22 [50176/50176]	Loss: 1.0984
2022-12-08 23:56:56.411 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:56:56,434 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.75 energy=516.83
2022-12-08 18:56:56,434 [ZeusDataLoader(train)] Up to epoch 23: time=1203.69, energy=172779.85, cost=191713.00
2022-12-08 18:56:56,435 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:56:56,435 [ZeusDataLoader(train)] Expected next epoch: time=1251.02, energy=180001.09, cost=199464.87
2022-12-08 18:56:56,436 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0017, Accuracy: 0.5431
2022-12-08 18:56:56,682 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:56:56,683 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:56:56.693 [ZeusMonitor] Monitor started.
2022-12-08 23:56:56.693 [ZeusMonitor] Running indefinitely. 2022-12-08 23:56:56.693 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:56:56.693 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e24+gpu0.power.log
2022-12-08 18:57:40,660 [ZeusDataLoader(train)] train epoch 24 done: time=44.22 energy=6705.98
2022-12-08 18:57:40,663 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.0774
Training Epoch: 23 [2048/50176]	Loss: 1.0672
Training Epoch: 23 [3072/50176]	Loss: 1.0261
Training Epoch: 23 [4096/50176]	Loss: 1.0642
Training Epoch: 23 [5120/50176]	Loss: 1.0519
Training Epoch: 23 [6144/50176]	Loss: 1.0768
Training Epoch: 23 [7168/50176]	Loss: 1.0942
Training Epoch: 23 [8192/50176]	Loss: 1.0584
Training Epoch: 23 [9216/50176]	Loss: 1.0585
Training Epoch: 23 [10240/50176]	Loss: 1.0482
Training Epoch: 23 [11264/50176]	Loss: 1.0809
Training Epoch: 23 [12288/50176]	Loss: 0.9921
Training Epoch: 23 [13312/50176]	Loss: 1.1719
Training Epoch: 23 [14336/50176]	Loss: 1.1051
Training Epoch: 23 [15360/50176]	Loss: 1.0718
Training Epoch: 23 [16384/50176]	Loss: 1.1028
Training Epoch: 23 [17408/50176]	Loss: 1.1567
Training Epoch: 23 [18432/50176]	Loss: 1.0124
Training Epoch: 23 [19456/50176]	Loss: 1.1077
Training Epoch: 23 [20480/50176]	Loss: 1.0794
Training Epoch: 23 [21504/50176]	Loss: 1.0935
Training Epoch: 23 [22528/50176]	Loss: 1.0708
Training Epoch: 23 [23552/50176]	Loss: 1.0354
Training Epoch: 23 [24576/50176]	Loss: 1.0720
Training Epoch: 23 [25600/50176]	Loss: 1.1277
Training Epoch: 23 [26624/50176]	Loss: 1.1030
Training Epoch: 23 [27648/50176]	Loss: 1.0800
Training Epoch: 23 [28672/50176]	Loss: 1.0790
Training Epoch: 23 [29696/50176]	Loss: 1.1190
Training Epoch: 23 [30720/50176]	Loss: 1.0864
Training Epoch: 23 [31744/50176]	Loss: 1.1559
Training Epoch: 23 [32768/50176]	Loss: 1.1398
Training Epoch: 23 [33792/50176]	Loss: 1.1015
Training Epoch: 23 [34816/50176]	Loss: 1.1548
Training Epoch: 23 [35840/50176]	Loss: 1.1083
Training Epoch: 23 [36864/50176]	Loss: 1.0560
Training Epoch: 23 [37888/50176]	Loss: 1.1283
Training Epoch: 23 [38912/50176]	Loss: 1.1930
Training Epoch: 23 [39936/50176]	Loss: 1.2007
Training Epoch: 23 [40960/50176]	Loss: 1.1638
Training Epoch: 23 [41984/50176]	Loss: 1.1260
Training Epoch: 23 [43008/50176]	Loss: 1.0947
Training Epoch: 23 [44032/50176]	Loss: 1.1886
Training Epoch: 23 [45056/50176]	Loss: 1.1636
Training Epoch: 23 [46080/50176]	Loss: 1.2342
Training Epoch: 23 [47104/50176]	Loss: 1.1706
Training Epoch: 23 [48128/50176]	Loss: 1.1241
Training Epoch: 23 [49152/50176]	Loss: 1.0984
Training Epoch: 23 [50176/50176]	Loss: 1.0993
2022-12-08 23:57:44.467 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:57:44,497 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.83 energy=532.36
2022-12-08 18:57:44,498 [ZeusDataLoader(train)] Up to epoch 24: time=1251.73, energy=180018.19, cost=199535.75
2022-12-08 18:57:44,498 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:57:44,498 [ZeusDataLoader(train)] Expected next epoch: time=1299.06, energy=187239.43, cost=207287.61
2022-12-08 18:57:44,499 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0016, Accuracy: 0.5648
2022-12-08 18:57:44,740 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:57:44,741 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:57:44.742 [ZeusMonitor] Monitor started.
2022-12-08 23:57:44.743 [ZeusMonitor] Running indefinitely. 2022-12-08 23:57:44.743 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:57:44.743 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e25+gpu0.power.log
2022-12-08 18:58:28,750 [ZeusDataLoader(train)] train epoch 25 done: time=44.24 energy=6718.51
2022-12-08 18:58:28,753 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.9954
Training Epoch: 24 [2048/50176]	Loss: 0.9520
Training Epoch: 24 [3072/50176]	Loss: 1.0276
Training Epoch: 24 [4096/50176]	Loss: 0.9614
Training Epoch: 24 [5120/50176]	Loss: 0.9882
Training Epoch: 24 [6144/50176]	Loss: 0.9703
Training Epoch: 24 [7168/50176]	Loss: 1.0540
Training Epoch: 24 [8192/50176]	Loss: 0.9906
Training Epoch: 24 [9216/50176]	Loss: 1.0153
Training Epoch: 24 [10240/50176]	Loss: 1.0039
Training Epoch: 24 [11264/50176]	Loss: 0.9797
Training Epoch: 24 [12288/50176]	Loss: 0.9779
Training Epoch: 24 [13312/50176]	Loss: 1.0253
Training Epoch: 24 [14336/50176]	Loss: 1.0227
Training Epoch: 24 [15360/50176]	Loss: 0.9822
Training Epoch: 24 [16384/50176]	Loss: 0.9356
Training Epoch: 24 [17408/50176]	Loss: 1.0719
Training Epoch: 24 [18432/50176]	Loss: 1.0341
Training Epoch: 24 [19456/50176]	Loss: 1.0886
Training Epoch: 24 [20480/50176]	Loss: 1.0266
Training Epoch: 24 [21504/50176]	Loss: 1.0388
Training Epoch: 24 [22528/50176]	Loss: 1.0349
Training Epoch: 24 [23552/50176]	Loss: 1.0887
Training Epoch: 24 [24576/50176]	Loss: 1.0053
Training Epoch: 24 [25600/50176]	Loss: 1.0373
Training Epoch: 24 [26624/50176]	Loss: 1.0374
Training Epoch: 24 [27648/50176]	Loss: 1.0850
Training Epoch: 24 [28672/50176]	Loss: 1.0206
Training Epoch: 24 [29696/50176]	Loss: 1.0418
Training Epoch: 24 [30720/50176]	Loss: 1.1256
Training Epoch: 24 [31744/50176]	Loss: 1.1192
Training Epoch: 24 [32768/50176]	Loss: 1.0467
Training Epoch: 24 [33792/50176]	Loss: 1.0266
Training Epoch: 24 [34816/50176]	Loss: 1.1512
Training Epoch: 24 [35840/50176]	Loss: 1.1669
Training Epoch: 24 [36864/50176]	Loss: 1.0356
Training Epoch: 24 [37888/50176]	Loss: 1.0351
Training Epoch: 24 [38912/50176]	Loss: 1.1560
Training Epoch: 24 [39936/50176]	Loss: 1.0034
Training Epoch: 24 [40960/50176]	Loss: 1.0907
Training Epoch: 24 [41984/50176]	Loss: 1.1219
Training Epoch: 24 [43008/50176]	Loss: 1.1272
Training Epoch: 24 [44032/50176]	Loss: 0.9822
Training Epoch: 24 [45056/50176]	Loss: 1.0923
Training Epoch: 24 [46080/50176]	Loss: 1.0459
Training Epoch: 24 [47104/50176]	Loss: 1.1726
Training Epoch: 24 [48128/50176]	Loss: 1.2020
Training Epoch: 24 [49152/50176]	Loss: 1.0799
Training Epoch: 24 [50176/50176]	Loss: 1.1293
2022-12-08 23:58:32.519 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:58:32,544 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.78 energy=516.49
2022-12-08 18:58:32,544 [ZeusDataLoader(train)] Up to epoch 25: time=1299.76, energy=187253.19, cost=207355.36
2022-12-08 18:58:32,544 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:58:32,544 [ZeusDataLoader(train)] Expected next epoch: time=1347.09, energy=194474.43, cost=215107.22
2022-12-08 18:58:32,545 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0016, Accuracy: 0.5677
2022-12-08 18:58:32,790 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:58:32,791 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:58:32.805 [ZeusMonitor] Monitor started.
2022-12-08 23:58:32.805 [ZeusMonitor] Running indefinitely. 2022-12-08 23:58:32.805 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:58:32.805 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e26+gpu0.power.log
2022-12-08 18:59:16,747 [ZeusDataLoader(train)] train epoch 26 done: time=44.19 energy=6704.75
2022-12-08 18:59:16,750 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.8872
Training Epoch: 25 [2048/50176]	Loss: 0.9386
Training Epoch: 25 [3072/50176]	Loss: 0.9571
Training Epoch: 25 [4096/50176]	Loss: 0.9930
Training Epoch: 25 [5120/50176]	Loss: 0.9308
Training Epoch: 25 [6144/50176]	Loss: 0.9995
Training Epoch: 25 [7168/50176]	Loss: 0.9707
Training Epoch: 25 [8192/50176]	Loss: 0.9748
Training Epoch: 25 [9216/50176]	Loss: 1.0238
Training Epoch: 25 [10240/50176]	Loss: 0.9585
Training Epoch: 25 [11264/50176]	Loss: 0.9658
Training Epoch: 25 [12288/50176]	Loss: 0.9247
Training Epoch: 25 [13312/50176]	Loss: 0.9508
Training Epoch: 25 [14336/50176]	Loss: 0.9506
Training Epoch: 25 [15360/50176]	Loss: 1.0044
Training Epoch: 25 [16384/50176]	Loss: 0.9806
Training Epoch: 25 [17408/50176]	Loss: 0.9437
Training Epoch: 25 [18432/50176]	Loss: 1.0469
Training Epoch: 25 [19456/50176]	Loss: 0.9728
Training Epoch: 25 [20480/50176]	Loss: 0.9962
Training Epoch: 25 [21504/50176]	Loss: 0.9471
Training Epoch: 25 [22528/50176]	Loss: 1.0443
Training Epoch: 25 [23552/50176]	Loss: 1.0117
Training Epoch: 25 [24576/50176]	Loss: 0.9801
Training Epoch: 25 [25600/50176]	Loss: 0.9897
Training Epoch: 25 [26624/50176]	Loss: 1.0510
Training Epoch: 25 [27648/50176]	Loss: 1.0121
Training Epoch: 25 [28672/50176]	Loss: 1.0196
Training Epoch: 25 [29696/50176]	Loss: 1.0048
Training Epoch: 25 [30720/50176]	Loss: 1.0326
Training Epoch: 25 [31744/50176]	Loss: 0.9883
Training Epoch: 25 [32768/50176]	Loss: 1.0412
Training Epoch: 25 [33792/50176]	Loss: 0.9328
Training Epoch: 25 [34816/50176]	Loss: 1.0235
Training Epoch: 25 [35840/50176]	Loss: 0.9950
Training Epoch: 25 [36864/50176]	Loss: 1.0264
Training Epoch: 25 [37888/50176]	Loss: 0.9682
Training Epoch: 25 [38912/50176]	Loss: 1.0300
Training Epoch: 25 [39936/50176]	Loss: 1.0502
Training Epoch: 25 [40960/50176]	Loss: 1.0422
Training Epoch: 25 [41984/50176]	Loss: 1.0626
Training Epoch: 25 [43008/50176]	Loss: 1.0652
Training Epoch: 25 [44032/50176]	Loss: 1.0420
Training Epoch: 25 [45056/50176]	Loss: 1.1034
Training Epoch: 25 [46080/50176]	Loss: 1.1080
Training Epoch: 25 [47104/50176]	Loss: 1.0809
Training Epoch: 25 [48128/50176]	Loss: 1.0889
Training Epoch: 25 [49152/50176]	Loss: 1.0908
Training Epoch: 25 [50176/50176]	Loss: 1.0768
2022-12-08 23:59:20.488 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:59:20,506 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.75 energy=524.81
2022-12-08 18:59:20,506 [ZeusDataLoader(train)] Up to epoch 26: time=1347.70, energy=194482.75, cost=215164.88
2022-12-08 18:59:20,506 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 18:59:20,506 [ZeusDataLoader(train)] Expected next epoch: time=1395.03, energy=201703.99, cost=222916.74
2022-12-08 18:59:20,507 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0016, Accuracy: 0.5710
2022-12-08 18:59:20,761 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:59:20,762 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:59:20.764 [ZeusMonitor] Monitor started.
2022-12-08 23:59:20.764 [ZeusMonitor] Running indefinitely. 2022-12-08 23:59:20.764 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:59:20.764 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e27+gpu0.power.log
2022-12-08 19:00:04,788 [ZeusDataLoader(train)] train epoch 27 done: time=44.27 energy=6714.75
2022-12-08 19:00:04,792 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.8971
Training Epoch: 26 [2048/50176]	Loss: 0.9755
Training Epoch: 26 [3072/50176]	Loss: 0.9845
Training Epoch: 26 [4096/50176]	Loss: 0.9280
Training Epoch: 26 [5120/50176]	Loss: 0.9684
Training Epoch: 26 [6144/50176]	Loss: 0.9460
Training Epoch: 26 [7168/50176]	Loss: 0.9338
Training Epoch: 26 [8192/50176]	Loss: 0.9020
Training Epoch: 26 [9216/50176]	Loss: 0.8566
Training Epoch: 26 [10240/50176]	Loss: 0.9497
Training Epoch: 26 [11264/50176]	Loss: 0.9917
Training Epoch: 26 [12288/50176]	Loss: 0.8937
Training Epoch: 26 [13312/50176]	Loss: 0.8328
Training Epoch: 26 [14336/50176]	Loss: 0.8880
Training Epoch: 26 [15360/50176]	Loss: 0.8912
Training Epoch: 26 [16384/50176]	Loss: 0.8849
Training Epoch: 26 [17408/50176]	Loss: 0.8960
Training Epoch: 26 [18432/50176]	Loss: 0.9488
Training Epoch: 26 [19456/50176]	Loss: 1.0033
Training Epoch: 26 [20480/50176]	Loss: 0.9378
Training Epoch: 26 [21504/50176]	Loss: 0.9205
Training Epoch: 26 [22528/50176]	Loss: 0.8861
Training Epoch: 26 [23552/50176]	Loss: 0.9580
Training Epoch: 26 [24576/50176]	Loss: 0.9253
Training Epoch: 26 [25600/50176]	Loss: 0.9259
Training Epoch: 26 [26624/50176]	Loss: 0.9543
Training Epoch: 26 [27648/50176]	Loss: 1.0039
Training Epoch: 26 [28672/50176]	Loss: 0.9504
Training Epoch: 26 [29696/50176]	Loss: 0.9544
Training Epoch: 26 [30720/50176]	Loss: 0.9989
Training Epoch: 26 [31744/50176]	Loss: 0.9821
Training Epoch: 26 [32768/50176]	Loss: 0.9397
Training Epoch: 26 [33792/50176]	Loss: 1.0519
Training Epoch: 26 [34816/50176]	Loss: 0.9988
Training Epoch: 26 [35840/50176]	Loss: 0.9787
Training Epoch: 26 [36864/50176]	Loss: 0.9488
Training Epoch: 26 [37888/50176]	Loss: 1.0217
Training Epoch: 26 [38912/50176]	Loss: 0.9728
Training Epoch: 26 [39936/50176]	Loss: 1.0729
Training Epoch: 26 [40960/50176]	Loss: 0.9850
Training Epoch: 26 [41984/50176]	Loss: 1.0357
Training Epoch: 26 [43008/50176]	Loss: 1.0249
Training Epoch: 26 [44032/50176]	Loss: 1.0108
Training Epoch: 26 [45056/50176]	Loss: 0.9838
Training Epoch: 26 [46080/50176]	Loss: 1.0483
Training Epoch: 26 [47104/50176]	Loss: 0.9876
Training Epoch: 26 [48128/50176]	Loss: 1.0305
Training Epoch: 26 [49152/50176]	Loss: 0.9522
Training Epoch: 26 [50176/50176]	Loss: 1.0194
2022-12-09 00:00:08.634 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:00:08,654 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.85 energy=528.33
2022-12-08 19:00:08,654 [ZeusDataLoader(train)] Up to epoch 27: time=1395.82, energy=201725.83, cost=222997.40
2022-12-08 19:00:08,654 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:00:08,654 [ZeusDataLoader(train)] Expected next epoch: time=1443.15, energy=208947.07, cost=230749.27
2022-12-08 19:00:08,655 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0018, Accuracy: 0.5520
2022-12-08 19:00:08,868 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:00:08,869 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:00:08.873 [ZeusMonitor] Monitor started.
2022-12-09 00:00:08.873 [ZeusMonitor] Running indefinitely. 2022-12-09 00:00:08.873 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:00:08.873 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e28+gpu0.power.log
2022-12-08 19:00:52,887 [ZeusDataLoader(train)] train epoch 28 done: time=44.22 energy=6702.61
2022-12-08 19:00:52,890 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.8357
Training Epoch: 27 [2048/50176]	Loss: 0.8820
Training Epoch: 27 [3072/50176]	Loss: 0.8543
Training Epoch: 27 [4096/50176]	Loss: 0.9306
Training Epoch: 27 [5120/50176]	Loss: 0.8524
Training Epoch: 27 [6144/50176]	Loss: 0.8992
Training Epoch: 27 [7168/50176]	Loss: 0.8345
Training Epoch: 27 [8192/50176]	Loss: 0.9068
Training Epoch: 27 [9216/50176]	Loss: 0.8938
Training Epoch: 27 [10240/50176]	Loss: 0.9015
Training Epoch: 27 [11264/50176]	Loss: 0.8870
Training Epoch: 27 [12288/50176]	Loss: 0.8672
Training Epoch: 27 [13312/50176]	Loss: 0.8808
Training Epoch: 27 [14336/50176]	Loss: 0.9021
Training Epoch: 27 [15360/50176]	Loss: 0.8973
Training Epoch: 27 [16384/50176]	Loss: 0.9267
Training Epoch: 27 [17408/50176]	Loss: 0.8731
Training Epoch: 27 [18432/50176]	Loss: 0.9164
Training Epoch: 27 [19456/50176]	Loss: 0.9079
Training Epoch: 27 [20480/50176]	Loss: 0.8991
Training Epoch: 27 [21504/50176]	Loss: 0.9583
Training Epoch: 27 [22528/50176]	Loss: 0.9079
Training Epoch: 27 [23552/50176]	Loss: 0.8656
Training Epoch: 27 [24576/50176]	Loss: 0.9711
Training Epoch: 27 [25600/50176]	Loss: 0.9265
Training Epoch: 27 [26624/50176]	Loss: 0.9516
Training Epoch: 27 [27648/50176]	Loss: 0.9286
Training Epoch: 27 [28672/50176]	Loss: 0.9134
Training Epoch: 27 [29696/50176]	Loss: 0.9094
Training Epoch: 27 [30720/50176]	Loss: 0.9041
Training Epoch: 27 [31744/50176]	Loss: 0.9863
Training Epoch: 27 [32768/50176]	Loss: 0.9758
Training Epoch: 27 [33792/50176]	Loss: 0.9517
Training Epoch: 27 [34816/50176]	Loss: 1.0407
Training Epoch: 27 [35840/50176]	Loss: 1.0051
Training Epoch: 27 [36864/50176]	Loss: 0.9055
Training Epoch: 27 [37888/50176]	Loss: 0.9473
Training Epoch: 27 [38912/50176]	Loss: 0.9533
Training Epoch: 27 [39936/50176]	Loss: 1.0124
Training Epoch: 27 [40960/50176]	Loss: 0.9876
Training Epoch: 27 [41984/50176]	Loss: 0.9407
Training Epoch: 27 [43008/50176]	Loss: 0.9330
Training Epoch: 27 [44032/50176]	Loss: 1.0044
Training Epoch: 27 [45056/50176]	Loss: 0.9546
Training Epoch: 27 [46080/50176]	Loss: 0.9792
Training Epoch: 27 [47104/50176]	Loss: 1.0376
Training Epoch: 27 [48128/50176]	Loss: 0.9544
Training Epoch: 27 [49152/50176]	Loss: 0.9966
Training Epoch: 27 [50176/50176]	Loss: 1.0095
2022-12-09 00:00:56.683 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:00:56,738 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.84 energy=527.98
2022-12-08 19:00:56,739 [ZeusDataLoader(train)] Up to epoch 28: time=1443.88, energy=208956.42, cost=230818.14
2022-12-08 19:00:56,739 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:00:56,739 [ZeusDataLoader(train)] Expected next epoch: time=1491.21, energy=216177.66, cost=238570.00
2022-12-08 19:00:56,740 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0024, Accuracy: 0.4645
2022-12-08 19:00:56,997 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:00:56,998 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:00:57.000 [ZeusMonitor] Monitor started.
2022-12-09 00:00:57.000 [ZeusMonitor] Running indefinitely. 2022-12-09 00:00:57.000 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:00:57.000 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e29+gpu0.power.log
2022-12-08 19:01:41,061 [ZeusDataLoader(train)] train epoch 29 done: time=44.31 energy=6718.55
2022-12-08 19:01:41,065 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.8096
Training Epoch: 28 [2048/50176]	Loss: 0.8838
Training Epoch: 28 [3072/50176]	Loss: 0.8028
Training Epoch: 28 [4096/50176]	Loss: 0.9359
Training Epoch: 28 [5120/50176]	Loss: 0.8376
Training Epoch: 28 [6144/50176]	Loss: 0.8143
Training Epoch: 28 [7168/50176]	Loss: 0.7993
Training Epoch: 28 [8192/50176]	Loss: 0.8115
Training Epoch: 28 [9216/50176]	Loss: 0.8689
Training Epoch: 28 [10240/50176]	Loss: 0.8315
Training Epoch: 28 [11264/50176]	Loss: 0.8009
Training Epoch: 28 [12288/50176]	Loss: 0.8920
Training Epoch: 28 [13312/50176]	Loss: 0.8220
Training Epoch: 28 [14336/50176]	Loss: 0.8908
Training Epoch: 28 [15360/50176]	Loss: 0.9176
Training Epoch: 28 [16384/50176]	Loss: 0.8981
Training Epoch: 28 [17408/50176]	Loss: 0.8787
Training Epoch: 28 [18432/50176]	Loss: 0.8101
Training Epoch: 28 [19456/50176]	Loss: 0.9265
Training Epoch: 28 [20480/50176]	Loss: 0.8446
Training Epoch: 28 [21504/50176]	Loss: 0.8798
Training Epoch: 28 [22528/50176]	Loss: 0.9526
Training Epoch: 28 [23552/50176]	Loss: 0.9124
Training Epoch: 28 [24576/50176]	Loss: 0.8080
Training Epoch: 28 [25600/50176]	Loss: 0.8694
Training Epoch: 28 [26624/50176]	Loss: 0.9140
Training Epoch: 28 [27648/50176]	Loss: 0.9211
Training Epoch: 28 [28672/50176]	Loss: 0.8887
Training Epoch: 28 [29696/50176]	Loss: 0.8882
Training Epoch: 28 [30720/50176]	Loss: 0.9076
Training Epoch: 28 [31744/50176]	Loss: 0.8922
Training Epoch: 28 [32768/50176]	Loss: 0.8631
Training Epoch: 28 [33792/50176]	Loss: 0.8673
Training Epoch: 28 [34816/50176]	Loss: 0.8939
Training Epoch: 28 [35840/50176]	Loss: 0.8701
Training Epoch: 28 [36864/50176]	Loss: 1.0028
Training Epoch: 28 [37888/50176]	Loss: 0.8929
Training Epoch: 28 [38912/50176]	Loss: 0.8890
Training Epoch: 28 [39936/50176]	Loss: 0.8899
Training Epoch: 28 [40960/50176]	Loss: 0.9852
Training Epoch: 28 [41984/50176]	Loss: 0.8592
Training Epoch: 28 [43008/50176]	Loss: 0.8954
Training Epoch: 28 [44032/50176]	Loss: 0.9025
Training Epoch: 28 [45056/50176]	Loss: 1.0555
Training Epoch: 28 [46080/50176]	Loss: 0.9642
Training Epoch: 28 [47104/50176]	Loss: 0.9092
Training Epoch: 28 [48128/50176]	Loss: 0.8581
Training Epoch: 28 [49152/50176]	Loss: 0.9453
Training Epoch: 28 [50176/50176]	Loss: 0.9020
2022-12-09 00:01:44.907 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:01:44,938 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.86 energy=526.53
2022-12-08 19:01:44,938 [ZeusDataLoader(train)] Up to epoch 29: time=1492.06, energy=216201.50, cost=238656.11
2022-12-08 19:01:44,938 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:01:44,938 [ZeusDataLoader(train)] Expected next epoch: time=1539.39, energy=223422.74, cost=246407.97
2022-12-08 19:01:44,939 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0023, Accuracy: 0.4916
2022-12-08 19:01:45,205 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:01:45,205 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:01:45.207 [ZeusMonitor] Monitor started.
2022-12-09 00:01:45.207 [ZeusMonitor] Running indefinitely. 2022-12-09 00:01:45.207 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:01:45.207 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e30+gpu0.power.log
2022-12-08 19:02:29,187 [ZeusDataLoader(train)] train epoch 30 done: time=44.24 energy=6713.35
2022-12-08 19:02:29,190 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.8038
Training Epoch: 29 [2048/50176]	Loss: 0.7729
Training Epoch: 29 [3072/50176]	Loss: 0.7609
Training Epoch: 29 [4096/50176]	Loss: 0.8007
Training Epoch: 29 [5120/50176]	Loss: 0.8409
Training Epoch: 29 [6144/50176]	Loss: 0.7855
Training Epoch: 29 [7168/50176]	Loss: 0.7875
Training Epoch: 29 [8192/50176]	Loss: 0.7816
Training Epoch: 29 [9216/50176]	Loss: 0.8934
Training Epoch: 29 [10240/50176]	Loss: 0.8491
Training Epoch: 29 [11264/50176]	Loss: 0.8706
Training Epoch: 29 [12288/50176]	Loss: 0.8572
Training Epoch: 29 [13312/50176]	Loss: 0.7274
Training Epoch: 29 [14336/50176]	Loss: 0.8049
Training Epoch: 29 [15360/50176]	Loss: 0.9395
Training Epoch: 29 [16384/50176]	Loss: 0.8177
Training Epoch: 29 [17408/50176]	Loss: 0.8092
Training Epoch: 29 [18432/50176]	Loss: 0.8392
Training Epoch: 29 [19456/50176]	Loss: 0.9150
Training Epoch: 29 [20480/50176]	Loss: 0.7993
Training Epoch: 29 [21504/50176]	Loss: 0.8662
Training Epoch: 29 [22528/50176]	Loss: 0.7252
Training Epoch: 29 [23552/50176]	Loss: 0.8261
Training Epoch: 29 [24576/50176]	Loss: 0.8108
Training Epoch: 29 [25600/50176]	Loss: 0.8336
Training Epoch: 29 [26624/50176]	Loss: 0.8028
Training Epoch: 29 [27648/50176]	Loss: 0.8632
Training Epoch: 29 [28672/50176]	Loss: 0.8131
Training Epoch: 29 [29696/50176]	Loss: 0.7894
Training Epoch: 29 [30720/50176]	Loss: 0.8612
Training Epoch: 29 [31744/50176]	Loss: 0.8430
Training Epoch: 29 [32768/50176]	Loss: 0.8797
Training Epoch: 29 [33792/50176]	Loss: 0.8829
Training Epoch: 29 [34816/50176]	Loss: 0.9077
Training Epoch: 29 [35840/50176]	Loss: 0.7504
Training Epoch: 29 [36864/50176]	Loss: 0.8499
Training Epoch: 29 [37888/50176]	Loss: 0.8358
Training Epoch: 29 [38912/50176]	Loss: 0.8542
Training Epoch: 29 [39936/50176]	Loss: 0.8892
Training Epoch: 29 [40960/50176]	Loss: 0.9048
Training Epoch: 29 [41984/50176]	Loss: 0.8360
Training Epoch: 29 [43008/50176]	Loss: 0.9281
Training Epoch: 29 [44032/50176]	Loss: 0.9128
Training Epoch: 29 [45056/50176]	Loss: 0.8861
Training Epoch: 29 [46080/50176]	Loss: 0.9138
Training Epoch: 29 [47104/50176]	Loss: 0.8413
Training Epoch: 29 [48128/50176]	Loss: 0.9518
Training Epoch: 29 [49152/50176]	Loss: 0.9026
Training Epoch: 29 [50176/50176]	Loss: 0.9809
2022-12-09 00:02:32.984 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:02:33,002 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.80 energy=525.85
2022-12-08 19:02:33,003 [ZeusDataLoader(train)] Up to epoch 30: time=1540.10, energy=223440.70, cost=246479.37
2022-12-08 19:02:33,003 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:02:33,003 [ZeusDataLoader(train)] Expected next epoch: time=1587.43, energy=230661.94, cost=254231.23
2022-12-08 19:02:33,004 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0019, Accuracy: 0.5319
2022-12-08 19:02:33,266 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:02:33,267 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:02:33.283 [ZeusMonitor] Monitor started.
2022-12-09 00:02:33.283 [ZeusMonitor] Running indefinitely. 2022-12-09 00:02:33.283 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:02:33.283 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e31+gpu0.power.log
2022-12-08 19:03:17,192 [ZeusDataLoader(train)] train epoch 31 done: time=44.18 energy=6711.06
2022-12-08 19:03:17,196 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.8836
Training Epoch: 30 [2048/50176]	Loss: 0.7783
Training Epoch: 30 [3072/50176]	Loss: 0.7832
Training Epoch: 30 [4096/50176]	Loss: 0.7768
Training Epoch: 30 [5120/50176]	Loss: 0.7512
Training Epoch: 30 [6144/50176]	Loss: 0.7647
Training Epoch: 30 [7168/50176]	Loss: 0.7666
Training Epoch: 30 [8192/50176]	Loss: 0.7088
Training Epoch: 30 [9216/50176]	Loss: 0.7748
Training Epoch: 30 [10240/50176]	Loss: 0.7425
Training Epoch: 30 [11264/50176]	Loss: 0.7996
Training Epoch: 30 [12288/50176]	Loss: 0.7728
Training Epoch: 30 [13312/50176]	Loss: 0.7833
Training Epoch: 30 [14336/50176]	Loss: 0.7478
Training Epoch: 30 [15360/50176]	Loss: 0.7598
Training Epoch: 30 [16384/50176]	Loss: 0.8086
Training Epoch: 30 [17408/50176]	Loss: 0.7717
Training Epoch: 30 [18432/50176]	Loss: 0.7531
Training Epoch: 30 [19456/50176]	Loss: 0.7791
Training Epoch: 30 [20480/50176]	Loss: 0.7669
Training Epoch: 30 [21504/50176]	Loss: 0.7511
Training Epoch: 30 [22528/50176]	Loss: 0.8010
Training Epoch: 30 [23552/50176]	Loss: 0.7860
Training Epoch: 30 [24576/50176]	Loss: 0.7884
Training Epoch: 30 [25600/50176]	Loss: 0.8069
Training Epoch: 30 [26624/50176]	Loss: 0.7822
Training Epoch: 30 [27648/50176]	Loss: 0.8611
Training Epoch: 30 [28672/50176]	Loss: 0.9061
Training Epoch: 30 [29696/50176]	Loss: 0.8022
Training Epoch: 30 [30720/50176]	Loss: 0.7932
Training Epoch: 30 [31744/50176]	Loss: 0.7502
Training Epoch: 30 [32768/50176]	Loss: 0.7880
Training Epoch: 30 [33792/50176]	Loss: 0.8328
Training Epoch: 30 [34816/50176]	Loss: 0.8981
Training Epoch: 30 [35840/50176]	Loss: 0.8109
Training Epoch: 30 [36864/50176]	Loss: 0.8479
Training Epoch: 30 [37888/50176]	Loss: 0.8739
Training Epoch: 30 [38912/50176]	Loss: 0.8700
Training Epoch: 30 [39936/50176]	Loss: 0.8302
Training Epoch: 30 [40960/50176]	Loss: 0.8684
Training Epoch: 30 [41984/50176]	Loss: 0.8227
Training Epoch: 30 [43008/50176]	Loss: 0.9153
Training Epoch: 30 [44032/50176]	Loss: 0.7802
Training Epoch: 30 [45056/50176]	Loss: 0.8609
Training Epoch: 30 [46080/50176]	Loss: 0.8510
Training Epoch: 30 [47104/50176]	Loss: 0.8173
Training Epoch: 30 [48128/50176]	Loss: 0.8173
Training Epoch: 30 [49152/50176]	Loss: 0.8943
Training Epoch: 30 [50176/50176]	Loss: 0.9492
2022-12-09 00:03:20.977 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:03:21,010 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.80 energy=530.46
2022-12-08 19:03:21,010 [ZeusDataLoader(train)] Up to epoch 31: time=1588.09, energy=230682.22, cost=254298.76
2022-12-08 19:03:21,010 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:03:21,010 [ZeusDataLoader(train)] Expected next epoch: time=1635.42, energy=237903.46, cost=262050.62
2022-12-08 19:03:21,011 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0017, Accuracy: 0.5522
2022-12-08 19:03:21,279 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:03:21,280 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:03:21.282 [ZeusMonitor] Monitor started.
2022-12-09 00:03:21.282 [ZeusMonitor] Running indefinitely. 2022-12-09 00:03:21.282 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:03:21.282 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e32+gpu0.power.log
2022-12-08 19:04:05,183 [ZeusDataLoader(train)] train epoch 32 done: time=44.16 energy=6710.74
2022-12-08 19:04:05,187 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.7475
Training Epoch: 31 [2048/50176]	Loss: 0.6890
Training Epoch: 31 [3072/50176]	Loss: 0.7729
Training Epoch: 31 [4096/50176]	Loss: 0.6696
Training Epoch: 31 [5120/50176]	Loss: 0.7343
Training Epoch: 31 [6144/50176]	Loss: 0.7336
Training Epoch: 31 [7168/50176]	Loss: 0.7271
Training Epoch: 31 [8192/50176]	Loss: 0.7638
Training Epoch: 31 [9216/50176]	Loss: 0.7206
Training Epoch: 31 [10240/50176]	Loss: 0.7828
Training Epoch: 31 [11264/50176]	Loss: 0.7465
Training Epoch: 31 [12288/50176]	Loss: 0.7780
Training Epoch: 31 [13312/50176]	Loss: 0.7524
Training Epoch: 31 [14336/50176]	Loss: 0.7042
Training Epoch: 31 [15360/50176]	Loss: 0.7012
Training Epoch: 31 [16384/50176]	Loss: 0.7085
Training Epoch: 31 [17408/50176]	Loss: 0.7581
Training Epoch: 31 [18432/50176]	Loss: 0.7579
Training Epoch: 31 [19456/50176]	Loss: 0.7767
Training Epoch: 31 [20480/50176]	Loss: 0.7767
Training Epoch: 31 [21504/50176]	Loss: 0.8159
Training Epoch: 31 [22528/50176]	Loss: 0.7192
Training Epoch: 31 [23552/50176]	Loss: 0.8174
Training Epoch: 31 [24576/50176]	Loss: 0.7398
Training Epoch: 31 [25600/50176]	Loss: 0.7597
Training Epoch: 31 [26624/50176]	Loss: 0.7976
Training Epoch: 31 [27648/50176]	Loss: 0.7763
Training Epoch: 31 [28672/50176]	Loss: 0.7548
Training Epoch: 31 [29696/50176]	Loss: 0.8122
Training Epoch: 31 [30720/50176]	Loss: 0.7719
Training Epoch: 31 [31744/50176]	Loss: 0.7650
Training Epoch: 31 [32768/50176]	Loss: 0.8391
Training Epoch: 31 [33792/50176]	Loss: 0.7977
Training Epoch: 31 [34816/50176]	Loss: 0.9249
Training Epoch: 31 [35840/50176]	Loss: 0.8088
Training Epoch: 31 [36864/50176]	Loss: 0.7876
Training Epoch: 31 [37888/50176]	Loss: 0.8174
Training Epoch: 31 [38912/50176]	Loss: 0.8704
Training Epoch: 31 [39936/50176]	Loss: 0.8696
Training Epoch: 31 [40960/50176]	Loss: 0.8757
Training Epoch: 31 [41984/50176]	Loss: 0.7920
Training Epoch: 31 [43008/50176]	Loss: 0.7691
Training Epoch: 31 [44032/50176]	Loss: 0.7844
Training Epoch: 31 [45056/50176]	Loss: 0.8511
Training Epoch: 31 [46080/50176]	Loss: 0.8245
Training Epoch: 31 [47104/50176]	Loss: 0.7893
Training Epoch: 31 [48128/50176]	Loss: 0.8797
Training Epoch: 31 [49152/50176]	Loss: 0.7956
Training Epoch: 31 [50176/50176]	Loss: 0.7503
2022-12-09 00:04:08.904 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:04:08,913 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.72 energy=524.03
2022-12-08 19:04:08,914 [ZeusDataLoader(train)] Up to epoch 32: time=1635.97, energy=237916.99, cost=262105.76
2022-12-08 19:04:08,914 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:04:08,914 [ZeusDataLoader(train)] Expected next epoch: time=1683.30, energy=245138.23, cost=269857.62
2022-12-08 19:04:08,915 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0018, Accuracy: 0.5548
2022-12-08 19:04:09,166 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:04:09,167 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:04:09.181 [ZeusMonitor] Monitor started.
2022-12-09 00:04:09.181 [ZeusMonitor] Running indefinitely. 2022-12-09 00:04:09.181 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:04:09.181 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e33+gpu0.power.log
2022-12-08 19:04:53,123 [ZeusDataLoader(train)] train epoch 33 done: time=44.20 energy=6710.19
2022-12-08 19:04:53,127 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.6782
Training Epoch: 32 [2048/50176]	Loss: 0.6518
Training Epoch: 32 [3072/50176]	Loss: 0.7405
Training Epoch: 32 [4096/50176]	Loss: 0.6940
Training Epoch: 32 [5120/50176]	Loss: 0.7134
Training Epoch: 32 [6144/50176]	Loss: 0.7423
Training Epoch: 32 [7168/50176]	Loss: 0.6744
Training Epoch: 32 [8192/50176]	Loss: 0.6943
Training Epoch: 32 [9216/50176]	Loss: 0.6602
Training Epoch: 32 [10240/50176]	Loss: 0.6830
Training Epoch: 32 [11264/50176]	Loss: 0.7165
Training Epoch: 32 [12288/50176]	Loss: 0.7189
Training Epoch: 32 [13312/50176]	Loss: 0.7499
Training Epoch: 32 [14336/50176]	Loss: 0.7255
Training Epoch: 32 [15360/50176]	Loss: 0.6731
Training Epoch: 32 [16384/50176]	Loss: 0.6362
Training Epoch: 32 [17408/50176]	Loss: 0.7398
Training Epoch: 32 [18432/50176]	Loss: 0.6945
Training Epoch: 32 [19456/50176]	Loss: 0.6958
Training Epoch: 32 [20480/50176]	Loss: 0.6865
Training Epoch: 32 [21504/50176]	Loss: 0.7416
Training Epoch: 32 [22528/50176]	Loss: 0.7609
Training Epoch: 32 [23552/50176]	Loss: 0.7661
Training Epoch: 32 [24576/50176]	Loss: 0.6466
Training Epoch: 32 [25600/50176]	Loss: 0.7394
Training Epoch: 32 [26624/50176]	Loss: 0.7090
Training Epoch: 32 [27648/50176]	Loss: 0.6648
Training Epoch: 32 [28672/50176]	Loss: 0.7249
Training Epoch: 32 [29696/50176]	Loss: 0.7506
Training Epoch: 32 [30720/50176]	Loss: 0.7248
Training Epoch: 32 [31744/50176]	Loss: 0.7282
Training Epoch: 32 [32768/50176]	Loss: 0.6928
Training Epoch: 32 [33792/50176]	Loss: 0.7920
Training Epoch: 32 [34816/50176]	Loss: 0.8425
Training Epoch: 32 [35840/50176]	Loss: 0.7283
Training Epoch: 32 [36864/50176]	Loss: 0.7408
Training Epoch: 32 [37888/50176]	Loss: 0.7361
Training Epoch: 32 [38912/50176]	Loss: 0.7075
Training Epoch: 32 [39936/50176]	Loss: 0.7852
Training Epoch: 32 [40960/50176]	Loss: 0.7320
Training Epoch: 32 [41984/50176]	Loss: 0.7035
Training Epoch: 32 [43008/50176]	Loss: 0.8103
Training Epoch: 32 [44032/50176]	Loss: 0.7973
Training Epoch: 32 [45056/50176]	Loss: 0.6756
Training Epoch: 32 [46080/50176]	Loss: 0.8688
Training Epoch: 32 [47104/50176]	Loss: 0.8235
Training Epoch: 32 [48128/50176]	Loss: 0.7871
Training Epoch: 32 [49152/50176]	Loss: 0.7709
Training Epoch: 32 [50176/50176]	Loss: 0.8063
2022-12-09 00:04:56.875 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:04:56,895 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=517.03
2022-12-08 19:04:56,895 [ZeusDataLoader(train)] Up to epoch 33: time=1683.93, energy=245144.21, cost=269915.72
2022-12-08 19:04:56,895 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:04:56,895 [ZeusDataLoader(train)] Expected next epoch: time=1731.26, energy=252365.46, cost=277667.59
2022-12-08 19:04:56,896 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0016, Accuracy: 0.5851
2022-12-08 19:04:57,109 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:04:57,110 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:04:57.113 [ZeusMonitor] Monitor started.
2022-12-09 00:04:57.113 [ZeusMonitor] Running indefinitely. 2022-12-09 00:04:57.113 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:04:57.113 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e34+gpu0.power.log
2022-12-08 19:05:41,063 [ZeusDataLoader(train)] train epoch 34 done: time=44.16 energy=6711.48
2022-12-08 19:05:41,066 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.6855
Training Epoch: 33 [2048/50176]	Loss: 0.6069
Training Epoch: 33 [3072/50176]	Loss: 0.6766
Training Epoch: 33 [4096/50176]	Loss: 0.6537
Training Epoch: 33 [5120/50176]	Loss: 0.6568
Training Epoch: 33 [6144/50176]	Loss: 0.6572
Training Epoch: 33 [7168/50176]	Loss: 0.6999
Training Epoch: 33 [8192/50176]	Loss: 0.6378
Training Epoch: 33 [9216/50176]	Loss: 0.6701
Training Epoch: 33 [10240/50176]	Loss: 0.7196
Training Epoch: 33 [11264/50176]	Loss: 0.6849
Training Epoch: 33 [12288/50176]	Loss: 0.6948
Training Epoch: 33 [13312/50176]	Loss: 0.6489
Training Epoch: 33 [14336/50176]	Loss: 0.6418
Training Epoch: 33 [15360/50176]	Loss: 0.6345
Training Epoch: 33 [16384/50176]	Loss: 0.6608
Training Epoch: 33 [17408/50176]	Loss: 0.6545
Training Epoch: 33 [18432/50176]	Loss: 0.6969
Training Epoch: 33 [19456/50176]	Loss: 0.6691
Training Epoch: 33 [20480/50176]	Loss: 0.6926
Training Epoch: 33 [21504/50176]	Loss: 0.7148
Training Epoch: 33 [22528/50176]	Loss: 0.6317
Training Epoch: 33 [23552/50176]	Loss: 0.7060
Training Epoch: 33 [24576/50176]	Loss: 0.7024
Training Epoch: 33 [25600/50176]	Loss: 0.7200
Training Epoch: 33 [26624/50176]	Loss: 0.6384
Training Epoch: 33 [27648/50176]	Loss: 0.6544
Training Epoch: 33 [28672/50176]	Loss: 0.6875
Training Epoch: 33 [29696/50176]	Loss: 0.6812
Training Epoch: 33 [30720/50176]	Loss: 0.7001
Training Epoch: 33 [31744/50176]	Loss: 0.7164
Training Epoch: 33 [32768/50176]	Loss: 0.6852
Training Epoch: 33 [33792/50176]	Loss: 0.7425
Training Epoch: 33 [34816/50176]	Loss: 0.7167
Training Epoch: 33 [35840/50176]	Loss: 0.6886
Training Epoch: 33 [36864/50176]	Loss: 0.6836
Training Epoch: 33 [37888/50176]	Loss: 0.7311
Training Epoch: 33 [38912/50176]	Loss: 0.7220
Training Epoch: 33 [39936/50176]	Loss: 0.7234
Training Epoch: 33 [40960/50176]	Loss: 0.6736
Training Epoch: 33 [41984/50176]	Loss: 0.7422
Training Epoch: 33 [43008/50176]	Loss: 0.7300
Training Epoch: 33 [44032/50176]	Loss: 0.7643
Training Epoch: 33 [45056/50176]	Loss: 0.7788
Training Epoch: 33 [46080/50176]	Loss: 0.6699
Training Epoch: 33 [47104/50176]	Loss: 0.7452
Training Epoch: 33 [48128/50176]	Loss: 0.7052
Training Epoch: 33 [49152/50176]	Loss: 0.6811
Training Epoch: 33 [50176/50176]	Loss: 0.7615
2022-12-09 00:05:44.798 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:05:44,813 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.74 energy=525.01
2022-12-08 19:05:44,814 [ZeusDataLoader(train)] Up to epoch 34: time=1731.82, energy=252380.70, cost=277724.90
2022-12-08 19:05:44,814 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:05:44,814 [ZeusDataLoader(train)] Expected next epoch: time=1779.15, energy=259601.94, cost=285476.77
2022-12-08 19:05:44,815 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0020, Accuracy: 0.5371
2022-12-08 19:05:45,075 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:05:45,076 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:05:45.078 [ZeusMonitor] Monitor started.
2022-12-09 00:05:45.078 [ZeusMonitor] Running indefinitely. 2022-12-09 00:05:45.078 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:05:45.078 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e35+gpu0.power.log
2022-12-08 19:06:29,067 [ZeusDataLoader(train)] train epoch 35 done: time=44.24 energy=6711.30
2022-12-08 19:06:29,071 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.5314
Training Epoch: 34 [2048/50176]	Loss: 0.6310
Training Epoch: 34 [3072/50176]	Loss: 0.5868
Training Epoch: 34 [4096/50176]	Loss: 0.5746
Training Epoch: 34 [5120/50176]	Loss: 0.6153
Training Epoch: 34 [6144/50176]	Loss: 0.6202
Training Epoch: 34 [7168/50176]	Loss: 0.5969
Training Epoch: 34 [8192/50176]	Loss: 0.6559
Training Epoch: 34 [9216/50176]	Loss: 0.6052
Training Epoch: 34 [10240/50176]	Loss: 0.6454
Training Epoch: 34 [11264/50176]	Loss: 0.5924
Training Epoch: 34 [12288/50176]	Loss: 0.6688
Training Epoch: 34 [13312/50176]	Loss: 0.6500
Training Epoch: 34 [14336/50176]	Loss: 0.6061
Training Epoch: 34 [15360/50176]	Loss: 0.6184
Training Epoch: 34 [16384/50176]	Loss: 0.7347
Training Epoch: 34 [17408/50176]	Loss: 0.6613
Training Epoch: 34 [18432/50176]	Loss: 0.6256
Training Epoch: 34 [19456/50176]	Loss: 0.5795
Training Epoch: 34 [20480/50176]	Loss: 0.6835
Training Epoch: 34 [21504/50176]	Loss: 0.6532
Training Epoch: 34 [22528/50176]	Loss: 0.6349
Training Epoch: 34 [23552/50176]	Loss: 0.6548
Training Epoch: 34 [24576/50176]	Loss: 0.5721
Training Epoch: 34 [25600/50176]	Loss: 0.6857
Training Epoch: 34 [26624/50176]	Loss: 0.6828
Training Epoch: 34 [27648/50176]	Loss: 0.6702
Training Epoch: 34 [28672/50176]	Loss: 0.6543
Training Epoch: 34 [29696/50176]	Loss: 0.6956
Training Epoch: 34 [30720/50176]	Loss: 0.6497
Training Epoch: 34 [31744/50176]	Loss: 0.6812
Training Epoch: 34 [32768/50176]	Loss: 0.6660
Training Epoch: 34 [33792/50176]	Loss: 0.6712
Training Epoch: 34 [34816/50176]	Loss: 0.6617
Training Epoch: 34 [35840/50176]	Loss: 0.6698
Training Epoch: 34 [36864/50176]	Loss: 0.6791
Training Epoch: 34 [37888/50176]	Loss: 0.6745
Training Epoch: 34 [38912/50176]	Loss: 0.5897
Training Epoch: 34 [39936/50176]	Loss: 0.7587
Training Epoch: 34 [40960/50176]	Loss: 0.6656
Training Epoch: 34 [41984/50176]	Loss: 0.6528
Training Epoch: 34 [43008/50176]	Loss: 0.6706
Training Epoch: 34 [44032/50176]	Loss: 0.6609
Training Epoch: 34 [45056/50176]	Loss: 0.8056
Training Epoch: 34 [46080/50176]	Loss: 0.6642
Training Epoch: 34 [47104/50176]	Loss: 0.7015
Training Epoch: 34 [48128/50176]	Loss: 0.6879
Training Epoch: 34 [49152/50176]	Loss: 0.7000
Training Epoch: 34 [50176/50176]	Loss: 0.7024
2022-12-09 00:06:32.860 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:06:32,904 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.82 energy=530.08
2022-12-08 19:06:32,904 [ZeusDataLoader(train)] Up to epoch 35: time=1779.89, energy=259622.08, cost=285551.46
2022-12-08 19:06:32,904 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:06:32,904 [ZeusDataLoader(train)] Expected next epoch: time=1827.22, energy=266843.32, cost=293303.33
2022-12-08 19:06:32,905 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0017, Accuracy: 0.5825
2022-12-08 19:06:33,157 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:06:33,158 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:06:33.160 [ZeusMonitor] Monitor started.
2022-12-09 00:06:33.160 [ZeusMonitor] Running indefinitely. 2022-12-09 00:06:33.160 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:06:33.160 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e36+gpu0.power.log
2022-12-08 19:07:17,158 [ZeusDataLoader(train)] train epoch 36 done: time=44.24 energy=6718.38
2022-12-08 19:07:17,161 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.5827
Training Epoch: 35 [2048/50176]	Loss: 0.6169
Training Epoch: 35 [3072/50176]	Loss: 0.6174
Training Epoch: 35 [4096/50176]	Loss: 0.5610
Training Epoch: 35 [5120/50176]	Loss: 0.6002
Training Epoch: 35 [6144/50176]	Loss: 0.5620
Training Epoch: 35 [7168/50176]	Loss: 0.5929
Training Epoch: 35 [8192/50176]	Loss: 0.6133
Training Epoch: 35 [9216/50176]	Loss: 0.5295
Training Epoch: 35 [10240/50176]	Loss: 0.6125
Training Epoch: 35 [11264/50176]	Loss: 0.6355
Training Epoch: 35 [12288/50176]	Loss: 0.6473
Training Epoch: 35 [13312/50176]	Loss: 0.6140
Training Epoch: 35 [14336/50176]	Loss: 0.6184
Training Epoch: 35 [15360/50176]	Loss: 0.5999
Training Epoch: 35 [16384/50176]	Loss: 0.6146
Training Epoch: 35 [17408/50176]	Loss: 0.6396
Training Epoch: 35 [18432/50176]	Loss: 0.6682
Training Epoch: 35 [19456/50176]	Loss: 0.6383
Training Epoch: 35 [20480/50176]	Loss: 0.5858
Training Epoch: 35 [21504/50176]	Loss: 0.6043
Training Epoch: 35 [22528/50176]	Loss: 0.6583
Training Epoch: 35 [23552/50176]	Loss: 0.6087
Training Epoch: 35 [24576/50176]	Loss: 0.6722
Training Epoch: 35 [25600/50176]	Loss: 0.5921
Training Epoch: 35 [26624/50176]	Loss: 0.6060
Training Epoch: 35 [27648/50176]	Loss: 0.6053
Training Epoch: 35 [28672/50176]	Loss: 0.6927
Training Epoch: 35 [29696/50176]	Loss: 0.6028
Training Epoch: 35 [30720/50176]	Loss: 0.6842
Training Epoch: 35 [31744/50176]	Loss: 0.6296
Training Epoch: 35 [32768/50176]	Loss: 0.6251
Training Epoch: 35 [33792/50176]	Loss: 0.5896
Training Epoch: 35 [34816/50176]	Loss: 0.5952
Training Epoch: 35 [35840/50176]	Loss: 0.6564
Training Epoch: 35 [36864/50176]	Loss: 0.7170
Training Epoch: 35 [37888/50176]	Loss: 0.6705
Training Epoch: 35 [38912/50176]	Loss: 0.6715
Training Epoch: 35 [39936/50176]	Loss: 0.7853
Training Epoch: 35 [40960/50176]	Loss: 0.6411
Training Epoch: 35 [41984/50176]	Loss: 0.6796
Training Epoch: 35 [43008/50176]	Loss: 0.6263
Training Epoch: 35 [44032/50176]	Loss: 0.6658
Training Epoch: 35 [45056/50176]	Loss: 0.6705
Training Epoch: 35 [46080/50176]	Loss: 0.6810
Training Epoch: 35 [47104/50176]	Loss: 0.6873
Training Epoch: 35 [48128/50176]	Loss: 0.6913
Training Epoch: 35 [49152/50176]	Loss: 0.6664
Training Epoch: 35 [50176/50176]	Loss: 0.6413
2022-12-09 00:07:20.914 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:07:20,925 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.75 energy=514.65
2022-12-08 19:07:20,925 [ZeusDataLoader(train)] Up to epoch 36: time=1827.89, energy=266855.11, cost=293367.83
2022-12-08 19:07:20,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:07:20,925 [ZeusDataLoader(train)] Expected next epoch: time=1875.22, energy=274076.35, cost=301119.70
2022-12-08 19:07:20,926 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0018, Accuracy: 0.5751
2022-12-08 19:07:21,194 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:07:21,195 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:07:21.197 [ZeusMonitor] Monitor started.
2022-12-09 00:07:21.197 [ZeusMonitor] Running indefinitely. 2022-12-09 00:07:21.197 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:07:21.197 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e37+gpu0.power.log
2022-12-08 19:08:05,182 [ZeusDataLoader(train)] train epoch 37 done: time=44.25 energy=6730.78
2022-12-08 19:08:05,186 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.5030
Training Epoch: 36 [2048/50176]	Loss: 0.5849
Training Epoch: 36 [3072/50176]	Loss: 0.5173
Training Epoch: 36 [4096/50176]	Loss: 0.5602
Training Epoch: 36 [5120/50176]	Loss: 0.5734
Training Epoch: 36 [6144/50176]	Loss: 0.5328
Training Epoch: 36 [7168/50176]	Loss: 0.5919
Training Epoch: 36 [8192/50176]	Loss: 0.5748
Training Epoch: 36 [9216/50176]	Loss: 0.5713
Training Epoch: 36 [10240/50176]	Loss: 0.6153
Training Epoch: 36 [11264/50176]	Loss: 0.5437
Training Epoch: 36 [12288/50176]	Loss: 0.5652
Training Epoch: 36 [13312/50176]	Loss: 0.5573
Training Epoch: 36 [14336/50176]	Loss: 0.5403
Training Epoch: 36 [15360/50176]	Loss: 0.6103
Training Epoch: 36 [16384/50176]	Loss: 0.5452
Training Epoch: 36 [17408/50176]	Loss: 0.5800
Training Epoch: 36 [18432/50176]	Loss: 0.5893
Training Epoch: 36 [19456/50176]	Loss: 0.5799
Training Epoch: 36 [20480/50176]	Loss: 0.5771
Training Epoch: 36 [21504/50176]	Loss: 0.5857
Training Epoch: 36 [22528/50176]	Loss: 0.6533
Training Epoch: 36 [23552/50176]	Loss: 0.5663
Training Epoch: 36 [24576/50176]	Loss: 0.5877
Training Epoch: 36 [25600/50176]	Loss: 0.6700
Training Epoch: 36 [26624/50176]	Loss: 0.6199
Training Epoch: 36 [27648/50176]	Loss: 0.5991
Training Epoch: 36 [28672/50176]	Loss: 0.6368
Training Epoch: 36 [29696/50176]	Loss: 0.5964
Training Epoch: 36 [30720/50176]	Loss: 0.5986
Training Epoch: 36 [31744/50176]	Loss: 0.5963
Training Epoch: 36 [32768/50176]	Loss: 0.5915
Training Epoch: 36 [33792/50176]	Loss: 0.6017
Training Epoch: 36 [34816/50176]	Loss: 0.6190
Training Epoch: 36 [35840/50176]	Loss: 0.5974
Training Epoch: 36 [36864/50176]	Loss: 0.6050
Training Epoch: 36 [37888/50176]	Loss: 0.6582
Training Epoch: 36 [38912/50176]	Loss: 0.6225
Training Epoch: 36 [39936/50176]	Loss: 0.6332
Training Epoch: 36 [40960/50176]	Loss: 0.6298
Training Epoch: 36 [41984/50176]	Loss: 0.6815
Training Epoch: 36 [43008/50176]	Loss: 0.6861
Training Epoch: 36 [44032/50176]	Loss: 0.7168
Training Epoch: 36 [45056/50176]	Loss: 0.6345
Training Epoch: 36 [46080/50176]	Loss: 0.6122
Training Epoch: 36 [47104/50176]	Loss: 0.6544
Training Epoch: 36 [48128/50176]	Loss: 0.6285
Training Epoch: 36 [49152/50176]	Loss: 0.6338
Training Epoch: 36 [50176/50176]	Loss: 0.6124
2022-12-09 00:08:08.967 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:08:09,026 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.83 energy=533.15
2022-12-08 19:08:09,026 [ZeusDataLoader(train)] Up to epoch 37: time=1875.97, energy=274119.04, cost=301206.64
2022-12-08 19:08:09,027 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:08:09,027 [ZeusDataLoader(train)] Expected next epoch: time=1923.30, energy=281340.28, cost=308958.51
2022-12-08 19:08:09,028 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0019, Accuracy: 0.5728
2022-12-08 19:08:09,327 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:08:09,328 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:08:09.350 [ZeusMonitor] Monitor started.
2022-12-09 00:08:09.350 [ZeusMonitor] Running indefinitely. 2022-12-09 00:08:09.350 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:08:09.350 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e38+gpu0.power.log
2022-12-08 19:08:53,282 [ZeusDataLoader(train)] train epoch 38 done: time=44.25 energy=6707.83
2022-12-08 19:08:53,286 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.5298
Training Epoch: 37 [2048/50176]	Loss: 0.6152
Training Epoch: 37 [3072/50176]	Loss: 0.5143
Training Epoch: 37 [4096/50176]	Loss: 0.6079
Training Epoch: 37 [5120/50176]	Loss: 0.5231
Training Epoch: 37 [6144/50176]	Loss: 0.5641
Training Epoch: 37 [7168/50176]	Loss: 0.5770
Training Epoch: 37 [8192/50176]	Loss: 0.5400
Training Epoch: 37 [9216/50176]	Loss: 0.5474
Training Epoch: 37 [10240/50176]	Loss: 0.5589
Training Epoch: 37 [11264/50176]	Loss: 0.5965
Training Epoch: 37 [12288/50176]	Loss: 0.5471
Training Epoch: 37 [13312/50176]	Loss: 0.5318
Training Epoch: 37 [14336/50176]	Loss: 0.5212
Training Epoch: 37 [15360/50176]	Loss: 0.5683
Training Epoch: 37 [16384/50176]	Loss: 0.5307
Training Epoch: 37 [17408/50176]	Loss: 0.5491
Training Epoch: 37 [18432/50176]	Loss: 0.5478
Training Epoch: 37 [19456/50176]	Loss: 0.5421
Training Epoch: 37 [20480/50176]	Loss: 0.5486
Training Epoch: 37 [21504/50176]	Loss: 0.6179
Training Epoch: 37 [22528/50176]	Loss: 0.5737
Training Epoch: 37 [23552/50176]	Loss: 0.5524
Training Epoch: 37 [24576/50176]	Loss: 0.5464
Training Epoch: 37 [25600/50176]	Loss: 0.5740
Training Epoch: 37 [26624/50176]	Loss: 0.6311
Training Epoch: 37 [27648/50176]	Loss: 0.5902
Training Epoch: 37 [28672/50176]	Loss: 0.6087
Training Epoch: 37 [29696/50176]	Loss: 0.6553
Training Epoch: 37 [30720/50176]	Loss: 0.5512
Training Epoch: 37 [31744/50176]	Loss: 0.5421
Training Epoch: 37 [32768/50176]	Loss: 0.5688
Training Epoch: 37 [33792/50176]	Loss: 0.5812
Training Epoch: 37 [34816/50176]	Loss: 0.5963
Training Epoch: 37 [35840/50176]	Loss: 0.6131
Training Epoch: 37 [36864/50176]	Loss: 0.5526
Training Epoch: 37 [37888/50176]	Loss: 0.6530
Training Epoch: 37 [38912/50176]	Loss: 0.6515
Training Epoch: 37 [39936/50176]	Loss: 0.6043
Training Epoch: 37 [40960/50176]	Loss: 0.6262
Training Epoch: 37 [41984/50176]	Loss: 0.5954
Training Epoch: 37 [43008/50176]	Loss: 0.6371
Training Epoch: 37 [44032/50176]	Loss: 0.6374
Training Epoch: 37 [45056/50176]	Loss: 0.6299
Training Epoch: 37 [46080/50176]	Loss: 0.6005
Training Epoch: 37 [47104/50176]	Loss: 0.6457
Training Epoch: 37 [48128/50176]	Loss: 0.6496
Training Epoch: 37 [49152/50176]	Loss: 0.6066
Training Epoch: 37 [50176/50176]	Loss: 0.6730
2022-12-09 00:08:57.061 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:08:57,071 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.78 energy=527.79
2022-12-08 19:08:57,072 [ZeusDataLoader(train)] Up to epoch 38: time=1923.99, energy=281354.66, cost=309026.45
2022-12-08 19:08:57,072 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:08:57,072 [ZeusDataLoader(train)] Expected next epoch: time=1971.32, energy=288575.90, cost=316778.31
2022-12-08 19:08:57,073 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0017, Accuracy: 0.5816
2022-12-08 19:08:57,315 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:08:57,316 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:08:57.330 [ZeusMonitor] Monitor started.
2022-12-09 00:08:57.330 [ZeusMonitor] Running indefinitely. 2022-12-09 00:08:57.330 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:08:57.330 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e39+gpu0.power.log
2022-12-08 19:09:41,276 [ZeusDataLoader(train)] train epoch 39 done: time=44.19 energy=6710.44
2022-12-08 19:09:41,279 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.5565
Training Epoch: 38 [2048/50176]	Loss: 0.5065
Training Epoch: 38 [3072/50176]	Loss: 0.5228
Training Epoch: 38 [4096/50176]	Loss: 0.5050
Training Epoch: 38 [5120/50176]	Loss: 0.4974
Training Epoch: 38 [6144/50176]	Loss: 0.4859
Training Epoch: 38 [7168/50176]	Loss: 0.5478
Training Epoch: 38 [8192/50176]	Loss: 0.5112
Training Epoch: 38 [9216/50176]	Loss: 0.4730
Training Epoch: 38 [10240/50176]	Loss: 0.5157
Training Epoch: 38 [11264/50176]	Loss: 0.5634
Training Epoch: 38 [12288/50176]	Loss: 0.5508
Training Epoch: 38 [13312/50176]	Loss: 0.4754
Training Epoch: 38 [14336/50176]	Loss: 0.5485
Training Epoch: 38 [15360/50176]	Loss: 0.5244
Training Epoch: 38 [16384/50176]	Loss: 0.5052
Training Epoch: 38 [17408/50176]	Loss: 0.5224
Training Epoch: 38 [18432/50176]	Loss: 0.5362
Training Epoch: 38 [19456/50176]	Loss: 0.4982
Training Epoch: 38 [20480/50176]	Loss: 0.5277
Training Epoch: 38 [21504/50176]	Loss: 0.4809
Training Epoch: 38 [22528/50176]	Loss: 0.5563
Training Epoch: 38 [23552/50176]	Loss: 0.5656
Training Epoch: 38 [24576/50176]	Loss: 0.5282
Training Epoch: 38 [25600/50176]	Loss: 0.5546
Training Epoch: 38 [26624/50176]	Loss: 0.5776
Training Epoch: 38 [27648/50176]	Loss: 0.5433
Training Epoch: 38 [28672/50176]	Loss: 0.6035
Training Epoch: 38 [29696/50176]	Loss: 0.5439
Training Epoch: 38 [30720/50176]	Loss: 0.4945
Training Epoch: 38 [31744/50176]	Loss: 0.5589
Training Epoch: 38 [32768/50176]	Loss: 0.5628
Training Epoch: 38 [33792/50176]	Loss: 0.5503
Training Epoch: 38 [34816/50176]	Loss: 0.6083
Training Epoch: 38 [35840/50176]	Loss: 0.5430
Training Epoch: 38 [36864/50176]	Loss: 0.5778
Training Epoch: 38 [37888/50176]	Loss: 0.5598
Training Epoch: 38 [38912/50176]	Loss: 0.5306
Training Epoch: 38 [39936/50176]	Loss: 0.6135
Training Epoch: 38 [40960/50176]	Loss: 0.6064
Training Epoch: 38 [41984/50176]	Loss: 0.5418
Training Epoch: 38 [43008/50176]	Loss: 0.5852
Training Epoch: 38 [44032/50176]	Loss: 0.5999
Training Epoch: 38 [45056/50176]	Loss: 0.5550
Training Epoch: 38 [46080/50176]	Loss: 0.5759
Training Epoch: 38 [47104/50176]	Loss: 0.6427
Training Epoch: 38 [48128/50176]	Loss: 0.5347
Training Epoch: 38 [49152/50176]	Loss: 0.6589
Training Epoch: 38 [50176/50176]	Loss: 0.5588
2022-12-09 00:09:45.086 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:09:45,118 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.83 energy=537.52
2022-12-08 19:09:45,119 [ZeusDataLoader(train)] Up to epoch 39: time=1972.01, energy=288602.63, cost=316852.52
2022-12-08 19:09:45,119 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:09:45,119 [ZeusDataLoader(train)] Expected next epoch: time=2019.34, energy=295823.87, cost=324604.38
2022-12-08 19:09:45,120 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0018, Accuracy: 0.5864
2022-12-08 19:09:45,372 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:09:45,373 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:09:45.375 [ZeusMonitor] Monitor started.
2022-12-09 00:09:45.375 [ZeusMonitor] Running indefinitely. 2022-12-09 00:09:45.375 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:09:45.375 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e40+gpu0.power.log
2022-12-08 19:10:29,415 [ZeusDataLoader(train)] train epoch 40 done: time=44.29 energy=6717.75
2022-12-08 19:10:29,420 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.4388
Training Epoch: 39 [2048/50176]	Loss: 0.4665
Training Epoch: 39 [3072/50176]	Loss: 0.4734
Training Epoch: 39 [4096/50176]	Loss: 0.5157
Training Epoch: 39 [5120/50176]	Loss: 0.5138
Training Epoch: 39 [6144/50176]	Loss: 0.5130
Training Epoch: 39 [7168/50176]	Loss: 0.4104
Training Epoch: 39 [8192/50176]	Loss: 0.4875
Training Epoch: 39 [9216/50176]	Loss: 0.4733
Training Epoch: 39 [10240/50176]	Loss: 0.5064
Training Epoch: 39 [11264/50176]	Loss: 0.4844
Training Epoch: 39 [12288/50176]	Loss: 0.4706
Training Epoch: 39 [13312/50176]	Loss: 0.4872
Training Epoch: 39 [14336/50176]	Loss: 0.4975
Training Epoch: 39 [15360/50176]	Loss: 0.4635
Training Epoch: 39 [16384/50176]	Loss: 0.4911
Training Epoch: 39 [17408/50176]	Loss: 0.4876
Training Epoch: 39 [18432/50176]	Loss: 0.4959
Training Epoch: 39 [19456/50176]	Loss: 0.4866
Training Epoch: 39 [20480/50176]	Loss: 0.4826
Training Epoch: 39 [21504/50176]	Loss: 0.5374
Training Epoch: 39 [22528/50176]	Loss: 0.4772
Training Epoch: 39 [23552/50176]	Loss: 0.4873
Training Epoch: 39 [24576/50176]	Loss: 0.4590
Training Epoch: 39 [25600/50176]	Loss: 0.5238
Training Epoch: 39 [26624/50176]	Loss: 0.5483
Training Epoch: 39 [27648/50176]	Loss: 0.4956
Training Epoch: 39 [28672/50176]	Loss: 0.4803
Training Epoch: 39 [29696/50176]	Loss: 0.5383
Training Epoch: 39 [30720/50176]	Loss: 0.5174
Training Epoch: 39 [31744/50176]	Loss: 0.5404
Training Epoch: 39 [32768/50176]	Loss: 0.5026
Training Epoch: 39 [33792/50176]	Loss: 0.5245
Training Epoch: 39 [34816/50176]	Loss: 0.5211
Training Epoch: 39 [35840/50176]	Loss: 0.5274
Training Epoch: 39 [36864/50176]	Loss: 0.4745
Training Epoch: 39 [37888/50176]	Loss: 0.5385
Training Epoch: 39 [38912/50176]	Loss: 0.5461
Training Epoch: 39 [39936/50176]	Loss: 0.6177
Training Epoch: 39 [40960/50176]	Loss: 0.5362
Training Epoch: 39 [41984/50176]	Loss: 0.5386
Training Epoch: 39 [43008/50176]	Loss: 0.5450
Training Epoch: 39 [44032/50176]	Loss: 0.5562
Training Epoch: 39 [45056/50176]	Loss: 0.5860
Training Epoch: 39 [46080/50176]	Loss: 0.5085
Training Epoch: 39 [47104/50176]	Loss: 0.5714
Training Epoch: 39 [48128/50176]	Loss: 0.5145
Training Epoch: 39 [49152/50176]	Loss: 0.5818
Training Epoch: 39 [50176/50176]	Loss: 0.6236
2022-12-09 00:10:33.204 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:10:33,250 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.82 energy=533.24
2022-12-08 19:10:33,250 [ZeusDataLoader(train)] Up to epoch 40: time=2020.12, energy=295853.61, cost=324687.47
2022-12-08 19:10:33,250 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:10:33,250 [ZeusDataLoader(train)] Expected next epoch: time=2067.45, energy=303074.85, cost=332439.34
2022-12-08 19:10:33,251 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0020, Accuracy: 0.5711
2022-12-08 19:10:33,516 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:10:33,517 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:10:33.519 [ZeusMonitor] Monitor started.
2022-12-09 00:10:33.519 [ZeusMonitor] Running indefinitely. 2022-12-09 00:10:33.519 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:10:33.519 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e41+gpu0.power.log
2022-12-08 19:11:17,581 [ZeusDataLoader(train)] train epoch 41 done: time=44.32 energy=6731.30
2022-12-08 19:11:17,584 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.3985
Training Epoch: 40 [2048/50176]	Loss: 0.4625
Training Epoch: 40 [3072/50176]	Loss: 0.5129
Training Epoch: 40 [4096/50176]	Loss: 0.4647
Training Epoch: 40 [5120/50176]	Loss: 0.4849
Training Epoch: 40 [6144/50176]	Loss: 0.4762
Training Epoch: 40 [7168/50176]	Loss: 0.4260
Training Epoch: 40 [8192/50176]	Loss: 0.4274
Training Epoch: 40 [9216/50176]	Loss: 0.4718
Training Epoch: 40 [10240/50176]	Loss: 0.4558
Training Epoch: 40 [11264/50176]	Loss: 0.4755
Training Epoch: 40 [12288/50176]	Loss: 0.4522
Training Epoch: 40 [13312/50176]	Loss: 0.4752
Training Epoch: 40 [14336/50176]	Loss: 0.4593
Training Epoch: 40 [15360/50176]	Loss: 0.4348
Training Epoch: 40 [16384/50176]	Loss: 0.4760
Training Epoch: 40 [17408/50176]	Loss: 0.5083
Training Epoch: 40 [18432/50176]	Loss: 0.4827
Training Epoch: 40 [19456/50176]	Loss: 0.4430
Training Epoch: 40 [20480/50176]	Loss: 0.4781
Training Epoch: 40 [21504/50176]	Loss: 0.4762
Training Epoch: 40 [22528/50176]	Loss: 0.4583
Training Epoch: 40 [23552/50176]	Loss: 0.4908
Training Epoch: 40 [24576/50176]	Loss: 0.5190
Training Epoch: 40 [25600/50176]	Loss: 0.4843
Training Epoch: 40 [26624/50176]	Loss: 0.4967
Training Epoch: 40 [27648/50176]	Loss: 0.4537
Training Epoch: 40 [28672/50176]	Loss: 0.4364
Training Epoch: 40 [29696/50176]	Loss: 0.4665
Training Epoch: 40 [30720/50176]	Loss: 0.4628
Training Epoch: 40 [31744/50176]	Loss: 0.5073
Training Epoch: 40 [32768/50176]	Loss: 0.5567
Training Epoch: 40 [33792/50176]	Loss: 0.5066
Training Epoch: 40 [34816/50176]	Loss: 0.4968
Training Epoch: 40 [35840/50176]	Loss: 0.4572
Training Epoch: 40 [36864/50176]	Loss: 0.4358
Training Epoch: 40 [37888/50176]	Loss: 0.4440
Training Epoch: 40 [38912/50176]	Loss: 0.5022
Training Epoch: 40 [39936/50176]	Loss: 0.5216
Training Epoch: 40 [40960/50176]	Loss: 0.5603
Training Epoch: 40 [41984/50176]	Loss: 0.4899
Training Epoch: 40 [43008/50176]	Loss: 0.5157
Training Epoch: 40 [44032/50176]	Loss: 0.5017
Training Epoch: 40 [45056/50176]	Loss: 0.4938
Training Epoch: 40 [46080/50176]	Loss: 0.5523
Training Epoch: 40 [47104/50176]	Loss: 0.5090
Training Epoch: 40 [48128/50176]	Loss: 0.5574
Training Epoch: 40 [49152/50176]	Loss: 0.5262
Training Epoch: 40 [50176/50176]	Loss: 0.5224
2022-12-09 00:11:21.331 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:11:21,346 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.75 energy=515.35
2022-12-08 19:11:21,346 [ZeusDataLoader(train)] Up to epoch 41: time=2068.20, energy=303100.26, cost=332517.28
2022-12-08 19:11:21,346 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:11:21,346 [ZeusDataLoader(train)] Expected next epoch: time=2115.52, energy=310321.50, cost=340269.14
2022-12-08 19:11:21,347 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0019, Accuracy: 0.5791
2022-12-08 19:11:21,595 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:11:21,596 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:11:21.598 [ZeusMonitor] Monitor started.
2022-12-09 00:11:21.598 [ZeusMonitor] Running indefinitely. 2022-12-09 00:11:21.598 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:11:21.598 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e42+gpu0.power.log
2022-12-08 19:12:05,604 [ZeusDataLoader(train)] train epoch 42 done: time=44.25 energy=6721.53
2022-12-08 19:12:05,608 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.4174
Training Epoch: 41 [2048/50176]	Loss: 0.4170
Training Epoch: 41 [3072/50176]	Loss: 0.4483
Training Epoch: 41 [4096/50176]	Loss: 0.4489
Training Epoch: 41 [5120/50176]	Loss: 0.4237
Training Epoch: 41 [6144/50176]	Loss: 0.4474
Training Epoch: 41 [7168/50176]	Loss: 0.4761
Training Epoch: 41 [8192/50176]	Loss: 0.4310
Training Epoch: 41 [9216/50176]	Loss: 0.4490
Training Epoch: 41 [10240/50176]	Loss: 0.4535
Training Epoch: 41 [11264/50176]	Loss: 0.4499
Training Epoch: 41 [12288/50176]	Loss: 0.4122
Training Epoch: 41 [13312/50176]	Loss: 0.4497
Training Epoch: 41 [14336/50176]	Loss: 0.5107
Training Epoch: 41 [15360/50176]	Loss: 0.4677
Training Epoch: 41 [16384/50176]	Loss: 0.4005
Training Epoch: 41 [17408/50176]	Loss: 0.4235
Training Epoch: 41 [18432/50176]	Loss: 0.4593
Training Epoch: 41 [19456/50176]	Loss: 0.4769
Training Epoch: 41 [20480/50176]	Loss: 0.4326
Training Epoch: 41 [21504/50176]	Loss: 0.4720
Training Epoch: 41 [22528/50176]	Loss: 0.4570
Training Epoch: 41 [23552/50176]	Loss: 0.4697
Training Epoch: 41 [24576/50176]	Loss: 0.4434
Training Epoch: 41 [25600/50176]	Loss: 0.4932
Training Epoch: 41 [26624/50176]	Loss: 0.4850
Training Epoch: 41 [27648/50176]	Loss: 0.4464
Training Epoch: 41 [28672/50176]	Loss: 0.5358
Training Epoch: 41 [29696/50176]	Loss: 0.4802
Training Epoch: 41 [30720/50176]	Loss: 0.4836
Training Epoch: 41 [31744/50176]	Loss: 0.4647
Training Epoch: 41 [32768/50176]	Loss: 0.4805
Training Epoch: 41 [33792/50176]	Loss: 0.4601
Training Epoch: 41 [34816/50176]	Loss: 0.4731
Training Epoch: 41 [35840/50176]	Loss: 0.4830
Training Epoch: 41 [36864/50176]	Loss: 0.4891
Training Epoch: 41 [37888/50176]	Loss: 0.4755
Training Epoch: 41 [38912/50176]	Loss: 0.4849
Training Epoch: 41 [39936/50176]	Loss: 0.4964
Training Epoch: 41 [40960/50176]	Loss: 0.5388
Training Epoch: 41 [41984/50176]	Loss: 0.5799
Training Epoch: 41 [43008/50176]	Loss: 0.4695
Training Epoch: 41 [44032/50176]	Loss: 0.5276
Training Epoch: 41 [45056/50176]	Loss: 0.5029
Training Epoch: 41 [46080/50176]	Loss: 0.4995
Training Epoch: 41 [47104/50176]	Loss: 0.5166
Training Epoch: 41 [48128/50176]	Loss: 0.4674
Training Epoch: 41 [49152/50176]	Loss: 0.5049
Training Epoch: 41 [50176/50176]	Loss: 0.4925
2022-12-09 00:12:09.367 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:12:09,378 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.76 energy=519.00
2022-12-08 19:12:09,378 [ZeusDataLoader(train)] Up to epoch 42: time=2116.20, energy=310340.79, cost=340338.32
2022-12-08 19:12:09,378 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:12:09,378 [ZeusDataLoader(train)] Expected next epoch: time=2163.53, energy=317562.03, cost=348090.18
2022-12-08 19:12:09,379 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0019, Accuracy: 0.5865
2022-12-08 19:12:09,588 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:12:09,589 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:12:09.593 [ZeusMonitor] Monitor started.
2022-12-09 00:12:09.593 [ZeusMonitor] Running indefinitely. 2022-12-09 00:12:09.593 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:12:09.593 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e43+gpu0.power.log
2022-12-08 19:12:53,665 [ZeusDataLoader(train)] train epoch 43 done: time=44.28 energy=6717.20
2022-12-08 19:12:53,669 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.4127
Training Epoch: 42 [2048/50176]	Loss: 0.3816
Training Epoch: 42 [3072/50176]	Loss: 0.4021
Training Epoch: 42 [4096/50176]	Loss: 0.3932
Training Epoch: 42 [5120/50176]	Loss: 0.4101
Training Epoch: 42 [6144/50176]	Loss: 0.4383
Training Epoch: 42 [7168/50176]	Loss: 0.4045
Training Epoch: 42 [8192/50176]	Loss: 0.3940
Training Epoch: 42 [9216/50176]	Loss: 0.3730
Training Epoch: 42 [10240/50176]	Loss: 0.4326
Training Epoch: 42 [11264/50176]	Loss: 0.3911
Training Epoch: 42 [12288/50176]	Loss: 0.4275
Training Epoch: 42 [13312/50176]	Loss: 0.4537
Training Epoch: 42 [14336/50176]	Loss: 0.4179
Training Epoch: 42 [15360/50176]	Loss: 0.4324
Training Epoch: 42 [16384/50176]	Loss: 0.4023
Training Epoch: 42 [17408/50176]	Loss: 0.4118
Training Epoch: 42 [18432/50176]	Loss: 0.3925
Training Epoch: 42 [19456/50176]	Loss: 0.4891
Training Epoch: 42 [20480/50176]	Loss: 0.3758
Training Epoch: 42 [21504/50176]	Loss: 0.4419
Training Epoch: 42 [22528/50176]	Loss: 0.4413
Training Epoch: 42 [23552/50176]	Loss: 0.4251
Training Epoch: 42 [24576/50176]	Loss: 0.4219
Training Epoch: 42 [25600/50176]	Loss: 0.4485
Training Epoch: 42 [26624/50176]	Loss: 0.4092
Training Epoch: 42 [27648/50176]	Loss: 0.5118
Training Epoch: 42 [28672/50176]	Loss: 0.4740
Training Epoch: 42 [29696/50176]	Loss: 0.4748
Training Epoch: 42 [30720/50176]	Loss: 0.4263
Training Epoch: 42 [31744/50176]	Loss: 0.4897
Training Epoch: 42 [32768/50176]	Loss: 0.4519
Training Epoch: 42 [33792/50176]	Loss: 0.4534
Training Epoch: 42 [34816/50176]	Loss: 0.4900
Training Epoch: 42 [35840/50176]	Loss: 0.5045
Training Epoch: 42 [36864/50176]	Loss: 0.4419
Training Epoch: 42 [37888/50176]	Loss: 0.4682
Training Epoch: 42 [38912/50176]	Loss: 0.4792
Training Epoch: 42 [39936/50176]	Loss: 0.4292
Training Epoch: 42 [40960/50176]	Loss: 0.4580
Training Epoch: 42 [41984/50176]	Loss: 0.4653
Training Epoch: 42 [43008/50176]	Loss: 0.4943
Training Epoch: 42 [44032/50176]	Loss: 0.4743
Training Epoch: 42 [45056/50176]	Loss: 0.4851
Training Epoch: 42 [46080/50176]	Loss: 0.4886
Training Epoch: 42 [47104/50176]	Loss: 0.5079
Training Epoch: 42 [48128/50176]	Loss: 0.4330
Training Epoch: 42 [49152/50176]	Loss: 0.5045
Training Epoch: 42 [50176/50176]	Loss: 0.4854
2022-12-09 00:12:57.410 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:12:57,422 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.74 energy=514.01
2022-12-08 19:12:57,423 [ZeusDataLoader(train)] Up to epoch 43: time=2164.23, energy=317572.00, cost=348155.87
2022-12-08 19:12:57,423 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:12:57,423 [ZeusDataLoader(train)] Expected next epoch: time=2211.56, energy=324793.24, cost=355907.74
2022-12-08 19:12:57,424 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0019, Accuracy: 0.5731
2022-12-08 19:12:57,625 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:12:57,626 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:12:57.630 [ZeusMonitor] Monitor started.
2022-12-09 00:12:57.630 [ZeusMonitor] Running indefinitely. 2022-12-09 00:12:57.630 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:12:57.630 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e44+gpu0.power.log
2022-12-08 19:13:41,658 [ZeusDataLoader(train)] train epoch 44 done: time=44.23 energy=6726.09
2022-12-08 19:13:41,662 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.3495
Training Epoch: 43 [2048/50176]	Loss: 0.4277
Training Epoch: 43 [3072/50176]	Loss: 0.3662
Training Epoch: 43 [4096/50176]	Loss: 0.3902
Training Epoch: 43 [5120/50176]	Loss: 0.4000
Training Epoch: 43 [6144/50176]	Loss: 0.3612
Training Epoch: 43 [7168/50176]	Loss: 0.4101
Training Epoch: 43 [8192/50176]	Loss: 0.4090
Training Epoch: 43 [9216/50176]	Loss: 0.4601
Training Epoch: 43 [10240/50176]	Loss: 0.4337
Training Epoch: 43 [11264/50176]	Loss: 0.4104
Training Epoch: 43 [12288/50176]	Loss: 0.3723
Training Epoch: 43 [13312/50176]	Loss: 0.3892
Training Epoch: 43 [14336/50176]	Loss: 0.4191
Training Epoch: 43 [15360/50176]	Loss: 0.4107
Training Epoch: 43 [16384/50176]	Loss: 0.4659
Training Epoch: 43 [17408/50176]	Loss: 0.3940
Training Epoch: 43 [18432/50176]	Loss: 0.3661
Training Epoch: 43 [19456/50176]	Loss: 0.4052
Training Epoch: 43 [20480/50176]	Loss: 0.3818
Training Epoch: 43 [21504/50176]	Loss: 0.4172
Training Epoch: 43 [22528/50176]	Loss: 0.3942
Training Epoch: 43 [23552/50176]	Loss: 0.3619
Training Epoch: 43 [24576/50176]	Loss: 0.4090
Training Epoch: 43 [25600/50176]	Loss: 0.4363
Training Epoch: 43 [26624/50176]	Loss: 0.4440
Training Epoch: 43 [27648/50176]	Loss: 0.4212
Training Epoch: 43 [28672/50176]	Loss: 0.4367
Training Epoch: 43 [29696/50176]	Loss: 0.4035
Training Epoch: 43 [30720/50176]	Loss: 0.4248
Training Epoch: 43 [31744/50176]	Loss: 0.4100
Training Epoch: 43 [32768/50176]	Loss: 0.4476
Training Epoch: 43 [33792/50176]	Loss: 0.4204
Training Epoch: 43 [34816/50176]	Loss: 0.4420
Training Epoch: 43 [35840/50176]	Loss: 0.4324
Training Epoch: 43 [36864/50176]	Loss: 0.4662
Training Epoch: 43 [37888/50176]	Loss: 0.4698
Training Epoch: 43 [38912/50176]	Loss: 0.4208
Training Epoch: 43 [39936/50176]	Loss: 0.4385
Training Epoch: 43 [40960/50176]	Loss: 0.4015
Training Epoch: 43 [41984/50176]	Loss: 0.4481
Training Epoch: 43 [43008/50176]	Loss: 0.4424
Training Epoch: 43 [44032/50176]	Loss: 0.4482
Training Epoch: 43 [45056/50176]	Loss: 0.4623
Training Epoch: 43 [46080/50176]	Loss: 0.4833
Training Epoch: 43 [47104/50176]	Loss: 0.4871
Training Epoch: 43 [48128/50176]	Loss: 0.4444
Training Epoch: 43 [49152/50176]	Loss: 0.4254
Training Epoch: 43 [50176/50176]	Loss: 0.4597
2022-12-09 00:13:45.446 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:13:45,502 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.83 energy=535.47
2022-12-08 19:13:45,502 [ZeusDataLoader(train)] Up to epoch 44: time=2212.28, energy=324833.56, cost=355991.58
2022-12-08 19:13:45,502 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:13:45,502 [ZeusDataLoader(train)] Expected next epoch: time=2259.61, energy=332054.80, cost=363743.44
2022-12-08 19:13:45,503 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0020, Accuracy: 0.5841
2022-12-08 19:13:45,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:13:45,758 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:13:45.760 [ZeusMonitor] Monitor started.
2022-12-09 00:13:45.760 [ZeusMonitor] Running indefinitely. 2022-12-09 00:13:45.760 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:13:45.760 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e45+gpu0.power.log
2022-12-08 19:14:29,725 [ZeusDataLoader(train)] train epoch 45 done: time=44.21 energy=6712.17
2022-12-08 19:14:29,728 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.3403
Training Epoch: 44 [2048/50176]	Loss: 0.3781
Training Epoch: 44 [3072/50176]	Loss: 0.3875
Training Epoch: 44 [4096/50176]	Loss: 0.3654
Training Epoch: 44 [5120/50176]	Loss: 0.3638
Training Epoch: 44 [6144/50176]	Loss: 0.3319
Training Epoch: 44 [7168/50176]	Loss: 0.3626
Training Epoch: 44 [8192/50176]	Loss: 0.3504
Training Epoch: 44 [9216/50176]	Loss: 0.3949
Training Epoch: 44 [10240/50176]	Loss: 0.3355
Training Epoch: 44 [11264/50176]	Loss: 0.4018
Training Epoch: 44 [12288/50176]	Loss: 0.3267
Training Epoch: 44 [13312/50176]	Loss: 0.3886
Training Epoch: 44 [14336/50176]	Loss: 0.3419
Training Epoch: 44 [15360/50176]	Loss: 0.3384
Training Epoch: 44 [16384/50176]	Loss: 0.3653
Training Epoch: 44 [17408/50176]	Loss: 0.3916
Training Epoch: 44 [18432/50176]	Loss: 0.4125
Training Epoch: 44 [19456/50176]	Loss: 0.4015
Training Epoch: 44 [20480/50176]	Loss: 0.3936
Training Epoch: 44 [21504/50176]	Loss: 0.4428
Training Epoch: 44 [22528/50176]	Loss: 0.3767
Training Epoch: 44 [23552/50176]	Loss: 0.3722
Training Epoch: 44 [24576/50176]	Loss: 0.4042
Training Epoch: 44 [25600/50176]	Loss: 0.4053
Training Epoch: 44 [26624/50176]	Loss: 0.3994
Training Epoch: 44 [27648/50176]	Loss: 0.3848
Training Epoch: 44 [28672/50176]	Loss: 0.3935
Training Epoch: 44 [29696/50176]	Loss: 0.4012
Training Epoch: 44 [30720/50176]	Loss: 0.3738
Training Epoch: 44 [31744/50176]	Loss: 0.4478
Training Epoch: 44 [32768/50176]	Loss: 0.3632
Training Epoch: 44 [33792/50176]	Loss: 0.4287
Training Epoch: 44 [34816/50176]	Loss: 0.4126
Training Epoch: 44 [35840/50176]	Loss: 0.4251
Training Epoch: 44 [36864/50176]	Loss: 0.4388
Training Epoch: 44 [37888/50176]	Loss: 0.4477
Training Epoch: 44 [38912/50176]	Loss: 0.4238
Training Epoch: 44 [39936/50176]	Loss: 0.4248
Training Epoch: 44 [40960/50176]	Loss: 0.4151
Training Epoch: 44 [41984/50176]	Loss: 0.3991
Training Epoch: 44 [43008/50176]	Loss: 0.3854
Training Epoch: 44 [44032/50176]	Loss: 0.4105
Training Epoch: 44 [45056/50176]	Loss: 0.4490
Training Epoch: 44 [46080/50176]	Loss: 0.4354
Training Epoch: 44 [47104/50176]	Loss: 0.4373
Training Epoch: 44 [48128/50176]	Loss: 0.4051
Training Epoch: 44 [49152/50176]	Loss: 0.4476
Training Epoch: 44 [50176/50176]	Loss: 0.4059
2022-12-09 00:14:33.556 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:14:33,599 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.86 energy=531.39
2022-12-08 19:14:33,599 [ZeusDataLoader(train)] Up to epoch 45: time=2260.36, energy=332077.12, cost=363819.83
2022-12-08 19:14:33,599 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:14:33,599 [ZeusDataLoader(train)] Expected next epoch: time=2307.69, energy=339298.36, cost=371571.69
2022-12-08 19:14:33,600 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0020, Accuracy: 0.5862
2022-12-08 19:14:33,852 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:14:33,853 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:14:33.855 [ZeusMonitor] Monitor started.
2022-12-09 00:14:33.855 [ZeusMonitor] Running indefinitely. 2022-12-09 00:14:33.855 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:14:33.855 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e46+gpu0.power.log
2022-12-08 19:15:17,874 [ZeusDataLoader(train)] train epoch 46 done: time=44.27 energy=6714.64
2022-12-08 19:15:17,878 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.3480
Training Epoch: 45 [2048/50176]	Loss: 0.3210
Training Epoch: 45 [3072/50176]	Loss: 0.3123
Training Epoch: 45 [4096/50176]	Loss: 0.3781
Training Epoch: 45 [5120/50176]	Loss: 0.3284
Training Epoch: 45 [6144/50176]	Loss: 0.3655
Training Epoch: 45 [7168/50176]	Loss: 0.2988
Training Epoch: 45 [8192/50176]	Loss: 0.3345
Training Epoch: 45 [9216/50176]	Loss: 0.3732
Training Epoch: 45 [10240/50176]	Loss: 0.3727
Training Epoch: 45 [11264/50176]	Loss: 0.3763
Training Epoch: 45 [12288/50176]	Loss: 0.3889
Training Epoch: 45 [13312/50176]	Loss: 0.3685
Training Epoch: 45 [14336/50176]	Loss: 0.3918
Training Epoch: 45 [15360/50176]	Loss: 0.3767
Training Epoch: 45 [16384/50176]	Loss: 0.4316
Training Epoch: 45 [17408/50176]	Loss: 0.2987
Training Epoch: 45 [18432/50176]	Loss: 0.3800
Training Epoch: 45 [19456/50176]	Loss: 0.3649
Training Epoch: 45 [20480/50176]	Loss: 0.3808
Training Epoch: 45 [21504/50176]	Loss: 0.3906
Training Epoch: 45 [22528/50176]	Loss: 0.3641
Training Epoch: 45 [23552/50176]	Loss: 0.3367
Training Epoch: 45 [24576/50176]	Loss: 0.3595
Training Epoch: 45 [25600/50176]	Loss: 0.3631
Training Epoch: 45 [26624/50176]	Loss: 0.3856
Training Epoch: 45 [27648/50176]	Loss: 0.3615
Training Epoch: 45 [28672/50176]	Loss: 0.3727
Training Epoch: 45 [29696/50176]	Loss: 0.3715
Training Epoch: 45 [30720/50176]	Loss: 0.3694
Training Epoch: 45 [31744/50176]	Loss: 0.3623
Training Epoch: 45 [32768/50176]	Loss: 0.3849
Training Epoch: 45 [33792/50176]	Loss: 0.3333
Training Epoch: 45 [34816/50176]	Loss: 0.3620
Training Epoch: 45 [35840/50176]	Loss: 0.4137
Training Epoch: 45 [36864/50176]	Loss: 0.3978
Training Epoch: 45 [37888/50176]	Loss: 0.4144
Training Epoch: 45 [38912/50176]	Loss: 0.3836
Training Epoch: 45 [39936/50176]	Loss: 0.4100
Training Epoch: 45 [40960/50176]	Loss: 0.4012
Training Epoch: 45 [41984/50176]	Loss: 0.3992
Training Epoch: 45 [43008/50176]	Loss: 0.4534
Training Epoch: 45 [44032/50176]	Loss: 0.4074
Training Epoch: 45 [45056/50176]	Loss: 0.4564
Training Epoch: 45 [46080/50176]	Loss: 0.4704
Training Epoch: 45 [47104/50176]	Loss: 0.3931
Training Epoch: 45 [48128/50176]	Loss: 0.3254
Training Epoch: 45 [49152/50176]	Loss: 0.3762
Training Epoch: 45 [50176/50176]	Loss: 0.4948
2022-12-09 00:15:21.666 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:15:21,678 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.79 energy=537.15
2022-12-08 19:15:21,678 [ZeusDataLoader(train)] Up to epoch 46: time=2308.41, energy=339328.90, cost=371650.64
2022-12-08 19:15:21,678 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:15:21,678 [ZeusDataLoader(train)] Expected next epoch: time=2355.74, energy=346550.14, cost=379402.50
2022-12-08 19:15:21,679 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0020, Accuracy: 0.5867
2022-12-08 19:15:21,940 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:15:21,941 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:15:21.943 [ZeusMonitor] Monitor started.
2022-12-09 00:15:21.943 [ZeusMonitor] Running indefinitely. 2022-12-09 00:15:21.943 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:15:21.943 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e47+gpu0.power.log
2022-12-08 19:16:05,859 [ZeusDataLoader(train)] train epoch 47 done: time=44.17 energy=6707.78
2022-12-08 19:16:05,862 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.2892
Training Epoch: 46 [2048/50176]	Loss: 0.3557
Training Epoch: 46 [3072/50176]	Loss: 0.3622
Training Epoch: 46 [4096/50176]	Loss: 0.3359
Training Epoch: 46 [5120/50176]	Loss: 0.3422
Training Epoch: 46 [6144/50176]	Loss: 0.3592
Training Epoch: 46 [7168/50176]	Loss: 0.3468
Training Epoch: 46 [8192/50176]	Loss: 0.3063
Training Epoch: 46 [9216/50176]	Loss: 0.3783
Training Epoch: 46 [10240/50176]	Loss: 0.3474
Training Epoch: 46 [11264/50176]	Loss: 0.3344
Training Epoch: 46 [12288/50176]	Loss: 0.3443
Training Epoch: 46 [13312/50176]	Loss: 0.2973
Training Epoch: 46 [14336/50176]	Loss: 0.2976
Training Epoch: 46 [15360/50176]	Loss: 0.3328
Training Epoch: 46 [16384/50176]	Loss: 0.3578
Training Epoch: 46 [17408/50176]	Loss: 0.3811
Training Epoch: 46 [18432/50176]	Loss: 0.3830
Training Epoch: 46 [19456/50176]	Loss: 0.3642
Training Epoch: 46 [20480/50176]	Loss: 0.3237
Training Epoch: 46 [21504/50176]	Loss: 0.4010
Training Epoch: 46 [22528/50176]	Loss: 0.3338
Training Epoch: 46 [23552/50176]	Loss: 0.3972
Training Epoch: 46 [24576/50176]	Loss: 0.3356
Training Epoch: 46 [25600/50176]	Loss: 0.3587
Training Epoch: 46 [26624/50176]	Loss: 0.3768
Training Epoch: 46 [27648/50176]	Loss: 0.3724
Training Epoch: 46 [28672/50176]	Loss: 0.3625
Training Epoch: 46 [29696/50176]	Loss: 0.3545
Training Epoch: 46 [30720/50176]	Loss: 0.3691
Training Epoch: 46 [31744/50176]	Loss: 0.3945
Training Epoch: 46 [32768/50176]	Loss: 0.3070
Training Epoch: 46 [33792/50176]	Loss: 0.4173
Training Epoch: 46 [34816/50176]	Loss: 0.3874
Training Epoch: 46 [35840/50176]	Loss: 0.3916
Training Epoch: 46 [36864/50176]	Loss: 0.3500
Training Epoch: 46 [37888/50176]	Loss: 0.3660
Training Epoch: 46 [38912/50176]	Loss: 0.3596
Training Epoch: 46 [39936/50176]	Loss: 0.4028
Training Epoch: 46 [40960/50176]	Loss: 0.3887
Training Epoch: 46 [41984/50176]	Loss: 0.3937
Training Epoch: 46 [43008/50176]	Loss: 0.3660
Training Epoch: 46 [44032/50176]	Loss: 0.3718
Training Epoch: 46 [45056/50176]	Loss: 0.3737
Training Epoch: 46 [46080/50176]	Loss: 0.3886
Training Epoch: 46 [47104/50176]	Loss: 0.4113
Training Epoch: 46 [48128/50176]	Loss: 0.3846
Training Epoch: 46 [49152/50176]	Loss: 0.3993
Training Epoch: 46 [50176/50176]	Loss: 0.4050
2022-12-09 00:16:09.671 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:16:09,724 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.85 energy=529.87
2022-12-08 19:16:09,724 [ZeusDataLoader(train)] Up to epoch 47: time=2356.44, energy=346566.55, cost=379471.51
2022-12-08 19:16:09,724 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:16:09,724 [ZeusDataLoader(train)] Expected next epoch: time=2403.77, energy=353787.79, cost=387223.38
2022-12-08 19:16:09,725 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0020, Accuracy: 0.5817
2022-12-08 19:16:09,952 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:16:09,953 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:16:09.955 [ZeusMonitor] Monitor started.
2022-12-09 00:16:09.955 [ZeusMonitor] Running indefinitely. 2022-12-09 00:16:09.955 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:16:09.955 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e48+gpu0.power.log
2022-12-08 19:16:54,475 [ZeusDataLoader(train)] train epoch 48 done: time=44.74 energy=6794.35
2022-12-08 19:16:54,479 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.3089
Training Epoch: 47 [2048/50176]	Loss: 0.3428
Training Epoch: 47 [3072/50176]	Loss: 0.3527
Training Epoch: 47 [4096/50176]	Loss: 0.3045
Training Epoch: 47 [5120/50176]	Loss: 0.3184
Training Epoch: 47 [6144/50176]	Loss: 0.3434
Training Epoch: 47 [7168/50176]	Loss: 0.3183
Training Epoch: 47 [8192/50176]	Loss: 0.3277
Training Epoch: 47 [9216/50176]	Loss: 0.3089
Training Epoch: 47 [10240/50176]	Loss: 0.3518
Training Epoch: 47 [11264/50176]	Loss: 0.3451
Training Epoch: 47 [12288/50176]	Loss: 0.3287
Training Epoch: 47 [13312/50176]	Loss: 0.3466
Training Epoch: 47 [14336/50176]	Loss: 0.3235
Training Epoch: 47 [15360/50176]	Loss: 0.2991
Training Epoch: 47 [16384/50176]	Loss: 0.3622
Training Epoch: 47 [17408/50176]	Loss: 0.4037
Training Epoch: 47 [18432/50176]	Loss: 0.3255
Training Epoch: 47 [19456/50176]	Loss: 0.3383
Training Epoch: 47 [20480/50176]	Loss: 0.3063
Training Epoch: 47 [21504/50176]	Loss: 0.3295
Training Epoch: 47 [22528/50176]	Loss: 0.3555
Training Epoch: 47 [23552/50176]	Loss: 0.3398
Training Epoch: 47 [24576/50176]	Loss: 0.3323
Training Epoch: 47 [25600/50176]	Loss: 0.3728
Training Epoch: 47 [26624/50176]	Loss: 0.3006
Training Epoch: 47 [27648/50176]	Loss: 0.3421
Training Epoch: 47 [28672/50176]	Loss: 0.3844
Training Epoch: 47 [29696/50176]	Loss: 0.3558
Training Epoch: 47 [30720/50176]	Loss: 0.3913
Training Epoch: 47 [31744/50176]	Loss: 0.3705
Training Epoch: 47 [32768/50176]	Loss: 0.3872
Training Epoch: 47 [33792/50176]	Loss: 0.3960
Training Epoch: 47 [34816/50176]	Loss: 0.3549
Training Epoch: 47 [35840/50176]	Loss: 0.3374
Training Epoch: 47 [36864/50176]	Loss: 0.3631
Training Epoch: 47 [37888/50176]	Loss: 0.3901
Training Epoch: 47 [38912/50176]	Loss: 0.3817
Training Epoch: 47 [39936/50176]	Loss: 0.4068
Training Epoch: 47 [40960/50176]	Loss: 0.3553
Training Epoch: 47 [41984/50176]	Loss: 0.3894
Training Epoch: 47 [43008/50176]	Loss: 0.3682
Training Epoch: 47 [44032/50176]	Loss: 0.3745
Training Epoch: 47 [45056/50176]	Loss: 0.3620
Training Epoch: 47 [46080/50176]	Loss: 0.3991
Training Epoch: 47 [47104/50176]	Loss: 0.3540
Training Epoch: 47 [48128/50176]	Loss: 0.3690
Training Epoch: 47 [49152/50176]	Loss: 0.3846
Training Epoch: 47 [50176/50176]	Loss: 0.3826
2022-12-09 00:16:58.360 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:16:58,393 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.90 energy=541.33
2022-12-08 19:16:58,393 [ZeusDataLoader(train)] Up to epoch 48: time=2405.08, energy=353902.23, cost=387395.79
2022-12-08 19:16:58,393 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.33 energy=7221.24
2022-12-08 19:16:58,393 [ZeusDataLoader(train)] Expected next epoch: time=2452.41, energy=361123.47, cost=395147.65
2022-12-08 19:16:58,394 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0020, Accuracy: 0.5938
2022-12-08 19:16:58,668 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-09 00:16:58.669 [ZeusMonitor] Monitor started.
2022-12-09 00:16:58.669 [ZeusMonitor] Running indefinitely. 2022-12-09 00:16:58.669 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:16:58.669 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e49+gpu0.power.log
2022-12-08 19:16:58,669 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 19:17:43,181 [ZeusDataLoader(train)] train epoch 49 done: time=44.78 energy=6800.64
2022-12-08 19:17:43,185 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.2597
Training Epoch: 48 [2048/50176]	Loss: 0.2806
Training Epoch: 48 [3072/50176]	Loss: 0.3063
Training Epoch: 48 [4096/50176]	Loss: 0.2872
Training Epoch: 48 [5120/50176]	Loss: 0.2942
Training Epoch: 48 [6144/50176]	Loss: 0.2912
Training Epoch: 48 [7168/50176]	Loss: 0.3245
Training Epoch: 48 [8192/50176]	Loss: 0.3026
Training Epoch: 48 [9216/50176]	Loss: 0.3093
Training Epoch: 48 [10240/50176]	Loss: 0.3072
Training Epoch: 48 [11264/50176]	Loss: 0.3524
Training Epoch: 48 [12288/50176]	Loss: 0.3295
Training Epoch: 48 [13312/50176]	Loss: 0.2543
Training Epoch: 48 [14336/50176]	Loss: 0.3375
Training Epoch: 48 [15360/50176]	Loss: 0.3057
Training Epoch: 48 [16384/50176]	Loss: 0.3040
Training Epoch: 48 [17408/50176]	Loss: 0.2990
Training Epoch: 48 [18432/50176]	Loss: 0.2814
Training Epoch: 48 [19456/50176]	Loss: 0.2984
Training Epoch: 48 [20480/50176]	Loss: 0.3076
Training Epoch: 48 [21504/50176]	Loss: 0.3323
Training Epoch: 48 [22528/50176]	Loss: 0.2837
Training Epoch: 48 [23552/50176]	Loss: 0.3297
Training Epoch: 48 [24576/50176]	Loss: 0.3358
Training Epoch: 48 [25600/50176]	Loss: 0.3170
Training Epoch: 48 [26624/50176]	Loss: 0.2975
Training Epoch: 48 [27648/50176]	Loss: 0.2959
Training Epoch: 48 [28672/50176]	Loss: 0.3238
Training Epoch: 48 [29696/50176]	Loss: 0.3257
Training Epoch: 48 [30720/50176]	Loss: 0.3276
Training Epoch: 48 [31744/50176]	Loss: 0.3221
Training Epoch: 48 [32768/50176]	Loss: 0.3420
Training Epoch: 48 [33792/50176]	Loss: 0.3423
Training Epoch: 48 [34816/50176]	Loss: 0.3077
Training Epoch: 48 [35840/50176]	Loss: 0.2975
Training Epoch: 48 [36864/50176]	Loss: 0.3218
Training Epoch: 48 [37888/50176]	Loss: 0.3217
Training Epoch: 48 [38912/50176]	Loss: 0.3527
Training Epoch: 48 [39936/50176]	Loss: 0.3837
Training Epoch: 48 [40960/50176]	Loss: 0.3420
Training Epoch: 48 [41984/50176]	Loss: 0.3375
Training Epoch: 48 [43008/50176]	Loss: 0.3828
Training Epoch: 48 [44032/50176]	Loss: 0.3338
Training Epoch: 48 [45056/50176]	Loss: 0.2942
Training Epoch: 48 [46080/50176]	Loss: 0.3672
Training Epoch: 48 [47104/50176]	Loss: 0.3633
Training Epoch: 48 [48128/50176]	Loss: 0.3702
Training Epoch: 48 [49152/50176]	Loss: 0.3620
Training Epoch: 48 [50176/50176]	Loss: 0.3799
2022-12-09 00:17:47.043 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:17:47,093 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.90 energy=542.97
2022-12-08 19:17:47,093 [ZeusDataLoader(train)] Up to epoch 49: time=2453.76, energy=361245.85, cost=395326.87
2022-12-08 19:17:47,094 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-08 19:17:47,094 [ZeusDataLoader(train)] Training done.
2022-12-08 19:17:47,094 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec02+try01+bs1024+lr0.0080000.train.json: {"energy": 361245.8512208044, "time": 2453.759384225974, "cost": 395326.87173017487, "num_epochs": 49, "reached": true}
Validation Epoch: 48, Average loss: 0.0020, Accuracy: 0.6037

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 361245.8512208044, 'time': 2453.759384225974, 'cost': 395326.87173017487, 'num_epochs': 49, 'reached': True}
[run job; power] power_stats={'job_id': 'rec02+try01', 'train_power': {'175000': 154.89953148785654, '150000': 146.71964346885522, '125000': 122.82062575056527, '100000': 101.98676264846775}, 'train_throughput': {'175000': 1.133277720351713, '150000': 1.0989740762460123, '125000': 0.9681039581727158, '100000': 0.3668091756560675}, 'eval_power': {'175000': 128.0308069670569, '150000': 131.06058502963776, '125000': 115.01601627718911}, 'eval_throughput': {'175000': 2.444335818105813, '150000': 2.587981317609751, '125000': 2.3750444149937446}, 'optimal_pl': 175000}
[Zeus Master] cost=395326.87173017487

[Zeus Master] Reached target metric in 1 try.
[run job] Launching job with BS 1024: and LR: 0.009
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224', 'ZEUS_JOB_ID': 'rec03+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.009']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec03+try01.train.log'
2022-12-08 19:17:51,902 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 19:17:51,902 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 19:17:51,903 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 19:17:51,948 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 19:17:51,949 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 19:17:54,292 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 19:17:54,293 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 19:17:54,606 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-09 00:17:54.609 [ZeusMonitor] Monitor started.
2022-12-09 00:17:54.609 [ZeusMonitor] Running indefinitely. 2022-12-09 00:17:54.609 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:17:54.609 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e1+gpu0.power.log
2022-12-08 19:17:55,294 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 19:17:55,294 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 19:18:04,200 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 19:18:37,923 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 19:18:39,596 [ZeusDataLoader(train)] train epoch 1 done: time=45.30 energy=6770.11
2022-12-08 19:18:39,600 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 6.9068
Training Epoch: 0 [3072/50176]	Loss: 5.7365
Training Epoch: 0 [4096/50176]	Loss: 4.9163
Training Epoch: 0 [5120/50176]	Loss: 4.9819
Training Epoch: 0 [6144/50176]	Loss: 4.7946
Training Epoch: 0 [7168/50176]	Loss: 4.8841
Training Epoch: 0 [8192/50176]	Loss: 4.7931
Training Epoch: 0 [9216/50176]	Loss: 4.7013
Training Epoch: 0 [10240/50176]	Loss: 4.7538
Training Epoch: 0 [11264/50176]	Loss: 4.8006
Training Epoch: 0 [12288/50176]	Loss: 4.6580
Training Epoch: 0 [13312/50176]	Loss: 4.6226
Training Epoch: 0 [14336/50176]	Loss: 4.6684
Training Epoch: 0 [15360/50176]	Loss: 4.5813
Training Epoch: 0 [16384/50176]	Loss: 4.5590
Training Epoch: 0 [17408/50176]	Loss: 4.5651
Training Epoch: 0 [18432/50176]	Loss: 4.5534
Training Epoch: 0 [19456/50176]	Loss: 4.5627
Training Epoch: 0 [20480/50176]	Loss: 4.5205
Training Epoch: 0 [21504/50176]	Loss: 4.4916
Training Epoch: 0 [22528/50176]	Loss: 4.5052
Training Epoch: 0 [23552/50176]	Loss: 4.5267
Training Epoch: 0 [24576/50176]	Loss: 4.5102
Training Epoch: 0 [25600/50176]	Loss: 4.5090
Training Epoch: 0 [26624/50176]	Loss: 4.4724
Training Epoch: 0 [27648/50176]	Loss: 4.4666
Training Epoch: 0 [28672/50176]	Loss: 4.4158
Training Epoch: 0 [29696/50176]	Loss: 4.4672
Training Epoch: 0 [30720/50176]	Loss: 4.4666
Training Epoch: 0 [31744/50176]	Loss: 4.4810
Training Epoch: 0 [32768/50176]	Loss: 4.4261
Training Epoch: 0 [33792/50176]	Loss: 4.4433
Training Epoch: 0 [34816/50176]	Loss: 4.4165
Training Epoch: 0 [35840/50176]	Loss: 4.3994
Training Epoch: 0 [36864/50176]	Loss: 4.3858
Training Epoch: 0 [37888/50176]	Loss: 4.4108
Training Epoch: 0 [38912/50176]	Loss: 4.3787
Training Epoch: 0 [39936/50176]	Loss: 4.3848
Training Epoch: 0 [40960/50176]	Loss: 4.3648
Training Epoch: 0 [41984/50176]	Loss: 4.3750
Training Epoch: 0 [43008/50176]	Loss: 4.3642
Training Epoch: 0 [44032/50176]	Loss: 4.3785
Training Epoch: 0 [45056/50176]	Loss: 4.3438
Training Epoch: 0 [46080/50176]	Loss: 4.2987
Training Epoch: 0 [47104/50176]	Loss: 4.3230
Training Epoch: 0 [48128/50176]	Loss: 4.3047
Training Epoch: 0 [49152/50176]	Loss: 4.3094
Training Epoch: 0 [50176/50176]	Loss: 4.2697
2022-12-09 00:18:43.402 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:18:43,447 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.84 energy=527.97
2022-12-08 19:18:43,448 [ZeusDataLoader(train)] Up to epoch 1: time=49.13, energy=7298.07, cost=7948.35
2022-12-08 19:18:43,449 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0042, Accuracy: 0.0363
2022-12-08 19:18:43,715 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-09 00:18:43.726 [ZeusMonitor] Monitor started.
2022-12-09 00:18:43.726 [ZeusMonitor] Running indefinitely. 2022-12-09 00:18:43.726 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:18:43.726 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e2+gpu0.power.log
2022-12-08 19:18:44,461 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 19:18:44,461 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 19:18:52,768 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 19:19:27,331 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 19:19:29,055 [ZeusDataLoader(train)] train epoch 2 done: time=45.60 energy=6542.10
2022-12-08 19:19:29,058 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.2713
Training Epoch: 1 [2048/50176]	Loss: 4.2001
Training Epoch: 1 [3072/50176]	Loss: 4.2276
Training Epoch: 1 [4096/50176]	Loss: 4.1783
Training Epoch: 1 [5120/50176]	Loss: 4.1608
Training Epoch: 1 [6144/50176]	Loss: 4.1851
Training Epoch: 1 [7168/50176]	Loss: 4.1073
Training Epoch: 1 [8192/50176]	Loss: 4.0511
Training Epoch: 1 [9216/50176]	Loss: 4.1664
Training Epoch: 1 [10240/50176]	Loss: 4.1460
Training Epoch: 1 [11264/50176]	Loss: 4.1481
Training Epoch: 1 [12288/50176]	Loss: 4.0986
Training Epoch: 1 [13312/50176]	Loss: 4.0740
Training Epoch: 1 [14336/50176]	Loss: 4.1698
Training Epoch: 1 [15360/50176]	Loss: 4.0875
Training Epoch: 1 [16384/50176]	Loss: 4.1266
Training Epoch: 1 [17408/50176]	Loss: 4.0926
Training Epoch: 1 [18432/50176]	Loss: 4.0615
Training Epoch: 1 [19456/50176]	Loss: 4.1176
Training Epoch: 1 [20480/50176]	Loss: 4.0824
Training Epoch: 1 [21504/50176]	Loss: 4.0688
Training Epoch: 1 [22528/50176]	Loss: 4.0022
Training Epoch: 1 [23552/50176]	Loss: 3.9794
Training Epoch: 1 [24576/50176]	Loss: 3.9766
Training Epoch: 1 [25600/50176]	Loss: 3.9750
Training Epoch: 1 [26624/50176]	Loss: 3.9808
Training Epoch: 1 [27648/50176]	Loss: 3.9914
Training Epoch: 1 [28672/50176]	Loss: 3.9123
Training Epoch: 1 [29696/50176]	Loss: 4.0058
Training Epoch: 1 [30720/50176]	Loss: 3.9169
Training Epoch: 1 [31744/50176]	Loss: 3.9548
Training Epoch: 1 [32768/50176]	Loss: 3.9120
Training Epoch: 1 [33792/50176]	Loss: 3.9707
Training Epoch: 1 [34816/50176]	Loss: 3.9942
Training Epoch: 1 [35840/50176]	Loss: 3.9467
Training Epoch: 1 [36864/50176]	Loss: 3.8896
Training Epoch: 1 [37888/50176]	Loss: 3.8987
Training Epoch: 1 [38912/50176]	Loss: 3.8989
Training Epoch: 1 [39936/50176]	Loss: 3.9353
Training Epoch: 1 [40960/50176]	Loss: 3.9560
Training Epoch: 1 [41984/50176]	Loss: 3.8848
Training Epoch: 1 [43008/50176]	Loss: 3.8627
Training Epoch: 1 [44032/50176]	Loss: 3.8496
Training Epoch: 1 [45056/50176]	Loss: 3.8682
Training Epoch: 1 [46080/50176]	Loss: 3.8289
Training Epoch: 1 [47104/50176]	Loss: 3.8791
Training Epoch: 1 [48128/50176]	Loss: 3.8419
Training Epoch: 1 [49152/50176]	Loss: 3.8624
Training Epoch: 1 [50176/50176]	Loss: 3.8177
2022-12-09 00:19:32.923 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:19:32,947 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.88 energy=507.68
2022-12-08 19:19:32,948 [ZeusDataLoader(train)] Up to epoch 2: time=98.61, energy=14347.85, cost=15802.69
2022-12-08 19:19:32,949 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0039, Accuracy: 0.0797
2022-12-08 19:19:33,204 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-09 00:19:33.219 [ZeusMonitor] Monitor started.
2022-12-09 00:19:33.219 [ZeusMonitor] Running indefinitely. 2022-12-09 00:19:33.219 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:19:33.219 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e3+gpu0.power.log
2022-12-08 19:19:33,958 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 19:19:33,958 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 19:19:43,340 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 19:20:22,587 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 19:20:24,535 [ZeusDataLoader(train)] train epoch 3 done: time=51.58 energy=6244.47
2022-12-08 19:20:24,538 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.7327
Training Epoch: 2 [2048/50176]	Loss: 3.7978
Training Epoch: 2 [3072/50176]	Loss: 3.7394
Training Epoch: 2 [4096/50176]	Loss: 3.7455
Training Epoch: 2 [5120/50176]	Loss: 3.7110
Training Epoch: 2 [6144/50176]	Loss: 3.6953
Training Epoch: 2 [7168/50176]	Loss: 3.7664
Training Epoch: 2 [8192/50176]	Loss: 3.7858
Training Epoch: 2 [9216/50176]	Loss: 3.7165
Training Epoch: 2 [10240/50176]	Loss: 3.6502
Training Epoch: 2 [11264/50176]	Loss: 3.6346
Training Epoch: 2 [12288/50176]	Loss: 3.6615
Training Epoch: 2 [13312/50176]	Loss: 3.6589
Training Epoch: 2 [14336/50176]	Loss: 3.7024
Training Epoch: 2 [15360/50176]	Loss: 3.6854
Training Epoch: 2 [16384/50176]	Loss: 3.7439
Training Epoch: 2 [17408/50176]	Loss: 3.7030
Training Epoch: 2 [18432/50176]	Loss: 3.6764
Training Epoch: 2 [19456/50176]	Loss: 3.6569
Training Epoch: 2 [20480/50176]	Loss: 3.6672
Training Epoch: 2 [21504/50176]	Loss: 3.7313
Training Epoch: 2 [22528/50176]	Loss: 3.6744
Training Epoch: 2 [23552/50176]	Loss: 3.6488
Training Epoch: 2 [24576/50176]	Loss: 3.7177
Training Epoch: 2 [25600/50176]	Loss: 3.6788
Training Epoch: 2 [26624/50176]	Loss: 3.6838
Training Epoch: 2 [27648/50176]	Loss: 3.6732
Training Epoch: 2 [28672/50176]	Loss: 3.6847
Training Epoch: 2 [29696/50176]	Loss: 3.6129
Training Epoch: 2 [30720/50176]	Loss: 3.5770
Training Epoch: 2 [31744/50176]	Loss: 3.5998
Training Epoch: 2 [32768/50176]	Loss: 3.6105
Training Epoch: 2 [33792/50176]	Loss: 3.6438
Training Epoch: 2 [34816/50176]	Loss: 3.6080
Training Epoch: 2 [35840/50176]	Loss: 3.5667
Training Epoch: 2 [36864/50176]	Loss: 3.5105
Training Epoch: 2 [37888/50176]	Loss: 3.6783
Training Epoch: 2 [38912/50176]	Loss: 3.5433
Training Epoch: 2 [39936/50176]	Loss: 3.5013
Training Epoch: 2 [40960/50176]	Loss: 3.5406
Training Epoch: 2 [41984/50176]	Loss: 3.5193
Training Epoch: 2 [43008/50176]	Loss: 3.5139
Training Epoch: 2 [44032/50176]	Loss: 3.4604
Training Epoch: 2 [45056/50176]	Loss: 3.5480
Training Epoch: 2 [46080/50176]	Loss: 3.5485
Training Epoch: 2 [47104/50176]	Loss: 3.5408
Training Epoch: 2 [48128/50176]	Loss: 3.5100
Training Epoch: 2 [49152/50176]	Loss: 3.5403
Training Epoch: 2 [50176/50176]	Loss: 3.4851
2022-12-09 00:20:28.804 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:20:28,855 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.31 energy=491.27
2022-12-08 19:20:28,855 [ZeusDataLoader(train)] Up to epoch 3: time=154.50, energy=21083.59, cost=24060.63
2022-12-08 19:20:28,857 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0035, Accuracy: 0.1377
2022-12-08 19:20:29,139 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-09 00:20:29.142 [ZeusMonitor] Monitor started.
2022-12-09 00:20:29.142 [ZeusMonitor] Running indefinitely. 2022-12-09 00:20:29.142 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:20:29.142 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e4+gpu0.power.log
2022-12-08 19:20:29,838 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 19:20:29,838 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 19:20:54,937 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 19:22:39,759 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 19:22:39,759 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 19:22:39,759 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 19:22:39,762 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 19:22:41,575 [ZeusDataLoader(train)] train epoch 4 done: time=132.71 energy=13469.73
2022-12-08 19:22:41,579 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.4274
Training Epoch: 3 [2048/50176]	Loss: 3.3893
Training Epoch: 3 [3072/50176]	Loss: 3.4478
Training Epoch: 3 [4096/50176]	Loss: 3.4711
Training Epoch: 3 [5120/50176]	Loss: 3.4466
Training Epoch: 3 [6144/50176]	Loss: 3.4466
Training Epoch: 3 [7168/50176]	Loss: 3.4942
Training Epoch: 3 [8192/50176]	Loss: 3.4313
Training Epoch: 3 [9216/50176]	Loss: 3.4090
Training Epoch: 3 [10240/50176]	Loss: 3.4594
Training Epoch: 3 [11264/50176]	Loss: 3.4181
Training Epoch: 3 [12288/50176]	Loss: 3.4314
Training Epoch: 3 [13312/50176]	Loss: 3.4454
Training Epoch: 3 [14336/50176]	Loss: 3.3709
Training Epoch: 3 [15360/50176]	Loss: 3.3497
Training Epoch: 3 [16384/50176]	Loss: 3.4061
Training Epoch: 3 [17408/50176]	Loss: 3.3369
Training Epoch: 3 [18432/50176]	Loss: 3.4168
Training Epoch: 3 [19456/50176]	Loss: 3.3739
Training Epoch: 3 [20480/50176]	Loss: 3.3244
Training Epoch: 3 [21504/50176]	Loss: 3.3525
Training Epoch: 3 [22528/50176]	Loss: 3.3237
Training Epoch: 3 [23552/50176]	Loss: 3.3409
Training Epoch: 3 [24576/50176]	Loss: 3.3365
Training Epoch: 3 [25600/50176]	Loss: 3.2392
Training Epoch: 3 [26624/50176]	Loss: 3.3802
Training Epoch: 3 [27648/50176]	Loss: 3.3555
Training Epoch: 3 [28672/50176]	Loss: 3.2884
Training Epoch: 3 [29696/50176]	Loss: 3.2836
Training Epoch: 3 [30720/50176]	Loss: 3.3370
Training Epoch: 3 [31744/50176]	Loss: 3.3124
Training Epoch: 3 [32768/50176]	Loss: 3.2992
Training Epoch: 3 [33792/50176]	Loss: 3.1632
Training Epoch: 3 [34816/50176]	Loss: 3.2518
Training Epoch: 3 [35840/50176]	Loss: 3.2199
Training Epoch: 3 [36864/50176]	Loss: 3.2702
Training Epoch: 3 [37888/50176]	Loss: 3.2700
Training Epoch: 3 [38912/50176]	Loss: 3.2744
Training Epoch: 3 [39936/50176]	Loss: 3.2892
Training Epoch: 3 [40960/50176]	Loss: 3.1828
Training Epoch: 3 [41984/50176]	Loss: 3.1979
Training Epoch: 3 [43008/50176]	Loss: 3.1542
Training Epoch: 3 [44032/50176]	Loss: 3.1586
Training Epoch: 3 [45056/50176]	Loss: 3.1709
Training Epoch: 3 [46080/50176]	Loss: 3.2192
Training Epoch: 3 [47104/50176]	Loss: 3.1231
Training Epoch: 3 [48128/50176]	Loss: 3.2936
Training Epoch: 3 [49152/50176]	Loss: 3.1757
Training Epoch: 3 [50176/50176]	Loss: 3.1586
2022-12-09 00:22:45.303 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:22:45,321 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 19:22:45,321 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+lr0.0090000.power.json: {"job_id": "rec03+try01", "train_power": {"175000": 154.6792462130222, "150000": 146.55796781873008, "125000": 122.92324634463641, "100000": 101.76930623787774}, "train_throughput": {"175000": 1.1273475383617806, "150000": 1.0998245343207829, "125000": 0.9685367142449868, "100000": 0.3625758461971825}, "eval_power": {"175000": 137.33036751551163, "150000": 130.83428207217395, "125000": 114.04092551113034}, "eval_throughput": {"175000": 2.6801964520231563, "150000": 2.577116501549166, "125000": 2.3213637893790264}, "optimal_pl": 175000}
2022-12-08 19:22:45,321 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.73 energy=512.39
2022-12-08 19:22:45,322 [ZeusDataLoader(train)] Up to epoch 4: time=290.94, energy=35065.70, cost=42990.01
2022-12-08 19:22:45,322 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:22:45,322 [ZeusDataLoader(train)] Expected next epoch: time=338.13, energy=42301.21, cost=50737.40
2022-12-08 19:22:45,323 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0034, Accuracy: 0.1767
2022-12-08 19:22:45,544 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:22:45,545 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:22:45.549 [ZeusMonitor] Monitor started.
2022-12-09 00:22:45.549 [ZeusMonitor] Running indefinitely. 2022-12-09 00:22:45.549 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:22:45.549 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e5+gpu0.power.log
2022-12-08 19:23:29,330 [ZeusDataLoader(train)] train epoch 5 done: time=44.00 energy=6691.86
2022-12-08 19:23:29,333 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.1364
Training Epoch: 4 [2048/50176]	Loss: 3.1374
Training Epoch: 4 [3072/50176]	Loss: 3.0689
Training Epoch: 4 [4096/50176]	Loss: 3.0671
Training Epoch: 4 [5120/50176]	Loss: 3.0861
Training Epoch: 4 [6144/50176]	Loss: 3.1412
Training Epoch: 4 [7168/50176]	Loss: 3.0999
Training Epoch: 4 [8192/50176]	Loss: 3.1643
Training Epoch: 4 [9216/50176]	Loss: 3.1014
Training Epoch: 4 [10240/50176]	Loss: 3.0565
Training Epoch: 4 [11264/50176]	Loss: 3.0556
Training Epoch: 4 [12288/50176]	Loss: 3.0350
Training Epoch: 4 [13312/50176]	Loss: 3.0157
Training Epoch: 4 [14336/50176]	Loss: 3.1074
Training Epoch: 4 [15360/50176]	Loss: 3.0726
Training Epoch: 4 [16384/50176]	Loss: 2.9791
Training Epoch: 4 [17408/50176]	Loss: 3.0450
Training Epoch: 4 [18432/50176]	Loss: 3.0718
Training Epoch: 4 [19456/50176]	Loss: 3.0544
Training Epoch: 4 [20480/50176]	Loss: 3.0449
Training Epoch: 4 [21504/50176]	Loss: 3.0264
Training Epoch: 4 [22528/50176]	Loss: 2.9883
Training Epoch: 4 [23552/50176]	Loss: 3.0147
Training Epoch: 4 [24576/50176]	Loss: 2.9730
Training Epoch: 4 [25600/50176]	Loss: 2.9478
Training Epoch: 4 [26624/50176]	Loss: 2.9579
Training Epoch: 4 [27648/50176]	Loss: 3.0672
Training Epoch: 4 [28672/50176]	Loss: 2.9170
Training Epoch: 4 [29696/50176]	Loss: 3.0007
Training Epoch: 4 [30720/50176]	Loss: 2.9801
Training Epoch: 4 [31744/50176]	Loss: 2.9879
Training Epoch: 4 [32768/50176]	Loss: 3.0101
Training Epoch: 4 [33792/50176]	Loss: 2.9718
Training Epoch: 4 [34816/50176]	Loss: 2.8720
Training Epoch: 4 [35840/50176]	Loss: 3.0142
Training Epoch: 4 [36864/50176]	Loss: 2.9573
Training Epoch: 4 [37888/50176]	Loss: 3.1167
Training Epoch: 4 [38912/50176]	Loss: 2.9601
Training Epoch: 4 [39936/50176]	Loss: 2.9341
Training Epoch: 4 [40960/50176]	Loss: 2.9399
Training Epoch: 4 [41984/50176]	Loss: 2.8528
Training Epoch: 4 [43008/50176]	Loss: 2.9014
Training Epoch: 4 [44032/50176]	Loss: 2.8644
Training Epoch: 4 [45056/50176]	Loss: 2.9145
Training Epoch: 4 [46080/50176]	Loss: 2.9451
Training Epoch: 4 [47104/50176]	Loss: 2.9696
Training Epoch: 4 [48128/50176]	Loss: 2.9568
Training Epoch: 4 [49152/50176]	Loss: 2.9000
Training Epoch: 4 [50176/50176]	Loss: 2.9586
2022-12-09 00:23:33.068 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:23:33,078 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.74 energy=520.97
2022-12-08 19:23:33,079 [ZeusDataLoader(train)] Up to epoch 5: time=338.67, energy=42278.54, cost=50773.24
2022-12-08 19:23:33,079 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:23:33,079 [ZeusDataLoader(train)] Expected next epoch: time=385.87, energy=49514.04, cost=58520.63
2022-12-08 19:23:33,080 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0029, Accuracy: 0.2577
2022-12-08 19:23:33,340 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:23:33,341 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:23:33.355 [ZeusMonitor] Monitor started.
2022-12-09 00:23:33.355 [ZeusMonitor] Running indefinitely. 2022-12-09 00:23:33.355 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:23:33.355 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e6+gpu0.power.log
2022-12-08 19:24:17,222 [ZeusDataLoader(train)] train epoch 6 done: time=44.13 energy=6702.55
2022-12-08 19:24:17,226 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.7854
Training Epoch: 5 [2048/50176]	Loss: 2.7960
Training Epoch: 5 [3072/50176]	Loss: 2.9378
Training Epoch: 5 [4096/50176]	Loss: 2.8021
Training Epoch: 5 [5120/50176]	Loss: 2.7901
Training Epoch: 5 [6144/50176]	Loss: 2.8569
Training Epoch: 5 [7168/50176]	Loss: 2.7332
Training Epoch: 5 [8192/50176]	Loss: 2.7861
Training Epoch: 5 [9216/50176]	Loss: 2.7385
Training Epoch: 5 [10240/50176]	Loss: 2.8358
Training Epoch: 5 [11264/50176]	Loss: 2.8938
Training Epoch: 5 [12288/50176]	Loss: 2.7174
Training Epoch: 5 [13312/50176]	Loss: 2.7686
Training Epoch: 5 [14336/50176]	Loss: 2.7251
Training Epoch: 5 [15360/50176]	Loss: 2.8359
Training Epoch: 5 [16384/50176]	Loss: 2.7767
Training Epoch: 5 [17408/50176]	Loss: 2.7902
Training Epoch: 5 [18432/50176]	Loss: 2.7363
Training Epoch: 5 [19456/50176]	Loss: 2.7955
Training Epoch: 5 [20480/50176]	Loss: 2.7672
Training Epoch: 5 [21504/50176]	Loss: 2.7362
Training Epoch: 5 [22528/50176]	Loss: 2.8094
Training Epoch: 5 [23552/50176]	Loss: 2.7677
Training Epoch: 5 [24576/50176]	Loss: 2.7815
Training Epoch: 5 [25600/50176]	Loss: 2.7398
Training Epoch: 5 [26624/50176]	Loss: 2.7144
Training Epoch: 5 [27648/50176]	Loss: 2.7363
Training Epoch: 5 [28672/50176]	Loss: 2.7481
Training Epoch: 5 [29696/50176]	Loss: 2.6854
Training Epoch: 5 [30720/50176]	Loss: 2.6860
Training Epoch: 5 [31744/50176]	Loss: 2.6896
Training Epoch: 5 [32768/50176]	Loss: 2.7565
Training Epoch: 5 [33792/50176]	Loss: 2.6536
Training Epoch: 5 [34816/50176]	Loss: 2.6334
Training Epoch: 5 [35840/50176]	Loss: 2.7547
Training Epoch: 5 [36864/50176]	Loss: 2.6360
Training Epoch: 5 [37888/50176]	Loss: 2.5973
Training Epoch: 5 [38912/50176]	Loss: 2.6700
Training Epoch: 5 [39936/50176]	Loss: 2.7156
Training Epoch: 5 [40960/50176]	Loss: 2.6257
Training Epoch: 5 [41984/50176]	Loss: 2.7351
Training Epoch: 5 [43008/50176]	Loss: 2.6603
Training Epoch: 5 [44032/50176]	Loss: 2.7150
Training Epoch: 5 [45056/50176]	Loss: 2.7591
Training Epoch: 5 [46080/50176]	Loss: 2.6242
Training Epoch: 5 [47104/50176]	Loss: 2.6786
Training Epoch: 5 [48128/50176]	Loss: 2.7065
Training Epoch: 5 [49152/50176]	Loss: 2.7162
Training Epoch: 5 [50176/50176]	Loss: 2.6821
2022-12-09 00:24:21.010 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:24:21,056 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.82 energy=527.57
2022-12-08 19:24:21,057 [ZeusDataLoader(train)] Up to epoch 6: time=386.63, energy=49508.66, cost=58584.40
2022-12-08 19:24:21,057 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:24:21,057 [ZeusDataLoader(train)] Expected next epoch: time=433.83, energy=56744.16, cost=66331.79
2022-12-08 19:24:21,058 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0030, Accuracy: 0.2491
2022-12-08 19:24:21,270 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:24:21,271 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:24:21.273 [ZeusMonitor] Monitor started.
2022-12-09 00:24:21.273 [ZeusMonitor] Running indefinitely. 2022-12-09 00:24:21.273 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:24:21.273 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e7+gpu0.power.log
2022-12-08 19:25:05,195 [ZeusDataLoader(train)] train epoch 7 done: time=44.13 energy=6710.91
2022-12-08 19:25:05,198 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.5615
Training Epoch: 6 [2048/50176]	Loss: 2.5872
Training Epoch: 6 [3072/50176]	Loss: 2.6682
Training Epoch: 6 [4096/50176]	Loss: 2.6462
Training Epoch: 6 [5120/50176]	Loss: 2.4863
Training Epoch: 6 [6144/50176]	Loss: 2.5812
Training Epoch: 6 [7168/50176]	Loss: 2.5601
Training Epoch: 6 [8192/50176]	Loss: 2.5207
Training Epoch: 6 [9216/50176]	Loss: 2.6806
Training Epoch: 6 [10240/50176]	Loss: 2.6518
Training Epoch: 6 [11264/50176]	Loss: 2.5027
Training Epoch: 6 [12288/50176]	Loss: 2.6260
Training Epoch: 6 [13312/50176]	Loss: 2.5533
Training Epoch: 6 [14336/50176]	Loss: 2.5399
Training Epoch: 6 [15360/50176]	Loss: 2.4622
Training Epoch: 6 [16384/50176]	Loss: 2.5436
Training Epoch: 6 [17408/50176]	Loss: 2.4786
Training Epoch: 6 [18432/50176]	Loss: 2.5508
Training Epoch: 6 [19456/50176]	Loss: 2.4844
Training Epoch: 6 [20480/50176]	Loss: 2.6101
Training Epoch: 6 [21504/50176]	Loss: 2.6343
Training Epoch: 6 [22528/50176]	Loss: 2.5458
Training Epoch: 6 [23552/50176]	Loss: 2.5259
Training Epoch: 6 [24576/50176]	Loss: 2.5613
Training Epoch: 6 [25600/50176]	Loss: 2.4690
Training Epoch: 6 [26624/50176]	Loss: 2.5906
Training Epoch: 6 [27648/50176]	Loss: 2.5215
Training Epoch: 6 [28672/50176]	Loss: 2.4042
Training Epoch: 6 [29696/50176]	Loss: 2.5224
Training Epoch: 6 [30720/50176]	Loss: 2.4798
Training Epoch: 6 [31744/50176]	Loss: 2.4799
Training Epoch: 6 [32768/50176]	Loss: 2.4534
Training Epoch: 6 [33792/50176]	Loss: 2.5094
Training Epoch: 6 [34816/50176]	Loss: 2.5556
Training Epoch: 6 [35840/50176]	Loss: 2.4710
Training Epoch: 6 [36864/50176]	Loss: 2.5686
Training Epoch: 6 [37888/50176]	Loss: 2.5806
Training Epoch: 6 [38912/50176]	Loss: 2.5100
Training Epoch: 6 [39936/50176]	Loss: 2.5016
Training Epoch: 6 [40960/50176]	Loss: 2.4901
Training Epoch: 6 [41984/50176]	Loss: 2.4839
Training Epoch: 6 [43008/50176]	Loss: 2.5166
Training Epoch: 6 [44032/50176]	Loss: 2.4748
Training Epoch: 6 [45056/50176]	Loss: 2.4823
Training Epoch: 6 [46080/50176]	Loss: 2.5880
Training Epoch: 6 [47104/50176]	Loss: 2.4405
Training Epoch: 6 [48128/50176]	Loss: 2.4763
Training Epoch: 6 [49152/50176]	Loss: 2.4369
Training Epoch: 6 [50176/50176]	Loss: 2.4649
2022-12-09 00:25:08.954 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:25:08,976 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.77 energy=517.25
2022-12-08 19:25:08,976 [ZeusDataLoader(train)] Up to epoch 7: time=434.53, energy=56736.82, cost=66389.52
2022-12-08 19:25:08,976 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:25:08,976 [ZeusDataLoader(train)] Expected next epoch: time=481.72, energy=63972.32, cost=74136.91
2022-12-08 19:25:08,977 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0025, Accuracy: 0.3423
2022-12-08 19:25:09,193 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:25:09,194 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:25:09.198 [ZeusMonitor] Monitor started.
2022-12-09 00:25:09.198 [ZeusMonitor] Running indefinitely. 2022-12-09 00:25:09.198 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:25:09.198 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e8+gpu0.power.log
2022-12-08 19:25:53,181 [ZeusDataLoader(train)] train epoch 8 done: time=44.19 energy=6707.16
2022-12-08 19:25:53,184 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.3977
Training Epoch: 7 [2048/50176]	Loss: 2.3358
Training Epoch: 7 [3072/50176]	Loss: 2.3024
Training Epoch: 7 [4096/50176]	Loss: 2.3428
Training Epoch: 7 [5120/50176]	Loss: 2.3704
Training Epoch: 7 [6144/50176]	Loss: 2.3135
Training Epoch: 7 [7168/50176]	Loss: 2.3801
Training Epoch: 7 [8192/50176]	Loss: 2.3082
Training Epoch: 7 [9216/50176]	Loss: 2.2234
Training Epoch: 7 [10240/50176]	Loss: 2.3021
Training Epoch: 7 [11264/50176]	Loss: 2.2842
Training Epoch: 7 [12288/50176]	Loss: 2.3744
Training Epoch: 7 [13312/50176]	Loss: 2.2841
Training Epoch: 7 [14336/50176]	Loss: 2.4178
Training Epoch: 7 [15360/50176]	Loss: 2.3719
Training Epoch: 7 [16384/50176]	Loss: 2.3149
Training Epoch: 7 [17408/50176]	Loss: 2.3824
Training Epoch: 7 [18432/50176]	Loss: 2.3108
Training Epoch: 7 [19456/50176]	Loss: 2.3256
Training Epoch: 7 [20480/50176]	Loss: 2.3782
Training Epoch: 7 [21504/50176]	Loss: 2.3304
Training Epoch: 7 [22528/50176]	Loss: 2.3097
Training Epoch: 7 [23552/50176]	Loss: 2.3352
Training Epoch: 7 [24576/50176]	Loss: 2.3064
Training Epoch: 7 [25600/50176]	Loss: 2.3255
Training Epoch: 7 [26624/50176]	Loss: 2.3486
Training Epoch: 7 [27648/50176]	Loss: 2.3615
Training Epoch: 7 [28672/50176]	Loss: 2.2832
Training Epoch: 7 [29696/50176]	Loss: 2.3034
Training Epoch: 7 [30720/50176]	Loss: 2.2808
Training Epoch: 7 [31744/50176]	Loss: 2.3864
Training Epoch: 7 [32768/50176]	Loss: 2.2356
Training Epoch: 7 [33792/50176]	Loss: 2.3794
Training Epoch: 7 [34816/50176]	Loss: 2.3498
Training Epoch: 7 [35840/50176]	Loss: 2.2371
Training Epoch: 7 [36864/50176]	Loss: 2.2083
Training Epoch: 7 [37888/50176]	Loss: 2.2439
Training Epoch: 7 [38912/50176]	Loss: 2.3093
Training Epoch: 7 [39936/50176]	Loss: 2.3831
Training Epoch: 7 [40960/50176]	Loss: 2.3295
Training Epoch: 7 [41984/50176]	Loss: 2.2417
Training Epoch: 7 [43008/50176]	Loss: 2.2147
Training Epoch: 7 [44032/50176]	Loss: 2.2060
Training Epoch: 7 [45056/50176]	Loss: 2.3195
Training Epoch: 7 [46080/50176]	Loss: 2.3022
Training Epoch: 7 [47104/50176]	Loss: 2.1977
Training Epoch: 7 [48128/50176]	Loss: 2.2186
Training Epoch: 7 [49152/50176]	Loss: 2.3261
Training Epoch: 7 [50176/50176]	Loss: 2.2429
2022-12-09 00:25:56.991 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:25:57,035 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.84 energy=526.60
2022-12-08 19:25:57,035 [ZeusDataLoader(train)] Up to epoch 8: time=482.56, energy=63970.58, cost=74209.55
2022-12-08 19:25:57,036 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:25:57,036 [ZeusDataLoader(train)] Expected next epoch: time=529.76, energy=71206.08, cost=81956.95
2022-12-08 19:25:57,037 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0023, Accuracy: 0.3785
2022-12-08 19:25:57,308 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:25:57,309 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:25:57.310 [ZeusMonitor] Monitor started.
2022-12-09 00:25:57.310 [ZeusMonitor] Running indefinitely. 2022-12-09 00:25:57.311 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:25:57.311 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e9+gpu0.power.log
2022-12-08 19:26:41,293 [ZeusDataLoader(train)] train epoch 9 done: time=44.25 energy=6710.98
2022-12-08 19:26:41,296 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.2491
Training Epoch: 8 [2048/50176]	Loss: 2.2092
Training Epoch: 8 [3072/50176]	Loss: 2.2156
Training Epoch: 8 [4096/50176]	Loss: 2.1396
Training Epoch: 8 [5120/50176]	Loss: 2.1028
Training Epoch: 8 [6144/50176]	Loss: 2.1414
Training Epoch: 8 [7168/50176]	Loss: 2.2045
Training Epoch: 8 [8192/50176]	Loss: 2.2169
Training Epoch: 8 [9216/50176]	Loss: 2.1272
Training Epoch: 8 [10240/50176]	Loss: 2.1431
Training Epoch: 8 [11264/50176]	Loss: 2.1456
Training Epoch: 8 [12288/50176]	Loss: 2.1233
Training Epoch: 8 [13312/50176]	Loss: 2.1803
Training Epoch: 8 [14336/50176]	Loss: 2.1736
Training Epoch: 8 [15360/50176]	Loss: 2.2033
Training Epoch: 8 [16384/50176]	Loss: 2.1758
Training Epoch: 8 [17408/50176]	Loss: 2.2407
Training Epoch: 8 [18432/50176]	Loss: 2.1922
Training Epoch: 8 [19456/50176]	Loss: 2.1056
Training Epoch: 8 [20480/50176]	Loss: 2.1012
Training Epoch: 8 [21504/50176]	Loss: 2.1027
Training Epoch: 8 [22528/50176]	Loss: 2.1374
Training Epoch: 8 [23552/50176]	Loss: 2.1361
Training Epoch: 8 [24576/50176]	Loss: 2.1551
Training Epoch: 8 [25600/50176]	Loss: 2.1681
Training Epoch: 8 [26624/50176]	Loss: 2.1325
Training Epoch: 8 [27648/50176]	Loss: 2.0510
Training Epoch: 8 [28672/50176]	Loss: 2.1442
Training Epoch: 8 [29696/50176]	Loss: 2.1466
Training Epoch: 8 [30720/50176]	Loss: 2.1059
Training Epoch: 8 [31744/50176]	Loss: 2.0902
Training Epoch: 8 [32768/50176]	Loss: 2.0974
Training Epoch: 8 [33792/50176]	Loss: 2.2076
Training Epoch: 8 [34816/50176]	Loss: 2.1473
Training Epoch: 8 [35840/50176]	Loss: 2.1427
Training Epoch: 8 [36864/50176]	Loss: 2.1217
Training Epoch: 8 [37888/50176]	Loss: 2.1566
Training Epoch: 8 [38912/50176]	Loss: 2.1337
Training Epoch: 8 [39936/50176]	Loss: 2.1618
Training Epoch: 8 [40960/50176]	Loss: 2.0946
Training Epoch: 8 [41984/50176]	Loss: 2.1793
Training Epoch: 8 [43008/50176]	Loss: 2.1289
Training Epoch: 8 [44032/50176]	Loss: 2.1854
Training Epoch: 8 [45056/50176]	Loss: 2.1879
Training Epoch: 8 [46080/50176]	Loss: 2.1332
Training Epoch: 8 [47104/50176]	Loss: 2.1839
Training Epoch: 8 [48128/50176]	Loss: 2.1029
Training Epoch: 8 [49152/50176]	Loss: 2.1747
Training Epoch: 8 [50176/50176]	Loss: 2.1702
2022-12-09 00:26:45.048 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:26:45,059 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.75 energy=516.66
2022-12-08 19:26:45,059 [ZeusDataLoader(train)] Up to epoch 9: time=530.56, energy=71198.23, cost=82023.54
2022-12-08 19:26:45,060 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:26:45,060 [ZeusDataLoader(train)] Expected next epoch: time=577.76, energy=78433.73, cost=89770.94
2022-12-08 19:26:45,061 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0023, Accuracy: 0.3862
2022-12-08 19:26:45,332 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:26:45,333 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:26:45.335 [ZeusMonitor] Monitor started.
2022-12-09 00:26:45.335 [ZeusMonitor] Running indefinitely. 2022-12-09 00:26:45.335 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:26:45.335 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e10+gpu0.power.log
2022-12-08 19:27:29,257 [ZeusDataLoader(train)] train epoch 10 done: time=44.19 energy=6711.13
2022-12-08 19:27:29,261 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.0017
Training Epoch: 9 [2048/50176]	Loss: 2.0830
Training Epoch: 9 [3072/50176]	Loss: 2.1015
Training Epoch: 9 [4096/50176]	Loss: 1.9886
Training Epoch: 9 [5120/50176]	Loss: 2.1149
Training Epoch: 9 [6144/50176]	Loss: 1.9618
Training Epoch: 9 [7168/50176]	Loss: 2.0434
Training Epoch: 9 [8192/50176]	Loss: 2.0428
Training Epoch: 9 [9216/50176]	Loss: 2.0251
Training Epoch: 9 [10240/50176]	Loss: 2.0233
Training Epoch: 9 [11264/50176]	Loss: 2.1226
Training Epoch: 9 [12288/50176]	Loss: 2.1124
Training Epoch: 9 [13312/50176]	Loss: 1.9775
Training Epoch: 9 [14336/50176]	Loss: 2.0183
Training Epoch: 9 [15360/50176]	Loss: 2.0611
Training Epoch: 9 [16384/50176]	Loss: 2.1126
Training Epoch: 9 [17408/50176]	Loss: 1.9753
Training Epoch: 9 [18432/50176]	Loss: 2.0152
Training Epoch: 9 [19456/50176]	Loss: 1.9807
Training Epoch: 9 [20480/50176]	Loss: 2.0094
Training Epoch: 9 [21504/50176]	Loss: 2.0465
Training Epoch: 9 [22528/50176]	Loss: 1.9540
Training Epoch: 9 [23552/50176]	Loss: 1.9556
Training Epoch: 9 [24576/50176]	Loss: 1.9909
Training Epoch: 9 [25600/50176]	Loss: 1.9593
Training Epoch: 9 [26624/50176]	Loss: 1.9997
Training Epoch: 9 [27648/50176]	Loss: 2.0894
Training Epoch: 9 [28672/50176]	Loss: 2.0758
Training Epoch: 9 [29696/50176]	Loss: 2.0194
Training Epoch: 9 [30720/50176]	Loss: 1.9533
Training Epoch: 9 [31744/50176]	Loss: 2.0705
Training Epoch: 9 [32768/50176]	Loss: 1.9780
Training Epoch: 9 [33792/50176]	Loss: 1.9784
Training Epoch: 9 [34816/50176]	Loss: 2.0197
Training Epoch: 9 [35840/50176]	Loss: 1.9563
Training Epoch: 9 [36864/50176]	Loss: 2.0269
Training Epoch: 9 [37888/50176]	Loss: 2.0266
Training Epoch: 9 [38912/50176]	Loss: 1.9950
Training Epoch: 9 [39936/50176]	Loss: 2.0038
Training Epoch: 9 [40960/50176]	Loss: 2.0335
Training Epoch: 9 [41984/50176]	Loss: 1.9579
Training Epoch: 9 [43008/50176]	Loss: 1.9834
Training Epoch: 9 [44032/50176]	Loss: 1.9857
Training Epoch: 9 [45056/50176]	Loss: 1.9467
Training Epoch: 9 [46080/50176]	Loss: 1.9295
Training Epoch: 9 [47104/50176]	Loss: 1.9714
Training Epoch: 9 [48128/50176]	Loss: 1.9373
Training Epoch: 9 [49152/50176]	Loss: 1.8852
Training Epoch: 9 [50176/50176]	Loss: 1.8788
2022-12-09 00:27:33.061 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:27:33,101 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.83 energy=539.99
2022-12-08 19:27:33,101 [ZeusDataLoader(train)] Up to epoch 10: time=578.58, energy=78449.34, cost=89850.83
2022-12-08 19:27:33,101 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:27:33,102 [ZeusDataLoader(train)] Expected next epoch: time=625.78, energy=85684.84, cost=97598.22
2022-12-08 19:27:33,103 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0022, Accuracy: 0.4080
2022-12-08 19:27:33,364 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:27:33,365 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:27:33.383 [ZeusMonitor] Monitor started.
2022-12-09 00:27:33.383 [ZeusMonitor] Running indefinitely. 2022-12-09 00:27:33.383 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:27:33.383 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e11+gpu0.power.log
2022-12-08 19:28:17,275 [ZeusDataLoader(train)] train epoch 11 done: time=44.16 energy=6718.10
2022-12-08 19:28:17,279 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.9229
Training Epoch: 10 [2048/50176]	Loss: 1.8727
Training Epoch: 10 [3072/50176]	Loss: 1.8869
Training Epoch: 10 [4096/50176]	Loss: 1.9887
Training Epoch: 10 [5120/50176]	Loss: 1.8616
Training Epoch: 10 [6144/50176]	Loss: 1.9046
Training Epoch: 10 [7168/50176]	Loss: 1.8197
Training Epoch: 10 [8192/50176]	Loss: 1.7936
Training Epoch: 10 [9216/50176]	Loss: 1.9045
Training Epoch: 10 [10240/50176]	Loss: 1.8106
Training Epoch: 10 [11264/50176]	Loss: 1.9918
Training Epoch: 10 [12288/50176]	Loss: 1.8495
Training Epoch: 10 [13312/50176]	Loss: 2.0588
Training Epoch: 10 [14336/50176]	Loss: 1.9699
Training Epoch: 10 [15360/50176]	Loss: 1.9607
Training Epoch: 10 [16384/50176]	Loss: 1.9419
Training Epoch: 10 [17408/50176]	Loss: 1.9412
Training Epoch: 10 [18432/50176]	Loss: 1.8784
Training Epoch: 10 [19456/50176]	Loss: 1.8702
Training Epoch: 10 [20480/50176]	Loss: 1.8768
Training Epoch: 10 [21504/50176]	Loss: 1.9552
Training Epoch: 10 [22528/50176]	Loss: 1.8815
Training Epoch: 10 [23552/50176]	Loss: 1.8151
Training Epoch: 10 [24576/50176]	Loss: 1.8854
Training Epoch: 10 [25600/50176]	Loss: 1.8221
Training Epoch: 10 [26624/50176]	Loss: 1.8219
Training Epoch: 10 [27648/50176]	Loss: 1.8371
Training Epoch: 10 [28672/50176]	Loss: 1.9984
Training Epoch: 10 [29696/50176]	Loss: 2.0453
Training Epoch: 10 [30720/50176]	Loss: 1.8152
Training Epoch: 10 [31744/50176]	Loss: 1.9650
Training Epoch: 10 [32768/50176]	Loss: 1.8311
Training Epoch: 10 [33792/50176]	Loss: 1.8990
Training Epoch: 10 [34816/50176]	Loss: 1.9033
Training Epoch: 10 [35840/50176]	Loss: 2.0167
Training Epoch: 10 [36864/50176]	Loss: 1.9197
Training Epoch: 10 [37888/50176]	Loss: 1.7767
Training Epoch: 10 [38912/50176]	Loss: 1.7883
Training Epoch: 10 [39936/50176]	Loss: 1.9558
Training Epoch: 10 [40960/50176]	Loss: 1.7851
Training Epoch: 10 [41984/50176]	Loss: 1.7641
Training Epoch: 10 [43008/50176]	Loss: 1.9150
Training Epoch: 10 [44032/50176]	Loss: 1.8580
Training Epoch: 10 [45056/50176]	Loss: 1.8257
Training Epoch: 10 [46080/50176]	Loss: 1.7642
Training Epoch: 10 [47104/50176]	Loss: 1.8546
Training Epoch: 10 [48128/50176]	Loss: 1.9185
Training Epoch: 10 [49152/50176]	Loss: 1.9041
Training Epoch: 10 [50176/50176]	Loss: 1.9060
2022-12-09 00:28:21.044 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:28:21,063 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.78 energy=519.80
2022-12-08 19:28:21,064 [ZeusDataLoader(train)] Up to epoch 11: time=626.53, energy=85687.24, cost=97664.61
2022-12-08 19:28:21,064 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:28:21,064 [ZeusDataLoader(train)] Expected next epoch: time=673.72, energy=92922.75, cost=105412.00
2022-12-08 19:28:21,065 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0022, Accuracy: 0.4099
2022-12-08 19:28:21,331 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:28:21,332 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:28:21.334 [ZeusMonitor] Monitor started.
2022-12-09 00:28:21.334 [ZeusMonitor] Running indefinitely. 2022-12-09 00:28:21.334 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:28:21.334 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e12+gpu0.power.log
2022-12-08 19:29:05,279 [ZeusDataLoader(train)] train epoch 12 done: time=44.21 energy=6707.32
2022-12-08 19:29:05,283 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.6714
Training Epoch: 11 [2048/50176]	Loss: 1.7249
Training Epoch: 11 [3072/50176]	Loss: 1.7206
Training Epoch: 11 [4096/50176]	Loss: 1.9044
Training Epoch: 11 [5120/50176]	Loss: 1.8505
Training Epoch: 11 [6144/50176]	Loss: 1.6148
Training Epoch: 11 [7168/50176]	Loss: 1.6873
Training Epoch: 11 [8192/50176]	Loss: 1.7541
Training Epoch: 11 [9216/50176]	Loss: 1.7499
Training Epoch: 11 [10240/50176]	Loss: 1.8368
Training Epoch: 11 [11264/50176]	Loss: 1.7323
Training Epoch: 11 [12288/50176]	Loss: 1.7611
Training Epoch: 11 [13312/50176]	Loss: 1.8040
Training Epoch: 11 [14336/50176]	Loss: 1.7006
Training Epoch: 11 [15360/50176]	Loss: 1.7812
Training Epoch: 11 [16384/50176]	Loss: 1.7956
Training Epoch: 11 [17408/50176]	Loss: 1.7287
Training Epoch: 11 [18432/50176]	Loss: 1.7716
Training Epoch: 11 [19456/50176]	Loss: 1.7231
Training Epoch: 11 [20480/50176]	Loss: 1.8426
Training Epoch: 11 [21504/50176]	Loss: 1.8680
Training Epoch: 11 [22528/50176]	Loss: 1.7879
Training Epoch: 11 [23552/50176]	Loss: 1.8337
Training Epoch: 11 [24576/50176]	Loss: 1.7356
Training Epoch: 11 [25600/50176]	Loss: 1.7752
Training Epoch: 11 [26624/50176]	Loss: 1.7094
Training Epoch: 11 [27648/50176]	Loss: 1.7924
Training Epoch: 11 [28672/50176]	Loss: 1.7855
Training Epoch: 11 [29696/50176]	Loss: 1.8197
Training Epoch: 11 [30720/50176]	Loss: 1.6834
Training Epoch: 11 [31744/50176]	Loss: 1.7678
Training Epoch: 11 [32768/50176]	Loss: 1.7750
Training Epoch: 11 [33792/50176]	Loss: 1.7906
Training Epoch: 11 [34816/50176]	Loss: 1.8361
Training Epoch: 11 [35840/50176]	Loss: 1.7856
Training Epoch: 11 [36864/50176]	Loss: 1.7496
Training Epoch: 11 [37888/50176]	Loss: 1.7573
Training Epoch: 11 [38912/50176]	Loss: 1.7609
Training Epoch: 11 [39936/50176]	Loss: 1.7270
Training Epoch: 11 [40960/50176]	Loss: 1.7286
Training Epoch: 11 [41984/50176]	Loss: 1.8041
Training Epoch: 11 [43008/50176]	Loss: 1.8045
Training Epoch: 11 [44032/50176]	Loss: 1.7790
Training Epoch: 11 [45056/50176]	Loss: 1.8017
Training Epoch: 11 [46080/50176]	Loss: 1.7219
Training Epoch: 11 [47104/50176]	Loss: 1.7948
Training Epoch: 11 [48128/50176]	Loss: 1.7285
Training Epoch: 11 [49152/50176]	Loss: 1.7344
Training Epoch: 11 [50176/50176]	Loss: 1.7906
2022-12-09 00:29:09.105 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:29:09,134 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.84 energy=531.58
2022-12-08 19:29:09,135 [ZeusDataLoader(train)] Up to epoch 12: time=674.57, energy=92926.14, cost=105488.31
2022-12-08 19:29:09,135 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:29:09,135 [ZeusDataLoader(train)] Expected next epoch: time=721.77, energy=100161.64, cost=113235.70
2022-12-08 19:29:09,136 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0023, Accuracy: 0.4171
2022-12-08 19:29:09,391 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:29:09,392 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:29:09.396 [ZeusMonitor] Monitor started.
2022-12-09 00:29:09.396 [ZeusMonitor] Running indefinitely. 2022-12-09 00:29:09.396 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:29:09.396 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e13+gpu0.power.log
2022-12-08 19:29:53,473 [ZeusDataLoader(train)] train epoch 13 done: time=44.33 energy=6722.49
2022-12-08 19:29:53,477 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.7232
Training Epoch: 12 [2048/50176]	Loss: 1.6852
Training Epoch: 12 [3072/50176]	Loss: 1.7158
Training Epoch: 12 [4096/50176]	Loss: 1.6034
Training Epoch: 12 [5120/50176]	Loss: 1.5940
Training Epoch: 12 [6144/50176]	Loss: 1.6741
Training Epoch: 12 [7168/50176]	Loss: 1.7200
Training Epoch: 12 [8192/50176]	Loss: 1.5751
Training Epoch: 12 [9216/50176]	Loss: 1.6848
Training Epoch: 12 [10240/50176]	Loss: 1.6453
Training Epoch: 12 [11264/50176]	Loss: 1.8007
Training Epoch: 12 [12288/50176]	Loss: 1.6963
Training Epoch: 12 [13312/50176]	Loss: 1.6399
Training Epoch: 12 [14336/50176]	Loss: 1.7062
Training Epoch: 12 [15360/50176]	Loss: 1.6311
Training Epoch: 12 [16384/50176]	Loss: 1.6997
Training Epoch: 12 [17408/50176]	Loss: 1.6664
Training Epoch: 12 [18432/50176]	Loss: 1.6865
Training Epoch: 12 [19456/50176]	Loss: 1.6433
Training Epoch: 12 [20480/50176]	Loss: 1.7182
Training Epoch: 12 [21504/50176]	Loss: 1.7517
Training Epoch: 12 [22528/50176]	Loss: 1.6266
Training Epoch: 12 [23552/50176]	Loss: 1.6897
Training Epoch: 12 [24576/50176]	Loss: 1.6359
Training Epoch: 12 [25600/50176]	Loss: 1.7541
Training Epoch: 12 [26624/50176]	Loss: 1.7489
Training Epoch: 12 [27648/50176]	Loss: 1.6700
Training Epoch: 12 [28672/50176]	Loss: 1.6932
Training Epoch: 12 [29696/50176]	Loss: 1.7182
Training Epoch: 12 [30720/50176]	Loss: 1.6437
Training Epoch: 12 [31744/50176]	Loss: 1.6403
Training Epoch: 12 [32768/50176]	Loss: 1.7237
Training Epoch: 12 [33792/50176]	Loss: 1.6612
Training Epoch: 12 [34816/50176]	Loss: 1.6360
Training Epoch: 12 [35840/50176]	Loss: 1.6578
Training Epoch: 12 [36864/50176]	Loss: 1.6542
Training Epoch: 12 [37888/50176]	Loss: 1.7379
Training Epoch: 12 [38912/50176]	Loss: 1.6054
Training Epoch: 12 [39936/50176]	Loss: 1.7070
Training Epoch: 12 [40960/50176]	Loss: 1.6120
Training Epoch: 12 [41984/50176]	Loss: 1.7413
Training Epoch: 12 [43008/50176]	Loss: 1.6676
Training Epoch: 12 [44032/50176]	Loss: 1.7451
Training Epoch: 12 [45056/50176]	Loss: 1.5924
Training Epoch: 12 [46080/50176]	Loss: 1.7086
Training Epoch: 12 [47104/50176]	Loss: 1.6425
Training Epoch: 12 [48128/50176]	Loss: 1.5709
Training Epoch: 12 [49152/50176]	Loss: 1.6236
Training Epoch: 12 [50176/50176]	Loss: 1.5840
2022-12-09 00:29:57.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:29:57,226 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.74 energy=514.73
2022-12-08 19:29:57,227 [ZeusDataLoader(train)] Up to epoch 13: time=722.64, energy=100163.37, cost=113312.99
2022-12-08 19:29:57,227 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:29:57,227 [ZeusDataLoader(train)] Expected next epoch: time=769.84, energy=107398.87, cost=121060.38
2022-12-08 19:29:57,228 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0020, Accuracy: 0.4733
2022-12-08 19:29:57,509 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:29:57,510 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:29:57.512 [ZeusMonitor] Monitor started.
2022-12-09 00:29:57.512 [ZeusMonitor] Running indefinitely. 2022-12-09 00:29:57.512 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:29:57.512 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e14+gpu0.power.log
2022-12-08 19:30:41,435 [ZeusDataLoader(train)] train epoch 14 done: time=44.20 energy=6698.00
2022-12-08 19:30:41,439 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.6002
Training Epoch: 13 [2048/50176]	Loss: 1.5292
Training Epoch: 13 [3072/50176]	Loss: 1.6051
Training Epoch: 13 [4096/50176]	Loss: 1.4704
Training Epoch: 13 [5120/50176]	Loss: 1.5268
Training Epoch: 13 [6144/50176]	Loss: 1.5572
Training Epoch: 13 [7168/50176]	Loss: 1.5016
Training Epoch: 13 [8192/50176]	Loss: 1.5331
Training Epoch: 13 [9216/50176]	Loss: 1.5297
Training Epoch: 13 [10240/50176]	Loss: 1.6731
Training Epoch: 13 [11264/50176]	Loss: 1.5519
Training Epoch: 13 [12288/50176]	Loss: 1.5637
Training Epoch: 13 [13312/50176]	Loss: 1.5720
Training Epoch: 13 [14336/50176]	Loss: 1.5438
Training Epoch: 13 [15360/50176]	Loss: 1.6197
Training Epoch: 13 [16384/50176]	Loss: 1.5368
Training Epoch: 13 [17408/50176]	Loss: 1.5817
Training Epoch: 13 [18432/50176]	Loss: 1.5462
Training Epoch: 13 [19456/50176]	Loss: 1.5681
Training Epoch: 13 [20480/50176]	Loss: 1.5602
Training Epoch: 13 [21504/50176]	Loss: 1.6138
Training Epoch: 13 [22528/50176]	Loss: 1.5550
Training Epoch: 13 [23552/50176]	Loss: 1.6080
Training Epoch: 13 [24576/50176]	Loss: 1.5380
Training Epoch: 13 [25600/50176]	Loss: 1.5857
Training Epoch: 13 [26624/50176]	Loss: 1.6943
Training Epoch: 13 [27648/50176]	Loss: 1.5135
Training Epoch: 13 [28672/50176]	Loss: 1.5926
Training Epoch: 13 [29696/50176]	Loss: 1.5297
Training Epoch: 13 [30720/50176]	Loss: 1.5660
Training Epoch: 13 [31744/50176]	Loss: 1.6255
Training Epoch: 13 [32768/50176]	Loss: 1.4868
Training Epoch: 13 [33792/50176]	Loss: 1.6116
Training Epoch: 13 [34816/50176]	Loss: 1.6599
Training Epoch: 13 [35840/50176]	Loss: 1.6447
Training Epoch: 13 [36864/50176]	Loss: 1.6114
Training Epoch: 13 [37888/50176]	Loss: 1.7052
Training Epoch: 13 [38912/50176]	Loss: 1.5553
Training Epoch: 13 [39936/50176]	Loss: 1.5961
Training Epoch: 13 [40960/50176]	Loss: 1.6120
Training Epoch: 13 [41984/50176]	Loss: 1.5922
Training Epoch: 13 [43008/50176]	Loss: 1.5404
Training Epoch: 13 [44032/50176]	Loss: 1.6653
Training Epoch: 13 [45056/50176]	Loss: 1.5600
Training Epoch: 13 [46080/50176]	Loss: 1.5454
Training Epoch: 13 [47104/50176]	Loss: 1.5413
Training Epoch: 13 [48128/50176]	Loss: 1.5728
Training Epoch: 13 [49152/50176]	Loss: 1.5196
Training Epoch: 13 [50176/50176]	Loss: 1.6849
2022-12-09 00:30:45.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:30:45,250 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.80 energy=524.24
2022-12-08 19:30:45,250 [ZeusDataLoader(train)] Up to epoch 14: time=770.64, energy=107385.60, cost=121124.10
2022-12-08 19:30:45,250 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:30:45,250 [ZeusDataLoader(train)] Expected next epoch: time=817.84, energy=114621.10, cost=128871.49
2022-12-08 19:30:45,251 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0018, Accuracy: 0.5026
2022-12-08 19:30:45,513 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:30:45,514 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:30:45.516 [ZeusMonitor] Monitor started.
2022-12-09 00:30:45.516 [ZeusMonitor] Running indefinitely. 2022-12-09 00:30:45.516 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:30:45.516 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e15+gpu0.power.log
2022-12-08 19:31:29,484 [ZeusDataLoader(train)] train epoch 15 done: time=44.22 energy=6712.51
2022-12-08 19:31:29,488 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.4454
Training Epoch: 14 [2048/50176]	Loss: 1.5292
Training Epoch: 14 [3072/50176]	Loss: 1.5712
Training Epoch: 14 [4096/50176]	Loss: 1.5905
Training Epoch: 14 [5120/50176]	Loss: 1.4237
Training Epoch: 14 [6144/50176]	Loss: 1.5084
Training Epoch: 14 [7168/50176]	Loss: 1.4046
Training Epoch: 14 [8192/50176]	Loss: 1.4841
Training Epoch: 14 [9216/50176]	Loss: 1.4035
Training Epoch: 14 [10240/50176]	Loss: 1.4365
Training Epoch: 14 [11264/50176]	Loss: 1.4350
Training Epoch: 14 [12288/50176]	Loss: 1.4893
Training Epoch: 14 [13312/50176]	Loss: 1.4945
Training Epoch: 14 [14336/50176]	Loss: 1.4398
Training Epoch: 14 [15360/50176]	Loss: 1.4790
Training Epoch: 14 [16384/50176]	Loss: 1.4153
Training Epoch: 14 [17408/50176]	Loss: 1.5262
Training Epoch: 14 [18432/50176]	Loss: 1.5194
Training Epoch: 14 [19456/50176]	Loss: 1.4659
Training Epoch: 14 [20480/50176]	Loss: 1.5305
Training Epoch: 14 [21504/50176]	Loss: 1.5249
Training Epoch: 14 [22528/50176]	Loss: 1.4611
Training Epoch: 14 [23552/50176]	Loss: 1.4853
Training Epoch: 14 [24576/50176]	Loss: 1.4966
Training Epoch: 14 [25600/50176]	Loss: 1.6341
Training Epoch: 14 [26624/50176]	Loss: 1.4138
Training Epoch: 14 [27648/50176]	Loss: 1.4293
Training Epoch: 14 [28672/50176]	Loss: 1.5607
Training Epoch: 14 [29696/50176]	Loss: 1.4705
Training Epoch: 14 [30720/50176]	Loss: 1.5211
Training Epoch: 14 [31744/50176]	Loss: 1.4883
Training Epoch: 14 [32768/50176]	Loss: 1.5951
Training Epoch: 14 [33792/50176]	Loss: 1.5344
Training Epoch: 14 [34816/50176]	Loss: 1.5279
Training Epoch: 14 [35840/50176]	Loss: 1.5314
Training Epoch: 14 [36864/50176]	Loss: 1.6306
Training Epoch: 14 [37888/50176]	Loss: 1.5045
Training Epoch: 14 [38912/50176]	Loss: 1.5830
Training Epoch: 14 [39936/50176]	Loss: 1.4950
Training Epoch: 14 [40960/50176]	Loss: 1.4876
Training Epoch: 14 [41984/50176]	Loss: 1.5692
Training Epoch: 14 [43008/50176]	Loss: 1.5243
Training Epoch: 14 [44032/50176]	Loss: 1.4937
Training Epoch: 14 [45056/50176]	Loss: 1.5834
Training Epoch: 14 [46080/50176]	Loss: 1.4997
Training Epoch: 14 [47104/50176]	Loss: 1.4630
Training Epoch: 14 [48128/50176]	Loss: 1.4959
Training Epoch: 14 [49152/50176]	Loss: 1.5685
Training Epoch: 14 [50176/50176]	Loss: 1.4954
2022-12-09 00:31:33.301 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:31:33,342 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.85 energy=525.48
2022-12-08 19:31:33,342 [ZeusDataLoader(train)] Up to epoch 15: time=818.71, energy=114623.59, cost=128949.22
2022-12-08 19:31:33,343 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:31:33,343 [ZeusDataLoader(train)] Expected next epoch: time=865.91, energy=121859.09, cost=136696.61
2022-12-08 19:31:33,344 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.5058
2022-12-08 19:31:33,625 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:31:33,626 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:31:33.628 [ZeusMonitor] Monitor started.
2022-12-09 00:31:33.628 [ZeusMonitor] Running indefinitely. 2022-12-09 00:31:33.628 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:31:33.628 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e16+gpu0.power.log
2022-12-08 19:32:17,571 [ZeusDataLoader(train)] train epoch 16 done: time=44.22 energy=6722.51
2022-12-08 19:32:17,574 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.5067
Training Epoch: 15 [2048/50176]	Loss: 1.4130
Training Epoch: 15 [3072/50176]	Loss: 1.4273
Training Epoch: 15 [4096/50176]	Loss: 1.4313
Training Epoch: 15 [5120/50176]	Loss: 1.4428
Training Epoch: 15 [6144/50176]	Loss: 1.4399
Training Epoch: 15 [7168/50176]	Loss: 1.3931
Training Epoch: 15 [8192/50176]	Loss: 1.4385
Training Epoch: 15 [9216/50176]	Loss: 1.4062
Training Epoch: 15 [10240/50176]	Loss: 1.4262
Training Epoch: 15 [11264/50176]	Loss: 1.4441
Training Epoch: 15 [12288/50176]	Loss: 1.5087
Training Epoch: 15 [13312/50176]	Loss: 1.3704
Training Epoch: 15 [14336/50176]	Loss: 1.4308
Training Epoch: 15 [15360/50176]	Loss: 1.4720
Training Epoch: 15 [16384/50176]	Loss: 1.5108
Training Epoch: 15 [17408/50176]	Loss: 1.3826
Training Epoch: 15 [18432/50176]	Loss: 1.4715
Training Epoch: 15 [19456/50176]	Loss: 1.4302
Training Epoch: 15 [20480/50176]	Loss: 1.3708
Training Epoch: 15 [21504/50176]	Loss: 1.4030
Training Epoch: 15 [22528/50176]	Loss: 1.5254
Training Epoch: 15 [23552/50176]	Loss: 1.4631
Training Epoch: 15 [24576/50176]	Loss: 1.3971
Training Epoch: 15 [25600/50176]	Loss: 1.4230
Training Epoch: 15 [26624/50176]	Loss: 1.3961
Training Epoch: 15 [27648/50176]	Loss: 1.4906
Training Epoch: 15 [28672/50176]	Loss: 1.3542
Training Epoch: 15 [29696/50176]	Loss: 1.4771
Training Epoch: 15 [30720/50176]	Loss: 1.4844
Training Epoch: 15 [31744/50176]	Loss: 1.4732
Training Epoch: 15 [32768/50176]	Loss: 1.4441
Training Epoch: 15 [33792/50176]	Loss: 1.3935
Training Epoch: 15 [34816/50176]	Loss: 1.4633
Training Epoch: 15 [35840/50176]	Loss: 1.4314
Training Epoch: 15 [36864/50176]	Loss: 1.4035
Training Epoch: 15 [37888/50176]	Loss: 1.4353
Training Epoch: 15 [38912/50176]	Loss: 1.4322
Training Epoch: 15 [39936/50176]	Loss: 1.4386
Training Epoch: 15 [40960/50176]	Loss: 1.4754
Training Epoch: 15 [41984/50176]	Loss: 1.4674
Training Epoch: 15 [43008/50176]	Loss: 1.4877
Training Epoch: 15 [44032/50176]	Loss: 1.4024
Training Epoch: 15 [45056/50176]	Loss: 1.3657
Training Epoch: 15 [46080/50176]	Loss: 1.4646
Training Epoch: 15 [47104/50176]	Loss: 1.3764
Training Epoch: 15 [48128/50176]	Loss: 1.4847
Training Epoch: 15 [49152/50176]	Loss: 1.3009
Training Epoch: 15 [50176/50176]	Loss: 1.3613
2022-12-09 00:32:21.351 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:32:21,410 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.83 energy=531.53
2022-12-08 19:32:21,410 [ZeusDataLoader(train)] Up to epoch 16: time=866.76, energy=121877.63, cost=136780.12
2022-12-08 19:32:21,410 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:32:21,411 [ZeusDataLoader(train)] Expected next epoch: time=913.95, energy=129113.13, cost=144527.51
2022-12-08 19:32:21,412 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0018, Accuracy: 0.5065
2022-12-08 19:32:21,684 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:32:21,685 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:32:21.687 [ZeusMonitor] Monitor started.
2022-12-09 00:32:21.687 [ZeusMonitor] Running indefinitely. 2022-12-09 00:32:21.687 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:32:21.687 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e17+gpu0.power.log
2022-12-08 19:33:05,632 [ZeusDataLoader(train)] train epoch 17 done: time=44.21 energy=6717.43
2022-12-08 19:33:05,635 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.3444
Training Epoch: 16 [2048/50176]	Loss: 1.3562
Training Epoch: 16 [3072/50176]	Loss: 1.3238
Training Epoch: 16 [4096/50176]	Loss: 1.3535
Training Epoch: 16 [5120/50176]	Loss: 1.3437
Training Epoch: 16 [6144/50176]	Loss: 1.2813
Training Epoch: 16 [7168/50176]	Loss: 1.2881
Training Epoch: 16 [8192/50176]	Loss: 1.2816
Training Epoch: 16 [9216/50176]	Loss: 1.3204
Training Epoch: 16 [10240/50176]	Loss: 1.2998
Training Epoch: 16 [11264/50176]	Loss: 1.3466
Training Epoch: 16 [12288/50176]	Loss: 1.3459
Training Epoch: 16 [13312/50176]	Loss: 1.3341
Training Epoch: 16 [14336/50176]	Loss: 1.3739
Training Epoch: 16 [15360/50176]	Loss: 1.4213
Training Epoch: 16 [16384/50176]	Loss: 1.3372
Training Epoch: 16 [17408/50176]	Loss: 1.3504
Training Epoch: 16 [18432/50176]	Loss: 1.4162
Training Epoch: 16 [19456/50176]	Loss: 1.3497
Training Epoch: 16 [20480/50176]	Loss: 1.3484
Training Epoch: 16 [21504/50176]	Loss: 1.3437
Training Epoch: 16 [22528/50176]	Loss: 1.3536
Training Epoch: 16 [23552/50176]	Loss: 1.3797
Training Epoch: 16 [24576/50176]	Loss: 1.3932
Training Epoch: 16 [25600/50176]	Loss: 1.3559
Training Epoch: 16 [26624/50176]	Loss: 1.2974
Training Epoch: 16 [27648/50176]	Loss: 1.4112
Training Epoch: 16 [28672/50176]	Loss: 1.3918
Training Epoch: 16 [29696/50176]	Loss: 1.2908
Training Epoch: 16 [30720/50176]	Loss: 1.3557
Training Epoch: 16 [31744/50176]	Loss: 1.3571
Training Epoch: 16 [32768/50176]	Loss: 1.3971
Training Epoch: 16 [33792/50176]	Loss: 1.3348
Training Epoch: 16 [34816/50176]	Loss: 1.3661
Training Epoch: 16 [35840/50176]	Loss: 1.4212
Training Epoch: 16 [36864/50176]	Loss: 1.3868
Training Epoch: 16 [37888/50176]	Loss: 1.2794
Training Epoch: 16 [38912/50176]	Loss: 1.3745
Training Epoch: 16 [39936/50176]	Loss: 1.4858
Training Epoch: 16 [40960/50176]	Loss: 1.3777
Training Epoch: 16 [41984/50176]	Loss: 1.3557
Training Epoch: 16 [43008/50176]	Loss: 1.3619
Training Epoch: 16 [44032/50176]	Loss: 1.3965
Training Epoch: 16 [45056/50176]	Loss: 1.4495
Training Epoch: 16 [46080/50176]	Loss: 1.4301
Training Epoch: 16 [47104/50176]	Loss: 1.3542
Training Epoch: 16 [48128/50176]	Loss: 1.4421
Training Epoch: 16 [49152/50176]	Loss: 1.4469
Training Epoch: 16 [50176/50176]	Loss: 1.3674
2022-12-09 00:33:09.392 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:33:09,402 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.76 energy=512.92
2022-12-08 19:33:09,402 [ZeusDataLoader(train)] Up to epoch 17: time=914.73, energy=129107.97, cost=144592.62
2022-12-08 19:33:09,402 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:33:09,402 [ZeusDataLoader(train)] Expected next epoch: time=961.92, energy=136343.47, cost=152340.02
2022-12-08 19:33:09,403 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0017, Accuracy: 0.5200
2022-12-08 19:33:09,630 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:33:09,631 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:33:09.633 [ZeusMonitor] Monitor started.
2022-12-09 00:33:09.633 [ZeusMonitor] Running indefinitely. 2022-12-09 00:33:09.633 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:33:09.633 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e18+gpu0.power.log
2022-12-08 19:33:53,703 [ZeusDataLoader(train)] train epoch 18 done: time=44.29 energy=6732.32
2022-12-08 19:33:53,707 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.2475
Training Epoch: 17 [2048/50176]	Loss: 1.2302
Training Epoch: 17 [3072/50176]	Loss: 1.1571
Training Epoch: 17 [4096/50176]	Loss: 1.2380
Training Epoch: 17 [5120/50176]	Loss: 1.3716
Training Epoch: 17 [6144/50176]	Loss: 1.2969
Training Epoch: 17 [7168/50176]	Loss: 1.2235
Training Epoch: 17 [8192/50176]	Loss: 1.2369
Training Epoch: 17 [9216/50176]	Loss: 1.2879
Training Epoch: 17 [10240/50176]	Loss: 1.2274
Training Epoch: 17 [11264/50176]	Loss: 1.2986
Training Epoch: 17 [12288/50176]	Loss: 1.3170
Training Epoch: 17 [13312/50176]	Loss: 1.2406
Training Epoch: 17 [14336/50176]	Loss: 1.2674
Training Epoch: 17 [15360/50176]	Loss: 1.2234
Training Epoch: 17 [16384/50176]	Loss: 1.2313
Training Epoch: 17 [17408/50176]	Loss: 1.3225
Training Epoch: 17 [18432/50176]	Loss: 1.3613
Training Epoch: 17 [19456/50176]	Loss: 1.2304
Training Epoch: 17 [20480/50176]	Loss: 1.2557
Training Epoch: 17 [21504/50176]	Loss: 1.2872
Training Epoch: 17 [22528/50176]	Loss: 1.3755
Training Epoch: 17 [23552/50176]	Loss: 1.3041
Training Epoch: 17 [24576/50176]	Loss: 1.3402
Training Epoch: 17 [25600/50176]	Loss: 1.3246
Training Epoch: 17 [26624/50176]	Loss: 1.2910
Training Epoch: 17 [27648/50176]	Loss: 1.2426
Training Epoch: 17 [28672/50176]	Loss: 1.3643
Training Epoch: 17 [29696/50176]	Loss: 1.3720
Training Epoch: 17 [30720/50176]	Loss: 1.3815
Training Epoch: 17 [31744/50176]	Loss: 1.3088
Training Epoch: 17 [32768/50176]	Loss: 1.2859
Training Epoch: 17 [33792/50176]	Loss: 1.3350
Training Epoch: 17 [34816/50176]	Loss: 1.3100
Training Epoch: 17 [35840/50176]	Loss: 1.2378
Training Epoch: 17 [36864/50176]	Loss: 1.3490
Training Epoch: 17 [37888/50176]	Loss: 1.2873
Training Epoch: 17 [38912/50176]	Loss: 1.4054
Training Epoch: 17 [39936/50176]	Loss: 1.3861
Training Epoch: 17 [40960/50176]	Loss: 1.3056
Training Epoch: 17 [41984/50176]	Loss: 1.3709
Training Epoch: 17 [43008/50176]	Loss: 1.3299
Training Epoch: 17 [44032/50176]	Loss: 1.3873
Training Epoch: 17 [45056/50176]	Loss: 1.3293
Training Epoch: 17 [46080/50176]	Loss: 1.2812
Training Epoch: 17 [47104/50176]	Loss: 1.2978
Training Epoch: 17 [48128/50176]	Loss: 1.3296
Training Epoch: 17 [49152/50176]	Loss: 1.3054
Training Epoch: 17 [50176/50176]	Loss: 1.3173
2022-12-09 00:33:57.461 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:33:57,473 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.76 energy=513.60
2022-12-08 19:33:57,473 [ZeusDataLoader(train)] Up to epoch 18: time=962.78, energy=136353.89, cost=152419.77
2022-12-08 19:33:57,474 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:33:57,474 [ZeusDataLoader(train)] Expected next epoch: time=1009.97, energy=143589.39, cost=160167.16
2022-12-08 19:33:57,475 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0018, Accuracy: 0.5117
2022-12-08 19:33:57,688 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:33:57,689 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:33:57.693 [ZeusMonitor] Monitor started.
2022-12-09 00:33:57.693 [ZeusMonitor] Running indefinitely. 2022-12-09 00:33:57.693 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:33:57.693 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e19+gpu0.power.log
2022-12-08 19:34:41,628 [ZeusDataLoader(train)] train epoch 19 done: time=44.14 energy=6720.76
2022-12-08 19:34:41,632 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.2080
Training Epoch: 18 [2048/50176]	Loss: 1.2580
Training Epoch: 18 [3072/50176]	Loss: 1.2356
Training Epoch: 18 [4096/50176]	Loss: 1.1908
Training Epoch: 18 [5120/50176]	Loss: 1.2113
Training Epoch: 18 [6144/50176]	Loss: 1.2126
Training Epoch: 18 [7168/50176]	Loss: 1.2071
Training Epoch: 18 [8192/50176]	Loss: 1.2321
Training Epoch: 18 [9216/50176]	Loss: 1.2009
Training Epoch: 18 [10240/50176]	Loss: 1.2155
Training Epoch: 18 [11264/50176]	Loss: 1.2814
Training Epoch: 18 [12288/50176]	Loss: 1.2288
Training Epoch: 18 [13312/50176]	Loss: 1.2119
Training Epoch: 18 [14336/50176]	Loss: 1.1915
Training Epoch: 18 [15360/50176]	Loss: 1.2629
Training Epoch: 18 [16384/50176]	Loss: 1.2679
Training Epoch: 18 [17408/50176]	Loss: 1.2953
Training Epoch: 18 [18432/50176]	Loss: 1.2831
Training Epoch: 18 [19456/50176]	Loss: 1.3021
Training Epoch: 18 [20480/50176]	Loss: 1.2744
Training Epoch: 18 [21504/50176]	Loss: 1.2828
Training Epoch: 18 [22528/50176]	Loss: 1.3293
Training Epoch: 18 [23552/50176]	Loss: 1.1609
Training Epoch: 18 [24576/50176]	Loss: 1.1747
Training Epoch: 18 [25600/50176]	Loss: 1.2001
Training Epoch: 18 [26624/50176]	Loss: 1.1639
Training Epoch: 18 [27648/50176]	Loss: 1.2313
Training Epoch: 18 [28672/50176]	Loss: 1.2319
Training Epoch: 18 [29696/50176]	Loss: 1.2152
Training Epoch: 18 [30720/50176]	Loss: 1.2810
Training Epoch: 18 [31744/50176]	Loss: 1.2985
Training Epoch: 18 [32768/50176]	Loss: 1.2210
Training Epoch: 18 [33792/50176]	Loss: 1.2845
Training Epoch: 18 [34816/50176]	Loss: 1.2157
Training Epoch: 18 [35840/50176]	Loss: 1.3113
Training Epoch: 18 [36864/50176]	Loss: 1.2405
Training Epoch: 18 [37888/50176]	Loss: 1.1959
Training Epoch: 18 [38912/50176]	Loss: 1.2864
Training Epoch: 18 [39936/50176]	Loss: 1.2921
Training Epoch: 18 [40960/50176]	Loss: 1.2475
Training Epoch: 18 [41984/50176]	Loss: 1.2783
Training Epoch: 18 [43008/50176]	Loss: 1.2892
Training Epoch: 18 [44032/50176]	Loss: 1.2821
Training Epoch: 18 [45056/50176]	Loss: 1.2433
Training Epoch: 18 [46080/50176]	Loss: 1.3024
Training Epoch: 18 [47104/50176]	Loss: 1.2208
Training Epoch: 18 [48128/50176]	Loss: 1.2428
Training Epoch: 18 [49152/50176]	Loss: 1.2944
Training Epoch: 18 [50176/50176]	Loss: 1.3373
2022-12-09 00:34:45.391 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:34:45,407 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.77 energy=511.03
2022-12-08 19:34:45,407 [ZeusDataLoader(train)] Up to epoch 19: time=1010.69, energy=143585.68, cost=160227.86
2022-12-08 19:34:45,407 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:34:45,407 [ZeusDataLoader(train)] Expected next epoch: time=1057.88, energy=150821.18, cost=167975.26
2022-12-08 19:34:45,408 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0017, Accuracy: 0.5281
2022-12-08 19:34:45,678 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:34:45,679 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:34:45.693 [ZeusMonitor] Monitor started.
2022-12-09 00:34:45.693 [ZeusMonitor] Running indefinitely. 2022-12-09 00:34:45.693 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:34:45.693 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e20+gpu0.power.log
2022-12-08 19:35:29,586 [ZeusDataLoader(train)] train epoch 20 done: time=44.17 energy=6714.97
2022-12-08 19:35:29,590 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.1218
Training Epoch: 19 [2048/50176]	Loss: 1.1902
Training Epoch: 19 [3072/50176]	Loss: 1.0940
Training Epoch: 19 [4096/50176]	Loss: 1.1660
Training Epoch: 19 [5120/50176]	Loss: 1.1386
Training Epoch: 19 [6144/50176]	Loss: 1.1718
Training Epoch: 19 [7168/50176]	Loss: 1.1378
Training Epoch: 19 [8192/50176]	Loss: 1.1191
Training Epoch: 19 [9216/50176]	Loss: 1.1661
Training Epoch: 19 [10240/50176]	Loss: 1.2059
Training Epoch: 19 [11264/50176]	Loss: 1.1653
Training Epoch: 19 [12288/50176]	Loss: 1.1509
Training Epoch: 19 [13312/50176]	Loss: 1.1426
Training Epoch: 19 [14336/50176]	Loss: 1.1863
Training Epoch: 19 [15360/50176]	Loss: 1.1515
Training Epoch: 19 [16384/50176]	Loss: 1.2148
Training Epoch: 19 [17408/50176]	Loss: 1.2338
Training Epoch: 19 [18432/50176]	Loss: 1.1521
Training Epoch: 19 [19456/50176]	Loss: 1.1152
Training Epoch: 19 [20480/50176]	Loss: 1.2347
Training Epoch: 19 [21504/50176]	Loss: 1.1091
Training Epoch: 19 [22528/50176]	Loss: 1.2838
Training Epoch: 19 [23552/50176]	Loss: 1.2793
Training Epoch: 19 [24576/50176]	Loss: 1.1269
Training Epoch: 19 [25600/50176]	Loss: 1.2126
Training Epoch: 19 [26624/50176]	Loss: 1.2120
Training Epoch: 19 [27648/50176]	Loss: 1.1339
Training Epoch: 19 [28672/50176]	Loss: 1.2124
Training Epoch: 19 [29696/50176]	Loss: 1.2891
Training Epoch: 19 [30720/50176]	Loss: 1.2001
Training Epoch: 19 [31744/50176]	Loss: 1.2010
Training Epoch: 19 [32768/50176]	Loss: 1.2480
Training Epoch: 19 [33792/50176]	Loss: 1.2553
Training Epoch: 19 [34816/50176]	Loss: 1.2231
Training Epoch: 19 [35840/50176]	Loss: 1.1843
Training Epoch: 19 [36864/50176]	Loss: 1.2813
Training Epoch: 19 [37888/50176]	Loss: 1.1271
Training Epoch: 19 [38912/50176]	Loss: 1.3045
Training Epoch: 19 [39936/50176]	Loss: 1.1359
Training Epoch: 19 [40960/50176]	Loss: 1.1266
Training Epoch: 19 [41984/50176]	Loss: 1.2791
Training Epoch: 19 [43008/50176]	Loss: 1.2116
Training Epoch: 19 [44032/50176]	Loss: 1.2129
Training Epoch: 19 [45056/50176]	Loss: 1.1951
Training Epoch: 19 [46080/50176]	Loss: 1.1554
Training Epoch: 19 [47104/50176]	Loss: 1.2264
Training Epoch: 19 [48128/50176]	Loss: 1.1344
Training Epoch: 19 [49152/50176]	Loss: 1.2169
Training Epoch: 19 [50176/50176]	Loss: 1.1488
2022-12-09 00:35:33.316 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:35:33,328 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.73 energy=524.15
2022-12-08 19:35:33,328 [ZeusDataLoader(train)] Up to epoch 20: time=1058.59, energy=150824.80, cost=168038.60
2022-12-08 19:35:33,329 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:35:33,329 [ZeusDataLoader(train)] Expected next epoch: time=1105.78, energy=158060.30, cost=175785.99
2022-12-08 19:35:33,330 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0020, Accuracy: 0.4931
2022-12-08 19:35:33,544 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:35:33,545 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:35:33.549 [ZeusMonitor] Monitor started.
2022-12-09 00:35:33.549 [ZeusMonitor] Running indefinitely. 2022-12-09 00:35:33.549 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:35:33.549 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e21+gpu0.power.log
2022-12-08 19:36:17,526 [ZeusDataLoader(train)] train epoch 21 done: time=44.19 energy=6715.05
2022-12-08 19:36:17,529 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0834
Training Epoch: 20 [2048/50176]	Loss: 1.1361
Training Epoch: 20 [3072/50176]	Loss: 1.1214
Training Epoch: 20 [4096/50176]	Loss: 1.0695
Training Epoch: 20 [5120/50176]	Loss: 1.0609
Training Epoch: 20 [6144/50176]	Loss: 1.1645
Training Epoch: 20 [7168/50176]	Loss: 1.0647
Training Epoch: 20 [8192/50176]	Loss: 1.0973
Training Epoch: 20 [9216/50176]	Loss: 1.0547
Training Epoch: 20 [10240/50176]	Loss: 1.0633
Training Epoch: 20 [11264/50176]	Loss: 1.1104
Training Epoch: 20 [12288/50176]	Loss: 1.0796
Training Epoch: 20 [13312/50176]	Loss: 1.0466
Training Epoch: 20 [14336/50176]	Loss: 1.1399
Training Epoch: 20 [15360/50176]	Loss: 1.1610
Training Epoch: 20 [16384/50176]	Loss: 1.1853
Training Epoch: 20 [17408/50176]	Loss: 1.1041
Training Epoch: 20 [18432/50176]	Loss: 1.1525
Training Epoch: 20 [19456/50176]	Loss: 1.1862
Training Epoch: 20 [20480/50176]	Loss: 1.1233
Training Epoch: 20 [21504/50176]	Loss: 1.1858
Training Epoch: 20 [22528/50176]	Loss: 1.0903
Training Epoch: 20 [23552/50176]	Loss: 1.0759
Training Epoch: 20 [24576/50176]	Loss: 1.1550
Training Epoch: 20 [25600/50176]	Loss: 1.1786
Training Epoch: 20 [26624/50176]	Loss: 1.1531
Training Epoch: 20 [27648/50176]	Loss: 1.0215
Training Epoch: 20 [28672/50176]	Loss: 1.2237
Training Epoch: 20 [29696/50176]	Loss: 1.1000
Training Epoch: 20 [30720/50176]	Loss: 1.0773
Training Epoch: 20 [31744/50176]	Loss: 1.1641
Training Epoch: 20 [32768/50176]	Loss: 1.0983
Training Epoch: 20 [33792/50176]	Loss: 1.1361
Training Epoch: 20 [34816/50176]	Loss: 1.2082
Training Epoch: 20 [35840/50176]	Loss: 1.1751
Training Epoch: 20 [36864/50176]	Loss: 1.1468
Training Epoch: 20 [37888/50176]	Loss: 1.1110
Training Epoch: 20 [38912/50176]	Loss: 1.2186
Training Epoch: 20 [39936/50176]	Loss: 1.1796
Training Epoch: 20 [40960/50176]	Loss: 1.1722
Training Epoch: 20 [41984/50176]	Loss: 1.1723
Training Epoch: 20 [43008/50176]	Loss: 1.1795
Training Epoch: 20 [44032/50176]	Loss: 1.0710
Training Epoch: 20 [45056/50176]	Loss: 1.2130
Training Epoch: 20 [46080/50176]	Loss: 1.1296
Training Epoch: 20 [47104/50176]	Loss: 1.1866
Training Epoch: 20 [48128/50176]	Loss: 1.1188
Training Epoch: 20 [49152/50176]	Loss: 1.2176
Training Epoch: 20 [50176/50176]	Loss: 1.1581
2022-12-09 00:36:21.263 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:36:21,277 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.74 energy=517.59
2022-12-08 19:36:21,277 [ZeusDataLoader(train)] Up to epoch 21: time=1106.51, energy=158057.44, cost=175848.47
2022-12-08 19:36:21,277 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:36:21,277 [ZeusDataLoader(train)] Expected next epoch: time=1153.71, energy=165292.94, cost=183595.87
2022-12-08 19:36:21,278 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0017, Accuracy: 0.5396
2022-12-08 19:36:21,544 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:36:21,545 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:36:21.547 [ZeusMonitor] Monitor started.
2022-12-09 00:36:21.547 [ZeusMonitor] Running indefinitely. 2022-12-09 00:36:21.547 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:36:21.547 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e22+gpu0.power.log
2022-12-08 19:37:05,506 [ZeusDataLoader(train)] train epoch 22 done: time=44.22 energy=6702.81
2022-12-08 19:37:05,510 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0611
Training Epoch: 21 [2048/50176]	Loss: 1.0260
Training Epoch: 21 [3072/50176]	Loss: 1.0646
Training Epoch: 21 [4096/50176]	Loss: 1.0679
Training Epoch: 21 [5120/50176]	Loss: 1.0081
Training Epoch: 21 [6144/50176]	Loss: 1.0213
Training Epoch: 21 [7168/50176]	Loss: 0.9940
Training Epoch: 21 [8192/50176]	Loss: 1.0436
Training Epoch: 21 [9216/50176]	Loss: 1.0776
Training Epoch: 21 [10240/50176]	Loss: 1.0010
Training Epoch: 21 [11264/50176]	Loss: 1.0388
Training Epoch: 21 [12288/50176]	Loss: 1.0239
Training Epoch: 21 [13312/50176]	Loss: 1.0305
Training Epoch: 21 [14336/50176]	Loss: 1.1023
Training Epoch: 21 [15360/50176]	Loss: 1.0310
Training Epoch: 21 [16384/50176]	Loss: 1.1070
Training Epoch: 21 [17408/50176]	Loss: 1.0019
Training Epoch: 21 [18432/50176]	Loss: 1.0118
Training Epoch: 21 [19456/50176]	Loss: 1.0693
Training Epoch: 21 [20480/50176]	Loss: 1.0746
Training Epoch: 21 [21504/50176]	Loss: 1.0539
Training Epoch: 21 [22528/50176]	Loss: 1.1257
Training Epoch: 21 [23552/50176]	Loss: 1.1056
Training Epoch: 21 [24576/50176]	Loss: 1.0733
Training Epoch: 21 [25600/50176]	Loss: 1.1303
Training Epoch: 21 [26624/50176]	Loss: 1.1795
Training Epoch: 21 [27648/50176]	Loss: 1.0793
Training Epoch: 21 [28672/50176]	Loss: 1.0461
Training Epoch: 21 [29696/50176]	Loss: 1.1116
Training Epoch: 21 [30720/50176]	Loss: 1.0971
Training Epoch: 21 [31744/50176]	Loss: 1.0999
Training Epoch: 21 [32768/50176]	Loss: 1.1254
Training Epoch: 21 [33792/50176]	Loss: 1.0851
Training Epoch: 21 [34816/50176]	Loss: 1.0866
Training Epoch: 21 [35840/50176]	Loss: 1.0737
Training Epoch: 21 [36864/50176]	Loss: 1.0345
Training Epoch: 21 [37888/50176]	Loss: 1.1372
Training Epoch: 21 [38912/50176]	Loss: 1.1112
Training Epoch: 21 [39936/50176]	Loss: 1.1185
Training Epoch: 21 [40960/50176]	Loss: 1.0631
Training Epoch: 21 [41984/50176]	Loss: 1.1498
Training Epoch: 21 [43008/50176]	Loss: 1.0958
Training Epoch: 21 [44032/50176]	Loss: 1.1750
Training Epoch: 21 [45056/50176]	Loss: 1.1061
Training Epoch: 21 [46080/50176]	Loss: 1.0861
Training Epoch: 21 [47104/50176]	Loss: 1.1496
Training Epoch: 21 [48128/50176]	Loss: 1.1463
Training Epoch: 21 [49152/50176]	Loss: 1.1571
Training Epoch: 21 [50176/50176]	Loss: 1.1420
2022-12-09 00:37:09.311 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:37:09,347 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.83 energy=535.71
2022-12-08 19:37:09,348 [ZeusDataLoader(train)] Up to epoch 22: time=1154.56, energy=165295.96, cost=183671.99
2022-12-08 19:37:09,348 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:37:09,348 [ZeusDataLoader(train)] Expected next epoch: time=1201.76, energy=172531.46, cost=191419.39
2022-12-08 19:37:09,349 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0016, Accuracy: 0.5609
2022-12-08 19:37:09,650 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:37:09,651 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:37:09.673 [ZeusMonitor] Monitor started.
2022-12-09 00:37:09.673 [ZeusMonitor] Running indefinitely. 2022-12-09 00:37:09.673 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:37:09.673 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e23+gpu0.power.log
2022-12-08 19:37:53,576 [ZeusDataLoader(train)] train epoch 23 done: time=44.22 energy=6705.89
2022-12-08 19:37:53,580 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.0459
Training Epoch: 22 [2048/50176]	Loss: 1.0387
Training Epoch: 22 [3072/50176]	Loss: 1.0169
Training Epoch: 22 [4096/50176]	Loss: 0.9481
Training Epoch: 22 [5120/50176]	Loss: 1.0304
Training Epoch: 22 [6144/50176]	Loss: 0.9913
Training Epoch: 22 [7168/50176]	Loss: 1.0487
Training Epoch: 22 [8192/50176]	Loss: 1.0482
Training Epoch: 22 [9216/50176]	Loss: 1.0526
Training Epoch: 22 [10240/50176]	Loss: 0.9649
Training Epoch: 22 [11264/50176]	Loss: 1.0655
Training Epoch: 22 [12288/50176]	Loss: 1.0725
Training Epoch: 22 [13312/50176]	Loss: 0.9250
Training Epoch: 22 [14336/50176]	Loss: 1.0514
Training Epoch: 22 [15360/50176]	Loss: 1.0205
Training Epoch: 22 [16384/50176]	Loss: 1.0268
Training Epoch: 22 [17408/50176]	Loss: 0.9859
Training Epoch: 22 [18432/50176]	Loss: 1.0312
Training Epoch: 22 [19456/50176]	Loss: 1.0956
Training Epoch: 22 [20480/50176]	Loss: 1.0707
Training Epoch: 22 [21504/50176]	Loss: 1.0049
Training Epoch: 22 [22528/50176]	Loss: 1.1024
Training Epoch: 22 [23552/50176]	Loss: 1.0518
Training Epoch: 22 [24576/50176]	Loss: 1.0709
Training Epoch: 22 [25600/50176]	Loss: 1.0705
Training Epoch: 22 [26624/50176]	Loss: 1.0847
Training Epoch: 22 [27648/50176]	Loss: 1.0667
Training Epoch: 22 [28672/50176]	Loss: 1.0945
Training Epoch: 22 [29696/50176]	Loss: 1.1084
Training Epoch: 22 [30720/50176]	Loss: 0.9982
Training Epoch: 22 [31744/50176]	Loss: 1.1412
Training Epoch: 22 [32768/50176]	Loss: 1.0239
Training Epoch: 22 [33792/50176]	Loss: 1.0808
Training Epoch: 22 [34816/50176]	Loss: 1.0909
Training Epoch: 22 [35840/50176]	Loss: 1.0505
Training Epoch: 22 [36864/50176]	Loss: 1.0478
Training Epoch: 22 [37888/50176]	Loss: 1.0962
Training Epoch: 22 [38912/50176]	Loss: 1.0232
Training Epoch: 22 [39936/50176]	Loss: 1.0511
Training Epoch: 22 [40960/50176]	Loss: 1.0644
Training Epoch: 22 [41984/50176]	Loss: 1.1537
Training Epoch: 22 [43008/50176]	Loss: 1.0707
Training Epoch: 22 [44032/50176]	Loss: 1.0724
Training Epoch: 22 [45056/50176]	Loss: 1.0543
Training Epoch: 22 [46080/50176]	Loss: 1.0857
Training Epoch: 22 [47104/50176]	Loss: 1.0450
Training Epoch: 22 [48128/50176]	Loss: 1.1780
Training Epoch: 22 [49152/50176]	Loss: 1.1471
Training Epoch: 22 [50176/50176]	Loss: 1.0555
2022-12-09 00:37:57.402 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:37:57,437 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.85 energy=529.54
2022-12-08 19:37:57,437 [ZeusDataLoader(train)] Up to epoch 23: time=1202.63, energy=172531.39, cost=191495.52
2022-12-08 19:37:57,437 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:37:57,437 [ZeusDataLoader(train)] Expected next epoch: time=1249.82, energy=179766.89, cost=199242.91
2022-12-08 19:37:57,438 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0017, Accuracy: 0.5490
2022-12-08 19:37:57,669 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:37:57,670 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:37:57.674 [ZeusMonitor] Monitor started.
2022-12-09 00:37:57.674 [ZeusMonitor] Running indefinitely. 2022-12-09 00:37:57.674 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:37:57.674 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e24+gpu0.power.log
2022-12-08 19:38:41,695 [ZeusDataLoader(train)] train epoch 24 done: time=44.25 energy=6716.19
2022-12-08 19:38:41,699 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.0416
Training Epoch: 23 [2048/50176]	Loss: 0.9052
Training Epoch: 23 [3072/50176]	Loss: 0.9870
Training Epoch: 23 [4096/50176]	Loss: 0.9861
Training Epoch: 23 [5120/50176]	Loss: 1.0060
Training Epoch: 23 [6144/50176]	Loss: 0.9594
Training Epoch: 23 [7168/50176]	Loss: 0.9958
Training Epoch: 23 [8192/50176]	Loss: 0.9225
Training Epoch: 23 [9216/50176]	Loss: 0.9466
Training Epoch: 23 [10240/50176]	Loss: 0.9319
Training Epoch: 23 [11264/50176]	Loss: 1.0011
Training Epoch: 23 [12288/50176]	Loss: 0.9062
Training Epoch: 23 [13312/50176]	Loss: 1.0457
Training Epoch: 23 [14336/50176]	Loss: 0.9546
Training Epoch: 23 [15360/50176]	Loss: 0.9051
Training Epoch: 23 [16384/50176]	Loss: 1.0154
Training Epoch: 23 [17408/50176]	Loss: 0.9868
Training Epoch: 23 [18432/50176]	Loss: 0.9067
Training Epoch: 23 [19456/50176]	Loss: 0.9783
Training Epoch: 23 [20480/50176]	Loss: 0.9419
Training Epoch: 23 [21504/50176]	Loss: 1.0001
Training Epoch: 23 [22528/50176]	Loss: 0.9555
Training Epoch: 23 [23552/50176]	Loss: 0.9035
Training Epoch: 23 [24576/50176]	Loss: 0.9935
Training Epoch: 23 [25600/50176]	Loss: 0.9870
Training Epoch: 23 [26624/50176]	Loss: 0.9901
Training Epoch: 23 [27648/50176]	Loss: 0.9443
Training Epoch: 23 [28672/50176]	Loss: 0.9739
Training Epoch: 23 [29696/50176]	Loss: 0.9755
Training Epoch: 23 [30720/50176]	Loss: 1.0075
Training Epoch: 23 [31744/50176]	Loss: 1.0749
Training Epoch: 23 [32768/50176]	Loss: 1.0017
Training Epoch: 23 [33792/50176]	Loss: 0.9842
Training Epoch: 23 [34816/50176]	Loss: 1.0443
Training Epoch: 23 [35840/50176]	Loss: 0.9713
Training Epoch: 23 [36864/50176]	Loss: 0.9703
Training Epoch: 23 [37888/50176]	Loss: 0.9449
Training Epoch: 23 [38912/50176]	Loss: 1.0650
Training Epoch: 23 [39936/50176]	Loss: 0.9967
Training Epoch: 23 [40960/50176]	Loss: 1.0114
Training Epoch: 23 [41984/50176]	Loss: 1.0198
Training Epoch: 23 [43008/50176]	Loss: 0.9711
Training Epoch: 23 [44032/50176]	Loss: 1.0786
Training Epoch: 23 [45056/50176]	Loss: 1.0527
Training Epoch: 23 [46080/50176]	Loss: 1.0889
Training Epoch: 23 [47104/50176]	Loss: 1.0843
Training Epoch: 23 [48128/50176]	Loss: 1.0023
Training Epoch: 23 [49152/50176]	Loss: 0.9892
Training Epoch: 23 [50176/50176]	Loss: 0.9572
2022-12-09 00:38:45.445 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:38:45,457 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.75 energy=516.40
2022-12-08 19:38:45,457 [ZeusDataLoader(train)] Up to epoch 24: time=1250.62, energy=179763.97, cost=199311.64
2022-12-08 19:38:45,457 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:38:45,457 [ZeusDataLoader(train)] Expected next epoch: time=1297.82, energy=186999.47, cost=207059.03
2022-12-08 19:38:45,458 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0017, Accuracy: 0.5509
2022-12-08 19:38:45,749 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:38:45,750 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:38:45.752 [ZeusMonitor] Monitor started.
2022-12-09 00:38:45.752 [ZeusMonitor] Running indefinitely. 2022-12-09 00:38:45.752 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:38:45.752 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e25+gpu0.power.log
2022-12-08 19:39:29,677 [ZeusDataLoader(train)] train epoch 25 done: time=44.21 energy=6707.36
2022-12-08 19:39:29,681 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8575
Training Epoch: 24 [2048/50176]	Loss: 0.8416
Training Epoch: 24 [3072/50176]	Loss: 0.9202
Training Epoch: 24 [4096/50176]	Loss: 0.8690
Training Epoch: 24 [5120/50176]	Loss: 0.8908
Training Epoch: 24 [6144/50176]	Loss: 0.8815
Training Epoch: 24 [7168/50176]	Loss: 0.9525
Training Epoch: 24 [8192/50176]	Loss: 0.8956
Training Epoch: 24 [9216/50176]	Loss: 0.9493
Training Epoch: 24 [10240/50176]	Loss: 0.9111
Training Epoch: 24 [11264/50176]	Loss: 0.9044
Training Epoch: 24 [12288/50176]	Loss: 0.9181
Training Epoch: 24 [13312/50176]	Loss: 0.9178
Training Epoch: 24 [14336/50176]	Loss: 0.9278
Training Epoch: 24 [15360/50176]	Loss: 0.8392
Training Epoch: 24 [16384/50176]	Loss: 0.8506
Training Epoch: 24 [17408/50176]	Loss: 0.9957
Training Epoch: 24 [18432/50176]	Loss: 0.9392
Training Epoch: 24 [19456/50176]	Loss: 0.9704
Training Epoch: 24 [20480/50176]	Loss: 0.9830
Training Epoch: 24 [21504/50176]	Loss: 0.9840
Training Epoch: 24 [22528/50176]	Loss: 0.8206
Training Epoch: 24 [23552/50176]	Loss: 1.0167
Training Epoch: 24 [24576/50176]	Loss: 0.9422
Training Epoch: 24 [25600/50176]	Loss: 0.9751
Training Epoch: 24 [26624/50176]	Loss: 0.8960
Training Epoch: 24 [27648/50176]	Loss: 0.9882
Training Epoch: 24 [28672/50176]	Loss: 0.9254
Training Epoch: 24 [29696/50176]	Loss: 0.8624
Training Epoch: 24 [30720/50176]	Loss: 0.9733
Training Epoch: 24 [31744/50176]	Loss: 1.0100
Training Epoch: 24 [32768/50176]	Loss: 1.0036
Training Epoch: 24 [33792/50176]	Loss: 0.9446
Training Epoch: 24 [34816/50176]	Loss: 0.9812
Training Epoch: 24 [35840/50176]	Loss: 1.0108
Training Epoch: 24 [36864/50176]	Loss: 1.0161
Training Epoch: 24 [37888/50176]	Loss: 0.9375
Training Epoch: 24 [38912/50176]	Loss: 1.0156
Training Epoch: 24 [39936/50176]	Loss: 0.8716
Training Epoch: 24 [40960/50176]	Loss: 0.9531
Training Epoch: 24 [41984/50176]	Loss: 1.0295
Training Epoch: 24 [43008/50176]	Loss: 1.0242
Training Epoch: 24 [44032/50176]	Loss: 0.8917
Training Epoch: 24 [45056/50176]	Loss: 1.0059
Training Epoch: 24 [46080/50176]	Loss: 0.9618
Training Epoch: 24 [47104/50176]	Loss: 1.1226
Training Epoch: 24 [48128/50176]	Loss: 1.0939
Training Epoch: 24 [49152/50176]	Loss: 0.9875
Training Epoch: 24 [50176/50176]	Loss: 0.9892
2022-12-09 00:39:33.432 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:39:33,466 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.78 energy=526.68
2022-12-08 19:39:33,466 [ZeusDataLoader(train)] Up to epoch 25: time=1298.61, energy=186998.02, cost=207127.50
2022-12-08 19:39:33,467 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:39:33,467 [ZeusDataLoader(train)] Expected next epoch: time=1345.81, energy=194233.52, cost=214874.90
2022-12-08 19:39:33,468 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0017, Accuracy: 0.5521
2022-12-08 19:39:33,779 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:39:33,780 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:39:33.781 [ZeusMonitor] Monitor started.
2022-12-09 00:39:33.782 [ZeusMonitor] Running indefinitely. 2022-12-09 00:39:33.782 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:39:33.782 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e26+gpu0.power.log
2022-12-08 19:40:17,695 [ZeusDataLoader(train)] train epoch 26 done: time=44.22 energy=6698.36
2022-12-08 19:40:17,699 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.7951
Training Epoch: 25 [2048/50176]	Loss: 0.7926
Training Epoch: 25 [3072/50176]	Loss: 0.8535
Training Epoch: 25 [4096/50176]	Loss: 0.8746
Training Epoch: 25 [5120/50176]	Loss: 0.8460
Training Epoch: 25 [6144/50176]	Loss: 0.8849
Training Epoch: 25 [7168/50176]	Loss: 0.8035
Training Epoch: 25 [8192/50176]	Loss: 0.8605
Training Epoch: 25 [9216/50176]	Loss: 0.9167
Training Epoch: 25 [10240/50176]	Loss: 0.8206
Training Epoch: 25 [11264/50176]	Loss: 0.8709
Training Epoch: 25 [12288/50176]	Loss: 0.7895
Training Epoch: 25 [13312/50176]	Loss: 0.8635
Training Epoch: 25 [14336/50176]	Loss: 0.8765
Training Epoch: 25 [15360/50176]	Loss: 0.9136
Training Epoch: 25 [16384/50176]	Loss: 0.9027
Training Epoch: 25 [17408/50176]	Loss: 0.8754
Training Epoch: 25 [18432/50176]	Loss: 0.8959
Training Epoch: 25 [19456/50176]	Loss: 0.8383
Training Epoch: 25 [20480/50176]	Loss: 0.8915
Training Epoch: 25 [21504/50176]	Loss: 0.8212
Training Epoch: 25 [22528/50176]	Loss: 0.9113
Training Epoch: 25 [23552/50176]	Loss: 0.8270
Training Epoch: 25 [24576/50176]	Loss: 0.8670
Training Epoch: 25 [25600/50176]	Loss: 0.9058
Training Epoch: 25 [26624/50176]	Loss: 0.9167
Training Epoch: 25 [27648/50176]	Loss: 0.9184
Training Epoch: 25 [28672/50176]	Loss: 0.9215
Training Epoch: 25 [29696/50176]	Loss: 0.9041
Training Epoch: 25 [30720/50176]	Loss: 0.9524
Training Epoch: 25 [31744/50176]	Loss: 0.9011
Training Epoch: 25 [32768/50176]	Loss: 0.9408
Training Epoch: 25 [33792/50176]	Loss: 0.8660
Training Epoch: 25 [34816/50176]	Loss: 0.9307
Training Epoch: 25 [35840/50176]	Loss: 0.8797
Training Epoch: 25 [36864/50176]	Loss: 0.9038
Training Epoch: 25 [37888/50176]	Loss: 0.9216
Training Epoch: 25 [38912/50176]	Loss: 0.9339
Training Epoch: 25 [39936/50176]	Loss: 0.9236
Training Epoch: 25 [40960/50176]	Loss: 0.9003
Training Epoch: 25 [41984/50176]	Loss: 0.9143
Training Epoch: 25 [43008/50176]	Loss: 0.9587
Training Epoch: 25 [44032/50176]	Loss: 0.9371
Training Epoch: 25 [45056/50176]	Loss: 1.0013
Training Epoch: 25 [46080/50176]	Loss: 0.9169
Training Epoch: 25 [47104/50176]	Loss: 0.9323
Training Epoch: 25 [48128/50176]	Loss: 0.9295
Training Epoch: 25 [49152/50176]	Loss: 0.9163
Training Epoch: 25 [50176/50176]	Loss: 0.9235
2022-12-09 00:40:21.499 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:40:21,557 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.85 energy=530.05
2022-12-08 19:40:21,557 [ZeusDataLoader(train)] Up to epoch 26: time=1346.68, energy=194226.43, cost=214947.69
2022-12-08 19:40:21,557 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:40:21,557 [ZeusDataLoader(train)] Expected next epoch: time=1393.88, energy=201461.93, cost=222695.08
2022-12-08 19:40:21,558 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0017, Accuracy: 0.5603
2022-12-08 19:40:21,827 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:40:21,828 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:40:21.842 [ZeusMonitor] Monitor started.
2022-12-09 00:40:21.842 [ZeusMonitor] Running indefinitely. 2022-12-09 00:40:21.842 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:40:21.842 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e27+gpu0.power.log
2022-12-08 19:41:05,775 [ZeusDataLoader(train)] train epoch 27 done: time=44.21 energy=6704.69
2022-12-08 19:41:05,778 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.8179
Training Epoch: 26 [2048/50176]	Loss: 0.8197
Training Epoch: 26 [3072/50176]	Loss: 0.8405
Training Epoch: 26 [4096/50176]	Loss: 0.8034
Training Epoch: 26 [5120/50176]	Loss: 0.8212
Training Epoch: 26 [6144/50176]	Loss: 0.7900
Training Epoch: 26 [7168/50176]	Loss: 0.7940
Training Epoch: 26 [8192/50176]	Loss: 0.7999
Training Epoch: 26 [9216/50176]	Loss: 0.7727
Training Epoch: 26 [10240/50176]	Loss: 0.8548
Training Epoch: 26 [11264/50176]	Loss: 0.8124
Training Epoch: 26 [12288/50176]	Loss: 0.8170
Training Epoch: 26 [13312/50176]	Loss: 0.7652
Training Epoch: 26 [14336/50176]	Loss: 0.7729
Training Epoch: 26 [15360/50176]	Loss: 0.7942
Training Epoch: 26 [16384/50176]	Loss: 0.7758
Training Epoch: 26 [17408/50176]	Loss: 0.8305
Training Epoch: 26 [18432/50176]	Loss: 0.8053
Training Epoch: 26 [19456/50176]	Loss: 0.8376
Training Epoch: 26 [20480/50176]	Loss: 0.8258
Training Epoch: 26 [21504/50176]	Loss: 0.8344
Training Epoch: 26 [22528/50176]	Loss: 0.8117
Training Epoch: 26 [23552/50176]	Loss: 0.8170
Training Epoch: 26 [24576/50176]	Loss: 0.8364
Training Epoch: 26 [25600/50176]	Loss: 0.8604
Training Epoch: 26 [26624/50176]	Loss: 0.8409
Training Epoch: 26 [27648/50176]	Loss: 0.8768
Training Epoch: 26 [28672/50176]	Loss: 0.8466
Training Epoch: 26 [29696/50176]	Loss: 0.8437
Training Epoch: 26 [30720/50176]	Loss: 0.9659
Training Epoch: 26 [31744/50176]	Loss: 0.8515
Training Epoch: 26 [32768/50176]	Loss: 0.8379
Training Epoch: 26 [33792/50176]	Loss: 0.9367
Training Epoch: 26 [34816/50176]	Loss: 0.9404
Training Epoch: 26 [35840/50176]	Loss: 0.8872
Training Epoch: 26 [36864/50176]	Loss: 0.8662
Training Epoch: 26 [37888/50176]	Loss: 0.8895
Training Epoch: 26 [38912/50176]	Loss: 0.8688
Training Epoch: 26 [39936/50176]	Loss: 0.9751
Training Epoch: 26 [40960/50176]	Loss: 0.8936
Training Epoch: 26 [41984/50176]	Loss: 0.9350
Training Epoch: 26 [43008/50176]	Loss: 0.9262
Training Epoch: 26 [44032/50176]	Loss: 0.8559
Training Epoch: 26 [45056/50176]	Loss: 0.9043
Training Epoch: 26 [46080/50176]	Loss: 0.9654
Training Epoch: 26 [47104/50176]	Loss: 0.9199
Training Epoch: 26 [48128/50176]	Loss: 0.8993
Training Epoch: 26 [49152/50176]	Loss: 0.8609
Training Epoch: 26 [50176/50176]	Loss: 0.9654
2022-12-09 00:41:09.598 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:41:09,618 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.83 energy=534.63
2022-12-08 19:41:09,618 [ZeusDataLoader(train)] Up to epoch 27: time=1394.72, energy=201465.75, cost=222770.75
2022-12-08 19:41:09,618 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:41:09,618 [ZeusDataLoader(train)] Expected next epoch: time=1441.91, energy=208701.25, cost=230518.15
2022-12-08 19:41:09,619 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0018, Accuracy: 0.5481
2022-12-08 19:41:09,842 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:41:09,843 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:41:09.846 [ZeusMonitor] Monitor started.
2022-12-09 00:41:09.847 [ZeusMonitor] Running indefinitely. 2022-12-09 00:41:09.847 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:41:09.847 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e28+gpu0.power.log
2022-12-08 19:41:53,896 [ZeusDataLoader(train)] train epoch 28 done: time=44.27 energy=6717.01
2022-12-08 19:41:53,899 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7488
Training Epoch: 27 [2048/50176]	Loss: 0.8226
Training Epoch: 27 [3072/50176]	Loss: 0.7265
Training Epoch: 27 [4096/50176]	Loss: 0.8498
Training Epoch: 27 [5120/50176]	Loss: 0.7781
Training Epoch: 27 [6144/50176]	Loss: 0.7561
Training Epoch: 27 [7168/50176]	Loss: 0.7709
Training Epoch: 27 [8192/50176]	Loss: 0.7954
Training Epoch: 27 [9216/50176]	Loss: 0.8048
Training Epoch: 27 [10240/50176]	Loss: 0.7846
Training Epoch: 27 [11264/50176]	Loss: 0.8063
Training Epoch: 27 [12288/50176]	Loss: 0.7630
Training Epoch: 27 [13312/50176]	Loss: 0.7867
Training Epoch: 27 [14336/50176]	Loss: 0.8104
Training Epoch: 27 [15360/50176]	Loss: 0.7829
Training Epoch: 27 [16384/50176]	Loss: 0.8440
Training Epoch: 27 [17408/50176]	Loss: 0.7696
Training Epoch: 27 [18432/50176]	Loss: 0.8366
Training Epoch: 27 [19456/50176]	Loss: 0.7844
Training Epoch: 27 [20480/50176]	Loss: 0.7377
Training Epoch: 27 [21504/50176]	Loss: 0.8507
Training Epoch: 27 [22528/50176]	Loss: 0.7967
Training Epoch: 27 [23552/50176]	Loss: 0.7866
Training Epoch: 27 [24576/50176]	Loss: 0.7835
Training Epoch: 27 [25600/50176]	Loss: 0.7943
Training Epoch: 27 [26624/50176]	Loss: 0.8437
Training Epoch: 27 [27648/50176]	Loss: 0.8263
Training Epoch: 27 [28672/50176]	Loss: 0.8294
Training Epoch: 27 [29696/50176]	Loss: 0.7513
Training Epoch: 27 [30720/50176]	Loss: 0.8185
Training Epoch: 27 [31744/50176]	Loss: 0.8881
Training Epoch: 27 [32768/50176]	Loss: 0.7958
Training Epoch: 27 [33792/50176]	Loss: 0.8423
Training Epoch: 27 [34816/50176]	Loss: 0.8888
Training Epoch: 27 [35840/50176]	Loss: 0.8418
Training Epoch: 27 [36864/50176]	Loss: 0.8002
Training Epoch: 27 [37888/50176]	Loss: 0.8120
Training Epoch: 27 [38912/50176]	Loss: 0.7913
Training Epoch: 27 [39936/50176]	Loss: 0.9008
Training Epoch: 27 [40960/50176]	Loss: 0.8246
Training Epoch: 27 [41984/50176]	Loss: 0.8231
Training Epoch: 27 [43008/50176]	Loss: 0.8033
Training Epoch: 27 [44032/50176]	Loss: 0.8351
Training Epoch: 27 [45056/50176]	Loss: 0.8222
Training Epoch: 27 [46080/50176]	Loss: 0.8901
Training Epoch: 27 [47104/50176]	Loss: 0.9312
Training Epoch: 27 [48128/50176]	Loss: 0.8350
Training Epoch: 27 [49152/50176]	Loss: 0.8509
Training Epoch: 27 [50176/50176]	Loss: 0.8821
2022-12-09 00:41:57.691 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:41:57,733 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.83 energy=529.13
2022-12-08 19:41:57,733 [ZeusDataLoader(train)] Up to epoch 28: time=1442.81, energy=208711.90, cost=230601.94
2022-12-08 19:41:57,734 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:41:57,734 [ZeusDataLoader(train)] Expected next epoch: time=1490.01, energy=215947.40, cost=238349.34
2022-12-08 19:41:57,735 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0017, Accuracy: 0.5735
2022-12-08 19:41:57,994 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:41:57,995 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:41:57.997 [ZeusMonitor] Monitor started.
2022-12-09 00:41:57.997 [ZeusMonitor] Running indefinitely. 2022-12-09 00:41:57.997 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:41:57.997 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e29+gpu0.power.log
2022-12-08 19:42:41,977 [ZeusDataLoader(train)] train epoch 29 done: time=44.23 energy=6707.14
2022-12-08 19:42:41,980 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.6894
Training Epoch: 28 [2048/50176]	Loss: 0.7483
Training Epoch: 28 [3072/50176]	Loss: 0.6907
Training Epoch: 28 [4096/50176]	Loss: 0.8106
Training Epoch: 28 [5120/50176]	Loss: 0.6851
Training Epoch: 28 [6144/50176]	Loss: 0.7213
Training Epoch: 28 [7168/50176]	Loss: 0.7142
Training Epoch: 28 [8192/50176]	Loss: 0.7437
Training Epoch: 28 [9216/50176]	Loss: 0.7478
Training Epoch: 28 [10240/50176]	Loss: 0.7728
Training Epoch: 28 [11264/50176]	Loss: 0.7258
Training Epoch: 28 [12288/50176]	Loss: 0.7483
Training Epoch: 28 [13312/50176]	Loss: 0.6706
Training Epoch: 28 [14336/50176]	Loss: 0.7761
Training Epoch: 28 [15360/50176]	Loss: 0.7225
Training Epoch: 28 [16384/50176]	Loss: 0.7790
Training Epoch: 28 [17408/50176]	Loss: 0.7490
Training Epoch: 28 [18432/50176]	Loss: 0.7312
Training Epoch: 28 [19456/50176]	Loss: 0.7894
Training Epoch: 28 [20480/50176]	Loss: 0.7379
Training Epoch: 28 [21504/50176]	Loss: 0.8169
Training Epoch: 28 [22528/50176]	Loss: 0.7464
Training Epoch: 28 [23552/50176]	Loss: 0.7801
Training Epoch: 28 [24576/50176]	Loss: 0.7331
Training Epoch: 28 [25600/50176]	Loss: 0.7503
Training Epoch: 28 [26624/50176]	Loss: 0.7384
Training Epoch: 28 [27648/50176]	Loss: 0.8409
Training Epoch: 28 [28672/50176]	Loss: 0.7772
Training Epoch: 28 [29696/50176]	Loss: 0.7297
Training Epoch: 28 [30720/50176]	Loss: 0.7775
Training Epoch: 28 [31744/50176]	Loss: 0.7783
Training Epoch: 28 [32768/50176]	Loss: 0.7887
Training Epoch: 28 [33792/50176]	Loss: 0.7769
Training Epoch: 28 [34816/50176]	Loss: 0.7914
Training Epoch: 28 [35840/50176]	Loss: 0.8078
Training Epoch: 28 [36864/50176]	Loss: 0.8258
Training Epoch: 28 [37888/50176]	Loss: 0.7830
Training Epoch: 28 [38912/50176]	Loss: 0.8256
Training Epoch: 28 [39936/50176]	Loss: 0.7993
Training Epoch: 28 [40960/50176]	Loss: 0.8569
Training Epoch: 28 [41984/50176]	Loss: 0.7542
Training Epoch: 28 [43008/50176]	Loss: 0.7748
Training Epoch: 28 [44032/50176]	Loss: 0.8108
Training Epoch: 28 [45056/50176]	Loss: 0.9090
Training Epoch: 28 [46080/50176]	Loss: 0.8079
Training Epoch: 28 [47104/50176]	Loss: 0.8310
Training Epoch: 28 [48128/50176]	Loss: 0.7796
Training Epoch: 28 [49152/50176]	Loss: 0.8444
Training Epoch: 28 [50176/50176]	Loss: 0.8543
2022-12-09 00:42:45.754 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:42:45,782 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.79 energy=529.69
2022-12-08 19:42:45,782 [ZeusDataLoader(train)] Up to epoch 29: time=1490.84, energy=215948.72, cost=238422.71
2022-12-08 19:42:45,783 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:42:45,783 [ZeusDataLoader(train)] Expected next epoch: time=1538.03, energy=223184.22, cost=246170.11
2022-12-08 19:42:45,784 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0017, Accuracy: 0.5668
2022-12-08 19:42:46,039 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:42:46,040 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:42:46.055 [ZeusMonitor] Monitor started.
2022-12-09 00:42:46.055 [ZeusMonitor] Running indefinitely. 2022-12-09 00:42:46.055 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:42:46.055 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e30+gpu0.power.log
2022-12-08 19:43:29,989 [ZeusDataLoader(train)] train epoch 30 done: time=44.20 energy=6692.54
2022-12-08 19:43:29,992 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6938
Training Epoch: 29 [2048/50176]	Loss: 0.7075
Training Epoch: 29 [3072/50176]	Loss: 0.6871
Training Epoch: 29 [4096/50176]	Loss: 0.6995
Training Epoch: 29 [5120/50176]	Loss: 0.7543
Training Epoch: 29 [6144/50176]	Loss: 0.7002
Training Epoch: 29 [7168/50176]	Loss: 0.6928
Training Epoch: 29 [8192/50176]	Loss: 0.6818
Training Epoch: 29 [9216/50176]	Loss: 0.7623
Training Epoch: 29 [10240/50176]	Loss: 0.7076
Training Epoch: 29 [11264/50176]	Loss: 0.7310
Training Epoch: 29 [12288/50176]	Loss: 0.7206
Training Epoch: 29 [13312/50176]	Loss: 0.6378
Training Epoch: 29 [14336/50176]	Loss: 0.7457
Training Epoch: 29 [15360/50176]	Loss: 0.7669
Training Epoch: 29 [16384/50176]	Loss: 0.7046
Training Epoch: 29 [17408/50176]	Loss: 0.7668
Training Epoch: 29 [18432/50176]	Loss: 0.7352
Training Epoch: 29 [19456/50176]	Loss: 0.8195
Training Epoch: 29 [20480/50176]	Loss: 0.6859
Training Epoch: 29 [21504/50176]	Loss: 0.7167
Training Epoch: 29 [22528/50176]	Loss: 0.7082
Training Epoch: 29 [23552/50176]	Loss: 0.7536
Training Epoch: 29 [24576/50176]	Loss: 0.7276
Training Epoch: 29 [25600/50176]	Loss: 0.8005
Training Epoch: 29 [26624/50176]	Loss: 0.7074
Training Epoch: 29 [27648/50176]	Loss: 0.7559
Training Epoch: 29 [28672/50176]	Loss: 0.6502
Training Epoch: 29 [29696/50176]	Loss: 0.6985
Training Epoch: 29 [30720/50176]	Loss: 0.7939
Training Epoch: 29 [31744/50176]	Loss: 0.7260
Training Epoch: 29 [32768/50176]	Loss: 0.7632
Training Epoch: 29 [33792/50176]	Loss: 0.7838
Training Epoch: 29 [34816/50176]	Loss: 0.7666
Training Epoch: 29 [35840/50176]	Loss: 0.6691
Training Epoch: 29 [36864/50176]	Loss: 0.7454
Training Epoch: 29 [37888/50176]	Loss: 0.7488
Training Epoch: 29 [38912/50176]	Loss: 0.8176
Training Epoch: 29 [39936/50176]	Loss: 0.7988
Training Epoch: 29 [40960/50176]	Loss: 0.8046
Training Epoch: 29 [41984/50176]	Loss: 0.7229
Training Epoch: 29 [43008/50176]	Loss: 0.8263
Training Epoch: 29 [44032/50176]	Loss: 0.7668
Training Epoch: 29 [45056/50176]	Loss: 0.8135
Training Epoch: 29 [46080/50176]	Loss: 0.7920
Training Epoch: 29 [47104/50176]	Loss: 0.8248
Training Epoch: 29 [48128/50176]	Loss: 0.8521
Training Epoch: 29 [49152/50176]	Loss: 0.7745
Training Epoch: 29 [50176/50176]	Loss: 0.8313
2022-12-09 00:43:33.771 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:43:33,789 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.79 energy=513.51
2022-12-08 19:43:33,789 [ZeusDataLoader(train)] Up to epoch 30: time=1538.82, energy=223154.77, cost=246224.33
2022-12-08 19:43:33,789 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:43:33,789 [ZeusDataLoader(train)] Expected next epoch: time=1586.02, energy=230390.27, cost=253971.72
2022-12-08 19:43:33,790 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0018, Accuracy: 0.5584
2022-12-08 19:43:34,006 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:43:34,007 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:43:34.009 [ZeusMonitor] Monitor started.
2022-12-09 00:43:34.009 [ZeusMonitor] Running indefinitely. 2022-12-09 00:43:34.009 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:43:34.009 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e31+gpu0.power.log
2022-12-08 19:44:18,010 [ZeusDataLoader(train)] train epoch 31 done: time=44.21 energy=6710.89
2022-12-08 19:44:18,014 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7048
Training Epoch: 30 [2048/50176]	Loss: 0.6550
Training Epoch: 30 [3072/50176]	Loss: 0.6381
Training Epoch: 30 [4096/50176]	Loss: 0.6612
Training Epoch: 30 [5120/50176]	Loss: 0.6454
Training Epoch: 30 [6144/50176]	Loss: 0.6809
Training Epoch: 30 [7168/50176]	Loss: 0.6567
Training Epoch: 30 [8192/50176]	Loss: 0.6576
Training Epoch: 30 [9216/50176]	Loss: 0.6885
Training Epoch: 30 [10240/50176]	Loss: 0.6444
Training Epoch: 30 [11264/50176]	Loss: 0.7165
Training Epoch: 30 [12288/50176]	Loss: 0.6812
Training Epoch: 30 [13312/50176]	Loss: 0.7101
Training Epoch: 30 [14336/50176]	Loss: 0.6719
Training Epoch: 30 [15360/50176]	Loss: 0.7056
Training Epoch: 30 [16384/50176]	Loss: 0.7032
Training Epoch: 30 [17408/50176]	Loss: 0.6761
Training Epoch: 30 [18432/50176]	Loss: 0.6481
Training Epoch: 30 [19456/50176]	Loss: 0.6172
Training Epoch: 30 [20480/50176]	Loss: 0.7140
Training Epoch: 30 [21504/50176]	Loss: 0.6419
Training Epoch: 30 [22528/50176]	Loss: 0.6886
Training Epoch: 30 [23552/50176]	Loss: 0.6369
Training Epoch: 30 [24576/50176]	Loss: 0.7006
Training Epoch: 30 [25600/50176]	Loss: 0.7264
Training Epoch: 30 [26624/50176]	Loss: 0.6528
Training Epoch: 30 [27648/50176]	Loss: 0.7072
Training Epoch: 30 [28672/50176]	Loss: 0.7317
Training Epoch: 30 [29696/50176]	Loss: 0.7295
Training Epoch: 30 [30720/50176]	Loss: 0.7003
Training Epoch: 30 [31744/50176]	Loss: 0.6330
Training Epoch: 30 [32768/50176]	Loss: 0.6643
Training Epoch: 30 [33792/50176]	Loss: 0.7405
Training Epoch: 30 [34816/50176]	Loss: 0.7602
Training Epoch: 30 [35840/50176]	Loss: 0.7415
Training Epoch: 30 [36864/50176]	Loss: 0.7184
Training Epoch: 30 [37888/50176]	Loss: 0.6927
Training Epoch: 30 [38912/50176]	Loss: 0.7532
Training Epoch: 30 [39936/50176]	Loss: 0.7056
Training Epoch: 30 [40960/50176]	Loss: 0.7181
Training Epoch: 30 [41984/50176]	Loss: 0.7415
Training Epoch: 30 [43008/50176]	Loss: 0.7648
Training Epoch: 30 [44032/50176]	Loss: 0.7233
Training Epoch: 30 [45056/50176]	Loss: 0.7264
Training Epoch: 30 [46080/50176]	Loss: 0.7674
Training Epoch: 30 [47104/50176]	Loss: 0.6915
Training Epoch: 30 [48128/50176]	Loss: 0.6911
Training Epoch: 30 [49152/50176]	Loss: 0.7728
Training Epoch: 30 [50176/50176]	Loss: 0.8081
2022-12-09 00:44:21.808 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:44:21,857 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.83 energy=532.67
2022-12-08 19:44:21,858 [ZeusDataLoader(train)] Up to epoch 31: time=1586.87, energy=230398.34, cost=254050.13
2022-12-08 19:44:21,858 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:44:21,858 [ZeusDataLoader(train)] Expected next epoch: time=1634.06, energy=237633.84, cost=261797.53
2022-12-08 19:44:21,859 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0020, Accuracy: 0.5440
2022-12-08 19:44:22,176 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:44:22,177 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:44:22.179 [ZeusMonitor] Monitor started.
2022-12-09 00:44:22.179 [ZeusMonitor] Running indefinitely. 2022-12-09 00:44:22.179 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:44:22.179 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e32+gpu0.power.log
2022-12-08 19:45:06,120 [ZeusDataLoader(train)] train epoch 32 done: time=44.25 energy=6713.45
2022-12-08 19:45:06,123 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.6153
Training Epoch: 31 [2048/50176]	Loss: 0.5646
Training Epoch: 31 [3072/50176]	Loss: 0.6451
Training Epoch: 31 [4096/50176]	Loss: 0.5958
Training Epoch: 31 [5120/50176]	Loss: 0.6151
Training Epoch: 31 [6144/50176]	Loss: 0.6500
Training Epoch: 31 [7168/50176]	Loss: 0.5840
Training Epoch: 31 [8192/50176]	Loss: 0.6408
Training Epoch: 31 [9216/50176]	Loss: 0.6265
Training Epoch: 31 [10240/50176]	Loss: 0.6608
Training Epoch: 31 [11264/50176]	Loss: 0.6422
Training Epoch: 31 [12288/50176]	Loss: 0.6092
Training Epoch: 31 [13312/50176]	Loss: 0.7266
Training Epoch: 31 [14336/50176]	Loss: 0.6006
Training Epoch: 31 [15360/50176]	Loss: 0.6279
Training Epoch: 31 [16384/50176]	Loss: 0.6100
Training Epoch: 31 [17408/50176]	Loss: 0.6825
Training Epoch: 31 [18432/50176]	Loss: 0.7110
Training Epoch: 31 [19456/50176]	Loss: 0.6614
Training Epoch: 31 [20480/50176]	Loss: 0.6217
Training Epoch: 31 [21504/50176]	Loss: 0.6713
Training Epoch: 31 [22528/50176]	Loss: 0.6515
Training Epoch: 31 [23552/50176]	Loss: 0.7147
Training Epoch: 31 [24576/50176]	Loss: 0.6184
Training Epoch: 31 [25600/50176]	Loss: 0.6487
Training Epoch: 31 [26624/50176]	Loss: 0.6668
Training Epoch: 31 [27648/50176]	Loss: 0.6602
Training Epoch: 31 [28672/50176]	Loss: 0.6420
Training Epoch: 31 [29696/50176]	Loss: 0.6895
Training Epoch: 31 [30720/50176]	Loss: 0.6675
Training Epoch: 31 [31744/50176]	Loss: 0.7001
Training Epoch: 31 [32768/50176]	Loss: 0.6723
Training Epoch: 31 [33792/50176]	Loss: 0.6419
Training Epoch: 31 [34816/50176]	Loss: 0.7114
Training Epoch: 31 [35840/50176]	Loss: 0.6981
Training Epoch: 31 [36864/50176]	Loss: 0.7027
Training Epoch: 31 [37888/50176]	Loss: 0.6360
Training Epoch: 31 [38912/50176]	Loss: 0.6870
Training Epoch: 31 [39936/50176]	Loss: 0.7438
Training Epoch: 31 [40960/50176]	Loss: 0.6750
Training Epoch: 31 [41984/50176]	Loss: 0.6828
Training Epoch: 31 [43008/50176]	Loss: 0.6101
Training Epoch: 31 [44032/50176]	Loss: 0.6649
Training Epoch: 31 [45056/50176]	Loss: 0.7592
Training Epoch: 31 [46080/50176]	Loss: 0.7142
Training Epoch: 31 [47104/50176]	Loss: 0.6477
Training Epoch: 31 [48128/50176]	Loss: 0.7343
Training Epoch: 31 [49152/50176]	Loss: 0.6996
Training Epoch: 31 [50176/50176]	Loss: 0.7154
2022-12-09 00:45:09.890 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:45:09,901 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.77 energy=516.88
2022-12-08 19:45:09,901 [ZeusDataLoader(train)] Up to epoch 32: time=1634.89, energy=237628.67, cost=261867.09
2022-12-08 19:45:09,901 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:45:09,901 [ZeusDataLoader(train)] Expected next epoch: time=1682.08, energy=244864.17, cost=269614.48
2022-12-08 19:45:09,902 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0020, Accuracy: 0.5389
2022-12-08 19:45:10,117 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:45:10,118 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:45:10.121 [ZeusMonitor] Monitor started.
2022-12-09 00:45:10.122 [ZeusMonitor] Running indefinitely. 2022-12-09 00:45:10.122 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:45:10.122 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e33+gpu0.power.log
2022-12-08 19:45:54,158 [ZeusDataLoader(train)] train epoch 33 done: time=44.25 energy=6721.08
2022-12-08 19:45:54,161 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.5865
Training Epoch: 32 [2048/50176]	Loss: 0.5533
Training Epoch: 32 [3072/50176]	Loss: 0.6265
Training Epoch: 32 [4096/50176]	Loss: 0.5752
Training Epoch: 32 [5120/50176]	Loss: 0.6258
Training Epoch: 32 [6144/50176]	Loss: 0.5910
Training Epoch: 32 [7168/50176]	Loss: 0.5763
Training Epoch: 32 [8192/50176]	Loss: 0.6145
Training Epoch: 32 [9216/50176]	Loss: 0.5922
Training Epoch: 32 [10240/50176]	Loss: 0.5724
Training Epoch: 32 [11264/50176]	Loss: 0.6125
Training Epoch: 32 [12288/50176]	Loss: 0.6261
Training Epoch: 32 [13312/50176]	Loss: 0.6612
Training Epoch: 32 [14336/50176]	Loss: 0.6411
Training Epoch: 32 [15360/50176]	Loss: 0.5629
Training Epoch: 32 [16384/50176]	Loss: 0.5689
Training Epoch: 32 [17408/50176]	Loss: 0.6122
Training Epoch: 32 [18432/50176]	Loss: 0.5790
Training Epoch: 32 [19456/50176]	Loss: 0.5835
Training Epoch: 32 [20480/50176]	Loss: 0.6243
Training Epoch: 32 [21504/50176]	Loss: 0.6457
Training Epoch: 32 [22528/50176]	Loss: 0.6623
Training Epoch: 32 [23552/50176]	Loss: 0.6235
Training Epoch: 32 [24576/50176]	Loss: 0.5691
Training Epoch: 32 [25600/50176]	Loss: 0.6864
Training Epoch: 32 [26624/50176]	Loss: 0.5839
Training Epoch: 32 [27648/50176]	Loss: 0.5360
Training Epoch: 32 [28672/50176]	Loss: 0.6188
Training Epoch: 32 [29696/50176]	Loss: 0.6541
Training Epoch: 32 [30720/50176]	Loss: 0.5852
Training Epoch: 32 [31744/50176]	Loss: 0.6317
Training Epoch: 32 [32768/50176]	Loss: 0.6032
Training Epoch: 32 [33792/50176]	Loss: 0.6370
Training Epoch: 32 [34816/50176]	Loss: 0.6993
Training Epoch: 32 [35840/50176]	Loss: 0.6117
Training Epoch: 32 [36864/50176]	Loss: 0.6685
Training Epoch: 32 [37888/50176]	Loss: 0.5810
Training Epoch: 32 [38912/50176]	Loss: 0.6376
Training Epoch: 32 [39936/50176]	Loss: 0.6270
Training Epoch: 32 [40960/50176]	Loss: 0.6093
Training Epoch: 32 [41984/50176]	Loss: 0.6106
Training Epoch: 32 [43008/50176]	Loss: 0.6820
Training Epoch: 32 [44032/50176]	Loss: 0.6830
Training Epoch: 32 [45056/50176]	Loss: 0.6803
Training Epoch: 32 [46080/50176]	Loss: 0.7056
Training Epoch: 32 [47104/50176]	Loss: 0.6571
Training Epoch: 32 [48128/50176]	Loss: 0.6936
Training Epoch: 32 [49152/50176]	Loss: 0.7022
Training Epoch: 32 [50176/50176]	Loss: 0.6696
2022-12-09 00:45:57.913 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:45:57,927 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=513.37
2022-12-08 19:45:57,928 [ZeusDataLoader(train)] Up to epoch 33: time=1682.89, energy=244863.12, cost=269684.69
2022-12-08 19:45:57,928 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:45:57,928 [ZeusDataLoader(train)] Expected next epoch: time=1730.09, energy=252098.62, cost=277432.08
2022-12-08 19:45:57,929 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0017, Accuracy: 0.5868
2022-12-08 19:45:58,203 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:45:58,204 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:45:58.206 [ZeusMonitor] Monitor started.
2022-12-09 00:45:58.206 [ZeusMonitor] Running indefinitely. 2022-12-09 00:45:58.206 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:45:58.206 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e34+gpu0.power.log
2022-12-08 19:46:42,165 [ZeusDataLoader(train)] train epoch 34 done: time=44.23 energy=6720.25
2022-12-08 19:46:42,168 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.5408
Training Epoch: 33 [2048/50176]	Loss: 0.4887
Training Epoch: 33 [3072/50176]	Loss: 0.5818
Training Epoch: 33 [4096/50176]	Loss: 0.5300
Training Epoch: 33 [5120/50176]	Loss: 0.5740
Training Epoch: 33 [6144/50176]	Loss: 0.5034
Training Epoch: 33 [7168/50176]	Loss: 0.5550
Training Epoch: 33 [8192/50176]	Loss: 0.5385
Training Epoch: 33 [9216/50176]	Loss: 0.5573
Training Epoch: 33 [10240/50176]	Loss: 0.5478
Training Epoch: 33 [11264/50176]	Loss: 0.6252
Training Epoch: 33 [12288/50176]	Loss: 0.5778
Training Epoch: 33 [13312/50176]	Loss: 0.5750
Training Epoch: 33 [14336/50176]	Loss: 0.5475
Training Epoch: 33 [15360/50176]	Loss: 0.5866
Training Epoch: 33 [16384/50176]	Loss: 0.6065
Training Epoch: 33 [17408/50176]	Loss: 0.5770
Training Epoch: 33 [18432/50176]	Loss: 0.5795
Training Epoch: 33 [19456/50176]	Loss: 0.5835
Training Epoch: 33 [20480/50176]	Loss: 0.5942
Training Epoch: 33 [21504/50176]	Loss: 0.6488
Training Epoch: 33 [22528/50176]	Loss: 0.5723
Training Epoch: 33 [23552/50176]	Loss: 0.6242
Training Epoch: 33 [24576/50176]	Loss: 0.5937
Training Epoch: 33 [25600/50176]	Loss: 0.6190
Training Epoch: 33 [26624/50176]	Loss: 0.5311
Training Epoch: 33 [27648/50176]	Loss: 0.5596
Training Epoch: 33 [28672/50176]	Loss: 0.6081
Training Epoch: 33 [29696/50176]	Loss: 0.6365
Training Epoch: 33 [30720/50176]	Loss: 0.6352
Training Epoch: 33 [31744/50176]	Loss: 0.6161
Training Epoch: 33 [32768/50176]	Loss: 0.6098
Training Epoch: 33 [33792/50176]	Loss: 0.6582
Training Epoch: 33 [34816/50176]	Loss: 0.6036
Training Epoch: 33 [35840/50176]	Loss: 0.5564
Training Epoch: 33 [36864/50176]	Loss: 0.5793
Training Epoch: 33 [37888/50176]	Loss: 0.6418
Training Epoch: 33 [38912/50176]	Loss: 0.6553
Training Epoch: 33 [39936/50176]	Loss: 0.6196
Training Epoch: 33 [40960/50176]	Loss: 0.6135
Training Epoch: 33 [41984/50176]	Loss: 0.6760
Training Epoch: 33 [43008/50176]	Loss: 0.6109
Training Epoch: 33 [44032/50176]	Loss: 0.6136
Training Epoch: 33 [45056/50176]	Loss: 0.6604
Training Epoch: 33 [46080/50176]	Loss: 0.6040
Training Epoch: 33 [47104/50176]	Loss: 0.6533
Training Epoch: 33 [48128/50176]	Loss: 0.6518
Training Epoch: 33 [49152/50176]	Loss: 0.6131
Training Epoch: 33 [50176/50176]	Loss: 0.6753
2022-12-09 00:46:45.908 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:46:45,917 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.74 energy=515.15
2022-12-08 19:46:45,918 [ZeusDataLoader(train)] Up to epoch 34: time=1730.86, energy=252098.53, cost=277499.51
2022-12-08 19:46:45,918 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:46:45,918 [ZeusDataLoader(train)] Expected next epoch: time=1778.06, energy=259334.03, cost=285246.91
2022-12-08 19:46:45,919 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0020, Accuracy: 0.5516
2022-12-08 19:46:46,199 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:46:46,200 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:46:46.214 [ZeusMonitor] Monitor started.
2022-12-09 00:46:46.214 [ZeusMonitor] Running indefinitely. 2022-12-09 00:46:46.214 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:46:46.214 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e35+gpu0.power.log
2022-12-08 19:47:30,124 [ZeusDataLoader(train)] train epoch 35 done: time=44.20 energy=6713.97
2022-12-08 19:47:30,127 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.5399
Training Epoch: 34 [2048/50176]	Loss: 0.5552
Training Epoch: 34 [3072/50176]	Loss: 0.5315
Training Epoch: 34 [4096/50176]	Loss: 0.4841
Training Epoch: 34 [5120/50176]	Loss: 0.5316
Training Epoch: 34 [6144/50176]	Loss: 0.5448
Training Epoch: 34 [7168/50176]	Loss: 0.4915
Training Epoch: 34 [8192/50176]	Loss: 0.5814
Training Epoch: 34 [9216/50176]	Loss: 0.5081
Training Epoch: 34 [10240/50176]	Loss: 0.5492
Training Epoch: 34 [11264/50176]	Loss: 0.5142
Training Epoch: 34 [12288/50176]	Loss: 0.5500
Training Epoch: 34 [13312/50176]	Loss: 0.5981
Training Epoch: 34 [14336/50176]	Loss: 0.5301
Training Epoch: 34 [15360/50176]	Loss: 0.5535
Training Epoch: 34 [16384/50176]	Loss: 0.6159
Training Epoch: 34 [17408/50176]	Loss: 0.5619
Training Epoch: 34 [18432/50176]	Loss: 0.5296
Training Epoch: 34 [19456/50176]	Loss: 0.4886
Training Epoch: 34 [20480/50176]	Loss: 0.5984
Training Epoch: 34 [21504/50176]	Loss: 0.5400
Training Epoch: 34 [22528/50176]	Loss: 0.5595
Training Epoch: 34 [23552/50176]	Loss: 0.5649
Training Epoch: 34 [24576/50176]	Loss: 0.5205
Training Epoch: 34 [25600/50176]	Loss: 0.5522
Training Epoch: 34 [26624/50176]	Loss: 0.6303
Training Epoch: 34 [27648/50176]	Loss: 0.5716
Training Epoch: 34 [28672/50176]	Loss: 0.5839
Training Epoch: 34 [29696/50176]	Loss: 0.5962
Training Epoch: 34 [30720/50176]	Loss: 0.6172
Training Epoch: 34 [31744/50176]	Loss: 0.6166
Training Epoch: 34 [32768/50176]	Loss: 0.6497
Training Epoch: 34 [33792/50176]	Loss: 0.6012
Training Epoch: 34 [34816/50176]	Loss: 0.5907
Training Epoch: 34 [35840/50176]	Loss: 0.5595
Training Epoch: 34 [36864/50176]	Loss: 0.5769
Training Epoch: 34 [37888/50176]	Loss: 0.5821
Training Epoch: 34 [38912/50176]	Loss: 0.5452
Training Epoch: 34 [39936/50176]	Loss: 0.6505
Training Epoch: 34 [40960/50176]	Loss: 0.6198
Training Epoch: 34 [41984/50176]	Loss: 0.5801
Training Epoch: 34 [43008/50176]	Loss: 0.5953
Training Epoch: 34 [44032/50176]	Loss: 0.5854
Training Epoch: 34 [45056/50176]	Loss: 0.6147
Training Epoch: 34 [46080/50176]	Loss: 0.5959
Training Epoch: 34 [47104/50176]	Loss: 0.6416
Training Epoch: 34 [48128/50176]	Loss: 0.6295
Training Epoch: 34 [49152/50176]	Loss: 0.6174
Training Epoch: 34 [50176/50176]	Loss: 0.5954
2022-12-09 00:47:33.883 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:47:33,906 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.77 energy=511.35
2022-12-08 19:47:33,907 [ZeusDataLoader(train)] Up to epoch 35: time=1778.83, energy=259323.85, cost=285309.27
2022-12-08 19:47:33,907 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:47:33,907 [ZeusDataLoader(train)] Expected next epoch: time=1826.02, energy=266559.35, cost=293056.66
2022-12-08 19:47:33,908 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0023, Accuracy: 0.5387
2022-12-08 19:47:34,166 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:47:34,167 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:47:34.169 [ZeusMonitor] Monitor started.
2022-12-09 00:47:34.169 [ZeusMonitor] Running indefinitely. 2022-12-09 00:47:34.169 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:47:34.169 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e36+gpu0.power.log
2022-12-08 19:48:18,087 [ZeusDataLoader(train)] train epoch 36 done: time=44.17 energy=6712.86
2022-12-08 19:48:18,091 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.5169
Training Epoch: 35 [2048/50176]	Loss: 0.5596
Training Epoch: 35 [3072/50176]	Loss: 0.5125
Training Epoch: 35 [4096/50176]	Loss: 0.4660
Training Epoch: 35 [5120/50176]	Loss: 0.5620
Training Epoch: 35 [6144/50176]	Loss: 0.5015
Training Epoch: 35 [7168/50176]	Loss: 0.5184
Training Epoch: 35 [8192/50176]	Loss: 0.4914
Training Epoch: 35 [9216/50176]	Loss: 0.4792
Training Epoch: 35 [10240/50176]	Loss: 0.4754
Training Epoch: 35 [11264/50176]	Loss: 0.5291
Training Epoch: 35 [12288/50176]	Loss: 0.5959
Training Epoch: 35 [13312/50176]	Loss: 0.5117
Training Epoch: 35 [14336/50176]	Loss: 0.4865
Training Epoch: 35 [15360/50176]	Loss: 0.5511
Training Epoch: 35 [16384/50176]	Loss: 0.5627
Training Epoch: 35 [17408/50176]	Loss: 0.5472
Training Epoch: 35 [18432/50176]	Loss: 0.5057
Training Epoch: 35 [19456/50176]	Loss: 0.5674
Training Epoch: 35 [20480/50176]	Loss: 0.4552
Training Epoch: 35 [21504/50176]	Loss: 0.5185
Training Epoch: 35 [22528/50176]	Loss: 0.5589
Training Epoch: 35 [23552/50176]	Loss: 0.5509
Training Epoch: 35 [24576/50176]	Loss: 0.5829
Training Epoch: 35 [25600/50176]	Loss: 0.5021
Training Epoch: 35 [26624/50176]	Loss: 0.5041
Training Epoch: 35 [27648/50176]	Loss: 0.4955
Training Epoch: 35 [28672/50176]	Loss: 0.5714
Training Epoch: 35 [29696/50176]	Loss: 0.5183
Training Epoch: 35 [30720/50176]	Loss: 0.5914
Training Epoch: 35 [31744/50176]	Loss: 0.5229
Training Epoch: 35 [32768/50176]	Loss: 0.5525
Training Epoch: 35 [33792/50176]	Loss: 0.4857
Training Epoch: 35 [34816/50176]	Loss: 0.5512
Training Epoch: 35 [35840/50176]	Loss: 0.5435
Training Epoch: 35 [36864/50176]	Loss: 0.6343
Training Epoch: 35 [37888/50176]	Loss: 0.5641
Training Epoch: 35 [38912/50176]	Loss: 0.5577
Training Epoch: 35 [39936/50176]	Loss: 0.6630
Training Epoch: 35 [40960/50176]	Loss: 0.5114
Training Epoch: 35 [41984/50176]	Loss: 0.5950
Training Epoch: 35 [43008/50176]	Loss: 0.5444
Training Epoch: 35 [44032/50176]	Loss: 0.5994
Training Epoch: 35 [45056/50176]	Loss: 0.5826
Training Epoch: 35 [46080/50176]	Loss: 0.5798
Training Epoch: 35 [47104/50176]	Loss: 0.5428
Training Epoch: 35 [48128/50176]	Loss: 0.5863
Training Epoch: 35 [49152/50176]	Loss: 0.5817
Training Epoch: 35 [50176/50176]	Loss: 0.6044
2022-12-09 00:48:21.921 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:48:21,954 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.85 energy=526.54
2022-12-08 19:48:21,955 [ZeusDataLoader(train)] Up to epoch 36: time=1826.85, energy=266563.25, cost=293131.17
2022-12-08 19:48:21,955 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:48:21,955 [ZeusDataLoader(train)] Expected next epoch: time=1874.05, energy=273798.75, cost=300878.57
2022-12-08 19:48:21,956 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0021, Accuracy: 0.5566
2022-12-08 19:48:22,231 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:48:22,232 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:48:22.247 [ZeusMonitor] Monitor started.
2022-12-09 00:48:22.247 [ZeusMonitor] Running indefinitely. 2022-12-09 00:48:22.247 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:48:22.247 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e37+gpu0.power.log
2022-12-08 19:49:06,160 [ZeusDataLoader(train)] train epoch 37 done: time=44.20 energy=6715.04
2022-12-08 19:49:06,164 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.4548
Training Epoch: 36 [2048/50176]	Loss: 0.4586
Training Epoch: 36 [3072/50176]	Loss: 0.4566
Training Epoch: 36 [4096/50176]	Loss: 0.4743
Training Epoch: 36 [5120/50176]	Loss: 0.4969
Training Epoch: 36 [6144/50176]	Loss: 0.3980
Training Epoch: 36 [7168/50176]	Loss: 0.4870
Training Epoch: 36 [8192/50176]	Loss: 0.5038
Training Epoch: 36 [9216/50176]	Loss: 0.4696
Training Epoch: 36 [10240/50176]	Loss: 0.5320
Training Epoch: 36 [11264/50176]	Loss: 0.4567
Training Epoch: 36 [12288/50176]	Loss: 0.4751
Training Epoch: 36 [13312/50176]	Loss: 0.5088
Training Epoch: 36 [14336/50176]	Loss: 0.4629
Training Epoch: 36 [15360/50176]	Loss: 0.4924
Training Epoch: 36 [16384/50176]	Loss: 0.4813
Training Epoch: 36 [17408/50176]	Loss: 0.5259
Training Epoch: 36 [18432/50176]	Loss: 0.5406
Training Epoch: 36 [19456/50176]	Loss: 0.5006
Training Epoch: 36 [20480/50176]	Loss: 0.5108
Training Epoch: 36 [21504/50176]	Loss: 0.4768
Training Epoch: 36 [22528/50176]	Loss: 0.4961
Training Epoch: 36 [23552/50176]	Loss: 0.4496
Training Epoch: 36 [24576/50176]	Loss: 0.5338
Training Epoch: 36 [25600/50176]	Loss: 0.5568
Training Epoch: 36 [26624/50176]	Loss: 0.5801
Training Epoch: 36 [27648/50176]	Loss: 0.4749
Training Epoch: 36 [28672/50176]	Loss: 0.5112
Training Epoch: 36 [29696/50176]	Loss: 0.5614
Training Epoch: 36 [30720/50176]	Loss: 0.4985
Training Epoch: 36 [31744/50176]	Loss: 0.5109
Training Epoch: 36 [32768/50176]	Loss: 0.4941
Training Epoch: 36 [33792/50176]	Loss: 0.5315
Training Epoch: 36 [34816/50176]	Loss: 0.5039
Training Epoch: 36 [35840/50176]	Loss: 0.4665
Training Epoch: 36 [36864/50176]	Loss: 0.5189
Training Epoch: 36 [37888/50176]	Loss: 0.5223
Training Epoch: 36 [38912/50176]	Loss: 0.5176
Training Epoch: 36 [39936/50176]	Loss: 0.5597
Training Epoch: 36 [40960/50176]	Loss: 0.5348
Training Epoch: 36 [41984/50176]	Loss: 0.5560
Training Epoch: 36 [43008/50176]	Loss: 0.5635
Training Epoch: 36 [44032/50176]	Loss: 0.5669
Training Epoch: 36 [45056/50176]	Loss: 0.5504
Training Epoch: 36 [46080/50176]	Loss: 0.5281
Training Epoch: 36 [47104/50176]	Loss: 0.5556
Training Epoch: 36 [48128/50176]	Loss: 0.5375
Training Epoch: 36 [49152/50176]	Loss: 0.5182
Training Epoch: 36 [50176/50176]	Loss: 0.4664
2022-12-09 00:49:09.889 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:49:09,899 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.73 energy=520.21
2022-12-08 19:49:09,900 [ZeusDataLoader(train)] Up to epoch 37: time=1874.77, energy=273798.50, cost=300941.93
2022-12-08 19:49:09,900 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:49:09,900 [ZeusDataLoader(train)] Expected next epoch: time=1921.97, energy=281034.00, cost=308689.33
2022-12-08 19:49:09,901 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0019, Accuracy: 0.5741
2022-12-08 19:49:10,164 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:49:10,165 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:49:10.179 [ZeusMonitor] Monitor started.
2022-12-09 00:49:10.179 [ZeusMonitor] Running indefinitely. 2022-12-09 00:49:10.179 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:49:10.179 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e38+gpu0.power.log
2022-12-08 19:49:54,181 [ZeusDataLoader(train)] train epoch 38 done: time=44.27 energy=6721.60
2022-12-08 19:49:54,184 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.4274
Training Epoch: 37 [2048/50176]	Loss: 0.4886
Training Epoch: 37 [3072/50176]	Loss: 0.4086
Training Epoch: 37 [4096/50176]	Loss: 0.5011
Training Epoch: 37 [5120/50176]	Loss: 0.4404
Training Epoch: 37 [6144/50176]	Loss: 0.3998
Training Epoch: 37 [7168/50176]	Loss: 0.4531
Training Epoch: 37 [8192/50176]	Loss: 0.4627
Training Epoch: 37 [9216/50176]	Loss: 0.4402
Training Epoch: 37 [10240/50176]	Loss: 0.4289
Training Epoch: 37 [11264/50176]	Loss: 0.4935
Training Epoch: 37 [12288/50176]	Loss: 0.4417
Training Epoch: 37 [13312/50176]	Loss: 0.3921
Training Epoch: 37 [14336/50176]	Loss: 0.3964
Training Epoch: 37 [15360/50176]	Loss: 0.4555
Training Epoch: 37 [16384/50176]	Loss: 0.4140
Training Epoch: 37 [17408/50176]	Loss: 0.4623
Training Epoch: 37 [18432/50176]	Loss: 0.4537
Training Epoch: 37 [19456/50176]	Loss: 0.4832
Training Epoch: 37 [20480/50176]	Loss: 0.4404
Training Epoch: 37 [21504/50176]	Loss: 0.5054
Training Epoch: 37 [22528/50176]	Loss: 0.4512
Training Epoch: 37 [23552/50176]	Loss: 0.4674
Training Epoch: 37 [24576/50176]	Loss: 0.4566
Training Epoch: 37 [25600/50176]	Loss: 0.4760
Training Epoch: 37 [26624/50176]	Loss: 0.4764
Training Epoch: 37 [27648/50176]	Loss: 0.4851
Training Epoch: 37 [28672/50176]	Loss: 0.5327
Training Epoch: 37 [29696/50176]	Loss: 0.4778
Training Epoch: 37 [30720/50176]	Loss: 0.4441
Training Epoch: 37 [31744/50176]	Loss: 0.4806
Training Epoch: 37 [32768/50176]	Loss: 0.5273
Training Epoch: 37 [33792/50176]	Loss: 0.5170
Training Epoch: 37 [34816/50176]	Loss: 0.5489
Training Epoch: 37 [35840/50176]	Loss: 0.4785
Training Epoch: 37 [36864/50176]	Loss: 0.4599
Training Epoch: 37 [37888/50176]	Loss: 0.5696
Training Epoch: 37 [38912/50176]	Loss: 0.5509
Training Epoch: 37 [39936/50176]	Loss: 0.5145
Training Epoch: 37 [40960/50176]	Loss: 0.5289
Training Epoch: 37 [41984/50176]	Loss: 0.5234
Training Epoch: 37 [43008/50176]	Loss: 0.5726
Training Epoch: 37 [44032/50176]	Loss: 0.5415
Training Epoch: 37 [45056/50176]	Loss: 0.5096
Training Epoch: 37 [46080/50176]	Loss: 0.4690
Training Epoch: 37 [47104/50176]	Loss: 0.5203
Training Epoch: 37 [48128/50176]	Loss: 0.5740
Training Epoch: 37 [49152/50176]	Loss: 0.5157
Training Epoch: 37 [50176/50176]	Loss: 0.5811
2022-12-09 00:49:57.995 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:49:58,007 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.81 energy=524.35
2022-12-08 19:49:58,007 [ZeusDataLoader(train)] Up to epoch 38: time=1922.86, energy=281044.45, cost=308772.35
2022-12-08 19:49:58,007 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:49:58,007 [ZeusDataLoader(train)] Expected next epoch: time=1970.05, energy=288279.95, cost=316519.74
2022-12-08 19:49:58,008 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0020, Accuracy: 0.5616
2022-12-08 19:49:58,295 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:49:58,296 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:49:58.298 [ZeusMonitor] Monitor started.
2022-12-09 00:49:58.298 [ZeusMonitor] Running indefinitely. 2022-12-09 00:49:58.298 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:49:58.298 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e39+gpu0.power.log
2022-12-08 19:50:42,277 [ZeusDataLoader(train)] train epoch 39 done: time=44.26 energy=6719.29
2022-12-08 19:50:42,281 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.4346
Training Epoch: 38 [2048/50176]	Loss: 0.4445
Training Epoch: 38 [3072/50176]	Loss: 0.4388
Training Epoch: 38 [4096/50176]	Loss: 0.4012
Training Epoch: 38 [5120/50176]	Loss: 0.3863
Training Epoch: 38 [6144/50176]	Loss: 0.3788
Training Epoch: 38 [7168/50176]	Loss: 0.4354
Training Epoch: 38 [8192/50176]	Loss: 0.4235
Training Epoch: 38 [9216/50176]	Loss: 0.4447
Training Epoch: 38 [10240/50176]	Loss: 0.4662
Training Epoch: 38 [11264/50176]	Loss: 0.4215
Training Epoch: 38 [12288/50176]	Loss: 0.4200
Training Epoch: 38 [13312/50176]	Loss: 0.4342
Training Epoch: 38 [14336/50176]	Loss: 0.4798
Training Epoch: 38 [15360/50176]	Loss: 0.4815
Training Epoch: 38 [16384/50176]	Loss: 0.4160
Training Epoch: 38 [17408/50176]	Loss: 0.4301
Training Epoch: 38 [18432/50176]	Loss: 0.4336
Training Epoch: 38 [19456/50176]	Loss: 0.4504
Training Epoch: 38 [20480/50176]	Loss: 0.4756
Training Epoch: 38 [21504/50176]	Loss: 0.4416
Training Epoch: 38 [22528/50176]	Loss: 0.4660
Training Epoch: 38 [23552/50176]	Loss: 0.4929
Training Epoch: 38 [24576/50176]	Loss: 0.4420
Training Epoch: 38 [25600/50176]	Loss: 0.4812
Training Epoch: 38 [26624/50176]	Loss: 0.5025
Training Epoch: 38 [27648/50176]	Loss: 0.4184
Training Epoch: 38 [28672/50176]	Loss: 0.5147
Training Epoch: 38 [29696/50176]	Loss: 0.4534
Training Epoch: 38 [30720/50176]	Loss: 0.4211
Training Epoch: 38 [31744/50176]	Loss: 0.4341
Training Epoch: 38 [32768/50176]	Loss: 0.5290
Training Epoch: 38 [33792/50176]	Loss: 0.5182
Training Epoch: 38 [34816/50176]	Loss: 0.4988
Training Epoch: 38 [35840/50176]	Loss: 0.4718
Training Epoch: 38 [36864/50176]	Loss: 0.4968
Training Epoch: 38 [37888/50176]	Loss: 0.4972
Training Epoch: 38 [38912/50176]	Loss: 0.5113
Training Epoch: 38 [39936/50176]	Loss: 0.5027
Training Epoch: 38 [40960/50176]	Loss: 0.5153
Training Epoch: 38 [41984/50176]	Loss: 0.4458
Training Epoch: 38 [43008/50176]	Loss: 0.5156
Training Epoch: 38 [44032/50176]	Loss: 0.5111
Training Epoch: 38 [45056/50176]	Loss: 0.4956
Training Epoch: 38 [46080/50176]	Loss: 0.4709
Training Epoch: 38 [47104/50176]	Loss: 0.5416
Training Epoch: 38 [48128/50176]	Loss: 0.4606
Training Epoch: 38 [49152/50176]	Loss: 0.5459
Training Epoch: 38 [50176/50176]	Loss: 0.5437
2022-12-09 00:50:46.065 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:50:46,088 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.80 energy=518.44
2022-12-08 19:50:46,088 [ZeusDataLoader(train)] Up to epoch 39: time=1970.92, energy=288282.19, cost=316596.33
2022-12-08 19:50:46,088 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:50:46,088 [ZeusDataLoader(train)] Expected next epoch: time=2018.11, energy=295517.69, cost=324343.73
2022-12-08 19:50:46,089 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0020, Accuracy: 0.5617
2022-12-08 19:50:46,353 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:50:46,354 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:50:46.356 [ZeusMonitor] Monitor started.
2022-12-09 00:50:46.356 [ZeusMonitor] Running indefinitely. 2022-12-09 00:50:46.356 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:50:46.356 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e40+gpu0.power.log
2022-12-08 19:51:30,327 [ZeusDataLoader(train)] train epoch 40 done: time=44.23 energy=6713.02
2022-12-08 19:51:30,330 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.4151
Training Epoch: 39 [2048/50176]	Loss: 0.3921
Training Epoch: 39 [3072/50176]	Loss: 0.3946
Training Epoch: 39 [4096/50176]	Loss: 0.4235
Training Epoch: 39 [5120/50176]	Loss: 0.4854
Training Epoch: 39 [6144/50176]	Loss: 0.3915
Training Epoch: 39 [7168/50176]	Loss: 0.4011
Training Epoch: 39 [8192/50176]	Loss: 0.4078
Training Epoch: 39 [9216/50176]	Loss: 0.4203
Training Epoch: 39 [10240/50176]	Loss: 0.4252
Training Epoch: 39 [11264/50176]	Loss: 0.3902
Training Epoch: 39 [12288/50176]	Loss: 0.4098
Training Epoch: 39 [13312/50176]	Loss: 0.4210
Training Epoch: 39 [14336/50176]	Loss: 0.4641
Training Epoch: 39 [15360/50176]	Loss: 0.3939
Training Epoch: 39 [16384/50176]	Loss: 0.4033
Training Epoch: 39 [17408/50176]	Loss: 0.3770
Training Epoch: 39 [18432/50176]	Loss: 0.3898
Training Epoch: 39 [19456/50176]	Loss: 0.4236
Training Epoch: 39 [20480/50176]	Loss: 0.4428
Training Epoch: 39 [21504/50176]	Loss: 0.4693
Training Epoch: 39 [22528/50176]	Loss: 0.4185
Training Epoch: 39 [23552/50176]	Loss: 0.4200
Training Epoch: 39 [24576/50176]	Loss: 0.3529
Training Epoch: 39 [25600/50176]	Loss: 0.4624
Training Epoch: 39 [26624/50176]	Loss: 0.4911
Training Epoch: 39 [27648/50176]	Loss: 0.4127
Training Epoch: 39 [28672/50176]	Loss: 0.3998
Training Epoch: 39 [29696/50176]	Loss: 0.4548
Training Epoch: 39 [30720/50176]	Loss: 0.4355
Training Epoch: 39 [31744/50176]	Loss: 0.4562
Training Epoch: 39 [32768/50176]	Loss: 0.4175
Training Epoch: 39 [33792/50176]	Loss: 0.4429
Training Epoch: 39 [34816/50176]	Loss: 0.4827
Training Epoch: 39 [35840/50176]	Loss: 0.4238
Training Epoch: 39 [36864/50176]	Loss: 0.4456
Training Epoch: 39 [37888/50176]	Loss: 0.3756
Training Epoch: 39 [38912/50176]	Loss: 0.4389
Training Epoch: 39 [39936/50176]	Loss: 0.5226
Training Epoch: 39 [40960/50176]	Loss: 0.4514
Training Epoch: 39 [41984/50176]	Loss: 0.4713
Training Epoch: 39 [43008/50176]	Loss: 0.4238
Training Epoch: 39 [44032/50176]	Loss: 0.5275
Training Epoch: 39 [45056/50176]	Loss: 0.4995
Training Epoch: 39 [46080/50176]	Loss: 0.4248
Training Epoch: 39 [47104/50176]	Loss: 0.4890
Training Epoch: 39 [48128/50176]	Loss: 0.4222
Training Epoch: 39 [49152/50176]	Loss: 0.4723
Training Epoch: 39 [50176/50176]	Loss: 0.5700
2022-12-09 00:51:34.108 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:51:34,124 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.79 energy=526.49
2022-12-08 19:51:34,125 [ZeusDataLoader(train)] Up to epoch 40: time=2018.93, energy=295521.70, cost=324417.28
2022-12-08 19:51:34,125 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:51:34,125 [ZeusDataLoader(train)] Expected next epoch: time=2066.13, energy=302757.20, cost=332164.68
2022-12-08 19:51:34,126 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0025, Accuracy: 0.5276
2022-12-08 19:51:34,402 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:51:34,403 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:51:34.427 [ZeusMonitor] Monitor started.
2022-12-09 00:51:34.427 [ZeusMonitor] Running indefinitely. 2022-12-09 00:51:34.427 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:51:34.427 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e41+gpu0.power.log
2022-12-08 19:52:18,416 [ZeusDataLoader(train)] train epoch 41 done: time=44.28 energy=6709.00
2022-12-08 19:52:18,420 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.3464
Training Epoch: 40 [2048/50176]	Loss: 0.3671
Training Epoch: 40 [3072/50176]	Loss: 0.4084
Training Epoch: 40 [4096/50176]	Loss: 0.3717
Training Epoch: 40 [5120/50176]	Loss: 0.3868
Training Epoch: 40 [6144/50176]	Loss: 0.3806
Training Epoch: 40 [7168/50176]	Loss: 0.3657
Training Epoch: 40 [8192/50176]	Loss: 0.3889
Training Epoch: 40 [9216/50176]	Loss: 0.3813
Training Epoch: 40 [10240/50176]	Loss: 0.3974
Training Epoch: 40 [11264/50176]	Loss: 0.3981
Training Epoch: 40 [12288/50176]	Loss: 0.4159
Training Epoch: 40 [13312/50176]	Loss: 0.3919
Training Epoch: 40 [14336/50176]	Loss: 0.4080
Training Epoch: 40 [15360/50176]	Loss: 0.4162
Training Epoch: 40 [16384/50176]	Loss: 0.3602
Training Epoch: 40 [17408/50176]	Loss: 0.4010
Training Epoch: 40 [18432/50176]	Loss: 0.4467
Training Epoch: 40 [19456/50176]	Loss: 0.4074
Training Epoch: 40 [20480/50176]	Loss: 0.3870
Training Epoch: 40 [21504/50176]	Loss: 0.3564
Training Epoch: 40 [22528/50176]	Loss: 0.3690
Training Epoch: 40 [23552/50176]	Loss: 0.4264
Training Epoch: 40 [24576/50176]	Loss: 0.4359
Training Epoch: 40 [25600/50176]	Loss: 0.3506
Training Epoch: 40 [26624/50176]	Loss: 0.4104
Training Epoch: 40 [27648/50176]	Loss: 0.4450
Training Epoch: 40 [28672/50176]	Loss: 0.4182
Training Epoch: 40 [29696/50176]	Loss: 0.4273
Training Epoch: 40 [30720/50176]	Loss: 0.4082
Training Epoch: 40 [31744/50176]	Loss: 0.3988
Training Epoch: 40 [32768/50176]	Loss: 0.4047
Training Epoch: 40 [33792/50176]	Loss: 0.4483
Training Epoch: 40 [34816/50176]	Loss: 0.4234
Training Epoch: 40 [35840/50176]	Loss: 0.3835
Training Epoch: 40 [36864/50176]	Loss: 0.4024
Training Epoch: 40 [37888/50176]	Loss: 0.3956
Training Epoch: 40 [38912/50176]	Loss: 0.4783
Training Epoch: 40 [39936/50176]	Loss: 0.4983
Training Epoch: 40 [40960/50176]	Loss: 0.4536
Training Epoch: 40 [41984/50176]	Loss: 0.4485
Training Epoch: 40 [43008/50176]	Loss: 0.4639
Training Epoch: 40 [44032/50176]	Loss: 0.4969
Training Epoch: 40 [45056/50176]	Loss: 0.4263
Training Epoch: 40 [46080/50176]	Loss: 0.4510
Training Epoch: 40 [47104/50176]	Loss: 0.4034
Training Epoch: 40 [48128/50176]	Loss: 0.4722
Training Epoch: 40 [49152/50176]	Loss: 0.4764
Training Epoch: 40 [50176/50176]	Loss: 0.4036
2022-12-09 00:52:22.217 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:52:22,244 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.82 energy=535.18
2022-12-08 19:52:22,244 [ZeusDataLoader(train)] Up to epoch 41: time=2067.03, energy=302765.88, cost=332247.83
2022-12-08 19:52:22,244 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:52:22,245 [ZeusDataLoader(train)] Expected next epoch: time=2114.22, energy=310001.38, cost=339995.22
2022-12-08 19:52:22,246 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0020, Accuracy: 0.5718
2022-12-08 19:52:22,474 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:52:22,475 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:52:22.479 [ZeusMonitor] Monitor started.
2022-12-09 00:52:22.479 [ZeusMonitor] Running indefinitely. 2022-12-09 00:52:22.479 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:52:22.479 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e42+gpu0.power.log
2022-12-08 19:53:06,421 [ZeusDataLoader(train)] train epoch 42 done: time=44.17 energy=6715.01
2022-12-08 19:53:06,425 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.3317
Training Epoch: 41 [2048/50176]	Loss: 0.3854
Training Epoch: 41 [3072/50176]	Loss: 0.3871
Training Epoch: 41 [4096/50176]	Loss: 0.3599
Training Epoch: 41 [5120/50176]	Loss: 0.3487
Training Epoch: 41 [6144/50176]	Loss: 0.4118
Training Epoch: 41 [7168/50176]	Loss: 0.4061
Training Epoch: 41 [8192/50176]	Loss: 0.3578
Training Epoch: 41 [9216/50176]	Loss: 0.3433
Training Epoch: 41 [10240/50176]	Loss: 0.3921
Training Epoch: 41 [11264/50176]	Loss: 0.3342
Training Epoch: 41 [12288/50176]	Loss: 0.3683
Training Epoch: 41 [13312/50176]	Loss: 0.3963
Training Epoch: 41 [14336/50176]	Loss: 0.3957
Training Epoch: 41 [15360/50176]	Loss: 0.3655
Training Epoch: 41 [16384/50176]	Loss: 0.3549
Training Epoch: 41 [17408/50176]	Loss: 0.3267
Training Epoch: 41 [18432/50176]	Loss: 0.4017
Training Epoch: 41 [19456/50176]	Loss: 0.4146
Training Epoch: 41 [20480/50176]	Loss: 0.3869
Training Epoch: 41 [21504/50176]	Loss: 0.3962
Training Epoch: 41 [22528/50176]	Loss: 0.3605
Training Epoch: 41 [23552/50176]	Loss: 0.3850
Training Epoch: 41 [24576/50176]	Loss: 0.3909
Training Epoch: 41 [25600/50176]	Loss: 0.3640
Training Epoch: 41 [26624/50176]	Loss: 0.3637
Training Epoch: 41 [27648/50176]	Loss: 0.3573
Training Epoch: 41 [28672/50176]	Loss: 0.4147
Training Epoch: 41 [29696/50176]	Loss: 0.3815
Training Epoch: 41 [30720/50176]	Loss: 0.4062
Training Epoch: 41 [31744/50176]	Loss: 0.3881
Training Epoch: 41 [32768/50176]	Loss: 0.3717
Training Epoch: 41 [33792/50176]	Loss: 0.4310
Training Epoch: 41 [34816/50176]	Loss: 0.3886
Training Epoch: 41 [35840/50176]	Loss: 0.3767
Training Epoch: 41 [36864/50176]	Loss: 0.3648
Training Epoch: 41 [37888/50176]	Loss: 0.4258
Training Epoch: 41 [38912/50176]	Loss: 0.3958
Training Epoch: 41 [39936/50176]	Loss: 0.4182
Training Epoch: 41 [40960/50176]	Loss: 0.4351
Training Epoch: 41 [41984/50176]	Loss: 0.4110
Training Epoch: 41 [43008/50176]	Loss: 0.3611
Training Epoch: 41 [44032/50176]	Loss: 0.4001
Training Epoch: 41 [45056/50176]	Loss: 0.4367
Training Epoch: 41 [46080/50176]	Loss: 0.4030
Training Epoch: 41 [47104/50176]	Loss: 0.4406
Training Epoch: 41 [48128/50176]	Loss: 0.4261
Training Epoch: 41 [49152/50176]	Loss: 0.4486
Training Epoch: 41 [50176/50176]	Loss: 0.4426
2022-12-09 00:53:10.199 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:53:10,211 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.78 energy=529.13
2022-12-08 19:53:10,211 [ZeusDataLoader(train)] Up to epoch 42: time=2114.97, energy=310010.02, cost=340065.04
2022-12-08 19:53:10,211 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:53:10,212 [ZeusDataLoader(train)] Expected next epoch: time=2162.17, energy=317245.52, cost=347812.44
2022-12-08 19:53:10,213 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0020, Accuracy: 0.5901
2022-12-08 19:53:10,503 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:53:10,503 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:53:10.505 [ZeusMonitor] Monitor started.
2022-12-09 00:53:10.506 [ZeusMonitor] Running indefinitely. 2022-12-09 00:53:10.506 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:53:10.506 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e43+gpu0.power.log
2022-12-08 19:53:54,480 [ZeusDataLoader(train)] train epoch 43 done: time=44.26 energy=6715.78
2022-12-08 19:53:54,484 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.3317
Training Epoch: 42 [2048/50176]	Loss: 0.2941
Training Epoch: 42 [3072/50176]	Loss: 0.3527
Training Epoch: 42 [4096/50176]	Loss: 0.3663
Training Epoch: 42 [5120/50176]	Loss: 0.3743
Training Epoch: 42 [6144/50176]	Loss: 0.3349
Training Epoch: 42 [7168/50176]	Loss: 0.3452
Training Epoch: 42 [8192/50176]	Loss: 0.3116
Training Epoch: 42 [9216/50176]	Loss: 0.3301
Training Epoch: 42 [10240/50176]	Loss: 0.3666
Training Epoch: 42 [11264/50176]	Loss: 0.3886
Training Epoch: 42 [12288/50176]	Loss: 0.3487
Training Epoch: 42 [13312/50176]	Loss: 0.3739
Training Epoch: 42 [14336/50176]	Loss: 0.2995
Training Epoch: 42 [15360/50176]	Loss: 0.3619
Training Epoch: 42 [16384/50176]	Loss: 0.3189
Training Epoch: 42 [17408/50176]	Loss: 0.3926
Training Epoch: 42 [18432/50176]	Loss: 0.3782
Training Epoch: 42 [19456/50176]	Loss: 0.3616
Training Epoch: 42 [20480/50176]	Loss: 0.4057
Training Epoch: 42 [21504/50176]	Loss: 0.3358
Training Epoch: 42 [22528/50176]	Loss: 0.3313
Training Epoch: 42 [23552/50176]	Loss: 0.3439
Training Epoch: 42 [24576/50176]	Loss: 0.3522
Training Epoch: 42 [25600/50176]	Loss: 0.4019
Training Epoch: 42 [26624/50176]	Loss: 0.3264
Training Epoch: 42 [27648/50176]	Loss: 0.3611
Training Epoch: 42 [28672/50176]	Loss: 0.3615
Training Epoch: 42 [29696/50176]	Loss: 0.4069
Training Epoch: 42 [30720/50176]	Loss: 0.4082
Training Epoch: 42 [31744/50176]	Loss: 0.3749
Training Epoch: 42 [32768/50176]	Loss: 0.3720
Training Epoch: 42 [33792/50176]	Loss: 0.3720
Training Epoch: 42 [34816/50176]	Loss: 0.3963
Training Epoch: 42 [35840/50176]	Loss: 0.3754
Training Epoch: 42 [36864/50176]	Loss: 0.3898
Training Epoch: 42 [37888/50176]	Loss: 0.4224
Training Epoch: 42 [38912/50176]	Loss: 0.3913
Training Epoch: 42 [39936/50176]	Loss: 0.3621
Training Epoch: 42 [40960/50176]	Loss: 0.3899
Training Epoch: 42 [41984/50176]	Loss: 0.3993
Training Epoch: 42 [43008/50176]	Loss: 0.4256
Training Epoch: 42 [44032/50176]	Loss: 0.4209
Training Epoch: 42 [45056/50176]	Loss: 0.4346
Training Epoch: 42 [46080/50176]	Loss: 0.3889
Training Epoch: 42 [47104/50176]	Loss: 0.4419
Training Epoch: 42 [48128/50176]	Loss: 0.3922
Training Epoch: 42 [49152/50176]	Loss: 0.4479
Training Epoch: 42 [50176/50176]	Loss: 0.4215
2022-12-09 00:53:58.315 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:53:58,340 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.85 energy=535.72
2022-12-08 19:53:58,340 [ZeusDataLoader(train)] Up to epoch 43: time=2163.08, energy=317261.51, cost=347900.09
2022-12-08 19:53:58,341 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:53:58,341 [ZeusDataLoader(train)] Expected next epoch: time=2210.27, energy=324497.01, cost=355647.49
2022-12-08 19:53:58,342 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0023, Accuracy: 0.5619
2022-12-08 19:53:58,609 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:53:58,610 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:53:58.624 [ZeusMonitor] Monitor started.
2022-12-09 00:53:58.624 [ZeusMonitor] Running indefinitely. 2022-12-09 00:53:58.624 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:53:58.625 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e44+gpu0.power.log
2022-12-08 19:54:42,573 [ZeusDataLoader(train)] train epoch 44 done: time=44.22 energy=6703.81
2022-12-08 19:54:42,577 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.2999
Training Epoch: 43 [2048/50176]	Loss: 0.3643
Training Epoch: 43 [3072/50176]	Loss: 0.3238
Training Epoch: 43 [4096/50176]	Loss: 0.3394
Training Epoch: 43 [5120/50176]	Loss: 0.3140
Training Epoch: 43 [6144/50176]	Loss: 0.3008
Training Epoch: 43 [7168/50176]	Loss: 0.3922
Training Epoch: 43 [8192/50176]	Loss: 0.3022
Training Epoch: 43 [9216/50176]	Loss: 0.3734
Training Epoch: 43 [10240/50176]	Loss: 0.3706
Training Epoch: 43 [11264/50176]	Loss: 0.3166
Training Epoch: 43 [12288/50176]	Loss: 0.3417
Training Epoch: 43 [13312/50176]	Loss: 0.3519
Training Epoch: 43 [14336/50176]	Loss: 0.3524
Training Epoch: 43 [15360/50176]	Loss: 0.3021
Training Epoch: 43 [16384/50176]	Loss: 0.3452
Training Epoch: 43 [17408/50176]	Loss: 0.3099
Training Epoch: 43 [18432/50176]	Loss: 0.3073
Training Epoch: 43 [19456/50176]	Loss: 0.3718
Training Epoch: 43 [20480/50176]	Loss: 0.3270
Training Epoch: 43 [21504/50176]	Loss: 0.3640
Training Epoch: 43 [22528/50176]	Loss: 0.3262
Training Epoch: 43 [23552/50176]	Loss: 0.3352
Training Epoch: 43 [24576/50176]	Loss: 0.3698
Training Epoch: 43 [25600/50176]	Loss: 0.3784
Training Epoch: 43 [26624/50176]	Loss: 0.3603
Training Epoch: 43 [27648/50176]	Loss: 0.3559
Training Epoch: 43 [28672/50176]	Loss: 0.3264
Training Epoch: 43 [29696/50176]	Loss: 0.3026
Training Epoch: 43 [30720/50176]	Loss: 0.2808
Training Epoch: 43 [31744/50176]	Loss: 0.3650
Training Epoch: 43 [32768/50176]	Loss: 0.3796
Training Epoch: 43 [33792/50176]	Loss: 0.3026
Training Epoch: 43 [34816/50176]	Loss: 0.3098
Training Epoch: 43 [35840/50176]	Loss: 0.3520
Training Epoch: 43 [36864/50176]	Loss: 0.3458
Training Epoch: 43 [37888/50176]	Loss: 0.3733
Training Epoch: 43 [38912/50176]	Loss: 0.3956
Training Epoch: 43 [39936/50176]	Loss: 0.3678
Training Epoch: 43 [40960/50176]	Loss: 0.3339
Training Epoch: 43 [41984/50176]	Loss: 0.3474
Training Epoch: 43 [43008/50176]	Loss: 0.3221
Training Epoch: 43 [44032/50176]	Loss: 0.3630
Training Epoch: 43 [45056/50176]	Loss: 0.3323
Training Epoch: 43 [46080/50176]	Loss: 0.3646
Training Epoch: 43 [47104/50176]	Loss: 0.3977
Training Epoch: 43 [48128/50176]	Loss: 0.3686
Training Epoch: 43 [49152/50176]	Loss: 0.3705
Training Epoch: 43 [50176/50176]	Loss: 0.3757
2022-12-09 00:54:46.349 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:54:46,382 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.80 energy=534.58
2022-12-08 19:54:46,382 [ZeusDataLoader(train)] Up to epoch 44: time=2211.10, energy=324499.90, cost=355720.83
2022-12-08 19:54:46,382 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:54:46,382 [ZeusDataLoader(train)] Expected next epoch: time=2258.29, energy=331735.40, cost=363468.22
2022-12-08 19:54:46,383 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0021, Accuracy: 0.5876
2022-12-08 19:54:46,656 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:54:46,657 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:54:46.658 [ZeusMonitor] Monitor started.
2022-12-09 00:54:46.658 [ZeusMonitor] Running indefinitely. 2022-12-09 00:54:46.658 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:54:46.659 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e45+gpu0.power.log
2022-12-08 19:55:30,574 [ZeusDataLoader(train)] train epoch 45 done: time=44.18 energy=6719.81
2022-12-08 19:55:30,578 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.2790
Training Epoch: 44 [2048/50176]	Loss: 0.3286
Training Epoch: 44 [3072/50176]	Loss: 0.3046
Training Epoch: 44 [4096/50176]	Loss: 0.2919
Training Epoch: 44 [5120/50176]	Loss: 0.3016
Training Epoch: 44 [6144/50176]	Loss: 0.2903
Training Epoch: 44 [7168/50176]	Loss: 0.3292
Training Epoch: 44 [8192/50176]	Loss: 0.3152
Training Epoch: 44 [9216/50176]	Loss: 0.3110
Training Epoch: 44 [10240/50176]	Loss: 0.2805
Training Epoch: 44 [11264/50176]	Loss: 0.3277
Training Epoch: 44 [12288/50176]	Loss: 0.3110
Training Epoch: 44 [13312/50176]	Loss: 0.3206
Training Epoch: 44 [14336/50176]	Loss: 0.2710
Training Epoch: 44 [15360/50176]	Loss: 0.3278
Training Epoch: 44 [16384/50176]	Loss: 0.3294
Training Epoch: 44 [17408/50176]	Loss: 0.3242
Training Epoch: 44 [18432/50176]	Loss: 0.3205
Training Epoch: 44 [19456/50176]	Loss: 0.3140
Training Epoch: 44 [20480/50176]	Loss: 0.2909
Training Epoch: 44 [21504/50176]	Loss: 0.3453
Training Epoch: 44 [22528/50176]	Loss: 0.3119
Training Epoch: 44 [23552/50176]	Loss: 0.3245
Training Epoch: 44 [24576/50176]	Loss: 0.3419
Training Epoch: 44 [25600/50176]	Loss: 0.3476
Training Epoch: 44 [26624/50176]	Loss: 0.3236
Training Epoch: 44 [27648/50176]	Loss: 0.3191
Training Epoch: 44 [28672/50176]	Loss: 0.2842
Training Epoch: 44 [29696/50176]	Loss: 0.3239
Training Epoch: 44 [30720/50176]	Loss: 0.2954
Training Epoch: 44 [31744/50176]	Loss: 0.3408
Training Epoch: 44 [32768/50176]	Loss: 0.3346
Training Epoch: 44 [33792/50176]	Loss: 0.3300
Training Epoch: 44 [34816/50176]	Loss: 0.3516
Training Epoch: 44 [35840/50176]	Loss: 0.3456
Training Epoch: 44 [36864/50176]	Loss: 0.3398
Training Epoch: 44 [37888/50176]	Loss: 0.3944
Training Epoch: 44 [38912/50176]	Loss: 0.3242
Training Epoch: 44 [39936/50176]	Loss: 0.3598
Training Epoch: 44 [40960/50176]	Loss: 0.3403
Training Epoch: 44 [41984/50176]	Loss: 0.3410
Training Epoch: 44 [43008/50176]	Loss: 0.3294
Training Epoch: 44 [44032/50176]	Loss: 0.3764
Training Epoch: 44 [45056/50176]	Loss: 0.3232
Training Epoch: 44 [46080/50176]	Loss: 0.3493
Training Epoch: 44 [47104/50176]	Loss: 0.3853
Training Epoch: 44 [48128/50176]	Loss: 0.3394
Training Epoch: 44 [49152/50176]	Loss: 0.4019
Training Epoch: 44 [50176/50176]	Loss: 0.3362
2022-12-09 00:55:34.407 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:55:34,431 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.85 energy=527.55
2022-12-08 19:55:34,432 [ZeusDataLoader(train)] Up to epoch 45: time=2259.12, energy=331747.26, cost=363546.86
2022-12-08 19:55:34,432 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:55:34,432 [ZeusDataLoader(train)] Expected next epoch: time=2306.32, energy=338982.76, cost=371294.25
2022-12-08 19:55:34,433 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0020, Accuracy: 0.5837
2022-12-08 19:55:34,703 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:55:34,704 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:55:34.706 [ZeusMonitor] Monitor started.
2022-12-09 00:55:34.706 [ZeusMonitor] Running indefinitely. 2022-12-09 00:55:34.706 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:55:34.706 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e46+gpu0.power.log
2022-12-08 19:56:18,698 [ZeusDataLoader(train)] train epoch 46 done: time=44.26 energy=6708.69
2022-12-08 19:56:18,702 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.3035
Training Epoch: 45 [2048/50176]	Loss: 0.2833
Training Epoch: 45 [3072/50176]	Loss: 0.2664
Training Epoch: 45 [4096/50176]	Loss: 0.3057
Training Epoch: 45 [5120/50176]	Loss: 0.2425
Training Epoch: 45 [6144/50176]	Loss: 0.2786
Training Epoch: 45 [7168/50176]	Loss: 0.2776
Training Epoch: 45 [8192/50176]	Loss: 0.3280
Training Epoch: 45 [9216/50176]	Loss: 0.2668
Training Epoch: 45 [10240/50176]	Loss: 0.2879
Training Epoch: 45 [11264/50176]	Loss: 0.3038
Training Epoch: 45 [12288/50176]	Loss: 0.3302
Training Epoch: 45 [13312/50176]	Loss: 0.2850
Training Epoch: 45 [14336/50176]	Loss: 0.3274
Training Epoch: 45 [15360/50176]	Loss: 0.3042
Training Epoch: 45 [16384/50176]	Loss: 0.3134
Training Epoch: 45 [17408/50176]	Loss: 0.2787
Training Epoch: 45 [18432/50176]	Loss: 0.2942
Training Epoch: 45 [19456/50176]	Loss: 0.3203
Training Epoch: 45 [20480/50176]	Loss: 0.3136
Training Epoch: 45 [21504/50176]	Loss: 0.3023
Training Epoch: 45 [22528/50176]	Loss: 0.2742
Training Epoch: 45 [23552/50176]	Loss: 0.2610
Training Epoch: 45 [24576/50176]	Loss: 0.3552
Training Epoch: 45 [25600/50176]	Loss: 0.2944
Training Epoch: 45 [26624/50176]	Loss: 0.3231
Training Epoch: 45 [27648/50176]	Loss: 0.3143
Training Epoch: 45 [28672/50176]	Loss: 0.2940
Training Epoch: 45 [29696/50176]	Loss: 0.2947
Training Epoch: 45 [30720/50176]	Loss: 0.3247
Training Epoch: 45 [31744/50176]	Loss: 0.2729
Training Epoch: 45 [32768/50176]	Loss: 0.2641
Training Epoch: 45 [33792/50176]	Loss: 0.3214
Training Epoch: 45 [34816/50176]	Loss: 0.3387
Training Epoch: 45 [35840/50176]	Loss: 0.3525
Training Epoch: 45 [36864/50176]	Loss: 0.3045
Training Epoch: 45 [37888/50176]	Loss: 0.3432
Training Epoch: 45 [38912/50176]	Loss: 0.3118
Training Epoch: 45 [39936/50176]	Loss: 0.3813
Training Epoch: 45 [40960/50176]	Loss: 0.3567
Training Epoch: 45 [41984/50176]	Loss: 0.3656
Training Epoch: 45 [43008/50176]	Loss: 0.3444
Training Epoch: 45 [44032/50176]	Loss: 0.3455
Training Epoch: 45 [45056/50176]	Loss: 0.3467
Training Epoch: 45 [46080/50176]	Loss: 0.3606
Training Epoch: 45 [47104/50176]	Loss: 0.3635
Training Epoch: 45 [48128/50176]	Loss: 0.3349
Training Epoch: 45 [49152/50176]	Loss: 0.3476
Training Epoch: 45 [50176/50176]	Loss: 0.3215
2022-12-09 00:56:22.516 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:56:22,549 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.84 energy=532.14
2022-12-08 19:56:22,549 [ZeusDataLoader(train)] Up to epoch 46: time=2307.22, energy=338988.09, cost=371375.46
2022-12-08 19:56:22,549 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:56:22,549 [ZeusDataLoader(train)] Expected next epoch: time=2354.41, energy=346223.59, cost=379122.86
2022-12-08 19:56:22,550 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0021, Accuracy: 0.5796
2022-12-08 19:56:22,804 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:56:22,805 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:56:22.809 [ZeusMonitor] Monitor started.
2022-12-09 00:56:22.809 [ZeusMonitor] Running indefinitely. 2022-12-09 00:56:22.809 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:56:22.809 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e47+gpu0.power.log
2022-12-08 19:57:06,790 [ZeusDataLoader(train)] train epoch 47 done: time=44.23 energy=6719.97
2022-12-08 19:57:06,794 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.2833
Training Epoch: 46 [2048/50176]	Loss: 0.3119
Training Epoch: 46 [3072/50176]	Loss: 0.2923
Training Epoch: 46 [4096/50176]	Loss: 0.2933
Training Epoch: 46 [5120/50176]	Loss: 0.2747
Training Epoch: 46 [6144/50176]	Loss: 0.3008
Training Epoch: 46 [7168/50176]	Loss: 0.2696
Training Epoch: 46 [8192/50176]	Loss: 0.3005
Training Epoch: 46 [9216/50176]	Loss: 0.2619
Training Epoch: 46 [10240/50176]	Loss: 0.2937
Training Epoch: 46 [11264/50176]	Loss: 0.2970
Training Epoch: 46 [12288/50176]	Loss: 0.3177
Training Epoch: 46 [13312/50176]	Loss: 0.2998
Training Epoch: 46 [14336/50176]	Loss: 0.2944
Training Epoch: 46 [15360/50176]	Loss: 0.2743
Training Epoch: 46 [16384/50176]	Loss: 0.3008
Training Epoch: 46 [17408/50176]	Loss: 0.3028
Training Epoch: 46 [18432/50176]	Loss: 0.2949
Training Epoch: 46 [19456/50176]	Loss: 0.3079
Training Epoch: 46 [20480/50176]	Loss: 0.2622
Training Epoch: 46 [21504/50176]	Loss: 0.3119
Training Epoch: 46 [22528/50176]	Loss: 0.3118
Training Epoch: 46 [23552/50176]	Loss: 0.3246
Training Epoch: 46 [24576/50176]	Loss: 0.2925
Training Epoch: 46 [25600/50176]	Loss: 0.3273
Training Epoch: 46 [26624/50176]	Loss: 0.3188
Training Epoch: 46 [27648/50176]	Loss: 0.3195
Training Epoch: 46 [28672/50176]	Loss: 0.3011
Training Epoch: 46 [29696/50176]	Loss: 0.3182
Training Epoch: 46 [30720/50176]	Loss: 0.3302
Training Epoch: 46 [31744/50176]	Loss: 0.2875
Training Epoch: 46 [32768/50176]	Loss: 0.2793
Training Epoch: 46 [33792/50176]	Loss: 0.2900
Training Epoch: 46 [34816/50176]	Loss: 0.3148
Training Epoch: 46 [35840/50176]	Loss: 0.3027
Training Epoch: 46 [36864/50176]	Loss: 0.3381
Training Epoch: 46 [37888/50176]	Loss: 0.3121
Training Epoch: 46 [38912/50176]	Loss: 0.3347
Training Epoch: 46 [39936/50176]	Loss: 0.3341
Training Epoch: 46 [40960/50176]	Loss: 0.3152
Training Epoch: 46 [41984/50176]	Loss: 0.3152
Training Epoch: 46 [43008/50176]	Loss: 0.3067
Training Epoch: 46 [44032/50176]	Loss: 0.3265
Training Epoch: 46 [45056/50176]	Loss: 0.3356
Training Epoch: 46 [46080/50176]	Loss: 0.3353
Training Epoch: 46 [47104/50176]	Loss: 0.3428
Training Epoch: 46 [48128/50176]	Loss: 0.3273
Training Epoch: 46 [49152/50176]	Loss: 0.3124
Training Epoch: 46 [50176/50176]	Loss: 0.3356
2022-12-09 00:57:10.637 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:57:10,662 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.86 energy=527.48
2022-12-08 19:57:10,663 [ZeusDataLoader(train)] Up to epoch 47: time=2355.31, energy=346235.54, cost=379207.11
2022-12-08 19:57:10,663 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:57:10,663 [ZeusDataLoader(train)] Expected next epoch: time=2402.50, energy=353471.04, cost=386954.51
2022-12-08 19:57:10,664 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0020, Accuracy: 0.5899
2022-12-08 19:57:10,920 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:57:10,921 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:57:10.922 [ZeusMonitor] Monitor started.
2022-12-09 00:57:10.923 [ZeusMonitor] Running indefinitely. 2022-12-09 00:57:10.923 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:57:10.923 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e48+gpu0.power.log
2022-12-08 19:57:54,871 [ZeusDataLoader(train)] train epoch 48 done: time=44.20 energy=6713.59
2022-12-08 19:57:54,875 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.2904
Training Epoch: 47 [2048/50176]	Loss: 0.2837
Training Epoch: 47 [3072/50176]	Loss: 0.2814
Training Epoch: 47 [4096/50176]	Loss: 0.2978
Training Epoch: 47 [5120/50176]	Loss: 0.2599
Training Epoch: 47 [6144/50176]	Loss: 0.2720
Training Epoch: 47 [7168/50176]	Loss: 0.2745
Training Epoch: 47 [8192/50176]	Loss: 0.2626
Training Epoch: 47 [9216/50176]	Loss: 0.2715
Training Epoch: 47 [10240/50176]	Loss: 0.3003
Training Epoch: 47 [11264/50176]	Loss: 0.3163
Training Epoch: 47 [12288/50176]	Loss: 0.2901
Training Epoch: 47 [13312/50176]	Loss: 0.2725
Training Epoch: 47 [14336/50176]	Loss: 0.2738
Training Epoch: 47 [15360/50176]	Loss: 0.2615
Training Epoch: 47 [16384/50176]	Loss: 0.3124
Training Epoch: 47 [17408/50176]	Loss: 0.2988
Training Epoch: 47 [18432/50176]	Loss: 0.2357
Training Epoch: 47 [19456/50176]	Loss: 0.3096
Training Epoch: 47 [20480/50176]	Loss: 0.2658
Training Epoch: 47 [21504/50176]	Loss: 0.2914
Training Epoch: 47 [22528/50176]	Loss: 0.2833
Training Epoch: 47 [23552/50176]	Loss: 0.2560
Training Epoch: 47 [24576/50176]	Loss: 0.3072
Training Epoch: 47 [25600/50176]	Loss: 0.2819
Training Epoch: 47 [26624/50176]	Loss: 0.2696
Training Epoch: 47 [27648/50176]	Loss: 0.2518
Training Epoch: 47 [28672/50176]	Loss: 0.2917
Training Epoch: 47 [29696/50176]	Loss: 0.2776
Training Epoch: 47 [30720/50176]	Loss: 0.2952
Training Epoch: 47 [31744/50176]	Loss: 0.3109
Training Epoch: 47 [32768/50176]	Loss: 0.3121
Training Epoch: 47 [33792/50176]	Loss: 0.2840
Training Epoch: 47 [34816/50176]	Loss: 0.3120
Training Epoch: 47 [35840/50176]	Loss: 0.2928
Training Epoch: 47 [36864/50176]	Loss: 0.2897
Training Epoch: 47 [37888/50176]	Loss: 0.2812
Training Epoch: 47 [38912/50176]	Loss: 0.2931
Training Epoch: 47 [39936/50176]	Loss: 0.3214
Training Epoch: 47 [40960/50176]	Loss: 0.2976
Training Epoch: 47 [41984/50176]	Loss: 0.3442
Training Epoch: 47 [43008/50176]	Loss: 0.3318
Training Epoch: 47 [44032/50176]	Loss: 0.2855
Training Epoch: 47 [45056/50176]	Loss: 0.3186
Training Epoch: 47 [46080/50176]	Loss: 0.3378
Training Epoch: 47 [47104/50176]	Loss: 0.2977
Training Epoch: 47 [48128/50176]	Loss: 0.3317
Training Epoch: 47 [49152/50176]	Loss: 0.3260
Training Epoch: 47 [50176/50176]	Loss: 0.3127
2022-12-09 00:57:58.705 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:57:58,732 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.85 energy=538.88
2022-12-08 19:57:58,732 [ZeusDataLoader(train)] Up to epoch 48: time=2403.35, energy=353488.01, cost=387037.41
2022-12-08 19:57:58,732 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:57:58,733 [ZeusDataLoader(train)] Expected next epoch: time=2450.55, energy=360723.51, cost=394784.81
2022-12-08 19:57:58,734 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0020, Accuracy: 0.5945
2022-12-08 19:57:59,006 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:57:59,007 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:57:59.021 [ZeusMonitor] Monitor started.
2022-12-09 00:57:59.021 [ZeusMonitor] Running indefinitely. 2022-12-09 00:57:59.021 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:57:59.021 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e49+gpu0.power.log
2022-12-08 19:58:42,960 [ZeusDataLoader(train)] train epoch 49 done: time=44.22 energy=6721.18
2022-12-08 19:58:42,964 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.2395
Training Epoch: 48 [2048/50176]	Loss: 0.2365
Training Epoch: 48 [3072/50176]	Loss: 0.2301
Training Epoch: 48 [4096/50176]	Loss: 0.2571
Training Epoch: 48 [5120/50176]	Loss: 0.2450
Training Epoch: 48 [6144/50176]	Loss: 0.2547
Training Epoch: 48 [7168/50176]	Loss: 0.2217
Training Epoch: 48 [8192/50176]	Loss: 0.2657
Training Epoch: 48 [9216/50176]	Loss: 0.2557
Training Epoch: 48 [10240/50176]	Loss: 0.2479
Training Epoch: 48 [11264/50176]	Loss: 0.2696
Training Epoch: 48 [12288/50176]	Loss: 0.2832
Training Epoch: 48 [13312/50176]	Loss: 0.2655
Training Epoch: 48 [14336/50176]	Loss: 0.3090
Training Epoch: 48 [15360/50176]	Loss: 0.2749
Training Epoch: 48 [16384/50176]	Loss: 0.2733
Training Epoch: 48 [17408/50176]	Loss: 0.2661
Training Epoch: 48 [18432/50176]	Loss: 0.2813
Training Epoch: 48 [19456/50176]	Loss: 0.2604
Training Epoch: 48 [20480/50176]	Loss: 0.2498
Training Epoch: 48 [21504/50176]	Loss: 0.2214
Training Epoch: 48 [22528/50176]	Loss: 0.2524
Training Epoch: 48 [23552/50176]	Loss: 0.2997
Training Epoch: 48 [24576/50176]	Loss: 0.3079
Training Epoch: 48 [25600/50176]	Loss: 0.2799
Training Epoch: 48 [26624/50176]	Loss: 0.2628
Training Epoch: 48 [27648/50176]	Loss: 0.2720
Training Epoch: 48 [28672/50176]	Loss: 0.2784
Training Epoch: 48 [29696/50176]	Loss: 0.2860
Training Epoch: 48 [30720/50176]	Loss: 0.2873
Training Epoch: 48 [31744/50176]	Loss: 0.2740
Training Epoch: 48 [32768/50176]	Loss: 0.2929
Training Epoch: 48 [33792/50176]	Loss: 0.2515
Training Epoch: 48 [34816/50176]	Loss: 0.2453
Training Epoch: 48 [35840/50176]	Loss: 0.2653
Training Epoch: 48 [36864/50176]	Loss: 0.2654
Training Epoch: 48 [37888/50176]	Loss: 0.2976
Training Epoch: 48 [38912/50176]	Loss: 0.2436
Training Epoch: 48 [39936/50176]	Loss: 0.2696
Training Epoch: 48 [40960/50176]	Loss: 0.2937
Training Epoch: 48 [41984/50176]	Loss: 0.2921
Training Epoch: 48 [43008/50176]	Loss: 0.2838
Training Epoch: 48 [44032/50176]	Loss: 0.2876
Training Epoch: 48 [45056/50176]	Loss: 0.2870
Training Epoch: 48 [46080/50176]	Loss: 0.3380
Training Epoch: 48 [47104/50176]	Loss: 0.3109
Training Epoch: 48 [48128/50176]	Loss: 0.2857
Training Epoch: 48 [49152/50176]	Loss: 0.3473
Training Epoch: 48 [50176/50176]	Loss: 0.3234
2022-12-09 00:58:46.717 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:58:46,730 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.76 energy=516.95
2022-12-08 19:58:46,730 [ZeusDataLoader(train)] Up to epoch 49: time=2451.33, energy=360726.14, cost=394854.28
2022-12-08 19:58:46,730 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:58:46,731 [ZeusDataLoader(train)] Expected next epoch: time=2498.52, energy=367961.64, cost=402601.68
2022-12-08 19:58:46,732 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0021, Accuracy: 0.5988
2022-12-08 19:58:46,994 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:58:46,995 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:58:46.997 [ZeusMonitor] Monitor started.
2022-12-09 00:58:46.997 [ZeusMonitor] Running indefinitely. 2022-12-09 00:58:46.997 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:58:46.997 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e50+gpu0.power.log
2022-12-08 19:59:31,026 [ZeusDataLoader(train)] train epoch 50 done: time=44.29 energy=6720.47
2022-12-08 19:59:31,030 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 0.1924
Training Epoch: 49 [2048/50176]	Loss: 0.2641
Training Epoch: 49 [3072/50176]	Loss: 0.2224
Training Epoch: 49 [4096/50176]	Loss: 0.2503
Training Epoch: 49 [5120/50176]	Loss: 0.2345
Training Epoch: 49 [6144/50176]	Loss: 0.2330
Training Epoch: 49 [7168/50176]	Loss: 0.2442
Training Epoch: 49 [8192/50176]	Loss: 0.3050
Training Epoch: 49 [9216/50176]	Loss: 0.2573
Training Epoch: 49 [10240/50176]	Loss: 0.2751
Training Epoch: 49 [11264/50176]	Loss: 0.2916
Training Epoch: 49 [12288/50176]	Loss: 0.2724
Training Epoch: 49 [13312/50176]	Loss: 0.2814
Training Epoch: 49 [14336/50176]	Loss: 0.2547
Training Epoch: 49 [15360/50176]	Loss: 0.2317
Training Epoch: 49 [16384/50176]	Loss: 0.2383
Training Epoch: 49 [17408/50176]	Loss: 0.2371
Training Epoch: 49 [18432/50176]	Loss: 0.3109
Training Epoch: 49 [19456/50176]	Loss: 0.2438
Training Epoch: 49 [20480/50176]	Loss: 0.2577
Training Epoch: 49 [21504/50176]	Loss: 0.2352
Training Epoch: 49 [22528/50176]	Loss: 0.2886
Training Epoch: 49 [23552/50176]	Loss: 0.2574
Training Epoch: 49 [24576/50176]	Loss: 0.2441
Training Epoch: 49 [25600/50176]	Loss: 0.2240
Training Epoch: 49 [26624/50176]	Loss: 0.2528
Training Epoch: 49 [27648/50176]	Loss: 0.2528
Training Epoch: 49 [28672/50176]	Loss: 0.2314
Training Epoch: 49 [29696/50176]	Loss: 0.2387
Training Epoch: 49 [30720/50176]	Loss: 0.2639
Training Epoch: 49 [31744/50176]	Loss: 0.2913
Training Epoch: 49 [32768/50176]	Loss: 0.2418
Training Epoch: 49 [33792/50176]	Loss: 0.2773
Training Epoch: 49 [34816/50176]	Loss: 0.2688
Training Epoch: 49 [35840/50176]	Loss: 0.2809
Training Epoch: 49 [36864/50176]	Loss: 0.3017
Training Epoch: 49 [37888/50176]	Loss: 0.2924
Training Epoch: 49 [38912/50176]	Loss: 0.3330
Training Epoch: 49 [39936/50176]	Loss: 0.2911
Training Epoch: 49 [40960/50176]	Loss: 0.3298
Training Epoch: 49 [41984/50176]	Loss: 0.3153
Training Epoch: 49 [43008/50176]	Loss: 0.2861
Training Epoch: 49 [44032/50176]	Loss: 0.2653
Training Epoch: 49 [45056/50176]	Loss: 0.3596
Training Epoch: 49 [46080/50176]	Loss: 0.2555
Training Epoch: 49 [47104/50176]	Loss: 0.3059
Training Epoch: 49 [48128/50176]	Loss: 0.3153
Training Epoch: 49 [49152/50176]	Loss: 0.3038
Training Epoch: 49 [50176/50176]	Loss: 0.2806
2022-12-09 00:59:34.815 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 19:59:34,872 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.83 energy=532.82
2022-12-08 19:59:34,872 [ZeusDataLoader(train)] Up to epoch 50: time=2499.45, energy=367979.43, cost=402691.41
2022-12-08 19:59:34,873 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 19:59:34,873 [ZeusDataLoader(train)] Expected next epoch: time=2546.64, energy=375214.93, cost=410438.80
2022-12-08 19:59:34,874 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0023, Accuracy: 0.5849
2022-12-08 19:59:35,148 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 19:59:35,149 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 00:59:35.160 [ZeusMonitor] Monitor started.
2022-12-09 00:59:35.160 [ZeusMonitor] Running indefinitely. 2022-12-09 00:59:35.160 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 00:59:35.160 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e51+gpu0.power.log
2022-12-08 20:00:19,184 [ZeusDataLoader(train)] train epoch 51 done: time=44.30 energy=6708.67
2022-12-08 20:00:19,188 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 0.2339
Training Epoch: 50 [2048/50176]	Loss: 0.2025
Training Epoch: 50 [3072/50176]	Loss: 0.2925
Training Epoch: 50 [4096/50176]	Loss: 0.2931
Training Epoch: 50 [5120/50176]	Loss: 0.2527
Training Epoch: 50 [6144/50176]	Loss: 0.2269
Training Epoch: 50 [7168/50176]	Loss: 0.2547
Training Epoch: 50 [8192/50176]	Loss: 0.2475
Training Epoch: 50 [9216/50176]	Loss: 0.2449
Training Epoch: 50 [10240/50176]	Loss: 0.2015
Training Epoch: 50 [11264/50176]	Loss: 0.2420
Training Epoch: 50 [12288/50176]	Loss: 0.2200
Training Epoch: 50 [13312/50176]	Loss: 0.2576
Training Epoch: 50 [14336/50176]	Loss: 0.2521
Training Epoch: 50 [15360/50176]	Loss: 0.2398
Training Epoch: 50 [16384/50176]	Loss: 0.2390
Training Epoch: 50 [17408/50176]	Loss: 0.2410
Training Epoch: 50 [18432/50176]	Loss: 0.2475
Training Epoch: 50 [19456/50176]	Loss: 0.2701
Training Epoch: 50 [20480/50176]	Loss: 0.2483
Training Epoch: 50 [21504/50176]	Loss: 0.2768
Training Epoch: 50 [22528/50176]	Loss: 0.2357
Training Epoch: 50 [23552/50176]	Loss: 0.2689
Training Epoch: 50 [24576/50176]	Loss: 0.2421
Training Epoch: 50 [25600/50176]	Loss: 0.2771
Training Epoch: 50 [26624/50176]	Loss: 0.2945
Training Epoch: 50 [27648/50176]	Loss: 0.2408
Training Epoch: 50 [28672/50176]	Loss: 0.2199
Training Epoch: 50 [29696/50176]	Loss: 0.2440
Training Epoch: 50 [30720/50176]	Loss: 0.2653
Training Epoch: 50 [31744/50176]	Loss: 0.2881
Training Epoch: 50 [32768/50176]	Loss: 0.2466
Training Epoch: 50 [33792/50176]	Loss: 0.2476
Training Epoch: 50 [34816/50176]	Loss: 0.2560
Training Epoch: 50 [35840/50176]	Loss: 0.2875
Training Epoch: 50 [36864/50176]	Loss: 0.3054
Training Epoch: 50 [37888/50176]	Loss: 0.2534
Training Epoch: 50 [38912/50176]	Loss: 0.2810
Training Epoch: 50 [39936/50176]	Loss: 0.2560
Training Epoch: 50 [40960/50176]	Loss: 0.2833
Training Epoch: 50 [41984/50176]	Loss: 0.2683
Training Epoch: 50 [43008/50176]	Loss: 0.2748
Training Epoch: 50 [44032/50176]	Loss: 0.2833
Training Epoch: 50 [45056/50176]	Loss: 0.3227
Training Epoch: 50 [46080/50176]	Loss: 0.2585
Training Epoch: 50 [47104/50176]	Loss: 0.2736
Training Epoch: 50 [48128/50176]	Loss: 0.2588
Training Epoch: 50 [49152/50176]	Loss: 0.2761
Training Epoch: 50 [50176/50176]	Loss: 0.3277
2022-12-09 01:00:23.021 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:00:23,048 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.85 energy=531.49
2022-12-08 20:00:23,049 [ZeusDataLoader(train)] Up to epoch 51: time=2547.60, energy=375219.58, cost=410524.91
2022-12-08 20:00:23,049 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:00:23,049 [ZeusDataLoader(train)] Expected next epoch: time=2594.80, energy=382455.08, cost=418272.30
2022-12-08 20:00:23,050 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0022, Accuracy: 0.5895
2022-12-08 20:00:23,274 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:00:23,275 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:00:23.278 [ZeusMonitor] Monitor started.
2022-12-09 01:00:23.279 [ZeusMonitor] Running indefinitely. 2022-12-09 01:00:23.279 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:00:23.279 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e52+gpu0.power.log
2022-12-08 20:01:07,268 [ZeusDataLoader(train)] train epoch 52 done: time=44.21 energy=6715.86
2022-12-08 20:01:07,272 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 0.2246
Training Epoch: 51 [2048/50176]	Loss: 0.2609
Training Epoch: 51 [3072/50176]	Loss: 0.1999
Training Epoch: 51 [4096/50176]	Loss: 0.2032
Training Epoch: 51 [5120/50176]	Loss: 0.2103
Training Epoch: 51 [6144/50176]	Loss: 0.2424
Training Epoch: 51 [7168/50176]	Loss: 0.2369
Training Epoch: 51 [8192/50176]	Loss: 0.1871
Training Epoch: 51 [9216/50176]	Loss: 0.2228
Training Epoch: 51 [10240/50176]	Loss: 0.2178
Training Epoch: 51 [11264/50176]	Loss: 0.2593
Training Epoch: 51 [12288/50176]	Loss: 0.2746
Training Epoch: 51 [13312/50176]	Loss: 0.2030
Training Epoch: 51 [14336/50176]	Loss: 0.1950
Training Epoch: 51 [15360/50176]	Loss: 0.2488
Training Epoch: 51 [16384/50176]	Loss: 0.2661
Training Epoch: 51 [17408/50176]	Loss: 0.2740
Training Epoch: 51 [18432/50176]	Loss: 0.2692
Training Epoch: 51 [19456/50176]	Loss: 0.2499
Training Epoch: 51 [20480/50176]	Loss: 0.2464
Training Epoch: 51 [21504/50176]	Loss: 0.2504
Training Epoch: 51 [22528/50176]	Loss: 0.2395
Training Epoch: 51 [23552/50176]	Loss: 0.2414
Training Epoch: 51 [24576/50176]	Loss: 0.2610
Training Epoch: 51 [25600/50176]	Loss: 0.2615
Training Epoch: 51 [26624/50176]	Loss: 0.2767
Training Epoch: 51 [27648/50176]	Loss: 0.2568
Training Epoch: 51 [28672/50176]	Loss: 0.2705
Training Epoch: 51 [29696/50176]	Loss: 0.3117
Training Epoch: 51 [30720/50176]	Loss: 0.2376
Training Epoch: 51 [31744/50176]	Loss: 0.2438
Training Epoch: 51 [32768/50176]	Loss: 0.2309
Training Epoch: 51 [33792/50176]	Loss: 0.2711
Training Epoch: 51 [34816/50176]	Loss: 0.2676
Training Epoch: 51 [35840/50176]	Loss: 0.2529
Training Epoch: 51 [36864/50176]	Loss: 0.2513
Training Epoch: 51 [37888/50176]	Loss: 0.2646
Training Epoch: 51 [38912/50176]	Loss: 0.2657
Training Epoch: 51 [39936/50176]	Loss: 0.2770
Training Epoch: 51 [40960/50176]	Loss: 0.2736
Training Epoch: 51 [41984/50176]	Loss: 0.2760
Training Epoch: 51 [43008/50176]	Loss: 0.2512
Training Epoch: 51 [44032/50176]	Loss: 0.2810
Training Epoch: 51 [45056/50176]	Loss: 0.2597
Training Epoch: 51 [46080/50176]	Loss: 0.3012
Training Epoch: 51 [47104/50176]	Loss: 0.2727
Training Epoch: 51 [48128/50176]	Loss: 0.2838
Training Epoch: 51 [49152/50176]	Loss: 0.2732
Training Epoch: 51 [50176/50176]	Loss: 0.3060
2022-12-09 01:01:11.023 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:01:11,033 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.75 energy=512.55
2022-12-08 20:01:11,033 [ZeusDataLoader(train)] Up to epoch 52: time=2595.56, energy=382447.99, cost=418335.78
2022-12-08 20:01:11,033 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:01:11,033 [ZeusDataLoader(train)] Expected next epoch: time=2642.76, energy=389683.49, cost=426083.18
2022-12-08 20:01:11,034 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0021, Accuracy: 0.5913
2022-12-08 20:01:11,254 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:01:11,255 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:01:11.259 [ZeusMonitor] Monitor started.
2022-12-09 01:01:11.259 [ZeusMonitor] Running indefinitely. 2022-12-09 01:01:11.259 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:01:11.259 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e53+gpu0.power.log
2022-12-08 20:01:55,264 [ZeusDataLoader(train)] train epoch 53 done: time=44.22 energy=6733.85
2022-12-08 20:01:55,267 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 0.1962
Training Epoch: 52 [2048/50176]	Loss: 0.1994
Training Epoch: 52 [3072/50176]	Loss: 0.2255
Training Epoch: 52 [4096/50176]	Loss: 0.2148
Training Epoch: 52 [5120/50176]	Loss: 0.2017
Training Epoch: 52 [6144/50176]	Loss: 0.1970
Training Epoch: 52 [7168/50176]	Loss: 0.1821
Training Epoch: 52 [8192/50176]	Loss: 0.2196
Training Epoch: 52 [9216/50176]	Loss: 0.1912
Training Epoch: 52 [10240/50176]	Loss: 0.2357
Training Epoch: 52 [11264/50176]	Loss: 0.2455
Training Epoch: 52 [12288/50176]	Loss: 0.2244
Training Epoch: 52 [13312/50176]	Loss: 0.2219
Training Epoch: 52 [14336/50176]	Loss: 0.2287
Training Epoch: 52 [15360/50176]	Loss: 0.2181
Training Epoch: 52 [16384/50176]	Loss: 0.2526
Training Epoch: 52 [17408/50176]	Loss: 0.1936
Training Epoch: 52 [18432/50176]	Loss: 0.2208
Training Epoch: 52 [19456/50176]	Loss: 0.2567
Training Epoch: 52 [20480/50176]	Loss: 0.2419
Training Epoch: 52 [21504/50176]	Loss: 0.2197
Training Epoch: 52 [22528/50176]	Loss: 0.2443
Training Epoch: 52 [23552/50176]	Loss: 0.2458
Training Epoch: 52 [24576/50176]	Loss: 0.2551
Training Epoch: 52 [25600/50176]	Loss: 0.2367
Training Epoch: 52 [26624/50176]	Loss: 0.1873
Training Epoch: 52 [27648/50176]	Loss: 0.2324
Training Epoch: 52 [28672/50176]	Loss: 0.2408
Training Epoch: 52 [29696/50176]	Loss: 0.2482
Training Epoch: 52 [30720/50176]	Loss: 0.2240
Training Epoch: 52 [31744/50176]	Loss: 0.2235
Training Epoch: 52 [32768/50176]	Loss: 0.2213
Training Epoch: 52 [33792/50176]	Loss: 0.2471
Training Epoch: 52 [34816/50176]	Loss: 0.2488
Training Epoch: 52 [35840/50176]	Loss: 0.2068
Training Epoch: 52 [36864/50176]	Loss: 0.2148
Training Epoch: 52 [37888/50176]	Loss: 0.2562
Training Epoch: 52 [38912/50176]	Loss: 0.2455
Training Epoch: 52 [39936/50176]	Loss: 0.2486
Training Epoch: 52 [40960/50176]	Loss: 0.2494
Training Epoch: 52 [41984/50176]	Loss: 0.2202
Training Epoch: 52 [43008/50176]	Loss: 0.2375
Training Epoch: 52 [44032/50176]	Loss: 0.3161
Training Epoch: 52 [45056/50176]	Loss: 0.2103
Training Epoch: 52 [46080/50176]	Loss: 0.2652
Training Epoch: 52 [47104/50176]	Loss: 0.2255
Training Epoch: 52 [48128/50176]	Loss: 0.2462
Training Epoch: 52 [49152/50176]	Loss: 0.2257
Training Epoch: 52 [50176/50176]	Loss: 0.2231
2022-12-09 01:01:59.002 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:01:59,025 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.75 energy=521.23
2022-12-08 20:01:59,025 [ZeusDataLoader(train)] Up to epoch 53: time=2643.53, energy=389703.07, cost=426160.72
2022-12-08 20:01:59,025 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:01:59,025 [ZeusDataLoader(train)] Expected next epoch: time=2690.73, energy=396938.57, cost=433908.11
2022-12-08 20:01:59,026 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0023, Accuracy: 0.5912
2022-12-08 20:01:59,298 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:01:59,299 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:01:59.313 [ZeusMonitor] Monitor started.
2022-12-09 01:01:59.313 [ZeusMonitor] Running indefinitely. 2022-12-09 01:01:59.313 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:01:59.313 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e54+gpu0.power.log
2022-12-08 20:02:43,211 [ZeusDataLoader(train)] train epoch 54 done: time=44.18 energy=6711.47
2022-12-08 20:02:43,215 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 0.1746
Training Epoch: 53 [2048/50176]	Loss: 0.1947
Training Epoch: 53 [3072/50176]	Loss: 0.2179
Training Epoch: 53 [4096/50176]	Loss: 0.2054
Training Epoch: 53 [5120/50176]	Loss: 0.2034
Training Epoch: 53 [6144/50176]	Loss: 0.2017
Training Epoch: 53 [7168/50176]	Loss: 0.2022
Training Epoch: 53 [8192/50176]	Loss: 0.1877
Training Epoch: 53 [9216/50176]	Loss: 0.2064
Training Epoch: 53 [10240/50176]	Loss: 0.2099
Training Epoch: 53 [11264/50176]	Loss: 0.2060
Training Epoch: 53 [12288/50176]	Loss: 0.2098
Training Epoch: 53 [13312/50176]	Loss: 0.2349
Training Epoch: 53 [14336/50176]	Loss: 0.2048
Training Epoch: 53 [15360/50176]	Loss: 0.2416
Training Epoch: 53 [16384/50176]	Loss: 0.2195
Training Epoch: 53 [17408/50176]	Loss: 0.1949
Training Epoch: 53 [18432/50176]	Loss: 0.2425
Training Epoch: 53 [19456/50176]	Loss: 0.2256
Training Epoch: 53 [20480/50176]	Loss: 0.1737
Training Epoch: 53 [21504/50176]	Loss: 0.2000
Training Epoch: 53 [22528/50176]	Loss: 0.2225
Training Epoch: 53 [23552/50176]	Loss: 0.2318
Training Epoch: 53 [24576/50176]	Loss: 0.2133
Training Epoch: 53 [25600/50176]	Loss: 0.2290
Training Epoch: 53 [26624/50176]	Loss: 0.2146
Training Epoch: 53 [27648/50176]	Loss: 0.2417
Training Epoch: 53 [28672/50176]	Loss: 0.2508
Training Epoch: 53 [29696/50176]	Loss: 0.2297
Training Epoch: 53 [30720/50176]	Loss: 0.2552
Training Epoch: 53 [31744/50176]	Loss: 0.2123
Training Epoch: 53 [32768/50176]	Loss: 0.2271
Training Epoch: 53 [33792/50176]	Loss: 0.2151
Training Epoch: 53 [34816/50176]	Loss: 0.2327
Training Epoch: 53 [35840/50176]	Loss: 0.2455
Training Epoch: 53 [36864/50176]	Loss: 0.2252
Training Epoch: 53 [37888/50176]	Loss: 0.2734
Training Epoch: 53 [38912/50176]	Loss: 0.2394
Training Epoch: 53 [39936/50176]	Loss: 0.2530
Training Epoch: 53 [40960/50176]	Loss: 0.2287
Training Epoch: 53 [41984/50176]	Loss: 0.2181
Training Epoch: 53 [43008/50176]	Loss: 0.2726
Training Epoch: 53 [44032/50176]	Loss: 0.2564
Training Epoch: 53 [45056/50176]	Loss: 0.2708
Training Epoch: 53 [46080/50176]	Loss: 0.1989
Training Epoch: 53 [47104/50176]	Loss: 0.2422
Training Epoch: 53 [48128/50176]	Loss: 0.2265
Training Epoch: 53 [49152/50176]	Loss: 0.2745
Training Epoch: 53 [50176/50176]	Loss: 0.2548
2022-12-09 01:02:46.934 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:02:46,944 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.72 energy=519.83
2022-12-08 20:02:46,945 [ZeusDataLoader(train)] Up to epoch 54: time=2691.43, energy=396934.37, cost=433967.38
2022-12-08 20:02:46,945 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:02:46,945 [ZeusDataLoader(train)] Expected next epoch: time=2738.63, energy=404169.87, cost=441714.77
2022-12-08 20:02:46,946 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0022, Accuracy: 0.5960
2022-12-08 20:02:47,201 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:02:47,202 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:02:47.203 [ZeusMonitor] Monitor started.
2022-12-09 01:02:47.203 [ZeusMonitor] Running indefinitely. 2022-12-09 01:02:47.204 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:02:47.204 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e55+gpu0.power.log
2022-12-08 20:03:31,212 [ZeusDataLoader(train)] train epoch 55 done: time=44.26 energy=6723.66
2022-12-08 20:03:31,216 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 0.2052
Training Epoch: 54 [2048/50176]	Loss: 0.2156
Training Epoch: 54 [3072/50176]	Loss: 0.1736
Training Epoch: 54 [4096/50176]	Loss: 0.1906
Training Epoch: 54 [5120/50176]	Loss: 0.1750
Training Epoch: 54 [6144/50176]	Loss: 0.1759
Training Epoch: 54 [7168/50176]	Loss: 0.1802
Training Epoch: 54 [8192/50176]	Loss: 0.2106
Training Epoch: 54 [9216/50176]	Loss: 0.1684
Training Epoch: 54 [10240/50176]	Loss: 0.1910
Training Epoch: 54 [11264/50176]	Loss: 0.1961
Training Epoch: 54 [12288/50176]	Loss: 0.1880
Training Epoch: 54 [13312/50176]	Loss: 0.2318
Training Epoch: 54 [14336/50176]	Loss: 0.1948
Training Epoch: 54 [15360/50176]	Loss: 0.2407
Training Epoch: 54 [16384/50176]	Loss: 0.1939
Training Epoch: 54 [17408/50176]	Loss: 0.2168
Training Epoch: 54 [18432/50176]	Loss: 0.2147
Training Epoch: 54 [19456/50176]	Loss: 0.2070
Training Epoch: 54 [20480/50176]	Loss: 0.1816
Training Epoch: 54 [21504/50176]	Loss: 0.2077
Training Epoch: 54 [22528/50176]	Loss: 0.2347
Training Epoch: 54 [23552/50176]	Loss: 0.1792
Training Epoch: 54 [24576/50176]	Loss: 0.2040
Training Epoch: 54 [25600/50176]	Loss: 0.2256
Training Epoch: 54 [26624/50176]	Loss: 0.1989
Training Epoch: 54 [27648/50176]	Loss: 0.2227
Training Epoch: 54 [28672/50176]	Loss: 0.1957
Training Epoch: 54 [29696/50176]	Loss: 0.2230
Training Epoch: 54 [30720/50176]	Loss: 0.1992
Training Epoch: 54 [31744/50176]	Loss: 0.2561
Training Epoch: 54 [32768/50176]	Loss: 0.2103
Training Epoch: 54 [33792/50176]	Loss: 0.2139
Training Epoch: 54 [34816/50176]	Loss: 0.2326
Training Epoch: 54 [35840/50176]	Loss: 0.1931
Training Epoch: 54 [36864/50176]	Loss: 0.2216
Training Epoch: 54 [37888/50176]	Loss: 0.2519
Training Epoch: 54 [38912/50176]	Loss: 0.2178
Training Epoch: 54 [39936/50176]	Loss: 0.2260
Training Epoch: 54 [40960/50176]	Loss: 0.2484
Training Epoch: 54 [41984/50176]	Loss: 0.2064
Training Epoch: 54 [43008/50176]	Loss: 0.2085
Training Epoch: 54 [44032/50176]	Loss: 0.2355
Training Epoch: 54 [45056/50176]	Loss: 0.2277
Training Epoch: 54 [46080/50176]	Loss: 0.2659
Training Epoch: 54 [47104/50176]	Loss: 0.2332
Training Epoch: 54 [48128/50176]	Loss: 0.2045
Training Epoch: 54 [49152/50176]	Loss: 0.2020
Training Epoch: 54 [50176/50176]	Loss: 0.2425
2022-12-09 01:03:34.950 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:03:34,963 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.74 energy=513.97
2022-12-08 20:03:34,963 [ZeusDataLoader(train)] Up to epoch 55: time=2739.43, energy=404172.00, cost=441785.79
2022-12-08 20:03:34,963 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:03:34,964 [ZeusDataLoader(train)] Expected next epoch: time=2786.62, energy=411407.51, cost=449533.18
2022-12-08 20:03:34,965 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0026, Accuracy: 0.5811
2022-12-08 20:03:35,235 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:03:35,236 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:03:35.238 [ZeusMonitor] Monitor started.
2022-12-09 01:03:35.238 [ZeusMonitor] Running indefinitely. 2022-12-09 01:03:35.238 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:03:35.238 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e56+gpu0.power.log
2022-12-08 20:04:19,230 [ZeusDataLoader(train)] train epoch 56 done: time=44.26 energy=6706.12
2022-12-08 20:04:19,233 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 0.1944
Training Epoch: 55 [2048/50176]	Loss: 0.2217
Training Epoch: 55 [3072/50176]	Loss: 0.1933
Training Epoch: 55 [4096/50176]	Loss: 0.2175
Training Epoch: 55 [5120/50176]	Loss: 0.1938
Training Epoch: 55 [6144/50176]	Loss: 0.1890
Training Epoch: 55 [7168/50176]	Loss: 0.2032
Training Epoch: 55 [8192/50176]	Loss: 0.1913
Training Epoch: 55 [9216/50176]	Loss: 0.2006
Training Epoch: 55 [10240/50176]	Loss: 0.2384
Training Epoch: 55 [11264/50176]	Loss: 0.1912
Training Epoch: 55 [12288/50176]	Loss: 0.1680
Training Epoch: 55 [13312/50176]	Loss: 0.2160
Training Epoch: 55 [14336/50176]	Loss: 0.2107
Training Epoch: 55 [15360/50176]	Loss: 0.1534
Training Epoch: 55 [16384/50176]	Loss: 0.1686
Training Epoch: 55 [17408/50176]	Loss: 0.2146
Training Epoch: 55 [18432/50176]	Loss: 0.1836
Training Epoch: 55 [19456/50176]	Loss: 0.2048
Training Epoch: 55 [20480/50176]	Loss: 0.2159
Training Epoch: 55 [21504/50176]	Loss: 0.2020
Training Epoch: 55 [22528/50176]	Loss: 0.2023
Training Epoch: 55 [23552/50176]	Loss: 0.2109
Training Epoch: 55 [24576/50176]	Loss: 0.2047
Training Epoch: 55 [25600/50176]	Loss: 0.2026
Training Epoch: 55 [26624/50176]	Loss: 0.2114
Training Epoch: 55 [27648/50176]	Loss: 0.2065
Training Epoch: 55 [28672/50176]	Loss: 0.2035
Training Epoch: 55 [29696/50176]	Loss: 0.2401
Training Epoch: 55 [30720/50176]	Loss: 0.1995
Training Epoch: 55 [31744/50176]	Loss: 0.2119
Training Epoch: 55 [32768/50176]	Loss: 0.2828
Training Epoch: 55 [33792/50176]	Loss: 0.2376
Training Epoch: 55 [34816/50176]	Loss: 0.2058
Training Epoch: 55 [35840/50176]	Loss: 0.2368
Training Epoch: 55 [36864/50176]	Loss: 0.2335
Training Epoch: 55 [37888/50176]	Loss: 0.2068
Training Epoch: 55 [38912/50176]	Loss: 0.2188
Training Epoch: 55 [39936/50176]	Loss: 0.2058
Training Epoch: 55 [40960/50176]	Loss: 0.1542
Training Epoch: 55 [41984/50176]	Loss: 0.1878
Training Epoch: 55 [43008/50176]	Loss: 0.2056
Training Epoch: 55 [44032/50176]	Loss: 0.2445
Training Epoch: 55 [45056/50176]	Loss: 0.2594
Training Epoch: 55 [46080/50176]	Loss: 0.2214
Training Epoch: 55 [47104/50176]	Loss: 0.2063
Training Epoch: 55 [48128/50176]	Loss: 0.2225
Training Epoch: 55 [49152/50176]	Loss: 0.2493
Training Epoch: 55 [50176/50176]	Loss: 0.2536
2022-12-09 01:04:22.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:04:23,007 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.77 energy=518.60
2022-12-08 20:04:23,007 [ZeusDataLoader(train)] Up to epoch 56: time=2787.45, energy=411396.73, cost=449600.08
2022-12-08 20:04:23,008 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:04:23,008 [ZeusDataLoader(train)] Expected next epoch: time=2834.64, energy=418632.23, cost=457347.47
2022-12-08 20:04:23,009 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0023, Accuracy: 0.5932
2022-12-08 20:04:23,223 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:04:23,224 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:04:23.225 [ZeusMonitor] Monitor started.
2022-12-09 01:04:23.226 [ZeusMonitor] Running indefinitely. 2022-12-09 01:04:23.226 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:04:23.226 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e57+gpu0.power.log
2022-12-08 20:05:07,228 [ZeusDataLoader(train)] train epoch 57 done: time=44.21 energy=6718.85
2022-12-08 20:05:07,232 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 0.1822
Training Epoch: 56 [2048/50176]	Loss: 0.1566
Training Epoch: 56 [3072/50176]	Loss: 0.1620
Training Epoch: 56 [4096/50176]	Loss: 0.1760
Training Epoch: 56 [5120/50176]	Loss: 0.2098
Training Epoch: 56 [6144/50176]	Loss: 0.1717
Training Epoch: 56 [7168/50176]	Loss: 0.2214
Training Epoch: 56 [8192/50176]	Loss: 0.1495
Training Epoch: 56 [9216/50176]	Loss: 0.1866
Training Epoch: 56 [10240/50176]	Loss: 0.1920
Training Epoch: 56 [11264/50176]	Loss: 0.1835
Training Epoch: 56 [12288/50176]	Loss: 0.2271
Training Epoch: 56 [13312/50176]	Loss: 0.2193
Training Epoch: 56 [14336/50176]	Loss: 0.1794
Training Epoch: 56 [15360/50176]	Loss: 0.1962
Training Epoch: 56 [16384/50176]	Loss: 0.2154
Training Epoch: 56 [17408/50176]	Loss: 0.1996
Training Epoch: 56 [18432/50176]	Loss: 0.2093
Training Epoch: 56 [19456/50176]	Loss: 0.1974
Training Epoch: 56 [20480/50176]	Loss: 0.1823
Training Epoch: 56 [21504/50176]	Loss: 0.2057
Training Epoch: 56 [22528/50176]	Loss: 0.2481
Training Epoch: 56 [23552/50176]	Loss: 0.2050
Training Epoch: 56 [24576/50176]	Loss: 0.1882
Training Epoch: 56 [25600/50176]	Loss: 0.1596
Training Epoch: 56 [26624/50176]	Loss: 0.1843
Training Epoch: 56 [27648/50176]	Loss: 0.1836
Training Epoch: 56 [28672/50176]	Loss: 0.2253
Training Epoch: 56 [29696/50176]	Loss: 0.2264
Training Epoch: 56 [30720/50176]	Loss: 0.2062
Training Epoch: 56 [31744/50176]	Loss: 0.2270
Training Epoch: 56 [32768/50176]	Loss: 0.2272
Training Epoch: 56 [33792/50176]	Loss: 0.2000
Training Epoch: 56 [34816/50176]	Loss: 0.2328
Training Epoch: 56 [35840/50176]	Loss: 0.2406
Training Epoch: 56 [36864/50176]	Loss: 0.2000
Training Epoch: 56 [37888/50176]	Loss: 0.2470
Training Epoch: 56 [38912/50176]	Loss: 0.2150
Training Epoch: 56 [39936/50176]	Loss: 0.2034
Training Epoch: 56 [40960/50176]	Loss: 0.2373
Training Epoch: 56 [41984/50176]	Loss: 0.2103
Training Epoch: 56 [43008/50176]	Loss: 0.2068
Training Epoch: 56 [44032/50176]	Loss: 0.2138
Training Epoch: 56 [45056/50176]	Loss: 0.2362
Training Epoch: 56 [46080/50176]	Loss: 0.1958
Training Epoch: 56 [47104/50176]	Loss: 0.2626
Training Epoch: 56 [48128/50176]	Loss: 0.2295
Training Epoch: 56 [49152/50176]	Loss: 0.2516
Training Epoch: 56 [50176/50176]	Loss: 0.2699
2022-12-09 01:05:11.070 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:05:11,093 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.85 energy=527.71
2022-12-08 20:05:11,093 [ZeusDataLoader(train)] Up to epoch 57: time=2835.51, energy=418643.28, cost=457428.88
2022-12-08 20:05:11,093 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:05:11,093 [ZeusDataLoader(train)] Expected next epoch: time=2882.71, energy=425878.79, cost=465176.28
2022-12-08 20:05:11,094 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0024, Accuracy: 0.5942
2022-12-08 20:05:11,358 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:05:11,359 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:05:11.360 [ZeusMonitor] Monitor started.
2022-12-09 01:05:11.361 [ZeusMonitor] Running indefinitely. 2022-12-09 01:05:11.361 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:05:11.361 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e58+gpu0.power.log
2022-12-08 20:05:55,409 [ZeusDataLoader(train)] train epoch 58 done: time=44.31 energy=6728.04
2022-12-08 20:05:55,412 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 0.1945
Training Epoch: 57 [2048/50176]	Loss: 0.1937
Training Epoch: 57 [3072/50176]	Loss: 0.1693
Training Epoch: 57 [4096/50176]	Loss: 0.1635
Training Epoch: 57 [5120/50176]	Loss: 0.2337
Training Epoch: 57 [6144/50176]	Loss: 0.1616
Training Epoch: 57 [7168/50176]	Loss: 0.1832
Training Epoch: 57 [8192/50176]	Loss: 0.1723
Training Epoch: 57 [9216/50176]	Loss: 0.1791
Training Epoch: 57 [10240/50176]	Loss: 0.2024
Training Epoch: 57 [11264/50176]	Loss: 0.2311
Training Epoch: 57 [12288/50176]	Loss: 0.1825
Training Epoch: 57 [13312/50176]	Loss: 0.2212
Training Epoch: 57 [14336/50176]	Loss: 0.2044
Training Epoch: 57 [15360/50176]	Loss: 0.1763
Training Epoch: 57 [16384/50176]	Loss: 0.1692
Training Epoch: 57 [17408/50176]	Loss: 0.1990
Training Epoch: 57 [18432/50176]	Loss: 0.1723
Training Epoch: 57 [19456/50176]	Loss: 0.1755
Training Epoch: 57 [20480/50176]	Loss: 0.2112
Training Epoch: 57 [21504/50176]	Loss: 0.1994
Training Epoch: 57 [22528/50176]	Loss: 0.1574
Training Epoch: 57 [23552/50176]	Loss: 0.2003
Training Epoch: 57 [24576/50176]	Loss: 0.1869
Training Epoch: 57 [25600/50176]	Loss: 0.2043
Training Epoch: 57 [26624/50176]	Loss: 0.2009
Training Epoch: 57 [27648/50176]	Loss: 0.1882
Training Epoch: 57 [28672/50176]	Loss: 0.1710
Training Epoch: 57 [29696/50176]	Loss: 0.1737
Training Epoch: 57 [30720/50176]	Loss: 0.1977
Training Epoch: 57 [31744/50176]	Loss: 0.1883
Training Epoch: 57 [32768/50176]	Loss: 0.2068
Training Epoch: 57 [33792/50176]	Loss: 0.2556
Training Epoch: 57 [34816/50176]	Loss: 0.2354
Training Epoch: 57 [35840/50176]	Loss: 0.2086
Training Epoch: 57 [36864/50176]	Loss: 0.1925
Training Epoch: 57 [37888/50176]	Loss: 0.2128
Training Epoch: 57 [38912/50176]	Loss: 0.1993
Training Epoch: 57 [39936/50176]	Loss: 0.2133
Training Epoch: 57 [40960/50176]	Loss: 0.1747
Training Epoch: 57 [41984/50176]	Loss: 0.1995
Training Epoch: 57 [43008/50176]	Loss: 0.2062
Training Epoch: 57 [44032/50176]	Loss: 0.2252
Training Epoch: 57 [45056/50176]	Loss: 0.2161
Training Epoch: 57 [46080/50176]	Loss: 0.1770
Training Epoch: 57 [47104/50176]	Loss: 0.2727
Training Epoch: 57 [48128/50176]	Loss: 0.1851
Training Epoch: 57 [49152/50176]	Loss: 0.2175
Training Epoch: 57 [50176/50176]	Loss: 0.2238
2022-12-09 01:05:59.193 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:05:59,244 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.82 energy=534.75
2022-12-08 20:05:59,245 [ZeusDataLoader(train)] Up to epoch 58: time=2883.64, energy=425906.07, cost=465271.60
2022-12-08 20:05:59,245 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:05:59,245 [ZeusDataLoader(train)] Expected next epoch: time=2930.84, energy=433141.57, cost=473018.99
2022-12-08 20:05:59,246 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0024, Accuracy: 0.5799
2022-12-08 20:05:59,513 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:05:59,514 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:05:59.516 [ZeusMonitor] Monitor started.
2022-12-09 01:05:59.517 [ZeusMonitor] Running indefinitely. 2022-12-09 01:05:59.517 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:05:59.517 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e59+gpu0.power.log
2022-12-08 20:06:43,494 [ZeusDataLoader(train)] train epoch 59 done: time=44.24 energy=6718.71
2022-12-08 20:06:43,497 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 0.1562
Training Epoch: 58 [2048/50176]	Loss: 0.1753
Training Epoch: 58 [3072/50176]	Loss: 0.2020
Training Epoch: 58 [4096/50176]	Loss: 0.1567
Training Epoch: 58 [5120/50176]	Loss: 0.1483
Training Epoch: 58 [6144/50176]	Loss: 0.1682
Training Epoch: 58 [7168/50176]	Loss: 0.1594
Training Epoch: 58 [8192/50176]	Loss: 0.1571
Training Epoch: 58 [9216/50176]	Loss: 0.1891
Training Epoch: 58 [10240/50176]	Loss: 0.1873
Training Epoch: 58 [11264/50176]	Loss: 0.1633
Training Epoch: 58 [12288/50176]	Loss: 0.1720
Training Epoch: 58 [13312/50176]	Loss: 0.1724
Training Epoch: 58 [14336/50176]	Loss: 0.2131
Training Epoch: 58 [15360/50176]	Loss: 0.1710
Training Epoch: 58 [16384/50176]	Loss: 0.1994
Training Epoch: 58 [17408/50176]	Loss: 0.2131
Training Epoch: 58 [18432/50176]	Loss: 0.1885
Training Epoch: 58 [19456/50176]	Loss: 0.1602
Training Epoch: 58 [20480/50176]	Loss: 0.1618
Training Epoch: 58 [21504/50176]	Loss: 0.1803
Training Epoch: 58 [22528/50176]	Loss: 0.2064
Training Epoch: 58 [23552/50176]	Loss: 0.1775
Training Epoch: 58 [24576/50176]	Loss: 0.1746
Training Epoch: 58 [25600/50176]	Loss: 0.1904
Training Epoch: 58 [26624/50176]	Loss: 0.1690
Training Epoch: 58 [27648/50176]	Loss: 0.2178
Training Epoch: 58 [28672/50176]	Loss: 0.2103
Training Epoch: 58 [29696/50176]	Loss: 0.2022
Training Epoch: 58 [30720/50176]	Loss: 0.1926
Training Epoch: 58 [31744/50176]	Loss: 0.1766
Training Epoch: 58 [32768/50176]	Loss: 0.1615
Training Epoch: 58 [33792/50176]	Loss: 0.2164
Training Epoch: 58 [34816/50176]	Loss: 0.1902
Training Epoch: 58 [35840/50176]	Loss: 0.2096
Training Epoch: 58 [36864/50176]	Loss: 0.1829
Training Epoch: 58 [37888/50176]	Loss: 0.2204
Training Epoch: 58 [38912/50176]	Loss: 0.1855
Training Epoch: 58 [39936/50176]	Loss: 0.2207
Training Epoch: 58 [40960/50176]	Loss: 0.2176
Training Epoch: 58 [41984/50176]	Loss: 0.2027
Training Epoch: 58 [43008/50176]	Loss: 0.2017
Training Epoch: 58 [44032/50176]	Loss: 0.2167
Training Epoch: 58 [45056/50176]	Loss: 0.2250
Training Epoch: 58 [46080/50176]	Loss: 0.2076
Training Epoch: 58 [47104/50176]	Loss: 0.1832
Training Epoch: 58 [48128/50176]	Loss: 0.2210
Training Epoch: 58 [49152/50176]	Loss: 0.2264
Training Epoch: 58 [50176/50176]	Loss: 0.1873
2022-12-09 01:06:47.251 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:06:47,282 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.78 energy=524.46
2022-12-08 20:06:47,282 [ZeusDataLoader(train)] Up to epoch 59: time=2931.66, energy=433149.24, cost=473094.55
2022-12-08 20:06:47,283 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:06:47,283 [ZeusDataLoader(train)] Expected next epoch: time=2978.85, energy=440384.74, cost=480841.95
2022-12-08 20:06:47,284 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0024, Accuracy: 0.5874
2022-12-08 20:06:47,542 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:06:47,543 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:06:47.557 [ZeusMonitor] Monitor started.
2022-12-09 01:06:47.557 [ZeusMonitor] Running indefinitely. 2022-12-09 01:06:47.557 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:06:47.557 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e60+gpu0.power.log
2022-12-08 20:07:31,600 [ZeusDataLoader(train)] train epoch 60 done: time=44.31 energy=6720.69
2022-12-08 20:07:31,604 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 0.1343
Training Epoch: 59 [2048/50176]	Loss: 0.1552
Training Epoch: 59 [3072/50176]	Loss: 0.2013
Training Epoch: 59 [4096/50176]	Loss: 0.1743
Training Epoch: 59 [5120/50176]	Loss: 0.1495
Training Epoch: 59 [6144/50176]	Loss: 0.1734
Training Epoch: 59 [7168/50176]	Loss: 0.1728
Training Epoch: 59 [8192/50176]	Loss: 0.1857
Training Epoch: 59 [9216/50176]	Loss: 0.1817
Training Epoch: 59 [10240/50176]	Loss: 0.1880
Training Epoch: 59 [11264/50176]	Loss: 0.1685
Training Epoch: 59 [12288/50176]	Loss: 0.1914
Training Epoch: 59 [13312/50176]	Loss: 0.1745
Training Epoch: 59 [14336/50176]	Loss: 0.1769
Training Epoch: 59 [15360/50176]	Loss: 0.2072
Training Epoch: 59 [16384/50176]	Loss: 0.1572
Training Epoch: 59 [17408/50176]	Loss: 0.1614
Training Epoch: 59 [18432/50176]	Loss: 0.1823
Training Epoch: 59 [19456/50176]	Loss: 0.1819
Training Epoch: 59 [20480/50176]	Loss: 0.1648
Training Epoch: 59 [21504/50176]	Loss: 0.1730
Training Epoch: 59 [22528/50176]	Loss: 0.1670
Training Epoch: 59 [23552/50176]	Loss: 0.1830
Training Epoch: 59 [24576/50176]	Loss: 0.1846
Training Epoch: 59 [25600/50176]	Loss: 0.1918
Training Epoch: 59 [26624/50176]	Loss: 0.1837
Training Epoch: 59 [27648/50176]	Loss: 0.1887
Training Epoch: 59 [28672/50176]	Loss: 0.1961
Training Epoch: 59 [29696/50176]	Loss: 0.1798
Training Epoch: 59 [30720/50176]	Loss: 0.2106
Training Epoch: 59 [31744/50176]	Loss: 0.1927
Training Epoch: 59 [32768/50176]	Loss: 0.1653
Training Epoch: 59 [33792/50176]	Loss: 0.2027
Training Epoch: 59 [34816/50176]	Loss: 0.1886
Training Epoch: 59 [35840/50176]	Loss: 0.2002
Training Epoch: 59 [36864/50176]	Loss: 0.2589
Training Epoch: 59 [37888/50176]	Loss: 0.1972
Training Epoch: 59 [38912/50176]	Loss: 0.1563
Training Epoch: 59 [39936/50176]	Loss: 0.2047
Training Epoch: 59 [40960/50176]	Loss: 0.1833
Training Epoch: 59 [41984/50176]	Loss: 0.1677
Training Epoch: 59 [43008/50176]	Loss: 0.1900
Training Epoch: 59 [44032/50176]	Loss: 0.2048
Training Epoch: 59 [45056/50176]	Loss: 0.2316
Training Epoch: 59 [46080/50176]	Loss: 0.1914
Training Epoch: 59 [47104/50176]	Loss: 0.1719
Training Epoch: 59 [48128/50176]	Loss: 0.1887
Training Epoch: 59 [49152/50176]	Loss: 0.2050
Training Epoch: 59 [50176/50176]	Loss: 0.1794
2022-12-09 01:07:35.342 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:07:35,365 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.75 energy=516.83
2022-12-08 20:07:35,366 [ZeusDataLoader(train)] Up to epoch 60: time=2979.72, energy=440386.76, cost=480918.60
2022-12-08 20:07:35,366 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:07:35,366 [ZeusDataLoader(train)] Expected next epoch: time=3026.91, energy=447622.26, cost=488666.00
2022-12-08 20:07:35,367 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0023, Accuracy: 0.5981
2022-12-08 20:07:35,586 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:07:35,587 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:07:35.591 [ZeusMonitor] Monitor started.
2022-12-09 01:07:35.591 [ZeusMonitor] Running indefinitely. 2022-12-09 01:07:35.591 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:07:35.591 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e61+gpu0.power.log
2022-12-08 20:08:19,645 [ZeusDataLoader(train)] train epoch 61 done: time=44.27 energy=6739.48
2022-12-08 20:08:19,648 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.1617
Training Epoch: 60 [2048/50176]	Loss: 0.1253
Training Epoch: 60 [3072/50176]	Loss: 0.1610
Training Epoch: 60 [4096/50176]	Loss: 0.1428
Training Epoch: 60 [5120/50176]	Loss: 0.1710
Training Epoch: 60 [6144/50176]	Loss: 0.1673
Training Epoch: 60 [7168/50176]	Loss: 0.1806
Training Epoch: 60 [8192/50176]	Loss: 0.1433
Training Epoch: 60 [9216/50176]	Loss: 0.1539
Training Epoch: 60 [10240/50176]	Loss: 0.1643
Training Epoch: 60 [11264/50176]	Loss: 0.1564
Training Epoch: 60 [12288/50176]	Loss: 0.1822
Training Epoch: 60 [13312/50176]	Loss: 0.1414
Training Epoch: 60 [14336/50176]	Loss: 0.2037
Training Epoch: 60 [15360/50176]	Loss: 0.1677
Training Epoch: 60 [16384/50176]	Loss: 0.1671
Training Epoch: 60 [17408/50176]	Loss: 0.1724
Training Epoch: 60 [18432/50176]	Loss: 0.1477
Training Epoch: 60 [19456/50176]	Loss: 0.1919
Training Epoch: 60 [20480/50176]	Loss: 0.1272
Training Epoch: 60 [21504/50176]	Loss: 0.1696
Training Epoch: 60 [22528/50176]	Loss: 0.1985
Training Epoch: 60 [23552/50176]	Loss: 0.1572
Training Epoch: 60 [24576/50176]	Loss: 0.1722
Training Epoch: 60 [25600/50176]	Loss: 0.1913
Training Epoch: 60 [26624/50176]	Loss: 0.2271
Training Epoch: 60 [27648/50176]	Loss: 0.1726
Training Epoch: 60 [28672/50176]	Loss: 0.1580
Training Epoch: 60 [29696/50176]	Loss: 0.1880
Training Epoch: 60 [30720/50176]	Loss: 0.2152
Training Epoch: 60 [31744/50176]	Loss: 0.1767
Training Epoch: 60 [32768/50176]	Loss: 0.1992
Training Epoch: 60 [33792/50176]	Loss: 0.1862
Training Epoch: 60 [34816/50176]	Loss: 0.1926
Training Epoch: 60 [35840/50176]	Loss: 0.1524
Training Epoch: 60 [36864/50176]	Loss: 0.1976
Training Epoch: 60 [37888/50176]	Loss: 0.1770
Training Epoch: 60 [38912/50176]	Loss: 0.2036
Training Epoch: 60 [39936/50176]	Loss: 0.1772
Training Epoch: 60 [40960/50176]	Loss: 0.1802
Training Epoch: 60 [41984/50176]	Loss: 0.1550
Training Epoch: 60 [43008/50176]	Loss: 0.2045
Training Epoch: 60 [44032/50176]	Loss: 0.1873
Training Epoch: 60 [45056/50176]	Loss: 0.1939
Training Epoch: 60 [46080/50176]	Loss: 0.1819
Training Epoch: 60 [47104/50176]	Loss: 0.1412
Training Epoch: 60 [48128/50176]	Loss: 0.1734
Training Epoch: 60 [49152/50176]	Loss: 0.1966
Training Epoch: 60 [50176/50176]	Loss: 0.1979
2022-12-09 01:08:23.423 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:08:23,433 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.78 energy=522.23
2022-12-08 20:08:23,434 [ZeusDataLoader(train)] Up to epoch 61: time=3027.76, energy=447648.46, cost=488753.39
2022-12-08 20:08:23,434 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:08:23,434 [ZeusDataLoader(train)] Expected next epoch: time=3074.96, energy=454883.96, cost=496500.78
2022-12-08 20:08:23,435 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0023, Accuracy: 0.5889
2022-12-08 20:08:23,647 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:08:23,648 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:08:23.652 [ZeusMonitor] Monitor started.
2022-12-09 01:08:23.652 [ZeusMonitor] Running indefinitely. 2022-12-09 01:08:23.652 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:08:23.652 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e62+gpu0.power.log
2022-12-08 20:09:07,677 [ZeusDataLoader(train)] train epoch 62 done: time=44.23 energy=6727.49
2022-12-08 20:09:07,681 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.1396
Training Epoch: 61 [2048/50176]	Loss: 0.1576
Training Epoch: 61 [3072/50176]	Loss: 0.1390
Training Epoch: 61 [4096/50176]	Loss: 0.1856
Training Epoch: 61 [5120/50176]	Loss: 0.1597
Training Epoch: 61 [6144/50176]	Loss: 0.1703
Training Epoch: 61 [7168/50176]	Loss: 0.1557
Training Epoch: 61 [8192/50176]	Loss: 0.1633
Training Epoch: 61 [9216/50176]	Loss: 0.1472
Training Epoch: 61 [10240/50176]	Loss: 0.1518
Training Epoch: 61 [11264/50176]	Loss: 0.1867
Training Epoch: 61 [12288/50176]	Loss: 0.1431
Training Epoch: 61 [13312/50176]	Loss: 0.1594
Training Epoch: 61 [14336/50176]	Loss: 0.1570
Training Epoch: 61 [15360/50176]	Loss: 0.1640
Training Epoch: 61 [16384/50176]	Loss: 0.1722
Training Epoch: 61 [17408/50176]	Loss: 0.1553
Training Epoch: 61 [18432/50176]	Loss: 0.1663
Training Epoch: 61 [19456/50176]	Loss: 0.1737
Training Epoch: 61 [20480/50176]	Loss: 0.1484
Training Epoch: 61 [21504/50176]	Loss: 0.1790
Training Epoch: 61 [22528/50176]	Loss: 0.1758
Training Epoch: 61 [23552/50176]	Loss: 0.1380
Training Epoch: 61 [24576/50176]	Loss: 0.1643
Training Epoch: 61 [25600/50176]	Loss: 0.1599
Training Epoch: 61 [26624/50176]	Loss: 0.1403
Training Epoch: 61 [27648/50176]	Loss: 0.1767
Training Epoch: 61 [28672/50176]	Loss: 0.1879
Training Epoch: 61 [29696/50176]	Loss: 0.2020
Training Epoch: 61 [30720/50176]	Loss: 0.1463
Training Epoch: 61 [31744/50176]	Loss: 0.1566
Training Epoch: 61 [32768/50176]	Loss: 0.1590
Training Epoch: 61 [33792/50176]	Loss: 0.1748
Training Epoch: 61 [34816/50176]	Loss: 0.1881
Training Epoch: 61 [35840/50176]	Loss: 0.1545
Training Epoch: 61 [36864/50176]	Loss: 0.1960
Training Epoch: 61 [37888/50176]	Loss: 0.1617
Training Epoch: 61 [38912/50176]	Loss: 0.1991
Training Epoch: 61 [39936/50176]	Loss: 0.1493
Training Epoch: 61 [40960/50176]	Loss: 0.1486
Training Epoch: 61 [41984/50176]	Loss: 0.1605
Training Epoch: 61 [43008/50176]	Loss: 0.1627
Training Epoch: 61 [44032/50176]	Loss: 0.1726
Training Epoch: 61 [45056/50176]	Loss: 0.1882
Training Epoch: 61 [46080/50176]	Loss: 0.1574
Training Epoch: 61 [47104/50176]	Loss: 0.1765
Training Epoch: 61 [48128/50176]	Loss: 0.1677
Training Epoch: 61 [49152/50176]	Loss: 0.2183
Training Epoch: 61 [50176/50176]	Loss: 0.1801
2022-12-09 01:09:11.496 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:09:11,534 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.84 energy=529.01
2022-12-08 20:09:11,534 [ZeusDataLoader(train)] Up to epoch 62: time=3075.84, energy=454904.96, cost=496588.47
2022-12-08 20:09:11,534 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:09:11,534 [ZeusDataLoader(train)] Expected next epoch: time=3123.04, energy=462140.46, cost=504335.86
2022-12-08 20:09:11,535 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0025, Accuracy: 0.5828
2022-12-08 20:09:11,745 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:09:11,746 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:09:11.750 [ZeusMonitor] Monitor started.
2022-12-09 01:09:11.750 [ZeusMonitor] Running indefinitely. 2022-12-09 01:09:11.750 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:09:11.750 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e63+gpu0.power.log
2022-12-08 20:09:55,850 [ZeusDataLoader(train)] train epoch 63 done: time=44.31 energy=6749.92
2022-12-08 20:09:55,853 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.1128
Training Epoch: 62 [2048/50176]	Loss: 0.1144
Training Epoch: 62 [3072/50176]	Loss: 0.1467
Training Epoch: 62 [4096/50176]	Loss: 0.1721
Training Epoch: 62 [5120/50176]	Loss: 0.1738
Training Epoch: 62 [6144/50176]	Loss: 0.1762
Training Epoch: 62 [7168/50176]	Loss: 0.1631
Training Epoch: 62 [8192/50176]	Loss: 0.1956
Training Epoch: 62 [9216/50176]	Loss: 0.1212
Training Epoch: 62 [10240/50176]	Loss: 0.1408
Training Epoch: 62 [11264/50176]	Loss: 0.1507
Training Epoch: 62 [12288/50176]	Loss: 0.1587
Training Epoch: 62 [13312/50176]	Loss: 0.1531
Training Epoch: 62 [14336/50176]	Loss: 0.1734
Training Epoch: 62 [15360/50176]	Loss: 0.1614
Training Epoch: 62 [16384/50176]	Loss: 0.1649
Training Epoch: 62 [17408/50176]	Loss: 0.1476
Training Epoch: 62 [18432/50176]	Loss: 0.1494
Training Epoch: 62 [19456/50176]	Loss: 0.1759
Training Epoch: 62 [20480/50176]	Loss: 0.1963
Training Epoch: 62 [21504/50176]	Loss: 0.1572
Training Epoch: 62 [22528/50176]	Loss: 0.1662
Training Epoch: 62 [23552/50176]	Loss: 0.1381
Training Epoch: 62 [24576/50176]	Loss: 0.1486
Training Epoch: 62 [25600/50176]	Loss: 0.1558
Training Epoch: 62 [26624/50176]	Loss: 0.1539
Training Epoch: 62 [27648/50176]	Loss: 0.1794
Training Epoch: 62 [28672/50176]	Loss: 0.1715
Training Epoch: 62 [29696/50176]	Loss: 0.1375
Training Epoch: 62 [30720/50176]	Loss: 0.1633
Training Epoch: 62 [31744/50176]	Loss: 0.1414
Training Epoch: 62 [32768/50176]	Loss: 0.1765
Training Epoch: 62 [33792/50176]	Loss: 0.1699
Training Epoch: 62 [34816/50176]	Loss: 0.1755
Training Epoch: 62 [35840/50176]	Loss: 0.1427
Training Epoch: 62 [36864/50176]	Loss: 0.1671
Training Epoch: 62 [37888/50176]	Loss: 0.1992
Training Epoch: 62 [38912/50176]	Loss: 0.1698
Training Epoch: 62 [39936/50176]	Loss: 0.1605
Training Epoch: 62 [40960/50176]	Loss: 0.1641
Training Epoch: 62 [41984/50176]	Loss: 0.1486
Training Epoch: 62 [43008/50176]	Loss: 0.1681
Training Epoch: 62 [44032/50176]	Loss: 0.1920
Training Epoch: 62 [45056/50176]	Loss: 0.2082
Training Epoch: 62 [46080/50176]	Loss: 0.1794
Training Epoch: 62 [47104/50176]	Loss: 0.2296
Training Epoch: 62 [48128/50176]	Loss: 0.2109
Training Epoch: 62 [49152/50176]	Loss: 0.2218
Training Epoch: 62 [50176/50176]	Loss: 0.2191
2022-12-09 01:09:59.618 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:09:59,647 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.79 energy=526.96
2022-12-08 20:09:59,647 [ZeusDataLoader(train)] Up to epoch 63: time=3123.93, energy=462181.83, cost=504434.93
2022-12-08 20:09:59,647 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.20 energy=7235.50
2022-12-08 20:09:59,647 [ZeusDataLoader(train)] Expected next epoch: time=3171.13, energy=469417.33, cost=512182.32
2022-12-08 20:09:59,648 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0025, Accuracy: 0.5931
2022-12-08 20:09:59,857 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 20:09:59,858 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-09 01:09:59.862 [ZeusMonitor] Monitor started.
2022-12-09 01:09:59.862 [ZeusMonitor] Running indefinitely. 2022-12-09 01:09:59.862 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-09 01:09:59.862 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e64+gpu0.power.log
2022-12-08 20:10:43,826 [ZeusDataLoader(train)] train epoch 64 done: time=44.17 energy=6714.67
2022-12-08 20:10:43,831 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 0.1368
Training Epoch: 63 [2048/50176]	Loss: 0.1693
Training Epoch: 63 [3072/50176]	Loss: 0.1489
Training Epoch: 63 [4096/50176]	Loss: 0.1676
Training Epoch: 63 [5120/50176]	Loss: 0.1626
Training Epoch: 63 [6144/50176]	Loss: 0.1670
Training Epoch: 63 [7168/50176]	Loss: 0.1951
Training Epoch: 63 [8192/50176]	Loss: 0.1398
Training Epoch: 63 [9216/50176]	Loss: 0.1292
Training Epoch: 63 [10240/50176]	Loss: 0.1779
Training Epoch: 63 [11264/50176]	Loss: 0.1504
Training Epoch: 63 [12288/50176]	Loss: 0.1776
Training Epoch: 63 [13312/50176]	Loss: 0.1522
Training Epoch: 63 [14336/50176]	Loss: 0.1665
Training Epoch: 63 [15360/50176]	Loss: 0.1652
Training Epoch: 63 [16384/50176]	Loss: 0.1644
Training Epoch: 63 [17408/50176]	Loss: 0.1235
Training Epoch: 63 [18432/50176]	Loss: 0.1395
Training Epoch: 63 [19456/50176]	Loss: 0.1736
Training Epoch: 63 [20480/50176]	Loss: 0.1532
Training Epoch: 63 [21504/50176]	Loss: 0.2225
Training Epoch: 63 [22528/50176]	Loss: 0.1670
Training Epoch: 63 [23552/50176]	Loss: 0.1582
Training Epoch: 63 [24576/50176]	Loss: 0.1541
Training Epoch: 63 [25600/50176]	Loss: 0.1681
Training Epoch: 63 [26624/50176]	Loss: 0.1516
Training Epoch: 63 [27648/50176]	Loss: 0.1557
Training Epoch: 63 [28672/50176]	Loss: 0.1466
Training Epoch: 63 [29696/50176]	Loss: 0.1665
Training Epoch: 63 [30720/50176]	Loss: 0.1553
Training Epoch: 63 [31744/50176]	Loss: 0.1797
Training Epoch: 63 [32768/50176]	Loss: 0.1913
Training Epoch: 63 [33792/50176]	Loss: 0.1519
Training Epoch: 63 [34816/50176]	Loss: 0.1538
Training Epoch: 63 [35840/50176]	Loss: 0.1888
Training Epoch: 63 [36864/50176]	Loss: 0.1752
Training Epoch: 63 [37888/50176]	Loss: 0.1592
Training Epoch: 63 [38912/50176]	Loss: 0.2015
Training Epoch: 63 [39936/50176]	Loss: 0.1749
Training Epoch: 63 [40960/50176]	Loss: 0.1564
Training Epoch: 63 [41984/50176]	Loss: 0.1876
Training Epoch: 63 [43008/50176]	Loss: 0.1735
Training Epoch: 63 [44032/50176]	Loss: 0.1537
Training Epoch: 63 [45056/50176]	Loss: 0.1486
Training Epoch: 63 [46080/50176]	Loss: 0.1679
Training Epoch: 63 [47104/50176]	Loss: 0.1626
Training Epoch: 63 [48128/50176]	Loss: 0.1795
Training Epoch: 63 [49152/50176]	Loss: 0.2030
Training Epoch: 63 [50176/50176]	Loss: 0.1870
2022-12-09 01:10:47.623 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 20:10:47,637 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.80 energy=531.20
2022-12-08 20:10:47,637 [ZeusDataLoader(train)] Up to epoch 64: time=3171.90, energy=469427.70, cost=512254.88
2022-12-08 20:10:47,637 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-08 20:10:47,637 [ZeusDataLoader(train)] Training done.
2022-12-08 20:10:47,637 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec03+try01+bs1024+lr0.0090000.train.json: {"energy": 469427.69630999834, "time": 3171.8975488980213, "cost": 512254.883683576, "num_epochs": 64, "reached": true}
Validation Epoch: 63, Average loss: 0.0024, Accuracy: 0.6050

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 469427.69630999834, 'time': 3171.8975488980213, 'cost': 512254.883683576, 'num_epochs': 64, 'reached': True}
[run job; power] power_stats={'job_id': 'rec03+try01', 'train_power': {'175000': 154.6792462130222, '150000': 146.55796781873008, '125000': 122.92324634463641, '100000': 101.76930623787774}, 'train_throughput': {'175000': 1.1273475383617806, '150000': 1.0998245343207829, '125000': 0.9685367142449868, '100000': 0.3625758461971825}, 'eval_power': {'175000': 137.33036751551163, '150000': 130.83428207217395, '125000': 114.04092551113034}, 'eval_throughput': {'175000': 2.6801964520231563, '150000': 2.577116501549166, '125000': 2.3213637893790264}, 'optimal_pl': 175000}
[Zeus Master] cost=512254.883683576

[Zeus Master] Reached target metric in 1 try.
[Zeus Master]
[HistoryEntry(bs=1024, pl=175.0, lr=0.006, energy=245090.3820494143, reached=True, time=1682.810654917026), HistoryEntry(bs=1024, pl=175.0, lr=0.007, energy=244904.68639563024, reached=True, time=1681.7110675940203), HistoryEntry(bs=1024, pl=175.0, lr=0.008, energy=361245.8512208044, reached=True, time=2453.759384225974), HistoryEntry(bs=1024, pl=175.0, lr=0.009, energy=469427.69630999834, reached=True, time=3171.8975488980213)]
