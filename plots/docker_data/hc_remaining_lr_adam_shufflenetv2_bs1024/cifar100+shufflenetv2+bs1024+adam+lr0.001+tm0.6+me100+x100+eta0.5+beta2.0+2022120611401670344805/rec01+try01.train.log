2022-12-06 12:09:21,875 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 12:09:21,875 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 12:09:21,875 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 12:09:21,917 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 12:09:21,918 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 12:09:24,032 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 12:09:24,033 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 12:09:24,195 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:09:24.200 [ZeusMonitor] Monitor started.
2022-12-06 17:09:24.200 [ZeusMonitor] Running indefinitely. 2022-12-06 17:09:24.200 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:09:24.200 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 12:09:24,925 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 12:09:24,925 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 12:09:33,807 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 12:10:07,551 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 12:10:09,198 [ZeusDataLoader(train)] train epoch 1 done: time=45.16 energy=6329.31
2022-12-06 12:10:09,202 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 7.2692
Training Epoch: 0 [3072/50176]	Loss: 5.6022
Training Epoch: 0 [4096/50176]	Loss: 4.9331
Training Epoch: 0 [5120/50176]	Loss: 4.8748
Training Epoch: 0 [6144/50176]	Loss: 4.7699
Training Epoch: 0 [7168/50176]	Loss: 4.7535
Training Epoch: 0 [8192/50176]	Loss: 4.6976
Training Epoch: 0 [9216/50176]	Loss: 6.0939
Training Epoch: 0 [10240/50176]	Loss: 4.7540
Training Epoch: 0 [11264/50176]	Loss: 4.8019
Training Epoch: 0 [12288/50176]	Loss: 4.7126
Training Epoch: 0 [13312/50176]	Loss: 4.7030
Training Epoch: 0 [14336/50176]	Loss: 4.7404
Training Epoch: 0 [15360/50176]	Loss: 4.6252
Training Epoch: 0 [16384/50176]	Loss: 4.5980
Training Epoch: 0 [17408/50176]	Loss: 4.5968
Training Epoch: 0 [18432/50176]	Loss: 4.6040
Training Epoch: 0 [19456/50176]	Loss: 4.5735
Training Epoch: 0 [20480/50176]	Loss: 4.5946
Training Epoch: 0 [21504/50176]	Loss: 4.5663
Training Epoch: 0 [22528/50176]	Loss: 4.5823
Training Epoch: 0 [23552/50176]	Loss: 4.6223
Training Epoch: 0 [24576/50176]	Loss: 4.5538
Training Epoch: 0 [25600/50176]	Loss: 4.6158
Training Epoch: 0 [26624/50176]	Loss: 4.5745
Training Epoch: 0 [27648/50176]	Loss: 4.5322
Training Epoch: 0 [28672/50176]	Loss: 4.5393
Training Epoch: 0 [29696/50176]	Loss: 4.5451
Training Epoch: 0 [30720/50176]	Loss: 4.6034
Training Epoch: 0 [31744/50176]	Loss: 4.5339
Training Epoch: 0 [32768/50176]	Loss: 4.5171
Training Epoch: 0 [33792/50176]	Loss: 4.5396
Training Epoch: 0 [34816/50176]	Loss: 4.4955
Training Epoch: 0 [35840/50176]	Loss: 4.4758
Training Epoch: 0 [36864/50176]	Loss: 4.4761
Training Epoch: 0 [37888/50176]	Loss: 4.4962
Training Epoch: 0 [38912/50176]	Loss: 4.4688
Training Epoch: 0 [39936/50176]	Loss: 4.4904
Training Epoch: 0 [40960/50176]	Loss: 4.4454
Training Epoch: 0 [41984/50176]	Loss: 4.4555
Training Epoch: 0 [43008/50176]	Loss: 4.4633
Training Epoch: 0 [44032/50176]	Loss: 4.4330
Training Epoch: 0 [45056/50176]	Loss: 4.4490
Training Epoch: 0 [46080/50176]	Loss: 4.3958
Training Epoch: 0 [47104/50176]	Loss: 4.4271
Training Epoch: 0 [48128/50176]	Loss: 4.4233
Training Epoch: 0 [49152/50176]	Loss: 4.4203
Training Epoch: 0 [50176/50176]	Loss: 4.4098
2022-12-06 17:10:12.936 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:10:12,959 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.75 energy=474.15
2022-12-06 12:10:12,960 [ZeusDataLoader(train)] Up to epoch 1: time=48.91, energy=6803.46, cost=7681.25
2022-12-06 12:10:12,961 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0044, Accuracy: 0.0208
2022-12-06 12:10:13,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:10:13.188 [ZeusMonitor] Monitor started.
2022-12-06 17:10:13.188 [ZeusMonitor] Running indefinitely. 2022-12-06 17:10:13.188 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:10:13.188 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 12:10:13,907 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 12:10:13,908 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 12:10:21,951 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 12:10:56,252 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 12:10:57,914 [ZeusDataLoader(train)] train epoch 2 done: time=44.95 energy=6269.74
2022-12-06 12:10:57,917 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.4206
Training Epoch: 1 [2048/50176]	Loss: 4.3597
Training Epoch: 1 [3072/50176]	Loss: 4.4074
Training Epoch: 1 [4096/50176]	Loss: 4.3957
Training Epoch: 1 [5120/50176]	Loss: 4.3885
Training Epoch: 1 [6144/50176]	Loss: 4.3978
Training Epoch: 1 [7168/50176]	Loss: 4.3665
Training Epoch: 1 [8192/50176]	Loss: 4.3558
Training Epoch: 1 [9216/50176]	Loss: 4.3997
Training Epoch: 1 [10240/50176]	Loss: 4.3638
Training Epoch: 1 [11264/50176]	Loss: 4.3951
Training Epoch: 1 [12288/50176]	Loss: 4.3481
Training Epoch: 1 [13312/50176]	Loss: 4.3574
Training Epoch: 1 [14336/50176]	Loss: 4.3475
Training Epoch: 1 [15360/50176]	Loss: 4.3612
Training Epoch: 1 [16384/50176]	Loss: 4.3866
Training Epoch: 1 [17408/50176]	Loss: 4.3490
Training Epoch: 1 [18432/50176]	Loss: 4.3175
Training Epoch: 1 [19456/50176]	Loss: 4.3592
Training Epoch: 1 [20480/50176]	Loss: 4.3259
Training Epoch: 1 [21504/50176]	Loss: 4.3268
Training Epoch: 1 [22528/50176]	Loss: 4.2630
Training Epoch: 1 [23552/50176]	Loss: 4.2728
Training Epoch: 1 [24576/50176]	Loss: 4.2490
Training Epoch: 1 [25600/50176]	Loss: 4.2440
Training Epoch: 1 [26624/50176]	Loss: 4.2493
Training Epoch: 1 [27648/50176]	Loss: 4.2505
Training Epoch: 1 [28672/50176]	Loss: 4.1914
Training Epoch: 1 [29696/50176]	Loss: 4.2678
Training Epoch: 1 [30720/50176]	Loss: 4.1900
Training Epoch: 1 [31744/50176]	Loss: 4.1840
Training Epoch: 1 [32768/50176]	Loss: 4.1085
Training Epoch: 1 [33792/50176]	Loss: 4.1977
Training Epoch: 1 [34816/50176]	Loss: 4.1752
Training Epoch: 1 [35840/50176]	Loss: 4.1762
Training Epoch: 1 [36864/50176]	Loss: 4.1379
Training Epoch: 1 [37888/50176]	Loss: 4.1030
Training Epoch: 1 [38912/50176]	Loss: 4.1017
Training Epoch: 1 [39936/50176]	Loss: 4.1324
Training Epoch: 1 [40960/50176]	Loss: 4.1361
Training Epoch: 1 [41984/50176]	Loss: 4.0830
Training Epoch: 1 [43008/50176]	Loss: 4.1022
Training Epoch: 1 [44032/50176]	Loss: 4.0581
Training Epoch: 1 [45056/50176]	Loss: 4.0717
Training Epoch: 1 [46080/50176]	Loss: 4.0283
Training Epoch: 1 [47104/50176]	Loss: 4.0752
Training Epoch: 1 [48128/50176]	Loss: 4.0251
Training Epoch: 1 [49152/50176]	Loss: 4.0677
Training Epoch: 1 [50176/50176]	Loss: 4.0660
2022-12-06 17:11:01.714 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:11:01,725 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.80 energy=482.02
2022-12-06 12:11:01,726 [ZeusDataLoader(train)] Up to epoch 2: time=97.66, energy=13555.22, cost=15322.52
2022-12-06 12:11:01,727 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0040, Accuracy: 0.0612
2022-12-06 12:11:01,903 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:11:01.907 [ZeusMonitor] Monitor started.
2022-12-06 17:11:01.907 [ZeusMonitor] Running indefinitely. 2022-12-06 17:11:01.907 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:11:01.907 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 12:11:02,638 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 12:11:02,638 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 12:11:11,383 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 12:11:47,886 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 12:11:49,694 [ZeusDataLoader(train)] train epoch 3 done: time=47.96 energy=5780.10
2022-12-06 12:11:49,698 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.9860
Training Epoch: 2 [2048/50176]	Loss: 4.0120
Training Epoch: 2 [3072/50176]	Loss: 4.0145
Training Epoch: 2 [4096/50176]	Loss: 3.9428
Training Epoch: 2 [5120/50176]	Loss: 3.9130
Training Epoch: 2 [6144/50176]	Loss: 3.9444
Training Epoch: 2 [7168/50176]	Loss: 3.9718
Training Epoch: 2 [8192/50176]	Loss: 4.0064
Training Epoch: 2 [9216/50176]	Loss: 3.9571
Training Epoch: 2 [10240/50176]	Loss: 3.8709
Training Epoch: 2 [11264/50176]	Loss: 3.9006
Training Epoch: 2 [12288/50176]	Loss: 3.8673
Training Epoch: 2 [13312/50176]	Loss: 3.8502
Training Epoch: 2 [14336/50176]	Loss: 3.8913
Training Epoch: 2 [15360/50176]	Loss: 3.9196
Training Epoch: 2 [16384/50176]	Loss: 3.9275
Training Epoch: 2 [17408/50176]	Loss: 3.9013
Training Epoch: 2 [18432/50176]	Loss: 3.9064
Training Epoch: 2 [19456/50176]	Loss: 3.8495
Training Epoch: 2 [20480/50176]	Loss: 3.8284
Training Epoch: 2 [21504/50176]	Loss: 3.8676
Training Epoch: 2 [22528/50176]	Loss: 3.8507
Training Epoch: 2 [23552/50176]	Loss: 3.8168
Training Epoch: 2 [24576/50176]	Loss: 3.9065
Training Epoch: 2 [25600/50176]	Loss: 3.8170
Training Epoch: 2 [26624/50176]	Loss: 3.8557
Training Epoch: 2 [27648/50176]	Loss: 3.8866
Training Epoch: 2 [28672/50176]	Loss: 3.8435
Training Epoch: 2 [29696/50176]	Loss: 3.7705
Training Epoch: 2 [30720/50176]	Loss: 3.7920
Training Epoch: 2 [31744/50176]	Loss: 3.7892
Training Epoch: 2 [32768/50176]	Loss: 3.8199
Training Epoch: 2 [33792/50176]	Loss: 3.8603
Training Epoch: 2 [34816/50176]	Loss: 3.8123
Training Epoch: 2 [35840/50176]	Loss: 3.7628
Training Epoch: 2 [36864/50176]	Loss: 3.8079
Training Epoch: 2 [37888/50176]	Loss: 3.8364
Training Epoch: 2 [38912/50176]	Loss: 3.7307
Training Epoch: 2 [39936/50176]	Loss: 3.7242
Training Epoch: 2 [40960/50176]	Loss: 3.7236
Training Epoch: 2 [41984/50176]	Loss: 3.7694
Training Epoch: 2 [43008/50176]	Loss: 3.7270
Training Epoch: 2 [44032/50176]	Loss: 3.6796
Training Epoch: 2 [45056/50176]	Loss: 3.7254
Training Epoch: 2 [46080/50176]	Loss: 3.7040
Training Epoch: 2 [47104/50176]	Loss: 3.6844
Training Epoch: 2 [48128/50176]	Loss: 3.6713
Training Epoch: 2 [49152/50176]	Loss: 3.7302
Training Epoch: 2 [50176/50176]	Loss: 3.6374
2022-12-06 17:11:53.654 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:11:53,698 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.99 energy=461.68
2022-12-06 12:11:53,699 [ZeusDataLoader(train)] Up to epoch 3: time=149.61, energy=19797.00, cost=22989.34
2022-12-06 12:11:53,700 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0037, Accuracy: 0.1043
2022-12-06 12:11:53,911 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:11:53.914 [ZeusMonitor] Monitor started.
2022-12-06 17:11:53.914 [ZeusMonitor] Running indefinitely. 2022-12-06 17:11:53.914 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:11:53.914 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 12:11:54,610 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 12:11:54,610 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 12:12:10,035 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 12:13:20,075 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 12:13:20,076 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 12:13:20,076 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-06 12:13:20,079 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 12:13:21,866 [ZeusDataLoader(train)] train epoch 4 done: time=88.16 energy=8474.45
2022-12-06 12:13:21,869 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.5898
Training Epoch: 3 [2048/50176]	Loss: 3.5782
Training Epoch: 3 [3072/50176]	Loss: 3.6088
Training Epoch: 3 [4096/50176]	Loss: 3.6489
Training Epoch: 3 [5120/50176]	Loss: 3.6305
Training Epoch: 3 [6144/50176]	Loss: 3.5934
Training Epoch: 3 [7168/50176]	Loss: 3.6376
Training Epoch: 3 [8192/50176]	Loss: 3.6216
Training Epoch: 3 [9216/50176]	Loss: 3.5688
Training Epoch: 3 [10240/50176]	Loss: 3.6138
Training Epoch: 3 [11264/50176]	Loss: 3.5711
Training Epoch: 3 [12288/50176]	Loss: 3.5699
Training Epoch: 3 [13312/50176]	Loss: 3.6157
Training Epoch: 3 [14336/50176]	Loss: 3.5746
Training Epoch: 3 [15360/50176]	Loss: 3.5611
Training Epoch: 3 [16384/50176]	Loss: 3.6028
Training Epoch: 3 [17408/50176]	Loss: 3.5473
Training Epoch: 3 [18432/50176]	Loss: 3.5954
Training Epoch: 3 [19456/50176]	Loss: 3.5702
Training Epoch: 3 [20480/50176]	Loss: 3.4948
Training Epoch: 3 [21504/50176]	Loss: 3.5583
Training Epoch: 3 [22528/50176]	Loss: 3.4890
Training Epoch: 3 [23552/50176]	Loss: 3.5185
Training Epoch: 3 [24576/50176]	Loss: 3.5230
Training Epoch: 3 [25600/50176]	Loss: 3.4276
Training Epoch: 3 [26624/50176]	Loss: 3.5901
Training Epoch: 3 [27648/50176]	Loss: 3.5446
Training Epoch: 3 [28672/50176]	Loss: 3.5117
Training Epoch: 3 [29696/50176]	Loss: 3.4826
Training Epoch: 3 [30720/50176]	Loss: 3.5333
Training Epoch: 3 [31744/50176]	Loss: 3.5222
Training Epoch: 3 [32768/50176]	Loss: 3.4988
Training Epoch: 3 [33792/50176]	Loss: 3.3969
Training Epoch: 3 [34816/50176]	Loss: 3.4941
Training Epoch: 3 [35840/50176]	Loss: 3.4454
Training Epoch: 3 [36864/50176]	Loss: 3.4631
Training Epoch: 3 [37888/50176]	Loss: 3.5453
Training Epoch: 3 [38912/50176]	Loss: 3.4574
Training Epoch: 3 [39936/50176]	Loss: 3.4790
Training Epoch: 3 [40960/50176]	Loss: 3.3878
Training Epoch: 3 [41984/50176]	Loss: 3.4546
Training Epoch: 3 [43008/50176]	Loss: 3.3320
Training Epoch: 3 [44032/50176]	Loss: 3.3597
Training Epoch: 3 [45056/50176]	Loss: 3.3600
Training Epoch: 3 [46080/50176]	Loss: 3.4297
Training Epoch: 3 [47104/50176]	Loss: 3.3444
Training Epoch: 3 [48128/50176]	Loss: 3.5252
Training Epoch: 3 [49152/50176]	Loss: 3.3710
Training Epoch: 3 [50176/50176]	Loss: 3.3911
2022-12-06 17:13:25.636 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0100000.power.json: {"job_id": "rec01+try01", "train_power": {"175000": 144.87586386206175, "150000": 142.4413747226752, "125000": 122.47472127317002, "100000": 96.50525059382247}, "train_throughput": {"175000": 1.1265477788311575, "150000": 1.1081640906025203, "125000": 1.0413129456183774, "100000": 0.5426340296975655}, "eval_power": {"175000": 127.69507531813454, "150000": 126.8275325321136, "125000": 115.63754995827681}, "eval_throughput": {"175000": 2.6466800540332938, "150000": 2.6311429884394997, "125000": 2.5047197850078424}, "optimal_pl": 175000}
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.78 energy=482.47
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Up to epoch 4: time=241.55, energy=28753.93, cost=35512.24
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Expected next epoch: time=288.82, energy=35537.88, cost=43040.69
2022-12-06 12:13:25,658 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0034, Accuracy: 0.1624
2022-12-06 12:13:25,829 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:13:25,829 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:13:25.833 [ZeusMonitor] Monitor started.
2022-12-06 17:13:25.833 [ZeusMonitor] Running indefinitely. 2022-12-06 17:13:25.833 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:13:25.833 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 12:14:10,047 [ZeusDataLoader(train)] train epoch 5 done: time=44.38 energy=6267.42
2022-12-06 12:14:10,050 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.4063
Training Epoch: 4 [2048/50176]	Loss: 3.3291
Training Epoch: 4 [3072/50176]	Loss: 3.2680
Training Epoch: 4 [4096/50176]	Loss: 3.2868
Training Epoch: 4 [5120/50176]	Loss: 3.3121
Training Epoch: 4 [6144/50176]	Loss: 3.3551
Training Epoch: 4 [7168/50176]	Loss: 3.2978
Training Epoch: 4 [8192/50176]	Loss: 3.3245
Training Epoch: 4 [9216/50176]	Loss: 3.3116
Training Epoch: 4 [10240/50176]	Loss: 3.2891
Training Epoch: 4 [11264/50176]	Loss: 3.3165
Training Epoch: 4 [12288/50176]	Loss: 3.2993
Training Epoch: 4 [13312/50176]	Loss: 3.2531
Training Epoch: 4 [14336/50176]	Loss: 3.3272
Training Epoch: 4 [15360/50176]	Loss: 3.2647
Training Epoch: 4 [16384/50176]	Loss: 3.1280
Training Epoch: 4 [17408/50176]	Loss: 3.2798
Training Epoch: 4 [18432/50176]	Loss: 3.2758
Training Epoch: 4 [19456/50176]	Loss: 3.2626
Training Epoch: 4 [20480/50176]	Loss: 3.2464
Training Epoch: 4 [21504/50176]	Loss: 3.2532
Training Epoch: 4 [22528/50176]	Loss: 3.1895
Training Epoch: 4 [23552/50176]	Loss: 3.1603
Training Epoch: 4 [24576/50176]	Loss: 3.1936
Training Epoch: 4 [25600/50176]	Loss: 3.1511
Training Epoch: 4 [26624/50176]	Loss: 3.1908
Training Epoch: 4 [27648/50176]	Loss: 3.2773
Training Epoch: 4 [28672/50176]	Loss: 3.1804
Training Epoch: 4 [29696/50176]	Loss: 3.2485
Training Epoch: 4 [30720/50176]	Loss: 3.2008
Training Epoch: 4 [31744/50176]	Loss: 3.1834
Training Epoch: 4 [32768/50176]	Loss: 3.2229
Training Epoch: 4 [33792/50176]	Loss: 3.1853
Training Epoch: 4 [34816/50176]	Loss: 3.1065
Training Epoch: 4 [35840/50176]	Loss: 3.2341
Training Epoch: 4 [36864/50176]	Loss: 3.1485
Training Epoch: 4 [37888/50176]	Loss: 3.2989
Training Epoch: 4 [38912/50176]	Loss: 3.1362
Training Epoch: 4 [39936/50176]	Loss: 3.1439
Training Epoch: 4 [40960/50176]	Loss: 3.1268
Training Epoch: 4 [41984/50176]	Loss: 3.0621
Training Epoch: 4 [43008/50176]	Loss: 3.1125
Training Epoch: 4 [44032/50176]	Loss: 3.0213
Training Epoch: 4 [45056/50176]	Loss: 3.1229
Training Epoch: 4 [46080/50176]	Loss: 3.1625
Training Epoch: 4 [47104/50176]	Loss: 3.1693
Training Epoch: 4 [48128/50176]	Loss: 3.1391
Training Epoch: 4 [49152/50176]	Loss: 3.1140
Training Epoch: 4 [50176/50176]	Loss: 3.1858
2022-12-06 17:14:13.987 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:14:14,017 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.96 energy=490.97
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Up to epoch 5: time=289.89, energy=35512.32, cost=43121.15
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Expected next epoch: time=337.16, energy=42296.27, cost=50649.60
2022-12-06 12:14:14,019 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0032, Accuracy: 0.2041
2022-12-06 12:14:14,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:14:14,238 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:14:14.252 [ZeusMonitor] Monitor started.
2022-12-06 17:14:14.252 [ZeusMonitor] Running indefinitely. 2022-12-06 17:14:14.252 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:14:14.252 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 12:14:58,760 [ZeusDataLoader(train)] train epoch 6 done: time=44.73 energy=6326.94
2022-12-06 12:14:58,763 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.9563
Training Epoch: 5 [2048/50176]	Loss: 3.0004
Training Epoch: 5 [3072/50176]	Loss: 3.0997
Training Epoch: 5 [4096/50176]	Loss: 3.0537
Training Epoch: 5 [5120/50176]	Loss: 3.0336
Training Epoch: 5 [6144/50176]	Loss: 3.0359
Training Epoch: 5 [7168/50176]	Loss: 2.9642
Training Epoch: 5 [8192/50176]	Loss: 2.9951
Training Epoch: 5 [9216/50176]	Loss: 2.9865
Training Epoch: 5 [10240/50176]	Loss: 3.0399
Training Epoch: 5 [11264/50176]	Loss: 3.0934
Training Epoch: 5 [12288/50176]	Loss: 2.8902
Training Epoch: 5 [13312/50176]	Loss: 2.9725
Training Epoch: 5 [14336/50176]	Loss: 2.9433
Training Epoch: 5 [15360/50176]	Loss: 3.0814
Training Epoch: 5 [16384/50176]	Loss: 2.9742
Training Epoch: 5 [17408/50176]	Loss: 3.0131
Training Epoch: 5 [18432/50176]	Loss: 2.9494
Training Epoch: 5 [19456/50176]	Loss: 3.0111
Training Epoch: 5 [20480/50176]	Loss: 2.9507
Training Epoch: 5 [21504/50176]	Loss: 2.9631
Training Epoch: 5 [22528/50176]	Loss: 3.0175
Training Epoch: 5 [23552/50176]	Loss: 3.0109
Training Epoch: 5 [24576/50176]	Loss: 2.9940
Training Epoch: 5 [25600/50176]	Loss: 2.9868
Training Epoch: 5 [26624/50176]	Loss: 2.9075
Training Epoch: 5 [27648/50176]	Loss: 2.9379
Training Epoch: 5 [28672/50176]	Loss: 2.9552
Training Epoch: 5 [29696/50176]	Loss: 2.9199
Training Epoch: 5 [30720/50176]	Loss: 2.8690
Training Epoch: 5 [31744/50176]	Loss: 2.9687
Training Epoch: 5 [32768/50176]	Loss: 2.9600
Training Epoch: 5 [33792/50176]	Loss: 2.8845
Training Epoch: 5 [34816/50176]	Loss: 2.9285
Training Epoch: 5 [35840/50176]	Loss: 3.0645
Training Epoch: 5 [36864/50176]	Loss: 2.8677
Training Epoch: 5 [37888/50176]	Loss: 2.8436
Training Epoch: 5 [38912/50176]	Loss: 2.9040
Training Epoch: 5 [39936/50176]	Loss: 2.9541
Training Epoch: 5 [40960/50176]	Loss: 2.7901
Training Epoch: 5 [41984/50176]	Loss: 2.9610
Training Epoch: 5 [43008/50176]	Loss: 2.8984
Training Epoch: 5 [44032/50176]	Loss: 2.9068
Training Epoch: 5 [45056/50176]	Loss: 2.9729
Training Epoch: 5 [46080/50176]	Loss: 2.8450
Training Epoch: 5 [47104/50176]	Loss: 2.8860
Training Epoch: 5 [48128/50176]	Loss: 2.8550
Training Epoch: 5 [49152/50176]	Loss: 2.9020
Training Epoch: 5 [50176/50176]	Loss: 2.8539
2022-12-06 17:15:02.450 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:15:02,484 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.71 energy=471.46
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Up to epoch 6: time=338.33, energy=42310.71, cost=50759.36
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Expected next epoch: time=385.61, energy=49094.67, cost=58287.82
2022-12-06 12:15:02,485 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0029, Accuracy: 0.2611
2022-12-06 12:15:02,704 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:15:02,704 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:15:02.706 [ZeusMonitor] Monitor started.
2022-12-06 17:15:02.706 [ZeusMonitor] Running indefinitely. 2022-12-06 17:15:02.706 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:15:02.706 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 12:15:46,654 [ZeusDataLoader(train)] train epoch 7 done: time=44.16 energy=6293.87
2022-12-06 12:15:46,658 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.8185
Training Epoch: 6 [2048/50176]	Loss: 2.7465
Training Epoch: 6 [3072/50176]	Loss: 2.8982
Training Epoch: 6 [4096/50176]	Loss: 2.8028
Training Epoch: 6 [5120/50176]	Loss: 2.7192
Training Epoch: 6 [6144/50176]	Loss: 2.7052
Training Epoch: 6 [7168/50176]	Loss: 2.8001
Training Epoch: 6 [8192/50176]	Loss: 2.7520
Training Epoch: 6 [9216/50176]	Loss: 2.9003
Training Epoch: 6 [10240/50176]	Loss: 2.7731
Training Epoch: 6 [11264/50176]	Loss: 2.7315
Training Epoch: 6 [12288/50176]	Loss: 2.8034
Training Epoch: 6 [13312/50176]	Loss: 2.7995
Training Epoch: 6 [14336/50176]	Loss: 2.7677
Training Epoch: 6 [15360/50176]	Loss: 2.6551
Training Epoch: 6 [16384/50176]	Loss: 2.7565
Training Epoch: 6 [17408/50176]	Loss: 2.7130
Training Epoch: 6 [18432/50176]	Loss: 2.7794
Training Epoch: 6 [19456/50176]	Loss: 2.6563
Training Epoch: 6 [20480/50176]	Loss: 2.8020
Training Epoch: 6 [21504/50176]	Loss: 2.8078
Training Epoch: 6 [22528/50176]	Loss: 2.7608
Training Epoch: 6 [23552/50176]	Loss: 2.7170
Training Epoch: 6 [24576/50176]	Loss: 2.7047
Training Epoch: 6 [25600/50176]	Loss: 2.6504
Training Epoch: 6 [26624/50176]	Loss: 2.7095
Training Epoch: 6 [27648/50176]	Loss: 2.7098
Training Epoch: 6 [28672/50176]	Loss: 2.6106
Training Epoch: 6 [29696/50176]	Loss: 2.7183
Training Epoch: 6 [30720/50176]	Loss: 2.7219
Training Epoch: 6 [31744/50176]	Loss: 2.6931
Training Epoch: 6 [32768/50176]	Loss: 2.6702
Training Epoch: 6 [33792/50176]	Loss: 2.7171
Training Epoch: 6 [34816/50176]	Loss: 2.7634
Training Epoch: 6 [35840/50176]	Loss: 2.6162
Training Epoch: 6 [36864/50176]	Loss: 2.7386
Training Epoch: 6 [37888/50176]	Loss: 2.7664
Training Epoch: 6 [38912/50176]	Loss: 2.6960
Training Epoch: 6 [39936/50176]	Loss: 2.6587
Training Epoch: 6 [40960/50176]	Loss: 2.6744
Training Epoch: 6 [41984/50176]	Loss: 2.6731
Training Epoch: 6 [43008/50176]	Loss: 2.6460
Training Epoch: 6 [44032/50176]	Loss: 2.6601
Training Epoch: 6 [45056/50176]	Loss: 2.6809
Training Epoch: 6 [46080/50176]	Loss: 2.7140
Training Epoch: 6 [47104/50176]	Loss: 2.6507
Training Epoch: 6 [48128/50176]	Loss: 2.6781
Training Epoch: 6 [49152/50176]	Loss: 2.6216
Training Epoch: 6 [50176/50176]	Loss: 2.6240
2022-12-06 17:15:50.494 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:15:50,545 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.88 energy=484.94
2022-12-06 12:15:50,545 [ZeusDataLoader(train)] Up to epoch 7: time=386.37, energy=49089.53, cost=58352.39
2022-12-06 12:15:50,546 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:15:50,546 [ZeusDataLoader(train)] Expected next epoch: time=433.65, energy=55873.48, cost=65880.84
2022-12-06 12:15:50,547 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0027, Accuracy: 0.3030
2022-12-06 12:15:50,751 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:15:50,752 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:15:50.756 [ZeusMonitor] Monitor started.
2022-12-06 17:15:50.756 [ZeusMonitor] Running indefinitely. 2022-12-06 17:15:50.756 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:15:50.756 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 12:16:34,554 [ZeusDataLoader(train)] train epoch 8 done: time=44.00 energy=6298.77
2022-12-06 12:16:34,557 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.5663
Training Epoch: 7 [2048/50176]	Loss: 2.5452
Training Epoch: 7 [3072/50176]	Loss: 2.4976
Training Epoch: 7 [4096/50176]	Loss: 2.5012
Training Epoch: 7 [5120/50176]	Loss: 2.5959
Training Epoch: 7 [6144/50176]	Loss: 2.5570
Training Epoch: 7 [7168/50176]	Loss: 2.5030
Training Epoch: 7 [8192/50176]	Loss: 2.4973
Training Epoch: 7 [9216/50176]	Loss: 2.4024
Training Epoch: 7 [10240/50176]	Loss: 2.4930
Training Epoch: 7 [11264/50176]	Loss: 2.4376
Training Epoch: 7 [12288/50176]	Loss: 2.5551
Training Epoch: 7 [13312/50176]	Loss: 2.5035
Training Epoch: 7 [14336/50176]	Loss: 2.6342
Training Epoch: 7 [15360/50176]	Loss: 2.5190
Training Epoch: 7 [16384/50176]	Loss: 2.5171
Training Epoch: 7 [17408/50176]	Loss: 2.5772
Training Epoch: 7 [18432/50176]	Loss: 2.5156
Training Epoch: 7 [19456/50176]	Loss: 2.4943
Training Epoch: 7 [20480/50176]	Loss: 2.5456
Training Epoch: 7 [21504/50176]	Loss: 2.5989
Training Epoch: 7 [22528/50176]	Loss: 2.4611
Training Epoch: 7 [23552/50176]	Loss: 2.5023
Training Epoch: 7 [24576/50176]	Loss: 2.4875
Training Epoch: 7 [25600/50176]	Loss: 2.5689
Training Epoch: 7 [26624/50176]	Loss: 2.5462
Training Epoch: 7 [27648/50176]	Loss: 2.5676
Training Epoch: 7 [28672/50176]	Loss: 2.5178
Training Epoch: 7 [29696/50176]	Loss: 2.5313
Training Epoch: 7 [30720/50176]	Loss: 2.5158
Training Epoch: 7 [31744/50176]	Loss: 2.5748
Training Epoch: 7 [32768/50176]	Loss: 2.3992
Training Epoch: 7 [33792/50176]	Loss: 2.5138
Training Epoch: 7 [34816/50176]	Loss: 2.5655
Training Epoch: 7 [35840/50176]	Loss: 2.4385
Training Epoch: 7 [36864/50176]	Loss: 2.3902
Training Epoch: 7 [37888/50176]	Loss: 2.4096
Training Epoch: 7 [38912/50176]	Loss: 2.4930
Training Epoch: 7 [39936/50176]	Loss: 2.5838
Training Epoch: 7 [40960/50176]	Loss: 2.5435
Training Epoch: 7 [41984/50176]	Loss: 2.3495
Training Epoch: 7 [43008/50176]	Loss: 2.3500
Training Epoch: 7 [44032/50176]	Loss: 2.3898
Training Epoch: 7 [45056/50176]	Loss: 2.4684
Training Epoch: 7 [46080/50176]	Loss: 2.4580
Training Epoch: 7 [47104/50176]	Loss: 2.4149
Training Epoch: 7 [48128/50176]	Loss: 2.3975
Training Epoch: 7 [49152/50176]	Loss: 2.4992
Training Epoch: 7 [50176/50176]	Loss: 2.4142
2022-12-06 17:16:38.317 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:16:38,343 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.78 energy=497.03
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Up to epoch 8: time=434.15, energy=55885.32, cost=65930.83
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Expected next epoch: time=481.42, energy=62669.28, cost=73459.28
2022-12-06 12:16:38,345 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0026, Accuracy: 0.3319
2022-12-06 12:16:38,557 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:16:38,557 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:16:38.559 [ZeusMonitor] Monitor started.
2022-12-06 17:16:38.559 [ZeusMonitor] Running indefinitely. 2022-12-06 17:16:38.559 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:16:38.559 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 12:17:22,831 [ZeusDataLoader(train)] train epoch 9 done: time=44.48 energy=6323.16
2022-12-06 12:17:22,834 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.4281
Training Epoch: 8 [2048/50176]	Loss: 2.3750
Training Epoch: 8 [3072/50176]	Loss: 2.3843
Training Epoch: 8 [4096/50176]	Loss: 2.3391
Training Epoch: 8 [5120/50176]	Loss: 2.2565
Training Epoch: 8 [6144/50176]	Loss: 2.2765
Training Epoch: 8 [7168/50176]	Loss: 2.3832
Training Epoch: 8 [8192/50176]	Loss: 2.3403
Training Epoch: 8 [9216/50176]	Loss: 2.3341
Training Epoch: 8 [10240/50176]	Loss: 2.3709
Training Epoch: 8 [11264/50176]	Loss: 2.3045
Training Epoch: 8 [12288/50176]	Loss: 2.3570
Training Epoch: 8 [13312/50176]	Loss: 2.3069
Training Epoch: 8 [14336/50176]	Loss: 2.3074
Training Epoch: 8 [15360/50176]	Loss: 2.4284
Training Epoch: 8 [16384/50176]	Loss: 2.2933
Training Epoch: 8 [17408/50176]	Loss: 2.3808
Training Epoch: 8 [18432/50176]	Loss: 2.3371
Training Epoch: 8 [19456/50176]	Loss: 2.3092
Training Epoch: 8 [20480/50176]	Loss: 2.2576
Training Epoch: 8 [21504/50176]	Loss: 2.3173
Training Epoch: 8 [22528/50176]	Loss: 2.3282
Training Epoch: 8 [23552/50176]	Loss: 2.3205
Training Epoch: 8 [24576/50176]	Loss: 2.3669
Training Epoch: 8 [25600/50176]	Loss: 2.3500
Training Epoch: 8 [26624/50176]	Loss: 2.3100
Training Epoch: 8 [27648/50176]	Loss: 2.2753
Training Epoch: 8 [28672/50176]	Loss: 2.3639
Training Epoch: 8 [29696/50176]	Loss: 2.3575
Training Epoch: 8 [30720/50176]	Loss: 2.2945
Training Epoch: 8 [31744/50176]	Loss: 2.2453
Training Epoch: 8 [32768/50176]	Loss: 2.2806
Training Epoch: 8 [33792/50176]	Loss: 2.4170
Training Epoch: 8 [34816/50176]	Loss: 2.3555
Training Epoch: 8 [35840/50176]	Loss: 2.3208
Training Epoch: 8 [36864/50176]	Loss: 2.2858
Training Epoch: 8 [37888/50176]	Loss: 2.3639
Training Epoch: 8 [38912/50176]	Loss: 2.2992
Training Epoch: 8 [39936/50176]	Loss: 2.4305
Training Epoch: 8 [40960/50176]	Loss: 2.2885
Training Epoch: 8 [41984/50176]	Loss: 2.3272
Training Epoch: 8 [43008/50176]	Loss: 2.3280
Training Epoch: 8 [44032/50176]	Loss: 2.3825
Training Epoch: 8 [45056/50176]	Loss: 2.3085
Training Epoch: 8 [46080/50176]	Loss: 2.2659
Training Epoch: 8 [47104/50176]	Loss: 2.3571
Training Epoch: 8 [48128/50176]	Loss: 2.2323
Training Epoch: 8 [49152/50176]	Loss: 2.2745
Training Epoch: 8 [50176/50176]	Loss: 2.3027
2022-12-06 17:17:26.560 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:17:26,586 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.74 energy=476.52
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Up to epoch 9: time=482.37, energy=62685.00, cost=73550.06
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Expected next epoch: time=529.65, energy=69468.96, cost=81078.52
2022-12-06 12:17:26,587 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0026, Accuracy: 0.3223
2022-12-06 12:17:26,808 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:17:26,809 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:17:26.818 [ZeusMonitor] Monitor started.
2022-12-06 17:17:26.818 [ZeusMonitor] Running indefinitely. 2022-12-06 17:17:26.818 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:17:26.818 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 12:18:11,270 [ZeusDataLoader(train)] train epoch 10 done: time=44.68 energy=6337.35
2022-12-06 12:18:11,274 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.2287
Training Epoch: 9 [2048/50176]	Loss: 2.2523
Training Epoch: 9 [3072/50176]	Loss: 2.2677
Training Epoch: 9 [4096/50176]	Loss: 2.1733
Training Epoch: 9 [5120/50176]	Loss: 2.3190
Training Epoch: 9 [6144/50176]	Loss: 2.1331
Training Epoch: 9 [7168/50176]	Loss: 2.2534
Training Epoch: 9 [8192/50176]	Loss: 2.2401
Training Epoch: 9 [9216/50176]	Loss: 2.1990
Training Epoch: 9 [10240/50176]	Loss: 2.2031
Training Epoch: 9 [11264/50176]	Loss: 2.3334
Training Epoch: 9 [12288/50176]	Loss: 2.1999
Training Epoch: 9 [13312/50176]	Loss: 2.1831
Training Epoch: 9 [14336/50176]	Loss: 2.2271
Training Epoch: 9 [15360/50176]	Loss: 2.2267
Training Epoch: 9 [16384/50176]	Loss: 2.2671
Training Epoch: 9 [17408/50176]	Loss: 2.1582
Training Epoch: 9 [18432/50176]	Loss: 2.2571
Training Epoch: 9 [19456/50176]	Loss: 2.1318
Training Epoch: 9 [20480/50176]	Loss: 2.2247
Training Epoch: 9 [21504/50176]	Loss: 2.2025
Training Epoch: 9 [22528/50176]	Loss: 2.1423
Training Epoch: 9 [23552/50176]	Loss: 2.1025
Training Epoch: 9 [24576/50176]	Loss: 2.1989
Training Epoch: 9 [25600/50176]	Loss: 2.1434
Training Epoch: 9 [26624/50176]	Loss: 2.1264
Training Epoch: 9 [27648/50176]	Loss: 2.2443
Training Epoch: 9 [28672/50176]	Loss: 2.2014
Training Epoch: 9 [29696/50176]	Loss: 2.2252
Training Epoch: 9 [30720/50176]	Loss: 2.1381
Training Epoch: 9 [31744/50176]	Loss: 2.2467
Training Epoch: 9 [32768/50176]	Loss: 2.1739
Training Epoch: 9 [33792/50176]	Loss: 2.1305
Training Epoch: 9 [34816/50176]	Loss: 2.2283
Training Epoch: 9 [35840/50176]	Loss: 2.1375
Training Epoch: 9 [36864/50176]	Loss: 2.1650
Training Epoch: 9 [37888/50176]	Loss: 2.1888
Training Epoch: 9 [38912/50176]	Loss: 2.2058
Training Epoch: 9 [39936/50176]	Loss: 2.1524
Training Epoch: 9 [40960/50176]	Loss: 2.2251
Training Epoch: 9 [41984/50176]	Loss: 2.1151
Training Epoch: 9 [43008/50176]	Loss: 2.2090
Training Epoch: 9 [44032/50176]	Loss: 2.1456
Training Epoch: 9 [45056/50176]	Loss: 2.0714
Training Epoch: 9 [46080/50176]	Loss: 2.1271
Training Epoch: 9 [47104/50176]	Loss: 2.1614
Training Epoch: 9 [48128/50176]	Loss: 2.0812
Training Epoch: 9 [49152/50176]	Loss: 2.1337
Training Epoch: 9 [50176/50176]	Loss: 2.0916
2022-12-06 17:18:15.095 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:18:15,120 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.84 energy=480.79
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Up to epoch 10: time=530.89, energy=69503.14, cost=81204.16
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Expected next epoch: time=578.16, energy=76287.09, cost=88732.61
2022-12-06 12:18:15,122 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0023, Accuracy: 0.3846
2022-12-06 12:18:15,293 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:18:15,293 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:18:15.295 [ZeusMonitor] Monitor started.
2022-12-06 17:18:15.295 [ZeusMonitor] Running indefinitely. 2022-12-06 17:18:15.295 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:18:15.295 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 12:18:59,673 [ZeusDataLoader(train)] train epoch 11 done: time=44.54 energy=6336.49
2022-12-06 12:18:59,676 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 2.0917
Training Epoch: 10 [2048/50176]	Loss: 2.0795
Training Epoch: 10 [3072/50176]	Loss: 2.0594
Training Epoch: 10 [4096/50176]	Loss: 2.1435
Training Epoch: 10 [5120/50176]	Loss: 2.0145
Training Epoch: 10 [6144/50176]	Loss: 2.1191
Training Epoch: 10 [7168/50176]	Loss: 2.0136
Training Epoch: 10 [8192/50176]	Loss: 2.0503
Training Epoch: 10 [9216/50176]	Loss: 2.0048
Training Epoch: 10 [10240/50176]	Loss: 1.9905
Training Epoch: 10 [11264/50176]	Loss: 2.1351
Training Epoch: 10 [12288/50176]	Loss: 2.0282
Training Epoch: 10 [13312/50176]	Loss: 2.1514
Training Epoch: 10 [14336/50176]	Loss: 2.1062
Training Epoch: 10 [15360/50176]	Loss: 2.0974
Training Epoch: 10 [16384/50176]	Loss: 2.1347
Training Epoch: 10 [17408/50176]	Loss: 2.1656
Training Epoch: 10 [18432/50176]	Loss: 2.0226
Training Epoch: 10 [19456/50176]	Loss: 2.0883
Training Epoch: 10 [20480/50176]	Loss: 2.0313
Training Epoch: 10 [21504/50176]	Loss: 2.0950
Training Epoch: 10 [22528/50176]	Loss: 2.0829
Training Epoch: 10 [23552/50176]	Loss: 1.9970
Training Epoch: 10 [24576/50176]	Loss: 2.0823
Training Epoch: 10 [25600/50176]	Loss: 2.0383
Training Epoch: 10 [26624/50176]	Loss: 2.0121
Training Epoch: 10 [27648/50176]	Loss: 2.0150
Training Epoch: 10 [28672/50176]	Loss: 2.1179
Training Epoch: 10 [29696/50176]	Loss: 2.1646
Training Epoch: 10 [30720/50176]	Loss: 1.9454
Training Epoch: 10 [31744/50176]	Loss: 2.0789
Training Epoch: 10 [32768/50176]	Loss: 2.0106
Training Epoch: 10 [33792/50176]	Loss: 2.0403
Training Epoch: 10 [34816/50176]	Loss: 2.0756
Training Epoch: 10 [35840/50176]	Loss: 2.1561
Training Epoch: 10 [36864/50176]	Loss: 2.0566
Training Epoch: 10 [37888/50176]	Loss: 1.9118
Training Epoch: 10 [38912/50176]	Loss: 2.0055
Training Epoch: 10 [39936/50176]	Loss: 2.1302
Training Epoch: 10 [40960/50176]	Loss: 1.9503
Training Epoch: 10 [41984/50176]	Loss: 1.9544
Training Epoch: 10 [43008/50176]	Loss: 2.0519
Training Epoch: 10 [44032/50176]	Loss: 2.0581
Training Epoch: 10 [45056/50176]	Loss: 1.9546
Training Epoch: 10 [46080/50176]	Loss: 1.9045
Training Epoch: 10 [47104/50176]	Loss: 2.0222
Training Epoch: 10 [48128/50176]	Loss: 2.0152
Training Epoch: 10 [49152/50176]	Loss: 2.0692
Training Epoch: 10 [50176/50176]	Loss: 2.0204
2022-12-06 17:19:03.418 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:19:03,466 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.78 energy=490.67
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Up to epoch 11: time=579.21, energy=76330.30, cost=88846.16
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Expected next epoch: time=626.49, energy=83114.25, cost=96374.61
2022-12-06 12:19:03,467 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0023, Accuracy: 0.4015
2022-12-06 12:19:03,628 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:19:03,629 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:19:03.632 [ZeusMonitor] Monitor started.
2022-12-06 17:19:03.632 [ZeusMonitor] Running indefinitely. 2022-12-06 17:19:03.632 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:19:03.632 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 12:19:47,750 [ZeusDataLoader(train)] train epoch 12 done: time=44.28 energy=6313.32
2022-12-06 12:19:47,753 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.8688
Training Epoch: 11 [2048/50176]	Loss: 1.9038
Training Epoch: 11 [3072/50176]	Loss: 1.9000
Training Epoch: 11 [4096/50176]	Loss: 2.0402
Training Epoch: 11 [5120/50176]	Loss: 2.0050
Training Epoch: 11 [6144/50176]	Loss: 1.8311
Training Epoch: 11 [7168/50176]	Loss: 1.8619
Training Epoch: 11 [8192/50176]	Loss: 1.9308
Training Epoch: 11 [9216/50176]	Loss: 1.9030
Training Epoch: 11 [10240/50176]	Loss: 1.9810
Training Epoch: 11 [11264/50176]	Loss: 1.9220
Training Epoch: 11 [12288/50176]	Loss: 1.8937
Training Epoch: 11 [13312/50176]	Loss: 2.0175
Training Epoch: 11 [14336/50176]	Loss: 1.8756
Training Epoch: 11 [15360/50176]	Loss: 1.9712
Training Epoch: 11 [16384/50176]	Loss: 1.9270
Training Epoch: 11 [17408/50176]	Loss: 1.9132
Training Epoch: 11 [18432/50176]	Loss: 1.9387
Training Epoch: 11 [19456/50176]	Loss: 1.8664
Training Epoch: 11 [20480/50176]	Loss: 1.9995
Training Epoch: 11 [21504/50176]	Loss: 1.9793
Training Epoch: 11 [22528/50176]	Loss: 1.9397
Training Epoch: 11 [23552/50176]	Loss: 2.0041
Training Epoch: 11 [24576/50176]	Loss: 1.8828
Training Epoch: 11 [25600/50176]	Loss: 1.9853
Training Epoch: 11 [26624/50176]	Loss: 1.8593
Training Epoch: 11 [27648/50176]	Loss: 1.9564
Training Epoch: 11 [28672/50176]	Loss: 1.9347
Training Epoch: 11 [29696/50176]	Loss: 1.9862
Training Epoch: 11 [30720/50176]	Loss: 1.9167
Training Epoch: 11 [31744/50176]	Loss: 1.9175
Training Epoch: 11 [32768/50176]	Loss: 1.9712
Training Epoch: 11 [33792/50176]	Loss: 1.9995
Training Epoch: 11 [34816/50176]	Loss: 2.0363
Training Epoch: 11 [35840/50176]	Loss: 2.0060
Training Epoch: 11 [36864/50176]	Loss: 1.9395
Training Epoch: 11 [37888/50176]	Loss: 1.9913
Training Epoch: 11 [38912/50176]	Loss: 1.9509
Training Epoch: 11 [39936/50176]	Loss: 1.9142
Training Epoch: 11 [40960/50176]	Loss: 1.8913
Training Epoch: 11 [41984/50176]	Loss: 1.9372
Training Epoch: 11 [43008/50176]	Loss: 2.0099
Training Epoch: 11 [44032/50176]	Loss: 1.8974
Training Epoch: 11 [45056/50176]	Loss: 2.0069
Training Epoch: 11 [46080/50176]	Loss: 1.8288
Training Epoch: 11 [47104/50176]	Loss: 1.9613
Training Epoch: 11 [48128/50176]	Loss: 1.8786
Training Epoch: 11 [49152/50176]	Loss: 1.8754
Training Epoch: 11 [50176/50176]	Loss: 1.9650
2022-12-06 17:19:51.467 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:19:51,498 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.74 energy=476.42
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Up to epoch 12: time=627.22, energy=83120.03, cost=96442.06
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Expected next epoch: time=674.50, energy=89903.98, cost=103970.51
2022-12-06 12:19:51,499 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0021, Accuracy: 0.4262
2022-12-06 12:19:51,746 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:19:51,747 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:19:51.748 [ZeusMonitor] Monitor started.
2022-12-06 17:19:51.749 [ZeusMonitor] Running indefinitely. 2022-12-06 17:19:51.749 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:19:51.749 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 12:20:35,665 [ZeusDataLoader(train)] train epoch 13 done: time=44.16 energy=6309.46
2022-12-06 12:20:35,668 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.8662
Training Epoch: 12 [2048/50176]	Loss: 1.8275
Training Epoch: 12 [3072/50176]	Loss: 1.8527
Training Epoch: 12 [4096/50176]	Loss: 1.8066
Training Epoch: 12 [5120/50176]	Loss: 1.7771
Training Epoch: 12 [6144/50176]	Loss: 1.8289
Training Epoch: 12 [7168/50176]	Loss: 1.9264
Training Epoch: 12 [8192/50176]	Loss: 1.7563
Training Epoch: 12 [9216/50176]	Loss: 1.8826
Training Epoch: 12 [10240/50176]	Loss: 1.8332
Training Epoch: 12 [11264/50176]	Loss: 1.9429
Training Epoch: 12 [12288/50176]	Loss: 1.8065
Training Epoch: 12 [13312/50176]	Loss: 1.7846
Training Epoch: 12 [14336/50176]	Loss: 1.8621
Training Epoch: 12 [15360/50176]	Loss: 1.7384
Training Epoch: 12 [16384/50176]	Loss: 1.8213
Training Epoch: 12 [17408/50176]	Loss: 1.8196
Training Epoch: 12 [18432/50176]	Loss: 1.8189
Training Epoch: 12 [19456/50176]	Loss: 1.7886
Training Epoch: 12 [20480/50176]	Loss: 1.8489
Training Epoch: 12 [21504/50176]	Loss: 1.9132
Training Epoch: 12 [22528/50176]	Loss: 1.7593
Training Epoch: 12 [23552/50176]	Loss: 1.8886
Training Epoch: 12 [24576/50176]	Loss: 1.7315
Training Epoch: 12 [25600/50176]	Loss: 1.8976
Training Epoch: 12 [26624/50176]	Loss: 1.9768
Training Epoch: 12 [27648/50176]	Loss: 1.8368
Training Epoch: 12 [28672/50176]	Loss: 1.8679
Training Epoch: 12 [29696/50176]	Loss: 1.8054
Training Epoch: 12 [30720/50176]	Loss: 1.8332
Training Epoch: 12 [31744/50176]	Loss: 1.8256
Training Epoch: 12 [32768/50176]	Loss: 1.8722
Training Epoch: 12 [33792/50176]	Loss: 1.7943
Training Epoch: 12 [34816/50176]	Loss: 1.7928
Training Epoch: 12 [35840/50176]	Loss: 1.7722
Training Epoch: 12 [36864/50176]	Loss: 1.8557
Training Epoch: 12 [37888/50176]	Loss: 1.8925
Training Epoch: 12 [38912/50176]	Loss: 1.7479
Training Epoch: 12 [39936/50176]	Loss: 1.8688
Training Epoch: 12 [40960/50176]	Loss: 1.7744
Training Epoch: 12 [41984/50176]	Loss: 1.9149
Training Epoch: 12 [43008/50176]	Loss: 1.8340
Training Epoch: 12 [44032/50176]	Loss: 1.9044
Training Epoch: 12 [45056/50176]	Loss: 1.7615
Training Epoch: 12 [46080/50176]	Loss: 1.8684
Training Epoch: 12 [47104/50176]	Loss: 1.7826
Training Epoch: 12 [48128/50176]	Loss: 1.7692
Training Epoch: 12 [49152/50176]	Loss: 1.8565
Training Epoch: 12 [50176/50176]	Loss: 1.7421
2022-12-06 17:20:39.432 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:20:39,454 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.78 energy=485.12
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Up to epoch 13: time=675.16, energy=89914.61, cost=104033.74
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Expected next epoch: time=722.43, energy=96698.56, cost=111562.19
2022-12-06 12:20:39,456 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0021, Accuracy: 0.4374
2022-12-06 12:20:39,677 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:20:39,678 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:20:39.680 [ZeusMonitor] Monitor started.
2022-12-06 17:20:39.680 [ZeusMonitor] Running indefinitely. 2022-12-06 17:20:39.680 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:20:39.680 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 12:21:23,966 [ZeusDataLoader(train)] train epoch 14 done: time=44.50 energy=6329.56
2022-12-06 12:21:23,969 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.6987
Training Epoch: 13 [2048/50176]	Loss: 1.7216
Training Epoch: 13 [3072/50176]	Loss: 1.7560
Training Epoch: 13 [4096/50176]	Loss: 1.6326
Training Epoch: 13 [5120/50176]	Loss: 1.7207
Training Epoch: 13 [6144/50176]	Loss: 1.7851
Training Epoch: 13 [7168/50176]	Loss: 1.7168
Training Epoch: 13 [8192/50176]	Loss: 1.7408
Training Epoch: 13 [9216/50176]	Loss: 1.6817
Training Epoch: 13 [10240/50176]	Loss: 1.8625
Training Epoch: 13 [11264/50176]	Loss: 1.6766
Training Epoch: 13 [12288/50176]	Loss: 1.7282
Training Epoch: 13 [13312/50176]	Loss: 1.7259
Training Epoch: 13 [14336/50176]	Loss: 1.7044
Training Epoch: 13 [15360/50176]	Loss: 1.7584
Training Epoch: 13 [16384/50176]	Loss: 1.7374
Training Epoch: 13 [17408/50176]	Loss: 1.7378
Training Epoch: 13 [18432/50176]	Loss: 1.6743
Training Epoch: 13 [19456/50176]	Loss: 1.7813
Training Epoch: 13 [20480/50176]	Loss: 1.7286
Training Epoch: 13 [21504/50176]	Loss: 1.6766
Training Epoch: 13 [22528/50176]	Loss: 1.6548
Training Epoch: 13 [23552/50176]	Loss: 1.7288
Training Epoch: 13 [24576/50176]	Loss: 1.6669
Training Epoch: 13 [25600/50176]	Loss: 1.7599
Training Epoch: 13 [26624/50176]	Loss: 1.8227
Training Epoch: 13 [27648/50176]	Loss: 1.6803
Training Epoch: 13 [28672/50176]	Loss: 1.7358
Training Epoch: 13 [29696/50176]	Loss: 1.7344
Training Epoch: 13 [30720/50176]	Loss: 1.7102
Training Epoch: 13 [31744/50176]	Loss: 1.7661
Training Epoch: 13 [32768/50176]	Loss: 1.6381
Training Epoch: 13 [33792/50176]	Loss: 1.7578
Training Epoch: 13 [34816/50176]	Loss: 1.8114
Training Epoch: 13 [35840/50176]	Loss: 1.8153
Training Epoch: 13 [36864/50176]	Loss: 1.6912
Training Epoch: 13 [37888/50176]	Loss: 1.8238
Training Epoch: 13 [38912/50176]	Loss: 1.6229
Training Epoch: 13 [39936/50176]	Loss: 1.7063
Training Epoch: 13 [40960/50176]	Loss: 1.7405
Training Epoch: 13 [41984/50176]	Loss: 1.7626
Training Epoch: 13 [43008/50176]	Loss: 1.6197
Training Epoch: 13 [44032/50176]	Loss: 1.7909
Training Epoch: 13 [45056/50176]	Loss: 1.7180
Training Epoch: 13 [46080/50176]	Loss: 1.6965
Training Epoch: 13 [47104/50176]	Loss: 1.7364
Training Epoch: 13 [48128/50176]	Loss: 1.7411
Training Epoch: 13 [49152/50176]	Loss: 1.6521
Training Epoch: 13 [50176/50176]	Loss: 1.7830
2022-12-06 17:21:27.782 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:21:27,804 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.83 energy=488.05
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Up to epoch 14: time=723.49, energy=96732.23, cost=111671.27
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Expected next epoch: time=770.76, energy=103516.18, cost=119199.72
2022-12-06 12:21:27,805 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0019, Accuracy: 0.4712
2022-12-06 12:21:28,015 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:21:28,016 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:21:28.017 [ZeusMonitor] Monitor started.
2022-12-06 17:21:28.018 [ZeusMonitor] Running indefinitely. 2022-12-06 17:21:28.018 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:21:28.018 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 12:22:12,380 [ZeusDataLoader(train)] train epoch 15 done: time=44.57 energy=6337.73
2022-12-06 12:22:12,384 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.5892
Training Epoch: 14 [2048/50176]	Loss: 1.6590
Training Epoch: 14 [3072/50176]	Loss: 1.6605
Training Epoch: 14 [4096/50176]	Loss: 1.7317
Training Epoch: 14 [5120/50176]	Loss: 1.5602
Training Epoch: 14 [6144/50176]	Loss: 1.6604
Training Epoch: 14 [7168/50176]	Loss: 1.5634
Training Epoch: 14 [8192/50176]	Loss: 1.6242
Training Epoch: 14 [9216/50176]	Loss: 1.5893
Training Epoch: 14 [10240/50176]	Loss: 1.6165
Training Epoch: 14 [11264/50176]	Loss: 1.6025
Training Epoch: 14 [12288/50176]	Loss: 1.6964
Training Epoch: 14 [13312/50176]	Loss: 1.6635
Training Epoch: 14 [14336/50176]	Loss: 1.5946
Training Epoch: 14 [15360/50176]	Loss: 1.6152
Training Epoch: 14 [16384/50176]	Loss: 1.5429
Training Epoch: 14 [17408/50176]	Loss: 1.6715
Training Epoch: 14 [18432/50176]	Loss: 1.6502
Training Epoch: 14 [19456/50176]	Loss: 1.6417
Training Epoch: 14 [20480/50176]	Loss: 1.6677
Training Epoch: 14 [21504/50176]	Loss: 1.6437
Training Epoch: 14 [22528/50176]	Loss: 1.6022
Training Epoch: 14 [23552/50176]	Loss: 1.6784
Training Epoch: 14 [24576/50176]	Loss: 1.7006
Training Epoch: 14 [25600/50176]	Loss: 1.7566
Training Epoch: 14 [26624/50176]	Loss: 1.5873
Training Epoch: 14 [27648/50176]	Loss: 1.6062
Training Epoch: 14 [28672/50176]	Loss: 1.7189
Training Epoch: 14 [29696/50176]	Loss: 1.6130
Training Epoch: 14 [30720/50176]	Loss: 1.6523
Training Epoch: 14 [31744/50176]	Loss: 1.6231
Training Epoch: 14 [32768/50176]	Loss: 1.7701
Training Epoch: 14 [33792/50176]	Loss: 1.7180
Training Epoch: 14 [34816/50176]	Loss: 1.6605
Training Epoch: 14 [35840/50176]	Loss: 1.6641
Training Epoch: 14 [36864/50176]	Loss: 1.7503
Training Epoch: 14 [37888/50176]	Loss: 1.6544
Training Epoch: 14 [38912/50176]	Loss: 1.7287
Training Epoch: 14 [39936/50176]	Loss: 1.6775
Training Epoch: 14 [40960/50176]	Loss: 1.6670
Training Epoch: 14 [41984/50176]	Loss: 1.7811
Training Epoch: 14 [43008/50176]	Loss: 1.6810
Training Epoch: 14 [44032/50176]	Loss: 1.6709
Training Epoch: 14 [45056/50176]	Loss: 1.6844
Training Epoch: 14 [46080/50176]	Loss: 1.6261
Training Epoch: 14 [47104/50176]	Loss: 1.5781
Training Epoch: 14 [48128/50176]	Loss: 1.6281
Training Epoch: 14 [49152/50176]	Loss: 1.6692
Training Epoch: 14 [50176/50176]	Loss: 1.6262
2022-12-06 17:22:16.125 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:22:16,158 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.77 energy=478.38
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Up to epoch 15: time=771.82, energy=103548.34, cost=119308.52
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Expected next epoch: time=819.10, energy=110332.29, cost=126836.97
2022-12-06 12:22:16,159 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0020, Accuracy: 0.4678
2022-12-06 12:22:16,378 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:22:16,378 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:22:16.380 [ZeusMonitor] Monitor started.
2022-12-06 17:22:16.380 [ZeusMonitor] Running indefinitely. 2022-12-06 17:22:16.380 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:22:16.380 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 12:23:00,379 [ZeusDataLoader(train)] train epoch 16 done: time=44.21 energy=6314.42
2022-12-06 12:23:00,383 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.6161
Training Epoch: 15 [2048/50176]	Loss: 1.5174
Training Epoch: 15 [3072/50176]	Loss: 1.5690
Training Epoch: 15 [4096/50176]	Loss: 1.5410
Training Epoch: 15 [5120/50176]	Loss: 1.5181
Training Epoch: 15 [6144/50176]	Loss: 1.5746
Training Epoch: 15 [7168/50176]	Loss: 1.5144
Training Epoch: 15 [8192/50176]	Loss: 1.6135
Training Epoch: 15 [9216/50176]	Loss: 1.5513
Training Epoch: 15 [10240/50176]	Loss: 1.5135
Training Epoch: 15 [11264/50176]	Loss: 1.5328
Training Epoch: 15 [12288/50176]	Loss: 1.6070
Training Epoch: 15 [13312/50176]	Loss: 1.5138
Training Epoch: 15 [14336/50176]	Loss: 1.5350
Training Epoch: 15 [15360/50176]	Loss: 1.5721
Training Epoch: 15 [16384/50176]	Loss: 1.6241
Training Epoch: 15 [17408/50176]	Loss: 1.5904
Training Epoch: 15 [18432/50176]	Loss: 1.5718
Training Epoch: 15 [19456/50176]	Loss: 1.5307
Training Epoch: 15 [20480/50176]	Loss: 1.5145
Training Epoch: 15 [21504/50176]	Loss: 1.5243
Training Epoch: 15 [22528/50176]	Loss: 1.6972
Training Epoch: 15 [23552/50176]	Loss: 1.6019
Training Epoch: 15 [24576/50176]	Loss: 1.5317
Training Epoch: 15 [25600/50176]	Loss: 1.5904
Training Epoch: 15 [26624/50176]	Loss: 1.5974
Training Epoch: 15 [27648/50176]	Loss: 1.6379
Training Epoch: 15 [28672/50176]	Loss: 1.5241
Training Epoch: 15 [29696/50176]	Loss: 1.5950
Training Epoch: 15 [30720/50176]	Loss: 1.5554
Training Epoch: 15 [31744/50176]	Loss: 1.6451
Training Epoch: 15 [32768/50176]	Loss: 1.5650
Training Epoch: 15 [33792/50176]	Loss: 1.5290
Training Epoch: 15 [34816/50176]	Loss: 1.6832
Training Epoch: 15 [35840/50176]	Loss: 1.6097
Training Epoch: 15 [36864/50176]	Loss: 1.5249
Training Epoch: 15 [37888/50176]	Loss: 1.5858
Training Epoch: 15 [38912/50176]	Loss: 1.5055
Training Epoch: 15 [39936/50176]	Loss: 1.5726
Training Epoch: 15 [40960/50176]	Loss: 1.6268
Training Epoch: 15 [41984/50176]	Loss: 1.6205
Training Epoch: 15 [43008/50176]	Loss: 1.6191
Training Epoch: 15 [44032/50176]	Loss: 1.5865
Training Epoch: 15 [45056/50176]	Loss: 1.5088
Training Epoch: 15 [46080/50176]	Loss: 1.5788
Training Epoch: 15 [47104/50176]	Loss: 1.5359
Training Epoch: 15 [48128/50176]	Loss: 1.6329
Training Epoch: 15 [49152/50176]	Loss: 1.5076
Training Epoch: 15 [50176/50176]	Loss: 1.5567
2022-12-06 17:23:04.137 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:23:04,185 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.79 energy=477.40
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Up to epoch 16: time=819.83, energy=110340.16, cost=126905.00
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Expected next epoch: time=867.10, energy=117124.11, cost=134433.46
2022-12-06 12:23:04,187 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0018, Accuracy: 0.4964
2022-12-06 12:23:04,346 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:23:04,347 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:23:04.350 [ZeusMonitor] Monitor started.
2022-12-06 17:23:04.351 [ZeusMonitor] Running indefinitely. 2022-12-06 17:23:04.351 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:23:04.351 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 12:23:48,562 [ZeusDataLoader(train)] train epoch 17 done: time=44.37 energy=6324.15
2022-12-06 12:23:48,565 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.4721
Training Epoch: 16 [2048/50176]	Loss: 1.4755
Training Epoch: 16 [3072/50176]	Loss: 1.5033
Training Epoch: 16 [4096/50176]	Loss: 1.4711
Training Epoch: 16 [5120/50176]	Loss: 1.4875
Training Epoch: 16 [6144/50176]	Loss: 1.4559
Training Epoch: 16 [7168/50176]	Loss: 1.4783
Training Epoch: 16 [8192/50176]	Loss: 1.3940
Training Epoch: 16 [9216/50176]	Loss: 1.4604
Training Epoch: 16 [10240/50176]	Loss: 1.3689
Training Epoch: 16 [11264/50176]	Loss: 1.5578
Training Epoch: 16 [12288/50176]	Loss: 1.4800
Training Epoch: 16 [13312/50176]	Loss: 1.5174
Training Epoch: 16 [14336/50176]	Loss: 1.5315
Training Epoch: 16 [15360/50176]	Loss: 1.5048
Training Epoch: 16 [16384/50176]	Loss: 1.4848
Training Epoch: 16 [17408/50176]	Loss: 1.4348
Training Epoch: 16 [18432/50176]	Loss: 1.6198
Training Epoch: 16 [19456/50176]	Loss: 1.5043
Training Epoch: 16 [20480/50176]	Loss: 1.4669
Training Epoch: 16 [21504/50176]	Loss: 1.4312
Training Epoch: 16 [22528/50176]	Loss: 1.4729
Training Epoch: 16 [23552/50176]	Loss: 1.5206
Training Epoch: 16 [24576/50176]	Loss: 1.5003
Training Epoch: 16 [25600/50176]	Loss: 1.5064
Training Epoch: 16 [26624/50176]	Loss: 1.4474
Training Epoch: 16 [27648/50176]	Loss: 1.5253
Training Epoch: 16 [28672/50176]	Loss: 1.5310
Training Epoch: 16 [29696/50176]	Loss: 1.4339
Training Epoch: 16 [30720/50176]	Loss: 1.4333
Training Epoch: 16 [31744/50176]	Loss: 1.4652
Training Epoch: 16 [32768/50176]	Loss: 1.5342
Training Epoch: 16 [33792/50176]	Loss: 1.4703
Training Epoch: 16 [34816/50176]	Loss: 1.4510
Training Epoch: 16 [35840/50176]	Loss: 1.5104
Training Epoch: 16 [36864/50176]	Loss: 1.5347
Training Epoch: 16 [37888/50176]	Loss: 1.4285
Training Epoch: 16 [38912/50176]	Loss: 1.4851
Training Epoch: 16 [39936/50176]	Loss: 1.5755
Training Epoch: 16 [40960/50176]	Loss: 1.4905
Training Epoch: 16 [41984/50176]	Loss: 1.4935
Training Epoch: 16 [43008/50176]	Loss: 1.4622
Training Epoch: 16 [44032/50176]	Loss: 1.5616
Training Epoch: 16 [45056/50176]	Loss: 1.5976
Training Epoch: 16 [46080/50176]	Loss: 1.5192
Training Epoch: 16 [47104/50176]	Loss: 1.5097
Training Epoch: 16 [48128/50176]	Loss: 1.5630
Training Epoch: 16 [49152/50176]	Loss: 1.6030
Training Epoch: 16 [50176/50176]	Loss: 1.4910
2022-12-06 17:23:52.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:23:52,487 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.91 energy=495.88
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Up to epoch 17: time=868.11, energy=117160.20, cost=134539.65
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Expected next epoch: time=915.38, energy=123944.15, cost=142068.10
2022-12-06 12:23:52,489 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0020, Accuracy: 0.4662
2022-12-06 12:23:52,685 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:23:52,686 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:23:52.700 [ZeusMonitor] Monitor started.
2022-12-06 17:23:52.700 [ZeusMonitor] Running indefinitely. 2022-12-06 17:23:52.700 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:23:52.700 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 12:24:36,935 [ZeusDataLoader(train)] train epoch 18 done: time=44.44 energy=6341.68
2022-12-06 12:24:36,939 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.4255
Training Epoch: 17 [2048/50176]	Loss: 1.3598
Training Epoch: 17 [3072/50176]	Loss: 1.3233
Training Epoch: 17 [4096/50176]	Loss: 1.3227
Training Epoch: 17 [5120/50176]	Loss: 1.5097
Training Epoch: 17 [6144/50176]	Loss: 1.4093
Training Epoch: 17 [7168/50176]	Loss: 1.3709
Training Epoch: 17 [8192/50176]	Loss: 1.3838
Training Epoch: 17 [9216/50176]	Loss: 1.4566
Training Epoch: 17 [10240/50176]	Loss: 1.3478
Training Epoch: 17 [11264/50176]	Loss: 1.3549
Training Epoch: 17 [12288/50176]	Loss: 1.4301
Training Epoch: 17 [13312/50176]	Loss: 1.3816
Training Epoch: 17 [14336/50176]	Loss: 1.4598
Training Epoch: 17 [15360/50176]	Loss: 1.4220
Training Epoch: 17 [16384/50176]	Loss: 1.3602
Training Epoch: 17 [17408/50176]	Loss: 1.5045
Training Epoch: 17 [18432/50176]	Loss: 1.4824
Training Epoch: 17 [19456/50176]	Loss: 1.3710
Training Epoch: 17 [20480/50176]	Loss: 1.3743
Training Epoch: 17 [21504/50176]	Loss: 1.4305
Training Epoch: 17 [22528/50176]	Loss: 1.4982
Training Epoch: 17 [23552/50176]	Loss: 1.5032
Training Epoch: 17 [24576/50176]	Loss: 1.4799
Training Epoch: 17 [25600/50176]	Loss: 1.4613
Training Epoch: 17 [26624/50176]	Loss: 1.3846
Training Epoch: 17 [27648/50176]	Loss: 1.3867
Training Epoch: 17 [28672/50176]	Loss: 1.5114
Training Epoch: 17 [29696/50176]	Loss: 1.5027
Training Epoch: 17 [30720/50176]	Loss: 1.5582
Training Epoch: 17 [31744/50176]	Loss: 1.4242
Training Epoch: 17 [32768/50176]	Loss: 1.4519
Training Epoch: 17 [33792/50176]	Loss: 1.5351
Training Epoch: 17 [34816/50176]	Loss: 1.4471
Training Epoch: 17 [35840/50176]	Loss: 1.3507
Training Epoch: 17 [36864/50176]	Loss: 1.4899
Training Epoch: 17 [37888/50176]	Loss: 1.4001
Training Epoch: 17 [38912/50176]	Loss: 1.5100
Training Epoch: 17 [39936/50176]	Loss: 1.5389
Training Epoch: 17 [40960/50176]	Loss: 1.4190
Training Epoch: 17 [41984/50176]	Loss: 1.4908
Training Epoch: 17 [43008/50176]	Loss: 1.4581
Training Epoch: 17 [44032/50176]	Loss: 1.5039
Training Epoch: 17 [45056/50176]	Loss: 1.4491
Training Epoch: 17 [46080/50176]	Loss: 1.3803
Training Epoch: 17 [47104/50176]	Loss: 1.3579
Training Epoch: 17 [48128/50176]	Loss: 1.4598
Training Epoch: 17 [49152/50176]	Loss: 1.4796
Training Epoch: 17 [50176/50176]	Loss: 1.4096
2022-12-06 17:24:40.720 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:24:40,747 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.80 energy=492.47
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Up to epoch 18: time=916.35, energy=123994.35, cost=142177.59
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Expected next epoch: time=963.62, energy=130778.30, cost=149706.05
2022-12-06 12:24:40,749 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0017, Accuracy: 0.5153
2022-12-06 12:24:40,958 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:24:40,958 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:24:40.968 [ZeusMonitor] Monitor started.
2022-12-06 17:24:40.968 [ZeusMonitor] Running indefinitely. 2022-12-06 17:24:40.968 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:24:40.968 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 12:25:25,186 [ZeusDataLoader(train)] train epoch 19 done: time=44.43 energy=6326.57
2022-12-06 12:25:25,190 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.2747
Training Epoch: 18 [2048/50176]	Loss: 1.3536
Training Epoch: 18 [3072/50176]	Loss: 1.3736
Training Epoch: 18 [4096/50176]	Loss: 1.2906
Training Epoch: 18 [5120/50176]	Loss: 1.3456
Training Epoch: 18 [6144/50176]	Loss: 1.3660
Training Epoch: 18 [7168/50176]	Loss: 1.3025
Training Epoch: 18 [8192/50176]	Loss: 1.3470
Training Epoch: 18 [9216/50176]	Loss: 1.3200
Training Epoch: 18 [10240/50176]	Loss: 1.3174
Training Epoch: 18 [11264/50176]	Loss: 1.3480
Training Epoch: 18 [12288/50176]	Loss: 1.3294
Training Epoch: 18 [13312/50176]	Loss: 1.3815
Training Epoch: 18 [14336/50176]	Loss: 1.3424
Training Epoch: 18 [15360/50176]	Loss: 1.4091
Training Epoch: 18 [16384/50176]	Loss: 1.3833
Training Epoch: 18 [17408/50176]	Loss: 1.4272
Training Epoch: 18 [18432/50176]	Loss: 1.4172
Training Epoch: 18 [19456/50176]	Loss: 1.4182
Training Epoch: 18 [20480/50176]	Loss: 1.3548
Training Epoch: 18 [21504/50176]	Loss: 1.4219
Training Epoch: 18 [22528/50176]	Loss: 1.4015
Training Epoch: 18 [23552/50176]	Loss: 1.3032
Training Epoch: 18 [24576/50176]	Loss: 1.3380
Training Epoch: 18 [25600/50176]	Loss: 1.3070
Training Epoch: 18 [26624/50176]	Loss: 1.2694
Training Epoch: 18 [27648/50176]	Loss: 1.4035
Training Epoch: 18 [28672/50176]	Loss: 1.4074
Training Epoch: 18 [29696/50176]	Loss: 1.4040
Training Epoch: 18 [30720/50176]	Loss: 1.4381
Training Epoch: 18 [31744/50176]	Loss: 1.4630
Training Epoch: 18 [32768/50176]	Loss: 1.3922
Training Epoch: 18 [33792/50176]	Loss: 1.4161
Training Epoch: 18 [34816/50176]	Loss: 1.3998
Training Epoch: 18 [35840/50176]	Loss: 1.4767
Training Epoch: 18 [36864/50176]	Loss: 1.3944
Training Epoch: 18 [37888/50176]	Loss: 1.3496
Training Epoch: 18 [38912/50176]	Loss: 1.4032
Training Epoch: 18 [39936/50176]	Loss: 1.4201
Training Epoch: 18 [40960/50176]	Loss: 1.3597
Training Epoch: 18 [41984/50176]	Loss: 1.4166
Training Epoch: 18 [43008/50176]	Loss: 1.3991
Training Epoch: 18 [44032/50176]	Loss: 1.3800
Training Epoch: 18 [45056/50176]	Loss: 1.3854
Training Epoch: 18 [46080/50176]	Loss: 1.4066
Training Epoch: 18 [47104/50176]	Loss: 1.3843
Training Epoch: 18 [48128/50176]	Loss: 1.3188
Training Epoch: 18 [49152/50176]	Loss: 1.4005
Training Epoch: 18 [50176/50176]	Loss: 1.4375
2022-12-06 17:25:28.979 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:25:29,002 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.80 energy=488.07
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Up to epoch 19: time=964.58, energy=130808.99, cost=149805.37
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Expected next epoch: time=1011.86, energy=137592.94, cost=157333.82
2022-12-06 12:25:29,003 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0023, Accuracy: 0.4264
2022-12-06 12:25:29,228 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:25:29,229 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:25:29.231 [ZeusMonitor] Monitor started.
2022-12-06 17:25:29.231 [ZeusMonitor] Running indefinitely. 2022-12-06 17:25:29.231 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:25:29.231 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 12:26:13,397 [ZeusDataLoader(train)] train epoch 20 done: time=44.39 energy=6321.33
2022-12-06 12:26:13,400 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.2642
Training Epoch: 19 [2048/50176]	Loss: 1.2886
Training Epoch: 19 [3072/50176]	Loss: 1.2619
Training Epoch: 19 [4096/50176]	Loss: 1.2741
Training Epoch: 19 [5120/50176]	Loss: 1.3335
Training Epoch: 19 [6144/50176]	Loss: 1.2899
Training Epoch: 19 [7168/50176]	Loss: 1.2820
Training Epoch: 19 [8192/50176]	Loss: 1.2450
Training Epoch: 19 [9216/50176]	Loss: 1.2865
Training Epoch: 19 [10240/50176]	Loss: 1.3383
Training Epoch: 19 [11264/50176]	Loss: 1.2873
Training Epoch: 19 [12288/50176]	Loss: 1.2496
Training Epoch: 19 [13312/50176]	Loss: 1.2875
Training Epoch: 19 [14336/50176]	Loss: 1.3094
Training Epoch: 19 [15360/50176]	Loss: 1.3426
Training Epoch: 19 [16384/50176]	Loss: 1.2655
Training Epoch: 19 [17408/50176]	Loss: 1.3409
Training Epoch: 19 [18432/50176]	Loss: 1.3313
Training Epoch: 19 [19456/50176]	Loss: 1.2406
Training Epoch: 19 [20480/50176]	Loss: 1.3967
Training Epoch: 19 [21504/50176]	Loss: 1.2155
Training Epoch: 19 [22528/50176]	Loss: 1.3672
Training Epoch: 19 [23552/50176]	Loss: 1.3811
Training Epoch: 19 [24576/50176]	Loss: 1.2847
Training Epoch: 19 [25600/50176]	Loss: 1.3338
Training Epoch: 19 [26624/50176]	Loss: 1.3435
Training Epoch: 19 [27648/50176]	Loss: 1.2440
Training Epoch: 19 [28672/50176]	Loss: 1.3106
Training Epoch: 19 [29696/50176]	Loss: 1.4361
Training Epoch: 19 [30720/50176]	Loss: 1.3243
Training Epoch: 19 [31744/50176]	Loss: 1.3257
Training Epoch: 19 [32768/50176]	Loss: 1.3819
Training Epoch: 19 [33792/50176]	Loss: 1.3558
Training Epoch: 19 [34816/50176]	Loss: 1.3178
Training Epoch: 19 [35840/50176]	Loss: 1.3250
Training Epoch: 19 [36864/50176]	Loss: 1.3840
Training Epoch: 19 [37888/50176]	Loss: 1.2577
Training Epoch: 19 [38912/50176]	Loss: 1.3955
Training Epoch: 19 [39936/50176]	Loss: 1.2591
Training Epoch: 19 [40960/50176]	Loss: 1.2498
Training Epoch: 19 [41984/50176]	Loss: 1.3718
Training Epoch: 19 [43008/50176]	Loss: 1.3811
Training Epoch: 19 [44032/50176]	Loss: 1.2747
Training Epoch: 19 [45056/50176]	Loss: 1.3526
Training Epoch: 19 [46080/50176]	Loss: 1.2696
Training Epoch: 19 [47104/50176]	Loss: 1.2982
Training Epoch: 19 [48128/50176]	Loss: 1.2572
Training Epoch: 19 [49152/50176]	Loss: 1.3599
Training Epoch: 19 [50176/50176]	Loss: 1.2819
2022-12-06 17:26:17.166 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:26:17,195 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.79 energy=490.03
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Up to epoch 20: time=1012.75, energy=137620.35, cost=157426.13
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Expected next epoch: time=1060.03, energy=144404.30, cost=164954.59
2022-12-06 12:26:17,196 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0017, Accuracy: 0.5226
2022-12-06 12:26:17,418 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:26:17,419 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:26:17.420 [ZeusMonitor] Monitor started.
2022-12-06 17:26:17.420 [ZeusMonitor] Running indefinitely. 2022-12-06 17:26:17.420 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:26:17.420 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 12:27:02,170 [ZeusDataLoader(train)] train epoch 21 done: time=44.97 energy=6358.55
2022-12-06 12:27:02,173 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.2380
Training Epoch: 20 [2048/50176]	Loss: 1.2095
Training Epoch: 20 [3072/50176]	Loss: 1.2483
Training Epoch: 20 [4096/50176]	Loss: 1.1919
Training Epoch: 20 [5120/50176]	Loss: 1.2689
Training Epoch: 20 [6144/50176]	Loss: 1.2662
Training Epoch: 20 [7168/50176]	Loss: 1.1933
Training Epoch: 20 [8192/50176]	Loss: 1.2016
Training Epoch: 20 [9216/50176]	Loss: 1.2104
Training Epoch: 20 [10240/50176]	Loss: 1.1949
Training Epoch: 20 [11264/50176]	Loss: 1.2867
Training Epoch: 20 [12288/50176]	Loss: 1.2106
Training Epoch: 20 [13312/50176]	Loss: 1.2391
Training Epoch: 20 [14336/50176]	Loss: 1.2787
Training Epoch: 20 [15360/50176]	Loss: 1.2735
Training Epoch: 20 [16384/50176]	Loss: 1.2786
Training Epoch: 20 [17408/50176]	Loss: 1.2330
Training Epoch: 20 [18432/50176]	Loss: 1.2964
Training Epoch: 20 [19456/50176]	Loss: 1.2840
Training Epoch: 20 [20480/50176]	Loss: 1.2222
Training Epoch: 20 [21504/50176]	Loss: 1.3016
Training Epoch: 20 [22528/50176]	Loss: 1.2053
Training Epoch: 20 [23552/50176]	Loss: 1.1291
Training Epoch: 20 [24576/50176]	Loss: 1.2644
Training Epoch: 20 [25600/50176]	Loss: 1.3232
Training Epoch: 20 [26624/50176]	Loss: 1.2614
Training Epoch: 20 [27648/50176]	Loss: 1.1905
Training Epoch: 20 [28672/50176]	Loss: 1.3442
Training Epoch: 20 [29696/50176]	Loss: 1.2554
Training Epoch: 20 [30720/50176]	Loss: 1.2475
Training Epoch: 20 [31744/50176]	Loss: 1.2065
Training Epoch: 20 [32768/50176]	Loss: 1.2284
Training Epoch: 20 [33792/50176]	Loss: 1.2463
Training Epoch: 20 [34816/50176]	Loss: 1.2734
Training Epoch: 20 [35840/50176]	Loss: 1.2194
Training Epoch: 20 [36864/50176]	Loss: 1.2377
Training Epoch: 20 [37888/50176]	Loss: 1.2604
Training Epoch: 20 [38912/50176]	Loss: 1.2702
Training Epoch: 20 [39936/50176]	Loss: 1.2713
Training Epoch: 20 [40960/50176]	Loss: 1.3155
Training Epoch: 20 [41984/50176]	Loss: 1.2812
Training Epoch: 20 [43008/50176]	Loss: 1.2430
Training Epoch: 20 [44032/50176]	Loss: 1.2054
Training Epoch: 20 [45056/50176]	Loss: 1.2708
Training Epoch: 20 [46080/50176]	Loss: 1.2995
Training Epoch: 20 [47104/50176]	Loss: 1.3118
Training Epoch: 20 [48128/50176]	Loss: 1.2757
Training Epoch: 20 [49152/50176]	Loss: 1.3079
Training Epoch: 20 [50176/50176]	Loss: 1.2796
2022-12-06 17:27:05.890 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:27:05,925 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.74 energy=473.98
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Up to epoch 21: time=1061.46, energy=144452.88, cost=165104.45
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Expected next epoch: time=1108.74, energy=151236.83, cost=172632.90
2022-12-06 12:27:05,926 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0019, Accuracy: 0.4920
2022-12-06 12:27:06,160 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:27:06,161 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:27:06.163 [ZeusMonitor] Monitor started.
2022-12-06 17:27:06.163 [ZeusMonitor] Running indefinitely. 2022-12-06 17:27:06.163 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:27:06.163 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 12:27:50,536 [ZeusDataLoader(train)] train epoch 22 done: time=44.60 energy=6336.83
2022-12-06 12:27:50,539 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.2282
Training Epoch: 21 [2048/50176]	Loss: 1.1548
Training Epoch: 21 [3072/50176]	Loss: 1.1690
Training Epoch: 21 [4096/50176]	Loss: 1.2001
Training Epoch: 21 [5120/50176]	Loss: 1.1447
Training Epoch: 21 [6144/50176]	Loss: 1.0901
Training Epoch: 21 [7168/50176]	Loss: 1.0788
Training Epoch: 21 [8192/50176]	Loss: 1.1531
Training Epoch: 21 [9216/50176]	Loss: 1.1823
Training Epoch: 21 [10240/50176]	Loss: 1.1673
Training Epoch: 21 [11264/50176]	Loss: 1.1780
Training Epoch: 21 [12288/50176]	Loss: 1.1707
Training Epoch: 21 [13312/50176]	Loss: 1.1837
Training Epoch: 21 [14336/50176]	Loss: 1.2128
Training Epoch: 21 [15360/50176]	Loss: 1.1441
Training Epoch: 21 [16384/50176]	Loss: 1.2172
Training Epoch: 21 [17408/50176]	Loss: 1.1697
Training Epoch: 21 [18432/50176]	Loss: 1.1047
Training Epoch: 21 [19456/50176]	Loss: 1.1566
Training Epoch: 21 [20480/50176]	Loss: 1.1311
Training Epoch: 21 [21504/50176]	Loss: 1.2216
Training Epoch: 21 [22528/50176]	Loss: 1.2375
Training Epoch: 21 [23552/50176]	Loss: 1.2706
Training Epoch: 21 [24576/50176]	Loss: 1.1523
Training Epoch: 21 [25600/50176]	Loss: 1.2764
Training Epoch: 21 [26624/50176]	Loss: 1.3117
Training Epoch: 21 [27648/50176]	Loss: 1.2223
Training Epoch: 21 [28672/50176]	Loss: 1.1983
Training Epoch: 21 [29696/50176]	Loss: 1.2556
Training Epoch: 21 [30720/50176]	Loss: 1.2369
Training Epoch: 21 [31744/50176]	Loss: 1.2925
Training Epoch: 21 [32768/50176]	Loss: 1.2497
Training Epoch: 21 [33792/50176]	Loss: 1.2417
Training Epoch: 21 [34816/50176]	Loss: 1.1636
Training Epoch: 21 [35840/50176]	Loss: 1.2604
Training Epoch: 21 [36864/50176]	Loss: 1.1678
Training Epoch: 21 [37888/50176]	Loss: 1.2944
Training Epoch: 21 [38912/50176]	Loss: 1.2104
Training Epoch: 21 [39936/50176]	Loss: 1.3090
Training Epoch: 21 [40960/50176]	Loss: 1.1852
Training Epoch: 21 [41984/50176]	Loss: 1.2529
Training Epoch: 21 [43008/50176]	Loss: 1.2444
Training Epoch: 21 [44032/50176]	Loss: 1.3172
Training Epoch: 21 [45056/50176]	Loss: 1.2022
Training Epoch: 21 [46080/50176]	Loss: 1.2559
Training Epoch: 21 [47104/50176]	Loss: 1.2631
Training Epoch: 21 [48128/50176]	Loss: 1.2217
Training Epoch: 21 [49152/50176]	Loss: 1.2466
Training Epoch: 21 [50176/50176]	Loss: 1.2902
2022-12-06 17:27:54.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:27:54,350 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.80 energy=484.13
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Up to epoch 22: time=1109.87, energy=151273.84, cost=172750.33
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Expected next epoch: time=1157.14, energy=158057.79, cost=180278.78
2022-12-06 12:27:54,351 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0021, Accuracy: 0.4569
2022-12-06 12:27:54,584 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:27:54,585 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:27:54.587 [ZeusMonitor] Monitor started.
2022-12-06 17:27:54.587 [ZeusMonitor] Running indefinitely. 2022-12-06 17:27:54.587 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:27:54.587 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 12:28:38,899 [ZeusDataLoader(train)] train epoch 23 done: time=44.54 energy=6351.07
2022-12-06 12:28:38,902 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.1509
Training Epoch: 22 [2048/50176]	Loss: 1.1550
Training Epoch: 22 [3072/50176]	Loss: 1.1260
Training Epoch: 22 [4096/50176]	Loss: 1.0285
Training Epoch: 22 [5120/50176]	Loss: 1.1573
Training Epoch: 22 [6144/50176]	Loss: 1.1061
Training Epoch: 22 [7168/50176]	Loss: 1.1733
Training Epoch: 22 [8192/50176]	Loss: 1.1899
Training Epoch: 22 [9216/50176]	Loss: 1.0822
Training Epoch: 22 [10240/50176]	Loss: 1.0929
Training Epoch: 22 [11264/50176]	Loss: 1.1723
Training Epoch: 22 [12288/50176]	Loss: 1.1772
Training Epoch: 22 [13312/50176]	Loss: 1.0585
Training Epoch: 22 [14336/50176]	Loss: 1.2155
Training Epoch: 22 [15360/50176]	Loss: 1.0892
Training Epoch: 22 [16384/50176]	Loss: 1.1896
Training Epoch: 22 [17408/50176]	Loss: 1.1353
Training Epoch: 22 [18432/50176]	Loss: 1.1679
Training Epoch: 22 [19456/50176]	Loss: 1.1693
Training Epoch: 22 [20480/50176]	Loss: 1.1764
Training Epoch: 22 [21504/50176]	Loss: 1.1839
Training Epoch: 22 [22528/50176]	Loss: 1.2493
Training Epoch: 22 [23552/50176]	Loss: 1.1668
Training Epoch: 22 [24576/50176]	Loss: 1.1942
Training Epoch: 22 [25600/50176]	Loss: 1.1651
Training Epoch: 22 [26624/50176]	Loss: 1.1801
Training Epoch: 22 [27648/50176]	Loss: 1.1942
Training Epoch: 22 [28672/50176]	Loss: 1.2178
Training Epoch: 22 [29696/50176]	Loss: 1.2200
Training Epoch: 22 [30720/50176]	Loss: 1.1385
Training Epoch: 22 [31744/50176]	Loss: 1.2880
Training Epoch: 22 [32768/50176]	Loss: 1.1742
Training Epoch: 22 [33792/50176]	Loss: 1.1997
Training Epoch: 22 [34816/50176]	Loss: 1.2221
Training Epoch: 22 [35840/50176]	Loss: 1.1809
Training Epoch: 22 [36864/50176]	Loss: 1.1555
Training Epoch: 22 [37888/50176]	Loss: 1.1931
Training Epoch: 22 [38912/50176]	Loss: 1.1373
Training Epoch: 22 [39936/50176]	Loss: 1.1559
Training Epoch: 22 [40960/50176]	Loss: 1.2013
Training Epoch: 22 [41984/50176]	Loss: 1.2547
Training Epoch: 22 [43008/50176]	Loss: 1.1124
Training Epoch: 22 [44032/50176]	Loss: 1.1510
Training Epoch: 22 [45056/50176]	Loss: 1.1723
Training Epoch: 22 [46080/50176]	Loss: 1.1365
Training Epoch: 22 [47104/50176]	Loss: 1.1427
Training Epoch: 22 [48128/50176]	Loss: 1.3186
Training Epoch: 22 [49152/50176]	Loss: 1.2815
Training Epoch: 22 [50176/50176]	Loss: 1.1308
2022-12-06 17:28:42.744 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:28:42,794 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.88 energy=491.77
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Up to epoch 23: time=1158.29, energy=158116.68, cost=180408.82
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Expected next epoch: time=1205.57, energy=164900.63, cost=187937.28
2022-12-06 12:28:42,795 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0019, Accuracy: 0.4860
2022-12-06 12:28:43,006 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:28:43,007 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:28:43.009 [ZeusMonitor] Monitor started.
2022-12-06 17:28:43.009 [ZeusMonitor] Running indefinitely. 2022-12-06 17:28:43.009 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:28:43.009 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 12:29:26,981 [ZeusDataLoader(train)] train epoch 24 done: time=44.18 energy=6304.69
2022-12-06 12:29:26,984 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.1240
Training Epoch: 23 [2048/50176]	Loss: 1.0512
Training Epoch: 23 [3072/50176]	Loss: 1.0347
Training Epoch: 23 [4096/50176]	Loss: 1.0858
Training Epoch: 23 [5120/50176]	Loss: 1.0548
Training Epoch: 23 [6144/50176]	Loss: 1.0871
Training Epoch: 23 [7168/50176]	Loss: 1.0885
Training Epoch: 23 [8192/50176]	Loss: 1.1403
Training Epoch: 23 [9216/50176]	Loss: 1.0628
Training Epoch: 23 [10240/50176]	Loss: 1.0388
Training Epoch: 23 [11264/50176]	Loss: 1.0433
Training Epoch: 23 [12288/50176]	Loss: 0.9969
Training Epoch: 23 [13312/50176]	Loss: 1.1546
Training Epoch: 23 [14336/50176]	Loss: 1.0779
Training Epoch: 23 [15360/50176]	Loss: 1.0534
Training Epoch: 23 [16384/50176]	Loss: 1.1209
Training Epoch: 23 [17408/50176]	Loss: 1.1103
Training Epoch: 23 [18432/50176]	Loss: 1.0817
Training Epoch: 23 [19456/50176]	Loss: 1.0736
Training Epoch: 23 [20480/50176]	Loss: 1.0887
Training Epoch: 23 [21504/50176]	Loss: 1.1602
Training Epoch: 23 [22528/50176]	Loss: 1.0769
Training Epoch: 23 [23552/50176]	Loss: 1.0469
Training Epoch: 23 [24576/50176]	Loss: 1.0792
Training Epoch: 23 [25600/50176]	Loss: 1.1250
Training Epoch: 23 [26624/50176]	Loss: 1.0351
Training Epoch: 23 [27648/50176]	Loss: 1.1094
Training Epoch: 23 [28672/50176]	Loss: 1.1030
Training Epoch: 23 [29696/50176]	Loss: 1.0535
Training Epoch: 23 [30720/50176]	Loss: 1.1250
Training Epoch: 23 [31744/50176]	Loss: 1.1780
Training Epoch: 23 [32768/50176]	Loss: 1.1491
Training Epoch: 23 [33792/50176]	Loss: 1.1020
Training Epoch: 23 [34816/50176]	Loss: 1.1667
Training Epoch: 23 [35840/50176]	Loss: 1.0965
Training Epoch: 23 [36864/50176]	Loss: 1.0840
Training Epoch: 23 [37888/50176]	Loss: 1.0936
Training Epoch: 23 [38912/50176]	Loss: 1.1741
Training Epoch: 23 [39936/50176]	Loss: 1.1650
Training Epoch: 23 [40960/50176]	Loss: 1.1873
Training Epoch: 23 [41984/50176]	Loss: 1.1356
Training Epoch: 23 [43008/50176]	Loss: 1.1417
Training Epoch: 23 [44032/50176]	Loss: 1.1929
Training Epoch: 23 [45056/50176]	Loss: 1.1611
Training Epoch: 23 [46080/50176]	Loss: 1.2130
Training Epoch: 23 [47104/50176]	Loss: 1.1752
Training Epoch: 23 [48128/50176]	Loss: 1.1113
Training Epoch: 23 [49152/50176]	Loss: 1.1194
Training Epoch: 23 [50176/50176]	Loss: 1.0872
2022-12-06 17:29:30.819 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:29:30,847 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.85 energy=483.17
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Up to epoch 24: time=1206.32, energy=164904.53, cost=188005.59
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Expected next epoch: time=1253.60, energy=171688.49, cost=195534.04
2022-12-06 12:29:30,848 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0017, Accuracy: 0.5359
2022-12-06 12:29:31,075 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:29:31,076 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:29:31.077 [ZeusMonitor] Monitor started.
2022-12-06 17:29:31.078 [ZeusMonitor] Running indefinitely. 2022-12-06 17:29:31.078 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:29:31.078 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 12:30:15,392 [ZeusDataLoader(train)] train epoch 25 done: time=44.54 energy=6331.88
2022-12-06 12:30:15,395 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 1.0087
Training Epoch: 24 [2048/50176]	Loss: 0.9555
Training Epoch: 24 [3072/50176]	Loss: 1.0395
Training Epoch: 24 [4096/50176]	Loss: 1.0164
Training Epoch: 24 [5120/50176]	Loss: 0.9546
Training Epoch: 24 [6144/50176]	Loss: 0.9625
Training Epoch: 24 [7168/50176]	Loss: 1.0812
Training Epoch: 24 [8192/50176]	Loss: 1.0041
Training Epoch: 24 [9216/50176]	Loss: 1.0469
Training Epoch: 24 [10240/50176]	Loss: 1.0432
Training Epoch: 24 [11264/50176]	Loss: 0.9823
Training Epoch: 24 [12288/50176]	Loss: 1.0084
Training Epoch: 24 [13312/50176]	Loss: 1.0073
Training Epoch: 24 [14336/50176]	Loss: 1.0808
Training Epoch: 24 [15360/50176]	Loss: 0.9680
Training Epoch: 24 [16384/50176]	Loss: 0.9683
Training Epoch: 24 [17408/50176]	Loss: 1.0522
Training Epoch: 24 [18432/50176]	Loss: 1.0447
Training Epoch: 24 [19456/50176]	Loss: 1.1047
Training Epoch: 24 [20480/50176]	Loss: 1.0482
Training Epoch: 24 [21504/50176]	Loss: 1.0331
Training Epoch: 24 [22528/50176]	Loss: 1.0104
Training Epoch: 24 [23552/50176]	Loss: 1.1116
Training Epoch: 24 [24576/50176]	Loss: 1.0284
Training Epoch: 24 [25600/50176]	Loss: 1.0838
Training Epoch: 24 [26624/50176]	Loss: 1.0253
Training Epoch: 24 [27648/50176]	Loss: 1.1426
Training Epoch: 24 [28672/50176]	Loss: 1.0271
Training Epoch: 24 [29696/50176]	Loss: 1.0920
Training Epoch: 24 [30720/50176]	Loss: 1.1788
Training Epoch: 24 [31744/50176]	Loss: 1.1066
Training Epoch: 24 [32768/50176]	Loss: 1.0971
Training Epoch: 24 [33792/50176]	Loss: 1.0833
Training Epoch: 24 [34816/50176]	Loss: 1.1238
Training Epoch: 24 [35840/50176]	Loss: 1.1840
Training Epoch: 24 [36864/50176]	Loss: 1.1006
Training Epoch: 24 [37888/50176]	Loss: 1.1145
Training Epoch: 24 [38912/50176]	Loss: 1.1435
Training Epoch: 24 [39936/50176]	Loss: 0.9964
Training Epoch: 24 [40960/50176]	Loss: 1.0715
Training Epoch: 24 [41984/50176]	Loss: 1.1572
Training Epoch: 24 [43008/50176]	Loss: 1.1807
Training Epoch: 24 [44032/50176]	Loss: 1.0205
Training Epoch: 24 [45056/50176]	Loss: 1.1019
Training Epoch: 24 [46080/50176]	Loss: 1.0715
Training Epoch: 24 [47104/50176]	Loss: 1.2086
Training Epoch: 24 [48128/50176]	Loss: 1.2298
Training Epoch: 24 [49152/50176]	Loss: 1.0917
Training Epoch: 24 [50176/50176]	Loss: 1.0770
2022-12-06 17:30:19.081 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:30:19,100 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.70 energy=475.89
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Up to epoch 25: time=1254.56, energy=171712.31, cost=195629.86
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Expected next epoch: time=1301.83, energy=178496.26, cost=203158.31
2022-12-06 12:30:19,102 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0018, Accuracy: 0.5284
2022-12-06 12:30:19,328 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:30:19,329 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:30:19.331 [ZeusMonitor] Monitor started.
2022-12-06 17:30:19.331 [ZeusMonitor] Running indefinitely. 2022-12-06 17:30:19.331 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:30:19.331 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 12:31:03,874 [ZeusDataLoader(train)] train epoch 26 done: time=44.76 energy=6355.46
2022-12-06 12:31:03,877 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.9314
Training Epoch: 25 [2048/50176]	Loss: 0.9417
Training Epoch: 25 [3072/50176]	Loss: 0.9894
Training Epoch: 25 [4096/50176]	Loss: 0.9847
Training Epoch: 25 [5120/50176]	Loss: 0.9606
Training Epoch: 25 [6144/50176]	Loss: 0.9758
Training Epoch: 25 [7168/50176]	Loss: 0.9786
Training Epoch: 25 [8192/50176]	Loss: 1.0143
Training Epoch: 25 [9216/50176]	Loss: 1.0568
Training Epoch: 25 [10240/50176]	Loss: 0.9838
Training Epoch: 25 [11264/50176]	Loss: 0.9688
Training Epoch: 25 [12288/50176]	Loss: 0.9270
Training Epoch: 25 [13312/50176]	Loss: 0.9332
Training Epoch: 25 [14336/50176]	Loss: 1.0044
Training Epoch: 25 [15360/50176]	Loss: 0.9923
Training Epoch: 25 [16384/50176]	Loss: 1.0611
Training Epoch: 25 [17408/50176]	Loss: 1.0049
Training Epoch: 25 [18432/50176]	Loss: 1.0237
Training Epoch: 25 [19456/50176]	Loss: 0.9874
Training Epoch: 25 [20480/50176]	Loss: 0.9564
Training Epoch: 25 [21504/50176]	Loss: 0.9979
Training Epoch: 25 [22528/50176]	Loss: 1.0759
Training Epoch: 25 [23552/50176]	Loss: 0.9483
Training Epoch: 25 [24576/50176]	Loss: 0.9849
Training Epoch: 25 [25600/50176]	Loss: 1.0076
Training Epoch: 25 [26624/50176]	Loss: 1.1405
Training Epoch: 25 [27648/50176]	Loss: 1.0791
Training Epoch: 25 [28672/50176]	Loss: 1.0914
Training Epoch: 25 [29696/50176]	Loss: 1.0671
Training Epoch: 25 [30720/50176]	Loss: 1.0416
Training Epoch: 25 [31744/50176]	Loss: 1.0079
Training Epoch: 25 [32768/50176]	Loss: 1.0595
Training Epoch: 25 [33792/50176]	Loss: 0.9845
Training Epoch: 25 [34816/50176]	Loss: 1.0668
Training Epoch: 25 [35840/50176]	Loss: 1.0417
Training Epoch: 25 [36864/50176]	Loss: 1.0300
Training Epoch: 25 [37888/50176]	Loss: 1.0384
Training Epoch: 25 [38912/50176]	Loss: 1.0397
Training Epoch: 25 [39936/50176]	Loss: 1.0602
Training Epoch: 25 [40960/50176]	Loss: 0.9910
Training Epoch: 25 [41984/50176]	Loss: 1.0477
Training Epoch: 25 [43008/50176]	Loss: 1.0956
Training Epoch: 25 [44032/50176]	Loss: 1.0558
Training Epoch: 25 [45056/50176]	Loss: 1.0821
Training Epoch: 25 [46080/50176]	Loss: 1.0295
Training Epoch: 25 [47104/50176]	Loss: 1.0941
Training Epoch: 25 [48128/50176]	Loss: 1.0764
Training Epoch: 25 [49152/50176]	Loss: 1.0824
Training Epoch: 25 [50176/50176]	Loss: 1.0919
2022-12-06 17:31:07.615 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:31:07,654 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.77 energy=476.21
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Up to epoch 26: time=1303.09, energy=178543.97, cost=203292.27
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Expected next epoch: time=1350.36, energy=185327.92, cost=210820.73
2022-12-06 12:31:07,655 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0016, Accuracy: 0.5569
2022-12-06 12:31:07,895 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:31:07,895 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:31:07.897 [ZeusMonitor] Monitor started.
2022-12-06 17:31:07.897 [ZeusMonitor] Running indefinitely. 2022-12-06 17:31:07.897 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:31:07.897 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 12:31:52,069 [ZeusDataLoader(train)] train epoch 27 done: time=44.41 energy=6320.28
2022-12-06 12:31:52,072 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.9313
Training Epoch: 26 [2048/50176]	Loss: 0.9670
Training Epoch: 26 [3072/50176]	Loss: 0.9897
Training Epoch: 26 [4096/50176]	Loss: 0.9642
Training Epoch: 26 [5120/50176]	Loss: 0.9408
Training Epoch: 26 [6144/50176]	Loss: 0.9501
Training Epoch: 26 [7168/50176]	Loss: 0.9334
Training Epoch: 26 [8192/50176]	Loss: 0.9756
Training Epoch: 26 [9216/50176]	Loss: 0.8775
Training Epoch: 26 [10240/50176]	Loss: 0.9824
Training Epoch: 26 [11264/50176]	Loss: 0.9095
Training Epoch: 26 [12288/50176]	Loss: 0.9144
Training Epoch: 26 [13312/50176]	Loss: 0.9212
Training Epoch: 26 [14336/50176]	Loss: 0.9449
Training Epoch: 26 [15360/50176]	Loss: 0.8996
Training Epoch: 26 [16384/50176]	Loss: 0.8651
Training Epoch: 26 [17408/50176]	Loss: 0.9533
Training Epoch: 26 [18432/50176]	Loss: 0.9603
Training Epoch: 26 [19456/50176]	Loss: 0.9712
Training Epoch: 26 [20480/50176]	Loss: 0.9000
Training Epoch: 26 [21504/50176]	Loss: 0.9669
Training Epoch: 26 [22528/50176]	Loss: 0.8577
Training Epoch: 26 [23552/50176]	Loss: 0.9796
Training Epoch: 26 [24576/50176]	Loss: 0.9683
Training Epoch: 26 [25600/50176]	Loss: 0.9687
Training Epoch: 26 [26624/50176]	Loss: 0.9919
Training Epoch: 26 [27648/50176]	Loss: 0.9967
Training Epoch: 26 [28672/50176]	Loss: 0.9251
Training Epoch: 26 [29696/50176]	Loss: 1.0381
Training Epoch: 26 [30720/50176]	Loss: 1.0913
Training Epoch: 26 [31744/50176]	Loss: 0.9711
Training Epoch: 26 [32768/50176]	Loss: 1.0177
Training Epoch: 26 [33792/50176]	Loss: 1.0444
Training Epoch: 26 [34816/50176]	Loss: 1.0872
Training Epoch: 26 [35840/50176]	Loss: 1.0227
Training Epoch: 26 [36864/50176]	Loss: 1.0028
Training Epoch: 26 [37888/50176]	Loss: 1.0103
Training Epoch: 26 [38912/50176]	Loss: 1.0136
Training Epoch: 26 [39936/50176]	Loss: 1.1057
Training Epoch: 26 [40960/50176]	Loss: 0.9863
Training Epoch: 26 [41984/50176]	Loss: 1.0567
Training Epoch: 26 [43008/50176]	Loss: 1.0274
Training Epoch: 26 [44032/50176]	Loss: 1.0368
Training Epoch: 26 [45056/50176]	Loss: 1.0203
Training Epoch: 26 [46080/50176]	Loss: 1.0705
Training Epoch: 26 [47104/50176]	Loss: 1.0769
Training Epoch: 26 [48128/50176]	Loss: 1.0357
Training Epoch: 26 [49152/50176]	Loss: 0.9908
Training Epoch: 26 [50176/50176]	Loss: 1.0203
2022-12-06 17:31:55.836 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:31:55,857 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.78 energy=479.44
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Up to epoch 27: time=1351.27, energy=185343.69, cost=210908.19
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Expected next epoch: time=1398.55, energy=192127.64, cost=218436.65
2022-12-06 12:31:55,859 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0017, Accuracy: 0.5475
2022-12-06 12:31:56,031 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:31:56,031 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:31:56.035 [ZeusMonitor] Monitor started.
2022-12-06 17:31:56.035 [ZeusMonitor] Running indefinitely. 2022-12-06 17:31:56.035 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:31:56.035 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 12:32:41,269 [ZeusDataLoader(train)] train epoch 28 done: time=45.40 energy=6392.82
2022-12-06 12:32:41,272 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.9036
Training Epoch: 27 [2048/50176]	Loss: 0.9075
Training Epoch: 27 [3072/50176]	Loss: 0.8437
Training Epoch: 27 [4096/50176]	Loss: 0.9719
Training Epoch: 27 [5120/50176]	Loss: 0.8983
Training Epoch: 27 [6144/50176]	Loss: 0.8806
Training Epoch: 27 [7168/50176]	Loss: 0.8570
Training Epoch: 27 [8192/50176]	Loss: 0.8709
Training Epoch: 27 [9216/50176]	Loss: 0.8953
Training Epoch: 27 [10240/50176]	Loss: 0.9188
Training Epoch: 27 [11264/50176]	Loss: 0.8897
Training Epoch: 27 [12288/50176]	Loss: 0.8792
Training Epoch: 27 [13312/50176]	Loss: 0.9021
Training Epoch: 27 [14336/50176]	Loss: 0.8972
Training Epoch: 27 [15360/50176]	Loss: 0.8717
Training Epoch: 27 [16384/50176]	Loss: 0.9097
Training Epoch: 27 [17408/50176]	Loss: 0.8991
Training Epoch: 27 [18432/50176]	Loss: 0.9472
Training Epoch: 27 [19456/50176]	Loss: 0.9319
Training Epoch: 27 [20480/50176]	Loss: 0.8543
Training Epoch: 27 [21504/50176]	Loss: 0.9340
Training Epoch: 27 [22528/50176]	Loss: 0.8853
Training Epoch: 27 [23552/50176]	Loss: 0.8815
Training Epoch: 27 [24576/50176]	Loss: 0.9446
Training Epoch: 27 [25600/50176]	Loss: 0.9115
Training Epoch: 27 [26624/50176]	Loss: 0.9587
Training Epoch: 27 [27648/50176]	Loss: 0.9547
Training Epoch: 27 [28672/50176]	Loss: 0.9358
Training Epoch: 27 [29696/50176]	Loss: 0.9324
Training Epoch: 27 [30720/50176]	Loss: 0.9381
Training Epoch: 27 [31744/50176]	Loss: 1.0364
Training Epoch: 27 [32768/50176]	Loss: 0.9196
Training Epoch: 27 [33792/50176]	Loss: 0.9023
Training Epoch: 27 [34816/50176]	Loss: 1.0417
Training Epoch: 27 [35840/50176]	Loss: 0.9972
Training Epoch: 27 [36864/50176]	Loss: 0.9817
Training Epoch: 27 [37888/50176]	Loss: 0.9319
Training Epoch: 27 [38912/50176]	Loss: 0.9973
Training Epoch: 27 [39936/50176]	Loss: 0.9844
Training Epoch: 27 [40960/50176]	Loss: 1.0000
Training Epoch: 27 [41984/50176]	Loss: 0.9443
Training Epoch: 27 [43008/50176]	Loss: 0.9401
Training Epoch: 27 [44032/50176]	Loss: 0.9613
Training Epoch: 27 [45056/50176]	Loss: 0.9271
Training Epoch: 27 [46080/50176]	Loss: 1.0277
Training Epoch: 27 [47104/50176]	Loss: 1.0458
Training Epoch: 27 [48128/50176]	Loss: 0.9602
Training Epoch: 27 [49152/50176]	Loss: 1.0111
Training Epoch: 27 [50176/50176]	Loss: 1.0609
2022-12-06 17:32:45.003 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:32:45,018 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=476.14
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Up to epoch 28: time=1400.41, energy=192212.64, cost=218642.44
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Expected next epoch: time=1447.69, energy=198996.59, cost=226170.89
2022-12-06 12:32:45,020 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0019, Accuracy: 0.5021
2022-12-06 12:32:45,244 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:32:45,244 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:32:45.246 [ZeusMonitor] Monitor started.
2022-12-06 17:32:45.246 [ZeusMonitor] Running indefinitely. 2022-12-06 17:32:45.246 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:32:45.246 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 12:33:29,939 [ZeusDataLoader(train)] train epoch 29 done: time=44.91 energy=6363.10
2022-12-06 12:33:29,942 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.8400
Training Epoch: 28 [2048/50176]	Loss: 0.9262
Training Epoch: 28 [3072/50176]	Loss: 0.8649
Training Epoch: 28 [4096/50176]	Loss: 0.9454
Training Epoch: 28 [5120/50176]	Loss: 0.8116
Training Epoch: 28 [6144/50176]	Loss: 0.8252
Training Epoch: 28 [7168/50176]	Loss: 0.8224
Training Epoch: 28 [8192/50176]	Loss: 0.8534
Training Epoch: 28 [9216/50176]	Loss: 0.8871
Training Epoch: 28 [10240/50176]	Loss: 0.8494
Training Epoch: 28 [11264/50176]	Loss: 0.8203
Training Epoch: 28 [12288/50176]	Loss: 0.8516
Training Epoch: 28 [13312/50176]	Loss: 0.8126
Training Epoch: 28 [14336/50176]	Loss: 0.9281
Training Epoch: 28 [15360/50176]	Loss: 0.8636
Training Epoch: 28 [16384/50176]	Loss: 0.8707
Training Epoch: 28 [17408/50176]	Loss: 0.8730
Training Epoch: 28 [18432/50176]	Loss: 0.8651
Training Epoch: 28 [19456/50176]	Loss: 0.8871
Training Epoch: 28 [20480/50176]	Loss: 0.8279
Training Epoch: 28 [21504/50176]	Loss: 0.9056
Training Epoch: 28 [22528/50176]	Loss: 0.8845
Training Epoch: 28 [23552/50176]	Loss: 0.8953
Training Epoch: 28 [24576/50176]	Loss: 0.8024
Training Epoch: 28 [25600/50176]	Loss: 0.8646
Training Epoch: 28 [26624/50176]	Loss: 0.8248
Training Epoch: 28 [27648/50176]	Loss: 0.9868
Training Epoch: 28 [28672/50176]	Loss: 0.9033
Training Epoch: 28 [29696/50176]	Loss: 0.8636
Training Epoch: 28 [30720/50176]	Loss: 0.9344
Training Epoch: 28 [31744/50176]	Loss: 0.9601
Training Epoch: 28 [32768/50176]	Loss: 0.8559
Training Epoch: 28 [33792/50176]	Loss: 0.9337
Training Epoch: 28 [34816/50176]	Loss: 0.9373
Training Epoch: 28 [35840/50176]	Loss: 0.9071
Training Epoch: 28 [36864/50176]	Loss: 0.9751
Training Epoch: 28 [37888/50176]	Loss: 0.9273
Training Epoch: 28 [38912/50176]	Loss: 0.9381
Training Epoch: 28 [39936/50176]	Loss: 0.9333
Training Epoch: 28 [40960/50176]	Loss: 0.9910
Training Epoch: 28 [41984/50176]	Loss: 0.9220
Training Epoch: 28 [43008/50176]	Loss: 0.9154
Training Epoch: 28 [44032/50176]	Loss: 0.9361
Training Epoch: 28 [45056/50176]	Loss: 1.0764
Training Epoch: 28 [46080/50176]	Loss: 0.9393
Training Epoch: 28 [47104/50176]	Loss: 0.9556
Training Epoch: 28 [48128/50176]	Loss: 0.8806
Training Epoch: 28 [49152/50176]	Loss: 0.9613
Training Epoch: 28 [50176/50176]	Loss: 0.9272
2022-12-06 17:33:33.698 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:33:33,744 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.79 energy=487.61
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Up to epoch 29: time=1449.12, energy=199063.36, cost=226329.46
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Expected next epoch: time=1496.39, energy=205847.31, cost=233857.91
2022-12-06 12:33:33,745 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0018, Accuracy: 0.5484
2022-12-06 12:33:33,976 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:33:33,977 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:33:33.979 [ZeusMonitor] Monitor started.
2022-12-06 17:33:33.979 [ZeusMonitor] Running indefinitely. 2022-12-06 17:33:33.979 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:33:33.979 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 12:34:18,330 [ZeusDataLoader(train)] train epoch 30 done: time=44.58 energy=6338.58
2022-12-06 12:34:18,333 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.8029
Training Epoch: 29 [2048/50176]	Loss: 0.8130
Training Epoch: 29 [3072/50176]	Loss: 0.8479
Training Epoch: 29 [4096/50176]	Loss: 0.8429
Training Epoch: 29 [5120/50176]	Loss: 0.9010
Training Epoch: 29 [6144/50176]	Loss: 0.8171
Training Epoch: 29 [7168/50176]	Loss: 0.7798
Training Epoch: 29 [8192/50176]	Loss: 0.7260
Training Epoch: 29 [9216/50176]	Loss: 0.8530
Training Epoch: 29 [10240/50176]	Loss: 0.8036
Training Epoch: 29 [11264/50176]	Loss: 0.8476
Training Epoch: 29 [12288/50176]	Loss: 0.8758
Training Epoch: 29 [13312/50176]	Loss: 0.7172
Training Epoch: 29 [14336/50176]	Loss: 0.8203
Training Epoch: 29 [15360/50176]	Loss: 0.9102
Training Epoch: 29 [16384/50176]	Loss: 0.8552
Training Epoch: 29 [17408/50176]	Loss: 0.7824
Training Epoch: 29 [18432/50176]	Loss: 0.8544
Training Epoch: 29 [19456/50176]	Loss: 0.8842
Training Epoch: 29 [20480/50176]	Loss: 0.8244
Training Epoch: 29 [21504/50176]	Loss: 0.8731
Training Epoch: 29 [22528/50176]	Loss: 0.7682
Training Epoch: 29 [23552/50176]	Loss: 0.8576
Training Epoch: 29 [24576/50176]	Loss: 0.8574
Training Epoch: 29 [25600/50176]	Loss: 0.8574
Training Epoch: 29 [26624/50176]	Loss: 0.8276
Training Epoch: 29 [27648/50176]	Loss: 0.8646
Training Epoch: 29 [28672/50176]	Loss: 0.8006
Training Epoch: 29 [29696/50176]	Loss: 0.7751
Training Epoch: 29 [30720/50176]	Loss: 0.8988
Training Epoch: 29 [31744/50176]	Loss: 0.8396
Training Epoch: 29 [32768/50176]	Loss: 0.8841
Training Epoch: 29 [33792/50176]	Loss: 0.8597
Training Epoch: 29 [34816/50176]	Loss: 0.8926
Training Epoch: 29 [35840/50176]	Loss: 0.7789
Training Epoch: 29 [36864/50176]	Loss: 0.9084
Training Epoch: 29 [37888/50176]	Loss: 0.8276
Training Epoch: 29 [38912/50176]	Loss: 0.8799
Training Epoch: 29 [39936/50176]	Loss: 0.8962
Training Epoch: 29 [40960/50176]	Loss: 0.9596
Training Epoch: 29 [41984/50176]	Loss: 0.8445
Training Epoch: 29 [43008/50176]	Loss: 0.8952
Training Epoch: 29 [44032/50176]	Loss: 0.9066
Training Epoch: 29 [45056/50176]	Loss: 0.8510
Training Epoch: 29 [46080/50176]	Loss: 0.9082
Training Epoch: 29 [47104/50176]	Loss: 0.9234
Training Epoch: 29 [48128/50176]	Loss: 0.9856
Training Epoch: 29 [49152/50176]	Loss: 0.9069
Training Epoch: 29 [50176/50176]	Loss: 0.9956
2022-12-06 17:34:22.040 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:34:22,066 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.73 energy=475.70
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Up to epoch 30: time=1497.42, energy=205877.63, cost=233963.00
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Expected next epoch: time=1544.69, energy=212661.58, cost=241491.45
2022-12-06 12:34:22,068 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0021, Accuracy: 0.5033
2022-12-06 12:34:22,236 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:34:22,236 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:34:22.240 [ZeusMonitor] Monitor started.
2022-12-06 17:34:22.240 [ZeusMonitor] Running indefinitely. 2022-12-06 17:34:22.240 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:34:22.240 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 12:35:06,648 [ZeusDataLoader(train)] train epoch 31 done: time=44.57 energy=6334.34
2022-12-06 12:35:06,651 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.8875
Training Epoch: 30 [2048/50176]	Loss: 0.7763
Training Epoch: 30 [3072/50176]	Loss: 0.8399
Training Epoch: 30 [4096/50176]	Loss: 0.8471
Training Epoch: 30 [5120/50176]	Loss: 0.7519
Training Epoch: 30 [6144/50176]	Loss: 0.7745
Training Epoch: 30 [7168/50176]	Loss: 0.7994
Training Epoch: 30 [8192/50176]	Loss: 0.7673
Training Epoch: 30 [9216/50176]	Loss: 0.7978
Training Epoch: 30 [10240/50176]	Loss: 0.7849
Training Epoch: 30 [11264/50176]	Loss: 0.7933
Training Epoch: 30 [12288/50176]	Loss: 0.7748
Training Epoch: 30 [13312/50176]	Loss: 0.7582
Training Epoch: 30 [14336/50176]	Loss: 0.7802
Training Epoch: 30 [15360/50176]	Loss: 0.7871
Training Epoch: 30 [16384/50176]	Loss: 0.8104
Training Epoch: 30 [17408/50176]	Loss: 0.8170
Training Epoch: 30 [18432/50176]	Loss: 0.7876
Training Epoch: 30 [19456/50176]	Loss: 0.7597
Training Epoch: 30 [20480/50176]	Loss: 0.7709
Training Epoch: 30 [21504/50176]	Loss: 0.7756
Training Epoch: 30 [22528/50176]	Loss: 0.8127
Training Epoch: 30 [23552/50176]	Loss: 0.7888
Training Epoch: 30 [24576/50176]	Loss: 0.8152
Training Epoch: 30 [25600/50176]	Loss: 0.8124
Training Epoch: 30 [26624/50176]	Loss: 0.7482
Training Epoch: 30 [27648/50176]	Loss: 0.8353
Training Epoch: 30 [28672/50176]	Loss: 0.8493
Training Epoch: 30 [29696/50176]	Loss: 0.8376
Training Epoch: 30 [30720/50176]	Loss: 0.8197
Training Epoch: 30 [31744/50176]	Loss: 0.7729
Training Epoch: 30 [32768/50176]	Loss: 0.7870
Training Epoch: 30 [33792/50176]	Loss: 0.8658
Training Epoch: 30 [34816/50176]	Loss: 0.9132
Training Epoch: 30 [35840/50176]	Loss: 0.8444
Training Epoch: 30 [36864/50176]	Loss: 0.8541
Training Epoch: 30 [37888/50176]	Loss: 0.8500
Training Epoch: 30 [38912/50176]	Loss: 0.8369
Training Epoch: 30 [39936/50176]	Loss: 0.8112
Training Epoch: 30 [40960/50176]	Loss: 0.8351
Training Epoch: 30 [41984/50176]	Loss: 0.8867
Training Epoch: 30 [43008/50176]	Loss: 0.8751
Training Epoch: 30 [44032/50176]	Loss: 0.8156
Training Epoch: 30 [45056/50176]	Loss: 0.8696
Training Epoch: 30 [46080/50176]	Loss: 0.8676
Training Epoch: 30 [47104/50176]	Loss: 0.8093
Training Epoch: 30 [48128/50176]	Loss: 0.8123
Training Epoch: 30 [49152/50176]	Loss: 0.8943
Training Epoch: 30 [50176/50176]	Loss: 0.9287
2022-12-06 17:35:10.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:35:10,449 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.79 energy=486.24
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Up to epoch 31: time=1545.78, energy=212698.20, cost=241604.99
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Expected next epoch: time=1593.06, energy=219482.15, cost=249133.44
2022-12-06 12:35:10,451 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0024, Accuracy: 0.4656
2022-12-06 12:35:10,663 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:35:10,663 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:35:10.665 [ZeusMonitor] Monitor started.
2022-12-06 17:35:10.665 [ZeusMonitor] Running indefinitely. 2022-12-06 17:35:10.665 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:35:10.665 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 12:35:55,001 [ZeusDataLoader(train)] train epoch 32 done: time=44.54 energy=6332.19
2022-12-06 12:35:55,005 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.7009
Training Epoch: 31 [2048/50176]	Loss: 0.6858
Training Epoch: 31 [3072/50176]	Loss: 0.7435
Training Epoch: 31 [4096/50176]	Loss: 0.6918
Training Epoch: 31 [5120/50176]	Loss: 0.7660
Training Epoch: 31 [6144/50176]	Loss: 0.6968
Training Epoch: 31 [7168/50176]	Loss: 0.7268
Training Epoch: 31 [8192/50176]	Loss: 0.7029
Training Epoch: 31 [9216/50176]	Loss: 0.7243
Training Epoch: 31 [10240/50176]	Loss: 0.7940
Training Epoch: 31 [11264/50176]	Loss: 0.6986
Training Epoch: 31 [12288/50176]	Loss: 0.7148
Training Epoch: 31 [13312/50176]	Loss: 0.7814
Training Epoch: 31 [14336/50176]	Loss: 0.6977
Training Epoch: 31 [15360/50176]	Loss: 0.7319
Training Epoch: 31 [16384/50176]	Loss: 0.7195
Training Epoch: 31 [17408/50176]	Loss: 0.7411
Training Epoch: 31 [18432/50176]	Loss: 0.7620
Training Epoch: 31 [19456/50176]	Loss: 0.7070
Training Epoch: 31 [20480/50176]	Loss: 0.7456
Training Epoch: 31 [21504/50176]	Loss: 0.8003
Training Epoch: 31 [22528/50176]	Loss: 0.8112
Training Epoch: 31 [23552/50176]	Loss: 0.7938
Training Epoch: 31 [24576/50176]	Loss: 0.7112
Training Epoch: 31 [25600/50176]	Loss: 0.7351
Training Epoch: 31 [26624/50176]	Loss: 0.8112
Training Epoch: 31 [27648/50176]	Loss: 0.7925
Training Epoch: 31 [28672/50176]	Loss: 0.7981
Training Epoch: 31 [29696/50176]	Loss: 0.7874
Training Epoch: 31 [30720/50176]	Loss: 0.7768
Training Epoch: 31 [31744/50176]	Loss: 0.7853
Training Epoch: 31 [32768/50176]	Loss: 0.8163
Training Epoch: 31 [33792/50176]	Loss: 0.7386
Training Epoch: 31 [34816/50176]	Loss: 0.8010
Training Epoch: 31 [35840/50176]	Loss: 0.8360
Training Epoch: 31 [36864/50176]	Loss: 0.8257
Training Epoch: 31 [37888/50176]	Loss: 0.7709
Training Epoch: 31 [38912/50176]	Loss: 0.8201
Training Epoch: 31 [39936/50176]	Loss: 0.8724
Training Epoch: 31 [40960/50176]	Loss: 0.8325
Training Epoch: 31 [41984/50176]	Loss: 0.7995
Training Epoch: 31 [43008/50176]	Loss: 0.7540
Training Epoch: 31 [44032/50176]	Loss: 0.7602
Training Epoch: 31 [45056/50176]	Loss: 0.8819
Training Epoch: 31 [46080/50176]	Loss: 0.8256
Training Epoch: 31 [47104/50176]	Loss: 0.7563
Training Epoch: 31 [48128/50176]	Loss: 0.9256
Training Epoch: 31 [49152/50176]	Loss: 0.7818
Training Epoch: 31 [50176/50176]	Loss: 0.7974
2022-12-06 17:35:58.795 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:35:58,804 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.79 energy=499.03
2022-12-06 12:35:58,804 [ZeusDataLoader(train)] Up to epoch 32: time=1594.11, energy=219529.42, cost=249249.75
2022-12-06 12:35:58,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:35:58,805 [ZeusDataLoader(train)] Expected next epoch: time=1641.39, energy=226313.38, cost=256778.21
2022-12-06 12:35:58,806 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0022, Accuracy: 0.5009
2022-12-06 12:35:59,017 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:35:59,018 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:35:59.019 [ZeusMonitor] Monitor started.
2022-12-06 17:35:59.020 [ZeusMonitor] Running indefinitely. 2022-12-06 17:35:59.020 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:35:59.020 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 12:36:44,238 [ZeusDataLoader(train)] train epoch 33 done: time=45.42 energy=6400.69
2022-12-06 12:36:44,243 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.6630
Training Epoch: 32 [2048/50176]	Loss: 0.6873
Training Epoch: 32 [3072/50176]	Loss: 0.7654
Training Epoch: 32 [4096/50176]	Loss: 0.6987
Training Epoch: 32 [5120/50176]	Loss: 0.7374
Training Epoch: 32 [6144/50176]	Loss: 0.7196
Training Epoch: 32 [7168/50176]	Loss: 0.7172
Training Epoch: 32 [8192/50176]	Loss: 0.7229
Training Epoch: 32 [9216/50176]	Loss: 0.6799
Training Epoch: 32 [10240/50176]	Loss: 0.6838
Training Epoch: 32 [11264/50176]	Loss: 0.7407
Training Epoch: 32 [12288/50176]	Loss: 0.7464
Training Epoch: 32 [13312/50176]	Loss: 0.7264
Training Epoch: 32 [14336/50176]	Loss: 0.7296
Training Epoch: 32 [15360/50176]	Loss: 0.6605
Training Epoch: 32 [16384/50176]	Loss: 0.6740
Training Epoch: 32 [17408/50176]	Loss: 0.7163
Training Epoch: 32 [18432/50176]	Loss: 0.7269
Training Epoch: 32 [19456/50176]	Loss: 0.7059
Training Epoch: 32 [20480/50176]	Loss: 0.7155
Training Epoch: 32 [21504/50176]	Loss: 0.7665
Training Epoch: 32 [22528/50176]	Loss: 0.7797
Training Epoch: 32 [23552/50176]	Loss: 0.7590
Training Epoch: 32 [24576/50176]	Loss: 0.7207
Training Epoch: 32 [25600/50176]	Loss: 0.7592
Training Epoch: 32 [26624/50176]	Loss: 0.6880
Training Epoch: 32 [27648/50176]	Loss: 0.6983
Training Epoch: 32 [28672/50176]	Loss: 0.6875
Training Epoch: 32 [29696/50176]	Loss: 0.7208
Training Epoch: 32 [30720/50176]	Loss: 0.6631
Training Epoch: 32 [31744/50176]	Loss: 0.7050
Training Epoch: 32 [32768/50176]	Loss: 0.7175
Training Epoch: 32 [33792/50176]	Loss: 0.7696
Training Epoch: 32 [34816/50176]	Loss: 0.8046
Training Epoch: 32 [35840/50176]	Loss: 0.7119
Training Epoch: 32 [36864/50176]	Loss: 0.8033
Training Epoch: 32 [37888/50176]	Loss: 0.7378
Training Epoch: 32 [38912/50176]	Loss: 0.7268
Training Epoch: 32 [39936/50176]	Loss: 0.7457
Training Epoch: 32 [40960/50176]	Loss: 0.7341
Training Epoch: 32 [41984/50176]	Loss: 0.6883
Training Epoch: 32 [43008/50176]	Loss: 0.8466
Training Epoch: 32 [44032/50176]	Loss: 0.7596
Training Epoch: 32 [45056/50176]	Loss: 0.7207
Training Epoch: 32 [46080/50176]	Loss: 0.8260
Training Epoch: 32 [47104/50176]	Loss: 0.7863
Training Epoch: 32 [48128/50176]	Loss: 0.7551
Training Epoch: 32 [49152/50176]	Loss: 0.7617
Training Epoch: 32 [50176/50176]	Loss: 0.7698
2022-12-06 17:36:48.036 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:36:48,046 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.80 energy=485.74
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Up to epoch 33: time=1643.33, energy=226415.86, cost=256999.74
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Expected next epoch: time=1690.61, energy=233199.81, cost=264528.19
2022-12-06 12:36:48,047 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0019, Accuracy: 0.5354
2022-12-06 12:36:48,256 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:36:48,257 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:36:48.259 [ZeusMonitor] Monitor started.
2022-12-06 17:36:48.259 [ZeusMonitor] Running indefinitely. 2022-12-06 17:36:48.259 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:36:48.259 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 12:37:33,653 [ZeusDataLoader(train)] train epoch 34 done: time=45.60 energy=6412.67
2022-12-06 12:37:33,657 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.6775
Training Epoch: 33 [2048/50176]	Loss: 0.6262
Training Epoch: 33 [3072/50176]	Loss: 0.6932
Training Epoch: 33 [4096/50176]	Loss: 0.6916
Training Epoch: 33 [5120/50176]	Loss: 0.6900
Training Epoch: 33 [6144/50176]	Loss: 0.6727
Training Epoch: 33 [7168/50176]	Loss: 0.7011
Training Epoch: 33 [8192/50176]	Loss: 0.6085
Training Epoch: 33 [9216/50176]	Loss: 0.6297
Training Epoch: 33 [10240/50176]	Loss: 0.7028
Training Epoch: 33 [11264/50176]	Loss: 0.7099
Training Epoch: 33 [12288/50176]	Loss: 0.7174
Training Epoch: 33 [13312/50176]	Loss: 0.7315
Training Epoch: 33 [14336/50176]	Loss: 0.6486
Training Epoch: 33 [15360/50176]	Loss: 0.6816
Training Epoch: 33 [16384/50176]	Loss: 0.7047
Training Epoch: 33 [17408/50176]	Loss: 0.6472
Training Epoch: 33 [18432/50176]	Loss: 0.7314
Training Epoch: 33 [19456/50176]	Loss: 0.6864
Training Epoch: 33 [20480/50176]	Loss: 0.6745
Training Epoch: 33 [21504/50176]	Loss: 0.7314
Training Epoch: 33 [22528/50176]	Loss: 0.7062
Training Epoch: 33 [23552/50176]	Loss: 0.7527
Training Epoch: 33 [24576/50176]	Loss: 0.6547
Training Epoch: 33 [25600/50176]	Loss: 0.7138
Training Epoch: 33 [26624/50176]	Loss: 0.6515
Training Epoch: 33 [27648/50176]	Loss: 0.6949
Training Epoch: 33 [28672/50176]	Loss: 0.7180
Training Epoch: 33 [29696/50176]	Loss: 0.6777
Training Epoch: 33 [30720/50176]	Loss: 0.7534
Training Epoch: 33 [31744/50176]	Loss: 0.6907
Training Epoch: 33 [32768/50176]	Loss: 0.7437
Training Epoch: 33 [33792/50176]	Loss: 0.7680
Training Epoch: 33 [34816/50176]	Loss: 0.7025
Training Epoch: 33 [35840/50176]	Loss: 0.6707
Training Epoch: 33 [36864/50176]	Loss: 0.6641
Training Epoch: 33 [37888/50176]	Loss: 0.7303
Training Epoch: 33 [38912/50176]	Loss: 0.7635
Training Epoch: 33 [39936/50176]	Loss: 0.7239
Training Epoch: 33 [40960/50176]	Loss: 0.7193
Training Epoch: 33 [41984/50176]	Loss: 0.7259
Training Epoch: 33 [43008/50176]	Loss: 0.7161
Training Epoch: 33 [44032/50176]	Loss: 0.7266
Training Epoch: 33 [45056/50176]	Loss: 0.7686
Training Epoch: 33 [46080/50176]	Loss: 0.6925
Training Epoch: 33 [47104/50176]	Loss: 0.7606
Training Epoch: 33 [48128/50176]	Loss: 0.7443
Training Epoch: 33 [49152/50176]	Loss: 0.6840
Training Epoch: 33 [50176/50176]	Loss: 0.7509
2022-12-06 17:37:37.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:37:37,613 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.95 energy=489.97
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Up to epoch 34: time=1692.88, energy=233318.50, cost=264786.38
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Expected next epoch: time=1740.16, energy=240102.45, cost=272314.83
2022-12-06 12:37:37,615 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0019, Accuracy: 0.5462
2022-12-06 12:37:37,786 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:37:37,786 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:37:37.790 [ZeusMonitor] Monitor started.
2022-12-06 17:37:37.790 [ZeusMonitor] Running indefinitely. 2022-12-06 17:37:37.790 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:37:37.790 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 12:38:23,293 [ZeusDataLoader(train)] train epoch 35 done: time=45.67 energy=6418.76
2022-12-06 12:38:23,297 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.6476
Training Epoch: 34 [2048/50176]	Loss: 0.6259
Training Epoch: 34 [3072/50176]	Loss: 0.6547
Training Epoch: 34 [4096/50176]	Loss: 0.6056
Training Epoch: 34 [5120/50176]	Loss: 0.6375
Training Epoch: 34 [6144/50176]	Loss: 0.6322
Training Epoch: 34 [7168/50176]	Loss: 0.6160
Training Epoch: 34 [8192/50176]	Loss: 0.6302
Training Epoch: 34 [9216/50176]	Loss: 0.5886
Training Epoch: 34 [10240/50176]	Loss: 0.7180
Training Epoch: 34 [11264/50176]	Loss: 0.6095
Training Epoch: 34 [12288/50176]	Loss: 0.6845
Training Epoch: 34 [13312/50176]	Loss: 0.6026
Training Epoch: 34 [14336/50176]	Loss: 0.6130
Training Epoch: 34 [15360/50176]	Loss: 0.6600
Training Epoch: 34 [16384/50176]	Loss: 0.7608
Training Epoch: 34 [17408/50176]	Loss: 0.5864
Training Epoch: 34 [18432/50176]	Loss: 0.6438
Training Epoch: 34 [19456/50176]	Loss: 0.5998
Training Epoch: 34 [20480/50176]	Loss: 0.6411
Training Epoch: 34 [21504/50176]	Loss: 0.7027
Training Epoch: 34 [22528/50176]	Loss: 0.6436
Training Epoch: 34 [23552/50176]	Loss: 0.6394
Training Epoch: 34 [24576/50176]	Loss: 0.5827
Training Epoch: 34 [25600/50176]	Loss: 0.6477
Training Epoch: 34 [26624/50176]	Loss: 0.7079
Training Epoch: 34 [27648/50176]	Loss: 0.6978
Training Epoch: 34 [28672/50176]	Loss: 0.6901
Training Epoch: 34 [29696/50176]	Loss: 0.6613
Training Epoch: 34 [30720/50176]	Loss: 0.7522
Training Epoch: 34 [31744/50176]	Loss: 0.6623
Training Epoch: 34 [32768/50176]	Loss: 0.7091
Training Epoch: 34 [33792/50176]	Loss: 0.6868
Training Epoch: 34 [34816/50176]	Loss: 0.6961
Training Epoch: 34 [35840/50176]	Loss: 0.6986
Training Epoch: 34 [36864/50176]	Loss: 0.6731
Training Epoch: 34 [37888/50176]	Loss: 0.7211
Training Epoch: 34 [38912/50176]	Loss: 0.6349
Training Epoch: 34 [39936/50176]	Loss: 0.6705
Training Epoch: 34 [40960/50176]	Loss: 0.6959
Training Epoch: 34 [41984/50176]	Loss: 0.6413
Training Epoch: 34 [43008/50176]	Loss: 0.7307
Training Epoch: 34 [44032/50176]	Loss: 0.6586
Training Epoch: 34 [45056/50176]	Loss: 0.7485
Training Epoch: 34 [46080/50176]	Loss: 0.6360
Training Epoch: 34 [47104/50176]	Loss: 0.7374
Training Epoch: 34 [48128/50176]	Loss: 0.7359
Training Epoch: 34 [49152/50176]	Loss: 0.7447
Training Epoch: 34 [50176/50176]	Loss: 0.7183
2022-12-06 17:38:27.023 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:38:27,042 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.74 energy=473.13
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Up to epoch 35: time=1742.29, energy=240210.39, cost=272555.48
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Expected next epoch: time=1789.56, energy=246994.34, cost=280083.93
2022-12-06 12:38:27,043 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0019, Accuracy: 0.5517
2022-12-06 12:38:27,216 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:38:27,217 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:38:27.220 [ZeusMonitor] Monitor started.
2022-12-06 17:38:27.220 [ZeusMonitor] Running indefinitely. 2022-12-06 17:38:27.220 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:38:27.220 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 12:39:11,739 [ZeusDataLoader(train)] train epoch 36 done: time=44.69 energy=6339.17
2022-12-06 12:39:11,743 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.6057
Training Epoch: 35 [2048/50176]	Loss: 0.6387
Training Epoch: 35 [3072/50176]	Loss: 0.6062
Training Epoch: 35 [4096/50176]	Loss: 0.5890
Training Epoch: 35 [5120/50176]	Loss: 0.5871
Training Epoch: 35 [6144/50176]	Loss: 0.5799
Training Epoch: 35 [7168/50176]	Loss: 0.6287
Training Epoch: 35 [8192/50176]	Loss: 0.6076
Training Epoch: 35 [9216/50176]	Loss: 0.5768
Training Epoch: 35 [10240/50176]	Loss: 0.5873
Training Epoch: 35 [11264/50176]	Loss: 0.6316
Training Epoch: 35 [12288/50176]	Loss: 0.6574
Training Epoch: 35 [13312/50176]	Loss: 0.5957
Training Epoch: 35 [14336/50176]	Loss: 0.6247
Training Epoch: 35 [15360/50176]	Loss: 0.5966
Training Epoch: 35 [16384/50176]	Loss: 0.6291
Training Epoch: 35 [17408/50176]	Loss: 0.7003
Training Epoch: 35 [18432/50176]	Loss: 0.6405
Training Epoch: 35 [19456/50176]	Loss: 0.6712
Training Epoch: 35 [20480/50176]	Loss: 0.5880
Training Epoch: 35 [21504/50176]	Loss: 0.6070
Training Epoch: 35 [22528/50176]	Loss: 0.6519
Training Epoch: 35 [23552/50176]	Loss: 0.6518
Training Epoch: 35 [24576/50176]	Loss: 0.7127
Training Epoch: 35 [25600/50176]	Loss: 0.6540
Training Epoch: 35 [26624/50176]	Loss: 0.6140
Training Epoch: 35 [27648/50176]	Loss: 0.6394
Training Epoch: 35 [28672/50176]	Loss: 0.6632
Training Epoch: 35 [29696/50176]	Loss: 0.6315
Training Epoch: 35 [30720/50176]	Loss: 0.6586
Training Epoch: 35 [31744/50176]	Loss: 0.6624
Training Epoch: 35 [32768/50176]	Loss: 0.6179
Training Epoch: 35 [33792/50176]	Loss: 0.6063
Training Epoch: 35 [34816/50176]	Loss: 0.6393
Training Epoch: 35 [35840/50176]	Loss: 0.6778
Training Epoch: 35 [36864/50176]	Loss: 0.7243
Training Epoch: 35 [37888/50176]	Loss: 0.6901
Training Epoch: 35 [38912/50176]	Loss: 0.6267
Training Epoch: 35 [39936/50176]	Loss: 0.7467
Training Epoch: 35 [40960/50176]	Loss: 0.6322
Training Epoch: 35 [41984/50176]	Loss: 0.7142
Training Epoch: 35 [43008/50176]	Loss: 0.6459
Training Epoch: 35 [44032/50176]	Loss: 0.6635
Training Epoch: 35 [45056/50176]	Loss: 0.6451
Training Epoch: 35 [46080/50176]	Loss: 0.6851
Training Epoch: 35 [47104/50176]	Loss: 0.6743
Training Epoch: 35 [48128/50176]	Loss: 0.6862
Training Epoch: 35 [49152/50176]	Loss: 0.6765
Training Epoch: 35 [50176/50176]	Loss: 0.6694
2022-12-06 17:39:15.434 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:39:15,453 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.70 energy=475.87
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Up to epoch 36: time=1790.68, energy=247025.44, cost=280197.15
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Expected next epoch: time=1837.95, energy=253809.39, cost=287725.61
2022-12-06 12:39:15,454 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0020, Accuracy: 0.5344
2022-12-06 12:39:15,679 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:39:15,679 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:39:15.681 [ZeusMonitor] Monitor started.
2022-12-06 17:39:15.681 [ZeusMonitor] Running indefinitely. 2022-12-06 17:39:15.681 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:39:15.681 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 12:40:00,189 [ZeusDataLoader(train)] train epoch 37 done: time=44.73 energy=6359.94
2022-12-06 12:40:00,193 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.5426
Training Epoch: 36 [2048/50176]	Loss: 0.5486
Training Epoch: 36 [3072/50176]	Loss: 0.5418
Training Epoch: 36 [4096/50176]	Loss: 0.5532
Training Epoch: 36 [5120/50176]	Loss: 0.5858
Training Epoch: 36 [6144/50176]	Loss: 0.5475
Training Epoch: 36 [7168/50176]	Loss: 0.6071
Training Epoch: 36 [8192/50176]	Loss: 0.6229
Training Epoch: 36 [9216/50176]	Loss: 0.5483
Training Epoch: 36 [10240/50176]	Loss: 0.6312
Training Epoch: 36 [11264/50176]	Loss: 0.5843
Training Epoch: 36 [12288/50176]	Loss: 0.6164
Training Epoch: 36 [13312/50176]	Loss: 0.5869
Training Epoch: 36 [14336/50176]	Loss: 0.5589
Training Epoch: 36 [15360/50176]	Loss: 0.6064
Training Epoch: 36 [16384/50176]	Loss: 0.5842
Training Epoch: 36 [17408/50176]	Loss: 0.6014
Training Epoch: 36 [18432/50176]	Loss: 0.6180
Training Epoch: 36 [19456/50176]	Loss: 0.5815
Training Epoch: 36 [20480/50176]	Loss: 0.5797
Training Epoch: 36 [21504/50176]	Loss: 0.6020
Training Epoch: 36 [22528/50176]	Loss: 0.6371
Training Epoch: 36 [23552/50176]	Loss: 0.5332
Training Epoch: 36 [24576/50176]	Loss: 0.6463
Training Epoch: 36 [25600/50176]	Loss: 0.6506
Training Epoch: 36 [26624/50176]	Loss: 0.6641
Training Epoch: 36 [27648/50176]	Loss: 0.6222
Training Epoch: 36 [28672/50176]	Loss: 0.6223
Training Epoch: 36 [29696/50176]	Loss: 0.6028
Training Epoch: 36 [30720/50176]	Loss: 0.6458
Training Epoch: 36 [31744/50176]	Loss: 0.5731
Training Epoch: 36 [32768/50176]	Loss: 0.6402
Training Epoch: 36 [33792/50176]	Loss: 0.6217
Training Epoch: 36 [34816/50176]	Loss: 0.6545
Training Epoch: 36 [35840/50176]	Loss: 0.6022
Training Epoch: 36 [36864/50176]	Loss: 0.6147
Training Epoch: 36 [37888/50176]	Loss: 0.6401
Training Epoch: 36 [38912/50176]	Loss: 0.6510
Training Epoch: 36 [39936/50176]	Loss: 0.6047
Training Epoch: 36 [40960/50176]	Loss: 0.6346
Training Epoch: 36 [41984/50176]	Loss: 0.6556
Training Epoch: 36 [43008/50176]	Loss: 0.6907
Training Epoch: 36 [44032/50176]	Loss: 0.6556
Training Epoch: 36 [45056/50176]	Loss: 0.5875
Training Epoch: 36 [46080/50176]	Loss: 0.6261
Training Epoch: 36 [47104/50176]	Loss: 0.6181
Training Epoch: 36 [48128/50176]	Loss: 0.6041
Training Epoch: 36 [49152/50176]	Loss: 0.6149
Training Epoch: 36 [50176/50176]	Loss: 0.6577
2022-12-06 17:40:04.009 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:40:04,038 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.84 energy=481.27
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Up to epoch 37: time=1839.24, energy=253866.65, cost=287867.14
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Expected next epoch: time=1886.52, energy=260650.60, cost=295395.59
2022-12-06 12:40:04,039 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0019, Accuracy: 0.5499
2022-12-06 12:40:04,254 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:40:04,255 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:40:04.269 [ZeusMonitor] Monitor started.
2022-12-06 17:40:04.269 [ZeusMonitor] Running indefinitely. 2022-12-06 17:40:04.269 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:40:04.269 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 12:40:48,722 [ZeusDataLoader(train)] train epoch 38 done: time=44.67 energy=6342.13
2022-12-06 12:40:48,725 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.5025
Training Epoch: 37 [2048/50176]	Loss: 0.5787
Training Epoch: 37 [3072/50176]	Loss: 0.5339
Training Epoch: 37 [4096/50176]	Loss: 0.5511
Training Epoch: 37 [5120/50176]	Loss: 0.5672
Training Epoch: 37 [6144/50176]	Loss: 0.5333
Training Epoch: 37 [7168/50176]	Loss: 0.5321
Training Epoch: 37 [8192/50176]	Loss: 0.5188
Training Epoch: 37 [9216/50176]	Loss: 0.5320
Training Epoch: 37 [10240/50176]	Loss: 0.5610
Training Epoch: 37 [11264/50176]	Loss: 0.5490
Training Epoch: 37 [12288/50176]	Loss: 0.5585
Training Epoch: 37 [13312/50176]	Loss: 0.5294
Training Epoch: 37 [14336/50176]	Loss: 0.4968
Training Epoch: 37 [15360/50176]	Loss: 0.5688
Training Epoch: 37 [16384/50176]	Loss: 0.5684
Training Epoch: 37 [17408/50176]	Loss: 0.5816
Training Epoch: 37 [18432/50176]	Loss: 0.5292
Training Epoch: 37 [19456/50176]	Loss: 0.5304
Training Epoch: 37 [20480/50176]	Loss: 0.5770
Training Epoch: 37 [21504/50176]	Loss: 0.5667
Training Epoch: 37 [22528/50176]	Loss: 0.5347
Training Epoch: 37 [23552/50176]	Loss: 0.5631
Training Epoch: 37 [24576/50176]	Loss: 0.5560
Training Epoch: 37 [25600/50176]	Loss: 0.5527
Training Epoch: 37 [26624/50176]	Loss: 0.5966
Training Epoch: 37 [27648/50176]	Loss: 0.5792
Training Epoch: 37 [28672/50176]	Loss: 0.6197
Training Epoch: 37 [29696/50176]	Loss: 0.5783
Training Epoch: 37 [30720/50176]	Loss: 0.5379
Training Epoch: 37 [31744/50176]	Loss: 0.5274
Training Epoch: 37 [32768/50176]	Loss: 0.5577
Training Epoch: 37 [33792/50176]	Loss: 0.5693
Training Epoch: 37 [34816/50176]	Loss: 0.6573
Training Epoch: 37 [35840/50176]	Loss: 0.6026
Training Epoch: 37 [36864/50176]	Loss: 0.5515
Training Epoch: 37 [37888/50176]	Loss: 0.6687
Training Epoch: 37 [38912/50176]	Loss: 0.6344
Training Epoch: 37 [39936/50176]	Loss: 0.5717
Training Epoch: 37 [40960/50176]	Loss: 0.6106
Training Epoch: 37 [41984/50176]	Loss: 0.6070
Training Epoch: 37 [43008/50176]	Loss: 0.5974
Training Epoch: 37 [44032/50176]	Loss: 0.6431
Training Epoch: 37 [45056/50176]	Loss: 0.6807
Training Epoch: 37 [46080/50176]	Loss: 0.6157
Training Epoch: 37 [47104/50176]	Loss: 0.6138
Training Epoch: 37 [48128/50176]	Loss: 0.6438
Training Epoch: 37 [49152/50176]	Loss: 0.5941
Training Epoch: 37 [50176/50176]	Loss: 0.6437
2022-12-06 17:40:52.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:40:52,463 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.73 energy=478.21
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Up to epoch 38: time=1887.65, energy=260686.99, cost=295512.78
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Expected next epoch: time=1934.92, energy=267470.94, cost=303041.24
2022-12-06 12:40:52,465 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0020, Accuracy: 0.5605
2022-12-06 12:40:52,676 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:40:52,676 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:40:52.678 [ZeusMonitor] Monitor started.
2022-12-06 17:40:52.678 [ZeusMonitor] Running indefinitely. 2022-12-06 17:40:52.678 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:40:52.678 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 12:41:36,951 [ZeusDataLoader(train)] train epoch 39 done: time=44.48 energy=6324.51
2022-12-06 12:41:36,954 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.5354
Training Epoch: 38 [2048/50176]	Loss: 0.4899
Training Epoch: 38 [3072/50176]	Loss: 0.5133
Training Epoch: 38 [4096/50176]	Loss: 0.4962
Training Epoch: 38 [5120/50176]	Loss: 0.5100
Training Epoch: 38 [6144/50176]	Loss: 0.4689
Training Epoch: 38 [7168/50176]	Loss: 0.5325
Training Epoch: 38 [8192/50176]	Loss: 0.4927
Training Epoch: 38 [9216/50176]	Loss: 0.5097
Training Epoch: 38 [10240/50176]	Loss: 0.5251
Training Epoch: 38 [11264/50176]	Loss: 0.5955
Training Epoch: 38 [12288/50176]	Loss: 0.5154
Training Epoch: 38 [13312/50176]	Loss: 0.5486
Training Epoch: 38 [14336/50176]	Loss: 0.5398
Training Epoch: 38 [15360/50176]	Loss: 0.5413
Training Epoch: 38 [16384/50176]	Loss: 0.5260
Training Epoch: 38 [17408/50176]	Loss: 0.5517
Training Epoch: 38 [18432/50176]	Loss: 0.5503
Training Epoch: 38 [19456/50176]	Loss: 0.5158
Training Epoch: 38 [20480/50176]	Loss: 0.5381
Training Epoch: 38 [21504/50176]	Loss: 0.5063
Training Epoch: 38 [22528/50176]	Loss: 0.5731
Training Epoch: 38 [23552/50176]	Loss: 0.5644
Training Epoch: 38 [24576/50176]	Loss: 0.5514
Training Epoch: 38 [25600/50176]	Loss: 0.4790
Training Epoch: 38 [26624/50176]	Loss: 0.5865
Training Epoch: 38 [27648/50176]	Loss: 0.5443
Training Epoch: 38 [28672/50176]	Loss: 0.6148
Training Epoch: 38 [29696/50176]	Loss: 0.5385
Training Epoch: 38 [30720/50176]	Loss: 0.5559
Training Epoch: 38 [31744/50176]	Loss: 0.5290
Training Epoch: 38 [32768/50176]	Loss: 0.5992
Training Epoch: 38 [33792/50176]	Loss: 0.5534
Training Epoch: 38 [34816/50176]	Loss: 0.5992
Training Epoch: 38 [35840/50176]	Loss: 0.5418
Training Epoch: 38 [36864/50176]	Loss: 0.5511
Training Epoch: 38 [37888/50176]	Loss: 0.5624
Training Epoch: 38 [38912/50176]	Loss: 0.5408
Training Epoch: 38 [39936/50176]	Loss: 0.5837
Training Epoch: 38 [40960/50176]	Loss: 0.6010
Training Epoch: 38 [41984/50176]	Loss: 0.5159
Training Epoch: 38 [43008/50176]	Loss: 0.6153
Training Epoch: 38 [44032/50176]	Loss: 0.5765
Training Epoch: 38 [45056/50176]	Loss: 0.5358
Training Epoch: 38 [46080/50176]	Loss: 0.5517
Training Epoch: 38 [47104/50176]	Loss: 0.6550
Training Epoch: 38 [48128/50176]	Loss: 0.5686
Training Epoch: 38 [49152/50176]	Loss: 0.6230
Training Epoch: 38 [50176/50176]	Loss: 0.5946
2022-12-06 17:41:40.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:41:40,765 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.80 energy=490.44
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Up to epoch 39: time=1935.93, energy=267501.94, cost=303144.85
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Expected next epoch: time=1983.20, energy=274285.89, cost=310673.30
2022-12-06 12:41:40,766 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0019, Accuracy: 0.5514
2022-12-06 12:41:40,982 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:41:40,983 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:41:40.985 [ZeusMonitor] Monitor started.
2022-12-06 17:41:40.985 [ZeusMonitor] Running indefinitely. 2022-12-06 17:41:40.985 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:41:40.985 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 12:42:25,700 [ZeusDataLoader(train)] train epoch 40 done: time=44.93 energy=6362.34
2022-12-06 12:42:25,703 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.4319
Training Epoch: 39 [2048/50176]	Loss: 0.4684
Training Epoch: 39 [3072/50176]	Loss: 0.4932
Training Epoch: 39 [4096/50176]	Loss: 0.5099
Training Epoch: 39 [5120/50176]	Loss: 0.5107
Training Epoch: 39 [6144/50176]	Loss: 0.5102
Training Epoch: 39 [7168/50176]	Loss: 0.4494
Training Epoch: 39 [8192/50176]	Loss: 0.5128
Training Epoch: 39 [9216/50176]	Loss: 0.4987
Training Epoch: 39 [10240/50176]	Loss: 0.4845
Training Epoch: 39 [11264/50176]	Loss: 0.4680
Training Epoch: 39 [12288/50176]	Loss: 0.4789
Training Epoch: 39 [13312/50176]	Loss: 0.4796
Training Epoch: 39 [14336/50176]	Loss: 0.5228
Training Epoch: 39 [15360/50176]	Loss: 0.4938
Training Epoch: 39 [16384/50176]	Loss: 0.4914
Training Epoch: 39 [17408/50176]	Loss: 0.4741
Training Epoch: 39 [18432/50176]	Loss: 0.4768
Training Epoch: 39 [19456/50176]	Loss: 0.5402
Training Epoch: 39 [20480/50176]	Loss: 0.5174
Training Epoch: 39 [21504/50176]	Loss: 0.5450
Training Epoch: 39 [22528/50176]	Loss: 0.5003
Training Epoch: 39 [23552/50176]	Loss: 0.4624
Training Epoch: 39 [24576/50176]	Loss: 0.4680
Training Epoch: 39 [25600/50176]	Loss: 0.5590
Training Epoch: 39 [26624/50176]	Loss: 0.5511
Training Epoch: 39 [27648/50176]	Loss: 0.5657
Training Epoch: 39 [28672/50176]	Loss: 0.5030
Training Epoch: 39 [29696/50176]	Loss: 0.5958
Training Epoch: 39 [30720/50176]	Loss: 0.5254
Training Epoch: 39 [31744/50176]	Loss: 0.5896
Training Epoch: 39 [32768/50176]	Loss: 0.4809
Training Epoch: 39 [33792/50176]	Loss: 0.5281
Training Epoch: 39 [34816/50176]	Loss: 0.6181
Training Epoch: 39 [35840/50176]	Loss: 0.5370
Training Epoch: 39 [36864/50176]	Loss: 0.5161
Training Epoch: 39 [37888/50176]	Loss: 0.5314
Training Epoch: 39 [38912/50176]	Loss: 0.5436
Training Epoch: 39 [39936/50176]	Loss: 0.6255
Training Epoch: 39 [40960/50176]	Loss: 0.6235
Training Epoch: 39 [41984/50176]	Loss: 0.5754
Training Epoch: 39 [43008/50176]	Loss: 0.5459
Training Epoch: 39 [44032/50176]	Loss: 0.5556
Training Epoch: 39 [45056/50176]	Loss: 0.6082
Training Epoch: 39 [46080/50176]	Loss: 0.5385
Training Epoch: 39 [47104/50176]	Loss: 0.5602
Training Epoch: 39 [48128/50176]	Loss: 0.4780
Training Epoch: 39 [49152/50176]	Loss: 0.5225
Training Epoch: 39 [50176/50176]	Loss: 0.6544
2022-12-06 17:42:29.422 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:42:29,439 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.73 energy=479.74
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Up to epoch 40: time=1984.58, energy=274344.02, cost=310823.09
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Expected next epoch: time=2031.86, energy=281127.97, cost=318351.54
2022-12-06 12:42:29,440 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0020, Accuracy: 0.5554
2022-12-06 12:42:29,659 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:42:29,659 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:42:29.661 [ZeusMonitor] Monitor started.
2022-12-06 17:42:29.661 [ZeusMonitor] Running indefinitely. 2022-12-06 17:42:29.661 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:42:29.661 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 12:43:13,855 [ZeusDataLoader(train)] train epoch 41 done: time=44.41 energy=6336.25
2022-12-06 12:43:13,859 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.4307
Training Epoch: 40 [2048/50176]	Loss: 0.4184
Training Epoch: 40 [3072/50176]	Loss: 0.4413
Training Epoch: 40 [4096/50176]	Loss: 0.4538
Training Epoch: 40 [5120/50176]	Loss: 0.4702
Training Epoch: 40 [6144/50176]	Loss: 0.4863
Training Epoch: 40 [7168/50176]	Loss: 0.4103
Training Epoch: 40 [8192/50176]	Loss: 0.4636
Training Epoch: 40 [9216/50176]	Loss: 0.4564
Training Epoch: 40 [10240/50176]	Loss: 0.4463
Training Epoch: 40 [11264/50176]	Loss: 0.4303
Training Epoch: 40 [12288/50176]	Loss: 0.5063
Training Epoch: 40 [13312/50176]	Loss: 0.4705
Training Epoch: 40 [14336/50176]	Loss: 0.4352
Training Epoch: 40 [15360/50176]	Loss: 0.4649
Training Epoch: 40 [16384/50176]	Loss: 0.4641
Training Epoch: 40 [17408/50176]	Loss: 0.4389
Training Epoch: 40 [18432/50176]	Loss: 0.4665
Training Epoch: 40 [19456/50176]	Loss: 0.5016
Training Epoch: 40 [20480/50176]	Loss: 0.4611
Training Epoch: 40 [21504/50176]	Loss: 0.4860
Training Epoch: 40 [22528/50176]	Loss: 0.4858
Training Epoch: 40 [23552/50176]	Loss: 0.5109
Training Epoch: 40 [24576/50176]	Loss: 0.5510
Training Epoch: 40 [25600/50176]	Loss: 0.5213
Training Epoch: 40 [26624/50176]	Loss: 0.4737
Training Epoch: 40 [27648/50176]	Loss: 0.4522
Training Epoch: 40 [28672/50176]	Loss: 0.4955
Training Epoch: 40 [29696/50176]	Loss: 0.4722
Training Epoch: 40 [30720/50176]	Loss: 0.4909
Training Epoch: 40 [31744/50176]	Loss: 0.4855
Training Epoch: 40 [32768/50176]	Loss: 0.5414
Training Epoch: 40 [33792/50176]	Loss: 0.5264
Training Epoch: 40 [34816/50176]	Loss: 0.4810
Training Epoch: 40 [35840/50176]	Loss: 0.4673
Training Epoch: 40 [36864/50176]	Loss: 0.5042
Training Epoch: 40 [37888/50176]	Loss: 0.4423
Training Epoch: 40 [38912/50176]	Loss: 0.5034
Training Epoch: 40 [39936/50176]	Loss: 0.5393
Training Epoch: 40 [40960/50176]	Loss: 0.5368
Training Epoch: 40 [41984/50176]	Loss: 0.5246
Training Epoch: 40 [43008/50176]	Loss: 0.5676
Training Epoch: 40 [44032/50176]	Loss: 0.5001
Training Epoch: 40 [45056/50176]	Loss: 0.5396
Training Epoch: 40 [46080/50176]	Loss: 0.5629
Training Epoch: 40 [47104/50176]	Loss: 0.5132
Training Epoch: 40 [48128/50176]	Loss: 0.5549
Training Epoch: 40 [49152/50176]	Loss: 0.5509
Training Epoch: 40 [50176/50176]	Loss: 0.5590
2022-12-06 17:43:17.638 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:43:17,661 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.79 energy=477.03
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Up to epoch 41: time=2032.79, energy=281157.29, cost=318447.41
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Expected next epoch: time=2080.06, energy=287941.24, cost=325975.87
2022-12-06 12:43:17,663 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0020, Accuracy: 0.5716
2022-12-06 12:43:17,839 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:43:17,840 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:43:17.841 [ZeusMonitor] Monitor started.
2022-12-06 17:43:17.842 [ZeusMonitor] Running indefinitely. 2022-12-06 17:43:17.842 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:43:17.842 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 12:44:01,830 [ZeusDataLoader(train)] train epoch 42 done: time=44.16 energy=6307.78
2022-12-06 12:44:01,834 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.4208
Training Epoch: 41 [2048/50176]	Loss: 0.4316
Training Epoch: 41 [3072/50176]	Loss: 0.4191
Training Epoch: 41 [4096/50176]	Loss: 0.4459
Training Epoch: 41 [5120/50176]	Loss: 0.4343
Training Epoch: 41 [6144/50176]	Loss: 0.4890
Training Epoch: 41 [7168/50176]	Loss: 0.4755
Training Epoch: 41 [8192/50176]	Loss: 0.4317
Training Epoch: 41 [9216/50176]	Loss: 0.4925
Training Epoch: 41 [10240/50176]	Loss: 0.4851
Training Epoch: 41 [11264/50176]	Loss: 0.4281
Training Epoch: 41 [12288/50176]	Loss: 0.4352
Training Epoch: 41 [13312/50176]	Loss: 0.4485
Training Epoch: 41 [14336/50176]	Loss: 0.4323
Training Epoch: 41 [15360/50176]	Loss: 0.4575
Training Epoch: 41 [16384/50176]	Loss: 0.4157
Training Epoch: 41 [17408/50176]	Loss: 0.4814
Training Epoch: 41 [18432/50176]	Loss: 0.4706
Training Epoch: 41 [19456/50176]	Loss: 0.5154
Training Epoch: 41 [20480/50176]	Loss: 0.4423
Training Epoch: 41 [21504/50176]	Loss: 0.4511
Training Epoch: 41 [22528/50176]	Loss: 0.4535
Training Epoch: 41 [23552/50176]	Loss: 0.4713
Training Epoch: 41 [24576/50176]	Loss: 0.4649
Training Epoch: 41 [25600/50176]	Loss: 0.4151
Training Epoch: 41 [26624/50176]	Loss: 0.4600
Training Epoch: 41 [27648/50176]	Loss: 0.4459
Training Epoch: 41 [28672/50176]	Loss: 0.4971
Training Epoch: 41 [29696/50176]	Loss: 0.4807
Training Epoch: 41 [30720/50176]	Loss: 0.4618
Training Epoch: 41 [31744/50176]	Loss: 0.4997
Training Epoch: 41 [32768/50176]	Loss: 0.4664
Training Epoch: 41 [33792/50176]	Loss: 0.4837
Training Epoch: 41 [34816/50176]	Loss: 0.4453
Training Epoch: 41 [35840/50176]	Loss: 0.4955
Training Epoch: 41 [36864/50176]	Loss: 0.4736
Training Epoch: 41 [37888/50176]	Loss: 0.4733
Training Epoch: 41 [38912/50176]	Loss: 0.4548
Training Epoch: 41 [39936/50176]	Loss: 0.5016
Training Epoch: 41 [40960/50176]	Loss: 0.5581
Training Epoch: 41 [41984/50176]	Loss: 0.5092
Training Epoch: 41 [43008/50176]	Loss: 0.4771
Training Epoch: 41 [44032/50176]	Loss: 0.5180
Training Epoch: 41 [45056/50176]	Loss: 0.4912
Training Epoch: 41 [46080/50176]	Loss: 0.4978
Training Epoch: 41 [47104/50176]	Loss: 0.4926
Training Epoch: 41 [48128/50176]	Loss: 0.5067
Training Epoch: 41 [49152/50176]	Loss: 0.5394
Training Epoch: 41 [50176/50176]	Loss: 0.5145
2022-12-06 17:44:05.530 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:44:05,554 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.71 energy=473.44
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Up to epoch 42: time=2080.66, energy=287938.50, cost=326026.79
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Expected next epoch: time=2127.93, energy=294722.45, cost=333555.25
2022-12-06 12:44:05,555 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0020, Accuracy: 0.5665
2022-12-06 12:44:05,733 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:44:05,734 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:44:05.738 [ZeusMonitor] Monitor started.
2022-12-06 17:44:05.738 [ZeusMonitor] Running indefinitely. 2022-12-06 17:44:05.738 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:44:05.738 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 12:44:49,828 [ZeusDataLoader(train)] train epoch 43 done: time=44.26 energy=6315.54
2022-12-06 12:44:49,831 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.3529
Training Epoch: 42 [2048/50176]	Loss: 0.3621
Training Epoch: 42 [3072/50176]	Loss: 0.4193
Training Epoch: 42 [4096/50176]	Loss: 0.4307
Training Epoch: 42 [5120/50176]	Loss: 0.4412
Training Epoch: 42 [6144/50176]	Loss: 0.4080
Training Epoch: 42 [7168/50176]	Loss: 0.4133
Training Epoch: 42 [8192/50176]	Loss: 0.4271
Training Epoch: 42 [9216/50176]	Loss: 0.4215
Training Epoch: 42 [10240/50176]	Loss: 0.4452
Training Epoch: 42 [11264/50176]	Loss: 0.4003
Training Epoch: 42 [12288/50176]	Loss: 0.4458
Training Epoch: 42 [13312/50176]	Loss: 0.4143
Training Epoch: 42 [14336/50176]	Loss: 0.4448
Training Epoch: 42 [15360/50176]	Loss: 0.4392
Training Epoch: 42 [16384/50176]	Loss: 0.3885
Training Epoch: 42 [17408/50176]	Loss: 0.4096
Training Epoch: 42 [18432/50176]	Loss: 0.4231
Training Epoch: 42 [19456/50176]	Loss: 0.4378
Training Epoch: 42 [20480/50176]	Loss: 0.4201
Training Epoch: 42 [21504/50176]	Loss: 0.4055
Training Epoch: 42 [22528/50176]	Loss: 0.4369
Training Epoch: 42 [23552/50176]	Loss: 0.4561
Training Epoch: 42 [24576/50176]	Loss: 0.3996
Training Epoch: 42 [25600/50176]	Loss: 0.4939
Training Epoch: 42 [26624/50176]	Loss: 0.4259
Training Epoch: 42 [27648/50176]	Loss: 0.4446
Training Epoch: 42 [28672/50176]	Loss: 0.4364
Training Epoch: 42 [29696/50176]	Loss: 0.4795
Training Epoch: 42 [30720/50176]	Loss: 0.4536
Training Epoch: 42 [31744/50176]	Loss: 0.4312
Training Epoch: 42 [32768/50176]	Loss: 0.4346
Training Epoch: 42 [33792/50176]	Loss: 0.4048
Training Epoch: 42 [34816/50176]	Loss: 0.4657
Training Epoch: 42 [35840/50176]	Loss: 0.5142
Training Epoch: 42 [36864/50176]	Loss: 0.5024
Training Epoch: 42 [37888/50176]	Loss: 0.4715
Training Epoch: 42 [38912/50176]	Loss: 0.4501
Training Epoch: 42 [39936/50176]	Loss: 0.4407
Training Epoch: 42 [40960/50176]	Loss: 0.5408
Training Epoch: 42 [41984/50176]	Loss: 0.4356
Training Epoch: 42 [43008/50176]	Loss: 0.5006
Training Epoch: 42 [44032/50176]	Loss: 0.5027
Training Epoch: 42 [45056/50176]	Loss: 0.4319
Training Epoch: 42 [46080/50176]	Loss: 0.5361
Training Epoch: 42 [47104/50176]	Loss: 0.4918
Training Epoch: 42 [48128/50176]	Loss: 0.4753
Training Epoch: 42 [49152/50176]	Loss: 0.5205
Training Epoch: 42 [50176/50176]	Loss: 0.4971
2022-12-06 17:44:53.648 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:44:53,672 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.83 energy=484.50
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Up to epoch 43: time=2128.76, energy=294738.55, cost=333635.39
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Expected next epoch: time=2176.03, energy=301522.50, cost=341163.85
2022-12-06 12:44:53,674 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0021, Accuracy: 0.5643
2022-12-06 12:44:53,839 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:44:53,840 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:44:53.843 [ZeusMonitor] Monitor started.
2022-12-06 17:44:53.843 [ZeusMonitor] Running indefinitely. 2022-12-06 17:44:53.843 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:44:53.843 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 12:45:37,845 [ZeusDataLoader(train)] train epoch 44 done: time=44.16 energy=6302.70
2022-12-06 12:45:37,849 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.3433
Training Epoch: 43 [2048/50176]	Loss: 0.3880
Training Epoch: 43 [3072/50176]	Loss: 0.4185
Training Epoch: 43 [4096/50176]	Loss: 0.4117
Training Epoch: 43 [5120/50176]	Loss: 0.3927
Training Epoch: 43 [6144/50176]	Loss: 0.4034
Training Epoch: 43 [7168/50176]	Loss: 0.4223
Training Epoch: 43 [8192/50176]	Loss: 0.3847
Training Epoch: 43 [9216/50176]	Loss: 0.4165
Training Epoch: 43 [10240/50176]	Loss: 0.4140
Training Epoch: 43 [11264/50176]	Loss: 0.3946
Training Epoch: 43 [12288/50176]	Loss: 0.4118
Training Epoch: 43 [13312/50176]	Loss: 0.3880
Training Epoch: 43 [14336/50176]	Loss: 0.4319
Training Epoch: 43 [15360/50176]	Loss: 0.4282
Training Epoch: 43 [16384/50176]	Loss: 0.4443
Training Epoch: 43 [17408/50176]	Loss: 0.3914
Training Epoch: 43 [18432/50176]	Loss: 0.3859
Training Epoch: 43 [19456/50176]	Loss: 0.4524
Training Epoch: 43 [20480/50176]	Loss: 0.3864
Training Epoch: 43 [21504/50176]	Loss: 0.4516
Training Epoch: 43 [22528/50176]	Loss: 0.3955
Training Epoch: 43 [23552/50176]	Loss: 0.4041
Training Epoch: 43 [24576/50176]	Loss: 0.4085
Training Epoch: 43 [25600/50176]	Loss: 0.4679
Training Epoch: 43 [26624/50176]	Loss: 0.4143
Training Epoch: 43 [27648/50176]	Loss: 0.4134
Training Epoch: 43 [28672/50176]	Loss: 0.3947
Training Epoch: 43 [29696/50176]	Loss: 0.3869
Training Epoch: 43 [30720/50176]	Loss: 0.3804
Training Epoch: 43 [31744/50176]	Loss: 0.4443
Training Epoch: 43 [32768/50176]	Loss: 0.4297
Training Epoch: 43 [33792/50176]	Loss: 0.3885
Training Epoch: 43 [34816/50176]	Loss: 0.4308
Training Epoch: 43 [35840/50176]	Loss: 0.4376
Training Epoch: 43 [36864/50176]	Loss: 0.4387
Training Epoch: 43 [37888/50176]	Loss: 0.4361
Training Epoch: 43 [38912/50176]	Loss: 0.4417
Training Epoch: 43 [39936/50176]	Loss: 0.4062
Training Epoch: 43 [40960/50176]	Loss: 0.3772
Training Epoch: 43 [41984/50176]	Loss: 0.4035
Training Epoch: 43 [43008/50176]	Loss: 0.3958
Training Epoch: 43 [44032/50176]	Loss: 0.4620
Training Epoch: 43 [45056/50176]	Loss: 0.4521
Training Epoch: 43 [46080/50176]	Loss: 0.4098
Training Epoch: 43 [47104/50176]	Loss: 0.4305
Training Epoch: 43 [48128/50176]	Loss: 0.4672
Training Epoch: 43 [49152/50176]	Loss: 0.4342
Training Epoch: 43 [50176/50176]	Loss: 0.4181
2022-12-06 17:45:41.525 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:45:41,536 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.68 energy=459.63
2022-12-06 12:45:41,536 [ZeusDataLoader(train)] Up to epoch 44: time=2176.60, energy=301500.88, cost=341202.69
2022-12-06 12:45:41,536 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:45:41,537 [ZeusDataLoader(train)] Expected next epoch: time=2223.87, energy=308284.83, cost=348731.14
2022-12-06 12:45:41,537 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0021, Accuracy: 0.5706
2022-12-06 12:45:41,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:45:41,758 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:45:41.759 [ZeusMonitor] Monitor started.
2022-12-06 17:45:41.759 [ZeusMonitor] Running indefinitely. 2022-12-06 17:45:41.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:45:41.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 12:46:26,245 [ZeusDataLoader(train)] train epoch 45 done: time=44.70 energy=6349.69
2022-12-06 12:46:26,248 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.3820
Training Epoch: 44 [2048/50176]	Loss: 0.4101
Training Epoch: 44 [3072/50176]	Loss: 0.3711
Training Epoch: 44 [4096/50176]	Loss: 0.4356
Training Epoch: 44 [5120/50176]	Loss: 0.3859
Training Epoch: 44 [6144/50176]	Loss: 0.3442
Training Epoch: 44 [7168/50176]	Loss: 0.3597
Training Epoch: 44 [8192/50176]	Loss: 0.3290
Training Epoch: 44 [9216/50176]	Loss: 0.4071
Training Epoch: 44 [10240/50176]	Loss: 0.3804
Training Epoch: 44 [11264/50176]	Loss: 0.3650
Training Epoch: 44 [12288/50176]	Loss: 0.3735
Training Epoch: 44 [13312/50176]	Loss: 0.3739
Training Epoch: 44 [14336/50176]	Loss: 0.3802
Training Epoch: 44 [15360/50176]	Loss: 0.3748
Training Epoch: 44 [16384/50176]	Loss: 0.3426
Training Epoch: 44 [17408/50176]	Loss: 0.3821
Training Epoch: 44 [18432/50176]	Loss: 0.3669
Training Epoch: 44 [19456/50176]	Loss: 0.3806
Training Epoch: 44 [20480/50176]	Loss: 0.3802
Training Epoch: 44 [21504/50176]	Loss: 0.3952
Training Epoch: 44 [22528/50176]	Loss: 0.3581
Training Epoch: 44 [23552/50176]	Loss: 0.3939
Training Epoch: 44 [24576/50176]	Loss: 0.3987
Training Epoch: 44 [25600/50176]	Loss: 0.4250
Training Epoch: 44 [26624/50176]	Loss: 0.4016
Training Epoch: 44 [27648/50176]	Loss: 0.3582
Training Epoch: 44 [28672/50176]	Loss: 0.3975
Training Epoch: 44 [29696/50176]	Loss: 0.3710
Training Epoch: 44 [30720/50176]	Loss: 0.3587
Training Epoch: 44 [31744/50176]	Loss: 0.4422
Training Epoch: 44 [32768/50176]	Loss: 0.4015
Training Epoch: 44 [33792/50176]	Loss: 0.3838
Training Epoch: 44 [34816/50176]	Loss: 0.4160
Training Epoch: 44 [35840/50176]	Loss: 0.4174
Training Epoch: 44 [36864/50176]	Loss: 0.4433
Training Epoch: 44 [37888/50176]	Loss: 0.4807
Training Epoch: 44 [38912/50176]	Loss: 0.4024
Training Epoch: 44 [39936/50176]	Loss: 0.4094
Training Epoch: 44 [40960/50176]	Loss: 0.3957
Training Epoch: 44 [41984/50176]	Loss: 0.3850
Training Epoch: 44 [43008/50176]	Loss: 0.3961
Training Epoch: 44 [44032/50176]	Loss: 0.4023
Training Epoch: 44 [45056/50176]	Loss: 0.4617
Training Epoch: 44 [46080/50176]	Loss: 0.4211
Training Epoch: 44 [47104/50176]	Loss: 0.4489
Training Epoch: 44 [48128/50176]	Loss: 0.4686
Training Epoch: 44 [49152/50176]	Loss: 0.4945
Training Epoch: 44 [50176/50176]	Loss: 0.4234
2022-12-06 17:46:29.996 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:46:30,051 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.79 energy=489.31
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Up to epoch 45: time=2225.09, energy=308339.88, cost=348865.45
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Expected next epoch: time=2272.37, energy=315123.83, cost=356393.90
2022-12-06 12:46:30,052 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0020, Accuracy: 0.5781
2022-12-06 12:46:30,261 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:46:30,262 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:46:30.276 [ZeusMonitor] Monitor started.
2022-12-06 17:46:30.276 [ZeusMonitor] Running indefinitely. 2022-12-06 17:46:30.276 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:46:30.276 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 12:47:14,766 [ZeusDataLoader(train)] train epoch 46 done: time=44.71 energy=6338.96
2022-12-06 12:47:14,769 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.3057
Training Epoch: 45 [2048/50176]	Loss: 0.3626
Training Epoch: 45 [3072/50176]	Loss: 0.3147
Training Epoch: 45 [4096/50176]	Loss: 0.3580
Training Epoch: 45 [5120/50176]	Loss: 0.3597
Training Epoch: 45 [6144/50176]	Loss: 0.3395
Training Epoch: 45 [7168/50176]	Loss: 0.3043
Training Epoch: 45 [8192/50176]	Loss: 0.4283
Training Epoch: 45 [9216/50176]	Loss: 0.3530
Training Epoch: 45 [10240/50176]	Loss: 0.3658
Training Epoch: 45 [11264/50176]	Loss: 0.4004
Training Epoch: 45 [12288/50176]	Loss: 0.3655
Training Epoch: 45 [13312/50176]	Loss: 0.3498
Training Epoch: 45 [14336/50176]	Loss: 0.3738
Training Epoch: 45 [15360/50176]	Loss: 0.3585
Training Epoch: 45 [16384/50176]	Loss: 0.3708
Training Epoch: 45 [17408/50176]	Loss: 0.3673
Training Epoch: 45 [18432/50176]	Loss: 0.3940
Training Epoch: 45 [19456/50176]	Loss: 0.3524
Training Epoch: 45 [20480/50176]	Loss: 0.3754
Training Epoch: 45 [21504/50176]	Loss: 0.3522
Training Epoch: 45 [22528/50176]	Loss: 0.3614
Training Epoch: 45 [23552/50176]	Loss: 0.3390
Training Epoch: 45 [24576/50176]	Loss: 0.3608
Training Epoch: 45 [25600/50176]	Loss: 0.4176
Training Epoch: 45 [26624/50176]	Loss: 0.3903
Training Epoch: 45 [27648/50176]	Loss: 0.3766
Training Epoch: 45 [28672/50176]	Loss: 0.3706
Training Epoch: 45 [29696/50176]	Loss: 0.3703
Training Epoch: 45 [30720/50176]	Loss: 0.3822
Training Epoch: 45 [31744/50176]	Loss: 0.3333
Training Epoch: 45 [32768/50176]	Loss: 0.4157
Training Epoch: 45 [33792/50176]	Loss: 0.3947
Training Epoch: 45 [34816/50176]	Loss: 0.3924
Training Epoch: 45 [35840/50176]	Loss: 0.4240
Training Epoch: 45 [36864/50176]	Loss: 0.3862
Training Epoch: 45 [37888/50176]	Loss: 0.4048
Training Epoch: 45 [38912/50176]	Loss: 0.4235
Training Epoch: 45 [39936/50176]	Loss: 0.4154
Training Epoch: 45 [40960/50176]	Loss: 0.4279
Training Epoch: 45 [41984/50176]	Loss: 0.3965
Training Epoch: 45 [43008/50176]	Loss: 0.4079
Training Epoch: 45 [44032/50176]	Loss: 0.4415
Training Epoch: 45 [45056/50176]	Loss: 0.4525
Training Epoch: 45 [46080/50176]	Loss: 0.4354
Training Epoch: 45 [47104/50176]	Loss: 0.4204
Training Epoch: 45 [48128/50176]	Loss: 0.3623
Training Epoch: 45 [49152/50176]	Loss: 0.4154
Training Epoch: 45 [50176/50176]	Loss: 0.4581
2022-12-06 17:47:18.480 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:47:18,509 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.73 energy=486.22
2022-12-06 12:47:18,509 [ZeusDataLoader(train)] Up to epoch 46: time=2273.53, energy=315165.06, cost=356516.32
2022-12-06 12:47:18,509 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:47:18,510 [ZeusDataLoader(train)] Expected next epoch: time=2320.80, energy=321949.01, cost=364044.77
2022-12-06 12:47:18,510 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0022, Accuracy: 0.5574
2022-12-06 12:47:18,718 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:47:18,719 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:47:18.737 [ZeusMonitor] Monitor started.
2022-12-06 17:47:18.737 [ZeusMonitor] Running indefinitely. 2022-12-06 17:47:18.737 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:47:18.737 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 12:48:02,903 [ZeusDataLoader(train)] train epoch 47 done: time=44.38 energy=6322.79
2022-12-06 12:48:02,906 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.3852
Training Epoch: 46 [2048/50176]	Loss: 0.3924
Training Epoch: 46 [3072/50176]	Loss: 0.3394
Training Epoch: 46 [4096/50176]	Loss: 0.3348
Training Epoch: 46 [5120/50176]	Loss: 0.3616
Training Epoch: 46 [6144/50176]	Loss: 0.3820
Training Epoch: 46 [7168/50176]	Loss: 0.3755
Training Epoch: 46 [8192/50176]	Loss: 0.3253
Training Epoch: 46 [9216/50176]	Loss: 0.3203
Training Epoch: 46 [10240/50176]	Loss: 0.3593
Training Epoch: 46 [11264/50176]	Loss: 0.3714
Training Epoch: 46 [12288/50176]	Loss: 0.3576
Training Epoch: 46 [13312/50176]	Loss: 0.3655
Training Epoch: 46 [14336/50176]	Loss: 0.4192
Training Epoch: 46 [15360/50176]	Loss: 0.3301
Training Epoch: 46 [16384/50176]	Loss: 0.3288
Training Epoch: 46 [17408/50176]	Loss: 0.3915
Training Epoch: 46 [18432/50176]	Loss: 0.3575
Training Epoch: 46 [19456/50176]	Loss: 0.3674
Training Epoch: 46 [20480/50176]	Loss: 0.3228
Training Epoch: 46 [21504/50176]	Loss: 0.3870
Training Epoch: 46 [22528/50176]	Loss: 0.3442
Training Epoch: 46 [23552/50176]	Loss: 0.3969
Training Epoch: 46 [24576/50176]	Loss: 0.4090
Training Epoch: 46 [25600/50176]	Loss: 0.3801
Training Epoch: 46 [26624/50176]	Loss: 0.3664
Training Epoch: 46 [27648/50176]	Loss: 0.3973
Training Epoch: 46 [28672/50176]	Loss: 0.3381
Training Epoch: 46 [29696/50176]	Loss: 0.3831
Training Epoch: 46 [30720/50176]	Loss: 0.3766
Training Epoch: 46 [31744/50176]	Loss: 0.4004
Training Epoch: 46 [32768/50176]	Loss: 0.3599
Training Epoch: 46 [33792/50176]	Loss: 0.3914
Training Epoch: 46 [34816/50176]	Loss: 0.3896
Training Epoch: 46 [35840/50176]	Loss: 0.3486
Training Epoch: 46 [36864/50176]	Loss: 0.4055
Training Epoch: 46 [37888/50176]	Loss: 0.3956
Training Epoch: 46 [38912/50176]	Loss: 0.4164
Training Epoch: 46 [39936/50176]	Loss: 0.4105
Training Epoch: 46 [40960/50176]	Loss: 0.4001
Training Epoch: 46 [41984/50176]	Loss: 0.3812
Training Epoch: 46 [43008/50176]	Loss: 0.3160
Training Epoch: 46 [44032/50176]	Loss: 0.3597
Training Epoch: 46 [45056/50176]	Loss: 0.4031
Training Epoch: 46 [46080/50176]	Loss: 0.3776
Training Epoch: 46 [47104/50176]	Loss: 0.3998
Training Epoch: 46 [48128/50176]	Loss: 0.3922
Training Epoch: 46 [49152/50176]	Loss: 0.3659
Training Epoch: 46 [50176/50176]	Loss: 0.4041
2022-12-06 17:48:06.661 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:48:06,698 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.78 energy=479.83
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Up to epoch 47: time=2321.70, energy=321967.68, cost=364132.33
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Expected next epoch: time=2368.97, energy=328751.63, cost=371660.78
2022-12-06 12:48:06,699 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0021, Accuracy: 0.5827
2022-12-06 12:48:06,921 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:48:06,921 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:48:06.923 [ZeusMonitor] Monitor started.
2022-12-06 17:48:06.923 [ZeusMonitor] Running indefinitely. 2022-12-06 17:48:06.923 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:48:06.923 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 12:48:51,396 [ZeusDataLoader(train)] train epoch 48 done: time=44.69 energy=6339.79
2022-12-06 12:48:51,400 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.3412
Training Epoch: 47 [2048/50176]	Loss: 0.3167
Training Epoch: 47 [3072/50176]	Loss: 0.3312
Training Epoch: 47 [4096/50176]	Loss: 0.2801
Training Epoch: 47 [5120/50176]	Loss: 0.3092
Training Epoch: 47 [6144/50176]	Loss: 0.3121
Training Epoch: 47 [7168/50176]	Loss: 0.3343
Training Epoch: 47 [8192/50176]	Loss: 0.3180
Training Epoch: 47 [9216/50176]	Loss: 0.3246
Training Epoch: 47 [10240/50176]	Loss: 0.3422
Training Epoch: 47 [11264/50176]	Loss: 0.3360
Training Epoch: 47 [12288/50176]	Loss: 0.3288
Training Epoch: 47 [13312/50176]	Loss: 0.3180
Training Epoch: 47 [14336/50176]	Loss: 0.3430
Training Epoch: 47 [15360/50176]	Loss: 0.3135
Training Epoch: 47 [16384/50176]	Loss: 0.3595
Training Epoch: 47 [17408/50176]	Loss: 0.3273
Training Epoch: 47 [18432/50176]	Loss: 0.3204
Training Epoch: 47 [19456/50176]	Loss: 0.3645
Training Epoch: 47 [20480/50176]	Loss: 0.3453
Training Epoch: 47 [21504/50176]	Loss: 0.3360
Training Epoch: 47 [22528/50176]	Loss: 0.3036
Training Epoch: 47 [23552/50176]	Loss: 0.3276
Training Epoch: 47 [24576/50176]	Loss: 0.3387
Training Epoch: 47 [25600/50176]	Loss: 0.3356
Training Epoch: 47 [26624/50176]	Loss: 0.3567
Training Epoch: 47 [27648/50176]	Loss: 0.3314
Training Epoch: 47 [28672/50176]	Loss: 0.3525
Training Epoch: 47 [29696/50176]	Loss: 0.2941
Training Epoch: 47 [30720/50176]	Loss: 0.3625
Training Epoch: 47 [31744/50176]	Loss: 0.3622
Training Epoch: 47 [32768/50176]	Loss: 0.3462
Training Epoch: 47 [33792/50176]	Loss: 0.3914
Training Epoch: 47 [34816/50176]	Loss: 0.3846
Training Epoch: 47 [35840/50176]	Loss: 0.3597
Training Epoch: 47 [36864/50176]	Loss: 0.3531
Training Epoch: 47 [37888/50176]	Loss: 0.3770
Training Epoch: 47 [38912/50176]	Loss: 0.3572
Training Epoch: 47 [39936/50176]	Loss: 0.4006
Training Epoch: 47 [40960/50176]	Loss: 0.3551
Training Epoch: 47 [41984/50176]	Loss: 0.3716
Training Epoch: 47 [43008/50176]	Loss: 0.4174
Training Epoch: 47 [44032/50176]	Loss: 0.3952
Training Epoch: 47 [45056/50176]	Loss: 0.3697
Training Epoch: 47 [46080/50176]	Loss: 0.3976
Training Epoch: 47 [47104/50176]	Loss: 0.3214
Training Epoch: 47 [48128/50176]	Loss: 0.4032
Training Epoch: 47 [49152/50176]	Loss: 0.3644
Training Epoch: 47 [50176/50176]	Loss: 0.3815
2022-12-06 17:48:55.277 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:48:55,319 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.91 energy=492.60
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Up to epoch 48: time=2370.30, energy=328800.07, cost=371801.05
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Expected next epoch: time=2417.57, energy=335584.02, cost=379329.51
2022-12-06 12:48:55,320 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0020, Accuracy: 0.5804
2022-12-06 12:48:55,493 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:48:55,494 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:48:55.495 [ZeusMonitor] Monitor started.
2022-12-06 17:48:55.496 [ZeusMonitor] Running indefinitely. 2022-12-06 17:48:55.496 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:48:55.496 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 12:49:40,074 [ZeusDataLoader(train)] train epoch 49 done: time=44.75 energy=6341.00
2022-12-06 12:49:40,077 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.3158
Training Epoch: 48 [2048/50176]	Loss: 0.3088
Training Epoch: 48 [3072/50176]	Loss: 0.2821
Training Epoch: 48 [4096/50176]	Loss: 0.3521
Training Epoch: 48 [5120/50176]	Loss: 0.2843
Training Epoch: 48 [6144/50176]	Loss: 0.2871
Training Epoch: 48 [7168/50176]	Loss: 0.3043
Training Epoch: 48 [8192/50176]	Loss: 0.2800
Training Epoch: 48 [9216/50176]	Loss: 0.3092
Training Epoch: 48 [10240/50176]	Loss: 0.3231
Training Epoch: 48 [11264/50176]	Loss: 0.2831
Training Epoch: 48 [12288/50176]	Loss: 0.3672
Training Epoch: 48 [13312/50176]	Loss: 0.3107
Training Epoch: 48 [14336/50176]	Loss: 0.3208
Training Epoch: 48 [15360/50176]	Loss: 0.3119
Training Epoch: 48 [16384/50176]	Loss: 0.2972
Training Epoch: 48 [17408/50176]	Loss: 0.2699
Training Epoch: 48 [18432/50176]	Loss: 0.3075
Training Epoch: 48 [19456/50176]	Loss: 0.3183
Training Epoch: 48 [20480/50176]	Loss: 0.3088
Training Epoch: 48 [21504/50176]	Loss: 0.3242
Training Epoch: 48 [22528/50176]	Loss: 0.3123
Training Epoch: 48 [23552/50176]	Loss: 0.3358
Training Epoch: 48 [24576/50176]	Loss: 0.3078
Training Epoch: 48 [25600/50176]	Loss: 0.3085
Training Epoch: 48 [26624/50176]	Loss: 0.3115
Training Epoch: 48 [27648/50176]	Loss: 0.3367
Training Epoch: 48 [28672/50176]	Loss: 0.2892
Training Epoch: 48 [29696/50176]	Loss: 0.3064
Training Epoch: 48 [30720/50176]	Loss: 0.2806
Training Epoch: 48 [31744/50176]	Loss: 0.3534
Training Epoch: 48 [32768/50176]	Loss: 0.3522
Training Epoch: 48 [33792/50176]	Loss: 0.3787
Training Epoch: 48 [34816/50176]	Loss: 0.3325
Training Epoch: 48 [35840/50176]	Loss: 0.3639
Training Epoch: 48 [36864/50176]	Loss: 0.3387
Training Epoch: 48 [37888/50176]	Loss: 0.3288
Training Epoch: 48 [38912/50176]	Loss: 0.3963
Training Epoch: 48 [39936/50176]	Loss: 0.3174
Training Epoch: 48 [40960/50176]	Loss: 0.3515
Training Epoch: 48 [41984/50176]	Loss: 0.3485
Training Epoch: 48 [43008/50176]	Loss: 0.3968
Training Epoch: 48 [44032/50176]	Loss: 0.3780
Training Epoch: 48 [45056/50176]	Loss: 0.3375
Training Epoch: 48 [46080/50176]	Loss: 0.3777
Training Epoch: 48 [47104/50176]	Loss: 0.3826
Training Epoch: 48 [48128/50176]	Loss: 0.3710
Training Epoch: 48 [49152/50176]	Loss: 0.4010
Training Epoch: 48 [50176/50176]	Loss: 0.3519
2022-12-06 17:49:43.781 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:49:43,794 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.71 energy=476.47
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Up to epoch 49: time=2418.75, energy=335617.54, cost=379449.58
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Expected next epoch: time=2466.03, energy=342401.49, cost=386978.04
2022-12-06 12:49:43,796 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0020, Accuracy: 0.5890
2022-12-06 12:49:44,017 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:49:44,018 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:49:44.028 [ZeusMonitor] Monitor started.
2022-12-06 17:49:44.028 [ZeusMonitor] Running indefinitely. 2022-12-06 17:49:44.028 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:49:44.028 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 12:50:28,513 [ZeusDataLoader(train)] train epoch 50 done: time=44.71 energy=6343.00
2022-12-06 12:50:28,516 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 0.2724
Training Epoch: 49 [2048/50176]	Loss: 0.2926
Training Epoch: 49 [3072/50176]	Loss: 0.3054
Training Epoch: 49 [4096/50176]	Loss: 0.3062
Training Epoch: 49 [5120/50176]	Loss: 0.3014
Training Epoch: 49 [6144/50176]	Loss: 0.3103
Training Epoch: 49 [7168/50176]	Loss: 0.2805
Training Epoch: 49 [8192/50176]	Loss: 0.3458
Training Epoch: 49 [9216/50176]	Loss: 0.2927
Training Epoch: 49 [10240/50176]	Loss: 0.2956
Training Epoch: 49 [11264/50176]	Loss: 0.3248
Training Epoch: 49 [12288/50176]	Loss: 0.3346
Training Epoch: 49 [13312/50176]	Loss: 0.3193
Training Epoch: 49 [14336/50176]	Loss: 0.3004
Training Epoch: 49 [15360/50176]	Loss: 0.3175
Training Epoch: 49 [16384/50176]	Loss: 0.3002
Training Epoch: 49 [17408/50176]	Loss: 0.2900
Training Epoch: 49 [18432/50176]	Loss: 0.3314
Training Epoch: 49 [19456/50176]	Loss: 0.3131
Training Epoch: 49 [20480/50176]	Loss: 0.2923
Training Epoch: 49 [21504/50176]	Loss: 0.2837
Training Epoch: 49 [22528/50176]	Loss: 0.3334
Training Epoch: 49 [23552/50176]	Loss: 0.3014
Training Epoch: 49 [24576/50176]	Loss: 0.2827
Training Epoch: 49 [25600/50176]	Loss: 0.3145
Training Epoch: 49 [26624/50176]	Loss: 0.3174
Training Epoch: 49 [27648/50176]	Loss: 0.3360
Training Epoch: 49 [28672/50176]	Loss: 0.2877
Training Epoch: 49 [29696/50176]	Loss: 0.2943
Training Epoch: 49 [30720/50176]	Loss: 0.2836
Training Epoch: 49 [31744/50176]	Loss: 0.3353
Training Epoch: 49 [32768/50176]	Loss: 0.3327
Training Epoch: 49 [33792/50176]	Loss: 0.3329
Training Epoch: 49 [34816/50176]	Loss: 0.3147
Training Epoch: 49 [35840/50176]	Loss: 0.3081
Training Epoch: 49 [36864/50176]	Loss: 0.3183
Training Epoch: 49 [37888/50176]	Loss: 0.3374
Training Epoch: 49 [38912/50176]	Loss: 0.3874
Training Epoch: 49 [39936/50176]	Loss: 0.3417
Training Epoch: 49 [40960/50176]	Loss: 0.2843
Training Epoch: 49 [41984/50176]	Loss: 0.3549
Training Epoch: 49 [43008/50176]	Loss: 0.3500
Training Epoch: 49 [44032/50176]	Loss: 0.3099
Training Epoch: 49 [45056/50176]	Loss: 0.3337
Training Epoch: 49 [46080/50176]	Loss: 0.3506
Training Epoch: 49 [47104/50176]	Loss: 0.3692
Training Epoch: 49 [48128/50176]	Loss: 0.3226
Training Epoch: 49 [49152/50176]	Loss: 0.3369
Training Epoch: 49 [50176/50176]	Loss: 0.2967
2022-12-06 17:50:32.348 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:50:32,364 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.84 energy=481.73
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Up to epoch 50: time=2467.30, energy=342442.27, cost=387110.03
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Expected next epoch: time=2514.58, energy=349226.22, cost=394638.48
2022-12-06 12:50:32,366 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0022, Accuracy: 0.5766
2022-12-06 12:50:32,577 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:50:32,578 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:50:32.592 [ZeusMonitor] Monitor started.
2022-12-06 17:50:32.592 [ZeusMonitor] Running indefinitely. 2022-12-06 17:50:32.592 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:50:32.592 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 12:51:16,843 [ZeusDataLoader(train)] train epoch 51 done: time=44.47 energy=6333.64
2022-12-06 12:51:16,847 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 0.2613
Training Epoch: 50 [2048/50176]	Loss: 0.2468
Training Epoch: 50 [3072/50176]	Loss: 0.2865
Training Epoch: 50 [4096/50176]	Loss: 0.3008
Training Epoch: 50 [5120/50176]	Loss: 0.3019
Training Epoch: 50 [6144/50176]	Loss: 0.2509
Training Epoch: 50 [7168/50176]	Loss: 0.2939
Training Epoch: 50 [8192/50176]	Loss: 0.3321
Training Epoch: 50 [9216/50176]	Loss: 0.2860
Training Epoch: 50 [10240/50176]	Loss: 0.2843
Training Epoch: 50 [11264/50176]	Loss: 0.2547
Training Epoch: 50 [12288/50176]	Loss: 0.2573
Training Epoch: 50 [13312/50176]	Loss: 0.2748
Training Epoch: 50 [14336/50176]	Loss: 0.2664
Training Epoch: 50 [15360/50176]	Loss: 0.2627
Training Epoch: 50 [16384/50176]	Loss: 0.3010
Training Epoch: 50 [17408/50176]	Loss: 0.2673
Training Epoch: 50 [18432/50176]	Loss: 0.2859
Training Epoch: 50 [19456/50176]	Loss: 0.2722
Training Epoch: 50 [20480/50176]	Loss: 0.3174
Training Epoch: 50 [21504/50176]	Loss: 0.2933
Training Epoch: 50 [22528/50176]	Loss: 0.2771
Training Epoch: 50 [23552/50176]	Loss: 0.2794
Training Epoch: 50 [24576/50176]	Loss: 0.2953
Training Epoch: 50 [25600/50176]	Loss: 0.2951
Training Epoch: 50 [26624/50176]	Loss: 0.2788
Training Epoch: 50 [27648/50176]	Loss: 0.3164
Training Epoch: 50 [28672/50176]	Loss: 0.2937
Training Epoch: 50 [29696/50176]	Loss: 0.3115
Training Epoch: 50 [30720/50176]	Loss: 0.3053
Training Epoch: 50 [31744/50176]	Loss: 0.2938
Training Epoch: 50 [32768/50176]	Loss: 0.3093
Training Epoch: 50 [33792/50176]	Loss: 0.2675
Training Epoch: 50 [34816/50176]	Loss: 0.2972
Training Epoch: 50 [35840/50176]	Loss: 0.3267
Training Epoch: 50 [36864/50176]	Loss: 0.3173
Training Epoch: 50 [37888/50176]	Loss: 0.2799
Training Epoch: 50 [38912/50176]	Loss: 0.3272
Training Epoch: 50 [39936/50176]	Loss: 0.3106
Training Epoch: 50 [40960/50176]	Loss: 0.3533
Training Epoch: 50 [41984/50176]	Loss: 0.2750
Training Epoch: 50 [43008/50176]	Loss: 0.3527
Training Epoch: 50 [44032/50176]	Loss: 0.3080
Training Epoch: 50 [45056/50176]	Loss: 0.3446
Training Epoch: 50 [46080/50176]	Loss: 0.3519
Training Epoch: 50 [47104/50176]	Loss: 0.3682
Training Epoch: 50 [48128/50176]	Loss: 0.3421
Training Epoch: 50 [49152/50176]	Loss: 0.2935
Training Epoch: 50 [50176/50176]	Loss: 0.3058
2022-12-06 17:51:20.583 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:51:20,602 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.75 energy=472.05
2022-12-06 12:51:20,602 [ZeusDataLoader(train)] Up to epoch 51: time=2515.52, energy=349247.96, cost=394731.93
2022-12-06 12:51:20,603 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:51:20,603 [ZeusDataLoader(train)] Expected next epoch: time=2562.79, energy=356031.91, cost=402260.38
2022-12-06 12:51:20,604 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0023, Accuracy: 0.5646
2022-12-06 12:51:20,817 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:51:20,818 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:51:20.820 [ZeusMonitor] Monitor started.
2022-12-06 17:51:20.820 [ZeusMonitor] Running indefinitely. 2022-12-06 17:51:20.820 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:51:20.820 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 12:52:05,272 [ZeusDataLoader(train)] train epoch 52 done: time=44.66 energy=6349.93
2022-12-06 12:52:05,275 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 0.2750
Training Epoch: 51 [2048/50176]	Loss: 0.3083
Training Epoch: 51 [3072/50176]	Loss: 0.2582
Training Epoch: 51 [4096/50176]	Loss: 0.2662
Training Epoch: 51 [5120/50176]	Loss: 0.2714
Training Epoch: 51 [6144/50176]	Loss: 0.2569
Training Epoch: 51 [7168/50176]	Loss: 0.2545
Training Epoch: 51 [8192/50176]	Loss: 0.2635
Training Epoch: 51 [9216/50176]	Loss: 0.2674
Training Epoch: 51 [10240/50176]	Loss: 0.2503
Training Epoch: 51 [11264/50176]	Loss: 0.2905
Training Epoch: 51 [12288/50176]	Loss: 0.2420
Training Epoch: 51 [13312/50176]	Loss: 0.2484
Training Epoch: 51 [14336/50176]	Loss: 0.2169
Training Epoch: 51 [15360/50176]	Loss: 0.3336
Training Epoch: 51 [16384/50176]	Loss: 0.3356
Training Epoch: 51 [17408/50176]	Loss: 0.3072
Training Epoch: 51 [18432/50176]	Loss: 0.2938
Training Epoch: 51 [19456/50176]	Loss: 0.2849
Training Epoch: 51 [20480/50176]	Loss: 0.2665
Training Epoch: 51 [21504/50176]	Loss: 0.2934
Training Epoch: 51 [22528/50176]	Loss: 0.3158
Training Epoch: 51 [23552/50176]	Loss: 0.2824
Training Epoch: 51 [24576/50176]	Loss: 0.3001
Training Epoch: 51 [25600/50176]	Loss: 0.3126
Training Epoch: 51 [26624/50176]	Loss: 0.3092
Training Epoch: 51 [27648/50176]	Loss: 0.3148
Training Epoch: 51 [28672/50176]	Loss: 0.2799
Training Epoch: 51 [29696/50176]	Loss: 0.3061
Training Epoch: 51 [30720/50176]	Loss: 0.2733
Training Epoch: 51 [31744/50176]	Loss: 0.2722
Training Epoch: 51 [32768/50176]	Loss: 0.2925
Training Epoch: 51 [33792/50176]	Loss: 0.3266
Training Epoch: 51 [34816/50176]	Loss: 0.2771
Training Epoch: 51 [35840/50176]	Loss: 0.2871
Training Epoch: 51 [36864/50176]	Loss: 0.2840
Training Epoch: 51 [37888/50176]	Loss: 0.3344
Training Epoch: 51 [38912/50176]	Loss: 0.2988
Training Epoch: 51 [39936/50176]	Loss: 0.2841
Training Epoch: 51 [40960/50176]	Loss: 0.3212
Training Epoch: 51 [41984/50176]	Loss: 0.3402
Training Epoch: 51 [43008/50176]	Loss: 0.3053
Training Epoch: 51 [44032/50176]	Loss: 0.2822
Training Epoch: 51 [45056/50176]	Loss: 0.3122
Training Epoch: 51 [46080/50176]	Loss: 0.3508
Training Epoch: 51 [47104/50176]	Loss: 0.3178
Training Epoch: 51 [48128/50176]	Loss: 0.3155
Training Epoch: 51 [49152/50176]	Loss: 0.3530
Training Epoch: 51 [50176/50176]	Loss: 0.3734
2022-12-06 17:52:09.023 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:52:09,050 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.77 energy=471.67
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Up to epoch 52: time=2563.95, energy=356069.55, cost=402380.12
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Expected next epoch: time=2611.22, energy=362853.50, cost=409908.57
2022-12-06 12:52:09,052 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0023, Accuracy: 0.5745
2022-12-06 12:52:09,277 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:52:09,277 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:52:09.279 [ZeusMonitor] Monitor started.
2022-12-06 17:52:09.279 [ZeusMonitor] Running indefinitely. 2022-12-06 17:52:09.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:52:09.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 12:52:53,721 [ZeusDataLoader(train)] train epoch 53 done: time=44.66 energy=6341.47
2022-12-06 12:52:53,724 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 0.2395
Training Epoch: 52 [2048/50176]	Loss: 0.2005
Training Epoch: 52 [3072/50176]	Loss: 0.2829
Training Epoch: 52 [4096/50176]	Loss: 0.2271
Training Epoch: 52 [5120/50176]	Loss: 0.2630
Training Epoch: 52 [6144/50176]	Loss: 0.2402
Training Epoch: 52 [7168/50176]	Loss: 0.2196
Training Epoch: 52 [8192/50176]	Loss: 0.2378
Training Epoch: 52 [9216/50176]	Loss: 0.2171
Training Epoch: 52 [10240/50176]	Loss: 0.2589
Training Epoch: 52 [11264/50176]	Loss: 0.2609
Training Epoch: 52 [12288/50176]	Loss: 0.2347
Training Epoch: 52 [13312/50176]	Loss: 0.2287
Training Epoch: 52 [14336/50176]	Loss: 0.2449
Training Epoch: 52 [15360/50176]	Loss: 0.2638
Training Epoch: 52 [16384/50176]	Loss: 0.3007
Training Epoch: 52 [17408/50176]	Loss: 0.2295
Training Epoch: 52 [18432/50176]	Loss: 0.2665
Training Epoch: 52 [19456/50176]	Loss: 0.2785
Training Epoch: 52 [20480/50176]	Loss: 0.2838
Training Epoch: 52 [21504/50176]	Loss: 0.2903
Training Epoch: 52 [22528/50176]	Loss: 0.2929
Training Epoch: 52 [23552/50176]	Loss: 0.2545
Training Epoch: 52 [24576/50176]	Loss: 0.3094
Training Epoch: 52 [25600/50176]	Loss: 0.2768
Training Epoch: 52 [26624/50176]	Loss: 0.2356
Training Epoch: 52 [27648/50176]	Loss: 0.2896
Training Epoch: 52 [28672/50176]	Loss: 0.2704
Training Epoch: 52 [29696/50176]	Loss: 0.2760
Training Epoch: 52 [30720/50176]	Loss: 0.2428
Training Epoch: 52 [31744/50176]	Loss: 0.2727
Training Epoch: 52 [32768/50176]	Loss: 0.3150
Training Epoch: 52 [33792/50176]	Loss: 0.2891
Training Epoch: 52 [34816/50176]	Loss: 0.2525
Training Epoch: 52 [35840/50176]	Loss: 0.2785
Training Epoch: 52 [36864/50176]	Loss: 0.2942
Training Epoch: 52 [37888/50176]	Loss: 0.3149
Training Epoch: 52 [38912/50176]	Loss: 0.2677
Training Epoch: 52 [39936/50176]	Loss: 0.2788
Training Epoch: 52 [40960/50176]	Loss: 0.2803
Training Epoch: 52 [41984/50176]	Loss: 0.2524
Training Epoch: 52 [43008/50176]	Loss: 0.2818
Training Epoch: 52 [44032/50176]	Loss: 0.2882
Training Epoch: 52 [45056/50176]	Loss: 0.2472
Training Epoch: 52 [46080/50176]	Loss: 0.3361
Training Epoch: 52 [47104/50176]	Loss: 0.2738
Training Epoch: 52 [48128/50176]	Loss: 0.2717
Training Epoch: 52 [49152/50176]	Loss: 0.2751
Training Epoch: 52 [50176/50176]	Loss: 0.2646
2022-12-06 17:52:57.437 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:52:57,471 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.74 energy=474.03
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Up to epoch 53: time=2612.35, energy=362885.05, cost=410022.92
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Expected next epoch: time=2659.62, energy=369669.00, cost=417551.38
2022-12-06 12:52:57,473 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0021, Accuracy: 0.5983
2022-12-06 12:52:57,681 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:52:57,682 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:52:57.696 [ZeusMonitor] Monitor started.
2022-12-06 17:52:57.696 [ZeusMonitor] Running indefinitely. 2022-12-06 17:52:57.696 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:52:57.696 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 12:53:41,985 [ZeusDataLoader(train)] train epoch 54 done: time=44.50 energy=6331.81
2022-12-06 12:53:41,988 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 0.2127
Training Epoch: 53 [2048/50176]	Loss: 0.2326
Training Epoch: 53 [3072/50176]	Loss: 0.2419
Training Epoch: 53 [4096/50176]	Loss: 0.2272
Training Epoch: 53 [5120/50176]	Loss: 0.2399
Training Epoch: 53 [6144/50176]	Loss: 0.2293
Training Epoch: 53 [7168/50176]	Loss: 0.2450
Training Epoch: 53 [8192/50176]	Loss: 0.2385
Training Epoch: 53 [9216/50176]	Loss: 0.2381
Training Epoch: 53 [10240/50176]	Loss: 0.2356
Training Epoch: 53 [11264/50176]	Loss: 0.2130
Training Epoch: 53 [12288/50176]	Loss: 0.2632
Training Epoch: 53 [13312/50176]	Loss: 0.2527
Training Epoch: 53 [14336/50176]	Loss: 0.2333
Training Epoch: 53 [15360/50176]	Loss: 0.2409
Training Epoch: 53 [16384/50176]	Loss: 0.2373
Training Epoch: 53 [17408/50176]	Loss: 0.2442
Training Epoch: 53 [18432/50176]	Loss: 0.2421
Training Epoch: 53 [19456/50176]	Loss: 0.2606
Training Epoch: 53 [20480/50176]	Loss: 0.2304
Training Epoch: 53 [21504/50176]	Loss: 0.2490
Training Epoch: 53 [22528/50176]	Loss: 0.2316
Training Epoch: 53 [23552/50176]	Loss: 0.2592
Training Epoch: 53 [24576/50176]	Loss: 0.2856
Training Epoch: 53 [25600/50176]	Loss: 0.2324
Training Epoch: 53 [26624/50176]	Loss: 0.2447
Training Epoch: 53 [27648/50176]	Loss: 0.2992
Training Epoch: 53 [28672/50176]	Loss: 0.2834
Training Epoch: 53 [29696/50176]	Loss: 0.2547
Training Epoch: 53 [30720/50176]	Loss: 0.2576
Training Epoch: 53 [31744/50176]	Loss: 0.2418
Training Epoch: 53 [32768/50176]	Loss: 0.2665
Training Epoch: 53 [33792/50176]	Loss: 0.2311
Training Epoch: 53 [34816/50176]	Loss: 0.2738
Training Epoch: 53 [35840/50176]	Loss: 0.2618
Training Epoch: 53 [36864/50176]	Loss: 0.2706
Training Epoch: 53 [37888/50176]	Loss: 0.2588
Training Epoch: 53 [38912/50176]	Loss: 0.2813
Training Epoch: 53 [39936/50176]	Loss: 0.2864
Training Epoch: 53 [40960/50176]	Loss: 0.2525
Training Epoch: 53 [41984/50176]	Loss: 0.2663
Training Epoch: 53 [43008/50176]	Loss: 0.2735
Training Epoch: 53 [44032/50176]	Loss: 0.3044
Training Epoch: 53 [45056/50176]	Loss: 0.3515
Training Epoch: 53 [46080/50176]	Loss: 0.2879
Training Epoch: 53 [47104/50176]	Loss: 0.2968
Training Epoch: 53 [48128/50176]	Loss: 0.2378
Training Epoch: 53 [49152/50176]	Loss: 0.3426
Training Epoch: 53 [50176/50176]	Loss: 0.3224
2022-12-06 17:53:45.677 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:53:45,699 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.70 energy=476.19
2022-12-06 12:53:45,699 [ZeusDataLoader(train)] Up to epoch 54: time=2660.55, energy=369693.05, cost=417645.00
2022-12-06 12:53:45,699 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:53:45,700 [ZeusDataLoader(train)] Expected next epoch: time=2707.83, energy=376477.01, cost=425173.46
2022-12-06 12:53:45,700 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0022, Accuracy: 0.5740
2022-12-06 12:53:45,912 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:53:45,913 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:53:45.914 [ZeusMonitor] Monitor started.
2022-12-06 17:53:45.914 [ZeusMonitor] Running indefinitely. 2022-12-06 17:53:45.915 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:53:45.915 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 12:54:30,162 [ZeusDataLoader(train)] train epoch 55 done: time=44.45 energy=6336.00
2022-12-06 12:54:30,165 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 0.2334
Training Epoch: 54 [2048/50176]	Loss: 0.2860
Training Epoch: 54 [3072/50176]	Loss: 0.2210
Training Epoch: 54 [4096/50176]	Loss: 0.2162
Training Epoch: 54 [5120/50176]	Loss: 0.2084
Training Epoch: 54 [6144/50176]	Loss: 0.2285
Training Epoch: 54 [7168/50176]	Loss: 0.2407
Training Epoch: 54 [8192/50176]	Loss: 0.2382
Training Epoch: 54 [9216/50176]	Loss: 0.2422
Training Epoch: 54 [10240/50176]	Loss: 0.2116
Training Epoch: 54 [11264/50176]	Loss: 0.2433
Training Epoch: 54 [12288/50176]	Loss: 0.2358
Training Epoch: 54 [13312/50176]	Loss: 0.2659
Training Epoch: 54 [14336/50176]	Loss: 0.2045
Training Epoch: 54 [15360/50176]	Loss: 0.2760
Training Epoch: 54 [16384/50176]	Loss: 0.2301
Training Epoch: 54 [17408/50176]	Loss: 0.2641
Training Epoch: 54 [18432/50176]	Loss: 0.2406
Training Epoch: 54 [19456/50176]	Loss: 0.2508
Training Epoch: 54 [20480/50176]	Loss: 0.2236
Training Epoch: 54 [21504/50176]	Loss: 0.2118
Training Epoch: 54 [22528/50176]	Loss: 0.2603
Training Epoch: 54 [23552/50176]	Loss: 0.2353
Training Epoch: 54 [24576/50176]	Loss: 0.2510
Training Epoch: 54 [25600/50176]	Loss: 0.2752
Training Epoch: 54 [26624/50176]	Loss: 0.2581
Training Epoch: 54 [27648/50176]	Loss: 0.2632
Training Epoch: 54 [28672/50176]	Loss: 0.2573
Training Epoch: 54 [29696/50176]	Loss: 0.2367
Training Epoch: 54 [30720/50176]	Loss: 0.2230
Training Epoch: 54 [31744/50176]	Loss: 0.2671
Training Epoch: 54 [32768/50176]	Loss: 0.2483
Training Epoch: 54 [33792/50176]	Loss: 0.2542
Training Epoch: 54 [34816/50176]	Loss: 0.3030
Training Epoch: 54 [35840/50176]	Loss: 0.2638
Training Epoch: 54 [36864/50176]	Loss: 0.2637
Training Epoch: 54 [37888/50176]	Loss: 0.2747
Training Epoch: 54 [38912/50176]	Loss: 0.3060
Training Epoch: 54 [39936/50176]	Loss: 0.2650
Training Epoch: 54 [40960/50176]	Loss: 0.2861
Training Epoch: 54 [41984/50176]	Loss: 0.2780
Training Epoch: 54 [43008/50176]	Loss: 0.2547
Training Epoch: 54 [44032/50176]	Loss: 0.2708
Training Epoch: 54 [45056/50176]	Loss: 0.2669
Training Epoch: 54 [46080/50176]	Loss: 0.2969
Training Epoch: 54 [47104/50176]	Loss: 0.3217
Training Epoch: 54 [48128/50176]	Loss: 0.2986
Training Epoch: 54 [49152/50176]	Loss: 0.3060
Training Epoch: 54 [50176/50176]	Loss: 0.2990
2022-12-06 17:54:33.917 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:54:33,963 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.79 energy=477.78
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Up to epoch 55: time=2708.80, energy=376506.83, cost=425273.20
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Expected next epoch: time=2756.07, energy=383290.78, cost=432801.65
2022-12-06 12:54:33,964 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0023, Accuracy: 0.5806
2022-12-06 12:54:34,167 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:54:34,168 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:54:34.170 [ZeusMonitor] Monitor started.
2022-12-06 17:54:34.170 [ZeusMonitor] Running indefinitely. 2022-12-06 17:54:34.170 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:54:34.170 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 12:55:19,148 [ZeusDataLoader(train)] train epoch 56 done: time=45.18 energy=6388.09
2022-12-06 12:55:19,152 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 0.2377
Training Epoch: 55 [2048/50176]	Loss: 0.2271
Training Epoch: 55 [3072/50176]	Loss: 0.2208
Training Epoch: 55 [4096/50176]	Loss: 0.2187
Training Epoch: 55 [5120/50176]	Loss: 0.2532
Training Epoch: 55 [6144/50176]	Loss: 0.2075
Training Epoch: 55 [7168/50176]	Loss: 0.2167
Training Epoch: 55 [8192/50176]	Loss: 0.2126
Training Epoch: 55 [9216/50176]	Loss: 0.2107
Training Epoch: 55 [10240/50176]	Loss: 0.2748
Training Epoch: 55 [11264/50176]	Loss: 0.2395
Training Epoch: 55 [12288/50176]	Loss: 0.2389
Training Epoch: 55 [13312/50176]	Loss: 0.1952
Training Epoch: 55 [14336/50176]	Loss: 0.2471
Training Epoch: 55 [15360/50176]	Loss: 0.2500
Training Epoch: 55 [16384/50176]	Loss: 0.2347
Training Epoch: 55 [17408/50176]	Loss: 0.2611
Training Epoch: 55 [18432/50176]	Loss: 0.2298
Training Epoch: 55 [19456/50176]	Loss: 0.2941
Training Epoch: 55 [20480/50176]	Loss: 0.2592
Training Epoch: 55 [21504/50176]	Loss: 0.2464
Training Epoch: 55 [22528/50176]	Loss: 0.2467
Training Epoch: 55 [23552/50176]	Loss: 0.2869
Training Epoch: 55 [24576/50176]	Loss: 0.2464
Training Epoch: 55 [25600/50176]	Loss: 0.2575
Training Epoch: 55 [26624/50176]	Loss: 0.2491
Training Epoch: 55 [27648/50176]	Loss: 0.2484
Training Epoch: 55 [28672/50176]	Loss: 0.2666
Training Epoch: 55 [29696/50176]	Loss: 0.2360
Training Epoch: 55 [30720/50176]	Loss: 0.2296
Training Epoch: 55 [31744/50176]	Loss: 0.2306
Training Epoch: 55 [32768/50176]	Loss: 0.2659
Training Epoch: 55 [33792/50176]	Loss: 0.2842
Training Epoch: 55 [34816/50176]	Loss: 0.2262
Training Epoch: 55 [35840/50176]	Loss: 0.2870
Training Epoch: 55 [36864/50176]	Loss: 0.2562
Training Epoch: 55 [37888/50176]	Loss: 0.2848
Training Epoch: 55 [38912/50176]	Loss: 0.2440
Training Epoch: 55 [39936/50176]	Loss: 0.2593
Training Epoch: 55 [40960/50176]	Loss: 0.2191
Training Epoch: 55 [41984/50176]	Loss: 0.2373
Training Epoch: 55 [43008/50176]	Loss: 0.2438
Training Epoch: 55 [44032/50176]	Loss: 0.2839
Training Epoch: 55 [45056/50176]	Loss: 0.2305
Training Epoch: 55 [46080/50176]	Loss: 0.2888
Training Epoch: 55 [47104/50176]	Loss: 0.2471
Training Epoch: 55 [48128/50176]	Loss: 0.2732
Training Epoch: 55 [49152/50176]	Loss: 0.2507
Training Epoch: 55 [50176/50176]	Loss: 0.2428
2022-12-06 17:55:22.967 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:55:22,978 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.82 energy=490.98
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Up to epoch 56: time=2757.79, energy=383385.90, cost=432999.73
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Expected next epoch: time=2805.07, energy=390169.85, cost=440528.18
2022-12-06 12:55:22,979 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0023, Accuracy: 0.5818
2022-12-06 12:55:23,197 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:55:23,197 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:55:23.199 [ZeusMonitor] Monitor started.
2022-12-06 17:55:23.199 [ZeusMonitor] Running indefinitely. 2022-12-06 17:55:23.199 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:55:23.199 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 12:56:08,394 [ZeusDataLoader(train)] train epoch 57 done: time=45.41 energy=6397.96
2022-12-06 12:56:08,397 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 0.1911
Training Epoch: 56 [2048/50176]	Loss: 0.2132
Training Epoch: 56 [3072/50176]	Loss: 0.2168
Training Epoch: 56 [4096/50176]	Loss: 0.1965
Training Epoch: 56 [5120/50176]	Loss: 0.2246
Training Epoch: 56 [6144/50176]	Loss: 0.2103
Training Epoch: 56 [7168/50176]	Loss: 0.2009
Training Epoch: 56 [8192/50176]	Loss: 0.1987
Training Epoch: 56 [9216/50176]	Loss: 0.2400
Training Epoch: 56 [10240/50176]	Loss: 0.2064
Training Epoch: 56 [11264/50176]	Loss: 0.2046
Training Epoch: 56 [12288/50176]	Loss: 0.2147
Training Epoch: 56 [13312/50176]	Loss: 0.2355
Training Epoch: 56 [14336/50176]	Loss: 0.1868
Training Epoch: 56 [15360/50176]	Loss: 0.2488
Training Epoch: 56 [16384/50176]	Loss: 0.2088
Training Epoch: 56 [17408/50176]	Loss: 0.1860
Training Epoch: 56 [18432/50176]	Loss: 0.2482
Training Epoch: 56 [19456/50176]	Loss: 0.2102
Training Epoch: 56 [20480/50176]	Loss: 0.2200
Training Epoch: 56 [21504/50176]	Loss: 0.2210
Training Epoch: 56 [22528/50176]	Loss: 0.2349
Training Epoch: 56 [23552/50176]	Loss: 0.2323
Training Epoch: 56 [24576/50176]	Loss: 0.2082
Training Epoch: 56 [25600/50176]	Loss: 0.2149
Training Epoch: 56 [26624/50176]	Loss: 0.1958
Training Epoch: 56 [27648/50176]	Loss: 0.2236
Training Epoch: 56 [28672/50176]	Loss: 0.2490
Training Epoch: 56 [29696/50176]	Loss: 0.1909
Training Epoch: 56 [30720/50176]	Loss: 0.2209
Training Epoch: 56 [31744/50176]	Loss: 0.2395
Training Epoch: 56 [32768/50176]	Loss: 0.2672
Training Epoch: 56 [33792/50176]	Loss: 0.2692
Training Epoch: 56 [34816/50176]	Loss: 0.2259
Training Epoch: 56 [35840/50176]	Loss: 0.2190
Training Epoch: 56 [36864/50176]	Loss: 0.2141
Training Epoch: 56 [37888/50176]	Loss: 0.2636
Training Epoch: 56 [38912/50176]	Loss: 0.2809
Training Epoch: 56 [39936/50176]	Loss: 0.2179
Training Epoch: 56 [40960/50176]	Loss: 0.2128
Training Epoch: 56 [41984/50176]	Loss: 0.2452
Training Epoch: 56 [43008/50176]	Loss: 0.2747
Training Epoch: 56 [44032/50176]	Loss: 0.2238
Training Epoch: 56 [45056/50176]	Loss: 0.2469
Training Epoch: 56 [46080/50176]	Loss: 0.2567
Training Epoch: 56 [47104/50176]	Loss: 0.2510
Training Epoch: 56 [48128/50176]	Loss: 0.2638
Training Epoch: 56 [49152/50176]	Loss: 0.2402
Training Epoch: 56 [50176/50176]	Loss: 0.2745
2022-12-06 17:56:12.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:56:12,228 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.82 energy=485.11
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Up to epoch 57: time=2807.02, energy=390268.98, cost=440748.84
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Expected next epoch: time=2854.30, energy=397052.93, cost=448277.29
2022-12-06 12:56:12,229 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0022, Accuracy: 0.5967
2022-12-06 12:56:12,438 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:56:12,439 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:56:12.448 [ZeusMonitor] Monitor started.
2022-12-06 17:56:12.449 [ZeusMonitor] Running indefinitely. 2022-12-06 17:56:12.449 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:56:12.449 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 12:56:57,708 [ZeusDataLoader(train)] train epoch 58 done: time=45.47 energy=6398.58
2022-12-06 12:56:57,712 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 0.1799
Training Epoch: 57 [2048/50176]	Loss: 0.2322
Training Epoch: 57 [3072/50176]	Loss: 0.1995
Training Epoch: 57 [4096/50176]	Loss: 0.2112
Training Epoch: 57 [5120/50176]	Loss: 0.2152
Training Epoch: 57 [6144/50176]	Loss: 0.2032
Training Epoch: 57 [7168/50176]	Loss: 0.2599
Training Epoch: 57 [8192/50176]	Loss: 0.1853
Training Epoch: 57 [9216/50176]	Loss: 0.1919
Training Epoch: 57 [10240/50176]	Loss: 0.1612
Training Epoch: 57 [11264/50176]	Loss: 0.2001
Training Epoch: 57 [12288/50176]	Loss: 0.2060
Training Epoch: 57 [13312/50176]	Loss: 0.1889
Training Epoch: 57 [14336/50176]	Loss: 0.1958
Training Epoch: 57 [15360/50176]	Loss: 0.1888
Training Epoch: 57 [16384/50176]	Loss: 0.2164
Training Epoch: 57 [17408/50176]	Loss: 0.2394
Training Epoch: 57 [18432/50176]	Loss: 0.2033
Training Epoch: 57 [19456/50176]	Loss: 0.2331
Training Epoch: 57 [20480/50176]	Loss: 0.1722
Training Epoch: 57 [21504/50176]	Loss: 0.2390
Training Epoch: 57 [22528/50176]	Loss: 0.1856
Training Epoch: 57 [23552/50176]	Loss: 0.2259
Training Epoch: 57 [24576/50176]	Loss: 0.1822
Training Epoch: 57 [25600/50176]	Loss: 0.2202
Training Epoch: 57 [26624/50176]	Loss: 0.2431
Training Epoch: 57 [27648/50176]	Loss: 0.2160
Training Epoch: 57 [28672/50176]	Loss: 0.2155
Training Epoch: 57 [29696/50176]	Loss: 0.2210
Training Epoch: 57 [30720/50176]	Loss: 0.2231
Training Epoch: 57 [31744/50176]	Loss: 0.1978
Training Epoch: 57 [32768/50176]	Loss: 0.2381
Training Epoch: 57 [33792/50176]	Loss: 0.2506
Training Epoch: 57 [34816/50176]	Loss: 0.2582
Training Epoch: 57 [35840/50176]	Loss: 0.2236
Training Epoch: 57 [36864/50176]	Loss: 0.1953
Training Epoch: 57 [37888/50176]	Loss: 0.2165
Training Epoch: 57 [38912/50176]	Loss: 0.2220
Training Epoch: 57 [39936/50176]	Loss: 0.2243
Training Epoch: 57 [40960/50176]	Loss: 0.2280
Training Epoch: 57 [41984/50176]	Loss: 0.2527
Training Epoch: 57 [43008/50176]	Loss: 0.2606
Training Epoch: 57 [44032/50176]	Loss: 0.2253
Training Epoch: 57 [45056/50176]	Loss: 0.2526
Training Epoch: 57 [46080/50176]	Loss: 0.1924
Training Epoch: 57 [47104/50176]	Loss: 0.2566
Training Epoch: 57 [48128/50176]	Loss: 0.2329
Training Epoch: 57 [49152/50176]	Loss: 0.2416
Training Epoch: 57 [50176/50176]	Loss: 0.2515
2022-12-06 17:57:01.464 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:57:01,503 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.78 energy=478.28
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Up to epoch 58: time=2856.28, energy=397145.84, cost=448497.08
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Expected next epoch: time=2903.55, energy=403929.79, cost=456025.54
2022-12-06 12:57:01,505 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0022, Accuracy: 0.5875
2022-12-06 12:57:01,739 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:57:01,740 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:57:01.741 [ZeusMonitor] Monitor started.
2022-12-06 17:57:01.742 [ZeusMonitor] Running indefinitely. 2022-12-06 17:57:01.742 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:57:01.742 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 12:57:46,125 [ZeusDataLoader(train)] train epoch 59 done: time=44.61 energy=6339.70
2022-12-06 12:57:46,128 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 0.1758
Training Epoch: 58 [2048/50176]	Loss: 0.1987
Training Epoch: 58 [3072/50176]	Loss: 0.2019
Training Epoch: 58 [4096/50176]	Loss: 0.1970
Training Epoch: 58 [5120/50176]	Loss: 0.2170
Training Epoch: 58 [6144/50176]	Loss: 0.1913
Training Epoch: 58 [7168/50176]	Loss: 0.1883
Training Epoch: 58 [8192/50176]	Loss: 0.1843
Training Epoch: 58 [9216/50176]	Loss: 0.2179
Training Epoch: 58 [10240/50176]	Loss: 0.1925
Training Epoch: 58 [11264/50176]	Loss: 0.2020
Training Epoch: 58 [12288/50176]	Loss: 0.2303
Training Epoch: 58 [13312/50176]	Loss: 0.1954
Training Epoch: 58 [14336/50176]	Loss: 0.1985
Training Epoch: 58 [15360/50176]	Loss: 0.1882
Training Epoch: 58 [16384/50176]	Loss: 0.2095
Training Epoch: 58 [17408/50176]	Loss: 0.2273
Training Epoch: 58 [18432/50176]	Loss: 0.1806
Training Epoch: 58 [19456/50176]	Loss: 0.1787
Training Epoch: 58 [20480/50176]	Loss: 0.1935
Training Epoch: 58 [21504/50176]	Loss: 0.2139
Training Epoch: 58 [22528/50176]	Loss: 0.1807
Training Epoch: 58 [23552/50176]	Loss: 0.2069
Training Epoch: 58 [24576/50176]	Loss: 0.2107
Training Epoch: 58 [25600/50176]	Loss: 0.2086
Training Epoch: 58 [26624/50176]	Loss: 0.2178
Training Epoch: 58 [27648/50176]	Loss: 0.2098
Training Epoch: 58 [28672/50176]	Loss: 0.2001
Training Epoch: 58 [29696/50176]	Loss: 0.2187
Training Epoch: 58 [30720/50176]	Loss: 0.2403
Training Epoch: 58 [31744/50176]	Loss: 0.2017
Training Epoch: 58 [32768/50176]	Loss: 0.2041
Training Epoch: 58 [33792/50176]	Loss: 0.2298
Training Epoch: 58 [34816/50176]	Loss: 0.1783
Training Epoch: 58 [35840/50176]	Loss: 0.2447
Training Epoch: 58 [36864/50176]	Loss: 0.1891
Training Epoch: 58 [37888/50176]	Loss: 0.2226
Training Epoch: 58 [38912/50176]	Loss: 0.2205
Training Epoch: 58 [39936/50176]	Loss: 0.2299
Training Epoch: 58 [40960/50176]	Loss: 0.2311
Training Epoch: 58 [41984/50176]	Loss: 0.2048
Training Epoch: 58 [43008/50176]	Loss: 0.2140
Training Epoch: 58 [44032/50176]	Loss: 0.2483
Training Epoch: 58 [45056/50176]	Loss: 0.2639
Training Epoch: 58 [46080/50176]	Loss: 0.2370
Training Epoch: 58 [47104/50176]	Loss: 0.2587
Training Epoch: 58 [48128/50176]	Loss: 0.2308
Training Epoch: 58 [49152/50176]	Loss: 0.2211
Training Epoch: 58 [50176/50176]	Loss: 0.2186
2022-12-06 17:57:49.810 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:57:49,819 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.68 energy=467.19
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Up to epoch 59: time=2904.57, energy=403952.73, cost=456126.35
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Expected next epoch: time=2951.85, energy=410736.68, cost=463654.81
2022-12-06 12:57:49,820 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0024, Accuracy: 0.5806
2022-12-06 12:57:50,015 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:57:50,016 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:57:50.030 [ZeusMonitor] Monitor started.
2022-12-06 17:57:50.030 [ZeusMonitor] Running indefinitely. 2022-12-06 17:57:50.030 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:57:50.030 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 12:58:34,190 [ZeusDataLoader(train)] train epoch 60 done: time=44.36 energy=6317.62
2022-12-06 12:58:34,193 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 0.1864
Training Epoch: 59 [2048/50176]	Loss: 0.1866
Training Epoch: 59 [3072/50176]	Loss: 0.2137
Training Epoch: 59 [4096/50176]	Loss: 0.2005
Training Epoch: 59 [5120/50176]	Loss: 0.1959
Training Epoch: 59 [6144/50176]	Loss: 0.2057
Training Epoch: 59 [7168/50176]	Loss: 0.2183
Training Epoch: 59 [8192/50176]	Loss: 0.1998
Training Epoch: 59 [9216/50176]	Loss: 0.1863
Training Epoch: 59 [10240/50176]	Loss: 0.1771
Training Epoch: 59 [11264/50176]	Loss: 0.1615
Training Epoch: 59 [12288/50176]	Loss: 0.1788
Training Epoch: 59 [13312/50176]	Loss: 0.2383
Training Epoch: 59 [14336/50176]	Loss: 0.1872
Training Epoch: 59 [15360/50176]	Loss: 0.2099
Training Epoch: 59 [16384/50176]	Loss: 0.1869
Training Epoch: 59 [17408/50176]	Loss: 0.2238
Training Epoch: 59 [18432/50176]	Loss: 0.1755
Training Epoch: 59 [19456/50176]	Loss: 0.2133
Training Epoch: 59 [20480/50176]	Loss: 0.2139
Training Epoch: 59 [21504/50176]	Loss: 0.1984
Training Epoch: 59 [22528/50176]	Loss: 0.2093
Training Epoch: 59 [23552/50176]	Loss: 0.2257
Training Epoch: 59 [24576/50176]	Loss: 0.2298
Training Epoch: 59 [25600/50176]	Loss: 0.1791
Training Epoch: 59 [26624/50176]	Loss: 0.2175
Training Epoch: 59 [27648/50176]	Loss: 0.2482
Training Epoch: 59 [28672/50176]	Loss: 0.2059
Training Epoch: 59 [29696/50176]	Loss: 0.2129
Training Epoch: 59 [30720/50176]	Loss: 0.2079
Training Epoch: 59 [31744/50176]	Loss: 0.2317
Training Epoch: 59 [32768/50176]	Loss: 0.2098
Training Epoch: 59 [33792/50176]	Loss: 0.2171
Training Epoch: 59 [34816/50176]	Loss: 0.2457
Training Epoch: 59 [35840/50176]	Loss: 0.2085
Training Epoch: 59 [36864/50176]	Loss: 0.2419
Training Epoch: 59 [37888/50176]	Loss: 0.2058
Training Epoch: 59 [38912/50176]	Loss: 0.2110
Training Epoch: 59 [39936/50176]	Loss: 0.2047
Training Epoch: 59 [40960/50176]	Loss: 0.2361
Training Epoch: 59 [41984/50176]	Loss: 0.2019
Training Epoch: 59 [43008/50176]	Loss: 0.2198
Training Epoch: 59 [44032/50176]	Loss: 0.2658
Training Epoch: 59 [45056/50176]	Loss: 0.2241
Training Epoch: 59 [46080/50176]	Loss: 0.2485
Training Epoch: 59 [47104/50176]	Loss: 0.2191
Training Epoch: 59 [48128/50176]	Loss: 0.2373
Training Epoch: 59 [49152/50176]	Loss: 0.2625
Training Epoch: 59 [50176/50176]	Loss: 0.2138
2022-12-06 17:58:38.005 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:58:38,042 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.84 energy=485.41
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Up to epoch 60: time=2952.77, energy=410755.76, cost=463745.64
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Expected next epoch: time=3000.05, energy=417539.71, cost=471274.09
2022-12-06 12:58:38,043 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0026, Accuracy: 0.5640
2022-12-06 12:58:38,259 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:58:38,260 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:58:38.274 [ZeusMonitor] Monitor started.
2022-12-06 17:58:38.274 [ZeusMonitor] Running indefinitely. 2022-12-06 17:58:38.274 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:58:38.274 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 12:59:22,645 [ZeusDataLoader(train)] train epoch 61 done: time=44.59 energy=6324.16
2022-12-06 12:59:22,648 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.1842
Training Epoch: 60 [2048/50176]	Loss: 0.1664
Training Epoch: 60 [3072/50176]	Loss: 0.1844
Training Epoch: 60 [4096/50176]	Loss: 0.1943
Training Epoch: 60 [5120/50176]	Loss: 0.2247
Training Epoch: 60 [6144/50176]	Loss: 0.1611
Training Epoch: 60 [7168/50176]	Loss: 0.2027
Training Epoch: 60 [8192/50176]	Loss: 0.1882
Training Epoch: 60 [9216/50176]	Loss: 0.1932
Training Epoch: 60 [10240/50176]	Loss: 0.1879
Training Epoch: 60 [11264/50176]	Loss: 0.1964
Training Epoch: 60 [12288/50176]	Loss: 0.2318
Training Epoch: 60 [13312/50176]	Loss: 0.2108
Training Epoch: 60 [14336/50176]	Loss: 0.2162
Training Epoch: 60 [15360/50176]	Loss: 0.2140
Training Epoch: 60 [16384/50176]	Loss: 0.1939
Training Epoch: 60 [17408/50176]	Loss: 0.1883
Training Epoch: 60 [18432/50176]	Loss: 0.1796
Training Epoch: 60 [19456/50176]	Loss: 0.2047
Training Epoch: 60 [20480/50176]	Loss: 0.1937
Training Epoch: 60 [21504/50176]	Loss: 0.2251
Training Epoch: 60 [22528/50176]	Loss: 0.2203
Training Epoch: 60 [23552/50176]	Loss: 0.1730
Training Epoch: 60 [24576/50176]	Loss: 0.2074
Training Epoch: 60 [25600/50176]	Loss: 0.2268
Training Epoch: 60 [26624/50176]	Loss: 0.1884
Training Epoch: 60 [27648/50176]	Loss: 0.2093
Training Epoch: 60 [28672/50176]	Loss: 0.1906
Training Epoch: 60 [29696/50176]	Loss: 0.2014
Training Epoch: 60 [30720/50176]	Loss: 0.2055
Training Epoch: 60 [31744/50176]	Loss: 0.2429
Training Epoch: 60 [32768/50176]	Loss: 0.1920
Training Epoch: 60 [33792/50176]	Loss: 0.2361
Training Epoch: 60 [34816/50176]	Loss: 0.2394
Training Epoch: 60 [35840/50176]	Loss: 0.1784
Training Epoch: 60 [36864/50176]	Loss: 0.2418
Training Epoch: 60 [37888/50176]	Loss: 0.2383
Training Epoch: 60 [38912/50176]	Loss: 0.2044
Training Epoch: 60 [39936/50176]	Loss: 0.1881
Training Epoch: 60 [40960/50176]	Loss: 0.2392
Training Epoch: 60 [41984/50176]	Loss: 0.2160
Training Epoch: 60 [43008/50176]	Loss: 0.2374
Training Epoch: 60 [44032/50176]	Loss: 0.2437
Training Epoch: 60 [45056/50176]	Loss: 0.2020
Training Epoch: 60 [46080/50176]	Loss: 0.2465
Training Epoch: 60 [47104/50176]	Loss: 0.2267
Training Epoch: 60 [48128/50176]	Loss: 0.2025
Training Epoch: 60 [49152/50176]	Loss: 0.2341
Training Epoch: 60 [50176/50176]	Loss: 0.2372
2022-12-06 17:59:26.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:59:26,356 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.70 energy=473.56
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Up to epoch 61: time=3001.07, energy=417553.47, cost=471370.18
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Expected next epoch: time=3048.34, energy=424337.42, cost=478898.64
2022-12-06 12:59:26,358 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0023, Accuracy: 0.5823
2022-12-06 12:59:26,572 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:59:26,573 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:59:26.574 [ZeusMonitor] Monitor started.
2022-12-06 17:59:26.574 [ZeusMonitor] Running indefinitely. 2022-12-06 17:59:26.574 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:59:26.574 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 13:00:10,760 [ZeusDataLoader(train)] train epoch 62 done: time=44.39 energy=6328.35
2022-12-06 13:00:10,763 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.1883
Training Epoch: 61 [2048/50176]	Loss: 0.1907
Training Epoch: 61 [3072/50176]	Loss: 0.1815
Training Epoch: 61 [4096/50176]	Loss: 0.1814
Training Epoch: 61 [5120/50176]	Loss: 0.1706
Training Epoch: 61 [6144/50176]	Loss: 0.1972
Training Epoch: 61 [7168/50176]	Loss: 0.2138
Training Epoch: 61 [8192/50176]	Loss: 0.1866
Training Epoch: 61 [9216/50176]	Loss: 0.1931
Training Epoch: 61 [10240/50176]	Loss: 0.1845
Training Epoch: 61 [11264/50176]	Loss: 0.1737
Training Epoch: 61 [12288/50176]	Loss: 0.1791
Training Epoch: 61 [13312/50176]	Loss: 0.2025
Training Epoch: 61 [14336/50176]	Loss: 0.2141
Training Epoch: 61 [15360/50176]	Loss: 0.1991
Training Epoch: 61 [16384/50176]	Loss: 0.1816
Training Epoch: 61 [17408/50176]	Loss: 0.1807
Training Epoch: 61 [18432/50176]	Loss: 0.1893
Training Epoch: 61 [19456/50176]	Loss: 0.1669
Training Epoch: 61 [20480/50176]	Loss: 0.1941
Training Epoch: 61 [21504/50176]	Loss: 0.2125
Training Epoch: 61 [22528/50176]	Loss: 0.2025
Training Epoch: 61 [23552/50176]	Loss: 0.1911
Training Epoch: 61 [24576/50176]	Loss: 0.1837
Training Epoch: 61 [25600/50176]	Loss: 0.1837
Training Epoch: 61 [26624/50176]	Loss: 0.1807
Training Epoch: 61 [27648/50176]	Loss: 0.2156
Training Epoch: 61 [28672/50176]	Loss: 0.1808
Training Epoch: 61 [29696/50176]	Loss: 0.1770
Training Epoch: 61 [30720/50176]	Loss: 0.2035
Training Epoch: 61 [31744/50176]	Loss: 0.2098
Training Epoch: 61 [32768/50176]	Loss: 0.1850
Training Epoch: 61 [33792/50176]	Loss: 0.2189
Training Epoch: 61 [34816/50176]	Loss: 0.2020
Training Epoch: 61 [35840/50176]	Loss: 0.1748
Training Epoch: 61 [36864/50176]	Loss: 0.2114
Training Epoch: 61 [37888/50176]	Loss: 0.2203
Training Epoch: 61 [38912/50176]	Loss: 0.1880
Training Epoch: 61 [39936/50176]	Loss: 0.2271
Training Epoch: 61 [40960/50176]	Loss: 0.2094
Training Epoch: 61 [41984/50176]	Loss: 0.2134
Training Epoch: 61 [43008/50176]	Loss: 0.2164
Training Epoch: 61 [44032/50176]	Loss: 0.2006
Training Epoch: 61 [45056/50176]	Loss: 0.2089
Training Epoch: 61 [46080/50176]	Loss: 0.2217
Training Epoch: 61 [47104/50176]	Loss: 0.2079
Training Epoch: 61 [48128/50176]	Loss: 0.2062
Training Epoch: 61 [49152/50176]	Loss: 0.2168
Training Epoch: 61 [50176/50176]	Loss: 0.2288
2022-12-06 18:00:14.516 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:00:14,544 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.77 energy=481.50
2022-12-06 13:00:14,544 [ZeusDataLoader(train)] Up to epoch 62: time=3049.24, energy=424363.32, cost=478989.76
2022-12-06 13:00:14,545 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:00:14,545 [ZeusDataLoader(train)] Expected next epoch: time=3096.51, energy=431147.28, cost=486518.21
2022-12-06 13:00:14,546 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0024, Accuracy: 0.5899
2022-12-06 13:00:14,776 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:00:14,777 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:00:14.779 [ZeusMonitor] Monitor started.
2022-12-06 18:00:14.779 [ZeusMonitor] Running indefinitely. 2022-12-06 18:00:14.779 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:00:14.779 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 13:00:58,968 [ZeusDataLoader(train)] train epoch 63 done: time=44.41 energy=6318.96
2022-12-06 13:00:58,971 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.1576
Training Epoch: 62 [2048/50176]	Loss: 0.1854
Training Epoch: 62 [3072/50176]	Loss: 0.1578
Training Epoch: 62 [4096/50176]	Loss: 0.1853
Training Epoch: 62 [5120/50176]	Loss: 0.1889
Training Epoch: 62 [6144/50176]	Loss: 0.1733
Training Epoch: 62 [7168/50176]	Loss: 0.1894
Training Epoch: 62 [8192/50176]	Loss: 0.1784
Training Epoch: 62 [9216/50176]	Loss: 0.1897
Training Epoch: 62 [10240/50176]	Loss: 0.1850
Training Epoch: 62 [11264/50176]	Loss: 0.1806
Training Epoch: 62 [12288/50176]	Loss: 0.2005
Training Epoch: 62 [13312/50176]	Loss: 0.1757
Training Epoch: 62 [14336/50176]	Loss: 0.2279
Training Epoch: 62 [15360/50176]	Loss: 0.1968
Training Epoch: 62 [16384/50176]	Loss: 0.1817
Training Epoch: 62 [17408/50176]	Loss: 0.1598
Training Epoch: 62 [18432/50176]	Loss: 0.2288
Training Epoch: 62 [19456/50176]	Loss: 0.1879
Training Epoch: 62 [20480/50176]	Loss: 0.2207
Training Epoch: 62 [21504/50176]	Loss: 0.1804
Training Epoch: 62 [22528/50176]	Loss: 0.1865
Training Epoch: 62 [23552/50176]	Loss: 0.1664
Training Epoch: 62 [24576/50176]	Loss: 0.1957
Training Epoch: 62 [25600/50176]	Loss: 0.1786
Training Epoch: 62 [26624/50176]	Loss: 0.1494
Training Epoch: 62 [27648/50176]	Loss: 0.2373
Training Epoch: 62 [28672/50176]	Loss: 0.2086
Training Epoch: 62 [29696/50176]	Loss: 0.1889
Training Epoch: 62 [30720/50176]	Loss: 0.1885
Training Epoch: 62 [31744/50176]	Loss: 0.2234
Training Epoch: 62 [32768/50176]	Loss: 0.1790
Training Epoch: 62 [33792/50176]	Loss: 0.2252
Training Epoch: 62 [34816/50176]	Loss: 0.1948
Training Epoch: 62 [35840/50176]	Loss: 0.1876
Training Epoch: 62 [36864/50176]	Loss: 0.2123
Training Epoch: 62 [37888/50176]	Loss: 0.1778
Training Epoch: 62 [38912/50176]	Loss: 0.2028
Training Epoch: 62 [39936/50176]	Loss: 0.2054
Training Epoch: 62 [40960/50176]	Loss: 0.1540
Training Epoch: 62 [41984/50176]	Loss: 0.1978
Training Epoch: 62 [43008/50176]	Loss: 0.2164
Training Epoch: 62 [44032/50176]	Loss: 0.1934
Training Epoch: 62 [45056/50176]	Loss: 0.2064
Training Epoch: 62 [46080/50176]	Loss: 0.2139
Training Epoch: 62 [47104/50176]	Loss: 0.2025
Training Epoch: 62 [48128/50176]	Loss: 0.2248
Training Epoch: 62 [49152/50176]	Loss: 0.2055
Training Epoch: 62 [50176/50176]	Loss: 0.2200
2022-12-06 18:01:02.783 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:01:02,813 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.83 energy=496.84
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Up to epoch 63: time=3097.48, energy=431179.13, cost=486619.41
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Expected next epoch: time=3144.76, energy=437963.08, cost=494147.86
2022-12-06 13:01:02,815 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0025, Accuracy: 0.5934
2022-12-06 13:01:02,989 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:01:02,990 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:01:02.993 [ZeusMonitor] Monitor started.
2022-12-06 18:01:02.993 [ZeusMonitor] Running indefinitely. 2022-12-06 18:01:02.994 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:01:02.994 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 13:01:47,276 [ZeusDataLoader(train)] train epoch 64 done: time=44.45 energy=6331.94
2022-12-06 13:01:47,280 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 0.1677
Training Epoch: 63 [2048/50176]	Loss: 0.1851
Training Epoch: 63 [3072/50176]	Loss: 0.1523
Training Epoch: 63 [4096/50176]	Loss: 0.1694
Training Epoch: 63 [5120/50176]	Loss: 0.1516
Training Epoch: 63 [6144/50176]	Loss: 0.1683
Training Epoch: 63 [7168/50176]	Loss: 0.2025
Training Epoch: 63 [8192/50176]	Loss: 0.1568
Training Epoch: 63 [9216/50176]	Loss: 0.1467
Training Epoch: 63 [10240/50176]	Loss: 0.1921
Training Epoch: 63 [11264/50176]	Loss: 0.1738
Training Epoch: 63 [12288/50176]	Loss: 0.1622
Training Epoch: 63 [13312/50176]	Loss: 0.1670
Training Epoch: 63 [14336/50176]	Loss: 0.1807
Training Epoch: 63 [15360/50176]	Loss: 0.1863
Training Epoch: 63 [16384/50176]	Loss: 0.1714
Training Epoch: 63 [17408/50176]	Loss: 0.1499
Training Epoch: 63 [18432/50176]	Loss: 0.1747
Training Epoch: 63 [19456/50176]	Loss: 0.1728
Training Epoch: 63 [20480/50176]	Loss: 0.1714
Training Epoch: 63 [21504/50176]	Loss: 0.1915
Training Epoch: 63 [22528/50176]	Loss: 0.1599
Training Epoch: 63 [23552/50176]	Loss: 0.1972
Training Epoch: 63 [24576/50176]	Loss: 0.1736
Training Epoch: 63 [25600/50176]	Loss: 0.1871
Training Epoch: 63 [26624/50176]	Loss: 0.1804
Training Epoch: 63 [27648/50176]	Loss: 0.1666
Training Epoch: 63 [28672/50176]	Loss: 0.1811
Training Epoch: 63 [29696/50176]	Loss: 0.2235
Training Epoch: 63 [30720/50176]	Loss: 0.2009
Training Epoch: 63 [31744/50176]	Loss: 0.1783
Training Epoch: 63 [32768/50176]	Loss: 0.2018
Training Epoch: 63 [33792/50176]	Loss: 0.1731
Training Epoch: 63 [34816/50176]	Loss: 0.1867
Training Epoch: 63 [35840/50176]	Loss: 0.1831
Training Epoch: 63 [36864/50176]	Loss: 0.2292
Training Epoch: 63 [37888/50176]	Loss: 0.2117
Training Epoch: 63 [38912/50176]	Loss: 0.1862
Training Epoch: 63 [39936/50176]	Loss: 0.1999
Training Epoch: 63 [40960/50176]	Loss: 0.2074
Training Epoch: 63 [41984/50176]	Loss: 0.2170
Training Epoch: 63 [43008/50176]	Loss: 0.2357
Training Epoch: 63 [44032/50176]	Loss: 0.1867
Training Epoch: 63 [45056/50176]	Loss: 0.1764
Training Epoch: 63 [46080/50176]	Loss: 0.1880
Training Epoch: 63 [47104/50176]	Loss: 0.1891
Training Epoch: 63 [48128/50176]	Loss: 0.2368
Training Epoch: 63 [49152/50176]	Loss: 0.1980
Training Epoch: 63 [50176/50176]	Loss: 0.1997
2022-12-06 18:01:51.000 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:01:51,019 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.73 energy=479.51
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Up to epoch 64: time=3145.67, energy=437990.57, cost=494241.38
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Expected next epoch: time=3192.94, energy=444774.52, cost=501769.84
2022-12-06 13:01:51,021 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0024, Accuracy: 0.5896
2022-12-06 13:01:51,229 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:01:51,230 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:01:51.231 [ZeusMonitor] Monitor started.
2022-12-06 18:01:51.231 [ZeusMonitor] Running indefinitely. 2022-12-06 18:01:51.231 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:01:51.231 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 13:02:35,180 [ZeusDataLoader(train)] train epoch 65 done: time=44.15 energy=6300.03
2022-12-06 13:02:35,184 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 0.1721
Training Epoch: 64 [2048/50176]	Loss: 0.1307
Training Epoch: 64 [3072/50176]	Loss: 0.1839
Training Epoch: 64 [4096/50176]	Loss: 0.1766
Training Epoch: 64 [5120/50176]	Loss: 0.1714
Training Epoch: 64 [6144/50176]	Loss: 0.1534
Training Epoch: 64 [7168/50176]	Loss: 0.1642
Training Epoch: 64 [8192/50176]	Loss: 0.1561
Training Epoch: 64 [9216/50176]	Loss: 0.1479
Training Epoch: 64 [10240/50176]	Loss: 0.1777
Training Epoch: 64 [11264/50176]	Loss: 0.1426
Training Epoch: 64 [12288/50176]	Loss: 0.1593
Training Epoch: 64 [13312/50176]	Loss: 0.1518
Training Epoch: 64 [14336/50176]	Loss: 0.1563
Training Epoch: 64 [15360/50176]	Loss: 0.1214
Training Epoch: 64 [16384/50176]	Loss: 0.1745
Training Epoch: 64 [17408/50176]	Loss: 0.1600
Training Epoch: 64 [18432/50176]	Loss: 0.2244
Training Epoch: 64 [19456/50176]	Loss: 0.1608
Training Epoch: 64 [20480/50176]	Loss: 0.1988
Training Epoch: 64 [21504/50176]	Loss: 0.1592
Training Epoch: 64 [22528/50176]	Loss: 0.1842
Training Epoch: 64 [23552/50176]	Loss: 0.1552
Training Epoch: 64 [24576/50176]	Loss: 0.1575
Training Epoch: 64 [25600/50176]	Loss: 0.1816
Training Epoch: 64 [26624/50176]	Loss: 0.1990
Training Epoch: 64 [27648/50176]	Loss: 0.1494
Training Epoch: 64 [28672/50176]	Loss: 0.1732
Training Epoch: 64 [29696/50176]	Loss: 0.1945
Training Epoch: 64 [30720/50176]	Loss: 0.1924
Training Epoch: 64 [31744/50176]	Loss: 0.1952
Training Epoch: 64 [32768/50176]	Loss: 0.1742
Training Epoch: 64 [33792/50176]	Loss: 0.2014
Training Epoch: 64 [34816/50176]	Loss: 0.1564
Training Epoch: 64 [35840/50176]	Loss: 0.1887
Training Epoch: 64 [36864/50176]	Loss: 0.1872
Training Epoch: 64 [37888/50176]	Loss: 0.1617
Training Epoch: 64 [38912/50176]	Loss: 0.1867
Training Epoch: 64 [39936/50176]	Loss: 0.1820
Training Epoch: 64 [40960/50176]	Loss: 0.2187
Training Epoch: 64 [41984/50176]	Loss: 0.2035
Training Epoch: 64 [43008/50176]	Loss: 0.2091
Training Epoch: 64 [44032/50176]	Loss: 0.1724
Training Epoch: 64 [45056/50176]	Loss: 0.1975
Training Epoch: 64 [46080/50176]	Loss: 0.2058
Training Epoch: 64 [47104/50176]	Loss: 0.1685
Training Epoch: 64 [48128/50176]	Loss: 0.1790
Training Epoch: 64 [49152/50176]	Loss: 0.2075
Training Epoch: 64 [50176/50176]	Loss: 0.1723
2022-12-06 18:02:38.952 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:02:38,988 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.80 energy=486.41
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Up to epoch 65: time=3193.62, energy=444777.01, cost=501829.97
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Expected next epoch: time=3240.89, energy=451560.96, cost=509358.42
2022-12-06 13:02:38,989 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0024, Accuracy: 0.5929
2022-12-06 13:02:39,221 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:02:39,222 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:02:39.232 [ZeusMonitor] Monitor started.
2022-12-06 18:02:39.232 [ZeusMonitor] Running indefinitely. 2022-12-06 18:02:39.232 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:02:39.232 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 13:03:23,579 [ZeusDataLoader(train)] train epoch 66 done: time=44.58 energy=6326.25
2022-12-06 13:03:23,582 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.1477
Training Epoch: 65 [2048/50176]	Loss: 0.1591
Training Epoch: 65 [3072/50176]	Loss: 0.1533
Training Epoch: 65 [4096/50176]	Loss: 0.1586
Training Epoch: 65 [5120/50176]	Loss: 0.1817
Training Epoch: 65 [6144/50176]	Loss: 0.1739
Training Epoch: 65 [7168/50176]	Loss: 0.1689
Training Epoch: 65 [8192/50176]	Loss: 0.1536
Training Epoch: 65 [9216/50176]	Loss: 0.1433
Training Epoch: 65 [10240/50176]	Loss: 0.1553
Training Epoch: 65 [11264/50176]	Loss: 0.1655
Training Epoch: 65 [12288/50176]	Loss: 0.1710
Training Epoch: 65 [13312/50176]	Loss: 0.1702
Training Epoch: 65 [14336/50176]	Loss: 0.1683
Training Epoch: 65 [15360/50176]	Loss: 0.1776
Training Epoch: 65 [16384/50176]	Loss: 0.1932
Training Epoch: 65 [17408/50176]	Loss: 0.1438
Training Epoch: 65 [18432/50176]	Loss: 0.1524
Training Epoch: 65 [19456/50176]	Loss: 0.1280
Training Epoch: 65 [20480/50176]	Loss: 0.1895
Training Epoch: 65 [21504/50176]	Loss: 0.2007
Training Epoch: 65 [22528/50176]	Loss: 0.1642
Training Epoch: 65 [23552/50176]	Loss: 0.1616
Training Epoch: 65 [24576/50176]	Loss: 0.1706
Training Epoch: 65 [25600/50176]	Loss: 0.1824
Training Epoch: 65 [26624/50176]	Loss: 0.1644
Training Epoch: 65 [27648/50176]	Loss: 0.2265
Training Epoch: 65 [28672/50176]	Loss: 0.1455
Training Epoch: 65 [29696/50176]	Loss: 0.1557
Training Epoch: 65 [30720/50176]	Loss: 0.1836
Training Epoch: 65 [31744/50176]	Loss: 0.1858
Training Epoch: 65 [32768/50176]	Loss: 0.1646
Training Epoch: 65 [33792/50176]	Loss: 0.1617
Training Epoch: 65 [34816/50176]	Loss: 0.1917
Training Epoch: 65 [35840/50176]	Loss: 0.1652
Training Epoch: 65 [36864/50176]	Loss: 0.1883
Training Epoch: 65 [37888/50176]	Loss: 0.1785
Training Epoch: 65 [38912/50176]	Loss: 0.2002
Training Epoch: 65 [39936/50176]	Loss: 0.1768
Training Epoch: 65 [40960/50176]	Loss: 0.1765
Training Epoch: 65 [41984/50176]	Loss: 0.1740
Training Epoch: 65 [43008/50176]	Loss: 0.1839
Training Epoch: 65 [44032/50176]	Loss: 0.1542
Training Epoch: 65 [45056/50176]	Loss: 0.1862
Training Epoch: 65 [46080/50176]	Loss: 0.1743
Training Epoch: 65 [47104/50176]	Loss: 0.1624
Training Epoch: 65 [48128/50176]	Loss: 0.1842
Training Epoch: 65 [49152/50176]	Loss: 0.2019
Training Epoch: 65 [50176/50176]	Loss: 0.2138
2022-12-06 18:03:27.375 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:03:27,387 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.80 energy=488.52
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Up to epoch 66: time=3242.00, energy=451591.79, cost=509470.46
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Expected next epoch: time=3289.27, energy=458375.74, cost=516998.91
2022-12-06 13:03:27,388 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0024, Accuracy: 0.5945
2022-12-06 13:03:27,613 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:03:27,613 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:03:27.615 [ZeusMonitor] Monitor started.
2022-12-06 18:03:27.615 [ZeusMonitor] Running indefinitely. 2022-12-06 18:03:27.615 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:03:27.615 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 13:04:12,028 [ZeusDataLoader(train)] train epoch 67 done: time=44.63 energy=6339.96
2022-12-06 13:04:12,031 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.1652
Training Epoch: 66 [2048/50176]	Loss: 0.1464
Training Epoch: 66 [3072/50176]	Loss: 0.1496
Training Epoch: 66 [4096/50176]	Loss: 0.1696
Training Epoch: 66 [5120/50176]	Loss: 0.1625
Training Epoch: 66 [6144/50176]	Loss: 0.1356
Training Epoch: 66 [7168/50176]	Loss: 0.1652
Training Epoch: 66 [8192/50176]	Loss: 0.1936
Training Epoch: 66 [9216/50176]	Loss: 0.1793
Training Epoch: 66 [10240/50176]	Loss: 0.1837
Training Epoch: 66 [11264/50176]	Loss: 0.1553
Training Epoch: 66 [12288/50176]	Loss: 0.1503
Training Epoch: 66 [13312/50176]	Loss: 0.1841
Training Epoch: 66 [14336/50176]	Loss: 0.1580
Training Epoch: 66 [15360/50176]	Loss: 0.1441
Training Epoch: 66 [16384/50176]	Loss: 0.1436
Training Epoch: 66 [17408/50176]	Loss: 0.1928
Training Epoch: 66 [18432/50176]	Loss: 0.1626
Training Epoch: 66 [19456/50176]	Loss: 0.1753
Training Epoch: 66 [20480/50176]	Loss: 0.1923
Training Epoch: 66 [21504/50176]	Loss: 0.1486
Training Epoch: 66 [22528/50176]	Loss: 0.1530
Training Epoch: 66 [23552/50176]	Loss: 0.2095
Training Epoch: 66 [24576/50176]	Loss: 0.1649
Training Epoch: 66 [25600/50176]	Loss: 0.1601
Training Epoch: 66 [26624/50176]	Loss: 0.1783
Training Epoch: 66 [27648/50176]	Loss: 0.1940
Training Epoch: 66 [28672/50176]	Loss: 0.1891
Training Epoch: 66 [29696/50176]	Loss: 0.1483
Training Epoch: 66 [30720/50176]	Loss: 0.1518
Training Epoch: 66 [31744/50176]	Loss: 0.1852
Training Epoch: 66 [32768/50176]	Loss: 0.1539
Training Epoch: 66 [33792/50176]	Loss: 0.1773
Training Epoch: 66 [34816/50176]	Loss: 0.1887
Training Epoch: 66 [35840/50176]	Loss: 0.2072
Training Epoch: 66 [36864/50176]	Loss: 0.1629
Training Epoch: 66 [37888/50176]	Loss: 0.1665
Training Epoch: 66 [38912/50176]	Loss: 0.1723
Training Epoch: 66 [39936/50176]	Loss: 0.2175
Training Epoch: 66 [40960/50176]	Loss: 0.2006
Training Epoch: 66 [41984/50176]	Loss: 0.2154
Training Epoch: 66 [43008/50176]	Loss: 0.1819
Training Epoch: 66 [44032/50176]	Loss: 0.1697
Training Epoch: 66 [45056/50176]	Loss: 0.1809
Training Epoch: 66 [46080/50176]	Loss: 0.1863
Training Epoch: 66 [47104/50176]	Loss: 0.1754
Training Epoch: 66 [48128/50176]	Loss: 0.1928
Training Epoch: 66 [49152/50176]	Loss: 0.1745
Training Epoch: 66 [50176/50176]	Loss: 0.1904
2022-12-06 18:04:15.774 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:04:15,824 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.78 energy=490.77
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Up to epoch 67: time=3290.41, energy=458422.52, cost=517122.28
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Expected next epoch: time=3337.69, energy=465206.47, cost=524650.74
2022-12-06 13:04:15,825 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0025, Accuracy: 0.5889
2022-12-06 13:04:16,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:04:16,033 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:04:16.047 [ZeusMonitor] Monitor started.
2022-12-06 18:04:16.047 [ZeusMonitor] Running indefinitely. 2022-12-06 18:04:16.047 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:04:16.047 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 13:05:00,217 [ZeusDataLoader(train)] train epoch 68 done: time=44.38 energy=6319.72
2022-12-06 13:05:00,220 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.1249
Training Epoch: 67 [2048/50176]	Loss: 0.1673
Training Epoch: 67 [3072/50176]	Loss: 0.1613
Training Epoch: 67 [4096/50176]	Loss: 0.1522
Training Epoch: 67 [5120/50176]	Loss: 0.1682
Training Epoch: 67 [6144/50176]	Loss: 0.1640
Training Epoch: 67 [7168/50176]	Loss: 0.1620
Training Epoch: 67 [8192/50176]	Loss: 0.1429
Training Epoch: 67 [9216/50176]	Loss: 0.1660
Training Epoch: 67 [10240/50176]	Loss: 0.1654
Training Epoch: 67 [11264/50176]	Loss: 0.1881
Training Epoch: 67 [12288/50176]	Loss: 0.1678
Training Epoch: 67 [13312/50176]	Loss: 0.1671
Training Epoch: 67 [14336/50176]	Loss: 0.1803
Training Epoch: 67 [15360/50176]	Loss: 0.1794
Training Epoch: 67 [16384/50176]	Loss: 0.1656
Training Epoch: 67 [17408/50176]	Loss: 0.1576
Training Epoch: 67 [18432/50176]	Loss: 0.1779
Training Epoch: 67 [19456/50176]	Loss: 0.2022
Training Epoch: 67 [20480/50176]	Loss: 0.1746
Training Epoch: 67 [21504/50176]	Loss: 0.1747
Training Epoch: 67 [22528/50176]	Loss: 0.1385
Training Epoch: 67 [23552/50176]	Loss: 0.1933
Training Epoch: 67 [24576/50176]	Loss: 0.1848
Training Epoch: 67 [25600/50176]	Loss: 0.1881
Training Epoch: 67 [26624/50176]	Loss: 0.1997
Training Epoch: 67 [27648/50176]	Loss: 0.1753
Training Epoch: 67 [28672/50176]	Loss: 0.1834
Training Epoch: 67 [29696/50176]	Loss: 0.1487
Training Epoch: 67 [30720/50176]	Loss: 0.1632
Training Epoch: 67 [31744/50176]	Loss: 0.2075
Training Epoch: 67 [32768/50176]	Loss: 0.1900
Training Epoch: 67 [33792/50176]	Loss: 0.1675
Training Epoch: 67 [34816/50176]	Loss: 0.1661
Training Epoch: 67 [35840/50176]	Loss: 0.1807
Training Epoch: 67 [36864/50176]	Loss: 0.1634
Training Epoch: 67 [37888/50176]	Loss: 0.1691
Training Epoch: 67 [38912/50176]	Loss: 0.1917
Training Epoch: 67 [39936/50176]	Loss: 0.1842
Training Epoch: 67 [40960/50176]	Loss: 0.1752
Training Epoch: 67 [41984/50176]	Loss: 0.2001
Training Epoch: 67 [43008/50176]	Loss: 0.1966
Training Epoch: 67 [44032/50176]	Loss: 0.1959
Training Epoch: 67 [45056/50176]	Loss: 0.1840
Training Epoch: 67 [46080/50176]	Loss: 0.1977
Training Epoch: 67 [47104/50176]	Loss: 0.1749
Training Epoch: 67 [48128/50176]	Loss: 0.1830
Training Epoch: 67 [49152/50176]	Loss: 0.1676
Training Epoch: 67 [50176/50176]	Loss: 0.1815
2022-12-06 18:05:03.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:05:03,955 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.73 energy=478.02
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Up to epoch 68: time=3338.52, energy=465220.26, cost=524730.88
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Expected next epoch: time=3385.80, energy=472004.21, cost=532259.34
2022-12-06 13:05:03,956 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0025, Accuracy: 0.5895
2022-12-06 13:05:04,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:05:04,174 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:05:04.176 [ZeusMonitor] Monitor started.
2022-12-06 18:05:04.176 [ZeusMonitor] Running indefinitely. 2022-12-06 18:05:04.176 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:05:04.176 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 13:05:48,209 [ZeusDataLoader(train)] train epoch 69 done: time=44.24 energy=6323.26
2022-12-06 13:05:48,212 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.1722
Training Epoch: 68 [2048/50176]	Loss: 0.1594
Training Epoch: 68 [3072/50176]	Loss: 0.1537
Training Epoch: 68 [4096/50176]	Loss: 0.1311
Training Epoch: 68 [5120/50176]	Loss: 0.1343
Training Epoch: 68 [6144/50176]	Loss: 0.1345
Training Epoch: 68 [7168/50176]	Loss: 0.1672
Training Epoch: 68 [8192/50176]	Loss: 0.1522
Training Epoch: 68 [9216/50176]	Loss: 0.1874
Training Epoch: 68 [10240/50176]	Loss: 0.1516
Training Epoch: 68 [11264/50176]	Loss: 0.1306
Training Epoch: 68 [12288/50176]	Loss: 0.1444
Training Epoch: 68 [13312/50176]	Loss: 0.1589
Training Epoch: 68 [14336/50176]	Loss: 0.1695
Training Epoch: 68 [15360/50176]	Loss: 0.1486
Training Epoch: 68 [16384/50176]	Loss: 0.1648
Training Epoch: 68 [17408/50176]	Loss: 0.1403
Training Epoch: 68 [18432/50176]	Loss: 0.1600
Training Epoch: 68 [19456/50176]	Loss: 0.1626
Training Epoch: 68 [20480/50176]	Loss: 0.1444
Training Epoch: 68 [21504/50176]	Loss: 0.1746
Training Epoch: 68 [22528/50176]	Loss: 0.1645
Training Epoch: 68 [23552/50176]	Loss: 0.1421
Training Epoch: 68 [24576/50176]	Loss: 0.1635
Training Epoch: 68 [25600/50176]	Loss: 0.1788
Training Epoch: 68 [26624/50176]	Loss: 0.1902
Training Epoch: 68 [27648/50176]	Loss: 0.1629
Training Epoch: 68 [28672/50176]	Loss: 0.1521
Training Epoch: 68 [29696/50176]	Loss: 0.1480
Training Epoch: 68 [30720/50176]	Loss: 0.1673
Training Epoch: 68 [31744/50176]	Loss: 0.1842
Training Epoch: 68 [32768/50176]	Loss: 0.1938
Training Epoch: 68 [33792/50176]	Loss: 0.1428
Training Epoch: 68 [34816/50176]	Loss: 0.1606
Training Epoch: 68 [35840/50176]	Loss: 0.1642
Training Epoch: 68 [36864/50176]	Loss: 0.1922
Training Epoch: 68 [37888/50176]	Loss: 0.1556
Training Epoch: 68 [38912/50176]	Loss: 0.1555
Training Epoch: 68 [39936/50176]	Loss: 0.2104
Training Epoch: 68 [40960/50176]	Loss: 0.1929
Training Epoch: 68 [41984/50176]	Loss: 0.1778
Training Epoch: 68 [43008/50176]	Loss: 0.1882
Training Epoch: 68 [44032/50176]	Loss: 0.1761
Training Epoch: 68 [45056/50176]	Loss: 0.1790
Training Epoch: 68 [46080/50176]	Loss: 0.1646
Training Epoch: 68 [47104/50176]	Loss: 0.1896
Training Epoch: 68 [48128/50176]	Loss: 0.2159
Training Epoch: 68 [49152/50176]	Loss: 0.1878
Training Epoch: 68 [50176/50176]	Loss: 0.1841
2022-12-06 18:05:51.916 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:05:51,930 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.71 energy=473.11
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Up to epoch 69: time=3386.48, energy=472016.62, cost=532325.14
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Expected next epoch: time=3433.75, energy=478800.58, cost=539853.60
2022-12-06 13:05:51,932 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0025, Accuracy: 0.5861
2022-12-06 13:05:52,153 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:05:52,154 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:05:52.156 [ZeusMonitor] Monitor started.
2022-12-06 18:05:52.156 [ZeusMonitor] Running indefinitely. 2022-12-06 18:05:52.156 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:05:52.156 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 13:06:36,492 [ZeusDataLoader(train)] train epoch 70 done: time=44.55 energy=6341.13
2022-12-06 13:06:36,495 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.1233
Training Epoch: 69 [2048/50176]	Loss: 0.1269
Training Epoch: 69 [3072/50176]	Loss: 0.1689
Training Epoch: 69 [4096/50176]	Loss: 0.1365
Training Epoch: 69 [5120/50176]	Loss: 0.1291
Training Epoch: 69 [6144/50176]	Loss: 0.1501
Training Epoch: 69 [7168/50176]	Loss: 0.1368
Training Epoch: 69 [8192/50176]	Loss: 0.1313
Training Epoch: 69 [9216/50176]	Loss: 0.1630
Training Epoch: 69 [10240/50176]	Loss: 0.1654
Training Epoch: 69 [11264/50176]	Loss: 0.1351
Training Epoch: 69 [12288/50176]	Loss: 0.1397
Training Epoch: 69 [13312/50176]	Loss: 0.1403
Training Epoch: 69 [14336/50176]	Loss: 0.1557
Training Epoch: 69 [15360/50176]	Loss: 0.1376
Training Epoch: 69 [16384/50176]	Loss: 0.1301
Training Epoch: 69 [17408/50176]	Loss: 0.1751
Training Epoch: 69 [18432/50176]	Loss: 0.1668
Training Epoch: 69 [19456/50176]	Loss: 0.1480
Training Epoch: 69 [20480/50176]	Loss: 0.1444
Training Epoch: 69 [21504/50176]	Loss: 0.1428
Training Epoch: 69 [22528/50176]	Loss: 0.2138
Training Epoch: 69 [23552/50176]	Loss: 0.1691
Training Epoch: 69 [24576/50176]	Loss: 0.1469
Training Epoch: 69 [25600/50176]	Loss: 0.1812
Training Epoch: 69 [26624/50176]	Loss: 0.1497
Training Epoch: 69 [27648/50176]	Loss: 0.1661
Training Epoch: 69 [28672/50176]	Loss: 0.1557
Training Epoch: 69 [29696/50176]	Loss: 0.1441
Training Epoch: 69 [30720/50176]	Loss: 0.1591
Training Epoch: 69 [31744/50176]	Loss: 0.1738
Training Epoch: 69 [32768/50176]	Loss: 0.1498
Training Epoch: 69 [33792/50176]	Loss: 0.1728
Training Epoch: 69 [34816/50176]	Loss: 0.1328
Training Epoch: 69 [35840/50176]	Loss: 0.1385
Training Epoch: 69 [36864/50176]	Loss: 0.1507
Training Epoch: 69 [37888/50176]	Loss: 0.1677
Training Epoch: 69 [38912/50176]	Loss: 0.1637
Training Epoch: 69 [39936/50176]	Loss: 0.1736
Training Epoch: 69 [40960/50176]	Loss: 0.1752
Training Epoch: 69 [41984/50176]	Loss: 0.1790
Training Epoch: 69 [43008/50176]	Loss: 0.1590
Training Epoch: 69 [44032/50176]	Loss: 0.1429
Training Epoch: 69 [45056/50176]	Loss: 0.1824
Training Epoch: 69 [46080/50176]	Loss: 0.1531
Training Epoch: 69 [47104/50176]	Loss: 0.1888
Training Epoch: 69 [48128/50176]	Loss: 0.1708
Training Epoch: 69 [49152/50176]	Loss: 0.1733
Training Epoch: 69 [50176/50176]	Loss: 0.2030
2022-12-06 18:06:40.173 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:06:40,192 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.69 energy=461.84
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Up to epoch 70: time=3434.72, energy=478819.60, cost=539947.75
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Expected next epoch: time=3481.99, energy=485603.55, cost=547476.20
2022-12-06 13:06:40,194 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0024, Accuracy: 0.5967
2022-12-06 13:06:40,410 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:06:40,411 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:06:40.413 [ZeusMonitor] Monitor started.
2022-12-06 18:06:40.413 [ZeusMonitor] Running indefinitely. 2022-12-06 18:06:40.413 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:06:40.413 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 13:07:25,003 [ZeusDataLoader(train)] train epoch 71 done: time=44.80 energy=6344.43
2022-12-06 13:07:25,006 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.1248
Training Epoch: 70 [2048/50176]	Loss: 0.1334
Training Epoch: 70 [3072/50176]	Loss: 0.1283
Training Epoch: 70 [4096/50176]	Loss: 0.1334
Training Epoch: 70 [5120/50176]	Loss: 0.1815
Training Epoch: 70 [6144/50176]	Loss: 0.1141
Training Epoch: 70 [7168/50176]	Loss: 0.1691
Training Epoch: 70 [8192/50176]	Loss: 0.1542
Training Epoch: 70 [9216/50176]	Loss: 0.1631
Training Epoch: 70 [10240/50176]	Loss: 0.1656
Training Epoch: 70 [11264/50176]	Loss: 0.1183
Training Epoch: 70 [12288/50176]	Loss: 0.1472
Training Epoch: 70 [13312/50176]	Loss: 0.1502
Training Epoch: 70 [14336/50176]	Loss: 0.1802
Training Epoch: 70 [15360/50176]	Loss: 0.1925
Training Epoch: 70 [16384/50176]	Loss: 0.1528
Training Epoch: 70 [17408/50176]	Loss: 0.1530
Training Epoch: 70 [18432/50176]	Loss: 0.1299
Training Epoch: 70 [19456/50176]	Loss: 0.1679
Training Epoch: 70 [20480/50176]	Loss: 0.1717
Training Epoch: 70 [21504/50176]	Loss: 0.1727
Training Epoch: 70 [22528/50176]	Loss: 0.1691
Training Epoch: 70 [23552/50176]	Loss: 0.1716
Training Epoch: 70 [24576/50176]	Loss: 0.1530
Training Epoch: 70 [25600/50176]	Loss: 0.1470
Training Epoch: 70 [26624/50176]	Loss: 0.1712
Training Epoch: 70 [27648/50176]	Loss: 0.1801
Training Epoch: 70 [28672/50176]	Loss: 0.1391
Training Epoch: 70 [29696/50176]	Loss: 0.1761
Training Epoch: 70 [30720/50176]	Loss: 0.1261
Training Epoch: 70 [31744/50176]	Loss: 0.1622
Training Epoch: 70 [32768/50176]	Loss: 0.1767
Training Epoch: 70 [33792/50176]	Loss: 0.1604
Training Epoch: 70 [34816/50176]	Loss: 0.1448
Training Epoch: 70 [35840/50176]	Loss: 0.1766
Training Epoch: 70 [36864/50176]	Loss: 0.1903
Training Epoch: 70 [37888/50176]	Loss: 0.1796
Training Epoch: 70 [38912/50176]	Loss: 0.1751
Training Epoch: 70 [39936/50176]	Loss: 0.1632
Training Epoch: 70 [40960/50176]	Loss: 0.2042
Training Epoch: 70 [41984/50176]	Loss: 0.1701
Training Epoch: 70 [43008/50176]	Loss: 0.1535
Training Epoch: 70 [44032/50176]	Loss: 0.1782
Training Epoch: 70 [45056/50176]	Loss: 0.2004
Training Epoch: 70 [46080/50176]	Loss: 0.1520
Training Epoch: 70 [47104/50176]	Loss: 0.1605
Training Epoch: 70 [48128/50176]	Loss: 0.1559
Training Epoch: 70 [49152/50176]	Loss: 0.2130
Training Epoch: 70 [50176/50176]	Loss: 0.1892
2022-12-06 18:07:28.728 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:07:28,742 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.73 energy=478.58
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Up to epoch 71: time=3483.25, energy=485642.61, cost=547605.57
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Expected next epoch: time=3530.52, energy=492426.56, cost=555134.02
2022-12-06 13:07:28,744 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0026, Accuracy: 0.5861
2022-12-06 13:07:28,944 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:07:28,945 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:07:28.947 [ZeusMonitor] Monitor started.
2022-12-06 18:07:28.947 [ZeusMonitor] Running indefinitely. 2022-12-06 18:07:28.947 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:07:28.947 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 13:08:13,010 [ZeusDataLoader(train)] train epoch 72 done: time=44.26 energy=6323.49
2022-12-06 13:08:13,013 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.1614
Training Epoch: 71 [2048/50176]	Loss: 0.1561
Training Epoch: 71 [3072/50176]	Loss: 0.1456
Training Epoch: 71 [4096/50176]	Loss: 0.1373
Training Epoch: 71 [5120/50176]	Loss: 0.1427
Training Epoch: 71 [6144/50176]	Loss: 0.1411
Training Epoch: 71 [7168/50176]	Loss: 0.1516
Training Epoch: 71 [8192/50176]	Loss: 0.1517
Training Epoch: 71 [9216/50176]	Loss: 0.1336
Training Epoch: 71 [10240/50176]	Loss: 0.1558
Training Epoch: 71 [11264/50176]	Loss: 0.1390
Training Epoch: 71 [12288/50176]	Loss: 0.1672
Training Epoch: 71 [13312/50176]	Loss: 0.1612
Training Epoch: 71 [14336/50176]	Loss: 0.1636
Training Epoch: 71 [15360/50176]	Loss: 0.1483
Training Epoch: 71 [16384/50176]	Loss: 0.1475
Training Epoch: 71 [17408/50176]	Loss: 0.1447
Training Epoch: 71 [18432/50176]	Loss: 0.1512
Training Epoch: 71 [19456/50176]	Loss: 0.1572
Training Epoch: 71 [20480/50176]	Loss: 0.1682
Training Epoch: 71 [21504/50176]	Loss: 0.1255
Training Epoch: 71 [22528/50176]	Loss: 0.1388
Training Epoch: 71 [23552/50176]	Loss: 0.1661
Training Epoch: 71 [24576/50176]	Loss: 0.1521
Training Epoch: 71 [25600/50176]	Loss: 0.1748
Training Epoch: 71 [26624/50176]	Loss: 0.1585
Training Epoch: 71 [27648/50176]	Loss: 0.1522
Training Epoch: 71 [28672/50176]	Loss: 0.1587
Training Epoch: 71 [29696/50176]	Loss: 0.1692
Training Epoch: 71 [30720/50176]	Loss: 0.1292
Training Epoch: 71 [31744/50176]	Loss: 0.1424
Training Epoch: 71 [32768/50176]	Loss: 0.1712
Training Epoch: 71 [33792/50176]	Loss: 0.1721
Training Epoch: 71 [34816/50176]	Loss: 0.1548
Training Epoch: 71 [35840/50176]	Loss: 0.1509
Training Epoch: 71 [36864/50176]	Loss: 0.1657
Training Epoch: 71 [37888/50176]	Loss: 0.1532
Training Epoch: 71 [38912/50176]	Loss: 0.1506
Training Epoch: 71 [39936/50176]	Loss: 0.1292
Training Epoch: 71 [40960/50176]	Loss: 0.1370
Training Epoch: 71 [41984/50176]	Loss: 0.1477
Training Epoch: 71 [43008/50176]	Loss: 0.1594
Training Epoch: 71 [44032/50176]	Loss: 0.1647
Training Epoch: 71 [45056/50176]	Loss: 0.1658
Training Epoch: 71 [46080/50176]	Loss: 0.1591
Training Epoch: 71 [47104/50176]	Loss: 0.1636
Training Epoch: 71 [48128/50176]	Loss: 0.1630
Training Epoch: 71 [49152/50176]	Loss: 0.1416
Training Epoch: 71 [50176/50176]	Loss: 0.1785
2022-12-06 18:08:16.750 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:08:16,793 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.77 energy=476.64
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Up to epoch 72: time=3531.28, energy=492442.73, cost=555208.25
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Expected next epoch: time=3578.55, energy=499226.68, cost=562736.70
2022-12-06 13:08:16,794 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0024, Accuracy: 0.5970
2022-12-06 13:08:17,010 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:08:17,011 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:08:17.012 [ZeusMonitor] Monitor started.
2022-12-06 18:08:17.013 [ZeusMonitor] Running indefinitely. 2022-12-06 18:08:17.013 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:08:17.013 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 13:09:00,993 [ZeusDataLoader(train)] train epoch 73 done: time=44.19 energy=6305.67
2022-12-06 13:09:00,996 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.1752
Training Epoch: 72 [2048/50176]	Loss: 0.1348
Training Epoch: 72 [3072/50176]	Loss: 0.1255
Training Epoch: 72 [4096/50176]	Loss: 0.1592
Training Epoch: 72 [5120/50176]	Loss: 0.1024
Training Epoch: 72 [6144/50176]	Loss: 0.1181
Training Epoch: 72 [7168/50176]	Loss: 0.1452
Training Epoch: 72 [8192/50176]	Loss: 0.1151
Training Epoch: 72 [9216/50176]	Loss: 0.1594
Training Epoch: 72 [10240/50176]	Loss: 0.1433
Training Epoch: 72 [11264/50176]	Loss: 0.1431
Training Epoch: 72 [12288/50176]	Loss: 0.1418
Training Epoch: 72 [13312/50176]	Loss: 0.1558
Training Epoch: 72 [14336/50176]	Loss: 0.1281
Training Epoch: 72 [15360/50176]	Loss: 0.1183
Training Epoch: 72 [16384/50176]	Loss: 0.1633
Training Epoch: 72 [17408/50176]	Loss: 0.1504
Training Epoch: 72 [18432/50176]	Loss: 0.1492
Training Epoch: 72 [19456/50176]	Loss: 0.1358
Training Epoch: 72 [20480/50176]	Loss: 0.1410
Training Epoch: 72 [21504/50176]	Loss: 0.1338
Training Epoch: 72 [22528/50176]	Loss: 0.1673
Training Epoch: 72 [23552/50176]	Loss: 0.1365
Training Epoch: 72 [24576/50176]	Loss: 0.1626
Training Epoch: 72 [25600/50176]	Loss: 0.1289
Training Epoch: 72 [26624/50176]	Loss: 0.1555
Training Epoch: 72 [27648/50176]	Loss: 0.1454
Training Epoch: 72 [28672/50176]	Loss: 0.1324
Training Epoch: 72 [29696/50176]	Loss: 0.1743
Training Epoch: 72 [30720/50176]	Loss: 0.1518
Training Epoch: 72 [31744/50176]	Loss: 0.1289
Training Epoch: 72 [32768/50176]	Loss: 0.1567
Training Epoch: 72 [33792/50176]	Loss: 0.1227
Training Epoch: 72 [34816/50176]	Loss: 0.1304
Training Epoch: 72 [35840/50176]	Loss: 0.1762
Training Epoch: 72 [36864/50176]	Loss: 0.1771
Training Epoch: 72 [37888/50176]	Loss: 0.1478
Training Epoch: 72 [38912/50176]	Loss: 0.1636
Training Epoch: 72 [39936/50176]	Loss: 0.1477
Training Epoch: 72 [40960/50176]	Loss: 0.1635
Training Epoch: 72 [41984/50176]	Loss: 0.1585
Training Epoch: 72 [43008/50176]	Loss: 0.1643
Training Epoch: 72 [44032/50176]	Loss: 0.1547
Training Epoch: 72 [45056/50176]	Loss: 0.1621
Training Epoch: 72 [46080/50176]	Loss: 0.1952
Training Epoch: 72 [47104/50176]	Loss: 0.1492
Training Epoch: 72 [48128/50176]	Loss: 0.1532
Training Epoch: 72 [49152/50176]	Loss: 0.1846
Training Epoch: 72 [50176/50176]	Loss: 0.1527
2022-12-06 18:09:04.711 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:09:04,733 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.73 energy=473.96
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Up to epoch 73: time=3579.20, energy=499222.37, cost=562791.05
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Expected next epoch: time=3626.47, energy=506006.32, cost=570319.50
2022-12-06 13:09:04,734 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0026, Accuracy: 0.5908
2022-12-06 13:09:04,897 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:09:04,897 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:09:04.901 [ZeusMonitor] Monitor started.
2022-12-06 18:09:04.901 [ZeusMonitor] Running indefinitely. 2022-12-06 18:09:04.901 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:09:04.901 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 13:09:49,210 [ZeusDataLoader(train)] train epoch 74 done: time=44.47 energy=6327.06
2022-12-06 13:09:49,213 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.1417
Training Epoch: 73 [2048/50176]	Loss: 0.1216
Training Epoch: 73 [3072/50176]	Loss: 0.1304
Training Epoch: 73 [4096/50176]	Loss: 0.1301
Training Epoch: 73 [5120/50176]	Loss: 0.1418
Training Epoch: 73 [6144/50176]	Loss: 0.1568
Training Epoch: 73 [7168/50176]	Loss: 0.1210
Training Epoch: 73 [8192/50176]	Loss: 0.1333
Training Epoch: 73 [9216/50176]	Loss: 0.1253
Training Epoch: 73 [10240/50176]	Loss: 0.1321
Training Epoch: 73 [11264/50176]	Loss: 0.1273
Training Epoch: 73 [12288/50176]	Loss: 0.1334
Training Epoch: 73 [13312/50176]	Loss: 0.1187
Training Epoch: 73 [14336/50176]	Loss: 0.1412
Training Epoch: 73 [15360/50176]	Loss: 0.1554
Training Epoch: 73 [16384/50176]	Loss: 0.1358
Training Epoch: 73 [17408/50176]	Loss: 0.1233
Training Epoch: 73 [18432/50176]	Loss: 0.1500
Training Epoch: 73 [19456/50176]	Loss: 0.1411
Training Epoch: 73 [20480/50176]	Loss: 0.1361
Training Epoch: 73 [21504/50176]	Loss: 0.1020
Training Epoch: 73 [22528/50176]	Loss: 0.1342
Training Epoch: 73 [23552/50176]	Loss: 0.1490
Training Epoch: 73 [24576/50176]	Loss: 0.1346
Training Epoch: 73 [25600/50176]	Loss: 0.1239
Training Epoch: 73 [26624/50176]	Loss: 0.1332
Training Epoch: 73 [27648/50176]	Loss: 0.1494
Training Epoch: 73 [28672/50176]	Loss: 0.1612
Training Epoch: 73 [29696/50176]	Loss: 0.1557
Training Epoch: 73 [30720/50176]	Loss: 0.1358
Training Epoch: 73 [31744/50176]	Loss: 0.1797
Training Epoch: 73 [32768/50176]	Loss: 0.1460
Training Epoch: 73 [33792/50176]	Loss: 0.1559
Training Epoch: 73 [34816/50176]	Loss: 0.1561
Training Epoch: 73 [35840/50176]	Loss: 0.1338
Training Epoch: 73 [36864/50176]	Loss: 0.1525
Training Epoch: 73 [37888/50176]	Loss: 0.1584
Training Epoch: 73 [38912/50176]	Loss: 0.1736
Training Epoch: 73 [39936/50176]	Loss: 0.1447
Training Epoch: 73 [40960/50176]	Loss: 0.1612
Training Epoch: 73 [41984/50176]	Loss: 0.1409
Training Epoch: 73 [43008/50176]	Loss: 0.1709
Training Epoch: 73 [44032/50176]	Loss: 0.1796
Training Epoch: 73 [45056/50176]	Loss: 0.1432
Training Epoch: 73 [46080/50176]	Loss: 0.1418
Training Epoch: 73 [47104/50176]	Loss: 0.1565
Training Epoch: 73 [48128/50176]	Loss: 0.1627
Training Epoch: 73 [49152/50176]	Loss: 0.1549
Training Epoch: 73 [50176/50176]	Loss: 0.1345
2022-12-06 18:09:52.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:09:53,009 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.79 energy=489.64
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Up to epoch 74: time=3627.45, energy=506039.07, cost=570421.82
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Expected next epoch: time=3674.73, energy=512823.02, cost=577950.27
2022-12-06 13:09:53,011 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0028, Accuracy: 0.5645
2022-12-06 13:09:53,177 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:09:53,178 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:09:53.181 [ZeusMonitor] Monitor started.
2022-12-06 18:09:53.181 [ZeusMonitor] Running indefinitely. 2022-12-06 18:09:53.181 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:09:53.181 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 13:10:37,742 [ZeusDataLoader(train)] train epoch 75 done: time=44.72 energy=6336.45
2022-12-06 13:10:37,747 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.1173
Training Epoch: 74 [2048/50176]	Loss: 0.1258
Training Epoch: 74 [3072/50176]	Loss: 0.1016
Training Epoch: 74 [4096/50176]	Loss: 0.1100
Training Epoch: 74 [5120/50176]	Loss: 0.1422
Training Epoch: 74 [6144/50176]	Loss: 0.1239
Training Epoch: 74 [7168/50176]	Loss: 0.0985
Training Epoch: 74 [8192/50176]	Loss: 0.1226
Training Epoch: 74 [9216/50176]	Loss: 0.1191
Training Epoch: 74 [10240/50176]	Loss: 0.1464
Training Epoch: 74 [11264/50176]	Loss: 0.1254
Training Epoch: 74 [12288/50176]	Loss: 0.1308
Training Epoch: 74 [13312/50176]	Loss: 0.1212
Training Epoch: 74 [14336/50176]	Loss: 0.1246
Training Epoch: 74 [15360/50176]	Loss: 0.1197
Training Epoch: 74 [16384/50176]	Loss: 0.1188
Training Epoch: 74 [17408/50176]	Loss: 0.1042
Training Epoch: 74 [18432/50176]	Loss: 0.1309
Training Epoch: 74 [19456/50176]	Loss: 0.1186
Training Epoch: 74 [20480/50176]	Loss: 0.1353
Training Epoch: 74 [21504/50176]	Loss: 0.1102
Training Epoch: 74 [22528/50176]	Loss: 0.1107
Training Epoch: 74 [23552/50176]	Loss: 0.1586
Training Epoch: 74 [24576/50176]	Loss: 0.1423
Training Epoch: 74 [25600/50176]	Loss: 0.1233
Training Epoch: 74 [26624/50176]	Loss: 0.1161
Training Epoch: 74 [27648/50176]	Loss: 0.1443
Training Epoch: 74 [28672/50176]	Loss: 0.1271
Training Epoch: 74 [29696/50176]	Loss: 0.1257
Training Epoch: 74 [30720/50176]	Loss: 0.1693
Training Epoch: 74 [31744/50176]	Loss: 0.1629
Training Epoch: 74 [32768/50176]	Loss: 0.1643
Training Epoch: 74 [33792/50176]	Loss: 0.1646
Training Epoch: 74 [34816/50176]	Loss: 0.1494
Training Epoch: 74 [35840/50176]	Loss: 0.1256
Training Epoch: 74 [36864/50176]	Loss: 0.1341
Training Epoch: 74 [37888/50176]	Loss: 0.1449
Training Epoch: 74 [38912/50176]	Loss: 0.1549
Training Epoch: 74 [39936/50176]	Loss: 0.1626
Training Epoch: 74 [40960/50176]	Loss: 0.1582
Training Epoch: 74 [41984/50176]	Loss: 0.1389
Training Epoch: 74 [43008/50176]	Loss: 0.1470
Training Epoch: 74 [44032/50176]	Loss: 0.1483
Training Epoch: 74 [45056/50176]	Loss: 0.1356
Training Epoch: 74 [46080/50176]	Loss: 0.1464
Training Epoch: 74 [47104/50176]	Loss: 0.1551
Training Epoch: 74 [48128/50176]	Loss: 0.1258
Training Epoch: 74 [49152/50176]	Loss: 0.1250
Training Epoch: 74 [50176/50176]	Loss: 0.1723
2022-12-06 18:10:41.517 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:10:41,550 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.80 energy=489.21
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Up to epoch 75: time=3675.97, energy=512864.73, cost=578080.10
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Training done.
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec01+try01+bs1024+lr0.0100000.train.json: {"energy": 512864.726165234, "time": 3675.9740900210018, "cost": 578080.0959594547, "num_epochs": 75, "reached": true}
Validation Epoch: 74, Average loss: 0.0025, Accuracy: 0.6062
