2022-12-06 11:40:08,783 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 11:40:08,783 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 11:40:08,783 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 11:40:08,826 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 11:40:08,826 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 11:40:11,512 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 11:40:11,513 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 11:40:11,698 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:40:11.714 [ZeusMonitor] Monitor started.
2022-12-06 16:40:11.714 [ZeusMonitor] Running indefinitely. 2022-12-06 16:40:11.714 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:40:11.714 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 11:40:12,401 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 11:40:12,401 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 11:40:21,418 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 11:40:54,691 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 11:40:56,433 [ZeusDataLoader(train)] train epoch 1 done: time=44.91 energy=6238.72
2022-12-06 11:40:56,436 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 5.5343
Training Epoch: 0 [3072/50176]	Loss: 5.0683
Training Epoch: 0 [4096/50176]	Loss: 4.7607
Training Epoch: 0 [5120/50176]	Loss: 4.6681
Training Epoch: 0 [6144/50176]	Loss: 4.6611
Training Epoch: 0 [7168/50176]	Loss: 4.6457
Training Epoch: 0 [8192/50176]	Loss: 4.6605
Training Epoch: 0 [9216/50176]	Loss: 4.6269
Training Epoch: 0 [10240/50176]	Loss: 4.5660
Training Epoch: 0 [11264/50176]	Loss: 4.5799
Training Epoch: 0 [12288/50176]	Loss: 4.5745
Training Epoch: 0 [13312/50176]	Loss: 4.5268
Training Epoch: 0 [14336/50176]	Loss: 4.4826
Training Epoch: 0 [15360/50176]	Loss: 4.4759
Training Epoch: 0 [16384/50176]	Loss: 4.5123
Training Epoch: 0 [17408/50176]	Loss: 4.4495
Training Epoch: 0 [18432/50176]	Loss: 4.4586
Training Epoch: 0 [19456/50176]	Loss: 4.4567
Training Epoch: 0 [20480/50176]	Loss: 4.4203
Training Epoch: 0 [21504/50176]	Loss: 4.3561
Training Epoch: 0 [22528/50176]	Loss: 4.3618
Training Epoch: 0 [23552/50176]	Loss: 4.3975
Training Epoch: 0 [24576/50176]	Loss: 4.3250
Training Epoch: 0 [25600/50176]	Loss: 4.3468
Training Epoch: 0 [26624/50176]	Loss: 4.3073
Training Epoch: 0 [27648/50176]	Loss: 4.2892
Training Epoch: 0 [28672/50176]	Loss: 4.2260
Training Epoch: 0 [29696/50176]	Loss: 4.2464
Training Epoch: 0 [30720/50176]	Loss: 4.2757
Training Epoch: 0 [31744/50176]	Loss: 4.2487
Training Epoch: 0 [32768/50176]	Loss: 4.2071
Training Epoch: 0 [33792/50176]	Loss: 4.2670
Training Epoch: 0 [34816/50176]	Loss: 4.1602
Training Epoch: 0 [35840/50176]	Loss: 4.1071
Training Epoch: 0 [36864/50176]	Loss: 4.1265
Training Epoch: 0 [37888/50176]	Loss: 4.1387
Training Epoch: 0 [38912/50176]	Loss: 4.0729
Training Epoch: 0 [39936/50176]	Loss: 4.1678
Training Epoch: 0 [40960/50176]	Loss: 4.0497
Training Epoch: 0 [41984/50176]	Loss: 4.0856
Training Epoch: 0 [43008/50176]	Loss: 4.1665
Training Epoch: 0 [44032/50176]	Loss: 4.0349
Training Epoch: 0 [45056/50176]	Loss: 4.0645
Training Epoch: 0 [46080/50176]	Loss: 4.0508
Training Epoch: 0 [47104/50176]	Loss: 4.0334
Training Epoch: 0 [48128/50176]	Loss: 4.0365
Training Epoch: 0 [49152/50176]	Loss: 4.0259
Training Epoch: 0 [50176/50176]	Loss: 3.9686
2022-12-06 16:41:00.131 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:41:00,186 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.74 energy=467.15
2022-12-06 11:41:00,186 [ZeusDataLoader(train)] Up to epoch 1: time=48.65, energy=6705.86, cost=7610.23
2022-12-06 11:41:00,187 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0041, Accuracy: 0.0505
2022-12-06 11:41:00,388 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:41:00.390 [ZeusMonitor] Monitor started.
2022-12-06 16:41:00.390 [ZeusMonitor] Running indefinitely. 2022-12-06 16:41:00.390 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:41:00.391 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 11:41:01,054 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 11:41:01,054 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 11:41:09,109 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 11:41:43,105 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 11:41:44,763 [ZeusDataLoader(train)] train epoch 2 done: time=44.57 energy=6240.51
2022-12-06 11:41:44,766 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 3.9852
Training Epoch: 1 [2048/50176]	Loss: 3.9422
Training Epoch: 1 [3072/50176]	Loss: 3.9606
Training Epoch: 1 [4096/50176]	Loss: 3.9125
Training Epoch: 1 [5120/50176]	Loss: 3.8919
Training Epoch: 1 [6144/50176]	Loss: 3.9170
Training Epoch: 1 [7168/50176]	Loss: 3.8252
Training Epoch: 1 [8192/50176]	Loss: 3.8158
Training Epoch: 1 [9216/50176]	Loss: 3.9104
Training Epoch: 1 [10240/50176]	Loss: 3.8336
Training Epoch: 1 [11264/50176]	Loss: 3.9169
Training Epoch: 1 [12288/50176]	Loss: 3.8325
Training Epoch: 1 [13312/50176]	Loss: 3.8377
Training Epoch: 1 [14336/50176]	Loss: 3.8871
Training Epoch: 1 [15360/50176]	Loss: 3.8391
Training Epoch: 1 [16384/50176]	Loss: 3.8555
Training Epoch: 1 [17408/50176]	Loss: 3.8231
Training Epoch: 1 [18432/50176]	Loss: 3.7156
Training Epoch: 1 [19456/50176]	Loss: 3.8153
Training Epoch: 1 [20480/50176]	Loss: 3.7289
Training Epoch: 1 [21504/50176]	Loss: 3.7548
Training Epoch: 1 [22528/50176]	Loss: 3.6835
Training Epoch: 1 [23552/50176]	Loss: 3.7174
Training Epoch: 1 [24576/50176]	Loss: 3.6840
Training Epoch: 1 [25600/50176]	Loss: 3.6680
Training Epoch: 1 [26624/50176]	Loss: 3.7296
Training Epoch: 1 [27648/50176]	Loss: 3.6589
Training Epoch: 1 [28672/50176]	Loss: 3.6096
Training Epoch: 1 [29696/50176]	Loss: 3.7284
Training Epoch: 1 [30720/50176]	Loss: 3.6632
Training Epoch: 1 [31744/50176]	Loss: 3.6665
Training Epoch: 1 [32768/50176]	Loss: 3.6077
Training Epoch: 1 [33792/50176]	Loss: 3.7060
Training Epoch: 1 [34816/50176]	Loss: 3.6662
Training Epoch: 1 [35840/50176]	Loss: 3.7077
Training Epoch: 1 [36864/50176]	Loss: 3.6304
Training Epoch: 1 [37888/50176]	Loss: 3.6209
Training Epoch: 1 [38912/50176]	Loss: 3.6299
Training Epoch: 1 [39936/50176]	Loss: 3.6078
Training Epoch: 1 [40960/50176]	Loss: 3.6384
Training Epoch: 1 [41984/50176]	Loss: 3.5418
Training Epoch: 1 [43008/50176]	Loss: 3.6161
Training Epoch: 1 [44032/50176]	Loss: 3.5741
Training Epoch: 1 [45056/50176]	Loss: 3.5546
Training Epoch: 1 [46080/50176]	Loss: 3.5655
Training Epoch: 1 [47104/50176]	Loss: 3.5853
Training Epoch: 1 [48128/50176]	Loss: 3.5694
Training Epoch: 1 [49152/50176]	Loss: 3.5943
Training Epoch: 1 [50176/50176]	Loss: 3.5030
2022-12-06 16:41:48.519 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:41:48,553 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.78 energy=487.72
2022-12-06 11:41:48,553 [ZeusDataLoader(train)] Up to epoch 2: time=97.00, energy=13434.09, cost=15204.83
2022-12-06 11:41:48,554 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0037, Accuracy: 0.1223
2022-12-06 11:41:48,764 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:41:48.766 [ZeusMonitor] Monitor started.
2022-12-06 16:41:48.767 [ZeusMonitor] Running indefinitely. 2022-12-06 16:41:48.767 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:41:48.767 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 11:41:49,459 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 11:41:49,459 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 11:41:58,206 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 11:42:34,716 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 11:42:36,513 [ZeusDataLoader(train)] train epoch 3 done: time=47.95 energy=5772.90
2022-12-06 11:42:36,516 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.4925
Training Epoch: 2 [2048/50176]	Loss: 3.5421
Training Epoch: 2 [3072/50176]	Loss: 3.4328
Training Epoch: 2 [4096/50176]	Loss: 3.4549
Training Epoch: 2 [5120/50176]	Loss: 3.4348
Training Epoch: 2 [6144/50176]	Loss: 3.4339
Training Epoch: 2 [7168/50176]	Loss: 3.4920
Training Epoch: 2 [8192/50176]	Loss: 3.5211
Training Epoch: 2 [9216/50176]	Loss: 3.4571
Training Epoch: 2 [10240/50176]	Loss: 3.3872
Training Epoch: 2 [11264/50176]	Loss: 3.3290
Training Epoch: 2 [12288/50176]	Loss: 3.4471
Training Epoch: 2 [13312/50176]	Loss: 3.3901
Training Epoch: 2 [14336/50176]	Loss: 3.4797
Training Epoch: 2 [15360/50176]	Loss: 3.4467
Training Epoch: 2 [16384/50176]	Loss: 3.4825
Training Epoch: 2 [17408/50176]	Loss: 3.4802
Training Epoch: 2 [18432/50176]	Loss: 3.4636
Training Epoch: 2 [19456/50176]	Loss: 3.4263
Training Epoch: 2 [20480/50176]	Loss: 3.3974
Training Epoch: 2 [21504/50176]	Loss: 3.4837
Training Epoch: 2 [22528/50176]	Loss: 3.4374
Training Epoch: 2 [23552/50176]	Loss: 3.4019
Training Epoch: 2 [24576/50176]	Loss: 3.4825
Training Epoch: 2 [25600/50176]	Loss: 3.4096
Training Epoch: 2 [26624/50176]	Loss: 3.4357
Training Epoch: 2 [27648/50176]	Loss: 3.4491
Training Epoch: 2 [28672/50176]	Loss: 3.4449
Training Epoch: 2 [29696/50176]	Loss: 3.3406
Training Epoch: 2 [30720/50176]	Loss: 3.3509
Training Epoch: 2 [31744/50176]	Loss: 3.3338
Training Epoch: 2 [32768/50176]	Loss: 3.3497
Training Epoch: 2 [33792/50176]	Loss: 3.3892
Training Epoch: 2 [34816/50176]	Loss: 3.3774
Training Epoch: 2 [35840/50176]	Loss: 3.2817
Training Epoch: 2 [36864/50176]	Loss: 3.3599
Training Epoch: 2 [37888/50176]	Loss: 3.3667
Training Epoch: 2 [38912/50176]	Loss: 3.3198
Training Epoch: 2 [39936/50176]	Loss: 3.2880
Training Epoch: 2 [40960/50176]	Loss: 3.3076
Training Epoch: 2 [41984/50176]	Loss: 3.2939
Training Epoch: 2 [43008/50176]	Loss: 3.3045
Training Epoch: 2 [44032/50176]	Loss: 3.2181
Training Epoch: 2 [45056/50176]	Loss: 3.2708
Training Epoch: 2 [46080/50176]	Loss: 3.2594
Training Epoch: 2 [47104/50176]	Loss: 3.2161
Training Epoch: 2 [48128/50176]	Loss: 3.2479
Training Epoch: 2 [49152/50176]	Loss: 3.2443
Training Epoch: 2 [50176/50176]	Loss: 3.1993
2022-12-06 16:42:40.593 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:42:40,644 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.11 energy=463.20
2022-12-06 11:42:40,648 [ZeusDataLoader(train)] Up to epoch 3: time=149.06, energy=19670.19, cost=22878.04
2022-12-06 11:42:40,649 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0033, Accuracy: 0.1899
2022-12-06 11:42:41,098 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:42:41.109 [ZeusMonitor] Monitor started.
2022-12-06 16:42:41.109 [ZeusMonitor] Running indefinitely. 2022-12-06 16:42:41.109 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:42:41.109 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 11:42:41,936 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 11:42:41,936 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 11:42:58,577 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-06 11:44:08,615 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 11:44:10,431 [ZeusDataLoader(train)] train epoch 4 done: time=89.77 energy=8598.48
2022-12-06 11:44:10,435 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.1635
Training Epoch: 3 [2048/50176]	Loss: 3.1339
Training Epoch: 3 [3072/50176]	Loss: 3.1659
Training Epoch: 3 [4096/50176]	Loss: 3.2216
Training Epoch: 3 [5120/50176]	Loss: 3.1559
Training Epoch: 3 [6144/50176]	Loss: 3.1971
Training Epoch: 3 [7168/50176]	Loss: 3.1841
Training Epoch: 3 [8192/50176]	Loss: 3.1995
Training Epoch: 3 [9216/50176]	Loss: 3.0996
Training Epoch: 3 [10240/50176]	Loss: 3.1574
Training Epoch: 3 [11264/50176]	Loss: 3.2253
Training Epoch: 3 [12288/50176]	Loss: 3.1679
Training Epoch: 3 [13312/50176]	Loss: 3.2145
Training Epoch: 3 [14336/50176]	Loss: 3.1009
Training Epoch: 3 [15360/50176]	Loss: 3.1137
Training Epoch: 3 [16384/50176]	Loss: 3.1087
Training Epoch: 3 [17408/50176]	Loss: 3.0932
Training Epoch: 3 [18432/50176]	Loss: 3.1418
Training Epoch: 3 [19456/50176]	Loss: 3.0653
Training Epoch: 3 [20480/50176]	Loss: 3.1112
Training Epoch: 3 [21504/50176]	Loss: 3.1216
Training Epoch: 3 [22528/50176]	Loss: 3.0740
Training Epoch: 3 [23552/50176]	Loss: 3.0686
Training Epoch: 3 [24576/50176]	Loss: 3.0654
Training Epoch: 3 [25600/50176]	Loss: 2.9397
Training Epoch: 3 [26624/50176]	Loss: 3.1387
Training Epoch: 3 [27648/50176]	Loss: 3.1292
Training Epoch: 3 [28672/50176]	Loss: 3.0384
Training Epoch: 3 [29696/50176]	Loss: 3.0652
Training Epoch: 3 [30720/50176]	Loss: 3.0245
Training Epoch: 3 [31744/50176]	Loss: 3.0432
Training Epoch: 3 [32768/50176]	Loss: 2.9858
Training Epoch: 3 [33792/50176]	Loss: 2.9091
Training Epoch: 3 [34816/50176]	Loss: 3.0848
Training Epoch: 3 [35840/50176]	Loss: 2.9487
Training Epoch: 3 [36864/50176]	Loss: 3.0022
Training Epoch: 3 [37888/50176]	Loss: 3.0321
Training Epoch: 3 [38912/50176]	Loss: 3.0885
Training Epoch: 3 [39936/50176]	Loss: 3.0297
Training Epoch: 3 [40960/50176]	Loss: 2.8721
Training Epoch: 3 [41984/50176]	Loss: 3.0220
Training Epoch: 3 [43008/50176]	Loss: 2.8403
Training Epoch: 3 [44032/50176]	Loss: 2.9736
Training Epoch: 3 [45056/50176]	Loss: 2.9257
Training Epoch: 3 [46080/50176]	Loss: 2.9519
Training Epoch: 3 [47104/50176]	Loss: 2.8454
Training Epoch: 3 [48128/50176]	Loss: 3.0942
Training Epoch: 3 [49152/50176]	Loss: 2.9600
Training Epoch: 3 [50176/50176]	Loss: 2.8934
2022-12-06 16:44:14.265 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0050000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 144.6526908887388, "150000": 142.9144590501422, "125000": 122.3746729763121, "100000": 96.26969013202073}, "train_throughput": {"175000": 1.1426061331830712, "150000": 1.1181391463369061, "125000": 1.0411058844569772, "100000": 0.5428501950648409}, "eval_power": {"175000": 122.91663523083511, "150000": 129.06686853531815, "125000": 112.79114027828794}, "eval_throughput": {"175000": 2.6032730606481405, "150000": 2.6463149332718254, "125000": 2.435059632683371}, "optimal_pl": 175000}
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.84 energy=472.16
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Up to epoch 4: time=242.68, energy=28740.83, cost=35604.63
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Expected next epoch: time=289.40, energy=35416.34, cost=43030.88
2022-12-06 11:44:14,288 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0029, Accuracy: 0.2505
2022-12-06 11:44:14,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:44:14,502 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:44:14.504 [ZeusMonitor] Monitor started.
2022-12-06 16:44:14.504 [ZeusMonitor] Running indefinitely. 2022-12-06 16:44:14.504 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:44:14.504 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 11:44:58,679 [ZeusDataLoader(train)] train epoch 5 done: time=44.38 energy=6272.47
2022-12-06 11:44:58,682 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 2.9563
Training Epoch: 4 [2048/50176]	Loss: 2.8645
Training Epoch: 4 [3072/50176]	Loss: 2.7914
Training Epoch: 4 [4096/50176]	Loss: 2.8467
Training Epoch: 4 [5120/50176]	Loss: 2.8062
Training Epoch: 4 [6144/50176]	Loss: 2.8976
Training Epoch: 4 [7168/50176]	Loss: 2.8345
Training Epoch: 4 [8192/50176]	Loss: 2.8761
Training Epoch: 4 [9216/50176]	Loss: 2.8755
Training Epoch: 4 [10240/50176]	Loss: 2.8379
Training Epoch: 4 [11264/50176]	Loss: 2.8331
Training Epoch: 4 [12288/50176]	Loss: 2.8272
Training Epoch: 4 [13312/50176]	Loss: 2.8075
Training Epoch: 4 [14336/50176]	Loss: 2.9049
Training Epoch: 4 [15360/50176]	Loss: 2.8613
Training Epoch: 4 [16384/50176]	Loss: 2.7548
Training Epoch: 4 [17408/50176]	Loss: 2.8338
Training Epoch: 4 [18432/50176]	Loss: 2.8447
Training Epoch: 4 [19456/50176]	Loss: 2.8649
Training Epoch: 4 [20480/50176]	Loss: 2.8132
Training Epoch: 4 [21504/50176]	Loss: 2.8629
Training Epoch: 4 [22528/50176]	Loss: 2.7166
Training Epoch: 4 [23552/50176]	Loss: 2.7309
Training Epoch: 4 [24576/50176]	Loss: 2.7419
Training Epoch: 4 [25600/50176]	Loss: 2.7595
Training Epoch: 4 [26624/50176]	Loss: 2.6967
Training Epoch: 4 [27648/50176]	Loss: 2.7835
Training Epoch: 4 [28672/50176]	Loss: 2.7091
Training Epoch: 4 [29696/50176]	Loss: 2.8265
Training Epoch: 4 [30720/50176]	Loss: 2.7993
Training Epoch: 4 [31744/50176]	Loss: 2.7171
Training Epoch: 4 [32768/50176]	Loss: 2.7843
Training Epoch: 4 [33792/50176]	Loss: 2.7740
Training Epoch: 4 [34816/50176]	Loss: 2.6621
Training Epoch: 4 [35840/50176]	Loss: 2.7555
Training Epoch: 4 [36864/50176]	Loss: 2.7142
Training Epoch: 4 [37888/50176]	Loss: 2.9461
Training Epoch: 4 [38912/50176]	Loss: 2.7422
Training Epoch: 4 [39936/50176]	Loss: 2.6894
Training Epoch: 4 [40960/50176]	Loss: 2.6750
Training Epoch: 4 [41984/50176]	Loss: 2.5978
Training Epoch: 4 [43008/50176]	Loss: 2.7106
Training Epoch: 4 [44032/50176]	Loss: 2.6261
Training Epoch: 4 [45056/50176]	Loss: 2.6492
Training Epoch: 4 [46080/50176]	Loss: 2.8002
Training Epoch: 4 [47104/50176]	Loss: 2.7616
Training Epoch: 4 [48128/50176]	Loss: 2.7518
Training Epoch: 4 [49152/50176]	Loss: 2.7479
Training Epoch: 4 [50176/50176]	Loss: 2.8066
2022-12-06 16:45:02.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:45:02,374 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.68 energy=473.64
2022-12-06 11:45:02,374 [ZeusDataLoader(train)] Up to epoch 5: time=290.74, energy=35486.94, cost=43183.57
2022-12-06 11:45:02,375 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:45:02,375 [ZeusDataLoader(train)] Expected next epoch: time=337.47, energy=42162.45, cost=50609.83
2022-12-06 11:45:02,376 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0027, Accuracy: 0.2879
2022-12-06 11:45:02,567 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:45:02,568 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:45:02.580 [ZeusMonitor] Monitor started.
2022-12-06 16:45:02.580 [ZeusMonitor] Running indefinitely. 2022-12-06 16:45:02.580 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:45:02.580 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 11:45:47,067 [ZeusDataLoader(train)] train epoch 6 done: time=44.68 energy=6332.24
2022-12-06 11:45:47,071 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.5677
Training Epoch: 5 [2048/50176]	Loss: 2.6005
Training Epoch: 5 [3072/50176]	Loss: 2.7070
Training Epoch: 5 [4096/50176]	Loss: 2.5873
Training Epoch: 5 [5120/50176]	Loss: 2.5484
Training Epoch: 5 [6144/50176]	Loss: 2.6412
Training Epoch: 5 [7168/50176]	Loss: 2.5366
Training Epoch: 5 [8192/50176]	Loss: 2.5814
Training Epoch: 5 [9216/50176]	Loss: 2.5396
Training Epoch: 5 [10240/50176]	Loss: 2.6339
Training Epoch: 5 [11264/50176]	Loss: 2.6634
Training Epoch: 5 [12288/50176]	Loss: 2.4816
Training Epoch: 5 [13312/50176]	Loss: 2.6559
Training Epoch: 5 [14336/50176]	Loss: 2.5837
Training Epoch: 5 [15360/50176]	Loss: 2.6468
Training Epoch: 5 [16384/50176]	Loss: 2.5686
Training Epoch: 5 [17408/50176]	Loss: 2.6002
Training Epoch: 5 [18432/50176]	Loss: 2.5054
Training Epoch: 5 [19456/50176]	Loss: 2.6110
Training Epoch: 5 [20480/50176]	Loss: 2.6170
Training Epoch: 5 [21504/50176]	Loss: 2.5320
Training Epoch: 5 [22528/50176]	Loss: 2.5869
Training Epoch: 5 [23552/50176]	Loss: 2.5656
Training Epoch: 5 [24576/50176]	Loss: 2.5869
Training Epoch: 5 [25600/50176]	Loss: 2.5462
Training Epoch: 5 [26624/50176]	Loss: 2.5166
Training Epoch: 5 [27648/50176]	Loss: 2.4939
Training Epoch: 5 [28672/50176]	Loss: 2.5762
Training Epoch: 5 [29696/50176]	Loss: 2.5581
Training Epoch: 5 [30720/50176]	Loss: 2.5231
Training Epoch: 5 [31744/50176]	Loss: 2.5526
Training Epoch: 5 [32768/50176]	Loss: 2.5186
Training Epoch: 5 [33792/50176]	Loss: 2.5165
Training Epoch: 5 [34816/50176]	Loss: 2.5421
Training Epoch: 5 [35840/50176]	Loss: 2.5978
Training Epoch: 5 [36864/50176]	Loss: 2.4338
Training Epoch: 5 [37888/50176]	Loss: 2.4625
Training Epoch: 5 [38912/50176]	Loss: 2.5189
Training Epoch: 5 [39936/50176]	Loss: 2.5471
Training Epoch: 5 [40960/50176]	Loss: 2.3983
Training Epoch: 5 [41984/50176]	Loss: 2.5359
Training Epoch: 5 [43008/50176]	Loss: 2.5070
Training Epoch: 5 [44032/50176]	Loss: 2.4775
Training Epoch: 5 [45056/50176]	Loss: 2.6054
Training Epoch: 5 [46080/50176]	Loss: 2.3548
Training Epoch: 5 [47104/50176]	Loss: 2.4918
Training Epoch: 5 [48128/50176]	Loss: 2.5138
Training Epoch: 5 [49152/50176]	Loss: 2.5466
Training Epoch: 5 [50176/50176]	Loss: 2.4548
2022-12-06 16:45:50.892 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:45:50,911 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.83 energy=480.81
2022-12-06 11:45:50,911 [ZeusDataLoader(train)] Up to epoch 6: time=339.26, energy=42299.99, cost=50835.29
2022-12-06 11:45:50,912 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:45:50,912 [ZeusDataLoader(train)] Expected next epoch: time=385.99, energy=48975.50, cost=58261.55
2022-12-06 11:45:50,913 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0024, Accuracy: 0.3559
2022-12-06 11:45:51,102 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:45:51,103 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:45:51.117 [ZeusMonitor] Monitor started.
2022-12-06 16:45:51.117 [ZeusMonitor] Running indefinitely. 2022-12-06 16:45:51.117 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:45:51.117 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 11:46:35,688 [ZeusDataLoader(train)] train epoch 7 done: time=44.77 energy=6358.26
2022-12-06 11:46:35,691 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.3357
Training Epoch: 6 [2048/50176]	Loss: 2.3671
Training Epoch: 6 [3072/50176]	Loss: 2.4505
Training Epoch: 6 [4096/50176]	Loss: 2.3816
Training Epoch: 6 [5120/50176]	Loss: 2.3584
Training Epoch: 6 [6144/50176]	Loss: 2.3823
Training Epoch: 6 [7168/50176]	Loss: 2.4110
Training Epoch: 6 [8192/50176]	Loss: 2.3418
Training Epoch: 6 [9216/50176]	Loss: 2.4598
Training Epoch: 6 [10240/50176]	Loss: 2.4201
Training Epoch: 6 [11264/50176]	Loss: 2.3429
Training Epoch: 6 [12288/50176]	Loss: 2.4180
Training Epoch: 6 [13312/50176]	Loss: 2.3562
Training Epoch: 6 [14336/50176]	Loss: 2.3558
Training Epoch: 6 [15360/50176]	Loss: 2.2759
Training Epoch: 6 [16384/50176]	Loss: 2.4105
Training Epoch: 6 [17408/50176]	Loss: 2.3137
Training Epoch: 6 [18432/50176]	Loss: 2.3756
Training Epoch: 6 [19456/50176]	Loss: 2.3177
Training Epoch: 6 [20480/50176]	Loss: 2.4270
Training Epoch: 6 [21504/50176]	Loss: 2.4025
Training Epoch: 6 [22528/50176]	Loss: 2.3718
Training Epoch: 6 [23552/50176]	Loss: 2.3543
Training Epoch: 6 [24576/50176]	Loss: 2.3550
Training Epoch: 6 [25600/50176]	Loss: 2.2180
Training Epoch: 6 [26624/50176]	Loss: 2.3741
Training Epoch: 6 [27648/50176]	Loss: 2.2760
Training Epoch: 6 [28672/50176]	Loss: 2.2029
Training Epoch: 6 [29696/50176]	Loss: 2.2882
Training Epoch: 6 [30720/50176]	Loss: 2.3100
Training Epoch: 6 [31744/50176]	Loss: 2.2855
Training Epoch: 6 [32768/50176]	Loss: 2.3051
Training Epoch: 6 [33792/50176]	Loss: 2.3301
Training Epoch: 6 [34816/50176]	Loss: 2.3659
Training Epoch: 6 [35840/50176]	Loss: 2.3249
Training Epoch: 6 [36864/50176]	Loss: 2.4451
Training Epoch: 6 [37888/50176]	Loss: 2.3794
Training Epoch: 6 [38912/50176]	Loss: 2.3747
Training Epoch: 6 [39936/50176]	Loss: 2.3546
Training Epoch: 6 [40960/50176]	Loss: 2.3183
Training Epoch: 6 [41984/50176]	Loss: 2.3316
Training Epoch: 6 [43008/50176]	Loss: 2.2957
Training Epoch: 6 [44032/50176]	Loss: 2.2782
Training Epoch: 6 [45056/50176]	Loss: 2.3056
Training Epoch: 6 [46080/50176]	Loss: 2.3478
Training Epoch: 6 [47104/50176]	Loss: 2.2943
Training Epoch: 6 [48128/50176]	Loss: 2.2935
Training Epoch: 6 [49152/50176]	Loss: 2.2404
Training Epoch: 6 [50176/50176]	Loss: 2.2620
2022-12-06 16:46:39.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:46:39,391 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.69 energy=480.48
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Up to epoch 7: time=387.72, energy=49138.73, cost=58494.85
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Expected next epoch: time=434.45, energy=55814.24, cost=65921.11
2022-12-06 11:46:39,392 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0023, Accuracy: 0.3716
2022-12-06 11:46:39,569 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:46:39,569 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:46:39.583 [ZeusMonitor] Monitor started.
2022-12-06 16:46:39.584 [ZeusMonitor] Running indefinitely. 2022-12-06 16:46:39.584 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:46:39.584 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 11:47:23,706 [ZeusDataLoader(train)] train epoch 8 done: time=44.31 energy=6323.50
2022-12-06 11:47:23,709 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.2447
Training Epoch: 7 [2048/50176]	Loss: 2.1501
Training Epoch: 7 [3072/50176]	Loss: 2.1443
Training Epoch: 7 [4096/50176]	Loss: 2.1689
Training Epoch: 7 [5120/50176]	Loss: 2.1987
Training Epoch: 7 [6144/50176]	Loss: 2.1249
Training Epoch: 7 [7168/50176]	Loss: 2.2078
Training Epoch: 7 [8192/50176]	Loss: 2.1730
Training Epoch: 7 [9216/50176]	Loss: 2.0388
Training Epoch: 7 [10240/50176]	Loss: 2.1536
Training Epoch: 7 [11264/50176]	Loss: 2.1076
Training Epoch: 7 [12288/50176]	Loss: 2.1612
Training Epoch: 7 [13312/50176]	Loss: 2.1903
Training Epoch: 7 [14336/50176]	Loss: 2.3065
Training Epoch: 7 [15360/50176]	Loss: 2.1935
Training Epoch: 7 [16384/50176]	Loss: 2.1547
Training Epoch: 7 [17408/50176]	Loss: 2.2089
Training Epoch: 7 [18432/50176]	Loss: 2.1230
Training Epoch: 7 [19456/50176]	Loss: 2.1660
Training Epoch: 7 [20480/50176]	Loss: 2.2164
Training Epoch: 7 [21504/50176]	Loss: 2.2410
Training Epoch: 7 [22528/50176]	Loss: 2.1716
Training Epoch: 7 [23552/50176]	Loss: 2.1699
Training Epoch: 7 [24576/50176]	Loss: 2.1307
Training Epoch: 7 [25600/50176]	Loss: 2.1717
Training Epoch: 7 [26624/50176]	Loss: 2.1883
Training Epoch: 7 [27648/50176]	Loss: 2.2179
Training Epoch: 7 [28672/50176]	Loss: 2.0747
Training Epoch: 7 [29696/50176]	Loss: 2.1419
Training Epoch: 7 [30720/50176]	Loss: 2.1444
Training Epoch: 7 [31744/50176]	Loss: 2.1775
Training Epoch: 7 [32768/50176]	Loss: 2.0547
Training Epoch: 7 [33792/50176]	Loss: 2.1481
Training Epoch: 7 [34816/50176]	Loss: 2.1691
Training Epoch: 7 [35840/50176]	Loss: 2.0901
Training Epoch: 7 [36864/50176]	Loss: 2.0101
Training Epoch: 7 [37888/50176]	Loss: 2.0831
Training Epoch: 7 [38912/50176]	Loss: 2.1746
Training Epoch: 7 [39936/50176]	Loss: 2.1936
Training Epoch: 7 [40960/50176]	Loss: 2.1621
Training Epoch: 7 [41984/50176]	Loss: 2.0431
Training Epoch: 7 [43008/50176]	Loss: 2.0515
Training Epoch: 7 [44032/50176]	Loss: 2.1115
Training Epoch: 7 [45056/50176]	Loss: 2.1368
Training Epoch: 7 [46080/50176]	Loss: 2.1878
Training Epoch: 7 [47104/50176]	Loss: 2.0753
Training Epoch: 7 [48128/50176]	Loss: 2.0887
Training Epoch: 7 [49152/50176]	Loss: 2.1865
Training Epoch: 7 [50176/50176]	Loss: 2.0520
2022-12-06 16:47:27.442 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:47:27,480 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.76 energy=477.00
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Up to epoch 8: time=435.79, energy=55939.23, cost=66101.11
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Expected next epoch: time=482.51, energy=62614.74, cost=73527.37
2022-12-06 11:47:27,482 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0022, Accuracy: 0.4112
2022-12-06 11:47:27,673 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:47:27,674 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:47:27.688 [ZeusMonitor] Monitor started.
2022-12-06 16:47:27.688 [ZeusMonitor] Running indefinitely. 2022-12-06 16:47:27.688 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:47:27.688 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 11:48:12,492 [ZeusDataLoader(train)] train epoch 9 done: time=45.00 energy=6376.64
2022-12-06 11:48:12,495 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.1241
Training Epoch: 8 [2048/50176]	Loss: 2.0853
Training Epoch: 8 [3072/50176]	Loss: 2.0883
Training Epoch: 8 [4096/50176]	Loss: 2.0447
Training Epoch: 8 [5120/50176]	Loss: 1.9784
Training Epoch: 8 [6144/50176]	Loss: 2.0387
Training Epoch: 8 [7168/50176]	Loss: 2.0607
Training Epoch: 8 [8192/50176]	Loss: 2.0438
Training Epoch: 8 [9216/50176]	Loss: 1.9998
Training Epoch: 8 [10240/50176]	Loss: 2.0368
Training Epoch: 8 [11264/50176]	Loss: 2.0359
Training Epoch: 8 [12288/50176]	Loss: 2.0569
Training Epoch: 8 [13312/50176]	Loss: 2.0523
Training Epoch: 8 [14336/50176]	Loss: 2.0321
Training Epoch: 8 [15360/50176]	Loss: 2.1113
Training Epoch: 8 [16384/50176]	Loss: 2.0021
Training Epoch: 8 [17408/50176]	Loss: 2.1305
Training Epoch: 8 [18432/50176]	Loss: 2.0708
Training Epoch: 8 [19456/50176]	Loss: 1.9875
Training Epoch: 8 [20480/50176]	Loss: 2.0000
Training Epoch: 8 [21504/50176]	Loss: 1.9350
Training Epoch: 8 [22528/50176]	Loss: 2.0000
Training Epoch: 8 [23552/50176]	Loss: 2.0227
Training Epoch: 8 [24576/50176]	Loss: 2.0609
Training Epoch: 8 [25600/50176]	Loss: 2.0436
Training Epoch: 8 [26624/50176]	Loss: 2.0294
Training Epoch: 8 [27648/50176]	Loss: 1.9460
Training Epoch: 8 [28672/50176]	Loss: 2.0687
Training Epoch: 8 [29696/50176]	Loss: 2.0043
Training Epoch: 8 [30720/50176]	Loss: 2.0190
Training Epoch: 8 [31744/50176]	Loss: 1.9463
Training Epoch: 8 [32768/50176]	Loss: 1.9775
Training Epoch: 8 [33792/50176]	Loss: 2.1205
Training Epoch: 8 [34816/50176]	Loss: 2.0009
Training Epoch: 8 [35840/50176]	Loss: 2.0425
Training Epoch: 8 [36864/50176]	Loss: 2.0144
Training Epoch: 8 [37888/50176]	Loss: 2.0492
Training Epoch: 8 [38912/50176]	Loss: 1.9767
Training Epoch: 8 [39936/50176]	Loss: 2.1177
Training Epoch: 8 [40960/50176]	Loss: 2.0151
Training Epoch: 8 [41984/50176]	Loss: 2.0321
Training Epoch: 8 [43008/50176]	Loss: 1.9751
Training Epoch: 8 [44032/50176]	Loss: 2.0590
Training Epoch: 8 [45056/50176]	Loss: 2.0824
Training Epoch: 8 [46080/50176]	Loss: 1.9870
Training Epoch: 8 [47104/50176]	Loss: 2.0677
Training Epoch: 8 [48128/50176]	Loss: 1.9268
Training Epoch: 8 [49152/50176]	Loss: 2.0137
Training Epoch: 8 [50176/50176]	Loss: 1.9713
2022-12-06 16:48:16.360 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:48:16,370 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.87 energy=475.70
2022-12-06 11:48:16,370 [ZeusDataLoader(train)] Up to epoch 9: time=484.66, energy=62791.56, cost=73803.27
2022-12-06 11:48:16,371 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:48:16,371 [ZeusDataLoader(train)] Expected next epoch: time=531.38, energy=69467.07, cost=81229.52
2022-12-06 11:48:16,372 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0020, Accuracy: 0.4342
2022-12-06 11:48:16,566 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:48:16,566 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:48:16.568 [ZeusMonitor] Monitor started.
2022-12-06 16:48:16.568 [ZeusMonitor] Running indefinitely. 2022-12-06 16:48:16.568 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:48:16.568 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 11:49:01,888 [ZeusDataLoader(train)] train epoch 10 done: time=45.51 energy=6409.30
2022-12-06 11:49:01,891 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 1.9041
Training Epoch: 9 [2048/50176]	Loss: 1.9819
Training Epoch: 9 [3072/50176]	Loss: 1.9942
Training Epoch: 9 [4096/50176]	Loss: 1.8659
Training Epoch: 9 [5120/50176]	Loss: 2.0097
Training Epoch: 9 [6144/50176]	Loss: 1.8342
Training Epoch: 9 [7168/50176]	Loss: 1.9558
Training Epoch: 9 [8192/50176]	Loss: 1.9092
Training Epoch: 9 [9216/50176]	Loss: 1.9199
Training Epoch: 9 [10240/50176]	Loss: 1.8773
Training Epoch: 9 [11264/50176]	Loss: 1.9808
Training Epoch: 9 [12288/50176]	Loss: 1.9404
Training Epoch: 9 [13312/50176]	Loss: 1.8954
Training Epoch: 9 [14336/50176]	Loss: 1.9277
Training Epoch: 9 [15360/50176]	Loss: 1.9483
Training Epoch: 9 [16384/50176]	Loss: 1.9439
Training Epoch: 9 [17408/50176]	Loss: 1.9100
Training Epoch: 9 [18432/50176]	Loss: 1.9229
Training Epoch: 9 [19456/50176]	Loss: 1.8565
Training Epoch: 9 [20480/50176]	Loss: 1.9218
Training Epoch: 9 [21504/50176]	Loss: 1.8983
Training Epoch: 9 [22528/50176]	Loss: 1.8631
Training Epoch: 9 [23552/50176]	Loss: 1.8835
Training Epoch: 9 [24576/50176]	Loss: 1.9052
Training Epoch: 9 [25600/50176]	Loss: 1.8447
Training Epoch: 9 [26624/50176]	Loss: 1.8753
Training Epoch: 9 [27648/50176]	Loss: 2.0149
Training Epoch: 9 [28672/50176]	Loss: 1.9160
Training Epoch: 9 [29696/50176]	Loss: 1.9408
Training Epoch: 9 [30720/50176]	Loss: 1.8483
Training Epoch: 9 [31744/50176]	Loss: 1.9183
Training Epoch: 9 [32768/50176]	Loss: 1.9016
Training Epoch: 9 [33792/50176]	Loss: 1.8297
Training Epoch: 9 [34816/50176]	Loss: 1.9257
Training Epoch: 9 [35840/50176]	Loss: 1.8827
Training Epoch: 9 [36864/50176]	Loss: 1.8773
Training Epoch: 9 [37888/50176]	Loss: 1.8989
Training Epoch: 9 [38912/50176]	Loss: 1.9278
Training Epoch: 9 [39936/50176]	Loss: 1.8659
Training Epoch: 9 [40960/50176]	Loss: 1.8891
Training Epoch: 9 [41984/50176]	Loss: 1.8113
Training Epoch: 9 [43008/50176]	Loss: 1.9216
Training Epoch: 9 [44032/50176]	Loss: 1.8892
Training Epoch: 9 [45056/50176]	Loss: 1.8015
Training Epoch: 9 [46080/50176]	Loss: 1.8068
Training Epoch: 9 [47104/50176]	Loss: 1.8425
Training Epoch: 9 [48128/50176]	Loss: 1.8303
Training Epoch: 9 [49152/50176]	Loss: 1.8374
Training Epoch: 9 [50176/50176]	Loss: 1.8139
2022-12-06 16:49:05.701 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:49:05,738 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.84 energy=486.09
2022-12-06 11:49:05,738 [ZeusDataLoader(train)] Up to epoch 10: time=534.00, energy=69686.95, cost=81568.84
2022-12-06 11:49:05,739 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:49:05,739 [ZeusDataLoader(train)] Expected next epoch: time=580.73, energy=76362.46, cost=88995.09
2022-12-06 11:49:05,740 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0020, Accuracy: 0.4418
2022-12-06 11:49:05,922 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:49:05,923 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:49:05.937 [ZeusMonitor] Monitor started.
2022-12-06 16:49:05.937 [ZeusMonitor] Running indefinitely. 2022-12-06 16:49:05.937 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:49:05.937 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 11:49:51,211 [ZeusDataLoader(train)] train epoch 11 done: time=45.46 energy=6406.70
2022-12-06 11:49:51,214 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.8527
Training Epoch: 10 [2048/50176]	Loss: 1.7677
Training Epoch: 10 [3072/50176]	Loss: 1.7478
Training Epoch: 10 [4096/50176]	Loss: 1.8399
Training Epoch: 10 [5120/50176]	Loss: 1.7764
Training Epoch: 10 [6144/50176]	Loss: 1.8363
Training Epoch: 10 [7168/50176]	Loss: 1.7848
Training Epoch: 10 [8192/50176]	Loss: 1.7203
Training Epoch: 10 [9216/50176]	Loss: 1.7184
Training Epoch: 10 [10240/50176]	Loss: 1.6559
Training Epoch: 10 [11264/50176]	Loss: 1.8817
Training Epoch: 10 [12288/50176]	Loss: 1.7081
Training Epoch: 10 [13312/50176]	Loss: 1.8553
Training Epoch: 10 [14336/50176]	Loss: 1.8783
Training Epoch: 10 [15360/50176]	Loss: 1.8235
Training Epoch: 10 [16384/50176]	Loss: 1.8235
Training Epoch: 10 [17408/50176]	Loss: 1.8372
Training Epoch: 10 [18432/50176]	Loss: 1.7293
Training Epoch: 10 [19456/50176]	Loss: 1.7910
Training Epoch: 10 [20480/50176]	Loss: 1.7401
Training Epoch: 10 [21504/50176]	Loss: 1.7961
Training Epoch: 10 [22528/50176]	Loss: 1.7561
Training Epoch: 10 [23552/50176]	Loss: 1.7476
Training Epoch: 10 [24576/50176]	Loss: 1.8035
Training Epoch: 10 [25600/50176]	Loss: 1.7452
Training Epoch: 10 [26624/50176]	Loss: 1.7356
Training Epoch: 10 [27648/50176]	Loss: 1.7489
Training Epoch: 10 [28672/50176]	Loss: 1.8624
Training Epoch: 10 [29696/50176]	Loss: 1.9023
Training Epoch: 10 [30720/50176]	Loss: 1.7400
Training Epoch: 10 [31744/50176]	Loss: 1.8558
Training Epoch: 10 [32768/50176]	Loss: 1.7755
Training Epoch: 10 [33792/50176]	Loss: 1.7514
Training Epoch: 10 [34816/50176]	Loss: 1.8326
Training Epoch: 10 [35840/50176]	Loss: 1.9035
Training Epoch: 10 [36864/50176]	Loss: 1.8262
Training Epoch: 10 [37888/50176]	Loss: 1.6934
Training Epoch: 10 [38912/50176]	Loss: 1.7245
Training Epoch: 10 [39936/50176]	Loss: 1.9098
Training Epoch: 10 [40960/50176]	Loss: 1.6865
Training Epoch: 10 [41984/50176]	Loss: 1.7042
Training Epoch: 10 [43008/50176]	Loss: 1.8538
Training Epoch: 10 [44032/50176]	Loss: 1.8035
Training Epoch: 10 [45056/50176]	Loss: 1.7269
Training Epoch: 10 [46080/50176]	Loss: 1.6445
Training Epoch: 10 [47104/50176]	Loss: 1.8462
Training Epoch: 10 [48128/50176]	Loss: 1.7346
Training Epoch: 10 [49152/50176]	Loss: 1.7687
Training Epoch: 10 [50176/50176]	Loss: 1.8029
2022-12-06 16:49:55.143 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:49:55,164 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.94 energy=493.25
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Up to epoch 11: time=583.41, energy=76586.91, cost=89341.74
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Expected next epoch: time=630.13, energy=83262.42, cost=96767.99
2022-12-06 11:49:55,165 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0019, Accuracy: 0.4789
2022-12-06 11:49:55,361 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:49:55,362 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:49:55.376 [ZeusMonitor] Monitor started.
2022-12-06 16:49:55.376 [ZeusMonitor] Running indefinitely. 2022-12-06 16:49:55.376 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:49:55.376 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 11:50:39,981 [ZeusDataLoader(train)] train epoch 12 done: time=44.81 energy=6349.56
2022-12-06 11:50:39,984 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.6035
Training Epoch: 11 [2048/50176]	Loss: 1.6605
Training Epoch: 11 [3072/50176]	Loss: 1.6687
Training Epoch: 11 [4096/50176]	Loss: 1.8013
Training Epoch: 11 [5120/50176]	Loss: 1.8018
Training Epoch: 11 [6144/50176]	Loss: 1.5212
Training Epoch: 11 [7168/50176]	Loss: 1.6249
Training Epoch: 11 [8192/50176]	Loss: 1.6900
Training Epoch: 11 [9216/50176]	Loss: 1.6688
Training Epoch: 11 [10240/50176]	Loss: 1.7524
Training Epoch: 11 [11264/50176]	Loss: 1.6827
Training Epoch: 11 [12288/50176]	Loss: 1.6656
Training Epoch: 11 [13312/50176]	Loss: 1.7801
Training Epoch: 11 [14336/50176]	Loss: 1.6230
Training Epoch: 11 [15360/50176]	Loss: 1.7447
Training Epoch: 11 [16384/50176]	Loss: 1.7004
Training Epoch: 11 [17408/50176]	Loss: 1.6584
Training Epoch: 11 [18432/50176]	Loss: 1.6654
Training Epoch: 11 [19456/50176]	Loss: 1.6802
Training Epoch: 11 [20480/50176]	Loss: 1.8047
Training Epoch: 11 [21504/50176]	Loss: 1.7324
Training Epoch: 11 [22528/50176]	Loss: 1.7323
Training Epoch: 11 [23552/50176]	Loss: 1.7297
Training Epoch: 11 [24576/50176]	Loss: 1.6634
Training Epoch: 11 [25600/50176]	Loss: 1.6569
Training Epoch: 11 [26624/50176]	Loss: 1.6225
Training Epoch: 11 [27648/50176]	Loss: 1.6742
Training Epoch: 11 [28672/50176]	Loss: 1.7057
Training Epoch: 11 [29696/50176]	Loss: 1.7666
Training Epoch: 11 [30720/50176]	Loss: 1.6618
Training Epoch: 11 [31744/50176]	Loss: 1.6658
Training Epoch: 11 [32768/50176]	Loss: 1.7777
Training Epoch: 11 [33792/50176]	Loss: 1.7264
Training Epoch: 11 [34816/50176]	Loss: 1.7712
Training Epoch: 11 [35840/50176]	Loss: 1.7379
Training Epoch: 11 [36864/50176]	Loss: 1.6658
Training Epoch: 11 [37888/50176]	Loss: 1.7229
Training Epoch: 11 [38912/50176]	Loss: 1.7000
Training Epoch: 11 [39936/50176]	Loss: 1.6999
Training Epoch: 11 [40960/50176]	Loss: 1.6223
Training Epoch: 11 [41984/50176]	Loss: 1.6814
Training Epoch: 11 [43008/50176]	Loss: 1.7719
Training Epoch: 11 [44032/50176]	Loss: 1.6730
Training Epoch: 11 [45056/50176]	Loss: 1.7860
Training Epoch: 11 [46080/50176]	Loss: 1.6199
Training Epoch: 11 [47104/50176]	Loss: 1.7495
Training Epoch: 11 [48128/50176]	Loss: 1.6718
Training Epoch: 11 [49152/50176]	Loss: 1.6158
Training Epoch: 11 [50176/50176]	Loss: 1.7604
2022-12-06 16:50:43.822 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:50:43,862 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.87 energy=485.49
2022-12-06 11:50:43,862 [ZeusDataLoader(train)] Up to epoch 12: time=632.09, energy=83421.97, cost=97018.54
2022-12-06 11:50:43,863 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:50:43,863 [ZeusDataLoader(train)] Expected next epoch: time=678.81, energy=90097.48, cost=104444.80
2022-12-06 11:50:43,864 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0018, Accuracy: 0.4956
2022-12-06 11:50:44,054 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:50:44,055 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:50:44.069 [ZeusMonitor] Monitor started.
2022-12-06 16:50:44.069 [ZeusMonitor] Running indefinitely. 2022-12-06 16:50:44.069 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:50:44.069 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 11:51:28,080 [ZeusDataLoader(train)] train epoch 13 done: time=44.21 energy=6310.19
2022-12-06 11:51:28,083 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.6044
Training Epoch: 12 [2048/50176]	Loss: 1.5993
Training Epoch: 12 [3072/50176]	Loss: 1.6137
Training Epoch: 12 [4096/50176]	Loss: 1.5894
Training Epoch: 12 [5120/50176]	Loss: 1.5152
Training Epoch: 12 [6144/50176]	Loss: 1.6161
Training Epoch: 12 [7168/50176]	Loss: 1.6767
Training Epoch: 12 [8192/50176]	Loss: 1.4651
Training Epoch: 12 [9216/50176]	Loss: 1.6560
Training Epoch: 12 [10240/50176]	Loss: 1.5591
Training Epoch: 12 [11264/50176]	Loss: 1.7074
Training Epoch: 12 [12288/50176]	Loss: 1.5738
Training Epoch: 12 [13312/50176]	Loss: 1.5386
Training Epoch: 12 [14336/50176]	Loss: 1.5959
Training Epoch: 12 [15360/50176]	Loss: 1.5319
Training Epoch: 12 [16384/50176]	Loss: 1.5515
Training Epoch: 12 [17408/50176]	Loss: 1.5665
Training Epoch: 12 [18432/50176]	Loss: 1.5891
Training Epoch: 12 [19456/50176]	Loss: 1.5822
Training Epoch: 12 [20480/50176]	Loss: 1.5907
Training Epoch: 12 [21504/50176]	Loss: 1.7110
Training Epoch: 12 [22528/50176]	Loss: 1.5338
Training Epoch: 12 [23552/50176]	Loss: 1.6049
Training Epoch: 12 [24576/50176]	Loss: 1.5136
Training Epoch: 12 [25600/50176]	Loss: 1.6199
Training Epoch: 12 [26624/50176]	Loss: 1.7173
Training Epoch: 12 [27648/50176]	Loss: 1.5379
Training Epoch: 12 [28672/50176]	Loss: 1.6288
Training Epoch: 12 [29696/50176]	Loss: 1.5463
Training Epoch: 12 [30720/50176]	Loss: 1.5558
Training Epoch: 12 [31744/50176]	Loss: 1.5783
Training Epoch: 12 [32768/50176]	Loss: 1.6123
Training Epoch: 12 [33792/50176]	Loss: 1.5739
Training Epoch: 12 [34816/50176]	Loss: 1.5772
Training Epoch: 12 [35840/50176]	Loss: 1.5546
Training Epoch: 12 [36864/50176]	Loss: 1.6023
Training Epoch: 12 [37888/50176]	Loss: 1.6630
Training Epoch: 12 [38912/50176]	Loss: 1.5763
Training Epoch: 12 [39936/50176]	Loss: 1.6543
Training Epoch: 12 [40960/50176]	Loss: 1.4857
Training Epoch: 12 [41984/50176]	Loss: 1.6576
Training Epoch: 12 [43008/50176]	Loss: 1.5840
Training Epoch: 12 [44032/50176]	Loss: 1.6782
Training Epoch: 12 [45056/50176]	Loss: 1.5512
Training Epoch: 12 [46080/50176]	Loss: 1.6551
Training Epoch: 12 [47104/50176]	Loss: 1.5531
Training Epoch: 12 [48128/50176]	Loss: 1.5695
Training Epoch: 12 [49152/50176]	Loss: 1.6232
Training Epoch: 12 [50176/50176]	Loss: 1.5573
2022-12-06 16:51:31.904 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:51:31,948 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.86 energy=483.83
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Up to epoch 13: time=680.15, energy=90215.98, cost=104621.30
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Expected next epoch: time=726.88, energy=96891.49, cost=112047.56
2022-12-06 11:51:31,950 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0018, Accuracy: 0.5036
2022-12-06 11:51:32,135 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:51:32,135 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:51:32.149 [ZeusMonitor] Monitor started.
2022-12-06 16:51:32.150 [ZeusMonitor] Running indefinitely. 2022-12-06 16:51:32.150 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:51:32.150 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 11:52:16,480 [ZeusDataLoader(train)] train epoch 14 done: time=44.52 energy=6324.77
2022-12-06 11:52:16,483 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.4576
Training Epoch: 13 [2048/50176]	Loss: 1.5433
Training Epoch: 13 [3072/50176]	Loss: 1.5277
Training Epoch: 13 [4096/50176]	Loss: 1.4356
Training Epoch: 13 [5120/50176]	Loss: 1.4868
Training Epoch: 13 [6144/50176]	Loss: 1.4884
Training Epoch: 13 [7168/50176]	Loss: 1.4474
Training Epoch: 13 [8192/50176]	Loss: 1.5026
Training Epoch: 13 [9216/50176]	Loss: 1.4711
Training Epoch: 13 [10240/50176]	Loss: 1.6753
Training Epoch: 13 [11264/50176]	Loss: 1.4667
Training Epoch: 13 [12288/50176]	Loss: 1.4819
Training Epoch: 13 [13312/50176]	Loss: 1.5147
Training Epoch: 13 [14336/50176]	Loss: 1.5027
Training Epoch: 13 [15360/50176]	Loss: 1.5825
Training Epoch: 13 [16384/50176]	Loss: 1.5221
Training Epoch: 13 [17408/50176]	Loss: 1.5457
Training Epoch: 13 [18432/50176]	Loss: 1.3944
Training Epoch: 13 [19456/50176]	Loss: 1.4813
Training Epoch: 13 [20480/50176]	Loss: 1.4606
Training Epoch: 13 [21504/50176]	Loss: 1.4793
Training Epoch: 13 [22528/50176]	Loss: 1.4865
Training Epoch: 13 [23552/50176]	Loss: 1.5334
Training Epoch: 13 [24576/50176]	Loss: 1.5174
Training Epoch: 13 [25600/50176]	Loss: 1.4859
Training Epoch: 13 [26624/50176]	Loss: 1.6245
Training Epoch: 13 [27648/50176]	Loss: 1.4582
Training Epoch: 13 [28672/50176]	Loss: 1.5066
Training Epoch: 13 [29696/50176]	Loss: 1.5128
Training Epoch: 13 [30720/50176]	Loss: 1.5235
Training Epoch: 13 [31744/50176]	Loss: 1.5176
Training Epoch: 13 [32768/50176]	Loss: 1.4542
Training Epoch: 13 [33792/50176]	Loss: 1.5757
Training Epoch: 13 [34816/50176]	Loss: 1.6544
Training Epoch: 13 [35840/50176]	Loss: 1.6298
Training Epoch: 13 [36864/50176]	Loss: 1.5108
Training Epoch: 13 [37888/50176]	Loss: 1.5966
Training Epoch: 13 [38912/50176]	Loss: 1.4692
Training Epoch: 13 [39936/50176]	Loss: 1.4646
Training Epoch: 13 [40960/50176]	Loss: 1.5243
Training Epoch: 13 [41984/50176]	Loss: 1.5414
Training Epoch: 13 [43008/50176]	Loss: 1.4098
Training Epoch: 13 [44032/50176]	Loss: 1.5605
Training Epoch: 13 [45056/50176]	Loss: 1.4826
Training Epoch: 13 [46080/50176]	Loss: 1.4833
Training Epoch: 13 [47104/50176]	Loss: 1.5340
Training Epoch: 13 [48128/50176]	Loss: 1.5027
Training Epoch: 13 [49152/50176]	Loss: 1.4525
Training Epoch: 13 [50176/50176]	Loss: 1.6361
2022-12-06 16:52:20.192 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:52:20,211 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.72 energy=474.74
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Up to epoch 14: time=728.39, energy=97015.49, cost=112242.23
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Expected next epoch: time=775.12, energy=103691.00, cost=119668.49
2022-12-06 11:52:20,212 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0018, Accuracy: 0.5073
2022-12-06 11:52:20,410 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:52:20,410 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:52:20.424 [ZeusMonitor] Monitor started.
2022-12-06 16:52:20.424 [ZeusMonitor] Running indefinitely. 2022-12-06 16:52:20.424 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:52:20.425 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 11:53:04,974 [ZeusDataLoader(train)] train epoch 15 done: time=44.75 energy=6353.17
2022-12-06 11:53:04,977 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.3885
Training Epoch: 14 [2048/50176]	Loss: 1.4497
Training Epoch: 14 [3072/50176]	Loss: 1.4651
Training Epoch: 14 [4096/50176]	Loss: 1.5345
Training Epoch: 14 [5120/50176]	Loss: 1.3928
Training Epoch: 14 [6144/50176]	Loss: 1.4210
Training Epoch: 14 [7168/50176]	Loss: 1.3674
Training Epoch: 14 [8192/50176]	Loss: 1.4208
Training Epoch: 14 [9216/50176]	Loss: 1.3988
Training Epoch: 14 [10240/50176]	Loss: 1.3915
Training Epoch: 14 [11264/50176]	Loss: 1.3596
Training Epoch: 14 [12288/50176]	Loss: 1.3997
Training Epoch: 14 [13312/50176]	Loss: 1.4468
Training Epoch: 14 [14336/50176]	Loss: 1.4330
Training Epoch: 14 [15360/50176]	Loss: 1.4107
Training Epoch: 14 [16384/50176]	Loss: 1.3376
Training Epoch: 14 [17408/50176]	Loss: 1.5018
Training Epoch: 14 [18432/50176]	Loss: 1.4123
Training Epoch: 14 [19456/50176]	Loss: 1.4395
Training Epoch: 14 [20480/50176]	Loss: 1.4284
Training Epoch: 14 [21504/50176]	Loss: 1.4708
Training Epoch: 14 [22528/50176]	Loss: 1.4293
Training Epoch: 14 [23552/50176]	Loss: 1.4093
Training Epoch: 14 [24576/50176]	Loss: 1.4441
Training Epoch: 14 [25600/50176]	Loss: 1.5348
Training Epoch: 14 [26624/50176]	Loss: 1.3500
Training Epoch: 14 [27648/50176]	Loss: 1.3357
Training Epoch: 14 [28672/50176]	Loss: 1.5034
Training Epoch: 14 [29696/50176]	Loss: 1.4307
Training Epoch: 14 [30720/50176]	Loss: 1.4506
Training Epoch: 14 [31744/50176]	Loss: 1.4004
Training Epoch: 14 [32768/50176]	Loss: 1.5937
Training Epoch: 14 [33792/50176]	Loss: 1.4651
Training Epoch: 14 [34816/50176]	Loss: 1.4809
Training Epoch: 14 [35840/50176]	Loss: 1.4549
Training Epoch: 14 [36864/50176]	Loss: 1.5340
Training Epoch: 14 [37888/50176]	Loss: 1.3891
Training Epoch: 14 [38912/50176]	Loss: 1.5099
Training Epoch: 14 [39936/50176]	Loss: 1.4514
Training Epoch: 14 [40960/50176]	Loss: 1.4603
Training Epoch: 14 [41984/50176]	Loss: 1.5464
Training Epoch: 14 [43008/50176]	Loss: 1.5014
Training Epoch: 14 [44032/50176]	Loss: 1.4436
Training Epoch: 14 [45056/50176]	Loss: 1.4810
Training Epoch: 14 [46080/50176]	Loss: 1.4657
Training Epoch: 14 [47104/50176]	Loss: 1.4323
Training Epoch: 14 [48128/50176]	Loss: 1.4453
Training Epoch: 14 [49152/50176]	Loss: 1.5071
Training Epoch: 14 [50176/50176]	Loss: 1.4496
2022-12-06 16:53:08.718 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:53:08,745 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.76 energy=479.28
2022-12-06 11:53:08,745 [ZeusDataLoader(train)] Up to epoch 15: time=776.91, energy=103847.95, cost=119903.41
2022-12-06 11:53:08,746 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:53:08,746 [ZeusDataLoader(train)] Expected next epoch: time=823.63, energy=110523.45, cost=127329.66
2022-12-06 11:53:08,747 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.5107
2022-12-06 11:53:08,969 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:53:08,970 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:53:08.972 [ZeusMonitor] Monitor started.
2022-12-06 16:53:08.972 [ZeusMonitor] Running indefinitely. 2022-12-06 16:53:08.972 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:53:08.972 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 11:53:52,959 [ZeusDataLoader(train)] train epoch 16 done: time=44.20 energy=6316.67
2022-12-06 11:53:52,963 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.4065
Training Epoch: 15 [2048/50176]	Loss: 1.3541
Training Epoch: 15 [3072/50176]	Loss: 1.3629
Training Epoch: 15 [4096/50176]	Loss: 1.3273
Training Epoch: 15 [5120/50176]	Loss: 1.2943
Training Epoch: 15 [6144/50176]	Loss: 1.3598
Training Epoch: 15 [7168/50176]	Loss: 1.3696
Training Epoch: 15 [8192/50176]	Loss: 1.3766
Training Epoch: 15 [9216/50176]	Loss: 1.3578
Training Epoch: 15 [10240/50176]	Loss: 1.3445
Training Epoch: 15 [11264/50176]	Loss: 1.3280
Training Epoch: 15 [12288/50176]	Loss: 1.4640
Training Epoch: 15 [13312/50176]	Loss: 1.3008
Training Epoch: 15 [14336/50176]	Loss: 1.4004
Training Epoch: 15 [15360/50176]	Loss: 1.4434
Training Epoch: 15 [16384/50176]	Loss: 1.4112
Training Epoch: 15 [17408/50176]	Loss: 1.3670
Training Epoch: 15 [18432/50176]	Loss: 1.4018
Training Epoch: 15 [19456/50176]	Loss: 1.3491
Training Epoch: 15 [20480/50176]	Loss: 1.2988
Training Epoch: 15 [21504/50176]	Loss: 1.2885
Training Epoch: 15 [22528/50176]	Loss: 1.4597
Training Epoch: 15 [23552/50176]	Loss: 1.3895
Training Epoch: 15 [24576/50176]	Loss: 1.3950
Training Epoch: 15 [25600/50176]	Loss: 1.3520
Training Epoch: 15 [26624/50176]	Loss: 1.3802
Training Epoch: 15 [27648/50176]	Loss: 1.4223
Training Epoch: 15 [28672/50176]	Loss: 1.3107
Training Epoch: 15 [29696/50176]	Loss: 1.4167
Training Epoch: 15 [30720/50176]	Loss: 1.3476
Training Epoch: 15 [31744/50176]	Loss: 1.3852
Training Epoch: 15 [32768/50176]	Loss: 1.3709
Training Epoch: 15 [33792/50176]	Loss: 1.3075
Training Epoch: 15 [34816/50176]	Loss: 1.4807
Training Epoch: 15 [35840/50176]	Loss: 1.4296
Training Epoch: 15 [36864/50176]	Loss: 1.3808
Training Epoch: 15 [37888/50176]	Loss: 1.4182
Training Epoch: 15 [38912/50176]	Loss: 1.3533
Training Epoch: 15 [39936/50176]	Loss: 1.3878
Training Epoch: 15 [40960/50176]	Loss: 1.4035
Training Epoch: 15 [41984/50176]	Loss: 1.4122
Training Epoch: 15 [43008/50176]	Loss: 1.4821
Training Epoch: 15 [44032/50176]	Loss: 1.3597
Training Epoch: 15 [45056/50176]	Loss: 1.2987
Training Epoch: 15 [46080/50176]	Loss: 1.3525
Training Epoch: 15 [47104/50176]	Loss: 1.3512
Training Epoch: 15 [48128/50176]	Loss: 1.4309
Training Epoch: 15 [49152/50176]	Loss: 1.3066
Training Epoch: 15 [50176/50176]	Loss: 1.3706
2022-12-06 16:53:56.719 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:53:56,739 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.77 energy=475.51
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Up to epoch 16: time=824.88, energy=110640.13, cost=127497.19
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Expected next epoch: time=871.61, energy=117315.64, cost=134923.45
2022-12-06 11:53:56,741 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0017, Accuracy: 0.5308
2022-12-06 11:53:56,940 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:53:56,941 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:53:56.943 [ZeusMonitor] Monitor started.
2022-12-06 16:53:56.955 [ZeusMonitor] Running indefinitely. 2022-12-06 16:53:56.955 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:53:56.955 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 11:54:41,225 [ZeusDataLoader(train)] train epoch 17 done: time=44.48 energy=6336.65
2022-12-06 11:54:41,228 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.2760
Training Epoch: 16 [2048/50176]	Loss: 1.3080
Training Epoch: 16 [3072/50176]	Loss: 1.2655
Training Epoch: 16 [4096/50176]	Loss: 1.3121
Training Epoch: 16 [5120/50176]	Loss: 1.3274
Training Epoch: 16 [6144/50176]	Loss: 1.2385
Training Epoch: 16 [7168/50176]	Loss: 1.2559
Training Epoch: 16 [8192/50176]	Loss: 1.1950
Training Epoch: 16 [9216/50176]	Loss: 1.2807
Training Epoch: 16 [10240/50176]	Loss: 1.1912
Training Epoch: 16 [11264/50176]	Loss: 1.3603
Training Epoch: 16 [12288/50176]	Loss: 1.2824
Training Epoch: 16 [13312/50176]	Loss: 1.3123
Training Epoch: 16 [14336/50176]	Loss: 1.3212
Training Epoch: 16 [15360/50176]	Loss: 1.3507
Training Epoch: 16 [16384/50176]	Loss: 1.2483
Training Epoch: 16 [17408/50176]	Loss: 1.2809
Training Epoch: 16 [18432/50176]	Loss: 1.3981
Training Epoch: 16 [19456/50176]	Loss: 1.2959
Training Epoch: 16 [20480/50176]	Loss: 1.2486
Training Epoch: 16 [21504/50176]	Loss: 1.2731
Training Epoch: 16 [22528/50176]	Loss: 1.3089
Training Epoch: 16 [23552/50176]	Loss: 1.3361
Training Epoch: 16 [24576/50176]	Loss: 1.2933
Training Epoch: 16 [25600/50176]	Loss: 1.2850
Training Epoch: 16 [26624/50176]	Loss: 1.2816
Training Epoch: 16 [27648/50176]	Loss: 1.3851
Training Epoch: 16 [28672/50176]	Loss: 1.3604
Training Epoch: 16 [29696/50176]	Loss: 1.2154
Training Epoch: 16 [30720/50176]	Loss: 1.2800
Training Epoch: 16 [31744/50176]	Loss: 1.3114
Training Epoch: 16 [32768/50176]	Loss: 1.3552
Training Epoch: 16 [33792/50176]	Loss: 1.2644
Training Epoch: 16 [34816/50176]	Loss: 1.3153
Training Epoch: 16 [35840/50176]	Loss: 1.4044
Training Epoch: 16 [36864/50176]	Loss: 1.3831
Training Epoch: 16 [37888/50176]	Loss: 1.2794
Training Epoch: 16 [38912/50176]	Loss: 1.3591
Training Epoch: 16 [39936/50176]	Loss: 1.5151
Training Epoch: 16 [40960/50176]	Loss: 1.4036
Training Epoch: 16 [41984/50176]	Loss: 1.3819
Training Epoch: 16 [43008/50176]	Loss: 1.3299
Training Epoch: 16 [44032/50176]	Loss: 1.4080
Training Epoch: 16 [45056/50176]	Loss: 1.4468
Training Epoch: 16 [46080/50176]	Loss: 1.4048
Training Epoch: 16 [47104/50176]	Loss: 1.3834
Training Epoch: 16 [48128/50176]	Loss: 1.4215
Training Epoch: 16 [49152/50176]	Loss: 1.4265
Training Epoch: 16 [50176/50176]	Loss: 1.3511
2022-12-06 16:54:44.980 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:54:45,004 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.77 energy=476.54
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Up to epoch 17: time=873.13, energy=117453.32, cost=135125.15
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Expected next epoch: time=919.85, energy=124128.83, cost=142551.41
2022-12-06 11:54:45,005 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0022, Accuracy: 0.4850
2022-12-06 11:54:45,202 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:54:45,202 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:54:45.204 [ZeusMonitor] Monitor started.
2022-12-06 16:54:45.204 [ZeusMonitor] Running indefinitely. 2022-12-06 16:54:45.204 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:54:45.204 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 11:55:29,555 [ZeusDataLoader(train)] train epoch 18 done: time=44.54 energy=6340.18
2022-12-06 11:55:29,558 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.2280
Training Epoch: 17 [2048/50176]	Loss: 1.2516
Training Epoch: 17 [3072/50176]	Loss: 1.1451
Training Epoch: 17 [4096/50176]	Loss: 1.2165
Training Epoch: 17 [5120/50176]	Loss: 1.3797
Training Epoch: 17 [6144/50176]	Loss: 1.2384
Training Epoch: 17 [7168/50176]	Loss: 1.2401
Training Epoch: 17 [8192/50176]	Loss: 1.2394
Training Epoch: 17 [9216/50176]	Loss: 1.2820
Training Epoch: 17 [10240/50176]	Loss: 1.2124
Training Epoch: 17 [11264/50176]	Loss: 1.2185
Training Epoch: 17 [12288/50176]	Loss: 1.2642
Training Epoch: 17 [13312/50176]	Loss: 1.2785
Training Epoch: 17 [14336/50176]	Loss: 1.2517
Training Epoch: 17 [15360/50176]	Loss: 1.2056
Training Epoch: 17 [16384/50176]	Loss: 1.2515
Training Epoch: 17 [17408/50176]	Loss: 1.3346
Training Epoch: 17 [18432/50176]	Loss: 1.3637
Training Epoch: 17 [19456/50176]	Loss: 1.2165
Training Epoch: 17 [20480/50176]	Loss: 1.2814
Training Epoch: 17 [21504/50176]	Loss: 1.3065
Training Epoch: 17 [22528/50176]	Loss: 1.3576
Training Epoch: 17 [23552/50176]	Loss: 1.2883
Training Epoch: 17 [24576/50176]	Loss: 1.3367
Training Epoch: 17 [25600/50176]	Loss: 1.3081
Training Epoch: 17 [26624/50176]	Loss: 1.2506
Training Epoch: 17 [27648/50176]	Loss: 1.2379
Training Epoch: 17 [28672/50176]	Loss: 1.3033
Training Epoch: 17 [29696/50176]	Loss: 1.3131
Training Epoch: 17 [30720/50176]	Loss: 1.3598
Training Epoch: 17 [31744/50176]	Loss: 1.2968
Training Epoch: 17 [32768/50176]	Loss: 1.2541
Training Epoch: 17 [33792/50176]	Loss: 1.3433
Training Epoch: 17 [34816/50176]	Loss: 1.2751
Training Epoch: 17 [35840/50176]	Loss: 1.1601
Training Epoch: 17 [36864/50176]	Loss: 1.3844
Training Epoch: 17 [37888/50176]	Loss: 1.2954
Training Epoch: 17 [38912/50176]	Loss: 1.3503
Training Epoch: 17 [39936/50176]	Loss: 1.3750
Training Epoch: 17 [40960/50176]	Loss: 1.2800
Training Epoch: 17 [41984/50176]	Loss: 1.3200
Training Epoch: 17 [43008/50176]	Loss: 1.2557
Training Epoch: 17 [44032/50176]	Loss: 1.3413
Training Epoch: 17 [45056/50176]	Loss: 1.2909
Training Epoch: 17 [46080/50176]	Loss: 1.2607
Training Epoch: 17 [47104/50176]	Loss: 1.2093
Training Epoch: 17 [48128/50176]	Loss: 1.2923
Training Epoch: 17 [49152/50176]	Loss: 1.2977
Training Epoch: 17 [50176/50176]	Loss: 1.2947
2022-12-06 16:55:33.234 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:55:33,243 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.68 energy=462.94
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Up to epoch 18: time=921.34, energy=124256.44, cost=142745.84
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Expected next epoch: time=968.07, energy=130931.95, cost=150172.10
2022-12-06 11:55:33,244 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0016, Accuracy: 0.5598
2022-12-06 11:55:33,437 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:55:33,438 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:55:33.452 [ZeusMonitor] Monitor started.
2022-12-06 16:55:33.452 [ZeusMonitor] Running indefinitely. 2022-12-06 16:55:33.452 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:55:33.452 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 11:56:17,523 [ZeusDataLoader(train)] train epoch 19 done: time=44.27 energy=6308.44
2022-12-06 11:56:17,526 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.1640
Training Epoch: 18 [2048/50176]	Loss: 1.2136
Training Epoch: 18 [3072/50176]	Loss: 1.2065
Training Epoch: 18 [4096/50176]	Loss: 1.1425
Training Epoch: 18 [5120/50176]	Loss: 1.1904
Training Epoch: 18 [6144/50176]	Loss: 1.1817
Training Epoch: 18 [7168/50176]	Loss: 1.1415
Training Epoch: 18 [8192/50176]	Loss: 1.2037
Training Epoch: 18 [9216/50176]	Loss: 1.1287
Training Epoch: 18 [10240/50176]	Loss: 1.1671
Training Epoch: 18 [11264/50176]	Loss: 1.1767
Training Epoch: 18 [12288/50176]	Loss: 1.1587
Training Epoch: 18 [13312/50176]	Loss: 1.2363
Training Epoch: 18 [14336/50176]	Loss: 1.1847
Training Epoch: 18 [15360/50176]	Loss: 1.2422
Training Epoch: 18 [16384/50176]	Loss: 1.2307
Training Epoch: 18 [17408/50176]	Loss: 1.2305
Training Epoch: 18 [18432/50176]	Loss: 1.2336
Training Epoch: 18 [19456/50176]	Loss: 1.2227
Training Epoch: 18 [20480/50176]	Loss: 1.2153
Training Epoch: 18 [21504/50176]	Loss: 1.2529
Training Epoch: 18 [22528/50176]	Loss: 1.2465
Training Epoch: 18 [23552/50176]	Loss: 1.1749
Training Epoch: 18 [24576/50176]	Loss: 1.1603
Training Epoch: 18 [25600/50176]	Loss: 1.1337
Training Epoch: 18 [26624/50176]	Loss: 1.1192
Training Epoch: 18 [27648/50176]	Loss: 1.1800
Training Epoch: 18 [28672/50176]	Loss: 1.2057
Training Epoch: 18 [29696/50176]	Loss: 1.2585
Training Epoch: 18 [30720/50176]	Loss: 1.2618
Training Epoch: 18 [31744/50176]	Loss: 1.3169
Training Epoch: 18 [32768/50176]	Loss: 1.1897
Training Epoch: 18 [33792/50176]	Loss: 1.2462
Training Epoch: 18 [34816/50176]	Loss: 1.2271
Training Epoch: 18 [35840/50176]	Loss: 1.3287
Training Epoch: 18 [36864/50176]	Loss: 1.2476
Training Epoch: 18 [37888/50176]	Loss: 1.1785
Training Epoch: 18 [38912/50176]	Loss: 1.2605
Training Epoch: 18 [39936/50176]	Loss: 1.2729
Training Epoch: 18 [40960/50176]	Loss: 1.2188
Training Epoch: 18 [41984/50176]	Loss: 1.2334
Training Epoch: 18 [43008/50176]	Loss: 1.2083
Training Epoch: 18 [44032/50176]	Loss: 1.1972
Training Epoch: 18 [45056/50176]	Loss: 1.1943
Training Epoch: 18 [46080/50176]	Loss: 1.2712
Training Epoch: 18 [47104/50176]	Loss: 1.2006
Training Epoch: 18 [48128/50176]	Loss: 1.1715
Training Epoch: 18 [49152/50176]	Loss: 1.2148
Training Epoch: 18 [50176/50176]	Loss: 1.2826
2022-12-06 16:56:21.225 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:56:21,254 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.72 energy=487.69
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Up to epoch 19: time=969.33, energy=131052.57, cost=150343.05
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Expected next epoch: time=1016.06, energy=137728.08, cost=157769.30
2022-12-06 11:56:21,255 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0016, Accuracy: 0.5516
2022-12-06 11:56:21,458 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:56:21,459 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:56:21.461 [ZeusMonitor] Monitor started.
2022-12-06 16:56:21.461 [ZeusMonitor] Running indefinitely. 2022-12-06 16:56:21.461 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:56:21.461 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 11:57:06,107 [ZeusDataLoader(train)] train epoch 20 done: time=44.84 energy=6361.07
2022-12-06 11:57:06,110 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.0998
Training Epoch: 19 [2048/50176]	Loss: 1.1733
Training Epoch: 19 [3072/50176]	Loss: 1.1430
Training Epoch: 19 [4096/50176]	Loss: 1.1045
Training Epoch: 19 [5120/50176]	Loss: 1.1059
Training Epoch: 19 [6144/50176]	Loss: 1.1141
Training Epoch: 19 [7168/50176]	Loss: 1.1375
Training Epoch: 19 [8192/50176]	Loss: 1.1444
Training Epoch: 19 [9216/50176]	Loss: 1.1441
Training Epoch: 19 [10240/50176]	Loss: 1.1525
Training Epoch: 19 [11264/50176]	Loss: 1.1692
Training Epoch: 19 [12288/50176]	Loss: 1.0705
Training Epoch: 19 [13312/50176]	Loss: 1.1296
Training Epoch: 19 [14336/50176]	Loss: 1.1751
Training Epoch: 19 [15360/50176]	Loss: 1.1887
Training Epoch: 19 [16384/50176]	Loss: 1.1157
Training Epoch: 19 [17408/50176]	Loss: 1.1694
Training Epoch: 19 [18432/50176]	Loss: 1.1878
Training Epoch: 19 [19456/50176]	Loss: 1.1233
Training Epoch: 19 [20480/50176]	Loss: 1.1809
Training Epoch: 19 [21504/50176]	Loss: 1.1049
Training Epoch: 19 [22528/50176]	Loss: 1.2525
Training Epoch: 19 [23552/50176]	Loss: 1.2307
Training Epoch: 19 [24576/50176]	Loss: 1.0846
Training Epoch: 19 [25600/50176]	Loss: 1.1635
Training Epoch: 19 [26624/50176]	Loss: 1.1775
Training Epoch: 19 [27648/50176]	Loss: 1.0725
Training Epoch: 19 [28672/50176]	Loss: 1.1763
Training Epoch: 19 [29696/50176]	Loss: 1.2336
Training Epoch: 19 [30720/50176]	Loss: 1.1887
Training Epoch: 19 [31744/50176]	Loss: 1.1470
Training Epoch: 19 [32768/50176]	Loss: 1.1939
Training Epoch: 19 [33792/50176]	Loss: 1.1758
Training Epoch: 19 [34816/50176]	Loss: 1.1350
Training Epoch: 19 [35840/50176]	Loss: 1.1617
Training Epoch: 19 [36864/50176]	Loss: 1.2281
Training Epoch: 19 [37888/50176]	Loss: 1.1473
Training Epoch: 19 [38912/50176]	Loss: 1.2323
Training Epoch: 19 [39936/50176]	Loss: 1.1527
Training Epoch: 19 [40960/50176]	Loss: 1.0713
Training Epoch: 19 [41984/50176]	Loss: 1.2028
Training Epoch: 19 [43008/50176]	Loss: 1.1515
Training Epoch: 19 [44032/50176]	Loss: 1.1541
Training Epoch: 19 [45056/50176]	Loss: 1.1680
Training Epoch: 19 [46080/50176]	Loss: 1.1065
Training Epoch: 19 [47104/50176]	Loss: 1.1358
Training Epoch: 19 [48128/50176]	Loss: 1.0965
Training Epoch: 19 [49152/50176]	Loss: 1.1868
Training Epoch: 19 [50176/50176]	Loss: 1.1559
2022-12-06 16:57:09.847 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:57:09,886 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.77 energy=482.33
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Up to epoch 20: time=1017.95, energy=137895.97, cost=158018.26
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Expected next epoch: time=1064.67, energy=144571.47, cost=165444.52
2022-12-06 11:57:09,887 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0016, Accuracy: 0.5588
2022-12-06 11:57:10,082 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:57:10,083 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:57:10.093 [ZeusMonitor] Monitor started.
2022-12-06 16:57:10.093 [ZeusMonitor] Running indefinitely. 2022-12-06 16:57:10.093 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:57:10.093 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 11:57:54,617 [ZeusDataLoader(train)] train epoch 21 done: time=44.72 energy=6346.84
2022-12-06 11:57:54,620 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0482
Training Epoch: 20 [2048/50176]	Loss: 1.0811
Training Epoch: 20 [3072/50176]	Loss: 1.0967
Training Epoch: 20 [4096/50176]	Loss: 1.0494
Training Epoch: 20 [5120/50176]	Loss: 1.0312
Training Epoch: 20 [6144/50176]	Loss: 1.0965
Training Epoch: 20 [7168/50176]	Loss: 1.0366
Training Epoch: 20 [8192/50176]	Loss: 1.1007
Training Epoch: 20 [9216/50176]	Loss: 1.0713
Training Epoch: 20 [10240/50176]	Loss: 1.0513
Training Epoch: 20 [11264/50176]	Loss: 1.0878
Training Epoch: 20 [12288/50176]	Loss: 1.0178
Training Epoch: 20 [13312/50176]	Loss: 1.0249
Training Epoch: 20 [14336/50176]	Loss: 1.1055
Training Epoch: 20 [15360/50176]	Loss: 1.0929
Training Epoch: 20 [16384/50176]	Loss: 1.1550
Training Epoch: 20 [17408/50176]	Loss: 1.0638
Training Epoch: 20 [18432/50176]	Loss: 1.1092
Training Epoch: 20 [19456/50176]	Loss: 1.1528
Training Epoch: 20 [20480/50176]	Loss: 1.0645
Training Epoch: 20 [21504/50176]	Loss: 1.1534
Training Epoch: 20 [22528/50176]	Loss: 1.0550
Training Epoch: 20 [23552/50176]	Loss: 1.0316
Training Epoch: 20 [24576/50176]	Loss: 1.0967
Training Epoch: 20 [25600/50176]	Loss: 1.1576
Training Epoch: 20 [26624/50176]	Loss: 1.1288
Training Epoch: 20 [27648/50176]	Loss: 1.0541
Training Epoch: 20 [28672/50176]	Loss: 1.1524
Training Epoch: 20 [29696/50176]	Loss: 1.0547
Training Epoch: 20 [30720/50176]	Loss: 1.0975
Training Epoch: 20 [31744/50176]	Loss: 1.1139
Training Epoch: 20 [32768/50176]	Loss: 1.1169
Training Epoch: 20 [33792/50176]	Loss: 1.0763
Training Epoch: 20 [34816/50176]	Loss: 1.1883
Training Epoch: 20 [35840/50176]	Loss: 1.0973
Training Epoch: 20 [36864/50176]	Loss: 1.1068
Training Epoch: 20 [37888/50176]	Loss: 1.0918
Training Epoch: 20 [38912/50176]	Loss: 1.1663
Training Epoch: 20 [39936/50176]	Loss: 1.1198
Training Epoch: 20 [40960/50176]	Loss: 1.1987
Training Epoch: 20 [41984/50176]	Loss: 1.1081
Training Epoch: 20 [43008/50176]	Loss: 1.0983
Training Epoch: 20 [44032/50176]	Loss: 1.0519
Training Epoch: 20 [45056/50176]	Loss: 1.1337
Training Epoch: 20 [46080/50176]	Loss: 1.1122
Training Epoch: 20 [47104/50176]	Loss: 1.1425
Training Epoch: 20 [48128/50176]	Loss: 1.0933
Training Epoch: 20 [49152/50176]	Loss: 1.1543
Training Epoch: 20 [50176/50176]	Loss: 1.1028
2022-12-06 16:57:58.534 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:57:58,570 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.94 energy=491.77
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Up to epoch 21: time=1066.61, energy=144734.58, cost=165695.70
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Expected next epoch: time=1113.34, energy=151410.08, cost=173121.95
2022-12-06 11:57:58,572 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0016, Accuracy: 0.5661
2022-12-06 11:57:58,769 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:57:58,770 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:57:58.772 [ZeusMonitor] Monitor started.
2022-12-06 16:57:58.772 [ZeusMonitor] Running indefinitely. 2022-12-06 16:57:58.772 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:57:58.772 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 11:58:42,845 [ZeusDataLoader(train)] train epoch 22 done: time=44.27 energy=6320.25
2022-12-06 11:58:42,848 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0073
Training Epoch: 21 [2048/50176]	Loss: 0.9738
Training Epoch: 21 [3072/50176]	Loss: 1.0230
Training Epoch: 21 [4096/50176]	Loss: 1.0117
Training Epoch: 21 [5120/50176]	Loss: 1.0012
Training Epoch: 21 [6144/50176]	Loss: 0.9337
Training Epoch: 21 [7168/50176]	Loss: 0.9598
Training Epoch: 21 [8192/50176]	Loss: 1.0590
Training Epoch: 21 [9216/50176]	Loss: 1.0082
Training Epoch: 21 [10240/50176]	Loss: 0.9964
Training Epoch: 21 [11264/50176]	Loss: 0.9989
Training Epoch: 21 [12288/50176]	Loss: 1.0188
Training Epoch: 21 [13312/50176]	Loss: 1.0031
Training Epoch: 21 [14336/50176]	Loss: 1.0801
Training Epoch: 21 [15360/50176]	Loss: 1.0284
Training Epoch: 21 [16384/50176]	Loss: 1.0560
Training Epoch: 21 [17408/50176]	Loss: 1.0008
Training Epoch: 21 [18432/50176]	Loss: 1.0169
Training Epoch: 21 [19456/50176]	Loss: 1.0629
Training Epoch: 21 [20480/50176]	Loss: 1.0452
Training Epoch: 21 [21504/50176]	Loss: 1.0415
Training Epoch: 21 [22528/50176]	Loss: 1.0911
Training Epoch: 21 [23552/50176]	Loss: 1.0710
Training Epoch: 21 [24576/50176]	Loss: 0.9983
Training Epoch: 21 [25600/50176]	Loss: 1.0725
Training Epoch: 21 [26624/50176]	Loss: 1.1441
Training Epoch: 21 [27648/50176]	Loss: 1.1301
Training Epoch: 21 [28672/50176]	Loss: 1.0217
Training Epoch: 21 [29696/50176]	Loss: 1.1069
Training Epoch: 21 [30720/50176]	Loss: 1.0635
Training Epoch: 21 [31744/50176]	Loss: 1.0656
Training Epoch: 21 [32768/50176]	Loss: 1.1165
Training Epoch: 21 [33792/50176]	Loss: 1.0735
Training Epoch: 21 [34816/50176]	Loss: 1.0258
Training Epoch: 21 [35840/50176]	Loss: 1.0762
Training Epoch: 21 [36864/50176]	Loss: 1.0126
Training Epoch: 21 [37888/50176]	Loss: 1.1912
Training Epoch: 21 [38912/50176]	Loss: 1.0647
Training Epoch: 21 [39936/50176]	Loss: 1.1058
Training Epoch: 21 [40960/50176]	Loss: 1.0618
Training Epoch: 21 [41984/50176]	Loss: 1.0205
Training Epoch: 21 [43008/50176]	Loss: 1.0779
Training Epoch: 21 [44032/50176]	Loss: 1.1368
Training Epoch: 21 [45056/50176]	Loss: 1.0571
Training Epoch: 21 [46080/50176]	Loss: 1.0742
Training Epoch: 21 [47104/50176]	Loss: 1.0797
Training Epoch: 21 [48128/50176]	Loss: 1.1106
Training Epoch: 21 [49152/50176]	Loss: 1.1121
Training Epoch: 21 [50176/50176]	Loss: 1.1147
2022-12-06 16:58:46.507 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:58:46,517 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.66 energy=464.90
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Up to epoch 22: time=1114.54, energy=151519.73, cost=173281.78
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Expected next epoch: time=1161.26, energy=158195.23, cost=180708.03
2022-12-06 11:58:46,519 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0018, Accuracy: 0.5493
2022-12-06 11:58:46,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:58:46,702 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:58:46.716 [ZeusMonitor] Monitor started.
2022-12-06 16:58:46.716 [ZeusMonitor] Running indefinitely. 2022-12-06 16:58:46.716 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:58:46.716 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 11:59:31,260 [ZeusDataLoader(train)] train epoch 23 done: time=44.73 energy=6343.56
2022-12-06 11:59:31,263 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 0.9982
Training Epoch: 22 [2048/50176]	Loss: 0.9893
Training Epoch: 22 [3072/50176]	Loss: 0.9443
Training Epoch: 22 [4096/50176]	Loss: 0.8971
Training Epoch: 22 [5120/50176]	Loss: 0.9799
Training Epoch: 22 [6144/50176]	Loss: 0.9989
Training Epoch: 22 [7168/50176]	Loss: 1.0449
Training Epoch: 22 [8192/50176]	Loss: 1.0453
Training Epoch: 22 [9216/50176]	Loss: 0.9658
Training Epoch: 22 [10240/50176]	Loss: 0.9447
Training Epoch: 22 [11264/50176]	Loss: 1.0409
Training Epoch: 22 [12288/50176]	Loss: 0.9878
Training Epoch: 22 [13312/50176]	Loss: 0.9158
Training Epoch: 22 [14336/50176]	Loss: 0.9786
Training Epoch: 22 [15360/50176]	Loss: 0.9603
Training Epoch: 22 [16384/50176]	Loss: 1.0163
Training Epoch: 22 [17408/50176]	Loss: 0.9734
Training Epoch: 22 [18432/50176]	Loss: 0.9610
Training Epoch: 22 [19456/50176]	Loss: 1.0095
Training Epoch: 22 [20480/50176]	Loss: 1.0124
Training Epoch: 22 [21504/50176]	Loss: 0.9888
Training Epoch: 22 [22528/50176]	Loss: 0.9976
Training Epoch: 22 [23552/50176]	Loss: 1.0034
Training Epoch: 22 [24576/50176]	Loss: 1.0074
Training Epoch: 22 [25600/50176]	Loss: 1.0029
Training Epoch: 22 [26624/50176]	Loss: 1.0490
Training Epoch: 22 [27648/50176]	Loss: 1.0217
Training Epoch: 22 [28672/50176]	Loss: 1.0797
Training Epoch: 22 [29696/50176]	Loss: 1.0096
Training Epoch: 22 [30720/50176]	Loss: 1.0056
Training Epoch: 22 [31744/50176]	Loss: 1.1250
Training Epoch: 22 [32768/50176]	Loss: 0.9775
Training Epoch: 22 [33792/50176]	Loss: 1.0293
Training Epoch: 22 [34816/50176]	Loss: 1.0822
Training Epoch: 22 [35840/50176]	Loss: 1.0489
Training Epoch: 22 [36864/50176]	Loss: 1.0413
Training Epoch: 22 [37888/50176]	Loss: 1.0403
Training Epoch: 22 [38912/50176]	Loss: 0.9694
Training Epoch: 22 [39936/50176]	Loss: 1.0214
Training Epoch: 22 [40960/50176]	Loss: 1.0597
Training Epoch: 22 [41984/50176]	Loss: 1.0845
Training Epoch: 22 [43008/50176]	Loss: 1.0330
Training Epoch: 22 [44032/50176]	Loss: 1.0300
Training Epoch: 22 [45056/50176]	Loss: 1.0635
Training Epoch: 22 [46080/50176]	Loss: 1.0157
Training Epoch: 22 [47104/50176]	Loss: 1.0134
Training Epoch: 22 [48128/50176]	Loss: 1.1634
Training Epoch: 22 [49152/50176]	Loss: 1.0981
Training Epoch: 22 [50176/50176]	Loss: 0.9845
2022-12-06 16:59:34.960 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:59:34,982 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.71 energy=483.87
2022-12-06 11:59:34,982 [ZeusDataLoader(train)] Up to epoch 23: time=1162.98, energy=158347.15, cost=180934.24
2022-12-06 11:59:34,982 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:59:34,983 [ZeusDataLoader(train)] Expected next epoch: time=1209.70, energy=165022.66, cost=188360.50
2022-12-06 11:59:34,983 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0016, Accuracy: 0.5721
2022-12-06 11:59:35,137 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:59:35,138 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:59:35.141 [ZeusMonitor] Monitor started.
2022-12-06 16:59:35.141 [ZeusMonitor] Running indefinitely. 2022-12-06 16:59:35.141 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:59:35.141 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 12:00:19,628 [ZeusDataLoader(train)] train epoch 24 done: time=44.64 energy=6345.18
2022-12-06 12:00:19,631 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 0.9621
Training Epoch: 23 [2048/50176]	Loss: 0.9439
Training Epoch: 23 [3072/50176]	Loss: 0.9568
Training Epoch: 23 [4096/50176]	Loss: 0.9681
Training Epoch: 23 [5120/50176]	Loss: 0.9090
Training Epoch: 23 [6144/50176]	Loss: 0.9510
Training Epoch: 23 [7168/50176]	Loss: 0.9426
Training Epoch: 23 [8192/50176]	Loss: 0.9612
Training Epoch: 23 [9216/50176]	Loss: 0.9098
Training Epoch: 23 [10240/50176]	Loss: 0.8650
Training Epoch: 23 [11264/50176]	Loss: 0.9550
Training Epoch: 23 [12288/50176]	Loss: 0.8543
Training Epoch: 23 [13312/50176]	Loss: 1.0054
Training Epoch: 23 [14336/50176]	Loss: 0.9389
Training Epoch: 23 [15360/50176]	Loss: 0.9013
Training Epoch: 23 [16384/50176]	Loss: 0.9805
Training Epoch: 23 [17408/50176]	Loss: 0.9742
Training Epoch: 23 [18432/50176]	Loss: 0.8866
Training Epoch: 23 [19456/50176]	Loss: 0.9653
Training Epoch: 23 [20480/50176]	Loss: 0.9153
Training Epoch: 23 [21504/50176]	Loss: 0.9535
Training Epoch: 23 [22528/50176]	Loss: 0.9421
Training Epoch: 23 [23552/50176]	Loss: 0.8583
Training Epoch: 23 [24576/50176]	Loss: 0.9638
Training Epoch: 23 [25600/50176]	Loss: 0.9600
Training Epoch: 23 [26624/50176]	Loss: 0.9538
Training Epoch: 23 [27648/50176]	Loss: 0.9111
Training Epoch: 23 [28672/50176]	Loss: 0.9965
Training Epoch: 23 [29696/50176]	Loss: 0.9079
Training Epoch: 23 [30720/50176]	Loss: 0.9605
Training Epoch: 23 [31744/50176]	Loss: 0.9851
Training Epoch: 23 [32768/50176]	Loss: 0.9783
Training Epoch: 23 [33792/50176]	Loss: 1.0153
Training Epoch: 23 [34816/50176]	Loss: 1.0448
Training Epoch: 23 [35840/50176]	Loss: 0.9831
Training Epoch: 23 [36864/50176]	Loss: 0.9486
Training Epoch: 23 [37888/50176]	Loss: 0.9629
Training Epoch: 23 [38912/50176]	Loss: 1.0624
Training Epoch: 23 [39936/50176]	Loss: 1.0399
Training Epoch: 23 [40960/50176]	Loss: 1.0335
Training Epoch: 23 [41984/50176]	Loss: 1.0341
Training Epoch: 23 [43008/50176]	Loss: 0.9351
Training Epoch: 23 [44032/50176]	Loss: 1.0050
Training Epoch: 23 [45056/50176]	Loss: 1.0001
Training Epoch: 23 [46080/50176]	Loss: 1.0365
Training Epoch: 23 [47104/50176]	Loss: 1.0233
Training Epoch: 23 [48128/50176]	Loss: 0.9670
Training Epoch: 23 [49152/50176]	Loss: 0.9801
Training Epoch: 23 [50176/50176]	Loss: 0.9291
2022-12-06 17:00:23.293 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:00:23,311 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.67 energy=462.27
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Up to epoch 24: time=1211.29, energy=165154.60, cost=188564.96
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Expected next epoch: time=1258.01, energy=171830.11, cost=195991.21
2022-12-06 12:00:23,313 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0016, Accuracy: 0.5737
2022-12-06 12:00:23,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:00:23,502 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:00:23.516 [ZeusMonitor] Monitor started.
2022-12-06 17:00:23.516 [ZeusMonitor] Running indefinitely. 2022-12-06 17:00:23.516 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:00:23.516 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 12:01:08,142 [ZeusDataLoader(train)] train epoch 25 done: time=44.82 energy=6354.04
2022-12-06 12:01:08,145 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8523
Training Epoch: 24 [2048/50176]	Loss: 0.7583
Training Epoch: 24 [3072/50176]	Loss: 0.9024
Training Epoch: 24 [4096/50176]	Loss: 0.8401
Training Epoch: 24 [5120/50176]	Loss: 0.8865
Training Epoch: 24 [6144/50176]	Loss: 0.8737
Training Epoch: 24 [7168/50176]	Loss: 0.9296
Training Epoch: 24 [8192/50176]	Loss: 0.8441
Training Epoch: 24 [9216/50176]	Loss: 0.9152
Training Epoch: 24 [10240/50176]	Loss: 0.8832
Training Epoch: 24 [11264/50176]	Loss: 0.8638
Training Epoch: 24 [12288/50176]	Loss: 0.8923
Training Epoch: 24 [13312/50176]	Loss: 0.9226
Training Epoch: 24 [14336/50176]	Loss: 0.8873
Training Epoch: 24 [15360/50176]	Loss: 0.8270
Training Epoch: 24 [16384/50176]	Loss: 0.8262
Training Epoch: 24 [17408/50176]	Loss: 0.9466
Training Epoch: 24 [18432/50176]	Loss: 0.9580
Training Epoch: 24 [19456/50176]	Loss: 0.9507
Training Epoch: 24 [20480/50176]	Loss: 0.9604
Training Epoch: 24 [21504/50176]	Loss: 1.0064
Training Epoch: 24 [22528/50176]	Loss: 1.0259
Training Epoch: 24 [23552/50176]	Loss: 1.0564
Training Epoch: 24 [24576/50176]	Loss: 0.9873
Training Epoch: 24 [25600/50176]	Loss: 1.0308
Training Epoch: 24 [26624/50176]	Loss: 1.0581
Training Epoch: 24 [27648/50176]	Loss: 1.1604
Training Epoch: 24 [28672/50176]	Loss: 1.0604
Training Epoch: 24 [29696/50176]	Loss: 0.9716
Training Epoch: 24 [30720/50176]	Loss: 1.0921
Training Epoch: 24 [31744/50176]	Loss: 1.1230
Training Epoch: 24 [32768/50176]	Loss: 1.0424
Training Epoch: 24 [33792/50176]	Loss: 1.0481
Training Epoch: 24 [34816/50176]	Loss: 1.1380
Training Epoch: 24 [35840/50176]	Loss: 1.0967
Training Epoch: 24 [36864/50176]	Loss: 1.0695
Training Epoch: 24 [37888/50176]	Loss: 1.0571
Training Epoch: 24 [38912/50176]	Loss: 1.0553
Training Epoch: 24 [39936/50176]	Loss: 0.9478
Training Epoch: 24 [40960/50176]	Loss: 1.0021
Training Epoch: 24 [41984/50176]	Loss: 1.0548
Training Epoch: 24 [43008/50176]	Loss: 1.1347
Training Epoch: 24 [44032/50176]	Loss: 0.9893
Training Epoch: 24 [45056/50176]	Loss: 1.0295
Training Epoch: 24 [46080/50176]	Loss: 0.9657
Training Epoch: 24 [47104/50176]	Loss: 1.0924
Training Epoch: 24 [48128/50176]	Loss: 1.1756
Training Epoch: 24 [49152/50176]	Loss: 1.0135
Training Epoch: 24 [50176/50176]	Loss: 1.0091
2022-12-06 17:01:11.954 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:01:12,006 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.85 energy=494.42
2022-12-06 12:01:12,006 [ZeusDataLoader(train)] Up to epoch 25: time=1259.96, energy=172003.07, cost=196248.17
2022-12-06 12:01:12,006 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:01:12,007 [ZeusDataLoader(train)] Expected next epoch: time=1306.69, energy=178678.58, cost=203674.43
2022-12-06 12:01:12,007 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0016, Accuracy: 0.5782
2022-12-06 12:01:12,188 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:01:12,189 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:01:12.191 [ZeusMonitor] Monitor started.
2022-12-06 17:01:12.191 [ZeusMonitor] Running indefinitely. 2022-12-06 17:01:12.191 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:01:12.191 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 12:01:56,393 [ZeusDataLoader(train)] train epoch 26 done: time=44.38 energy=6320.75
2022-12-06 12:01:56,396 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.8650
Training Epoch: 25 [2048/50176]	Loss: 0.8801
Training Epoch: 25 [3072/50176]	Loss: 0.9113
Training Epoch: 25 [4096/50176]	Loss: 0.9089
Training Epoch: 25 [5120/50176]	Loss: 0.8984
Training Epoch: 25 [6144/50176]	Loss: 0.9205
Training Epoch: 25 [7168/50176]	Loss: 0.8502
Training Epoch: 25 [8192/50176]	Loss: 0.9312
Training Epoch: 25 [9216/50176]	Loss: 0.9694
Training Epoch: 25 [10240/50176]	Loss: 0.8582
Training Epoch: 25 [11264/50176]	Loss: 0.8975
Training Epoch: 25 [12288/50176]	Loss: 0.8483
Training Epoch: 25 [13312/50176]	Loss: 0.8768
Training Epoch: 25 [14336/50176]	Loss: 0.9049
Training Epoch: 25 [15360/50176]	Loss: 0.9332
Training Epoch: 25 [16384/50176]	Loss: 0.9561
Training Epoch: 25 [17408/50176]	Loss: 0.8720
Training Epoch: 25 [18432/50176]	Loss: 0.9440
Training Epoch: 25 [19456/50176]	Loss: 0.8734
Training Epoch: 25 [20480/50176]	Loss: 0.9127
Training Epoch: 25 [21504/50176]	Loss: 0.8933
Training Epoch: 25 [22528/50176]	Loss: 0.9560
Training Epoch: 25 [23552/50176]	Loss: 0.9109
Training Epoch: 25 [24576/50176]	Loss: 0.8863
Training Epoch: 25 [25600/50176]	Loss: 0.8282
Training Epoch: 25 [26624/50176]	Loss: 0.9371
Training Epoch: 25 [27648/50176]	Loss: 0.8850
Training Epoch: 25 [28672/50176]	Loss: 0.9241
Training Epoch: 25 [29696/50176]	Loss: 0.9078
Training Epoch: 25 [30720/50176]	Loss: 0.9827
Training Epoch: 25 [31744/50176]	Loss: 0.8526
Training Epoch: 25 [32768/50176]	Loss: 0.9232
Training Epoch: 25 [33792/50176]	Loss: 0.8538
Training Epoch: 25 [34816/50176]	Loss: 0.8985
Training Epoch: 25 [35840/50176]	Loss: 0.9398
Training Epoch: 25 [36864/50176]	Loss: 0.9110
Training Epoch: 25 [37888/50176]	Loss: 0.8854
Training Epoch: 25 [38912/50176]	Loss: 0.9135
Training Epoch: 25 [39936/50176]	Loss: 0.9505
Training Epoch: 25 [40960/50176]	Loss: 0.8514
Training Epoch: 25 [41984/50176]	Loss: 0.9432
Training Epoch: 25 [43008/50176]	Loss: 0.9724
Training Epoch: 25 [44032/50176]	Loss: 0.9381
Training Epoch: 25 [45056/50176]	Loss: 1.0045
Training Epoch: 25 [46080/50176]	Loss: 0.9538
Training Epoch: 25 [47104/50176]	Loss: 0.9972
Training Epoch: 25 [48128/50176]	Loss: 0.9804
Training Epoch: 25 [49152/50176]	Loss: 0.9323
Training Epoch: 25 [50176/50176]	Loss: 0.9950
2022-12-06 17:02:00.176 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:02:00,189 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.78 energy=493.65
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Up to epoch 26: time=1308.12, energy=178817.47, cost=203869.55
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Expected next epoch: time=1354.85, energy=185492.98, cost=211295.80
2022-12-06 12:02:00,190 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0017, Accuracy: 0.5697
2022-12-06 12:02:00,377 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:02:00,378 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:02:00.392 [ZeusMonitor] Monitor started.
2022-12-06 17:02:00.392 [ZeusMonitor] Running indefinitely. 2022-12-06 17:02:00.392 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:02:00.392 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 12:02:44,767 [ZeusDataLoader(train)] train epoch 27 done: time=44.56 energy=6344.97
2022-12-06 12:02:44,774 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.7815
Training Epoch: 26 [2048/50176]	Loss: 0.8182
Training Epoch: 26 [3072/50176]	Loss: 0.8257
Training Epoch: 26 [4096/50176]	Loss: 0.8309
Training Epoch: 26 [5120/50176]	Loss: 0.8155
Training Epoch: 26 [6144/50176]	Loss: 0.8089
Training Epoch: 26 [7168/50176]	Loss: 0.7664
Training Epoch: 26 [8192/50176]	Loss: 0.8067
Training Epoch: 26 [9216/50176]	Loss: 0.8329
Training Epoch: 26 [10240/50176]	Loss: 0.8778
Training Epoch: 26 [11264/50176]	Loss: 0.7994
Training Epoch: 26 [12288/50176]	Loss: 0.8021
Training Epoch: 26 [13312/50176]	Loss: 0.7849
Training Epoch: 26 [14336/50176]	Loss: 0.8180
Training Epoch: 26 [15360/50176]	Loss: 0.7819
Training Epoch: 26 [16384/50176]	Loss: 0.7832
Training Epoch: 26 [17408/50176]	Loss: 0.8209
Training Epoch: 26 [18432/50176]	Loss: 0.8615
Training Epoch: 26 [19456/50176]	Loss: 0.8466
Training Epoch: 26 [20480/50176]	Loss: 0.8060
Training Epoch: 26 [21504/50176]	Loss: 0.8661
Training Epoch: 26 [22528/50176]	Loss: 0.7941
Training Epoch: 26 [23552/50176]	Loss: 0.8338
Training Epoch: 26 [24576/50176]	Loss: 0.8617
Training Epoch: 26 [25600/50176]	Loss: 0.8341
Training Epoch: 26 [26624/50176]	Loss: 0.8647
Training Epoch: 26 [27648/50176]	Loss: 0.8381
Training Epoch: 26 [28672/50176]	Loss: 0.7884
Training Epoch: 26 [29696/50176]	Loss: 0.8604
Training Epoch: 26 [30720/50176]	Loss: 0.9754
Training Epoch: 26 [31744/50176]	Loss: 0.8379
Training Epoch: 26 [32768/50176]	Loss: 0.8700
Training Epoch: 26 [33792/50176]	Loss: 0.8696
Training Epoch: 26 [34816/50176]	Loss: 0.8713
Training Epoch: 26 [35840/50176]	Loss: 0.8621
Training Epoch: 26 [36864/50176]	Loss: 0.8352
Training Epoch: 26 [37888/50176]	Loss: 0.8646
Training Epoch: 26 [38912/50176]	Loss: 0.8348
Training Epoch: 26 [39936/50176]	Loss: 0.9861
Training Epoch: 26 [40960/50176]	Loss: 0.8756
Training Epoch: 26 [41984/50176]	Loss: 0.9251
Training Epoch: 26 [43008/50176]	Loss: 0.8957
Training Epoch: 26 [44032/50176]	Loss: 0.8734
Training Epoch: 26 [45056/50176]	Loss: 0.8639
Training Epoch: 26 [46080/50176]	Loss: 0.9078
Training Epoch: 26 [47104/50176]	Loss: 0.9065
Training Epoch: 26 [48128/50176]	Loss: 0.9339
Training Epoch: 26 [49152/50176]	Loss: 0.8397
Training Epoch: 26 [50176/50176]	Loss: 0.8929
2022-12-06 17:02:48.918 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:02:48,944 [ZeusDataLoader(eval)] eval epoch 27 done: time=4.16 energy=505.77
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Up to epoch 27: time=1356.84, energy=185668.21, cost=211557.69
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Expected next epoch: time=1403.57, energy=192343.72, cost=218983.95
2022-12-06 12:02:48,945 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0016, Accuracy: 0.5764
2022-12-06 12:02:49,155 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:02:49,156 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:02:49.158 [ZeusMonitor] Monitor started.
2022-12-06 17:02:49.158 [ZeusMonitor] Running indefinitely. 2022-12-06 17:02:49.158 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:02:49.158 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 12:03:33,550 [ZeusDataLoader(train)] train epoch 28 done: time=44.60 energy=6339.24
2022-12-06 12:03:33,554 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7236
Training Epoch: 27 [2048/50176]	Loss: 0.7694
Training Epoch: 27 [3072/50176]	Loss: 0.7302
Training Epoch: 27 [4096/50176]	Loss: 0.8191
Training Epoch: 27 [5120/50176]	Loss: 0.7735
Training Epoch: 27 [6144/50176]	Loss: 0.7334
Training Epoch: 27 [7168/50176]	Loss: 0.7281
Training Epoch: 27 [8192/50176]	Loss: 0.7528
Training Epoch: 27 [9216/50176]	Loss: 0.7637
Training Epoch: 27 [10240/50176]	Loss: 0.7587
Training Epoch: 27 [11264/50176]	Loss: 0.7868
Training Epoch: 27 [12288/50176]	Loss: 0.7699
Training Epoch: 27 [13312/50176]	Loss: 0.7691
Training Epoch: 27 [14336/50176]	Loss: 0.7667
Training Epoch: 27 [15360/50176]	Loss: 0.7599
Training Epoch: 27 [16384/50176]	Loss: 0.8061
Training Epoch: 27 [17408/50176]	Loss: 0.7479
Training Epoch: 27 [18432/50176]	Loss: 0.7690
Training Epoch: 27 [19456/50176]	Loss: 0.7663
Training Epoch: 27 [20480/50176]	Loss: 0.7462
Training Epoch: 27 [21504/50176]	Loss: 0.8066
Training Epoch: 27 [22528/50176]	Loss: 0.7826
Training Epoch: 27 [23552/50176]	Loss: 0.7521
Training Epoch: 27 [24576/50176]	Loss: 0.7929
Training Epoch: 27 [25600/50176]	Loss: 0.8300
Training Epoch: 27 [26624/50176]	Loss: 0.8276
Training Epoch: 27 [27648/50176]	Loss: 0.8552
Training Epoch: 27 [28672/50176]	Loss: 0.8085
Training Epoch: 27 [29696/50176]	Loss: 0.8019
Training Epoch: 27 [30720/50176]	Loss: 0.7572
Training Epoch: 27 [31744/50176]	Loss: 0.8431
Training Epoch: 27 [32768/50176]	Loss: 0.7760
Training Epoch: 27 [33792/50176]	Loss: 0.7651
Training Epoch: 27 [34816/50176]	Loss: 0.8183
Training Epoch: 27 [35840/50176]	Loss: 0.8319
Training Epoch: 27 [36864/50176]	Loss: 0.7865
Training Epoch: 27 [37888/50176]	Loss: 0.8199
Training Epoch: 27 [38912/50176]	Loss: 0.7884
Training Epoch: 27 [39936/50176]	Loss: 0.8294
Training Epoch: 27 [40960/50176]	Loss: 0.8052
Training Epoch: 27 [41984/50176]	Loss: 0.8097
Training Epoch: 27 [43008/50176]	Loss: 0.7785
Training Epoch: 27 [44032/50176]	Loss: 0.8811
Training Epoch: 27 [45056/50176]	Loss: 0.8201
Training Epoch: 27 [46080/50176]	Loss: 0.8102
Training Epoch: 27 [47104/50176]	Loss: 0.8943
Training Epoch: 27 [48128/50176]	Loss: 0.8114
Training Epoch: 27 [49152/50176]	Loss: 0.9260
Training Epoch: 27 [50176/50176]	Loss: 0.8879
2022-12-06 17:03:37.364 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:03:37,401 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.84 energy=491.04
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Up to epoch 28: time=1405.28, energy=192498.48, cost=219210.90
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Expected next epoch: time=1452.00, energy=199173.99, cost=226637.16
2022-12-06 12:03:37,403 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0016, Accuracy: 0.5837
2022-12-06 12:03:37,551 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:03:37,551 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:03:37.555 [ZeusMonitor] Monitor started.
2022-12-06 17:03:37.555 [ZeusMonitor] Running indefinitely. 2022-12-06 17:03:37.555 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:03:37.555 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 12:04:21,674 [ZeusDataLoader(train)] train epoch 29 done: time=44.26 energy=6330.28
2022-12-06 12:04:21,678 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.7195
Training Epoch: 28 [2048/50176]	Loss: 0.7447
Training Epoch: 28 [3072/50176]	Loss: 0.7381
Training Epoch: 28 [4096/50176]	Loss: 0.7538
Training Epoch: 28 [5120/50176]	Loss: 0.7151
Training Epoch: 28 [6144/50176]	Loss: 0.6946
Training Epoch: 28 [7168/50176]	Loss: 0.7011
Training Epoch: 28 [8192/50176]	Loss: 0.7352
Training Epoch: 28 [9216/50176]	Loss: 0.7376
Training Epoch: 28 [10240/50176]	Loss: 0.6698
Training Epoch: 28 [11264/50176]	Loss: 0.7047
Training Epoch: 28 [12288/50176]	Loss: 0.7792
Training Epoch: 28 [13312/50176]	Loss: 0.7111
Training Epoch: 28 [14336/50176]	Loss: 0.7342
Training Epoch: 28 [15360/50176]	Loss: 0.7110
Training Epoch: 28 [16384/50176]	Loss: 0.7549
Training Epoch: 28 [17408/50176]	Loss: 0.7377
Training Epoch: 28 [18432/50176]	Loss: 0.6965
Training Epoch: 28 [19456/50176]	Loss: 0.7960
Training Epoch: 28 [20480/50176]	Loss: 0.7552
Training Epoch: 28 [21504/50176]	Loss: 0.7179
Training Epoch: 28 [22528/50176]	Loss: 0.7441
Training Epoch: 28 [23552/50176]	Loss: 0.8067
Training Epoch: 28 [24576/50176]	Loss: 0.6884
Training Epoch: 28 [25600/50176]	Loss: 0.7485
Training Epoch: 28 [26624/50176]	Loss: 0.7281
Training Epoch: 28 [27648/50176]	Loss: 0.7999
Training Epoch: 28 [28672/50176]	Loss: 0.7923
Training Epoch: 28 [29696/50176]	Loss: 0.7613
Training Epoch: 28 [30720/50176]	Loss: 0.7464
Training Epoch: 28 [31744/50176]	Loss: 0.8365
Training Epoch: 28 [32768/50176]	Loss: 0.7690
Training Epoch: 28 [33792/50176]	Loss: 0.7658
Training Epoch: 28 [34816/50176]	Loss: 0.8065
Training Epoch: 28 [35840/50176]	Loss: 0.7722
Training Epoch: 28 [36864/50176]	Loss: 0.7993
Training Epoch: 28 [37888/50176]	Loss: 0.7432
Training Epoch: 28 [38912/50176]	Loss: 0.7498
Training Epoch: 28 [39936/50176]	Loss: 0.8093
Training Epoch: 28 [40960/50176]	Loss: 0.8642
Training Epoch: 28 [41984/50176]	Loss: 0.7843
Training Epoch: 28 [43008/50176]	Loss: 0.7609
Training Epoch: 28 [44032/50176]	Loss: 0.7829
Training Epoch: 28 [45056/50176]	Loss: 0.9436
Training Epoch: 28 [46080/50176]	Loss: 0.7937
Training Epoch: 28 [47104/50176]	Loss: 0.8100
Training Epoch: 28 [48128/50176]	Loss: 0.7387
Training Epoch: 28 [49152/50176]	Loss: 0.8235
Training Epoch: 28 [50176/50176]	Loss: 0.8562
2022-12-06 17:04:25.345 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:04:25,369 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.68 energy=477.13
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Up to epoch 29: time=1453.22, energy=199305.90, cost=226809.95
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Expected next epoch: time=1499.95, energy=205981.41, cost=234236.21
2022-12-06 12:04:25,370 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0016, Accuracy: 0.5829
2022-12-06 12:04:25,572 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:04:25,573 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:04:25.575 [ZeusMonitor] Monitor started.
2022-12-06 17:04:25.575 [ZeusMonitor] Running indefinitely. 2022-12-06 17:04:25.575 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:04:25.575 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 12:05:09,790 [ZeusDataLoader(train)] train epoch 30 done: time=44.41 energy=6314.41
2022-12-06 12:05:09,793 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6738
Training Epoch: 29 [2048/50176]	Loss: 0.7086
Training Epoch: 29 [3072/50176]	Loss: 0.7226
Training Epoch: 29 [4096/50176]	Loss: 0.6859
Training Epoch: 29 [5120/50176]	Loss: 0.7143
Training Epoch: 29 [6144/50176]	Loss: 0.6843
Training Epoch: 29 [7168/50176]	Loss: 0.6525
Training Epoch: 29 [8192/50176]	Loss: 0.6234
Training Epoch: 29 [9216/50176]	Loss: 0.7486
Training Epoch: 29 [10240/50176]	Loss: 0.6966
Training Epoch: 29 [11264/50176]	Loss: 0.7341
Training Epoch: 29 [12288/50176]	Loss: 0.7441
Training Epoch: 29 [13312/50176]	Loss: 0.6633
Training Epoch: 29 [14336/50176]	Loss: 0.6677
Training Epoch: 29 [15360/50176]	Loss: 0.8200
Training Epoch: 29 [16384/50176]	Loss: 0.6996
Training Epoch: 29 [17408/50176]	Loss: 0.7240
Training Epoch: 29 [18432/50176]	Loss: 0.7040
Training Epoch: 29 [19456/50176]	Loss: 0.7649
Training Epoch: 29 [20480/50176]	Loss: 0.7117
Training Epoch: 29 [21504/50176]	Loss: 0.7019
Training Epoch: 29 [22528/50176]	Loss: 0.6595
Training Epoch: 29 [23552/50176]	Loss: 0.6939
Training Epoch: 29 [24576/50176]	Loss: 0.7521
Training Epoch: 29 [25600/50176]	Loss: 0.7033
Training Epoch: 29 [26624/50176]	Loss: 0.6860
Training Epoch: 29 [27648/50176]	Loss: 0.7516
Training Epoch: 29 [28672/50176]	Loss: 0.6960
Training Epoch: 29 [29696/50176]	Loss: 0.6528
Training Epoch: 29 [30720/50176]	Loss: 0.7620
Training Epoch: 29 [31744/50176]	Loss: 0.7195
Training Epoch: 29 [32768/50176]	Loss: 0.7344
Training Epoch: 29 [33792/50176]	Loss: 0.7480
Training Epoch: 29 [34816/50176]	Loss: 0.8667
Training Epoch: 29 [35840/50176]	Loss: 0.6870
Training Epoch: 29 [36864/50176]	Loss: 0.7108
Training Epoch: 29 [37888/50176]	Loss: 0.7417
Training Epoch: 29 [38912/50176]	Loss: 0.7114
Training Epoch: 29 [39936/50176]	Loss: 0.7239
Training Epoch: 29 [40960/50176]	Loss: 0.7940
Training Epoch: 29 [41984/50176]	Loss: 0.7154
Training Epoch: 29 [43008/50176]	Loss: 0.8021
Training Epoch: 29 [44032/50176]	Loss: 0.7773
Training Epoch: 29 [45056/50176]	Loss: 0.7363
Training Epoch: 29 [46080/50176]	Loss: 0.7719
Training Epoch: 29 [47104/50176]	Loss: 0.7700
Training Epoch: 29 [48128/50176]	Loss: 0.7979
Training Epoch: 29 [49152/50176]	Loss: 0.7671
Training Epoch: 29 [50176/50176]	Loss: 0.8526
2022-12-06 17:05:13.582 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:05:13,606 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.81 energy=483.07
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Up to epoch 30: time=1501.44, energy=206103.38, cost=234427.70
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Expected next epoch: time=1548.17, energy=212778.88, cost=241853.96
2022-12-06 12:05:13,608 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0017, Accuracy: 0.5779
2022-12-06 12:05:13,804 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:05:13,805 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:05:13.807 [ZeusMonitor] Monitor started.
2022-12-06 17:05:13.807 [ZeusMonitor] Running indefinitely. 2022-12-06 17:05:13.807 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:05:13.807 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 12:05:58,522 [ZeusDataLoader(train)] train epoch 31 done: time=44.91 energy=6347.97
2022-12-06 12:05:58,526 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7333
Training Epoch: 30 [2048/50176]	Loss: 0.6387
Training Epoch: 30 [3072/50176]	Loss: 0.6722
Training Epoch: 30 [4096/50176]	Loss: 0.6370
Training Epoch: 30 [5120/50176]	Loss: 0.6342
Training Epoch: 30 [6144/50176]	Loss: 0.6548
Training Epoch: 30 [7168/50176]	Loss: 0.6286
Training Epoch: 30 [8192/50176]	Loss: 0.6325
Training Epoch: 30 [9216/50176]	Loss: 0.6689
Training Epoch: 30 [10240/50176]	Loss: 0.6190
Training Epoch: 30 [11264/50176]	Loss: 0.6336
Training Epoch: 30 [12288/50176]	Loss: 0.6740
Training Epoch: 30 [13312/50176]	Loss: 0.6553
Training Epoch: 30 [14336/50176]	Loss: 0.7122
Training Epoch: 30 [15360/50176]	Loss: 0.6481
Training Epoch: 30 [16384/50176]	Loss: 0.6405
Training Epoch: 30 [17408/50176]	Loss: 0.6516
Training Epoch: 30 [18432/50176]	Loss: 0.5789
Training Epoch: 30 [19456/50176]	Loss: 0.6205
Training Epoch: 30 [20480/50176]	Loss: 0.6630
Training Epoch: 30 [21504/50176]	Loss: 0.6480
Training Epoch: 30 [22528/50176]	Loss: 0.6690
Training Epoch: 30 [23552/50176]	Loss: 0.6396
Training Epoch: 30 [24576/50176]	Loss: 0.6935
Training Epoch: 30 [25600/50176]	Loss: 0.6886
Training Epoch: 30 [26624/50176]	Loss: 0.6423
Training Epoch: 30 [27648/50176]	Loss: 0.6964
Training Epoch: 30 [28672/50176]	Loss: 0.7007
Training Epoch: 30 [29696/50176]	Loss: 0.7212
Training Epoch: 30 [30720/50176]	Loss: 0.6998
Training Epoch: 30 [31744/50176]	Loss: 0.6223
Training Epoch: 30 [32768/50176]	Loss: 0.6911
Training Epoch: 30 [33792/50176]	Loss: 0.6798
Training Epoch: 30 [34816/50176]	Loss: 0.6829
Training Epoch: 30 [35840/50176]	Loss: 0.7162
Training Epoch: 30 [36864/50176]	Loss: 0.6994
Training Epoch: 30 [37888/50176]	Loss: 0.7492
Training Epoch: 30 [38912/50176]	Loss: 0.6792
Training Epoch: 30 [39936/50176]	Loss: 0.6924
Training Epoch: 30 [40960/50176]	Loss: 0.7458
Training Epoch: 30 [41984/50176]	Loss: 0.7240
Training Epoch: 30 [43008/50176]	Loss: 0.7754
Training Epoch: 30 [44032/50176]	Loss: 0.7266
Training Epoch: 30 [45056/50176]	Loss: 0.7735
Training Epoch: 30 [46080/50176]	Loss: 0.7576
Training Epoch: 30 [47104/50176]	Loss: 0.6737
Training Epoch: 30 [48128/50176]	Loss: 0.7400
Training Epoch: 30 [49152/50176]	Loss: 0.7822
Training Epoch: 30 [50176/50176]	Loss: 0.8309
2022-12-06 17:06:02.310 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:06:02,348 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.81 energy=486.53
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Up to epoch 31: time=1550.16, energy=212937.88, cost=242107.90
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Expected next epoch: time=1596.89, energy=219613.39, cost=249534.15
2022-12-06 12:06:02,349 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0017, Accuracy: 0.5922
2022-12-06 12:06:02,538 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:06:02,539 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:06:02.554 [ZeusMonitor] Monitor started.
2022-12-06 17:06:02.555 [ZeusMonitor] Running indefinitely. 2022-12-06 17:06:02.555 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:06:02.555 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 12:06:46,887 [ZeusDataLoader(train)] train epoch 32 done: time=44.53 energy=6338.21
2022-12-06 12:06:46,890 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.6106
Training Epoch: 31 [2048/50176]	Loss: 0.5720
Training Epoch: 31 [3072/50176]	Loss: 0.6245
Training Epoch: 31 [4096/50176]	Loss: 0.5914
Training Epoch: 31 [5120/50176]	Loss: 0.6213
Training Epoch: 31 [6144/50176]	Loss: 0.6107
Training Epoch: 31 [7168/50176]	Loss: 0.6271
Training Epoch: 31 [8192/50176]	Loss: 0.6409
Training Epoch: 31 [9216/50176]	Loss: 0.6342
Training Epoch: 31 [10240/50176]	Loss: 0.6439
Training Epoch: 31 [11264/50176]	Loss: 0.5904
Training Epoch: 31 [12288/50176]	Loss: 0.6440
Training Epoch: 31 [13312/50176]	Loss: 0.6962
Training Epoch: 31 [14336/50176]	Loss: 0.5905
Training Epoch: 31 [15360/50176]	Loss: 0.5772
Training Epoch: 31 [16384/50176]	Loss: 0.6108
Training Epoch: 31 [17408/50176]	Loss: 0.6288
Training Epoch: 31 [18432/50176]	Loss: 0.6424
Training Epoch: 31 [19456/50176]	Loss: 0.6297
Training Epoch: 31 [20480/50176]	Loss: 0.6692
Training Epoch: 31 [21504/50176]	Loss: 0.6905
Training Epoch: 31 [22528/50176]	Loss: 0.6054
Training Epoch: 31 [23552/50176]	Loss: 0.6632
Training Epoch: 31 [24576/50176]	Loss: 0.6207
Training Epoch: 31 [25600/50176]	Loss: 0.6488
Training Epoch: 31 [26624/50176]	Loss: 0.7067
Training Epoch: 31 [27648/50176]	Loss: 0.6089
Training Epoch: 31 [28672/50176]	Loss: 0.6448
Training Epoch: 31 [29696/50176]	Loss: 0.7157
Training Epoch: 31 [30720/50176]	Loss: 0.6277
Training Epoch: 31 [31744/50176]	Loss: 0.6704
Training Epoch: 31 [32768/50176]	Loss: 0.6824
Training Epoch: 31 [33792/50176]	Loss: 0.6655
Training Epoch: 31 [34816/50176]	Loss: 0.6543
Training Epoch: 31 [35840/50176]	Loss: 0.6987
Training Epoch: 31 [36864/50176]	Loss: 0.7134
Training Epoch: 31 [37888/50176]	Loss: 0.7166
Training Epoch: 31 [38912/50176]	Loss: 0.6970
Training Epoch: 31 [39936/50176]	Loss: 0.7696
Training Epoch: 31 [40960/50176]	Loss: 0.6626
Training Epoch: 31 [41984/50176]	Loss: 0.6592
Training Epoch: 31 [43008/50176]	Loss: 0.6539
Training Epoch: 31 [44032/50176]	Loss: 0.6477
Training Epoch: 31 [45056/50176]	Loss: 0.7320
Training Epoch: 31 [46080/50176]	Loss: 0.6786
Training Epoch: 31 [47104/50176]	Loss: 0.6989
Training Epoch: 31 [48128/50176]	Loss: 0.7875
Training Epoch: 31 [49152/50176]	Loss: 0.6966
Training Epoch: 31 [50176/50176]	Loss: 0.6594
2022-12-06 17:06:50.636 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:06:50,681 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.78 energy=491.63
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Up to epoch 32: time=1598.47, energy=219767.72, cost=249750.16
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Expected next epoch: time=1645.20, energy=226443.23, cost=257176.41
2022-12-06 12:06:50,682 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5827
2022-12-06 12:06:50,872 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:06:50,872 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:06:50.874 [ZeusMonitor] Monitor started.
2022-12-06 17:06:50.874 [ZeusMonitor] Running indefinitely. 2022-12-06 17:06:50.874 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:06:50.874 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 12:07:35,228 [ZeusDataLoader(train)] train epoch 33 done: time=44.54 energy=6332.27
2022-12-06 12:07:35,231 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.5860
Training Epoch: 32 [2048/50176]	Loss: 0.5307
Training Epoch: 32 [3072/50176]	Loss: 0.6134
Training Epoch: 32 [4096/50176]	Loss: 0.5556
Training Epoch: 32 [5120/50176]	Loss: 0.6033
Training Epoch: 32 [6144/50176]	Loss: 0.6001
Training Epoch: 32 [7168/50176]	Loss: 0.5359
Training Epoch: 32 [8192/50176]	Loss: 0.5704
Training Epoch: 32 [9216/50176]	Loss: 0.5388
Training Epoch: 32 [10240/50176]	Loss: 0.5651
Training Epoch: 32 [11264/50176]	Loss: 0.5890
Training Epoch: 32 [12288/50176]	Loss: 0.6128
Training Epoch: 32 [13312/50176]	Loss: 0.5905
Training Epoch: 32 [14336/50176]	Loss: 0.6108
Training Epoch: 32 [15360/50176]	Loss: 0.5831
Training Epoch: 32 [16384/50176]	Loss: 0.5757
Training Epoch: 32 [17408/50176]	Loss: 0.5640
Training Epoch: 32 [18432/50176]	Loss: 0.5696
Training Epoch: 32 [19456/50176]	Loss: 0.5621
Training Epoch: 32 [20480/50176]	Loss: 0.6020
Training Epoch: 32 [21504/50176]	Loss: 0.6245
Training Epoch: 32 [22528/50176]	Loss: 0.6958
Training Epoch: 32 [23552/50176]	Loss: 0.6127
Training Epoch: 32 [24576/50176]	Loss: 0.5069
Training Epoch: 32 [25600/50176]	Loss: 0.6667
Training Epoch: 32 [26624/50176]	Loss: 0.5917
Training Epoch: 32 [27648/50176]	Loss: 0.5849
Training Epoch: 32 [28672/50176]	Loss: 0.5863
Training Epoch: 32 [29696/50176]	Loss: 0.5829
Training Epoch: 32 [30720/50176]	Loss: 0.5731
Training Epoch: 32 [31744/50176]	Loss: 0.6566
Training Epoch: 32 [32768/50176]	Loss: 0.6045
Training Epoch: 32 [33792/50176]	Loss: 0.6311
Training Epoch: 32 [34816/50176]	Loss: 0.6294
Training Epoch: 32 [35840/50176]	Loss: 0.6362
Training Epoch: 32 [36864/50176]	Loss: 0.6302
Training Epoch: 32 [37888/50176]	Loss: 0.6173
Training Epoch: 32 [38912/50176]	Loss: 0.6296
Training Epoch: 32 [39936/50176]	Loss: 0.6689
Training Epoch: 32 [40960/50176]	Loss: 0.6009
Training Epoch: 32 [41984/50176]	Loss: 0.5850
Training Epoch: 32 [43008/50176]	Loss: 0.6773
Training Epoch: 32 [44032/50176]	Loss: 0.6979
Training Epoch: 32 [45056/50176]	Loss: 0.6121
Training Epoch: 32 [46080/50176]	Loss: 0.6757
Training Epoch: 32 [47104/50176]	Loss: 0.6392
Training Epoch: 32 [48128/50176]	Loss: 0.6344
Training Epoch: 32 [49152/50176]	Loss: 0.7005
Training Epoch: 32 [50176/50176]	Loss: 0.6688
2022-12-06 17:07:39.043 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:07:39,096 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.86 energy=485.39
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Up to epoch 33: time=1646.87, energy=226585.38, cost=257393.53
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Expected next epoch: time=1693.59, energy=233260.88, cost=264819.78
2022-12-06 12:07:39,098 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0017, Accuracy: 0.5884
2022-12-06 12:07:39,308 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:07:39,309 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:07:39.311 [ZeusMonitor] Monitor started.
2022-12-06 17:07:39.311 [ZeusMonitor] Running indefinitely. 2022-12-06 17:07:39.311 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:07:39.311 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 12:08:24,400 [ZeusDataLoader(train)] train epoch 34 done: time=45.29 energy=6400.54
2022-12-06 12:08:24,403 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.5475
Training Epoch: 33 [2048/50176]	Loss: 0.5254
Training Epoch: 33 [3072/50176]	Loss: 0.5564
Training Epoch: 33 [4096/50176]	Loss: 0.5569
Training Epoch: 33 [5120/50176]	Loss: 0.5456
Training Epoch: 33 [6144/50176]	Loss: 0.5404
Training Epoch: 33 [7168/50176]	Loss: 0.6189
Training Epoch: 33 [8192/50176]	Loss: 0.5248
Training Epoch: 33 [9216/50176]	Loss: 0.5437
Training Epoch: 33 [10240/50176]	Loss: 0.5493
Training Epoch: 33 [11264/50176]	Loss: 0.5389
Training Epoch: 33 [12288/50176]	Loss: 0.5335
Training Epoch: 33 [13312/50176]	Loss: 0.6272
Training Epoch: 33 [14336/50176]	Loss: 0.5398
Training Epoch: 33 [15360/50176]	Loss: 0.5768
Training Epoch: 33 [16384/50176]	Loss: 0.5970
Training Epoch: 33 [17408/50176]	Loss: 0.5253
Training Epoch: 33 [18432/50176]	Loss: 0.5826
Training Epoch: 33 [19456/50176]	Loss: 0.5674
Training Epoch: 33 [20480/50176]	Loss: 0.5808
Training Epoch: 33 [21504/50176]	Loss: 0.5988
Training Epoch: 33 [22528/50176]	Loss: 0.5478
Training Epoch: 33 [23552/50176]	Loss: 0.6380
Training Epoch: 33 [24576/50176]	Loss: 0.5710
Training Epoch: 33 [25600/50176]	Loss: 0.5765
Training Epoch: 33 [26624/50176]	Loss: 0.5642
Training Epoch: 33 [27648/50176]	Loss: 0.5639
Training Epoch: 33 [28672/50176]	Loss: 0.5487
Training Epoch: 33 [29696/50176]	Loss: 0.5886
Training Epoch: 33 [30720/50176]	Loss: 0.6197
Training Epoch: 33 [31744/50176]	Loss: 0.5881
Training Epoch: 33 [32768/50176]	Loss: 0.5740
Training Epoch: 33 [33792/50176]	Loss: 0.6867
Training Epoch: 33 [34816/50176]	Loss: 0.6215
Training Epoch: 33 [35840/50176]	Loss: 0.5511
Training Epoch: 33 [36864/50176]	Loss: 0.5931
Training Epoch: 33 [37888/50176]	Loss: 0.5962
Training Epoch: 33 [38912/50176]	Loss: 0.6161
Training Epoch: 33 [39936/50176]	Loss: 0.5977
Training Epoch: 33 [40960/50176]	Loss: 0.5593
Training Epoch: 33 [41984/50176]	Loss: 0.6234
Training Epoch: 33 [43008/50176]	Loss: 0.6062
Training Epoch: 33 [44032/50176]	Loss: 0.6471
Training Epoch: 33 [45056/50176]	Loss: 0.6775
Training Epoch: 33 [46080/50176]	Loss: 0.5763
Training Epoch: 33 [47104/50176]	Loss: 0.6229
Training Epoch: 33 [48128/50176]	Loss: 0.6245
Training Epoch: 33 [49152/50176]	Loss: 0.6085
Training Epoch: 33 [50176/50176]	Loss: 0.6396
2022-12-06 17:08:28.164 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:08:28,196 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.78 energy=475.00
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Up to epoch 34: time=1695.95, energy=233460.91, cost=265125.66
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Expected next epoch: time=1742.67, energy=240136.42, cost=272551.92
2022-12-06 12:08:28,197 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0018, Accuracy: 0.5785
2022-12-06 12:08:28,362 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:08:28,363 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:08:28.364 [ZeusMonitor] Monitor started.
2022-12-06 17:08:28.365 [ZeusMonitor] Running indefinitely. 2022-12-06 17:08:28.365 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:08:28.365 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 12:09:13,555 [ZeusDataLoader(train)] train epoch 35 done: time=45.35 energy=6399.22
2022-12-06 12:09:13,558 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.4784
Training Epoch: 34 [2048/50176]	Loss: 0.4875
Training Epoch: 34 [3072/50176]	Loss: 0.4935
Training Epoch: 34 [4096/50176]	Loss: 0.5091
Training Epoch: 34 [5120/50176]	Loss: 0.5224
Training Epoch: 34 [6144/50176]	Loss: 0.5004
Training Epoch: 34 [7168/50176]	Loss: 0.4702
Training Epoch: 34 [8192/50176]	Loss: 0.5334
Training Epoch: 34 [9216/50176]	Loss: 0.5133
Training Epoch: 34 [10240/50176]	Loss: 0.5668
Training Epoch: 34 [11264/50176]	Loss: 0.5317
Training Epoch: 34 [12288/50176]	Loss: 0.5339
Training Epoch: 34 [13312/50176]	Loss: 0.4974
Training Epoch: 34 [14336/50176]	Loss: 0.4863
Training Epoch: 34 [15360/50176]	Loss: 0.5369
Training Epoch: 34 [16384/50176]	Loss: 0.6396
Training Epoch: 34 [17408/50176]	Loss: 0.5008
Training Epoch: 34 [18432/50176]	Loss: 0.5440
Training Epoch: 34 [19456/50176]	Loss: 0.4616
Training Epoch: 34 [20480/50176]	Loss: 0.5518
Training Epoch: 34 [21504/50176]	Loss: 0.5518
Training Epoch: 34 [22528/50176]	Loss: 0.5799
Training Epoch: 34 [23552/50176]	Loss: 0.5352
Training Epoch: 34 [24576/50176]	Loss: 0.5089
Training Epoch: 34 [25600/50176]	Loss: 0.5513
Training Epoch: 34 [26624/50176]	Loss: 0.5997
Training Epoch: 34 [27648/50176]	Loss: 0.5742
Training Epoch: 34 [28672/50176]	Loss: 0.5601
Training Epoch: 34 [29696/50176]	Loss: 0.5416
Training Epoch: 34 [30720/50176]	Loss: 0.6042
Training Epoch: 34 [31744/50176]	Loss: 0.5387
Training Epoch: 34 [32768/50176]	Loss: 0.6150
Training Epoch: 34 [33792/50176]	Loss: 0.5652
Training Epoch: 34 [34816/50176]	Loss: 0.5530
Training Epoch: 34 [35840/50176]	Loss: 0.5783
Training Epoch: 34 [36864/50176]	Loss: 0.5699
Training Epoch: 34 [37888/50176]	Loss: 0.5572
Training Epoch: 34 [38912/50176]	Loss: 0.4868
Training Epoch: 34 [39936/50176]	Loss: 0.5579
Training Epoch: 34 [40960/50176]	Loss: 0.5486
Training Epoch: 34 [41984/50176]	Loss: 0.5109
Training Epoch: 34 [43008/50176]	Loss: 0.5645
Training Epoch: 34 [44032/50176]	Loss: 0.5817
Training Epoch: 34 [45056/50176]	Loss: 0.5584
Training Epoch: 34 [46080/50176]	Loss: 0.5581
Training Epoch: 34 [47104/50176]	Loss: 0.6355
Training Epoch: 34 [48128/50176]	Loss: 0.5851
Training Epoch: 34 [49152/50176]	Loss: 0.5880
Training Epoch: 34 [50176/50176]	Loss: 0.5423
2022-12-06 17:09:17.271 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:09:17,282 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.72 energy=483.29
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Up to epoch 35: time=1745.01, energy=240343.41, cost=272860.09
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Training done.
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec00+try01+bs1024+lr0.0050000.train.json: {"energy": 240343.41170650077, "time": 1745.0100623509989, "cost": 272860.0863089628, "num_epochs": 35, "reached": true}
Validation Epoch: 34, Average loss: 0.0017, Accuracy: 0.6034
