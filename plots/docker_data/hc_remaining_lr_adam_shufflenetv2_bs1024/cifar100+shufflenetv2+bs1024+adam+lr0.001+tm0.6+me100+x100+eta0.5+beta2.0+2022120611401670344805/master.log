[Zeus Master] Job(cifar100,shufflenetv2,adam,0.6,bs1024~100) x 100
[Zeus Master] Batch sizes: [1024]
[Zeus Master] Learning rates: [0.005, 0.01, 0.05, 0.5]
[run job] Launching job with BS 1024: and LR: 0.005
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec00+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.005']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec00+try01.train.log'
2022-12-06 11:40:08,783 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 11:40:08,783 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 11:40:08,783 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 11:40:08,826 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 11:40:08,826 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 11:40:11,512 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 11:40:11,513 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 11:40:11,698 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:40:11.714 [ZeusMonitor] Monitor started.
2022-12-06 16:40:11.714 [ZeusMonitor] Running indefinitely. 2022-12-06 16:40:11.714 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:40:11.714 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 11:40:12,401 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 11:40:12,401 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 11:40:21,418 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 11:40:54,691 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 11:40:56,433 [ZeusDataLoader(train)] train epoch 1 done: time=44.91 energy=6238.72
2022-12-06 11:40:56,436 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 5.5343
Training Epoch: 0 [3072/50176]	Loss: 5.0683
Training Epoch: 0 [4096/50176]	Loss: 4.7607
Training Epoch: 0 [5120/50176]	Loss: 4.6681
Training Epoch: 0 [6144/50176]	Loss: 4.6611
Training Epoch: 0 [7168/50176]	Loss: 4.6457
Training Epoch: 0 [8192/50176]	Loss: 4.6605
Training Epoch: 0 [9216/50176]	Loss: 4.6269
Training Epoch: 0 [10240/50176]	Loss: 4.5660
Training Epoch: 0 [11264/50176]	Loss: 4.5799
Training Epoch: 0 [12288/50176]	Loss: 4.5745
Training Epoch: 0 [13312/50176]	Loss: 4.5268
Training Epoch: 0 [14336/50176]	Loss: 4.4826
Training Epoch: 0 [15360/50176]	Loss: 4.4759
Training Epoch: 0 [16384/50176]	Loss: 4.5123
Training Epoch: 0 [17408/50176]	Loss: 4.4495
Training Epoch: 0 [18432/50176]	Loss: 4.4586
Training Epoch: 0 [19456/50176]	Loss: 4.4567
Training Epoch: 0 [20480/50176]	Loss: 4.4203
Training Epoch: 0 [21504/50176]	Loss: 4.3561
Training Epoch: 0 [22528/50176]	Loss: 4.3618
Training Epoch: 0 [23552/50176]	Loss: 4.3975
Training Epoch: 0 [24576/50176]	Loss: 4.3250
Training Epoch: 0 [25600/50176]	Loss: 4.3468
Training Epoch: 0 [26624/50176]	Loss: 4.3073
Training Epoch: 0 [27648/50176]	Loss: 4.2892
Training Epoch: 0 [28672/50176]	Loss: 4.2260
Training Epoch: 0 [29696/50176]	Loss: 4.2464
Training Epoch: 0 [30720/50176]	Loss: 4.2757
Training Epoch: 0 [31744/50176]	Loss: 4.2487
Training Epoch: 0 [32768/50176]	Loss: 4.2071
Training Epoch: 0 [33792/50176]	Loss: 4.2670
Training Epoch: 0 [34816/50176]	Loss: 4.1602
Training Epoch: 0 [35840/50176]	Loss: 4.1071
Training Epoch: 0 [36864/50176]	Loss: 4.1265
Training Epoch: 0 [37888/50176]	Loss: 4.1387
Training Epoch: 0 [38912/50176]	Loss: 4.0729
Training Epoch: 0 [39936/50176]	Loss: 4.1678
Training Epoch: 0 [40960/50176]	Loss: 4.0497
Training Epoch: 0 [41984/50176]	Loss: 4.0856
Training Epoch: 0 [43008/50176]	Loss: 4.1665
Training Epoch: 0 [44032/50176]	Loss: 4.0349
Training Epoch: 0 [45056/50176]	Loss: 4.0645
Training Epoch: 0 [46080/50176]	Loss: 4.0508
Training Epoch: 0 [47104/50176]	Loss: 4.0334
Training Epoch: 0 [48128/50176]	Loss: 4.0365
Training Epoch: 0 [49152/50176]	Loss: 4.0259
Training Epoch: 0 [50176/50176]	Loss: 3.9686
2022-12-06 16:41:00.131 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:41:00,186 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.74 energy=467.15
2022-12-06 11:41:00,186 [ZeusDataLoader(train)] Up to epoch 1: time=48.65, energy=6705.86, cost=7610.23
2022-12-06 11:41:00,187 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0041, Accuracy: 0.0505
2022-12-06 11:41:00,388 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:41:00.390 [ZeusMonitor] Monitor started.
2022-12-06 16:41:00.390 [ZeusMonitor] Running indefinitely. 2022-12-06 16:41:00.390 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:41:00.391 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 11:41:01,054 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 11:41:01,054 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 11:41:09,109 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 11:41:43,105 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 11:41:44,763 [ZeusDataLoader(train)] train epoch 2 done: time=44.57 energy=6240.51
2022-12-06 11:41:44,766 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 3.9852
Training Epoch: 1 [2048/50176]	Loss: 3.9422
Training Epoch: 1 [3072/50176]	Loss: 3.9606
Training Epoch: 1 [4096/50176]	Loss: 3.9125
Training Epoch: 1 [5120/50176]	Loss: 3.8919
Training Epoch: 1 [6144/50176]	Loss: 3.9170
Training Epoch: 1 [7168/50176]	Loss: 3.8252
Training Epoch: 1 [8192/50176]	Loss: 3.8158
Training Epoch: 1 [9216/50176]	Loss: 3.9104
Training Epoch: 1 [10240/50176]	Loss: 3.8336
Training Epoch: 1 [11264/50176]	Loss: 3.9169
Training Epoch: 1 [12288/50176]	Loss: 3.8325
Training Epoch: 1 [13312/50176]	Loss: 3.8377
Training Epoch: 1 [14336/50176]	Loss: 3.8871
Training Epoch: 1 [15360/50176]	Loss: 3.8391
Training Epoch: 1 [16384/50176]	Loss: 3.8555
Training Epoch: 1 [17408/50176]	Loss: 3.8231
Training Epoch: 1 [18432/50176]	Loss: 3.7156
Training Epoch: 1 [19456/50176]	Loss: 3.8153
Training Epoch: 1 [20480/50176]	Loss: 3.7289
Training Epoch: 1 [21504/50176]	Loss: 3.7548
Training Epoch: 1 [22528/50176]	Loss: 3.6835
Training Epoch: 1 [23552/50176]	Loss: 3.7174
Training Epoch: 1 [24576/50176]	Loss: 3.6840
Training Epoch: 1 [25600/50176]	Loss: 3.6680
Training Epoch: 1 [26624/50176]	Loss: 3.7296
Training Epoch: 1 [27648/50176]	Loss: 3.6589
Training Epoch: 1 [28672/50176]	Loss: 3.6096
Training Epoch: 1 [29696/50176]	Loss: 3.7284
Training Epoch: 1 [30720/50176]	Loss: 3.6632
Training Epoch: 1 [31744/50176]	Loss: 3.6665
Training Epoch: 1 [32768/50176]	Loss: 3.6077
Training Epoch: 1 [33792/50176]	Loss: 3.7060
Training Epoch: 1 [34816/50176]	Loss: 3.6662
Training Epoch: 1 [35840/50176]	Loss: 3.7077
Training Epoch: 1 [36864/50176]	Loss: 3.6304
Training Epoch: 1 [37888/50176]	Loss: 3.6209
Training Epoch: 1 [38912/50176]	Loss: 3.6299
Training Epoch: 1 [39936/50176]	Loss: 3.6078
Training Epoch: 1 [40960/50176]	Loss: 3.6384
Training Epoch: 1 [41984/50176]	Loss: 3.5418
Training Epoch: 1 [43008/50176]	Loss: 3.6161
Training Epoch: 1 [44032/50176]	Loss: 3.5741
Training Epoch: 1 [45056/50176]	Loss: 3.5546
Training Epoch: 1 [46080/50176]	Loss: 3.5655
Training Epoch: 1 [47104/50176]	Loss: 3.5853
Training Epoch: 1 [48128/50176]	Loss: 3.5694
Training Epoch: 1 [49152/50176]	Loss: 3.5943
Training Epoch: 1 [50176/50176]	Loss: 3.5030
2022-12-06 16:41:48.519 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:41:48,553 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.78 energy=487.72
2022-12-06 11:41:48,553 [ZeusDataLoader(train)] Up to epoch 2: time=97.00, energy=13434.09, cost=15204.83
2022-12-06 11:41:48,554 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0037, Accuracy: 0.1223
2022-12-06 11:41:48,764 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:41:48.766 [ZeusMonitor] Monitor started.
2022-12-06 16:41:48.767 [ZeusMonitor] Running indefinitely. 2022-12-06 16:41:48.767 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:41:48.767 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 11:41:49,459 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 11:41:49,459 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 11:41:58,206 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 11:42:34,716 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 11:42:36,513 [ZeusDataLoader(train)] train epoch 3 done: time=47.95 energy=5772.90
2022-12-06 11:42:36,516 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.4925
Training Epoch: 2 [2048/50176]	Loss: 3.5421
Training Epoch: 2 [3072/50176]	Loss: 3.4328
Training Epoch: 2 [4096/50176]	Loss: 3.4549
Training Epoch: 2 [5120/50176]	Loss: 3.4348
Training Epoch: 2 [6144/50176]	Loss: 3.4339
Training Epoch: 2 [7168/50176]	Loss: 3.4920
Training Epoch: 2 [8192/50176]	Loss: 3.5211
Training Epoch: 2 [9216/50176]	Loss: 3.4571
Training Epoch: 2 [10240/50176]	Loss: 3.3872
Training Epoch: 2 [11264/50176]	Loss: 3.3290
Training Epoch: 2 [12288/50176]	Loss: 3.4471
Training Epoch: 2 [13312/50176]	Loss: 3.3901
Training Epoch: 2 [14336/50176]	Loss: 3.4797
Training Epoch: 2 [15360/50176]	Loss: 3.4467
Training Epoch: 2 [16384/50176]	Loss: 3.4825
Training Epoch: 2 [17408/50176]	Loss: 3.4802
Training Epoch: 2 [18432/50176]	Loss: 3.4636
Training Epoch: 2 [19456/50176]	Loss: 3.4263
Training Epoch: 2 [20480/50176]	Loss: 3.3974
Training Epoch: 2 [21504/50176]	Loss: 3.4837
Training Epoch: 2 [22528/50176]	Loss: 3.4374
Training Epoch: 2 [23552/50176]	Loss: 3.4019
Training Epoch: 2 [24576/50176]	Loss: 3.4825
Training Epoch: 2 [25600/50176]	Loss: 3.4096
Training Epoch: 2 [26624/50176]	Loss: 3.4357
Training Epoch: 2 [27648/50176]	Loss: 3.4491
Training Epoch: 2 [28672/50176]	Loss: 3.4449
Training Epoch: 2 [29696/50176]	Loss: 3.3406
Training Epoch: 2 [30720/50176]	Loss: 3.3509
Training Epoch: 2 [31744/50176]	Loss: 3.3338
Training Epoch: 2 [32768/50176]	Loss: 3.3497
Training Epoch: 2 [33792/50176]	Loss: 3.3892
Training Epoch: 2 [34816/50176]	Loss: 3.3774
Training Epoch: 2 [35840/50176]	Loss: 3.2817
Training Epoch: 2 [36864/50176]	Loss: 3.3599
Training Epoch: 2 [37888/50176]	Loss: 3.3667
Training Epoch: 2 [38912/50176]	Loss: 3.3198
Training Epoch: 2 [39936/50176]	Loss: 3.2880
Training Epoch: 2 [40960/50176]	Loss: 3.3076
Training Epoch: 2 [41984/50176]	Loss: 3.2939
Training Epoch: 2 [43008/50176]	Loss: 3.3045
Training Epoch: 2 [44032/50176]	Loss: 3.2181
Training Epoch: 2 [45056/50176]	Loss: 3.2708
Training Epoch: 2 [46080/50176]	Loss: 3.2594
Training Epoch: 2 [47104/50176]	Loss: 3.2161
Training Epoch: 2 [48128/50176]	Loss: 3.2479
Training Epoch: 2 [49152/50176]	Loss: 3.2443
Training Epoch: 2 [50176/50176]	Loss: 3.1993
2022-12-06 16:42:40.593 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:42:40,644 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.11 energy=463.20
2022-12-06 11:42:40,648 [ZeusDataLoader(train)] Up to epoch 3: time=149.06, energy=19670.19, cost=22878.04
2022-12-06 11:42:40,649 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0033, Accuracy: 0.1899
2022-12-06 11:42:41,098 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 16:42:41.109 [ZeusMonitor] Monitor started.
2022-12-06 16:42:41.109 [ZeusMonitor] Running indefinitely. 2022-12-06 16:42:41.109 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:42:41.109 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 11:42:41,936 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 11:42:41,936 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 11:42:58,577 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 11:44:08,608 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-06 11:44:08,615 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 11:44:10,431 [ZeusDataLoader(train)] train epoch 4 done: time=89.77 energy=8598.48
2022-12-06 11:44:10,435 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.1635
Training Epoch: 3 [2048/50176]	Loss: 3.1339
Training Epoch: 3 [3072/50176]	Loss: 3.1659
Training Epoch: 3 [4096/50176]	Loss: 3.2216
Training Epoch: 3 [5120/50176]	Loss: 3.1559
Training Epoch: 3 [6144/50176]	Loss: 3.1971
Training Epoch: 3 [7168/50176]	Loss: 3.1841
Training Epoch: 3 [8192/50176]	Loss: 3.1995
Training Epoch: 3 [9216/50176]	Loss: 3.0996
Training Epoch: 3 [10240/50176]	Loss: 3.1574
Training Epoch: 3 [11264/50176]	Loss: 3.2253
Training Epoch: 3 [12288/50176]	Loss: 3.1679
Training Epoch: 3 [13312/50176]	Loss: 3.2145
Training Epoch: 3 [14336/50176]	Loss: 3.1009
Training Epoch: 3 [15360/50176]	Loss: 3.1137
Training Epoch: 3 [16384/50176]	Loss: 3.1087
Training Epoch: 3 [17408/50176]	Loss: 3.0932
Training Epoch: 3 [18432/50176]	Loss: 3.1418
Training Epoch: 3 [19456/50176]	Loss: 3.0653
Training Epoch: 3 [20480/50176]	Loss: 3.1112
Training Epoch: 3 [21504/50176]	Loss: 3.1216
Training Epoch: 3 [22528/50176]	Loss: 3.0740
Training Epoch: 3 [23552/50176]	Loss: 3.0686
Training Epoch: 3 [24576/50176]	Loss: 3.0654
Training Epoch: 3 [25600/50176]	Loss: 2.9397
Training Epoch: 3 [26624/50176]	Loss: 3.1387
Training Epoch: 3 [27648/50176]	Loss: 3.1292
Training Epoch: 3 [28672/50176]	Loss: 3.0384
Training Epoch: 3 [29696/50176]	Loss: 3.0652
Training Epoch: 3 [30720/50176]	Loss: 3.0245
Training Epoch: 3 [31744/50176]	Loss: 3.0432
Training Epoch: 3 [32768/50176]	Loss: 2.9858
Training Epoch: 3 [33792/50176]	Loss: 2.9091
Training Epoch: 3 [34816/50176]	Loss: 3.0848
Training Epoch: 3 [35840/50176]	Loss: 2.9487
Training Epoch: 3 [36864/50176]	Loss: 3.0022
Training Epoch: 3 [37888/50176]	Loss: 3.0321
Training Epoch: 3 [38912/50176]	Loss: 3.0885
Training Epoch: 3 [39936/50176]	Loss: 3.0297
Training Epoch: 3 [40960/50176]	Loss: 2.8721
Training Epoch: 3 [41984/50176]	Loss: 3.0220
Training Epoch: 3 [43008/50176]	Loss: 2.8403
Training Epoch: 3 [44032/50176]	Loss: 2.9736
Training Epoch: 3 [45056/50176]	Loss: 2.9257
Training Epoch: 3 [46080/50176]	Loss: 2.9519
Training Epoch: 3 [47104/50176]	Loss: 2.8454
Training Epoch: 3 [48128/50176]	Loss: 3.0942
Training Epoch: 3 [49152/50176]	Loss: 2.9600
Training Epoch: 3 [50176/50176]	Loss: 2.8934
2022-12-06 16:44:14.265 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0050000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 144.6526908887388, "150000": 142.9144590501422, "125000": 122.3746729763121, "100000": 96.26969013202073}, "train_throughput": {"175000": 1.1426061331830712, "150000": 1.1181391463369061, "125000": 1.0411058844569772, "100000": 0.5428501950648409}, "eval_power": {"175000": 122.91663523083511, "150000": 129.06686853531815, "125000": 112.79114027828794}, "eval_throughput": {"175000": 2.6032730606481405, "150000": 2.6463149332718254, "125000": 2.435059632683371}, "optimal_pl": 175000}
2022-12-06 11:44:14,286 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.84 energy=472.16
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Up to epoch 4: time=242.68, energy=28740.83, cost=35604.63
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:44:14,286 [ZeusDataLoader(train)] Expected next epoch: time=289.40, energy=35416.34, cost=43030.88
2022-12-06 11:44:14,288 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0029, Accuracy: 0.2505
2022-12-06 11:44:14,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:44:14,502 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:44:14.504 [ZeusMonitor] Monitor started.
2022-12-06 16:44:14.504 [ZeusMonitor] Running indefinitely. 2022-12-06 16:44:14.504 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:44:14.504 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 11:44:58,679 [ZeusDataLoader(train)] train epoch 5 done: time=44.38 energy=6272.47
2022-12-06 11:44:58,682 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 2.9563
Training Epoch: 4 [2048/50176]	Loss: 2.8645
Training Epoch: 4 [3072/50176]	Loss: 2.7914
Training Epoch: 4 [4096/50176]	Loss: 2.8467
Training Epoch: 4 [5120/50176]	Loss: 2.8062
Training Epoch: 4 [6144/50176]	Loss: 2.8976
Training Epoch: 4 [7168/50176]	Loss: 2.8345
Training Epoch: 4 [8192/50176]	Loss: 2.8761
Training Epoch: 4 [9216/50176]	Loss: 2.8755
Training Epoch: 4 [10240/50176]	Loss: 2.8379
Training Epoch: 4 [11264/50176]	Loss: 2.8331
Training Epoch: 4 [12288/50176]	Loss: 2.8272
Training Epoch: 4 [13312/50176]	Loss: 2.8075
Training Epoch: 4 [14336/50176]	Loss: 2.9049
Training Epoch: 4 [15360/50176]	Loss: 2.8613
Training Epoch: 4 [16384/50176]	Loss: 2.7548
Training Epoch: 4 [17408/50176]	Loss: 2.8338
Training Epoch: 4 [18432/50176]	Loss: 2.8447
Training Epoch: 4 [19456/50176]	Loss: 2.8649
Training Epoch: 4 [20480/50176]	Loss: 2.8132
Training Epoch: 4 [21504/50176]	Loss: 2.8629
Training Epoch: 4 [22528/50176]	Loss: 2.7166
Training Epoch: 4 [23552/50176]	Loss: 2.7309
Training Epoch: 4 [24576/50176]	Loss: 2.7419
Training Epoch: 4 [25600/50176]	Loss: 2.7595
Training Epoch: 4 [26624/50176]	Loss: 2.6967
Training Epoch: 4 [27648/50176]	Loss: 2.7835
Training Epoch: 4 [28672/50176]	Loss: 2.7091
Training Epoch: 4 [29696/50176]	Loss: 2.8265
Training Epoch: 4 [30720/50176]	Loss: 2.7993
Training Epoch: 4 [31744/50176]	Loss: 2.7171
Training Epoch: 4 [32768/50176]	Loss: 2.7843
Training Epoch: 4 [33792/50176]	Loss: 2.7740
Training Epoch: 4 [34816/50176]	Loss: 2.6621
Training Epoch: 4 [35840/50176]	Loss: 2.7555
Training Epoch: 4 [36864/50176]	Loss: 2.7142
Training Epoch: 4 [37888/50176]	Loss: 2.9461
Training Epoch: 4 [38912/50176]	Loss: 2.7422
Training Epoch: 4 [39936/50176]	Loss: 2.6894
Training Epoch: 4 [40960/50176]	Loss: 2.6750
Training Epoch: 4 [41984/50176]	Loss: 2.5978
Training Epoch: 4 [43008/50176]	Loss: 2.7106
Training Epoch: 4 [44032/50176]	Loss: 2.6261
Training Epoch: 4 [45056/50176]	Loss: 2.6492
Training Epoch: 4 [46080/50176]	Loss: 2.8002
Training Epoch: 4 [47104/50176]	Loss: 2.7616
Training Epoch: 4 [48128/50176]	Loss: 2.7518
Training Epoch: 4 [49152/50176]	Loss: 2.7479
Training Epoch: 4 [50176/50176]	Loss: 2.8066
2022-12-06 16:45:02.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:45:02,374 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.68 energy=473.64
2022-12-06 11:45:02,374 [ZeusDataLoader(train)] Up to epoch 5: time=290.74, energy=35486.94, cost=43183.57
2022-12-06 11:45:02,375 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:45:02,375 [ZeusDataLoader(train)] Expected next epoch: time=337.47, energy=42162.45, cost=50609.83
2022-12-06 11:45:02,376 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0027, Accuracy: 0.2879
2022-12-06 11:45:02,567 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:45:02,568 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:45:02.580 [ZeusMonitor] Monitor started.
2022-12-06 16:45:02.580 [ZeusMonitor] Running indefinitely. 2022-12-06 16:45:02.580 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:45:02.580 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 11:45:47,067 [ZeusDataLoader(train)] train epoch 6 done: time=44.68 energy=6332.24
2022-12-06 11:45:47,071 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.5677
Training Epoch: 5 [2048/50176]	Loss: 2.6005
Training Epoch: 5 [3072/50176]	Loss: 2.7070
Training Epoch: 5 [4096/50176]	Loss: 2.5873
Training Epoch: 5 [5120/50176]	Loss: 2.5484
Training Epoch: 5 [6144/50176]	Loss: 2.6412
Training Epoch: 5 [7168/50176]	Loss: 2.5366
Training Epoch: 5 [8192/50176]	Loss: 2.5814
Training Epoch: 5 [9216/50176]	Loss: 2.5396
Training Epoch: 5 [10240/50176]	Loss: 2.6339
Training Epoch: 5 [11264/50176]	Loss: 2.6634
Training Epoch: 5 [12288/50176]	Loss: 2.4816
Training Epoch: 5 [13312/50176]	Loss: 2.6559
Training Epoch: 5 [14336/50176]	Loss: 2.5837
Training Epoch: 5 [15360/50176]	Loss: 2.6468
Training Epoch: 5 [16384/50176]	Loss: 2.5686
Training Epoch: 5 [17408/50176]	Loss: 2.6002
Training Epoch: 5 [18432/50176]	Loss: 2.5054
Training Epoch: 5 [19456/50176]	Loss: 2.6110
Training Epoch: 5 [20480/50176]	Loss: 2.6170
Training Epoch: 5 [21504/50176]	Loss: 2.5320
Training Epoch: 5 [22528/50176]	Loss: 2.5869
Training Epoch: 5 [23552/50176]	Loss: 2.5656
Training Epoch: 5 [24576/50176]	Loss: 2.5869
Training Epoch: 5 [25600/50176]	Loss: 2.5462
Training Epoch: 5 [26624/50176]	Loss: 2.5166
Training Epoch: 5 [27648/50176]	Loss: 2.4939
Training Epoch: 5 [28672/50176]	Loss: 2.5762
Training Epoch: 5 [29696/50176]	Loss: 2.5581
Training Epoch: 5 [30720/50176]	Loss: 2.5231
Training Epoch: 5 [31744/50176]	Loss: 2.5526
Training Epoch: 5 [32768/50176]	Loss: 2.5186
Training Epoch: 5 [33792/50176]	Loss: 2.5165
Training Epoch: 5 [34816/50176]	Loss: 2.5421
Training Epoch: 5 [35840/50176]	Loss: 2.5978
Training Epoch: 5 [36864/50176]	Loss: 2.4338
Training Epoch: 5 [37888/50176]	Loss: 2.4625
Training Epoch: 5 [38912/50176]	Loss: 2.5189
Training Epoch: 5 [39936/50176]	Loss: 2.5471
Training Epoch: 5 [40960/50176]	Loss: 2.3983
Training Epoch: 5 [41984/50176]	Loss: 2.5359
Training Epoch: 5 [43008/50176]	Loss: 2.5070
Training Epoch: 5 [44032/50176]	Loss: 2.4775
Training Epoch: 5 [45056/50176]	Loss: 2.6054
Training Epoch: 5 [46080/50176]	Loss: 2.3548
Training Epoch: 5 [47104/50176]	Loss: 2.4918
Training Epoch: 5 [48128/50176]	Loss: 2.5138
Training Epoch: 5 [49152/50176]	Loss: 2.5466
Training Epoch: 5 [50176/50176]	Loss: 2.4548
2022-12-06 16:45:50.892 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:45:50,911 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.83 energy=480.81
2022-12-06 11:45:50,911 [ZeusDataLoader(train)] Up to epoch 6: time=339.26, energy=42299.99, cost=50835.29
2022-12-06 11:45:50,912 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:45:50,912 [ZeusDataLoader(train)] Expected next epoch: time=385.99, energy=48975.50, cost=58261.55
2022-12-06 11:45:50,913 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0024, Accuracy: 0.3559
2022-12-06 11:45:51,102 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:45:51,103 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:45:51.117 [ZeusMonitor] Monitor started.
2022-12-06 16:45:51.117 [ZeusMonitor] Running indefinitely. 2022-12-06 16:45:51.117 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:45:51.117 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 11:46:35,688 [ZeusDataLoader(train)] train epoch 7 done: time=44.77 energy=6358.26
2022-12-06 11:46:35,691 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.3357
Training Epoch: 6 [2048/50176]	Loss: 2.3671
Training Epoch: 6 [3072/50176]	Loss: 2.4505
Training Epoch: 6 [4096/50176]	Loss: 2.3816
Training Epoch: 6 [5120/50176]	Loss: 2.3584
Training Epoch: 6 [6144/50176]	Loss: 2.3823
Training Epoch: 6 [7168/50176]	Loss: 2.4110
Training Epoch: 6 [8192/50176]	Loss: 2.3418
Training Epoch: 6 [9216/50176]	Loss: 2.4598
Training Epoch: 6 [10240/50176]	Loss: 2.4201
Training Epoch: 6 [11264/50176]	Loss: 2.3429
Training Epoch: 6 [12288/50176]	Loss: 2.4180
Training Epoch: 6 [13312/50176]	Loss: 2.3562
Training Epoch: 6 [14336/50176]	Loss: 2.3558
Training Epoch: 6 [15360/50176]	Loss: 2.2759
Training Epoch: 6 [16384/50176]	Loss: 2.4105
Training Epoch: 6 [17408/50176]	Loss: 2.3137
Training Epoch: 6 [18432/50176]	Loss: 2.3756
Training Epoch: 6 [19456/50176]	Loss: 2.3177
Training Epoch: 6 [20480/50176]	Loss: 2.4270
Training Epoch: 6 [21504/50176]	Loss: 2.4025
Training Epoch: 6 [22528/50176]	Loss: 2.3718
Training Epoch: 6 [23552/50176]	Loss: 2.3543
Training Epoch: 6 [24576/50176]	Loss: 2.3550
Training Epoch: 6 [25600/50176]	Loss: 2.2180
Training Epoch: 6 [26624/50176]	Loss: 2.3741
Training Epoch: 6 [27648/50176]	Loss: 2.2760
Training Epoch: 6 [28672/50176]	Loss: 2.2029
Training Epoch: 6 [29696/50176]	Loss: 2.2882
Training Epoch: 6 [30720/50176]	Loss: 2.3100
Training Epoch: 6 [31744/50176]	Loss: 2.2855
Training Epoch: 6 [32768/50176]	Loss: 2.3051
Training Epoch: 6 [33792/50176]	Loss: 2.3301
Training Epoch: 6 [34816/50176]	Loss: 2.3659
Training Epoch: 6 [35840/50176]	Loss: 2.3249
Training Epoch: 6 [36864/50176]	Loss: 2.4451
Training Epoch: 6 [37888/50176]	Loss: 2.3794
Training Epoch: 6 [38912/50176]	Loss: 2.3747
Training Epoch: 6 [39936/50176]	Loss: 2.3546
Training Epoch: 6 [40960/50176]	Loss: 2.3183
Training Epoch: 6 [41984/50176]	Loss: 2.3316
Training Epoch: 6 [43008/50176]	Loss: 2.2957
Training Epoch: 6 [44032/50176]	Loss: 2.2782
Training Epoch: 6 [45056/50176]	Loss: 2.3056
Training Epoch: 6 [46080/50176]	Loss: 2.3478
Training Epoch: 6 [47104/50176]	Loss: 2.2943
Training Epoch: 6 [48128/50176]	Loss: 2.2935
Training Epoch: 6 [49152/50176]	Loss: 2.2404
Training Epoch: 6 [50176/50176]	Loss: 2.2620
2022-12-06 16:46:39.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:46:39,391 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.69 energy=480.48
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Up to epoch 7: time=387.72, energy=49138.73, cost=58494.85
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:46:39,391 [ZeusDataLoader(train)] Expected next epoch: time=434.45, energy=55814.24, cost=65921.11
2022-12-06 11:46:39,392 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0023, Accuracy: 0.3716
2022-12-06 11:46:39,569 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:46:39,569 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:46:39.583 [ZeusMonitor] Monitor started.
2022-12-06 16:46:39.584 [ZeusMonitor] Running indefinitely. 2022-12-06 16:46:39.584 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:46:39.584 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 11:47:23,706 [ZeusDataLoader(train)] train epoch 8 done: time=44.31 energy=6323.50
2022-12-06 11:47:23,709 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.2447
Training Epoch: 7 [2048/50176]	Loss: 2.1501
Training Epoch: 7 [3072/50176]	Loss: 2.1443
Training Epoch: 7 [4096/50176]	Loss: 2.1689
Training Epoch: 7 [5120/50176]	Loss: 2.1987
Training Epoch: 7 [6144/50176]	Loss: 2.1249
Training Epoch: 7 [7168/50176]	Loss: 2.2078
Training Epoch: 7 [8192/50176]	Loss: 2.1730
Training Epoch: 7 [9216/50176]	Loss: 2.0388
Training Epoch: 7 [10240/50176]	Loss: 2.1536
Training Epoch: 7 [11264/50176]	Loss: 2.1076
Training Epoch: 7 [12288/50176]	Loss: 2.1612
Training Epoch: 7 [13312/50176]	Loss: 2.1903
Training Epoch: 7 [14336/50176]	Loss: 2.3065
Training Epoch: 7 [15360/50176]	Loss: 2.1935
Training Epoch: 7 [16384/50176]	Loss: 2.1547
Training Epoch: 7 [17408/50176]	Loss: 2.2089
Training Epoch: 7 [18432/50176]	Loss: 2.1230
Training Epoch: 7 [19456/50176]	Loss: 2.1660
Training Epoch: 7 [20480/50176]	Loss: 2.2164
Training Epoch: 7 [21504/50176]	Loss: 2.2410
Training Epoch: 7 [22528/50176]	Loss: 2.1716
Training Epoch: 7 [23552/50176]	Loss: 2.1699
Training Epoch: 7 [24576/50176]	Loss: 2.1307
Training Epoch: 7 [25600/50176]	Loss: 2.1717
Training Epoch: 7 [26624/50176]	Loss: 2.1883
Training Epoch: 7 [27648/50176]	Loss: 2.2179
Training Epoch: 7 [28672/50176]	Loss: 2.0747
Training Epoch: 7 [29696/50176]	Loss: 2.1419
Training Epoch: 7 [30720/50176]	Loss: 2.1444
Training Epoch: 7 [31744/50176]	Loss: 2.1775
Training Epoch: 7 [32768/50176]	Loss: 2.0547
Training Epoch: 7 [33792/50176]	Loss: 2.1481
Training Epoch: 7 [34816/50176]	Loss: 2.1691
Training Epoch: 7 [35840/50176]	Loss: 2.0901
Training Epoch: 7 [36864/50176]	Loss: 2.0101
Training Epoch: 7 [37888/50176]	Loss: 2.0831
Training Epoch: 7 [38912/50176]	Loss: 2.1746
Training Epoch: 7 [39936/50176]	Loss: 2.1936
Training Epoch: 7 [40960/50176]	Loss: 2.1621
Training Epoch: 7 [41984/50176]	Loss: 2.0431
Training Epoch: 7 [43008/50176]	Loss: 2.0515
Training Epoch: 7 [44032/50176]	Loss: 2.1115
Training Epoch: 7 [45056/50176]	Loss: 2.1368
Training Epoch: 7 [46080/50176]	Loss: 2.1878
Training Epoch: 7 [47104/50176]	Loss: 2.0753
Training Epoch: 7 [48128/50176]	Loss: 2.0887
Training Epoch: 7 [49152/50176]	Loss: 2.1865
Training Epoch: 7 [50176/50176]	Loss: 2.0520
2022-12-06 16:47:27.442 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:47:27,480 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.76 energy=477.00
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Up to epoch 8: time=435.79, energy=55939.23, cost=66101.11
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:47:27,481 [ZeusDataLoader(train)] Expected next epoch: time=482.51, energy=62614.74, cost=73527.37
2022-12-06 11:47:27,482 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0022, Accuracy: 0.4112
2022-12-06 11:47:27,673 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:47:27,674 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:47:27.688 [ZeusMonitor] Monitor started.
2022-12-06 16:47:27.688 [ZeusMonitor] Running indefinitely. 2022-12-06 16:47:27.688 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:47:27.688 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 11:48:12,492 [ZeusDataLoader(train)] train epoch 9 done: time=45.00 energy=6376.64
2022-12-06 11:48:12,495 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.1241
Training Epoch: 8 [2048/50176]	Loss: 2.0853
Training Epoch: 8 [3072/50176]	Loss: 2.0883
Training Epoch: 8 [4096/50176]	Loss: 2.0447
Training Epoch: 8 [5120/50176]	Loss: 1.9784
Training Epoch: 8 [6144/50176]	Loss: 2.0387
Training Epoch: 8 [7168/50176]	Loss: 2.0607
Training Epoch: 8 [8192/50176]	Loss: 2.0438
Training Epoch: 8 [9216/50176]	Loss: 1.9998
Training Epoch: 8 [10240/50176]	Loss: 2.0368
Training Epoch: 8 [11264/50176]	Loss: 2.0359
Training Epoch: 8 [12288/50176]	Loss: 2.0569
Training Epoch: 8 [13312/50176]	Loss: 2.0523
Training Epoch: 8 [14336/50176]	Loss: 2.0321
Training Epoch: 8 [15360/50176]	Loss: 2.1113
Training Epoch: 8 [16384/50176]	Loss: 2.0021
Training Epoch: 8 [17408/50176]	Loss: 2.1305
Training Epoch: 8 [18432/50176]	Loss: 2.0708
Training Epoch: 8 [19456/50176]	Loss: 1.9875
Training Epoch: 8 [20480/50176]	Loss: 2.0000
Training Epoch: 8 [21504/50176]	Loss: 1.9350
Training Epoch: 8 [22528/50176]	Loss: 2.0000
Training Epoch: 8 [23552/50176]	Loss: 2.0227
Training Epoch: 8 [24576/50176]	Loss: 2.0609
Training Epoch: 8 [25600/50176]	Loss: 2.0436
Training Epoch: 8 [26624/50176]	Loss: 2.0294
Training Epoch: 8 [27648/50176]	Loss: 1.9460
Training Epoch: 8 [28672/50176]	Loss: 2.0687
Training Epoch: 8 [29696/50176]	Loss: 2.0043
Training Epoch: 8 [30720/50176]	Loss: 2.0190
Training Epoch: 8 [31744/50176]	Loss: 1.9463
Training Epoch: 8 [32768/50176]	Loss: 1.9775
Training Epoch: 8 [33792/50176]	Loss: 2.1205
Training Epoch: 8 [34816/50176]	Loss: 2.0009
Training Epoch: 8 [35840/50176]	Loss: 2.0425
Training Epoch: 8 [36864/50176]	Loss: 2.0144
Training Epoch: 8 [37888/50176]	Loss: 2.0492
Training Epoch: 8 [38912/50176]	Loss: 1.9767
Training Epoch: 8 [39936/50176]	Loss: 2.1177
Training Epoch: 8 [40960/50176]	Loss: 2.0151
Training Epoch: 8 [41984/50176]	Loss: 2.0321
Training Epoch: 8 [43008/50176]	Loss: 1.9751
Training Epoch: 8 [44032/50176]	Loss: 2.0590
Training Epoch: 8 [45056/50176]	Loss: 2.0824
Training Epoch: 8 [46080/50176]	Loss: 1.9870
Training Epoch: 8 [47104/50176]	Loss: 2.0677
Training Epoch: 8 [48128/50176]	Loss: 1.9268
Training Epoch: 8 [49152/50176]	Loss: 2.0137
Training Epoch: 8 [50176/50176]	Loss: 1.9713
2022-12-06 16:48:16.360 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:48:16,370 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.87 energy=475.70
2022-12-06 11:48:16,370 [ZeusDataLoader(train)] Up to epoch 9: time=484.66, energy=62791.56, cost=73803.27
2022-12-06 11:48:16,371 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:48:16,371 [ZeusDataLoader(train)] Expected next epoch: time=531.38, energy=69467.07, cost=81229.52
2022-12-06 11:48:16,372 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0020, Accuracy: 0.4342
2022-12-06 11:48:16,566 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:48:16,566 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:48:16.568 [ZeusMonitor] Monitor started.
2022-12-06 16:48:16.568 [ZeusMonitor] Running indefinitely. 2022-12-06 16:48:16.568 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:48:16.568 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 11:49:01,888 [ZeusDataLoader(train)] train epoch 10 done: time=45.51 energy=6409.30
2022-12-06 11:49:01,891 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 1.9041
Training Epoch: 9 [2048/50176]	Loss: 1.9819
Training Epoch: 9 [3072/50176]	Loss: 1.9942
Training Epoch: 9 [4096/50176]	Loss: 1.8659
Training Epoch: 9 [5120/50176]	Loss: 2.0097
Training Epoch: 9 [6144/50176]	Loss: 1.8342
Training Epoch: 9 [7168/50176]	Loss: 1.9558
Training Epoch: 9 [8192/50176]	Loss: 1.9092
Training Epoch: 9 [9216/50176]	Loss: 1.9199
Training Epoch: 9 [10240/50176]	Loss: 1.8773
Training Epoch: 9 [11264/50176]	Loss: 1.9808
Training Epoch: 9 [12288/50176]	Loss: 1.9404
Training Epoch: 9 [13312/50176]	Loss: 1.8954
Training Epoch: 9 [14336/50176]	Loss: 1.9277
Training Epoch: 9 [15360/50176]	Loss: 1.9483
Training Epoch: 9 [16384/50176]	Loss: 1.9439
Training Epoch: 9 [17408/50176]	Loss: 1.9100
Training Epoch: 9 [18432/50176]	Loss: 1.9229
Training Epoch: 9 [19456/50176]	Loss: 1.8565
Training Epoch: 9 [20480/50176]	Loss: 1.9218
Training Epoch: 9 [21504/50176]	Loss: 1.8983
Training Epoch: 9 [22528/50176]	Loss: 1.8631
Training Epoch: 9 [23552/50176]	Loss: 1.8835
Training Epoch: 9 [24576/50176]	Loss: 1.9052
Training Epoch: 9 [25600/50176]	Loss: 1.8447
Training Epoch: 9 [26624/50176]	Loss: 1.8753
Training Epoch: 9 [27648/50176]	Loss: 2.0149
Training Epoch: 9 [28672/50176]	Loss: 1.9160
Training Epoch: 9 [29696/50176]	Loss: 1.9408
Training Epoch: 9 [30720/50176]	Loss: 1.8483
Training Epoch: 9 [31744/50176]	Loss: 1.9183
Training Epoch: 9 [32768/50176]	Loss: 1.9016
Training Epoch: 9 [33792/50176]	Loss: 1.8297
Training Epoch: 9 [34816/50176]	Loss: 1.9257
Training Epoch: 9 [35840/50176]	Loss: 1.8827
Training Epoch: 9 [36864/50176]	Loss: 1.8773
Training Epoch: 9 [37888/50176]	Loss: 1.8989
Training Epoch: 9 [38912/50176]	Loss: 1.9278
Training Epoch: 9 [39936/50176]	Loss: 1.8659
Training Epoch: 9 [40960/50176]	Loss: 1.8891
Training Epoch: 9 [41984/50176]	Loss: 1.8113
Training Epoch: 9 [43008/50176]	Loss: 1.9216
Training Epoch: 9 [44032/50176]	Loss: 1.8892
Training Epoch: 9 [45056/50176]	Loss: 1.8015
Training Epoch: 9 [46080/50176]	Loss: 1.8068
Training Epoch: 9 [47104/50176]	Loss: 1.8425
Training Epoch: 9 [48128/50176]	Loss: 1.8303
Training Epoch: 9 [49152/50176]	Loss: 1.8374
Training Epoch: 9 [50176/50176]	Loss: 1.8139
2022-12-06 16:49:05.701 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:49:05,738 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.84 energy=486.09
2022-12-06 11:49:05,738 [ZeusDataLoader(train)] Up to epoch 10: time=534.00, energy=69686.95, cost=81568.84
2022-12-06 11:49:05,739 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:49:05,739 [ZeusDataLoader(train)] Expected next epoch: time=580.73, energy=76362.46, cost=88995.09
2022-12-06 11:49:05,740 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0020, Accuracy: 0.4418
2022-12-06 11:49:05,922 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:49:05,923 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:49:05.937 [ZeusMonitor] Monitor started.
2022-12-06 16:49:05.937 [ZeusMonitor] Running indefinitely. 2022-12-06 16:49:05.937 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:49:05.937 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 11:49:51,211 [ZeusDataLoader(train)] train epoch 11 done: time=45.46 energy=6406.70
2022-12-06 11:49:51,214 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.8527
Training Epoch: 10 [2048/50176]	Loss: 1.7677
Training Epoch: 10 [3072/50176]	Loss: 1.7478
Training Epoch: 10 [4096/50176]	Loss: 1.8399
Training Epoch: 10 [5120/50176]	Loss: 1.7764
Training Epoch: 10 [6144/50176]	Loss: 1.8363
Training Epoch: 10 [7168/50176]	Loss: 1.7848
Training Epoch: 10 [8192/50176]	Loss: 1.7203
Training Epoch: 10 [9216/50176]	Loss: 1.7184
Training Epoch: 10 [10240/50176]	Loss: 1.6559
Training Epoch: 10 [11264/50176]	Loss: 1.8817
Training Epoch: 10 [12288/50176]	Loss: 1.7081
Training Epoch: 10 [13312/50176]	Loss: 1.8553
Training Epoch: 10 [14336/50176]	Loss: 1.8783
Training Epoch: 10 [15360/50176]	Loss: 1.8235
Training Epoch: 10 [16384/50176]	Loss: 1.8235
Training Epoch: 10 [17408/50176]	Loss: 1.8372
Training Epoch: 10 [18432/50176]	Loss: 1.7293
Training Epoch: 10 [19456/50176]	Loss: 1.7910
Training Epoch: 10 [20480/50176]	Loss: 1.7401
Training Epoch: 10 [21504/50176]	Loss: 1.7961
Training Epoch: 10 [22528/50176]	Loss: 1.7561
Training Epoch: 10 [23552/50176]	Loss: 1.7476
Training Epoch: 10 [24576/50176]	Loss: 1.8035
Training Epoch: 10 [25600/50176]	Loss: 1.7452
Training Epoch: 10 [26624/50176]	Loss: 1.7356
Training Epoch: 10 [27648/50176]	Loss: 1.7489
Training Epoch: 10 [28672/50176]	Loss: 1.8624
Training Epoch: 10 [29696/50176]	Loss: 1.9023
Training Epoch: 10 [30720/50176]	Loss: 1.7400
Training Epoch: 10 [31744/50176]	Loss: 1.8558
Training Epoch: 10 [32768/50176]	Loss: 1.7755
Training Epoch: 10 [33792/50176]	Loss: 1.7514
Training Epoch: 10 [34816/50176]	Loss: 1.8326
Training Epoch: 10 [35840/50176]	Loss: 1.9035
Training Epoch: 10 [36864/50176]	Loss: 1.8262
Training Epoch: 10 [37888/50176]	Loss: 1.6934
Training Epoch: 10 [38912/50176]	Loss: 1.7245
Training Epoch: 10 [39936/50176]	Loss: 1.9098
Training Epoch: 10 [40960/50176]	Loss: 1.6865
Training Epoch: 10 [41984/50176]	Loss: 1.7042
Training Epoch: 10 [43008/50176]	Loss: 1.8538
Training Epoch: 10 [44032/50176]	Loss: 1.8035
Training Epoch: 10 [45056/50176]	Loss: 1.7269
Training Epoch: 10 [46080/50176]	Loss: 1.6445
Training Epoch: 10 [47104/50176]	Loss: 1.8462
Training Epoch: 10 [48128/50176]	Loss: 1.7346
Training Epoch: 10 [49152/50176]	Loss: 1.7687
Training Epoch: 10 [50176/50176]	Loss: 1.8029
2022-12-06 16:49:55.143 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:49:55,164 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.94 energy=493.25
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Up to epoch 11: time=583.41, energy=76586.91, cost=89341.74
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:49:55,164 [ZeusDataLoader(train)] Expected next epoch: time=630.13, energy=83262.42, cost=96767.99
2022-12-06 11:49:55,165 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0019, Accuracy: 0.4789
2022-12-06 11:49:55,361 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:49:55,362 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:49:55.376 [ZeusMonitor] Monitor started.
2022-12-06 16:49:55.376 [ZeusMonitor] Running indefinitely. 2022-12-06 16:49:55.376 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:49:55.376 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 11:50:39,981 [ZeusDataLoader(train)] train epoch 12 done: time=44.81 energy=6349.56
2022-12-06 11:50:39,984 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.6035
Training Epoch: 11 [2048/50176]	Loss: 1.6605
Training Epoch: 11 [3072/50176]	Loss: 1.6687
Training Epoch: 11 [4096/50176]	Loss: 1.8013
Training Epoch: 11 [5120/50176]	Loss: 1.8018
Training Epoch: 11 [6144/50176]	Loss: 1.5212
Training Epoch: 11 [7168/50176]	Loss: 1.6249
Training Epoch: 11 [8192/50176]	Loss: 1.6900
Training Epoch: 11 [9216/50176]	Loss: 1.6688
Training Epoch: 11 [10240/50176]	Loss: 1.7524
Training Epoch: 11 [11264/50176]	Loss: 1.6827
Training Epoch: 11 [12288/50176]	Loss: 1.6656
Training Epoch: 11 [13312/50176]	Loss: 1.7801
Training Epoch: 11 [14336/50176]	Loss: 1.6230
Training Epoch: 11 [15360/50176]	Loss: 1.7447
Training Epoch: 11 [16384/50176]	Loss: 1.7004
Training Epoch: 11 [17408/50176]	Loss: 1.6584
Training Epoch: 11 [18432/50176]	Loss: 1.6654
Training Epoch: 11 [19456/50176]	Loss: 1.6802
Training Epoch: 11 [20480/50176]	Loss: 1.8047
Training Epoch: 11 [21504/50176]	Loss: 1.7324
Training Epoch: 11 [22528/50176]	Loss: 1.7323
Training Epoch: 11 [23552/50176]	Loss: 1.7297
Training Epoch: 11 [24576/50176]	Loss: 1.6634
Training Epoch: 11 [25600/50176]	Loss: 1.6569
Training Epoch: 11 [26624/50176]	Loss: 1.6225
Training Epoch: 11 [27648/50176]	Loss: 1.6742
Training Epoch: 11 [28672/50176]	Loss: 1.7057
Training Epoch: 11 [29696/50176]	Loss: 1.7666
Training Epoch: 11 [30720/50176]	Loss: 1.6618
Training Epoch: 11 [31744/50176]	Loss: 1.6658
Training Epoch: 11 [32768/50176]	Loss: 1.7777
Training Epoch: 11 [33792/50176]	Loss: 1.7264
Training Epoch: 11 [34816/50176]	Loss: 1.7712
Training Epoch: 11 [35840/50176]	Loss: 1.7379
Training Epoch: 11 [36864/50176]	Loss: 1.6658
Training Epoch: 11 [37888/50176]	Loss: 1.7229
Training Epoch: 11 [38912/50176]	Loss: 1.7000
Training Epoch: 11 [39936/50176]	Loss: 1.6999
Training Epoch: 11 [40960/50176]	Loss: 1.6223
Training Epoch: 11 [41984/50176]	Loss: 1.6814
Training Epoch: 11 [43008/50176]	Loss: 1.7719
Training Epoch: 11 [44032/50176]	Loss: 1.6730
Training Epoch: 11 [45056/50176]	Loss: 1.7860
Training Epoch: 11 [46080/50176]	Loss: 1.6199
Training Epoch: 11 [47104/50176]	Loss: 1.7495
Training Epoch: 11 [48128/50176]	Loss: 1.6718
Training Epoch: 11 [49152/50176]	Loss: 1.6158
Training Epoch: 11 [50176/50176]	Loss: 1.7604
2022-12-06 16:50:43.822 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:50:43,862 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.87 energy=485.49
2022-12-06 11:50:43,862 [ZeusDataLoader(train)] Up to epoch 12: time=632.09, energy=83421.97, cost=97018.54
2022-12-06 11:50:43,863 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:50:43,863 [ZeusDataLoader(train)] Expected next epoch: time=678.81, energy=90097.48, cost=104444.80
2022-12-06 11:50:43,864 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0018, Accuracy: 0.4956
2022-12-06 11:50:44,054 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:50:44,055 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:50:44.069 [ZeusMonitor] Monitor started.
2022-12-06 16:50:44.069 [ZeusMonitor] Running indefinitely. 2022-12-06 16:50:44.069 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:50:44.069 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 11:51:28,080 [ZeusDataLoader(train)] train epoch 13 done: time=44.21 energy=6310.19
2022-12-06 11:51:28,083 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.6044
Training Epoch: 12 [2048/50176]	Loss: 1.5993
Training Epoch: 12 [3072/50176]	Loss: 1.6137
Training Epoch: 12 [4096/50176]	Loss: 1.5894
Training Epoch: 12 [5120/50176]	Loss: 1.5152
Training Epoch: 12 [6144/50176]	Loss: 1.6161
Training Epoch: 12 [7168/50176]	Loss: 1.6767
Training Epoch: 12 [8192/50176]	Loss: 1.4651
Training Epoch: 12 [9216/50176]	Loss: 1.6560
Training Epoch: 12 [10240/50176]	Loss: 1.5591
Training Epoch: 12 [11264/50176]	Loss: 1.7074
Training Epoch: 12 [12288/50176]	Loss: 1.5738
Training Epoch: 12 [13312/50176]	Loss: 1.5386
Training Epoch: 12 [14336/50176]	Loss: 1.5959
Training Epoch: 12 [15360/50176]	Loss: 1.5319
Training Epoch: 12 [16384/50176]	Loss: 1.5515
Training Epoch: 12 [17408/50176]	Loss: 1.5665
Training Epoch: 12 [18432/50176]	Loss: 1.5891
Training Epoch: 12 [19456/50176]	Loss: 1.5822
Training Epoch: 12 [20480/50176]	Loss: 1.5907
Training Epoch: 12 [21504/50176]	Loss: 1.7110
Training Epoch: 12 [22528/50176]	Loss: 1.5338
Training Epoch: 12 [23552/50176]	Loss: 1.6049
Training Epoch: 12 [24576/50176]	Loss: 1.5136
Training Epoch: 12 [25600/50176]	Loss: 1.6199
Training Epoch: 12 [26624/50176]	Loss: 1.7173
Training Epoch: 12 [27648/50176]	Loss: 1.5379
Training Epoch: 12 [28672/50176]	Loss: 1.6288
Training Epoch: 12 [29696/50176]	Loss: 1.5463
Training Epoch: 12 [30720/50176]	Loss: 1.5558
Training Epoch: 12 [31744/50176]	Loss: 1.5783
Training Epoch: 12 [32768/50176]	Loss: 1.6123
Training Epoch: 12 [33792/50176]	Loss: 1.5739
Training Epoch: 12 [34816/50176]	Loss: 1.5772
Training Epoch: 12 [35840/50176]	Loss: 1.5546
Training Epoch: 12 [36864/50176]	Loss: 1.6023
Training Epoch: 12 [37888/50176]	Loss: 1.6630
Training Epoch: 12 [38912/50176]	Loss: 1.5763
Training Epoch: 12 [39936/50176]	Loss: 1.6543
Training Epoch: 12 [40960/50176]	Loss: 1.4857
Training Epoch: 12 [41984/50176]	Loss: 1.6576
Training Epoch: 12 [43008/50176]	Loss: 1.5840
Training Epoch: 12 [44032/50176]	Loss: 1.6782
Training Epoch: 12 [45056/50176]	Loss: 1.5512
Training Epoch: 12 [46080/50176]	Loss: 1.6551
Training Epoch: 12 [47104/50176]	Loss: 1.5531
Training Epoch: 12 [48128/50176]	Loss: 1.5695
Training Epoch: 12 [49152/50176]	Loss: 1.6232
Training Epoch: 12 [50176/50176]	Loss: 1.5573
2022-12-06 16:51:31.904 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:51:31,948 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.86 energy=483.83
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Up to epoch 13: time=680.15, energy=90215.98, cost=104621.30
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:51:31,949 [ZeusDataLoader(train)] Expected next epoch: time=726.88, energy=96891.49, cost=112047.56
2022-12-06 11:51:31,950 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0018, Accuracy: 0.5036
2022-12-06 11:51:32,135 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:51:32,135 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:51:32.149 [ZeusMonitor] Monitor started.
2022-12-06 16:51:32.150 [ZeusMonitor] Running indefinitely. 2022-12-06 16:51:32.150 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:51:32.150 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 11:52:16,480 [ZeusDataLoader(train)] train epoch 14 done: time=44.52 energy=6324.77
2022-12-06 11:52:16,483 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.4576
Training Epoch: 13 [2048/50176]	Loss: 1.5433
Training Epoch: 13 [3072/50176]	Loss: 1.5277
Training Epoch: 13 [4096/50176]	Loss: 1.4356
Training Epoch: 13 [5120/50176]	Loss: 1.4868
Training Epoch: 13 [6144/50176]	Loss: 1.4884
Training Epoch: 13 [7168/50176]	Loss: 1.4474
Training Epoch: 13 [8192/50176]	Loss: 1.5026
Training Epoch: 13 [9216/50176]	Loss: 1.4711
Training Epoch: 13 [10240/50176]	Loss: 1.6753
Training Epoch: 13 [11264/50176]	Loss: 1.4667
Training Epoch: 13 [12288/50176]	Loss: 1.4819
Training Epoch: 13 [13312/50176]	Loss: 1.5147
Training Epoch: 13 [14336/50176]	Loss: 1.5027
Training Epoch: 13 [15360/50176]	Loss: 1.5825
Training Epoch: 13 [16384/50176]	Loss: 1.5221
Training Epoch: 13 [17408/50176]	Loss: 1.5457
Training Epoch: 13 [18432/50176]	Loss: 1.3944
Training Epoch: 13 [19456/50176]	Loss: 1.4813
Training Epoch: 13 [20480/50176]	Loss: 1.4606
Training Epoch: 13 [21504/50176]	Loss: 1.4793
Training Epoch: 13 [22528/50176]	Loss: 1.4865
Training Epoch: 13 [23552/50176]	Loss: 1.5334
Training Epoch: 13 [24576/50176]	Loss: 1.5174
Training Epoch: 13 [25600/50176]	Loss: 1.4859
Training Epoch: 13 [26624/50176]	Loss: 1.6245
Training Epoch: 13 [27648/50176]	Loss: 1.4582
Training Epoch: 13 [28672/50176]	Loss: 1.5066
Training Epoch: 13 [29696/50176]	Loss: 1.5128
Training Epoch: 13 [30720/50176]	Loss: 1.5235
Training Epoch: 13 [31744/50176]	Loss: 1.5176
Training Epoch: 13 [32768/50176]	Loss: 1.4542
Training Epoch: 13 [33792/50176]	Loss: 1.5757
Training Epoch: 13 [34816/50176]	Loss: 1.6544
Training Epoch: 13 [35840/50176]	Loss: 1.6298
Training Epoch: 13 [36864/50176]	Loss: 1.5108
Training Epoch: 13 [37888/50176]	Loss: 1.5966
Training Epoch: 13 [38912/50176]	Loss: 1.4692
Training Epoch: 13 [39936/50176]	Loss: 1.4646
Training Epoch: 13 [40960/50176]	Loss: 1.5243
Training Epoch: 13 [41984/50176]	Loss: 1.5414
Training Epoch: 13 [43008/50176]	Loss: 1.4098
Training Epoch: 13 [44032/50176]	Loss: 1.5605
Training Epoch: 13 [45056/50176]	Loss: 1.4826
Training Epoch: 13 [46080/50176]	Loss: 1.4833
Training Epoch: 13 [47104/50176]	Loss: 1.5340
Training Epoch: 13 [48128/50176]	Loss: 1.5027
Training Epoch: 13 [49152/50176]	Loss: 1.4525
Training Epoch: 13 [50176/50176]	Loss: 1.6361
2022-12-06 16:52:20.192 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:52:20,211 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.72 energy=474.74
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Up to epoch 14: time=728.39, energy=97015.49, cost=112242.23
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:52:20,211 [ZeusDataLoader(train)] Expected next epoch: time=775.12, energy=103691.00, cost=119668.49
2022-12-06 11:52:20,212 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0018, Accuracy: 0.5073
2022-12-06 11:52:20,410 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:52:20,410 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:52:20.424 [ZeusMonitor] Monitor started.
2022-12-06 16:52:20.424 [ZeusMonitor] Running indefinitely. 2022-12-06 16:52:20.424 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:52:20.425 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 11:53:04,974 [ZeusDataLoader(train)] train epoch 15 done: time=44.75 energy=6353.17
2022-12-06 11:53:04,977 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.3885
Training Epoch: 14 [2048/50176]	Loss: 1.4497
Training Epoch: 14 [3072/50176]	Loss: 1.4651
Training Epoch: 14 [4096/50176]	Loss: 1.5345
Training Epoch: 14 [5120/50176]	Loss: 1.3928
Training Epoch: 14 [6144/50176]	Loss: 1.4210
Training Epoch: 14 [7168/50176]	Loss: 1.3674
Training Epoch: 14 [8192/50176]	Loss: 1.4208
Training Epoch: 14 [9216/50176]	Loss: 1.3988
Training Epoch: 14 [10240/50176]	Loss: 1.3915
Training Epoch: 14 [11264/50176]	Loss: 1.3596
Training Epoch: 14 [12288/50176]	Loss: 1.3997
Training Epoch: 14 [13312/50176]	Loss: 1.4468
Training Epoch: 14 [14336/50176]	Loss: 1.4330
Training Epoch: 14 [15360/50176]	Loss: 1.4107
Training Epoch: 14 [16384/50176]	Loss: 1.3376
Training Epoch: 14 [17408/50176]	Loss: 1.5018
Training Epoch: 14 [18432/50176]	Loss: 1.4123
Training Epoch: 14 [19456/50176]	Loss: 1.4395
Training Epoch: 14 [20480/50176]	Loss: 1.4284
Training Epoch: 14 [21504/50176]	Loss: 1.4708
Training Epoch: 14 [22528/50176]	Loss: 1.4293
Training Epoch: 14 [23552/50176]	Loss: 1.4093
Training Epoch: 14 [24576/50176]	Loss: 1.4441
Training Epoch: 14 [25600/50176]	Loss: 1.5348
Training Epoch: 14 [26624/50176]	Loss: 1.3500
Training Epoch: 14 [27648/50176]	Loss: 1.3357
Training Epoch: 14 [28672/50176]	Loss: 1.5034
Training Epoch: 14 [29696/50176]	Loss: 1.4307
Training Epoch: 14 [30720/50176]	Loss: 1.4506
Training Epoch: 14 [31744/50176]	Loss: 1.4004
Training Epoch: 14 [32768/50176]	Loss: 1.5937
Training Epoch: 14 [33792/50176]	Loss: 1.4651
Training Epoch: 14 [34816/50176]	Loss: 1.4809
Training Epoch: 14 [35840/50176]	Loss: 1.4549
Training Epoch: 14 [36864/50176]	Loss: 1.5340
Training Epoch: 14 [37888/50176]	Loss: 1.3891
Training Epoch: 14 [38912/50176]	Loss: 1.5099
Training Epoch: 14 [39936/50176]	Loss: 1.4514
Training Epoch: 14 [40960/50176]	Loss: 1.4603
Training Epoch: 14 [41984/50176]	Loss: 1.5464
Training Epoch: 14 [43008/50176]	Loss: 1.5014
Training Epoch: 14 [44032/50176]	Loss: 1.4436
Training Epoch: 14 [45056/50176]	Loss: 1.4810
Training Epoch: 14 [46080/50176]	Loss: 1.4657
Training Epoch: 14 [47104/50176]	Loss: 1.4323
Training Epoch: 14 [48128/50176]	Loss: 1.4453
Training Epoch: 14 [49152/50176]	Loss: 1.5071
Training Epoch: 14 [50176/50176]	Loss: 1.4496
2022-12-06 16:53:08.718 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:53:08,745 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.76 energy=479.28
2022-12-06 11:53:08,745 [ZeusDataLoader(train)] Up to epoch 15: time=776.91, energy=103847.95, cost=119903.41
2022-12-06 11:53:08,746 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:53:08,746 [ZeusDataLoader(train)] Expected next epoch: time=823.63, energy=110523.45, cost=127329.66
2022-12-06 11:53:08,747 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.5107
2022-12-06 11:53:08,969 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:53:08,970 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:53:08.972 [ZeusMonitor] Monitor started.
2022-12-06 16:53:08.972 [ZeusMonitor] Running indefinitely. 2022-12-06 16:53:08.972 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:53:08.972 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 11:53:52,959 [ZeusDataLoader(train)] train epoch 16 done: time=44.20 energy=6316.67
2022-12-06 11:53:52,963 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.4065
Training Epoch: 15 [2048/50176]	Loss: 1.3541
Training Epoch: 15 [3072/50176]	Loss: 1.3629
Training Epoch: 15 [4096/50176]	Loss: 1.3273
Training Epoch: 15 [5120/50176]	Loss: 1.2943
Training Epoch: 15 [6144/50176]	Loss: 1.3598
Training Epoch: 15 [7168/50176]	Loss: 1.3696
Training Epoch: 15 [8192/50176]	Loss: 1.3766
Training Epoch: 15 [9216/50176]	Loss: 1.3578
Training Epoch: 15 [10240/50176]	Loss: 1.3445
Training Epoch: 15 [11264/50176]	Loss: 1.3280
Training Epoch: 15 [12288/50176]	Loss: 1.4640
Training Epoch: 15 [13312/50176]	Loss: 1.3008
Training Epoch: 15 [14336/50176]	Loss: 1.4004
Training Epoch: 15 [15360/50176]	Loss: 1.4434
Training Epoch: 15 [16384/50176]	Loss: 1.4112
Training Epoch: 15 [17408/50176]	Loss: 1.3670
Training Epoch: 15 [18432/50176]	Loss: 1.4018
Training Epoch: 15 [19456/50176]	Loss: 1.3491
Training Epoch: 15 [20480/50176]	Loss: 1.2988
Training Epoch: 15 [21504/50176]	Loss: 1.2885
Training Epoch: 15 [22528/50176]	Loss: 1.4597
Training Epoch: 15 [23552/50176]	Loss: 1.3895
Training Epoch: 15 [24576/50176]	Loss: 1.3950
Training Epoch: 15 [25600/50176]	Loss: 1.3520
Training Epoch: 15 [26624/50176]	Loss: 1.3802
Training Epoch: 15 [27648/50176]	Loss: 1.4223
Training Epoch: 15 [28672/50176]	Loss: 1.3107
Training Epoch: 15 [29696/50176]	Loss: 1.4167
Training Epoch: 15 [30720/50176]	Loss: 1.3476
Training Epoch: 15 [31744/50176]	Loss: 1.3852
Training Epoch: 15 [32768/50176]	Loss: 1.3709
Training Epoch: 15 [33792/50176]	Loss: 1.3075
Training Epoch: 15 [34816/50176]	Loss: 1.4807
Training Epoch: 15 [35840/50176]	Loss: 1.4296
Training Epoch: 15 [36864/50176]	Loss: 1.3808
Training Epoch: 15 [37888/50176]	Loss: 1.4182
Training Epoch: 15 [38912/50176]	Loss: 1.3533
Training Epoch: 15 [39936/50176]	Loss: 1.3878
Training Epoch: 15 [40960/50176]	Loss: 1.4035
Training Epoch: 15 [41984/50176]	Loss: 1.4122
Training Epoch: 15 [43008/50176]	Loss: 1.4821
Training Epoch: 15 [44032/50176]	Loss: 1.3597
Training Epoch: 15 [45056/50176]	Loss: 1.2987
Training Epoch: 15 [46080/50176]	Loss: 1.3525
Training Epoch: 15 [47104/50176]	Loss: 1.3512
Training Epoch: 15 [48128/50176]	Loss: 1.4309
Training Epoch: 15 [49152/50176]	Loss: 1.3066
Training Epoch: 15 [50176/50176]	Loss: 1.3706
2022-12-06 16:53:56.719 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:53:56,739 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.77 energy=475.51
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Up to epoch 16: time=824.88, energy=110640.13, cost=127497.19
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:53:56,740 [ZeusDataLoader(train)] Expected next epoch: time=871.61, energy=117315.64, cost=134923.45
2022-12-06 11:53:56,741 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0017, Accuracy: 0.5308
2022-12-06 11:53:56,940 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:53:56,941 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:53:56.943 [ZeusMonitor] Monitor started.
2022-12-06 16:53:56.955 [ZeusMonitor] Running indefinitely. 2022-12-06 16:53:56.955 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:53:56.955 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 11:54:41,225 [ZeusDataLoader(train)] train epoch 17 done: time=44.48 energy=6336.65
2022-12-06 11:54:41,228 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.2760
Training Epoch: 16 [2048/50176]	Loss: 1.3080
Training Epoch: 16 [3072/50176]	Loss: 1.2655
Training Epoch: 16 [4096/50176]	Loss: 1.3121
Training Epoch: 16 [5120/50176]	Loss: 1.3274
Training Epoch: 16 [6144/50176]	Loss: 1.2385
Training Epoch: 16 [7168/50176]	Loss: 1.2559
Training Epoch: 16 [8192/50176]	Loss: 1.1950
Training Epoch: 16 [9216/50176]	Loss: 1.2807
Training Epoch: 16 [10240/50176]	Loss: 1.1912
Training Epoch: 16 [11264/50176]	Loss: 1.3603
Training Epoch: 16 [12288/50176]	Loss: 1.2824
Training Epoch: 16 [13312/50176]	Loss: 1.3123
Training Epoch: 16 [14336/50176]	Loss: 1.3212
Training Epoch: 16 [15360/50176]	Loss: 1.3507
Training Epoch: 16 [16384/50176]	Loss: 1.2483
Training Epoch: 16 [17408/50176]	Loss: 1.2809
Training Epoch: 16 [18432/50176]	Loss: 1.3981
Training Epoch: 16 [19456/50176]	Loss: 1.2959
Training Epoch: 16 [20480/50176]	Loss: 1.2486
Training Epoch: 16 [21504/50176]	Loss: 1.2731
Training Epoch: 16 [22528/50176]	Loss: 1.3089
Training Epoch: 16 [23552/50176]	Loss: 1.3361
Training Epoch: 16 [24576/50176]	Loss: 1.2933
Training Epoch: 16 [25600/50176]	Loss: 1.2850
Training Epoch: 16 [26624/50176]	Loss: 1.2816
Training Epoch: 16 [27648/50176]	Loss: 1.3851
Training Epoch: 16 [28672/50176]	Loss: 1.3604
Training Epoch: 16 [29696/50176]	Loss: 1.2154
Training Epoch: 16 [30720/50176]	Loss: 1.2800
Training Epoch: 16 [31744/50176]	Loss: 1.3114
Training Epoch: 16 [32768/50176]	Loss: 1.3552
Training Epoch: 16 [33792/50176]	Loss: 1.2644
Training Epoch: 16 [34816/50176]	Loss: 1.3153
Training Epoch: 16 [35840/50176]	Loss: 1.4044
Training Epoch: 16 [36864/50176]	Loss: 1.3831
Training Epoch: 16 [37888/50176]	Loss: 1.2794
Training Epoch: 16 [38912/50176]	Loss: 1.3591
Training Epoch: 16 [39936/50176]	Loss: 1.5151
Training Epoch: 16 [40960/50176]	Loss: 1.4036
Training Epoch: 16 [41984/50176]	Loss: 1.3819
Training Epoch: 16 [43008/50176]	Loss: 1.3299
Training Epoch: 16 [44032/50176]	Loss: 1.4080
Training Epoch: 16 [45056/50176]	Loss: 1.4468
Training Epoch: 16 [46080/50176]	Loss: 1.4048
Training Epoch: 16 [47104/50176]	Loss: 1.3834
Training Epoch: 16 [48128/50176]	Loss: 1.4215
Training Epoch: 16 [49152/50176]	Loss: 1.4265
Training Epoch: 16 [50176/50176]	Loss: 1.3511
2022-12-06 16:54:44.980 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:54:45,004 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.77 energy=476.54
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Up to epoch 17: time=873.13, energy=117453.32, cost=135125.15
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:54:45,004 [ZeusDataLoader(train)] Expected next epoch: time=919.85, energy=124128.83, cost=142551.41
2022-12-06 11:54:45,005 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0022, Accuracy: 0.4850
2022-12-06 11:54:45,202 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:54:45,202 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:54:45.204 [ZeusMonitor] Monitor started.
2022-12-06 16:54:45.204 [ZeusMonitor] Running indefinitely. 2022-12-06 16:54:45.204 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:54:45.204 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 11:55:29,555 [ZeusDataLoader(train)] train epoch 18 done: time=44.54 energy=6340.18
2022-12-06 11:55:29,558 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.2280
Training Epoch: 17 [2048/50176]	Loss: 1.2516
Training Epoch: 17 [3072/50176]	Loss: 1.1451
Training Epoch: 17 [4096/50176]	Loss: 1.2165
Training Epoch: 17 [5120/50176]	Loss: 1.3797
Training Epoch: 17 [6144/50176]	Loss: 1.2384
Training Epoch: 17 [7168/50176]	Loss: 1.2401
Training Epoch: 17 [8192/50176]	Loss: 1.2394
Training Epoch: 17 [9216/50176]	Loss: 1.2820
Training Epoch: 17 [10240/50176]	Loss: 1.2124
Training Epoch: 17 [11264/50176]	Loss: 1.2185
Training Epoch: 17 [12288/50176]	Loss: 1.2642
Training Epoch: 17 [13312/50176]	Loss: 1.2785
Training Epoch: 17 [14336/50176]	Loss: 1.2517
Training Epoch: 17 [15360/50176]	Loss: 1.2056
Training Epoch: 17 [16384/50176]	Loss: 1.2515
Training Epoch: 17 [17408/50176]	Loss: 1.3346
Training Epoch: 17 [18432/50176]	Loss: 1.3637
Training Epoch: 17 [19456/50176]	Loss: 1.2165
Training Epoch: 17 [20480/50176]	Loss: 1.2814
Training Epoch: 17 [21504/50176]	Loss: 1.3065
Training Epoch: 17 [22528/50176]	Loss: 1.3576
Training Epoch: 17 [23552/50176]	Loss: 1.2883
Training Epoch: 17 [24576/50176]	Loss: 1.3367
Training Epoch: 17 [25600/50176]	Loss: 1.3081
Training Epoch: 17 [26624/50176]	Loss: 1.2506
Training Epoch: 17 [27648/50176]	Loss: 1.2379
Training Epoch: 17 [28672/50176]	Loss: 1.3033
Training Epoch: 17 [29696/50176]	Loss: 1.3131
Training Epoch: 17 [30720/50176]	Loss: 1.3598
Training Epoch: 17 [31744/50176]	Loss: 1.2968
Training Epoch: 17 [32768/50176]	Loss: 1.2541
Training Epoch: 17 [33792/50176]	Loss: 1.3433
Training Epoch: 17 [34816/50176]	Loss: 1.2751
Training Epoch: 17 [35840/50176]	Loss: 1.1601
Training Epoch: 17 [36864/50176]	Loss: 1.3844
Training Epoch: 17 [37888/50176]	Loss: 1.2954
Training Epoch: 17 [38912/50176]	Loss: 1.3503
Training Epoch: 17 [39936/50176]	Loss: 1.3750
Training Epoch: 17 [40960/50176]	Loss: 1.2800
Training Epoch: 17 [41984/50176]	Loss: 1.3200
Training Epoch: 17 [43008/50176]	Loss: 1.2557
Training Epoch: 17 [44032/50176]	Loss: 1.3413
Training Epoch: 17 [45056/50176]	Loss: 1.2909
Training Epoch: 17 [46080/50176]	Loss: 1.2607
Training Epoch: 17 [47104/50176]	Loss: 1.2093
Training Epoch: 17 [48128/50176]	Loss: 1.2923
Training Epoch: 17 [49152/50176]	Loss: 1.2977
Training Epoch: 17 [50176/50176]	Loss: 1.2947
2022-12-06 16:55:33.234 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:55:33,243 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.68 energy=462.94
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Up to epoch 18: time=921.34, energy=124256.44, cost=142745.84
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:55:33,243 [ZeusDataLoader(train)] Expected next epoch: time=968.07, energy=130931.95, cost=150172.10
2022-12-06 11:55:33,244 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0016, Accuracy: 0.5598
2022-12-06 11:55:33,437 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:55:33,438 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:55:33.452 [ZeusMonitor] Monitor started.
2022-12-06 16:55:33.452 [ZeusMonitor] Running indefinitely. 2022-12-06 16:55:33.452 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:55:33.452 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 11:56:17,523 [ZeusDataLoader(train)] train epoch 19 done: time=44.27 energy=6308.44
2022-12-06 11:56:17,526 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.1640
Training Epoch: 18 [2048/50176]	Loss: 1.2136
Training Epoch: 18 [3072/50176]	Loss: 1.2065
Training Epoch: 18 [4096/50176]	Loss: 1.1425
Training Epoch: 18 [5120/50176]	Loss: 1.1904
Training Epoch: 18 [6144/50176]	Loss: 1.1817
Training Epoch: 18 [7168/50176]	Loss: 1.1415
Training Epoch: 18 [8192/50176]	Loss: 1.2037
Training Epoch: 18 [9216/50176]	Loss: 1.1287
Training Epoch: 18 [10240/50176]	Loss: 1.1671
Training Epoch: 18 [11264/50176]	Loss: 1.1767
Training Epoch: 18 [12288/50176]	Loss: 1.1587
Training Epoch: 18 [13312/50176]	Loss: 1.2363
Training Epoch: 18 [14336/50176]	Loss: 1.1847
Training Epoch: 18 [15360/50176]	Loss: 1.2422
Training Epoch: 18 [16384/50176]	Loss: 1.2307
Training Epoch: 18 [17408/50176]	Loss: 1.2305
Training Epoch: 18 [18432/50176]	Loss: 1.2336
Training Epoch: 18 [19456/50176]	Loss: 1.2227
Training Epoch: 18 [20480/50176]	Loss: 1.2153
Training Epoch: 18 [21504/50176]	Loss: 1.2529
Training Epoch: 18 [22528/50176]	Loss: 1.2465
Training Epoch: 18 [23552/50176]	Loss: 1.1749
Training Epoch: 18 [24576/50176]	Loss: 1.1603
Training Epoch: 18 [25600/50176]	Loss: 1.1337
Training Epoch: 18 [26624/50176]	Loss: 1.1192
Training Epoch: 18 [27648/50176]	Loss: 1.1800
Training Epoch: 18 [28672/50176]	Loss: 1.2057
Training Epoch: 18 [29696/50176]	Loss: 1.2585
Training Epoch: 18 [30720/50176]	Loss: 1.2618
Training Epoch: 18 [31744/50176]	Loss: 1.3169
Training Epoch: 18 [32768/50176]	Loss: 1.1897
Training Epoch: 18 [33792/50176]	Loss: 1.2462
Training Epoch: 18 [34816/50176]	Loss: 1.2271
Training Epoch: 18 [35840/50176]	Loss: 1.3287
Training Epoch: 18 [36864/50176]	Loss: 1.2476
Training Epoch: 18 [37888/50176]	Loss: 1.1785
Training Epoch: 18 [38912/50176]	Loss: 1.2605
Training Epoch: 18 [39936/50176]	Loss: 1.2729
Training Epoch: 18 [40960/50176]	Loss: 1.2188
Training Epoch: 18 [41984/50176]	Loss: 1.2334
Training Epoch: 18 [43008/50176]	Loss: 1.2083
Training Epoch: 18 [44032/50176]	Loss: 1.1972
Training Epoch: 18 [45056/50176]	Loss: 1.1943
Training Epoch: 18 [46080/50176]	Loss: 1.2712
Training Epoch: 18 [47104/50176]	Loss: 1.2006
Training Epoch: 18 [48128/50176]	Loss: 1.1715
Training Epoch: 18 [49152/50176]	Loss: 1.2148
Training Epoch: 18 [50176/50176]	Loss: 1.2826
2022-12-06 16:56:21.225 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:56:21,254 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.72 energy=487.69
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Up to epoch 19: time=969.33, energy=131052.57, cost=150343.05
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:56:21,254 [ZeusDataLoader(train)] Expected next epoch: time=1016.06, energy=137728.08, cost=157769.30
2022-12-06 11:56:21,255 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0016, Accuracy: 0.5516
2022-12-06 11:56:21,458 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:56:21,459 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:56:21.461 [ZeusMonitor] Monitor started.
2022-12-06 16:56:21.461 [ZeusMonitor] Running indefinitely. 2022-12-06 16:56:21.461 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:56:21.461 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 11:57:06,107 [ZeusDataLoader(train)] train epoch 20 done: time=44.84 energy=6361.07
2022-12-06 11:57:06,110 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.0998
Training Epoch: 19 [2048/50176]	Loss: 1.1733
Training Epoch: 19 [3072/50176]	Loss: 1.1430
Training Epoch: 19 [4096/50176]	Loss: 1.1045
Training Epoch: 19 [5120/50176]	Loss: 1.1059
Training Epoch: 19 [6144/50176]	Loss: 1.1141
Training Epoch: 19 [7168/50176]	Loss: 1.1375
Training Epoch: 19 [8192/50176]	Loss: 1.1444
Training Epoch: 19 [9216/50176]	Loss: 1.1441
Training Epoch: 19 [10240/50176]	Loss: 1.1525
Training Epoch: 19 [11264/50176]	Loss: 1.1692
Training Epoch: 19 [12288/50176]	Loss: 1.0705
Training Epoch: 19 [13312/50176]	Loss: 1.1296
Training Epoch: 19 [14336/50176]	Loss: 1.1751
Training Epoch: 19 [15360/50176]	Loss: 1.1887
Training Epoch: 19 [16384/50176]	Loss: 1.1157
Training Epoch: 19 [17408/50176]	Loss: 1.1694
Training Epoch: 19 [18432/50176]	Loss: 1.1878
Training Epoch: 19 [19456/50176]	Loss: 1.1233
Training Epoch: 19 [20480/50176]	Loss: 1.1809
Training Epoch: 19 [21504/50176]	Loss: 1.1049
Training Epoch: 19 [22528/50176]	Loss: 1.2525
Training Epoch: 19 [23552/50176]	Loss: 1.2307
Training Epoch: 19 [24576/50176]	Loss: 1.0846
Training Epoch: 19 [25600/50176]	Loss: 1.1635
Training Epoch: 19 [26624/50176]	Loss: 1.1775
Training Epoch: 19 [27648/50176]	Loss: 1.0725
Training Epoch: 19 [28672/50176]	Loss: 1.1763
Training Epoch: 19 [29696/50176]	Loss: 1.2336
Training Epoch: 19 [30720/50176]	Loss: 1.1887
Training Epoch: 19 [31744/50176]	Loss: 1.1470
Training Epoch: 19 [32768/50176]	Loss: 1.1939
Training Epoch: 19 [33792/50176]	Loss: 1.1758
Training Epoch: 19 [34816/50176]	Loss: 1.1350
Training Epoch: 19 [35840/50176]	Loss: 1.1617
Training Epoch: 19 [36864/50176]	Loss: 1.2281
Training Epoch: 19 [37888/50176]	Loss: 1.1473
Training Epoch: 19 [38912/50176]	Loss: 1.2323
Training Epoch: 19 [39936/50176]	Loss: 1.1527
Training Epoch: 19 [40960/50176]	Loss: 1.0713
Training Epoch: 19 [41984/50176]	Loss: 1.2028
Training Epoch: 19 [43008/50176]	Loss: 1.1515
Training Epoch: 19 [44032/50176]	Loss: 1.1541
Training Epoch: 19 [45056/50176]	Loss: 1.1680
Training Epoch: 19 [46080/50176]	Loss: 1.1065
Training Epoch: 19 [47104/50176]	Loss: 1.1358
Training Epoch: 19 [48128/50176]	Loss: 1.0965
Training Epoch: 19 [49152/50176]	Loss: 1.1868
Training Epoch: 19 [50176/50176]	Loss: 1.1559
2022-12-06 16:57:09.847 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:57:09,886 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.77 energy=482.33
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Up to epoch 20: time=1017.95, energy=137895.97, cost=158018.26
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:57:09,886 [ZeusDataLoader(train)] Expected next epoch: time=1064.67, energy=144571.47, cost=165444.52
2022-12-06 11:57:09,887 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0016, Accuracy: 0.5588
2022-12-06 11:57:10,082 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:57:10,083 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:57:10.093 [ZeusMonitor] Monitor started.
2022-12-06 16:57:10.093 [ZeusMonitor] Running indefinitely. 2022-12-06 16:57:10.093 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:57:10.093 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 11:57:54,617 [ZeusDataLoader(train)] train epoch 21 done: time=44.72 energy=6346.84
2022-12-06 11:57:54,620 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0482
Training Epoch: 20 [2048/50176]	Loss: 1.0811
Training Epoch: 20 [3072/50176]	Loss: 1.0967
Training Epoch: 20 [4096/50176]	Loss: 1.0494
Training Epoch: 20 [5120/50176]	Loss: 1.0312
Training Epoch: 20 [6144/50176]	Loss: 1.0965
Training Epoch: 20 [7168/50176]	Loss: 1.0366
Training Epoch: 20 [8192/50176]	Loss: 1.1007
Training Epoch: 20 [9216/50176]	Loss: 1.0713
Training Epoch: 20 [10240/50176]	Loss: 1.0513
Training Epoch: 20 [11264/50176]	Loss: 1.0878
Training Epoch: 20 [12288/50176]	Loss: 1.0178
Training Epoch: 20 [13312/50176]	Loss: 1.0249
Training Epoch: 20 [14336/50176]	Loss: 1.1055
Training Epoch: 20 [15360/50176]	Loss: 1.0929
Training Epoch: 20 [16384/50176]	Loss: 1.1550
Training Epoch: 20 [17408/50176]	Loss: 1.0638
Training Epoch: 20 [18432/50176]	Loss: 1.1092
Training Epoch: 20 [19456/50176]	Loss: 1.1528
Training Epoch: 20 [20480/50176]	Loss: 1.0645
Training Epoch: 20 [21504/50176]	Loss: 1.1534
Training Epoch: 20 [22528/50176]	Loss: 1.0550
Training Epoch: 20 [23552/50176]	Loss: 1.0316
Training Epoch: 20 [24576/50176]	Loss: 1.0967
Training Epoch: 20 [25600/50176]	Loss: 1.1576
Training Epoch: 20 [26624/50176]	Loss: 1.1288
Training Epoch: 20 [27648/50176]	Loss: 1.0541
Training Epoch: 20 [28672/50176]	Loss: 1.1524
Training Epoch: 20 [29696/50176]	Loss: 1.0547
Training Epoch: 20 [30720/50176]	Loss: 1.0975
Training Epoch: 20 [31744/50176]	Loss: 1.1139
Training Epoch: 20 [32768/50176]	Loss: 1.1169
Training Epoch: 20 [33792/50176]	Loss: 1.0763
Training Epoch: 20 [34816/50176]	Loss: 1.1883
Training Epoch: 20 [35840/50176]	Loss: 1.0973
Training Epoch: 20 [36864/50176]	Loss: 1.1068
Training Epoch: 20 [37888/50176]	Loss: 1.0918
Training Epoch: 20 [38912/50176]	Loss: 1.1663
Training Epoch: 20 [39936/50176]	Loss: 1.1198
Training Epoch: 20 [40960/50176]	Loss: 1.1987
Training Epoch: 20 [41984/50176]	Loss: 1.1081
Training Epoch: 20 [43008/50176]	Loss: 1.0983
Training Epoch: 20 [44032/50176]	Loss: 1.0519
Training Epoch: 20 [45056/50176]	Loss: 1.1337
Training Epoch: 20 [46080/50176]	Loss: 1.1122
Training Epoch: 20 [47104/50176]	Loss: 1.1425
Training Epoch: 20 [48128/50176]	Loss: 1.0933
Training Epoch: 20 [49152/50176]	Loss: 1.1543
Training Epoch: 20 [50176/50176]	Loss: 1.1028
2022-12-06 16:57:58.534 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:57:58,570 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.94 energy=491.77
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Up to epoch 21: time=1066.61, energy=144734.58, cost=165695.70
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:57:58,571 [ZeusDataLoader(train)] Expected next epoch: time=1113.34, energy=151410.08, cost=173121.95
2022-12-06 11:57:58,572 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0016, Accuracy: 0.5661
2022-12-06 11:57:58,769 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:57:58,770 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:57:58.772 [ZeusMonitor] Monitor started.
2022-12-06 16:57:58.772 [ZeusMonitor] Running indefinitely. 2022-12-06 16:57:58.772 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:57:58.772 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 11:58:42,845 [ZeusDataLoader(train)] train epoch 22 done: time=44.27 energy=6320.25
2022-12-06 11:58:42,848 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0073
Training Epoch: 21 [2048/50176]	Loss: 0.9738
Training Epoch: 21 [3072/50176]	Loss: 1.0230
Training Epoch: 21 [4096/50176]	Loss: 1.0117
Training Epoch: 21 [5120/50176]	Loss: 1.0012
Training Epoch: 21 [6144/50176]	Loss: 0.9337
Training Epoch: 21 [7168/50176]	Loss: 0.9598
Training Epoch: 21 [8192/50176]	Loss: 1.0590
Training Epoch: 21 [9216/50176]	Loss: 1.0082
Training Epoch: 21 [10240/50176]	Loss: 0.9964
Training Epoch: 21 [11264/50176]	Loss: 0.9989
Training Epoch: 21 [12288/50176]	Loss: 1.0188
Training Epoch: 21 [13312/50176]	Loss: 1.0031
Training Epoch: 21 [14336/50176]	Loss: 1.0801
Training Epoch: 21 [15360/50176]	Loss: 1.0284
Training Epoch: 21 [16384/50176]	Loss: 1.0560
Training Epoch: 21 [17408/50176]	Loss: 1.0008
Training Epoch: 21 [18432/50176]	Loss: 1.0169
Training Epoch: 21 [19456/50176]	Loss: 1.0629
Training Epoch: 21 [20480/50176]	Loss: 1.0452
Training Epoch: 21 [21504/50176]	Loss: 1.0415
Training Epoch: 21 [22528/50176]	Loss: 1.0911
Training Epoch: 21 [23552/50176]	Loss: 1.0710
Training Epoch: 21 [24576/50176]	Loss: 0.9983
Training Epoch: 21 [25600/50176]	Loss: 1.0725
Training Epoch: 21 [26624/50176]	Loss: 1.1441
Training Epoch: 21 [27648/50176]	Loss: 1.1301
Training Epoch: 21 [28672/50176]	Loss: 1.0217
Training Epoch: 21 [29696/50176]	Loss: 1.1069
Training Epoch: 21 [30720/50176]	Loss: 1.0635
Training Epoch: 21 [31744/50176]	Loss: 1.0656
Training Epoch: 21 [32768/50176]	Loss: 1.1165
Training Epoch: 21 [33792/50176]	Loss: 1.0735
Training Epoch: 21 [34816/50176]	Loss: 1.0258
Training Epoch: 21 [35840/50176]	Loss: 1.0762
Training Epoch: 21 [36864/50176]	Loss: 1.0126
Training Epoch: 21 [37888/50176]	Loss: 1.1912
Training Epoch: 21 [38912/50176]	Loss: 1.0647
Training Epoch: 21 [39936/50176]	Loss: 1.1058
Training Epoch: 21 [40960/50176]	Loss: 1.0618
Training Epoch: 21 [41984/50176]	Loss: 1.0205
Training Epoch: 21 [43008/50176]	Loss: 1.0779
Training Epoch: 21 [44032/50176]	Loss: 1.1368
Training Epoch: 21 [45056/50176]	Loss: 1.0571
Training Epoch: 21 [46080/50176]	Loss: 1.0742
Training Epoch: 21 [47104/50176]	Loss: 1.0797
Training Epoch: 21 [48128/50176]	Loss: 1.1106
Training Epoch: 21 [49152/50176]	Loss: 1.1121
Training Epoch: 21 [50176/50176]	Loss: 1.1147
2022-12-06 16:58:46.507 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:58:46,517 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.66 energy=464.90
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Up to epoch 22: time=1114.54, energy=151519.73, cost=173281.78
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:58:46,518 [ZeusDataLoader(train)] Expected next epoch: time=1161.26, energy=158195.23, cost=180708.03
2022-12-06 11:58:46,519 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0018, Accuracy: 0.5493
2022-12-06 11:58:46,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:58:46,702 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:58:46.716 [ZeusMonitor] Monitor started.
2022-12-06 16:58:46.716 [ZeusMonitor] Running indefinitely. 2022-12-06 16:58:46.716 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:58:46.716 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 11:59:31,260 [ZeusDataLoader(train)] train epoch 23 done: time=44.73 energy=6343.56
2022-12-06 11:59:31,263 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 0.9982
Training Epoch: 22 [2048/50176]	Loss: 0.9893
Training Epoch: 22 [3072/50176]	Loss: 0.9443
Training Epoch: 22 [4096/50176]	Loss: 0.8971
Training Epoch: 22 [5120/50176]	Loss: 0.9799
Training Epoch: 22 [6144/50176]	Loss: 0.9989
Training Epoch: 22 [7168/50176]	Loss: 1.0449
Training Epoch: 22 [8192/50176]	Loss: 1.0453
Training Epoch: 22 [9216/50176]	Loss: 0.9658
Training Epoch: 22 [10240/50176]	Loss: 0.9447
Training Epoch: 22 [11264/50176]	Loss: 1.0409
Training Epoch: 22 [12288/50176]	Loss: 0.9878
Training Epoch: 22 [13312/50176]	Loss: 0.9158
Training Epoch: 22 [14336/50176]	Loss: 0.9786
Training Epoch: 22 [15360/50176]	Loss: 0.9603
Training Epoch: 22 [16384/50176]	Loss: 1.0163
Training Epoch: 22 [17408/50176]	Loss: 0.9734
Training Epoch: 22 [18432/50176]	Loss: 0.9610
Training Epoch: 22 [19456/50176]	Loss: 1.0095
Training Epoch: 22 [20480/50176]	Loss: 1.0124
Training Epoch: 22 [21504/50176]	Loss: 0.9888
Training Epoch: 22 [22528/50176]	Loss: 0.9976
Training Epoch: 22 [23552/50176]	Loss: 1.0034
Training Epoch: 22 [24576/50176]	Loss: 1.0074
Training Epoch: 22 [25600/50176]	Loss: 1.0029
Training Epoch: 22 [26624/50176]	Loss: 1.0490
Training Epoch: 22 [27648/50176]	Loss: 1.0217
Training Epoch: 22 [28672/50176]	Loss: 1.0797
Training Epoch: 22 [29696/50176]	Loss: 1.0096
Training Epoch: 22 [30720/50176]	Loss: 1.0056
Training Epoch: 22 [31744/50176]	Loss: 1.1250
Training Epoch: 22 [32768/50176]	Loss: 0.9775
Training Epoch: 22 [33792/50176]	Loss: 1.0293
Training Epoch: 22 [34816/50176]	Loss: 1.0822
Training Epoch: 22 [35840/50176]	Loss: 1.0489
Training Epoch: 22 [36864/50176]	Loss: 1.0413
Training Epoch: 22 [37888/50176]	Loss: 1.0403
Training Epoch: 22 [38912/50176]	Loss: 0.9694
Training Epoch: 22 [39936/50176]	Loss: 1.0214
Training Epoch: 22 [40960/50176]	Loss: 1.0597
Training Epoch: 22 [41984/50176]	Loss: 1.0845
Training Epoch: 22 [43008/50176]	Loss: 1.0330
Training Epoch: 22 [44032/50176]	Loss: 1.0300
Training Epoch: 22 [45056/50176]	Loss: 1.0635
Training Epoch: 22 [46080/50176]	Loss: 1.0157
Training Epoch: 22 [47104/50176]	Loss: 1.0134
Training Epoch: 22 [48128/50176]	Loss: 1.1634
Training Epoch: 22 [49152/50176]	Loss: 1.0981
Training Epoch: 22 [50176/50176]	Loss: 0.9845
2022-12-06 16:59:34.960 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:59:34,982 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.71 energy=483.87
2022-12-06 11:59:34,982 [ZeusDataLoader(train)] Up to epoch 23: time=1162.98, energy=158347.15, cost=180934.24
2022-12-06 11:59:34,982 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 11:59:34,983 [ZeusDataLoader(train)] Expected next epoch: time=1209.70, energy=165022.66, cost=188360.50
2022-12-06 11:59:34,983 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0016, Accuracy: 0.5721
2022-12-06 11:59:35,137 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:59:35,138 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:59:35.141 [ZeusMonitor] Monitor started.
2022-12-06 16:59:35.141 [ZeusMonitor] Running indefinitely. 2022-12-06 16:59:35.141 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:59:35.141 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 12:00:19,628 [ZeusDataLoader(train)] train epoch 24 done: time=44.64 energy=6345.18
2022-12-06 12:00:19,631 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 0.9621
Training Epoch: 23 [2048/50176]	Loss: 0.9439
Training Epoch: 23 [3072/50176]	Loss: 0.9568
Training Epoch: 23 [4096/50176]	Loss: 0.9681
Training Epoch: 23 [5120/50176]	Loss: 0.9090
Training Epoch: 23 [6144/50176]	Loss: 0.9510
Training Epoch: 23 [7168/50176]	Loss: 0.9426
Training Epoch: 23 [8192/50176]	Loss: 0.9612
Training Epoch: 23 [9216/50176]	Loss: 0.9098
Training Epoch: 23 [10240/50176]	Loss: 0.8650
Training Epoch: 23 [11264/50176]	Loss: 0.9550
Training Epoch: 23 [12288/50176]	Loss: 0.8543
Training Epoch: 23 [13312/50176]	Loss: 1.0054
Training Epoch: 23 [14336/50176]	Loss: 0.9389
Training Epoch: 23 [15360/50176]	Loss: 0.9013
Training Epoch: 23 [16384/50176]	Loss: 0.9805
Training Epoch: 23 [17408/50176]	Loss: 0.9742
Training Epoch: 23 [18432/50176]	Loss: 0.8866
Training Epoch: 23 [19456/50176]	Loss: 0.9653
Training Epoch: 23 [20480/50176]	Loss: 0.9153
Training Epoch: 23 [21504/50176]	Loss: 0.9535
Training Epoch: 23 [22528/50176]	Loss: 0.9421
Training Epoch: 23 [23552/50176]	Loss: 0.8583
Training Epoch: 23 [24576/50176]	Loss: 0.9638
Training Epoch: 23 [25600/50176]	Loss: 0.9600
Training Epoch: 23 [26624/50176]	Loss: 0.9538
Training Epoch: 23 [27648/50176]	Loss: 0.9111
Training Epoch: 23 [28672/50176]	Loss: 0.9965
Training Epoch: 23 [29696/50176]	Loss: 0.9079
Training Epoch: 23 [30720/50176]	Loss: 0.9605
Training Epoch: 23 [31744/50176]	Loss: 0.9851
Training Epoch: 23 [32768/50176]	Loss: 0.9783
Training Epoch: 23 [33792/50176]	Loss: 1.0153
Training Epoch: 23 [34816/50176]	Loss: 1.0448
Training Epoch: 23 [35840/50176]	Loss: 0.9831
Training Epoch: 23 [36864/50176]	Loss: 0.9486
Training Epoch: 23 [37888/50176]	Loss: 0.9629
Training Epoch: 23 [38912/50176]	Loss: 1.0624
Training Epoch: 23 [39936/50176]	Loss: 1.0399
Training Epoch: 23 [40960/50176]	Loss: 1.0335
Training Epoch: 23 [41984/50176]	Loss: 1.0341
Training Epoch: 23 [43008/50176]	Loss: 0.9351
Training Epoch: 23 [44032/50176]	Loss: 1.0050
Training Epoch: 23 [45056/50176]	Loss: 1.0001
Training Epoch: 23 [46080/50176]	Loss: 1.0365
Training Epoch: 23 [47104/50176]	Loss: 1.0233
Training Epoch: 23 [48128/50176]	Loss: 0.9670
Training Epoch: 23 [49152/50176]	Loss: 0.9801
Training Epoch: 23 [50176/50176]	Loss: 0.9291
2022-12-06 17:00:23.293 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:00:23,311 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.67 energy=462.27
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Up to epoch 24: time=1211.29, energy=165154.60, cost=188564.96
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:00:23,312 [ZeusDataLoader(train)] Expected next epoch: time=1258.01, energy=171830.11, cost=195991.21
2022-12-06 12:00:23,313 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0016, Accuracy: 0.5737
2022-12-06 12:00:23,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:00:23,502 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:00:23.516 [ZeusMonitor] Monitor started.
2022-12-06 17:00:23.516 [ZeusMonitor] Running indefinitely. 2022-12-06 17:00:23.516 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:00:23.516 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 12:01:08,142 [ZeusDataLoader(train)] train epoch 25 done: time=44.82 energy=6354.04
2022-12-06 12:01:08,145 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8523
Training Epoch: 24 [2048/50176]	Loss: 0.7583
Training Epoch: 24 [3072/50176]	Loss: 0.9024
Training Epoch: 24 [4096/50176]	Loss: 0.8401
Training Epoch: 24 [5120/50176]	Loss: 0.8865
Training Epoch: 24 [6144/50176]	Loss: 0.8737
Training Epoch: 24 [7168/50176]	Loss: 0.9296
Training Epoch: 24 [8192/50176]	Loss: 0.8441
Training Epoch: 24 [9216/50176]	Loss: 0.9152
Training Epoch: 24 [10240/50176]	Loss: 0.8832
Training Epoch: 24 [11264/50176]	Loss: 0.8638
Training Epoch: 24 [12288/50176]	Loss: 0.8923
Training Epoch: 24 [13312/50176]	Loss: 0.9226
Training Epoch: 24 [14336/50176]	Loss: 0.8873
Training Epoch: 24 [15360/50176]	Loss: 0.8270
Training Epoch: 24 [16384/50176]	Loss: 0.8262
Training Epoch: 24 [17408/50176]	Loss: 0.9466
Training Epoch: 24 [18432/50176]	Loss: 0.9580
Training Epoch: 24 [19456/50176]	Loss: 0.9507
Training Epoch: 24 [20480/50176]	Loss: 0.9604
Training Epoch: 24 [21504/50176]	Loss: 1.0064
Training Epoch: 24 [22528/50176]	Loss: 1.0259
Training Epoch: 24 [23552/50176]	Loss: 1.0564
Training Epoch: 24 [24576/50176]	Loss: 0.9873
Training Epoch: 24 [25600/50176]	Loss: 1.0308
Training Epoch: 24 [26624/50176]	Loss: 1.0581
Training Epoch: 24 [27648/50176]	Loss: 1.1604
Training Epoch: 24 [28672/50176]	Loss: 1.0604
Training Epoch: 24 [29696/50176]	Loss: 0.9716
Training Epoch: 24 [30720/50176]	Loss: 1.0921
Training Epoch: 24 [31744/50176]	Loss: 1.1230
Training Epoch: 24 [32768/50176]	Loss: 1.0424
Training Epoch: 24 [33792/50176]	Loss: 1.0481
Training Epoch: 24 [34816/50176]	Loss: 1.1380
Training Epoch: 24 [35840/50176]	Loss: 1.0967
Training Epoch: 24 [36864/50176]	Loss: 1.0695
Training Epoch: 24 [37888/50176]	Loss: 1.0571
Training Epoch: 24 [38912/50176]	Loss: 1.0553
Training Epoch: 24 [39936/50176]	Loss: 0.9478
Training Epoch: 24 [40960/50176]	Loss: 1.0021
Training Epoch: 24 [41984/50176]	Loss: 1.0548
Training Epoch: 24 [43008/50176]	Loss: 1.1347
Training Epoch: 24 [44032/50176]	Loss: 0.9893
Training Epoch: 24 [45056/50176]	Loss: 1.0295
Training Epoch: 24 [46080/50176]	Loss: 0.9657
Training Epoch: 24 [47104/50176]	Loss: 1.0924
Training Epoch: 24 [48128/50176]	Loss: 1.1756
Training Epoch: 24 [49152/50176]	Loss: 1.0135
Training Epoch: 24 [50176/50176]	Loss: 1.0091
2022-12-06 17:01:11.954 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:01:12,006 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.85 energy=494.42
2022-12-06 12:01:12,006 [ZeusDataLoader(train)] Up to epoch 25: time=1259.96, energy=172003.07, cost=196248.17
2022-12-06 12:01:12,006 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:01:12,007 [ZeusDataLoader(train)] Expected next epoch: time=1306.69, energy=178678.58, cost=203674.43
2022-12-06 12:01:12,007 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0016, Accuracy: 0.5782
2022-12-06 12:01:12,188 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:01:12,189 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:01:12.191 [ZeusMonitor] Monitor started.
2022-12-06 17:01:12.191 [ZeusMonitor] Running indefinitely. 2022-12-06 17:01:12.191 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:01:12.191 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 12:01:56,393 [ZeusDataLoader(train)] train epoch 26 done: time=44.38 energy=6320.75
2022-12-06 12:01:56,396 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.8650
Training Epoch: 25 [2048/50176]	Loss: 0.8801
Training Epoch: 25 [3072/50176]	Loss: 0.9113
Training Epoch: 25 [4096/50176]	Loss: 0.9089
Training Epoch: 25 [5120/50176]	Loss: 0.8984
Training Epoch: 25 [6144/50176]	Loss: 0.9205
Training Epoch: 25 [7168/50176]	Loss: 0.8502
Training Epoch: 25 [8192/50176]	Loss: 0.9312
Training Epoch: 25 [9216/50176]	Loss: 0.9694
Training Epoch: 25 [10240/50176]	Loss: 0.8582
Training Epoch: 25 [11264/50176]	Loss: 0.8975
Training Epoch: 25 [12288/50176]	Loss: 0.8483
Training Epoch: 25 [13312/50176]	Loss: 0.8768
Training Epoch: 25 [14336/50176]	Loss: 0.9049
Training Epoch: 25 [15360/50176]	Loss: 0.9332
Training Epoch: 25 [16384/50176]	Loss: 0.9561
Training Epoch: 25 [17408/50176]	Loss: 0.8720
Training Epoch: 25 [18432/50176]	Loss: 0.9440
Training Epoch: 25 [19456/50176]	Loss: 0.8734
Training Epoch: 25 [20480/50176]	Loss: 0.9127
Training Epoch: 25 [21504/50176]	Loss: 0.8933
Training Epoch: 25 [22528/50176]	Loss: 0.9560
Training Epoch: 25 [23552/50176]	Loss: 0.9109
Training Epoch: 25 [24576/50176]	Loss: 0.8863
Training Epoch: 25 [25600/50176]	Loss: 0.8282
Training Epoch: 25 [26624/50176]	Loss: 0.9371
Training Epoch: 25 [27648/50176]	Loss: 0.8850
Training Epoch: 25 [28672/50176]	Loss: 0.9241
Training Epoch: 25 [29696/50176]	Loss: 0.9078
Training Epoch: 25 [30720/50176]	Loss: 0.9827
Training Epoch: 25 [31744/50176]	Loss: 0.8526
Training Epoch: 25 [32768/50176]	Loss: 0.9232
Training Epoch: 25 [33792/50176]	Loss: 0.8538
Training Epoch: 25 [34816/50176]	Loss: 0.8985
Training Epoch: 25 [35840/50176]	Loss: 0.9398
Training Epoch: 25 [36864/50176]	Loss: 0.9110
Training Epoch: 25 [37888/50176]	Loss: 0.8854
Training Epoch: 25 [38912/50176]	Loss: 0.9135
Training Epoch: 25 [39936/50176]	Loss: 0.9505
Training Epoch: 25 [40960/50176]	Loss: 0.8514
Training Epoch: 25 [41984/50176]	Loss: 0.9432
Training Epoch: 25 [43008/50176]	Loss: 0.9724
Training Epoch: 25 [44032/50176]	Loss: 0.9381
Training Epoch: 25 [45056/50176]	Loss: 1.0045
Training Epoch: 25 [46080/50176]	Loss: 0.9538
Training Epoch: 25 [47104/50176]	Loss: 0.9972
Training Epoch: 25 [48128/50176]	Loss: 0.9804
Training Epoch: 25 [49152/50176]	Loss: 0.9323
Training Epoch: 25 [50176/50176]	Loss: 0.9950
2022-12-06 17:02:00.176 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:02:00,189 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.78 energy=493.65
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Up to epoch 26: time=1308.12, energy=178817.47, cost=203869.55
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:02:00,189 [ZeusDataLoader(train)] Expected next epoch: time=1354.85, energy=185492.98, cost=211295.80
2022-12-06 12:02:00,190 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0017, Accuracy: 0.5697
2022-12-06 12:02:00,377 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:02:00,378 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:02:00.392 [ZeusMonitor] Monitor started.
2022-12-06 17:02:00.392 [ZeusMonitor] Running indefinitely. 2022-12-06 17:02:00.392 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:02:00.392 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 12:02:44,767 [ZeusDataLoader(train)] train epoch 27 done: time=44.56 energy=6344.97
2022-12-06 12:02:44,774 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.7815
Training Epoch: 26 [2048/50176]	Loss: 0.8182
Training Epoch: 26 [3072/50176]	Loss: 0.8257
Training Epoch: 26 [4096/50176]	Loss: 0.8309
Training Epoch: 26 [5120/50176]	Loss: 0.8155
Training Epoch: 26 [6144/50176]	Loss: 0.8089
Training Epoch: 26 [7168/50176]	Loss: 0.7664
Training Epoch: 26 [8192/50176]	Loss: 0.8067
Training Epoch: 26 [9216/50176]	Loss: 0.8329
Training Epoch: 26 [10240/50176]	Loss: 0.8778
Training Epoch: 26 [11264/50176]	Loss: 0.7994
Training Epoch: 26 [12288/50176]	Loss: 0.8021
Training Epoch: 26 [13312/50176]	Loss: 0.7849
Training Epoch: 26 [14336/50176]	Loss: 0.8180
Training Epoch: 26 [15360/50176]	Loss: 0.7819
Training Epoch: 26 [16384/50176]	Loss: 0.7832
Training Epoch: 26 [17408/50176]	Loss: 0.8209
Training Epoch: 26 [18432/50176]	Loss: 0.8615
Training Epoch: 26 [19456/50176]	Loss: 0.8466
Training Epoch: 26 [20480/50176]	Loss: 0.8060
Training Epoch: 26 [21504/50176]	Loss: 0.8661
Training Epoch: 26 [22528/50176]	Loss: 0.7941
Training Epoch: 26 [23552/50176]	Loss: 0.8338
Training Epoch: 26 [24576/50176]	Loss: 0.8617
Training Epoch: 26 [25600/50176]	Loss: 0.8341
Training Epoch: 26 [26624/50176]	Loss: 0.8647
Training Epoch: 26 [27648/50176]	Loss: 0.8381
Training Epoch: 26 [28672/50176]	Loss: 0.7884
Training Epoch: 26 [29696/50176]	Loss: 0.8604
Training Epoch: 26 [30720/50176]	Loss: 0.9754
Training Epoch: 26 [31744/50176]	Loss: 0.8379
Training Epoch: 26 [32768/50176]	Loss: 0.8700
Training Epoch: 26 [33792/50176]	Loss: 0.8696
Training Epoch: 26 [34816/50176]	Loss: 0.8713
Training Epoch: 26 [35840/50176]	Loss: 0.8621
Training Epoch: 26 [36864/50176]	Loss: 0.8352
Training Epoch: 26 [37888/50176]	Loss: 0.8646
Training Epoch: 26 [38912/50176]	Loss: 0.8348
Training Epoch: 26 [39936/50176]	Loss: 0.9861
Training Epoch: 26 [40960/50176]	Loss: 0.8756
Training Epoch: 26 [41984/50176]	Loss: 0.9251
Training Epoch: 26 [43008/50176]	Loss: 0.8957
Training Epoch: 26 [44032/50176]	Loss: 0.8734
Training Epoch: 26 [45056/50176]	Loss: 0.8639
Training Epoch: 26 [46080/50176]	Loss: 0.9078
Training Epoch: 26 [47104/50176]	Loss: 0.9065
Training Epoch: 26 [48128/50176]	Loss: 0.9339
Training Epoch: 26 [49152/50176]	Loss: 0.8397
Training Epoch: 26 [50176/50176]	Loss: 0.8929
2022-12-06 17:02:48.918 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:02:48,944 [ZeusDataLoader(eval)] eval epoch 27 done: time=4.16 energy=505.77
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Up to epoch 27: time=1356.84, energy=185668.21, cost=211557.69
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:02:48,944 [ZeusDataLoader(train)] Expected next epoch: time=1403.57, energy=192343.72, cost=218983.95
2022-12-06 12:02:48,945 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0016, Accuracy: 0.5764
2022-12-06 12:02:49,155 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:02:49,156 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:02:49.158 [ZeusMonitor] Monitor started.
2022-12-06 17:02:49.158 [ZeusMonitor] Running indefinitely. 2022-12-06 17:02:49.158 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:02:49.158 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 12:03:33,550 [ZeusDataLoader(train)] train epoch 28 done: time=44.60 energy=6339.24
2022-12-06 12:03:33,554 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7236
Training Epoch: 27 [2048/50176]	Loss: 0.7694
Training Epoch: 27 [3072/50176]	Loss: 0.7302
Training Epoch: 27 [4096/50176]	Loss: 0.8191
Training Epoch: 27 [5120/50176]	Loss: 0.7735
Training Epoch: 27 [6144/50176]	Loss: 0.7334
Training Epoch: 27 [7168/50176]	Loss: 0.7281
Training Epoch: 27 [8192/50176]	Loss: 0.7528
Training Epoch: 27 [9216/50176]	Loss: 0.7637
Training Epoch: 27 [10240/50176]	Loss: 0.7587
Training Epoch: 27 [11264/50176]	Loss: 0.7868
Training Epoch: 27 [12288/50176]	Loss: 0.7699
Training Epoch: 27 [13312/50176]	Loss: 0.7691
Training Epoch: 27 [14336/50176]	Loss: 0.7667
Training Epoch: 27 [15360/50176]	Loss: 0.7599
Training Epoch: 27 [16384/50176]	Loss: 0.8061
Training Epoch: 27 [17408/50176]	Loss: 0.7479
Training Epoch: 27 [18432/50176]	Loss: 0.7690
Training Epoch: 27 [19456/50176]	Loss: 0.7663
Training Epoch: 27 [20480/50176]	Loss: 0.7462
Training Epoch: 27 [21504/50176]	Loss: 0.8066
Training Epoch: 27 [22528/50176]	Loss: 0.7826
Training Epoch: 27 [23552/50176]	Loss: 0.7521
Training Epoch: 27 [24576/50176]	Loss: 0.7929
Training Epoch: 27 [25600/50176]	Loss: 0.8300
Training Epoch: 27 [26624/50176]	Loss: 0.8276
Training Epoch: 27 [27648/50176]	Loss: 0.8552
Training Epoch: 27 [28672/50176]	Loss: 0.8085
Training Epoch: 27 [29696/50176]	Loss: 0.8019
Training Epoch: 27 [30720/50176]	Loss: 0.7572
Training Epoch: 27 [31744/50176]	Loss: 0.8431
Training Epoch: 27 [32768/50176]	Loss: 0.7760
Training Epoch: 27 [33792/50176]	Loss: 0.7651
Training Epoch: 27 [34816/50176]	Loss: 0.8183
Training Epoch: 27 [35840/50176]	Loss: 0.8319
Training Epoch: 27 [36864/50176]	Loss: 0.7865
Training Epoch: 27 [37888/50176]	Loss: 0.8199
Training Epoch: 27 [38912/50176]	Loss: 0.7884
Training Epoch: 27 [39936/50176]	Loss: 0.8294
Training Epoch: 27 [40960/50176]	Loss: 0.8052
Training Epoch: 27 [41984/50176]	Loss: 0.8097
Training Epoch: 27 [43008/50176]	Loss: 0.7785
Training Epoch: 27 [44032/50176]	Loss: 0.8811
Training Epoch: 27 [45056/50176]	Loss: 0.8201
Training Epoch: 27 [46080/50176]	Loss: 0.8102
Training Epoch: 27 [47104/50176]	Loss: 0.8943
Training Epoch: 27 [48128/50176]	Loss: 0.8114
Training Epoch: 27 [49152/50176]	Loss: 0.9260
Training Epoch: 27 [50176/50176]	Loss: 0.8879
2022-12-06 17:03:37.364 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:03:37,401 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.84 energy=491.04
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Up to epoch 28: time=1405.28, energy=192498.48, cost=219210.90
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:03:37,402 [ZeusDataLoader(train)] Expected next epoch: time=1452.00, energy=199173.99, cost=226637.16
2022-12-06 12:03:37,403 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0016, Accuracy: 0.5837
2022-12-06 12:03:37,551 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:03:37,551 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:03:37.555 [ZeusMonitor] Monitor started.
2022-12-06 17:03:37.555 [ZeusMonitor] Running indefinitely. 2022-12-06 17:03:37.555 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:03:37.555 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 12:04:21,674 [ZeusDataLoader(train)] train epoch 29 done: time=44.26 energy=6330.28
2022-12-06 12:04:21,678 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.7195
Training Epoch: 28 [2048/50176]	Loss: 0.7447
Training Epoch: 28 [3072/50176]	Loss: 0.7381
Training Epoch: 28 [4096/50176]	Loss: 0.7538
Training Epoch: 28 [5120/50176]	Loss: 0.7151
Training Epoch: 28 [6144/50176]	Loss: 0.6946
Training Epoch: 28 [7168/50176]	Loss: 0.7011
Training Epoch: 28 [8192/50176]	Loss: 0.7352
Training Epoch: 28 [9216/50176]	Loss: 0.7376
Training Epoch: 28 [10240/50176]	Loss: 0.6698
Training Epoch: 28 [11264/50176]	Loss: 0.7047
Training Epoch: 28 [12288/50176]	Loss: 0.7792
Training Epoch: 28 [13312/50176]	Loss: 0.7111
Training Epoch: 28 [14336/50176]	Loss: 0.7342
Training Epoch: 28 [15360/50176]	Loss: 0.7110
Training Epoch: 28 [16384/50176]	Loss: 0.7549
Training Epoch: 28 [17408/50176]	Loss: 0.7377
Training Epoch: 28 [18432/50176]	Loss: 0.6965
Training Epoch: 28 [19456/50176]	Loss: 0.7960
Training Epoch: 28 [20480/50176]	Loss: 0.7552
Training Epoch: 28 [21504/50176]	Loss: 0.7179
Training Epoch: 28 [22528/50176]	Loss: 0.7441
Training Epoch: 28 [23552/50176]	Loss: 0.8067
Training Epoch: 28 [24576/50176]	Loss: 0.6884
Training Epoch: 28 [25600/50176]	Loss: 0.7485
Training Epoch: 28 [26624/50176]	Loss: 0.7281
Training Epoch: 28 [27648/50176]	Loss: 0.7999
Training Epoch: 28 [28672/50176]	Loss: 0.7923
Training Epoch: 28 [29696/50176]	Loss: 0.7613
Training Epoch: 28 [30720/50176]	Loss: 0.7464
Training Epoch: 28 [31744/50176]	Loss: 0.8365
Training Epoch: 28 [32768/50176]	Loss: 0.7690
Training Epoch: 28 [33792/50176]	Loss: 0.7658
Training Epoch: 28 [34816/50176]	Loss: 0.8065
Training Epoch: 28 [35840/50176]	Loss: 0.7722
Training Epoch: 28 [36864/50176]	Loss: 0.7993
Training Epoch: 28 [37888/50176]	Loss: 0.7432
Training Epoch: 28 [38912/50176]	Loss: 0.7498
Training Epoch: 28 [39936/50176]	Loss: 0.8093
Training Epoch: 28 [40960/50176]	Loss: 0.8642
Training Epoch: 28 [41984/50176]	Loss: 0.7843
Training Epoch: 28 [43008/50176]	Loss: 0.7609
Training Epoch: 28 [44032/50176]	Loss: 0.7829
Training Epoch: 28 [45056/50176]	Loss: 0.9436
Training Epoch: 28 [46080/50176]	Loss: 0.7937
Training Epoch: 28 [47104/50176]	Loss: 0.8100
Training Epoch: 28 [48128/50176]	Loss: 0.7387
Training Epoch: 28 [49152/50176]	Loss: 0.8235
Training Epoch: 28 [50176/50176]	Loss: 0.8562
2022-12-06 17:04:25.345 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:04:25,369 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.68 energy=477.13
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Up to epoch 29: time=1453.22, energy=199305.90, cost=226809.95
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:04:25,369 [ZeusDataLoader(train)] Expected next epoch: time=1499.95, energy=205981.41, cost=234236.21
2022-12-06 12:04:25,370 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0016, Accuracy: 0.5829
2022-12-06 12:04:25,572 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:04:25,573 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:04:25.575 [ZeusMonitor] Monitor started.
2022-12-06 17:04:25.575 [ZeusMonitor] Running indefinitely. 2022-12-06 17:04:25.575 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:04:25.575 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 12:05:09,790 [ZeusDataLoader(train)] train epoch 30 done: time=44.41 energy=6314.41
2022-12-06 12:05:09,793 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6738
Training Epoch: 29 [2048/50176]	Loss: 0.7086
Training Epoch: 29 [3072/50176]	Loss: 0.7226
Training Epoch: 29 [4096/50176]	Loss: 0.6859
Training Epoch: 29 [5120/50176]	Loss: 0.7143
Training Epoch: 29 [6144/50176]	Loss: 0.6843
Training Epoch: 29 [7168/50176]	Loss: 0.6525
Training Epoch: 29 [8192/50176]	Loss: 0.6234
Training Epoch: 29 [9216/50176]	Loss: 0.7486
Training Epoch: 29 [10240/50176]	Loss: 0.6966
Training Epoch: 29 [11264/50176]	Loss: 0.7341
Training Epoch: 29 [12288/50176]	Loss: 0.7441
Training Epoch: 29 [13312/50176]	Loss: 0.6633
Training Epoch: 29 [14336/50176]	Loss: 0.6677
Training Epoch: 29 [15360/50176]	Loss: 0.8200
Training Epoch: 29 [16384/50176]	Loss: 0.6996
Training Epoch: 29 [17408/50176]	Loss: 0.7240
Training Epoch: 29 [18432/50176]	Loss: 0.7040
Training Epoch: 29 [19456/50176]	Loss: 0.7649
Training Epoch: 29 [20480/50176]	Loss: 0.7117
Training Epoch: 29 [21504/50176]	Loss: 0.7019
Training Epoch: 29 [22528/50176]	Loss: 0.6595
Training Epoch: 29 [23552/50176]	Loss: 0.6939
Training Epoch: 29 [24576/50176]	Loss: 0.7521
Training Epoch: 29 [25600/50176]	Loss: 0.7033
Training Epoch: 29 [26624/50176]	Loss: 0.6860
Training Epoch: 29 [27648/50176]	Loss: 0.7516
Training Epoch: 29 [28672/50176]	Loss: 0.6960
Training Epoch: 29 [29696/50176]	Loss: 0.6528
Training Epoch: 29 [30720/50176]	Loss: 0.7620
Training Epoch: 29 [31744/50176]	Loss: 0.7195
Training Epoch: 29 [32768/50176]	Loss: 0.7344
Training Epoch: 29 [33792/50176]	Loss: 0.7480
Training Epoch: 29 [34816/50176]	Loss: 0.8667
Training Epoch: 29 [35840/50176]	Loss: 0.6870
Training Epoch: 29 [36864/50176]	Loss: 0.7108
Training Epoch: 29 [37888/50176]	Loss: 0.7417
Training Epoch: 29 [38912/50176]	Loss: 0.7114
Training Epoch: 29 [39936/50176]	Loss: 0.7239
Training Epoch: 29 [40960/50176]	Loss: 0.7940
Training Epoch: 29 [41984/50176]	Loss: 0.7154
Training Epoch: 29 [43008/50176]	Loss: 0.8021
Training Epoch: 29 [44032/50176]	Loss: 0.7773
Training Epoch: 29 [45056/50176]	Loss: 0.7363
Training Epoch: 29 [46080/50176]	Loss: 0.7719
Training Epoch: 29 [47104/50176]	Loss: 0.7700
Training Epoch: 29 [48128/50176]	Loss: 0.7979
Training Epoch: 29 [49152/50176]	Loss: 0.7671
Training Epoch: 29 [50176/50176]	Loss: 0.8526
2022-12-06 17:05:13.582 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:05:13,606 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.81 energy=483.07
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Up to epoch 30: time=1501.44, energy=206103.38, cost=234427.70
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:05:13,607 [ZeusDataLoader(train)] Expected next epoch: time=1548.17, energy=212778.88, cost=241853.96
2022-12-06 12:05:13,608 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0017, Accuracy: 0.5779
2022-12-06 12:05:13,804 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:05:13,805 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:05:13.807 [ZeusMonitor] Monitor started.
2022-12-06 17:05:13.807 [ZeusMonitor] Running indefinitely. 2022-12-06 17:05:13.807 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:05:13.807 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 12:05:58,522 [ZeusDataLoader(train)] train epoch 31 done: time=44.91 energy=6347.97
2022-12-06 12:05:58,526 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7333
Training Epoch: 30 [2048/50176]	Loss: 0.6387
Training Epoch: 30 [3072/50176]	Loss: 0.6722
Training Epoch: 30 [4096/50176]	Loss: 0.6370
Training Epoch: 30 [5120/50176]	Loss: 0.6342
Training Epoch: 30 [6144/50176]	Loss: 0.6548
Training Epoch: 30 [7168/50176]	Loss: 0.6286
Training Epoch: 30 [8192/50176]	Loss: 0.6325
Training Epoch: 30 [9216/50176]	Loss: 0.6689
Training Epoch: 30 [10240/50176]	Loss: 0.6190
Training Epoch: 30 [11264/50176]	Loss: 0.6336
Training Epoch: 30 [12288/50176]	Loss: 0.6740
Training Epoch: 30 [13312/50176]	Loss: 0.6553
Training Epoch: 30 [14336/50176]	Loss: 0.7122
Training Epoch: 30 [15360/50176]	Loss: 0.6481
Training Epoch: 30 [16384/50176]	Loss: 0.6405
Training Epoch: 30 [17408/50176]	Loss: 0.6516
Training Epoch: 30 [18432/50176]	Loss: 0.5789
Training Epoch: 30 [19456/50176]	Loss: 0.6205
Training Epoch: 30 [20480/50176]	Loss: 0.6630
Training Epoch: 30 [21504/50176]	Loss: 0.6480
Training Epoch: 30 [22528/50176]	Loss: 0.6690
Training Epoch: 30 [23552/50176]	Loss: 0.6396
Training Epoch: 30 [24576/50176]	Loss: 0.6935
Training Epoch: 30 [25600/50176]	Loss: 0.6886
Training Epoch: 30 [26624/50176]	Loss: 0.6423
Training Epoch: 30 [27648/50176]	Loss: 0.6964
Training Epoch: 30 [28672/50176]	Loss: 0.7007
Training Epoch: 30 [29696/50176]	Loss: 0.7212
Training Epoch: 30 [30720/50176]	Loss: 0.6998
Training Epoch: 30 [31744/50176]	Loss: 0.6223
Training Epoch: 30 [32768/50176]	Loss: 0.6911
Training Epoch: 30 [33792/50176]	Loss: 0.6798
Training Epoch: 30 [34816/50176]	Loss: 0.6829
Training Epoch: 30 [35840/50176]	Loss: 0.7162
Training Epoch: 30 [36864/50176]	Loss: 0.6994
Training Epoch: 30 [37888/50176]	Loss: 0.7492
Training Epoch: 30 [38912/50176]	Loss: 0.6792
Training Epoch: 30 [39936/50176]	Loss: 0.6924
Training Epoch: 30 [40960/50176]	Loss: 0.7458
Training Epoch: 30 [41984/50176]	Loss: 0.7240
Training Epoch: 30 [43008/50176]	Loss: 0.7754
Training Epoch: 30 [44032/50176]	Loss: 0.7266
Training Epoch: 30 [45056/50176]	Loss: 0.7735
Training Epoch: 30 [46080/50176]	Loss: 0.7576
Training Epoch: 30 [47104/50176]	Loss: 0.6737
Training Epoch: 30 [48128/50176]	Loss: 0.7400
Training Epoch: 30 [49152/50176]	Loss: 0.7822
Training Epoch: 30 [50176/50176]	Loss: 0.8309
2022-12-06 17:06:02.310 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:06:02,348 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.81 energy=486.53
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Up to epoch 31: time=1550.16, energy=212937.88, cost=242107.90
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:06:02,348 [ZeusDataLoader(train)] Expected next epoch: time=1596.89, energy=219613.39, cost=249534.15
2022-12-06 12:06:02,349 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0017, Accuracy: 0.5922
2022-12-06 12:06:02,538 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:06:02,539 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:06:02.554 [ZeusMonitor] Monitor started.
2022-12-06 17:06:02.555 [ZeusMonitor] Running indefinitely. 2022-12-06 17:06:02.555 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:06:02.555 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 12:06:46,887 [ZeusDataLoader(train)] train epoch 32 done: time=44.53 energy=6338.21
2022-12-06 12:06:46,890 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.6106
Training Epoch: 31 [2048/50176]	Loss: 0.5720
Training Epoch: 31 [3072/50176]	Loss: 0.6245
Training Epoch: 31 [4096/50176]	Loss: 0.5914
Training Epoch: 31 [5120/50176]	Loss: 0.6213
Training Epoch: 31 [6144/50176]	Loss: 0.6107
Training Epoch: 31 [7168/50176]	Loss: 0.6271
Training Epoch: 31 [8192/50176]	Loss: 0.6409
Training Epoch: 31 [9216/50176]	Loss: 0.6342
Training Epoch: 31 [10240/50176]	Loss: 0.6439
Training Epoch: 31 [11264/50176]	Loss: 0.5904
Training Epoch: 31 [12288/50176]	Loss: 0.6440
Training Epoch: 31 [13312/50176]	Loss: 0.6962
Training Epoch: 31 [14336/50176]	Loss: 0.5905
Training Epoch: 31 [15360/50176]	Loss: 0.5772
Training Epoch: 31 [16384/50176]	Loss: 0.6108
Training Epoch: 31 [17408/50176]	Loss: 0.6288
Training Epoch: 31 [18432/50176]	Loss: 0.6424
Training Epoch: 31 [19456/50176]	Loss: 0.6297
Training Epoch: 31 [20480/50176]	Loss: 0.6692
Training Epoch: 31 [21504/50176]	Loss: 0.6905
Training Epoch: 31 [22528/50176]	Loss: 0.6054
Training Epoch: 31 [23552/50176]	Loss: 0.6632
Training Epoch: 31 [24576/50176]	Loss: 0.6207
Training Epoch: 31 [25600/50176]	Loss: 0.6488
Training Epoch: 31 [26624/50176]	Loss: 0.7067
Training Epoch: 31 [27648/50176]	Loss: 0.6089
Training Epoch: 31 [28672/50176]	Loss: 0.6448
Training Epoch: 31 [29696/50176]	Loss: 0.7157
Training Epoch: 31 [30720/50176]	Loss: 0.6277
Training Epoch: 31 [31744/50176]	Loss: 0.6704
Training Epoch: 31 [32768/50176]	Loss: 0.6824
Training Epoch: 31 [33792/50176]	Loss: 0.6655
Training Epoch: 31 [34816/50176]	Loss: 0.6543
Training Epoch: 31 [35840/50176]	Loss: 0.6987
Training Epoch: 31 [36864/50176]	Loss: 0.7134
Training Epoch: 31 [37888/50176]	Loss: 0.7166
Training Epoch: 31 [38912/50176]	Loss: 0.6970
Training Epoch: 31 [39936/50176]	Loss: 0.7696
Training Epoch: 31 [40960/50176]	Loss: 0.6626
Training Epoch: 31 [41984/50176]	Loss: 0.6592
Training Epoch: 31 [43008/50176]	Loss: 0.6539
Training Epoch: 31 [44032/50176]	Loss: 0.6477
Training Epoch: 31 [45056/50176]	Loss: 0.7320
Training Epoch: 31 [46080/50176]	Loss: 0.6786
Training Epoch: 31 [47104/50176]	Loss: 0.6989
Training Epoch: 31 [48128/50176]	Loss: 0.7875
Training Epoch: 31 [49152/50176]	Loss: 0.6966
Training Epoch: 31 [50176/50176]	Loss: 0.6594
2022-12-06 17:06:50.636 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:06:50,681 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.78 energy=491.63
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Up to epoch 32: time=1598.47, energy=219767.72, cost=249750.16
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:06:50,681 [ZeusDataLoader(train)] Expected next epoch: time=1645.20, energy=226443.23, cost=257176.41
2022-12-06 12:06:50,682 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5827
2022-12-06 12:06:50,872 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:06:50,872 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:06:50.874 [ZeusMonitor] Monitor started.
2022-12-06 17:06:50.874 [ZeusMonitor] Running indefinitely. 2022-12-06 17:06:50.874 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:06:50.874 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 12:07:35,228 [ZeusDataLoader(train)] train epoch 33 done: time=44.54 energy=6332.27
2022-12-06 12:07:35,231 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.5860
Training Epoch: 32 [2048/50176]	Loss: 0.5307
Training Epoch: 32 [3072/50176]	Loss: 0.6134
Training Epoch: 32 [4096/50176]	Loss: 0.5556
Training Epoch: 32 [5120/50176]	Loss: 0.6033
Training Epoch: 32 [6144/50176]	Loss: 0.6001
Training Epoch: 32 [7168/50176]	Loss: 0.5359
Training Epoch: 32 [8192/50176]	Loss: 0.5704
Training Epoch: 32 [9216/50176]	Loss: 0.5388
Training Epoch: 32 [10240/50176]	Loss: 0.5651
Training Epoch: 32 [11264/50176]	Loss: 0.5890
Training Epoch: 32 [12288/50176]	Loss: 0.6128
Training Epoch: 32 [13312/50176]	Loss: 0.5905
Training Epoch: 32 [14336/50176]	Loss: 0.6108
Training Epoch: 32 [15360/50176]	Loss: 0.5831
Training Epoch: 32 [16384/50176]	Loss: 0.5757
Training Epoch: 32 [17408/50176]	Loss: 0.5640
Training Epoch: 32 [18432/50176]	Loss: 0.5696
Training Epoch: 32 [19456/50176]	Loss: 0.5621
Training Epoch: 32 [20480/50176]	Loss: 0.6020
Training Epoch: 32 [21504/50176]	Loss: 0.6245
Training Epoch: 32 [22528/50176]	Loss: 0.6958
Training Epoch: 32 [23552/50176]	Loss: 0.6127
Training Epoch: 32 [24576/50176]	Loss: 0.5069
Training Epoch: 32 [25600/50176]	Loss: 0.6667
Training Epoch: 32 [26624/50176]	Loss: 0.5917
Training Epoch: 32 [27648/50176]	Loss: 0.5849
Training Epoch: 32 [28672/50176]	Loss: 0.5863
Training Epoch: 32 [29696/50176]	Loss: 0.5829
Training Epoch: 32 [30720/50176]	Loss: 0.5731
Training Epoch: 32 [31744/50176]	Loss: 0.6566
Training Epoch: 32 [32768/50176]	Loss: 0.6045
Training Epoch: 32 [33792/50176]	Loss: 0.6311
Training Epoch: 32 [34816/50176]	Loss: 0.6294
Training Epoch: 32 [35840/50176]	Loss: 0.6362
Training Epoch: 32 [36864/50176]	Loss: 0.6302
Training Epoch: 32 [37888/50176]	Loss: 0.6173
Training Epoch: 32 [38912/50176]	Loss: 0.6296
Training Epoch: 32 [39936/50176]	Loss: 0.6689
Training Epoch: 32 [40960/50176]	Loss: 0.6009
Training Epoch: 32 [41984/50176]	Loss: 0.5850
Training Epoch: 32 [43008/50176]	Loss: 0.6773
Training Epoch: 32 [44032/50176]	Loss: 0.6979
Training Epoch: 32 [45056/50176]	Loss: 0.6121
Training Epoch: 32 [46080/50176]	Loss: 0.6757
Training Epoch: 32 [47104/50176]	Loss: 0.6392
Training Epoch: 32 [48128/50176]	Loss: 0.6344
Training Epoch: 32 [49152/50176]	Loss: 0.7005
Training Epoch: 32 [50176/50176]	Loss: 0.6688
2022-12-06 17:07:39.043 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:07:39,096 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.86 energy=485.39
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Up to epoch 33: time=1646.87, energy=226585.38, cost=257393.53
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:07:39,097 [ZeusDataLoader(train)] Expected next epoch: time=1693.59, energy=233260.88, cost=264819.78
2022-12-06 12:07:39,098 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0017, Accuracy: 0.5884
2022-12-06 12:07:39,308 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:07:39,309 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:07:39.311 [ZeusMonitor] Monitor started.
2022-12-06 17:07:39.311 [ZeusMonitor] Running indefinitely. 2022-12-06 17:07:39.311 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:07:39.311 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 12:08:24,400 [ZeusDataLoader(train)] train epoch 34 done: time=45.29 energy=6400.54
2022-12-06 12:08:24,403 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.5475
Training Epoch: 33 [2048/50176]	Loss: 0.5254
Training Epoch: 33 [3072/50176]	Loss: 0.5564
Training Epoch: 33 [4096/50176]	Loss: 0.5569
Training Epoch: 33 [5120/50176]	Loss: 0.5456
Training Epoch: 33 [6144/50176]	Loss: 0.5404
Training Epoch: 33 [7168/50176]	Loss: 0.6189
Training Epoch: 33 [8192/50176]	Loss: 0.5248
Training Epoch: 33 [9216/50176]	Loss: 0.5437
Training Epoch: 33 [10240/50176]	Loss: 0.5493
Training Epoch: 33 [11264/50176]	Loss: 0.5389
Training Epoch: 33 [12288/50176]	Loss: 0.5335
Training Epoch: 33 [13312/50176]	Loss: 0.6272
Training Epoch: 33 [14336/50176]	Loss: 0.5398
Training Epoch: 33 [15360/50176]	Loss: 0.5768
Training Epoch: 33 [16384/50176]	Loss: 0.5970
Training Epoch: 33 [17408/50176]	Loss: 0.5253
Training Epoch: 33 [18432/50176]	Loss: 0.5826
Training Epoch: 33 [19456/50176]	Loss: 0.5674
Training Epoch: 33 [20480/50176]	Loss: 0.5808
Training Epoch: 33 [21504/50176]	Loss: 0.5988
Training Epoch: 33 [22528/50176]	Loss: 0.5478
Training Epoch: 33 [23552/50176]	Loss: 0.6380
Training Epoch: 33 [24576/50176]	Loss: 0.5710
Training Epoch: 33 [25600/50176]	Loss: 0.5765
Training Epoch: 33 [26624/50176]	Loss: 0.5642
Training Epoch: 33 [27648/50176]	Loss: 0.5639
Training Epoch: 33 [28672/50176]	Loss: 0.5487
Training Epoch: 33 [29696/50176]	Loss: 0.5886
Training Epoch: 33 [30720/50176]	Loss: 0.6197
Training Epoch: 33 [31744/50176]	Loss: 0.5881
Training Epoch: 33 [32768/50176]	Loss: 0.5740
Training Epoch: 33 [33792/50176]	Loss: 0.6867
Training Epoch: 33 [34816/50176]	Loss: 0.6215
Training Epoch: 33 [35840/50176]	Loss: 0.5511
Training Epoch: 33 [36864/50176]	Loss: 0.5931
Training Epoch: 33 [37888/50176]	Loss: 0.5962
Training Epoch: 33 [38912/50176]	Loss: 0.6161
Training Epoch: 33 [39936/50176]	Loss: 0.5977
Training Epoch: 33 [40960/50176]	Loss: 0.5593
Training Epoch: 33 [41984/50176]	Loss: 0.6234
Training Epoch: 33 [43008/50176]	Loss: 0.6062
Training Epoch: 33 [44032/50176]	Loss: 0.6471
Training Epoch: 33 [45056/50176]	Loss: 0.6775
Training Epoch: 33 [46080/50176]	Loss: 0.5763
Training Epoch: 33 [47104/50176]	Loss: 0.6229
Training Epoch: 33 [48128/50176]	Loss: 0.6245
Training Epoch: 33 [49152/50176]	Loss: 0.6085
Training Epoch: 33 [50176/50176]	Loss: 0.6396
2022-12-06 17:08:28.164 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:08:28,196 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.78 energy=475.00
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Up to epoch 34: time=1695.95, energy=233460.91, cost=265125.66
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.73 energy=6675.51
2022-12-06 12:08:28,196 [ZeusDataLoader(train)] Expected next epoch: time=1742.67, energy=240136.42, cost=272551.92
2022-12-06 12:08:28,197 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0018, Accuracy: 0.5785
2022-12-06 12:08:28,362 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:08:28,363 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:08:28.364 [ZeusMonitor] Monitor started.
2022-12-06 17:08:28.365 [ZeusMonitor] Running indefinitely. 2022-12-06 17:08:28.365 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:08:28.365 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 12:09:13,555 [ZeusDataLoader(train)] train epoch 35 done: time=45.35 energy=6399.22
2022-12-06 12:09:13,558 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.4784
Training Epoch: 34 [2048/50176]	Loss: 0.4875
Training Epoch: 34 [3072/50176]	Loss: 0.4935
Training Epoch: 34 [4096/50176]	Loss: 0.5091
Training Epoch: 34 [5120/50176]	Loss: 0.5224
Training Epoch: 34 [6144/50176]	Loss: 0.5004
Training Epoch: 34 [7168/50176]	Loss: 0.4702
Training Epoch: 34 [8192/50176]	Loss: 0.5334
Training Epoch: 34 [9216/50176]	Loss: 0.5133
Training Epoch: 34 [10240/50176]	Loss: 0.5668
Training Epoch: 34 [11264/50176]	Loss: 0.5317
Training Epoch: 34 [12288/50176]	Loss: 0.5339
Training Epoch: 34 [13312/50176]	Loss: 0.4974
Training Epoch: 34 [14336/50176]	Loss: 0.4863
Training Epoch: 34 [15360/50176]	Loss: 0.5369
Training Epoch: 34 [16384/50176]	Loss: 0.6396
Training Epoch: 34 [17408/50176]	Loss: 0.5008
Training Epoch: 34 [18432/50176]	Loss: 0.5440
Training Epoch: 34 [19456/50176]	Loss: 0.4616
Training Epoch: 34 [20480/50176]	Loss: 0.5518
Training Epoch: 34 [21504/50176]	Loss: 0.5518
Training Epoch: 34 [22528/50176]	Loss: 0.5799
Training Epoch: 34 [23552/50176]	Loss: 0.5352
Training Epoch: 34 [24576/50176]	Loss: 0.5089
Training Epoch: 34 [25600/50176]	Loss: 0.5513
Training Epoch: 34 [26624/50176]	Loss: 0.5997
Training Epoch: 34 [27648/50176]	Loss: 0.5742
Training Epoch: 34 [28672/50176]	Loss: 0.5601
Training Epoch: 34 [29696/50176]	Loss: 0.5416
Training Epoch: 34 [30720/50176]	Loss: 0.6042
Training Epoch: 34 [31744/50176]	Loss: 0.5387
Training Epoch: 34 [32768/50176]	Loss: 0.6150
Training Epoch: 34 [33792/50176]	Loss: 0.5652
Training Epoch: 34 [34816/50176]	Loss: 0.5530
Training Epoch: 34 [35840/50176]	Loss: 0.5783
Training Epoch: 34 [36864/50176]	Loss: 0.5699
Training Epoch: 34 [37888/50176]	Loss: 0.5572
Training Epoch: 34 [38912/50176]	Loss: 0.4868
Training Epoch: 34 [39936/50176]	Loss: 0.5579
Training Epoch: 34 [40960/50176]	Loss: 0.5486
Training Epoch: 34 [41984/50176]	Loss: 0.5109
Training Epoch: 34 [43008/50176]	Loss: 0.5645
Training Epoch: 34 [44032/50176]	Loss: 0.5817
Training Epoch: 34 [45056/50176]	Loss: 0.5584
Training Epoch: 34 [46080/50176]	Loss: 0.5581
Training Epoch: 34 [47104/50176]	Loss: 0.6355
Training Epoch: 34 [48128/50176]	Loss: 0.5851
Training Epoch: 34 [49152/50176]	Loss: 0.5880
Training Epoch: 34 [50176/50176]	Loss: 0.5423
2022-12-06 17:09:17.271 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:09:17,282 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.72 energy=483.29
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Up to epoch 35: time=1745.01, energy=240343.41, cost=272860.09
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Training done.
2022-12-06 12:09:17,282 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec00+try01+bs1024+lr0.0050000.train.json: {"energy": 240343.41170650077, "time": 1745.0100623509989, "cost": 272860.0863089628, "num_epochs": 35, "reached": true}
Validation Epoch: 34, Average loss: 0.0017, Accuracy: 0.6034

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 240343.41170650077, 'time': 1745.0100623509989, 'cost': 272860.0863089628, 'num_epochs': 35, 'reached': True}
[run job; power] power_stats={'job_id': 'rec00+try01', 'train_power': {'175000': 144.6526908887388, '150000': 142.9144590501422, '125000': 122.3746729763121, '100000': 96.26969013202073}, 'train_throughput': {'175000': 1.1426061331830712, '150000': 1.1181391463369061, '125000': 1.0411058844569772, '100000': 0.5428501950648409}, 'eval_power': {'175000': 122.91663523083511, '150000': 129.06686853531815, '125000': 112.79114027828794}, 'eval_throughput': {'175000': 2.6032730606481405, '150000': 2.6463149332718254, '125000': 2.435059632683371}, 'optimal_pl': 175000}
[Zeus Master] cost=272860.0863089628

[Zeus Master] Reached target metric in 1 try.
[run job] Launching job with BS 1024: and LR: 0.01
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec01+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.01']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec01+try01.train.log'
2022-12-06 12:09:21,875 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 12:09:21,875 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 12:09:21,875 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 12:09:21,917 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 12:09:21,918 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 12:09:24,032 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 12:09:24,033 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 12:09:24,195 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:09:24.200 [ZeusMonitor] Monitor started.
2022-12-06 17:09:24.200 [ZeusMonitor] Running indefinitely. 2022-12-06 17:09:24.200 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:09:24.200 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 12:09:24,925 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 12:09:24,925 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 12:09:33,807 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 12:10:07,551 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 12:10:09,198 [ZeusDataLoader(train)] train epoch 1 done: time=45.16 energy=6329.31
2022-12-06 12:10:09,202 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 7.2692
Training Epoch: 0 [3072/50176]	Loss: 5.6022
Training Epoch: 0 [4096/50176]	Loss: 4.9331
Training Epoch: 0 [5120/50176]	Loss: 4.8748
Training Epoch: 0 [6144/50176]	Loss: 4.7699
Training Epoch: 0 [7168/50176]	Loss: 4.7535
Training Epoch: 0 [8192/50176]	Loss: 4.6976
Training Epoch: 0 [9216/50176]	Loss: 6.0939
Training Epoch: 0 [10240/50176]	Loss: 4.7540
Training Epoch: 0 [11264/50176]	Loss: 4.8019
Training Epoch: 0 [12288/50176]	Loss: 4.7126
Training Epoch: 0 [13312/50176]	Loss: 4.7030
Training Epoch: 0 [14336/50176]	Loss: 4.7404
Training Epoch: 0 [15360/50176]	Loss: 4.6252
Training Epoch: 0 [16384/50176]	Loss: 4.5980
Training Epoch: 0 [17408/50176]	Loss: 4.5968
Training Epoch: 0 [18432/50176]	Loss: 4.6040
Training Epoch: 0 [19456/50176]	Loss: 4.5735
Training Epoch: 0 [20480/50176]	Loss: 4.5946
Training Epoch: 0 [21504/50176]	Loss: 4.5663
Training Epoch: 0 [22528/50176]	Loss: 4.5823
Training Epoch: 0 [23552/50176]	Loss: 4.6223
Training Epoch: 0 [24576/50176]	Loss: 4.5538
Training Epoch: 0 [25600/50176]	Loss: 4.6158
Training Epoch: 0 [26624/50176]	Loss: 4.5745
Training Epoch: 0 [27648/50176]	Loss: 4.5322
Training Epoch: 0 [28672/50176]	Loss: 4.5393
Training Epoch: 0 [29696/50176]	Loss: 4.5451
Training Epoch: 0 [30720/50176]	Loss: 4.6034
Training Epoch: 0 [31744/50176]	Loss: 4.5339
Training Epoch: 0 [32768/50176]	Loss: 4.5171
Training Epoch: 0 [33792/50176]	Loss: 4.5396
Training Epoch: 0 [34816/50176]	Loss: 4.4955
Training Epoch: 0 [35840/50176]	Loss: 4.4758
Training Epoch: 0 [36864/50176]	Loss: 4.4761
Training Epoch: 0 [37888/50176]	Loss: 4.4962
Training Epoch: 0 [38912/50176]	Loss: 4.4688
Training Epoch: 0 [39936/50176]	Loss: 4.4904
Training Epoch: 0 [40960/50176]	Loss: 4.4454
Training Epoch: 0 [41984/50176]	Loss: 4.4555
Training Epoch: 0 [43008/50176]	Loss: 4.4633
Training Epoch: 0 [44032/50176]	Loss: 4.4330
Training Epoch: 0 [45056/50176]	Loss: 4.4490
Training Epoch: 0 [46080/50176]	Loss: 4.3958
Training Epoch: 0 [47104/50176]	Loss: 4.4271
Training Epoch: 0 [48128/50176]	Loss: 4.4233
Training Epoch: 0 [49152/50176]	Loss: 4.4203
Training Epoch: 0 [50176/50176]	Loss: 4.4098
2022-12-06 17:10:12.936 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:10:12,959 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.75 energy=474.15
2022-12-06 12:10:12,960 [ZeusDataLoader(train)] Up to epoch 1: time=48.91, energy=6803.46, cost=7681.25
2022-12-06 12:10:12,961 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0044, Accuracy: 0.0208
2022-12-06 12:10:13,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:10:13.188 [ZeusMonitor] Monitor started.
2022-12-06 17:10:13.188 [ZeusMonitor] Running indefinitely. 2022-12-06 17:10:13.188 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:10:13.188 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 12:10:13,907 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 12:10:13,908 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 12:10:21,951 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 12:10:56,252 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 12:10:57,914 [ZeusDataLoader(train)] train epoch 2 done: time=44.95 energy=6269.74
2022-12-06 12:10:57,917 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.4206
Training Epoch: 1 [2048/50176]	Loss: 4.3597
Training Epoch: 1 [3072/50176]	Loss: 4.4074
Training Epoch: 1 [4096/50176]	Loss: 4.3957
Training Epoch: 1 [5120/50176]	Loss: 4.3885
Training Epoch: 1 [6144/50176]	Loss: 4.3978
Training Epoch: 1 [7168/50176]	Loss: 4.3665
Training Epoch: 1 [8192/50176]	Loss: 4.3558
Training Epoch: 1 [9216/50176]	Loss: 4.3997
Training Epoch: 1 [10240/50176]	Loss: 4.3638
Training Epoch: 1 [11264/50176]	Loss: 4.3951
Training Epoch: 1 [12288/50176]	Loss: 4.3481
Training Epoch: 1 [13312/50176]	Loss: 4.3574
Training Epoch: 1 [14336/50176]	Loss: 4.3475
Training Epoch: 1 [15360/50176]	Loss: 4.3612
Training Epoch: 1 [16384/50176]	Loss: 4.3866
Training Epoch: 1 [17408/50176]	Loss: 4.3490
Training Epoch: 1 [18432/50176]	Loss: 4.3175
Training Epoch: 1 [19456/50176]	Loss: 4.3592
Training Epoch: 1 [20480/50176]	Loss: 4.3259
Training Epoch: 1 [21504/50176]	Loss: 4.3268
Training Epoch: 1 [22528/50176]	Loss: 4.2630
Training Epoch: 1 [23552/50176]	Loss: 4.2728
Training Epoch: 1 [24576/50176]	Loss: 4.2490
Training Epoch: 1 [25600/50176]	Loss: 4.2440
Training Epoch: 1 [26624/50176]	Loss: 4.2493
Training Epoch: 1 [27648/50176]	Loss: 4.2505
Training Epoch: 1 [28672/50176]	Loss: 4.1914
Training Epoch: 1 [29696/50176]	Loss: 4.2678
Training Epoch: 1 [30720/50176]	Loss: 4.1900
Training Epoch: 1 [31744/50176]	Loss: 4.1840
Training Epoch: 1 [32768/50176]	Loss: 4.1085
Training Epoch: 1 [33792/50176]	Loss: 4.1977
Training Epoch: 1 [34816/50176]	Loss: 4.1752
Training Epoch: 1 [35840/50176]	Loss: 4.1762
Training Epoch: 1 [36864/50176]	Loss: 4.1379
Training Epoch: 1 [37888/50176]	Loss: 4.1030
Training Epoch: 1 [38912/50176]	Loss: 4.1017
Training Epoch: 1 [39936/50176]	Loss: 4.1324
Training Epoch: 1 [40960/50176]	Loss: 4.1361
Training Epoch: 1 [41984/50176]	Loss: 4.0830
Training Epoch: 1 [43008/50176]	Loss: 4.1022
Training Epoch: 1 [44032/50176]	Loss: 4.0581
Training Epoch: 1 [45056/50176]	Loss: 4.0717
Training Epoch: 1 [46080/50176]	Loss: 4.0283
Training Epoch: 1 [47104/50176]	Loss: 4.0752
Training Epoch: 1 [48128/50176]	Loss: 4.0251
Training Epoch: 1 [49152/50176]	Loss: 4.0677
Training Epoch: 1 [50176/50176]	Loss: 4.0660
2022-12-06 17:11:01.714 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:11:01,725 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.80 energy=482.02
2022-12-06 12:11:01,726 [ZeusDataLoader(train)] Up to epoch 2: time=97.66, energy=13555.22, cost=15322.52
2022-12-06 12:11:01,727 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0040, Accuracy: 0.0612
2022-12-06 12:11:01,903 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:11:01.907 [ZeusMonitor] Monitor started.
2022-12-06 17:11:01.907 [ZeusMonitor] Running indefinitely. 2022-12-06 17:11:01.907 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:11:01.907 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 12:11:02,638 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 12:11:02,638 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 12:11:11,383 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 12:11:47,886 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 12:11:49,694 [ZeusDataLoader(train)] train epoch 3 done: time=47.96 energy=5780.10
2022-12-06 12:11:49,698 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.9860
Training Epoch: 2 [2048/50176]	Loss: 4.0120
Training Epoch: 2 [3072/50176]	Loss: 4.0145
Training Epoch: 2 [4096/50176]	Loss: 3.9428
Training Epoch: 2 [5120/50176]	Loss: 3.9130
Training Epoch: 2 [6144/50176]	Loss: 3.9444
Training Epoch: 2 [7168/50176]	Loss: 3.9718
Training Epoch: 2 [8192/50176]	Loss: 4.0064
Training Epoch: 2 [9216/50176]	Loss: 3.9571
Training Epoch: 2 [10240/50176]	Loss: 3.8709
Training Epoch: 2 [11264/50176]	Loss: 3.9006
Training Epoch: 2 [12288/50176]	Loss: 3.8673
Training Epoch: 2 [13312/50176]	Loss: 3.8502
Training Epoch: 2 [14336/50176]	Loss: 3.8913
Training Epoch: 2 [15360/50176]	Loss: 3.9196
Training Epoch: 2 [16384/50176]	Loss: 3.9275
Training Epoch: 2 [17408/50176]	Loss: 3.9013
Training Epoch: 2 [18432/50176]	Loss: 3.9064
Training Epoch: 2 [19456/50176]	Loss: 3.8495
Training Epoch: 2 [20480/50176]	Loss: 3.8284
Training Epoch: 2 [21504/50176]	Loss: 3.8676
Training Epoch: 2 [22528/50176]	Loss: 3.8507
Training Epoch: 2 [23552/50176]	Loss: 3.8168
Training Epoch: 2 [24576/50176]	Loss: 3.9065
Training Epoch: 2 [25600/50176]	Loss: 3.8170
Training Epoch: 2 [26624/50176]	Loss: 3.8557
Training Epoch: 2 [27648/50176]	Loss: 3.8866
Training Epoch: 2 [28672/50176]	Loss: 3.8435
Training Epoch: 2 [29696/50176]	Loss: 3.7705
Training Epoch: 2 [30720/50176]	Loss: 3.7920
Training Epoch: 2 [31744/50176]	Loss: 3.7892
Training Epoch: 2 [32768/50176]	Loss: 3.8199
Training Epoch: 2 [33792/50176]	Loss: 3.8603
Training Epoch: 2 [34816/50176]	Loss: 3.8123
Training Epoch: 2 [35840/50176]	Loss: 3.7628
Training Epoch: 2 [36864/50176]	Loss: 3.8079
Training Epoch: 2 [37888/50176]	Loss: 3.8364
Training Epoch: 2 [38912/50176]	Loss: 3.7307
Training Epoch: 2 [39936/50176]	Loss: 3.7242
Training Epoch: 2 [40960/50176]	Loss: 3.7236
Training Epoch: 2 [41984/50176]	Loss: 3.7694
Training Epoch: 2 [43008/50176]	Loss: 3.7270
Training Epoch: 2 [44032/50176]	Loss: 3.6796
Training Epoch: 2 [45056/50176]	Loss: 3.7254
Training Epoch: 2 [46080/50176]	Loss: 3.7040
Training Epoch: 2 [47104/50176]	Loss: 3.6844
Training Epoch: 2 [48128/50176]	Loss: 3.6713
Training Epoch: 2 [49152/50176]	Loss: 3.7302
Training Epoch: 2 [50176/50176]	Loss: 3.6374
2022-12-06 17:11:53.654 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:11:53,698 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.99 energy=461.68
2022-12-06 12:11:53,699 [ZeusDataLoader(train)] Up to epoch 3: time=149.61, energy=19797.00, cost=22989.34
2022-12-06 12:11:53,700 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0037, Accuracy: 0.1043
2022-12-06 12:11:53,911 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 17:11:53.914 [ZeusMonitor] Monitor started.
2022-12-06 17:11:53.914 [ZeusMonitor] Running indefinitely. 2022-12-06 17:11:53.914 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:11:53.914 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 12:11:54,610 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 12:11:54,610 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 12:12:10,035 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 12:13:20,075 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 12:13:20,076 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 12:13:20,076 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-06 12:13:20,079 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 12:13:21,866 [ZeusDataLoader(train)] train epoch 4 done: time=88.16 energy=8474.45
2022-12-06 12:13:21,869 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.5898
Training Epoch: 3 [2048/50176]	Loss: 3.5782
Training Epoch: 3 [3072/50176]	Loss: 3.6088
Training Epoch: 3 [4096/50176]	Loss: 3.6489
Training Epoch: 3 [5120/50176]	Loss: 3.6305
Training Epoch: 3 [6144/50176]	Loss: 3.5934
Training Epoch: 3 [7168/50176]	Loss: 3.6376
Training Epoch: 3 [8192/50176]	Loss: 3.6216
Training Epoch: 3 [9216/50176]	Loss: 3.5688
Training Epoch: 3 [10240/50176]	Loss: 3.6138
Training Epoch: 3 [11264/50176]	Loss: 3.5711
Training Epoch: 3 [12288/50176]	Loss: 3.5699
Training Epoch: 3 [13312/50176]	Loss: 3.6157
Training Epoch: 3 [14336/50176]	Loss: 3.5746
Training Epoch: 3 [15360/50176]	Loss: 3.5611
Training Epoch: 3 [16384/50176]	Loss: 3.6028
Training Epoch: 3 [17408/50176]	Loss: 3.5473
Training Epoch: 3 [18432/50176]	Loss: 3.5954
Training Epoch: 3 [19456/50176]	Loss: 3.5702
Training Epoch: 3 [20480/50176]	Loss: 3.4948
Training Epoch: 3 [21504/50176]	Loss: 3.5583
Training Epoch: 3 [22528/50176]	Loss: 3.4890
Training Epoch: 3 [23552/50176]	Loss: 3.5185
Training Epoch: 3 [24576/50176]	Loss: 3.5230
Training Epoch: 3 [25600/50176]	Loss: 3.4276
Training Epoch: 3 [26624/50176]	Loss: 3.5901
Training Epoch: 3 [27648/50176]	Loss: 3.5446
Training Epoch: 3 [28672/50176]	Loss: 3.5117
Training Epoch: 3 [29696/50176]	Loss: 3.4826
Training Epoch: 3 [30720/50176]	Loss: 3.5333
Training Epoch: 3 [31744/50176]	Loss: 3.5222
Training Epoch: 3 [32768/50176]	Loss: 3.4988
Training Epoch: 3 [33792/50176]	Loss: 3.3969
Training Epoch: 3 [34816/50176]	Loss: 3.4941
Training Epoch: 3 [35840/50176]	Loss: 3.4454
Training Epoch: 3 [36864/50176]	Loss: 3.4631
Training Epoch: 3 [37888/50176]	Loss: 3.5453
Training Epoch: 3 [38912/50176]	Loss: 3.4574
Training Epoch: 3 [39936/50176]	Loss: 3.4790
Training Epoch: 3 [40960/50176]	Loss: 3.3878
Training Epoch: 3 [41984/50176]	Loss: 3.4546
Training Epoch: 3 [43008/50176]	Loss: 3.3320
Training Epoch: 3 [44032/50176]	Loss: 3.3597
Training Epoch: 3 [45056/50176]	Loss: 3.3600
Training Epoch: 3 [46080/50176]	Loss: 3.4297
Training Epoch: 3 [47104/50176]	Loss: 3.3444
Training Epoch: 3 [48128/50176]	Loss: 3.5252
Training Epoch: 3 [49152/50176]	Loss: 3.3710
Training Epoch: 3 [50176/50176]	Loss: 3.3911
2022-12-06 17:13:25.636 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0100000.power.json: {"job_id": "rec01+try01", "train_power": {"175000": 144.87586386206175, "150000": 142.4413747226752, "125000": 122.47472127317002, "100000": 96.50525059382247}, "train_throughput": {"175000": 1.1265477788311575, "150000": 1.1081640906025203, "125000": 1.0413129456183774, "100000": 0.5426340296975655}, "eval_power": {"175000": 127.69507531813454, "150000": 126.8275325321136, "125000": 115.63754995827681}, "eval_throughput": {"175000": 2.6466800540332938, "150000": 2.6311429884394997, "125000": 2.5047197850078424}, "optimal_pl": 175000}
2022-12-06 12:13:25,657 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.78 energy=482.47
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Up to epoch 4: time=241.55, energy=28753.93, cost=35512.24
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:13:25,657 [ZeusDataLoader(train)] Expected next epoch: time=288.82, energy=35537.88, cost=43040.69
2022-12-06 12:13:25,658 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0034, Accuracy: 0.1624
2022-12-06 12:13:25,829 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:13:25,829 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:13:25.833 [ZeusMonitor] Monitor started.
2022-12-06 17:13:25.833 [ZeusMonitor] Running indefinitely. 2022-12-06 17:13:25.833 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:13:25.833 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 12:14:10,047 [ZeusDataLoader(train)] train epoch 5 done: time=44.38 energy=6267.42
2022-12-06 12:14:10,050 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.4063
Training Epoch: 4 [2048/50176]	Loss: 3.3291
Training Epoch: 4 [3072/50176]	Loss: 3.2680
Training Epoch: 4 [4096/50176]	Loss: 3.2868
Training Epoch: 4 [5120/50176]	Loss: 3.3121
Training Epoch: 4 [6144/50176]	Loss: 3.3551
Training Epoch: 4 [7168/50176]	Loss: 3.2978
Training Epoch: 4 [8192/50176]	Loss: 3.3245
Training Epoch: 4 [9216/50176]	Loss: 3.3116
Training Epoch: 4 [10240/50176]	Loss: 3.2891
Training Epoch: 4 [11264/50176]	Loss: 3.3165
Training Epoch: 4 [12288/50176]	Loss: 3.2993
Training Epoch: 4 [13312/50176]	Loss: 3.2531
Training Epoch: 4 [14336/50176]	Loss: 3.3272
Training Epoch: 4 [15360/50176]	Loss: 3.2647
Training Epoch: 4 [16384/50176]	Loss: 3.1280
Training Epoch: 4 [17408/50176]	Loss: 3.2798
Training Epoch: 4 [18432/50176]	Loss: 3.2758
Training Epoch: 4 [19456/50176]	Loss: 3.2626
Training Epoch: 4 [20480/50176]	Loss: 3.2464
Training Epoch: 4 [21504/50176]	Loss: 3.2532
Training Epoch: 4 [22528/50176]	Loss: 3.1895
Training Epoch: 4 [23552/50176]	Loss: 3.1603
Training Epoch: 4 [24576/50176]	Loss: 3.1936
Training Epoch: 4 [25600/50176]	Loss: 3.1511
Training Epoch: 4 [26624/50176]	Loss: 3.1908
Training Epoch: 4 [27648/50176]	Loss: 3.2773
Training Epoch: 4 [28672/50176]	Loss: 3.1804
Training Epoch: 4 [29696/50176]	Loss: 3.2485
Training Epoch: 4 [30720/50176]	Loss: 3.2008
Training Epoch: 4 [31744/50176]	Loss: 3.1834
Training Epoch: 4 [32768/50176]	Loss: 3.2229
Training Epoch: 4 [33792/50176]	Loss: 3.1853
Training Epoch: 4 [34816/50176]	Loss: 3.1065
Training Epoch: 4 [35840/50176]	Loss: 3.2341
Training Epoch: 4 [36864/50176]	Loss: 3.1485
Training Epoch: 4 [37888/50176]	Loss: 3.2989
Training Epoch: 4 [38912/50176]	Loss: 3.1362
Training Epoch: 4 [39936/50176]	Loss: 3.1439
Training Epoch: 4 [40960/50176]	Loss: 3.1268
Training Epoch: 4 [41984/50176]	Loss: 3.0621
Training Epoch: 4 [43008/50176]	Loss: 3.1125
Training Epoch: 4 [44032/50176]	Loss: 3.0213
Training Epoch: 4 [45056/50176]	Loss: 3.1229
Training Epoch: 4 [46080/50176]	Loss: 3.1625
Training Epoch: 4 [47104/50176]	Loss: 3.1693
Training Epoch: 4 [48128/50176]	Loss: 3.1391
Training Epoch: 4 [49152/50176]	Loss: 3.1140
Training Epoch: 4 [50176/50176]	Loss: 3.1858
2022-12-06 17:14:13.987 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:14:14,017 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.96 energy=490.97
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Up to epoch 5: time=289.89, energy=35512.32, cost=43121.15
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:14:14,018 [ZeusDataLoader(train)] Expected next epoch: time=337.16, energy=42296.27, cost=50649.60
2022-12-06 12:14:14,019 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0032, Accuracy: 0.2041
2022-12-06 12:14:14,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:14:14,238 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:14:14.252 [ZeusMonitor] Monitor started.
2022-12-06 17:14:14.252 [ZeusMonitor] Running indefinitely. 2022-12-06 17:14:14.252 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:14:14.252 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 12:14:58,760 [ZeusDataLoader(train)] train epoch 6 done: time=44.73 energy=6326.94
2022-12-06 12:14:58,763 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.9563
Training Epoch: 5 [2048/50176]	Loss: 3.0004
Training Epoch: 5 [3072/50176]	Loss: 3.0997
Training Epoch: 5 [4096/50176]	Loss: 3.0537
Training Epoch: 5 [5120/50176]	Loss: 3.0336
Training Epoch: 5 [6144/50176]	Loss: 3.0359
Training Epoch: 5 [7168/50176]	Loss: 2.9642
Training Epoch: 5 [8192/50176]	Loss: 2.9951
Training Epoch: 5 [9216/50176]	Loss: 2.9865
Training Epoch: 5 [10240/50176]	Loss: 3.0399
Training Epoch: 5 [11264/50176]	Loss: 3.0934
Training Epoch: 5 [12288/50176]	Loss: 2.8902
Training Epoch: 5 [13312/50176]	Loss: 2.9725
Training Epoch: 5 [14336/50176]	Loss: 2.9433
Training Epoch: 5 [15360/50176]	Loss: 3.0814
Training Epoch: 5 [16384/50176]	Loss: 2.9742
Training Epoch: 5 [17408/50176]	Loss: 3.0131
Training Epoch: 5 [18432/50176]	Loss: 2.9494
Training Epoch: 5 [19456/50176]	Loss: 3.0111
Training Epoch: 5 [20480/50176]	Loss: 2.9507
Training Epoch: 5 [21504/50176]	Loss: 2.9631
Training Epoch: 5 [22528/50176]	Loss: 3.0175
Training Epoch: 5 [23552/50176]	Loss: 3.0109
Training Epoch: 5 [24576/50176]	Loss: 2.9940
Training Epoch: 5 [25600/50176]	Loss: 2.9868
Training Epoch: 5 [26624/50176]	Loss: 2.9075
Training Epoch: 5 [27648/50176]	Loss: 2.9379
Training Epoch: 5 [28672/50176]	Loss: 2.9552
Training Epoch: 5 [29696/50176]	Loss: 2.9199
Training Epoch: 5 [30720/50176]	Loss: 2.8690
Training Epoch: 5 [31744/50176]	Loss: 2.9687
Training Epoch: 5 [32768/50176]	Loss: 2.9600
Training Epoch: 5 [33792/50176]	Loss: 2.8845
Training Epoch: 5 [34816/50176]	Loss: 2.9285
Training Epoch: 5 [35840/50176]	Loss: 3.0645
Training Epoch: 5 [36864/50176]	Loss: 2.8677
Training Epoch: 5 [37888/50176]	Loss: 2.8436
Training Epoch: 5 [38912/50176]	Loss: 2.9040
Training Epoch: 5 [39936/50176]	Loss: 2.9541
Training Epoch: 5 [40960/50176]	Loss: 2.7901
Training Epoch: 5 [41984/50176]	Loss: 2.9610
Training Epoch: 5 [43008/50176]	Loss: 2.8984
Training Epoch: 5 [44032/50176]	Loss: 2.9068
Training Epoch: 5 [45056/50176]	Loss: 2.9729
Training Epoch: 5 [46080/50176]	Loss: 2.8450
Training Epoch: 5 [47104/50176]	Loss: 2.8860
Training Epoch: 5 [48128/50176]	Loss: 2.8550
Training Epoch: 5 [49152/50176]	Loss: 2.9020
Training Epoch: 5 [50176/50176]	Loss: 2.8539
2022-12-06 17:15:02.450 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:15:02,484 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.71 energy=471.46
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Up to epoch 6: time=338.33, energy=42310.71, cost=50759.36
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:15:02,484 [ZeusDataLoader(train)] Expected next epoch: time=385.61, energy=49094.67, cost=58287.82
2022-12-06 12:15:02,485 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0029, Accuracy: 0.2611
2022-12-06 12:15:02,704 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:15:02,704 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:15:02.706 [ZeusMonitor] Monitor started.
2022-12-06 17:15:02.706 [ZeusMonitor] Running indefinitely. 2022-12-06 17:15:02.706 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:15:02.706 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 12:15:46,654 [ZeusDataLoader(train)] train epoch 7 done: time=44.16 energy=6293.87
2022-12-06 12:15:46,658 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.8185
Training Epoch: 6 [2048/50176]	Loss: 2.7465
Training Epoch: 6 [3072/50176]	Loss: 2.8982
Training Epoch: 6 [4096/50176]	Loss: 2.8028
Training Epoch: 6 [5120/50176]	Loss: 2.7192
Training Epoch: 6 [6144/50176]	Loss: 2.7052
Training Epoch: 6 [7168/50176]	Loss: 2.8001
Training Epoch: 6 [8192/50176]	Loss: 2.7520
Training Epoch: 6 [9216/50176]	Loss: 2.9003
Training Epoch: 6 [10240/50176]	Loss: 2.7731
Training Epoch: 6 [11264/50176]	Loss: 2.7315
Training Epoch: 6 [12288/50176]	Loss: 2.8034
Training Epoch: 6 [13312/50176]	Loss: 2.7995
Training Epoch: 6 [14336/50176]	Loss: 2.7677
Training Epoch: 6 [15360/50176]	Loss: 2.6551
Training Epoch: 6 [16384/50176]	Loss: 2.7565
Training Epoch: 6 [17408/50176]	Loss: 2.7130
Training Epoch: 6 [18432/50176]	Loss: 2.7794
Training Epoch: 6 [19456/50176]	Loss: 2.6563
Training Epoch: 6 [20480/50176]	Loss: 2.8020
Training Epoch: 6 [21504/50176]	Loss: 2.8078
Training Epoch: 6 [22528/50176]	Loss: 2.7608
Training Epoch: 6 [23552/50176]	Loss: 2.7170
Training Epoch: 6 [24576/50176]	Loss: 2.7047
Training Epoch: 6 [25600/50176]	Loss: 2.6504
Training Epoch: 6 [26624/50176]	Loss: 2.7095
Training Epoch: 6 [27648/50176]	Loss: 2.7098
Training Epoch: 6 [28672/50176]	Loss: 2.6106
Training Epoch: 6 [29696/50176]	Loss: 2.7183
Training Epoch: 6 [30720/50176]	Loss: 2.7219
Training Epoch: 6 [31744/50176]	Loss: 2.6931
Training Epoch: 6 [32768/50176]	Loss: 2.6702
Training Epoch: 6 [33792/50176]	Loss: 2.7171
Training Epoch: 6 [34816/50176]	Loss: 2.7634
Training Epoch: 6 [35840/50176]	Loss: 2.6162
Training Epoch: 6 [36864/50176]	Loss: 2.7386
Training Epoch: 6 [37888/50176]	Loss: 2.7664
Training Epoch: 6 [38912/50176]	Loss: 2.6960
Training Epoch: 6 [39936/50176]	Loss: 2.6587
Training Epoch: 6 [40960/50176]	Loss: 2.6744
Training Epoch: 6 [41984/50176]	Loss: 2.6731
Training Epoch: 6 [43008/50176]	Loss: 2.6460
Training Epoch: 6 [44032/50176]	Loss: 2.6601
Training Epoch: 6 [45056/50176]	Loss: 2.6809
Training Epoch: 6 [46080/50176]	Loss: 2.7140
Training Epoch: 6 [47104/50176]	Loss: 2.6507
Training Epoch: 6 [48128/50176]	Loss: 2.6781
Training Epoch: 6 [49152/50176]	Loss: 2.6216
Training Epoch: 6 [50176/50176]	Loss: 2.6240
2022-12-06 17:15:50.494 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:15:50,545 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.88 energy=484.94
2022-12-06 12:15:50,545 [ZeusDataLoader(train)] Up to epoch 7: time=386.37, energy=49089.53, cost=58352.39
2022-12-06 12:15:50,546 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:15:50,546 [ZeusDataLoader(train)] Expected next epoch: time=433.65, energy=55873.48, cost=65880.84
2022-12-06 12:15:50,547 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0027, Accuracy: 0.3030
2022-12-06 12:15:50,751 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:15:50,752 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:15:50.756 [ZeusMonitor] Monitor started.
2022-12-06 17:15:50.756 [ZeusMonitor] Running indefinitely. 2022-12-06 17:15:50.756 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:15:50.756 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 12:16:34,554 [ZeusDataLoader(train)] train epoch 8 done: time=44.00 energy=6298.77
2022-12-06 12:16:34,557 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.5663
Training Epoch: 7 [2048/50176]	Loss: 2.5452
Training Epoch: 7 [3072/50176]	Loss: 2.4976
Training Epoch: 7 [4096/50176]	Loss: 2.5012
Training Epoch: 7 [5120/50176]	Loss: 2.5959
Training Epoch: 7 [6144/50176]	Loss: 2.5570
Training Epoch: 7 [7168/50176]	Loss: 2.5030
Training Epoch: 7 [8192/50176]	Loss: 2.4973
Training Epoch: 7 [9216/50176]	Loss: 2.4024
Training Epoch: 7 [10240/50176]	Loss: 2.4930
Training Epoch: 7 [11264/50176]	Loss: 2.4376
Training Epoch: 7 [12288/50176]	Loss: 2.5551
Training Epoch: 7 [13312/50176]	Loss: 2.5035
Training Epoch: 7 [14336/50176]	Loss: 2.6342
Training Epoch: 7 [15360/50176]	Loss: 2.5190
Training Epoch: 7 [16384/50176]	Loss: 2.5171
Training Epoch: 7 [17408/50176]	Loss: 2.5772
Training Epoch: 7 [18432/50176]	Loss: 2.5156
Training Epoch: 7 [19456/50176]	Loss: 2.4943
Training Epoch: 7 [20480/50176]	Loss: 2.5456
Training Epoch: 7 [21504/50176]	Loss: 2.5989
Training Epoch: 7 [22528/50176]	Loss: 2.4611
Training Epoch: 7 [23552/50176]	Loss: 2.5023
Training Epoch: 7 [24576/50176]	Loss: 2.4875
Training Epoch: 7 [25600/50176]	Loss: 2.5689
Training Epoch: 7 [26624/50176]	Loss: 2.5462
Training Epoch: 7 [27648/50176]	Loss: 2.5676
Training Epoch: 7 [28672/50176]	Loss: 2.5178
Training Epoch: 7 [29696/50176]	Loss: 2.5313
Training Epoch: 7 [30720/50176]	Loss: 2.5158
Training Epoch: 7 [31744/50176]	Loss: 2.5748
Training Epoch: 7 [32768/50176]	Loss: 2.3992
Training Epoch: 7 [33792/50176]	Loss: 2.5138
Training Epoch: 7 [34816/50176]	Loss: 2.5655
Training Epoch: 7 [35840/50176]	Loss: 2.4385
Training Epoch: 7 [36864/50176]	Loss: 2.3902
Training Epoch: 7 [37888/50176]	Loss: 2.4096
Training Epoch: 7 [38912/50176]	Loss: 2.4930
Training Epoch: 7 [39936/50176]	Loss: 2.5838
Training Epoch: 7 [40960/50176]	Loss: 2.5435
Training Epoch: 7 [41984/50176]	Loss: 2.3495
Training Epoch: 7 [43008/50176]	Loss: 2.3500
Training Epoch: 7 [44032/50176]	Loss: 2.3898
Training Epoch: 7 [45056/50176]	Loss: 2.4684
Training Epoch: 7 [46080/50176]	Loss: 2.4580
Training Epoch: 7 [47104/50176]	Loss: 2.4149
Training Epoch: 7 [48128/50176]	Loss: 2.3975
Training Epoch: 7 [49152/50176]	Loss: 2.4992
Training Epoch: 7 [50176/50176]	Loss: 2.4142
2022-12-06 17:16:38.317 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:16:38,343 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.78 energy=497.03
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Up to epoch 8: time=434.15, energy=55885.32, cost=65930.83
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:16:38,344 [ZeusDataLoader(train)] Expected next epoch: time=481.42, energy=62669.28, cost=73459.28
2022-12-06 12:16:38,345 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0026, Accuracy: 0.3319
2022-12-06 12:16:38,557 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:16:38,557 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:16:38.559 [ZeusMonitor] Monitor started.
2022-12-06 17:16:38.559 [ZeusMonitor] Running indefinitely. 2022-12-06 17:16:38.559 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:16:38.559 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 12:17:22,831 [ZeusDataLoader(train)] train epoch 9 done: time=44.48 energy=6323.16
2022-12-06 12:17:22,834 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.4281
Training Epoch: 8 [2048/50176]	Loss: 2.3750
Training Epoch: 8 [3072/50176]	Loss: 2.3843
Training Epoch: 8 [4096/50176]	Loss: 2.3391
Training Epoch: 8 [5120/50176]	Loss: 2.2565
Training Epoch: 8 [6144/50176]	Loss: 2.2765
Training Epoch: 8 [7168/50176]	Loss: 2.3832
Training Epoch: 8 [8192/50176]	Loss: 2.3403
Training Epoch: 8 [9216/50176]	Loss: 2.3341
Training Epoch: 8 [10240/50176]	Loss: 2.3709
Training Epoch: 8 [11264/50176]	Loss: 2.3045
Training Epoch: 8 [12288/50176]	Loss: 2.3570
Training Epoch: 8 [13312/50176]	Loss: 2.3069
Training Epoch: 8 [14336/50176]	Loss: 2.3074
Training Epoch: 8 [15360/50176]	Loss: 2.4284
Training Epoch: 8 [16384/50176]	Loss: 2.2933
Training Epoch: 8 [17408/50176]	Loss: 2.3808
Training Epoch: 8 [18432/50176]	Loss: 2.3371
Training Epoch: 8 [19456/50176]	Loss: 2.3092
Training Epoch: 8 [20480/50176]	Loss: 2.2576
Training Epoch: 8 [21504/50176]	Loss: 2.3173
Training Epoch: 8 [22528/50176]	Loss: 2.3282
Training Epoch: 8 [23552/50176]	Loss: 2.3205
Training Epoch: 8 [24576/50176]	Loss: 2.3669
Training Epoch: 8 [25600/50176]	Loss: 2.3500
Training Epoch: 8 [26624/50176]	Loss: 2.3100
Training Epoch: 8 [27648/50176]	Loss: 2.2753
Training Epoch: 8 [28672/50176]	Loss: 2.3639
Training Epoch: 8 [29696/50176]	Loss: 2.3575
Training Epoch: 8 [30720/50176]	Loss: 2.2945
Training Epoch: 8 [31744/50176]	Loss: 2.2453
Training Epoch: 8 [32768/50176]	Loss: 2.2806
Training Epoch: 8 [33792/50176]	Loss: 2.4170
Training Epoch: 8 [34816/50176]	Loss: 2.3555
Training Epoch: 8 [35840/50176]	Loss: 2.3208
Training Epoch: 8 [36864/50176]	Loss: 2.2858
Training Epoch: 8 [37888/50176]	Loss: 2.3639
Training Epoch: 8 [38912/50176]	Loss: 2.2992
Training Epoch: 8 [39936/50176]	Loss: 2.4305
Training Epoch: 8 [40960/50176]	Loss: 2.2885
Training Epoch: 8 [41984/50176]	Loss: 2.3272
Training Epoch: 8 [43008/50176]	Loss: 2.3280
Training Epoch: 8 [44032/50176]	Loss: 2.3825
Training Epoch: 8 [45056/50176]	Loss: 2.3085
Training Epoch: 8 [46080/50176]	Loss: 2.2659
Training Epoch: 8 [47104/50176]	Loss: 2.3571
Training Epoch: 8 [48128/50176]	Loss: 2.2323
Training Epoch: 8 [49152/50176]	Loss: 2.2745
Training Epoch: 8 [50176/50176]	Loss: 2.3027
2022-12-06 17:17:26.560 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:17:26,586 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.74 energy=476.52
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Up to epoch 9: time=482.37, energy=62685.00, cost=73550.06
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:17:26,586 [ZeusDataLoader(train)] Expected next epoch: time=529.65, energy=69468.96, cost=81078.52
2022-12-06 12:17:26,587 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0026, Accuracy: 0.3223
2022-12-06 12:17:26,808 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:17:26,809 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:17:26.818 [ZeusMonitor] Monitor started.
2022-12-06 17:17:26.818 [ZeusMonitor] Running indefinitely. 2022-12-06 17:17:26.818 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:17:26.818 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 12:18:11,270 [ZeusDataLoader(train)] train epoch 10 done: time=44.68 energy=6337.35
2022-12-06 12:18:11,274 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.2287
Training Epoch: 9 [2048/50176]	Loss: 2.2523
Training Epoch: 9 [3072/50176]	Loss: 2.2677
Training Epoch: 9 [4096/50176]	Loss: 2.1733
Training Epoch: 9 [5120/50176]	Loss: 2.3190
Training Epoch: 9 [6144/50176]	Loss: 2.1331
Training Epoch: 9 [7168/50176]	Loss: 2.2534
Training Epoch: 9 [8192/50176]	Loss: 2.2401
Training Epoch: 9 [9216/50176]	Loss: 2.1990
Training Epoch: 9 [10240/50176]	Loss: 2.2031
Training Epoch: 9 [11264/50176]	Loss: 2.3334
Training Epoch: 9 [12288/50176]	Loss: 2.1999
Training Epoch: 9 [13312/50176]	Loss: 2.1831
Training Epoch: 9 [14336/50176]	Loss: 2.2271
Training Epoch: 9 [15360/50176]	Loss: 2.2267
Training Epoch: 9 [16384/50176]	Loss: 2.2671
Training Epoch: 9 [17408/50176]	Loss: 2.1582
Training Epoch: 9 [18432/50176]	Loss: 2.2571
Training Epoch: 9 [19456/50176]	Loss: 2.1318
Training Epoch: 9 [20480/50176]	Loss: 2.2247
Training Epoch: 9 [21504/50176]	Loss: 2.2025
Training Epoch: 9 [22528/50176]	Loss: 2.1423
Training Epoch: 9 [23552/50176]	Loss: 2.1025
Training Epoch: 9 [24576/50176]	Loss: 2.1989
Training Epoch: 9 [25600/50176]	Loss: 2.1434
Training Epoch: 9 [26624/50176]	Loss: 2.1264
Training Epoch: 9 [27648/50176]	Loss: 2.2443
Training Epoch: 9 [28672/50176]	Loss: 2.2014
Training Epoch: 9 [29696/50176]	Loss: 2.2252
Training Epoch: 9 [30720/50176]	Loss: 2.1381
Training Epoch: 9 [31744/50176]	Loss: 2.2467
Training Epoch: 9 [32768/50176]	Loss: 2.1739
Training Epoch: 9 [33792/50176]	Loss: 2.1305
Training Epoch: 9 [34816/50176]	Loss: 2.2283
Training Epoch: 9 [35840/50176]	Loss: 2.1375
Training Epoch: 9 [36864/50176]	Loss: 2.1650
Training Epoch: 9 [37888/50176]	Loss: 2.1888
Training Epoch: 9 [38912/50176]	Loss: 2.2058
Training Epoch: 9 [39936/50176]	Loss: 2.1524
Training Epoch: 9 [40960/50176]	Loss: 2.2251
Training Epoch: 9 [41984/50176]	Loss: 2.1151
Training Epoch: 9 [43008/50176]	Loss: 2.2090
Training Epoch: 9 [44032/50176]	Loss: 2.1456
Training Epoch: 9 [45056/50176]	Loss: 2.0714
Training Epoch: 9 [46080/50176]	Loss: 2.1271
Training Epoch: 9 [47104/50176]	Loss: 2.1614
Training Epoch: 9 [48128/50176]	Loss: 2.0812
Training Epoch: 9 [49152/50176]	Loss: 2.1337
Training Epoch: 9 [50176/50176]	Loss: 2.0916
2022-12-06 17:18:15.095 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:18:15,120 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.84 energy=480.79
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Up to epoch 10: time=530.89, energy=69503.14, cost=81204.16
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:18:15,121 [ZeusDataLoader(train)] Expected next epoch: time=578.16, energy=76287.09, cost=88732.61
2022-12-06 12:18:15,122 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0023, Accuracy: 0.3846
2022-12-06 12:18:15,293 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:18:15,293 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:18:15.295 [ZeusMonitor] Monitor started.
2022-12-06 17:18:15.295 [ZeusMonitor] Running indefinitely. 2022-12-06 17:18:15.295 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:18:15.295 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 12:18:59,673 [ZeusDataLoader(train)] train epoch 11 done: time=44.54 energy=6336.49
2022-12-06 12:18:59,676 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 2.0917
Training Epoch: 10 [2048/50176]	Loss: 2.0795
Training Epoch: 10 [3072/50176]	Loss: 2.0594
Training Epoch: 10 [4096/50176]	Loss: 2.1435
Training Epoch: 10 [5120/50176]	Loss: 2.0145
Training Epoch: 10 [6144/50176]	Loss: 2.1191
Training Epoch: 10 [7168/50176]	Loss: 2.0136
Training Epoch: 10 [8192/50176]	Loss: 2.0503
Training Epoch: 10 [9216/50176]	Loss: 2.0048
Training Epoch: 10 [10240/50176]	Loss: 1.9905
Training Epoch: 10 [11264/50176]	Loss: 2.1351
Training Epoch: 10 [12288/50176]	Loss: 2.0282
Training Epoch: 10 [13312/50176]	Loss: 2.1514
Training Epoch: 10 [14336/50176]	Loss: 2.1062
Training Epoch: 10 [15360/50176]	Loss: 2.0974
Training Epoch: 10 [16384/50176]	Loss: 2.1347
Training Epoch: 10 [17408/50176]	Loss: 2.1656
Training Epoch: 10 [18432/50176]	Loss: 2.0226
Training Epoch: 10 [19456/50176]	Loss: 2.0883
Training Epoch: 10 [20480/50176]	Loss: 2.0313
Training Epoch: 10 [21504/50176]	Loss: 2.0950
Training Epoch: 10 [22528/50176]	Loss: 2.0829
Training Epoch: 10 [23552/50176]	Loss: 1.9970
Training Epoch: 10 [24576/50176]	Loss: 2.0823
Training Epoch: 10 [25600/50176]	Loss: 2.0383
Training Epoch: 10 [26624/50176]	Loss: 2.0121
Training Epoch: 10 [27648/50176]	Loss: 2.0150
Training Epoch: 10 [28672/50176]	Loss: 2.1179
Training Epoch: 10 [29696/50176]	Loss: 2.1646
Training Epoch: 10 [30720/50176]	Loss: 1.9454
Training Epoch: 10 [31744/50176]	Loss: 2.0789
Training Epoch: 10 [32768/50176]	Loss: 2.0106
Training Epoch: 10 [33792/50176]	Loss: 2.0403
Training Epoch: 10 [34816/50176]	Loss: 2.0756
Training Epoch: 10 [35840/50176]	Loss: 2.1561
Training Epoch: 10 [36864/50176]	Loss: 2.0566
Training Epoch: 10 [37888/50176]	Loss: 1.9118
Training Epoch: 10 [38912/50176]	Loss: 2.0055
Training Epoch: 10 [39936/50176]	Loss: 2.1302
Training Epoch: 10 [40960/50176]	Loss: 1.9503
Training Epoch: 10 [41984/50176]	Loss: 1.9544
Training Epoch: 10 [43008/50176]	Loss: 2.0519
Training Epoch: 10 [44032/50176]	Loss: 2.0581
Training Epoch: 10 [45056/50176]	Loss: 1.9546
Training Epoch: 10 [46080/50176]	Loss: 1.9045
Training Epoch: 10 [47104/50176]	Loss: 2.0222
Training Epoch: 10 [48128/50176]	Loss: 2.0152
Training Epoch: 10 [49152/50176]	Loss: 2.0692
Training Epoch: 10 [50176/50176]	Loss: 2.0204
2022-12-06 17:19:03.418 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:19:03,466 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.78 energy=490.67
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Up to epoch 11: time=579.21, energy=76330.30, cost=88846.16
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:19:03,466 [ZeusDataLoader(train)] Expected next epoch: time=626.49, energy=83114.25, cost=96374.61
2022-12-06 12:19:03,467 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0023, Accuracy: 0.4015
2022-12-06 12:19:03,628 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:19:03,629 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:19:03.632 [ZeusMonitor] Monitor started.
2022-12-06 17:19:03.632 [ZeusMonitor] Running indefinitely. 2022-12-06 17:19:03.632 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:19:03.632 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 12:19:47,750 [ZeusDataLoader(train)] train epoch 12 done: time=44.28 energy=6313.32
2022-12-06 12:19:47,753 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.8688
Training Epoch: 11 [2048/50176]	Loss: 1.9038
Training Epoch: 11 [3072/50176]	Loss: 1.9000
Training Epoch: 11 [4096/50176]	Loss: 2.0402
Training Epoch: 11 [5120/50176]	Loss: 2.0050
Training Epoch: 11 [6144/50176]	Loss: 1.8311
Training Epoch: 11 [7168/50176]	Loss: 1.8619
Training Epoch: 11 [8192/50176]	Loss: 1.9308
Training Epoch: 11 [9216/50176]	Loss: 1.9030
Training Epoch: 11 [10240/50176]	Loss: 1.9810
Training Epoch: 11 [11264/50176]	Loss: 1.9220
Training Epoch: 11 [12288/50176]	Loss: 1.8937
Training Epoch: 11 [13312/50176]	Loss: 2.0175
Training Epoch: 11 [14336/50176]	Loss: 1.8756
Training Epoch: 11 [15360/50176]	Loss: 1.9712
Training Epoch: 11 [16384/50176]	Loss: 1.9270
Training Epoch: 11 [17408/50176]	Loss: 1.9132
Training Epoch: 11 [18432/50176]	Loss: 1.9387
Training Epoch: 11 [19456/50176]	Loss: 1.8664
Training Epoch: 11 [20480/50176]	Loss: 1.9995
Training Epoch: 11 [21504/50176]	Loss: 1.9793
Training Epoch: 11 [22528/50176]	Loss: 1.9397
Training Epoch: 11 [23552/50176]	Loss: 2.0041
Training Epoch: 11 [24576/50176]	Loss: 1.8828
Training Epoch: 11 [25600/50176]	Loss: 1.9853
Training Epoch: 11 [26624/50176]	Loss: 1.8593
Training Epoch: 11 [27648/50176]	Loss: 1.9564
Training Epoch: 11 [28672/50176]	Loss: 1.9347
Training Epoch: 11 [29696/50176]	Loss: 1.9862
Training Epoch: 11 [30720/50176]	Loss: 1.9167
Training Epoch: 11 [31744/50176]	Loss: 1.9175
Training Epoch: 11 [32768/50176]	Loss: 1.9712
Training Epoch: 11 [33792/50176]	Loss: 1.9995
Training Epoch: 11 [34816/50176]	Loss: 2.0363
Training Epoch: 11 [35840/50176]	Loss: 2.0060
Training Epoch: 11 [36864/50176]	Loss: 1.9395
Training Epoch: 11 [37888/50176]	Loss: 1.9913
Training Epoch: 11 [38912/50176]	Loss: 1.9509
Training Epoch: 11 [39936/50176]	Loss: 1.9142
Training Epoch: 11 [40960/50176]	Loss: 1.8913
Training Epoch: 11 [41984/50176]	Loss: 1.9372
Training Epoch: 11 [43008/50176]	Loss: 2.0099
Training Epoch: 11 [44032/50176]	Loss: 1.8974
Training Epoch: 11 [45056/50176]	Loss: 2.0069
Training Epoch: 11 [46080/50176]	Loss: 1.8288
Training Epoch: 11 [47104/50176]	Loss: 1.9613
Training Epoch: 11 [48128/50176]	Loss: 1.8786
Training Epoch: 11 [49152/50176]	Loss: 1.8754
Training Epoch: 11 [50176/50176]	Loss: 1.9650
2022-12-06 17:19:51.467 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:19:51,498 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.74 energy=476.42
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Up to epoch 12: time=627.22, energy=83120.03, cost=96442.06
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:19:51,498 [ZeusDataLoader(train)] Expected next epoch: time=674.50, energy=89903.98, cost=103970.51
2022-12-06 12:19:51,499 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0021, Accuracy: 0.4262
2022-12-06 12:19:51,746 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:19:51,747 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:19:51.748 [ZeusMonitor] Monitor started.
2022-12-06 17:19:51.749 [ZeusMonitor] Running indefinitely. 2022-12-06 17:19:51.749 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:19:51.749 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 12:20:35,665 [ZeusDataLoader(train)] train epoch 13 done: time=44.16 energy=6309.46
2022-12-06 12:20:35,668 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.8662
Training Epoch: 12 [2048/50176]	Loss: 1.8275
Training Epoch: 12 [3072/50176]	Loss: 1.8527
Training Epoch: 12 [4096/50176]	Loss: 1.8066
Training Epoch: 12 [5120/50176]	Loss: 1.7771
Training Epoch: 12 [6144/50176]	Loss: 1.8289
Training Epoch: 12 [7168/50176]	Loss: 1.9264
Training Epoch: 12 [8192/50176]	Loss: 1.7563
Training Epoch: 12 [9216/50176]	Loss: 1.8826
Training Epoch: 12 [10240/50176]	Loss: 1.8332
Training Epoch: 12 [11264/50176]	Loss: 1.9429
Training Epoch: 12 [12288/50176]	Loss: 1.8065
Training Epoch: 12 [13312/50176]	Loss: 1.7846
Training Epoch: 12 [14336/50176]	Loss: 1.8621
Training Epoch: 12 [15360/50176]	Loss: 1.7384
Training Epoch: 12 [16384/50176]	Loss: 1.8213
Training Epoch: 12 [17408/50176]	Loss: 1.8196
Training Epoch: 12 [18432/50176]	Loss: 1.8189
Training Epoch: 12 [19456/50176]	Loss: 1.7886
Training Epoch: 12 [20480/50176]	Loss: 1.8489
Training Epoch: 12 [21504/50176]	Loss: 1.9132
Training Epoch: 12 [22528/50176]	Loss: 1.7593
Training Epoch: 12 [23552/50176]	Loss: 1.8886
Training Epoch: 12 [24576/50176]	Loss: 1.7315
Training Epoch: 12 [25600/50176]	Loss: 1.8976
Training Epoch: 12 [26624/50176]	Loss: 1.9768
Training Epoch: 12 [27648/50176]	Loss: 1.8368
Training Epoch: 12 [28672/50176]	Loss: 1.8679
Training Epoch: 12 [29696/50176]	Loss: 1.8054
Training Epoch: 12 [30720/50176]	Loss: 1.8332
Training Epoch: 12 [31744/50176]	Loss: 1.8256
Training Epoch: 12 [32768/50176]	Loss: 1.8722
Training Epoch: 12 [33792/50176]	Loss: 1.7943
Training Epoch: 12 [34816/50176]	Loss: 1.7928
Training Epoch: 12 [35840/50176]	Loss: 1.7722
Training Epoch: 12 [36864/50176]	Loss: 1.8557
Training Epoch: 12 [37888/50176]	Loss: 1.8925
Training Epoch: 12 [38912/50176]	Loss: 1.7479
Training Epoch: 12 [39936/50176]	Loss: 1.8688
Training Epoch: 12 [40960/50176]	Loss: 1.7744
Training Epoch: 12 [41984/50176]	Loss: 1.9149
Training Epoch: 12 [43008/50176]	Loss: 1.8340
Training Epoch: 12 [44032/50176]	Loss: 1.9044
Training Epoch: 12 [45056/50176]	Loss: 1.7615
Training Epoch: 12 [46080/50176]	Loss: 1.8684
Training Epoch: 12 [47104/50176]	Loss: 1.7826
Training Epoch: 12 [48128/50176]	Loss: 1.7692
Training Epoch: 12 [49152/50176]	Loss: 1.8565
Training Epoch: 12 [50176/50176]	Loss: 1.7421
2022-12-06 17:20:39.432 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:20:39,454 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.78 energy=485.12
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Up to epoch 13: time=675.16, energy=89914.61, cost=104033.74
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:20:39,455 [ZeusDataLoader(train)] Expected next epoch: time=722.43, energy=96698.56, cost=111562.19
2022-12-06 12:20:39,456 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0021, Accuracy: 0.4374
2022-12-06 12:20:39,677 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:20:39,678 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:20:39.680 [ZeusMonitor] Monitor started.
2022-12-06 17:20:39.680 [ZeusMonitor] Running indefinitely. 2022-12-06 17:20:39.680 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:20:39.680 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 12:21:23,966 [ZeusDataLoader(train)] train epoch 14 done: time=44.50 energy=6329.56
2022-12-06 12:21:23,969 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.6987
Training Epoch: 13 [2048/50176]	Loss: 1.7216
Training Epoch: 13 [3072/50176]	Loss: 1.7560
Training Epoch: 13 [4096/50176]	Loss: 1.6326
Training Epoch: 13 [5120/50176]	Loss: 1.7207
Training Epoch: 13 [6144/50176]	Loss: 1.7851
Training Epoch: 13 [7168/50176]	Loss: 1.7168
Training Epoch: 13 [8192/50176]	Loss: 1.7408
Training Epoch: 13 [9216/50176]	Loss: 1.6817
Training Epoch: 13 [10240/50176]	Loss: 1.8625
Training Epoch: 13 [11264/50176]	Loss: 1.6766
Training Epoch: 13 [12288/50176]	Loss: 1.7282
Training Epoch: 13 [13312/50176]	Loss: 1.7259
Training Epoch: 13 [14336/50176]	Loss: 1.7044
Training Epoch: 13 [15360/50176]	Loss: 1.7584
Training Epoch: 13 [16384/50176]	Loss: 1.7374
Training Epoch: 13 [17408/50176]	Loss: 1.7378
Training Epoch: 13 [18432/50176]	Loss: 1.6743
Training Epoch: 13 [19456/50176]	Loss: 1.7813
Training Epoch: 13 [20480/50176]	Loss: 1.7286
Training Epoch: 13 [21504/50176]	Loss: 1.6766
Training Epoch: 13 [22528/50176]	Loss: 1.6548
Training Epoch: 13 [23552/50176]	Loss: 1.7288
Training Epoch: 13 [24576/50176]	Loss: 1.6669
Training Epoch: 13 [25600/50176]	Loss: 1.7599
Training Epoch: 13 [26624/50176]	Loss: 1.8227
Training Epoch: 13 [27648/50176]	Loss: 1.6803
Training Epoch: 13 [28672/50176]	Loss: 1.7358
Training Epoch: 13 [29696/50176]	Loss: 1.7344
Training Epoch: 13 [30720/50176]	Loss: 1.7102
Training Epoch: 13 [31744/50176]	Loss: 1.7661
Training Epoch: 13 [32768/50176]	Loss: 1.6381
Training Epoch: 13 [33792/50176]	Loss: 1.7578
Training Epoch: 13 [34816/50176]	Loss: 1.8114
Training Epoch: 13 [35840/50176]	Loss: 1.8153
Training Epoch: 13 [36864/50176]	Loss: 1.6912
Training Epoch: 13 [37888/50176]	Loss: 1.8238
Training Epoch: 13 [38912/50176]	Loss: 1.6229
Training Epoch: 13 [39936/50176]	Loss: 1.7063
Training Epoch: 13 [40960/50176]	Loss: 1.7405
Training Epoch: 13 [41984/50176]	Loss: 1.7626
Training Epoch: 13 [43008/50176]	Loss: 1.6197
Training Epoch: 13 [44032/50176]	Loss: 1.7909
Training Epoch: 13 [45056/50176]	Loss: 1.7180
Training Epoch: 13 [46080/50176]	Loss: 1.6965
Training Epoch: 13 [47104/50176]	Loss: 1.7364
Training Epoch: 13 [48128/50176]	Loss: 1.7411
Training Epoch: 13 [49152/50176]	Loss: 1.6521
Training Epoch: 13 [50176/50176]	Loss: 1.7830
2022-12-06 17:21:27.782 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:21:27,804 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.83 energy=488.05
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Up to epoch 14: time=723.49, energy=96732.23, cost=111671.27
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:21:27,804 [ZeusDataLoader(train)] Expected next epoch: time=770.76, energy=103516.18, cost=119199.72
2022-12-06 12:21:27,805 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0019, Accuracy: 0.4712
2022-12-06 12:21:28,015 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:21:28,016 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:21:28.017 [ZeusMonitor] Monitor started.
2022-12-06 17:21:28.018 [ZeusMonitor] Running indefinitely. 2022-12-06 17:21:28.018 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:21:28.018 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 12:22:12,380 [ZeusDataLoader(train)] train epoch 15 done: time=44.57 energy=6337.73
2022-12-06 12:22:12,384 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.5892
Training Epoch: 14 [2048/50176]	Loss: 1.6590
Training Epoch: 14 [3072/50176]	Loss: 1.6605
Training Epoch: 14 [4096/50176]	Loss: 1.7317
Training Epoch: 14 [5120/50176]	Loss: 1.5602
Training Epoch: 14 [6144/50176]	Loss: 1.6604
Training Epoch: 14 [7168/50176]	Loss: 1.5634
Training Epoch: 14 [8192/50176]	Loss: 1.6242
Training Epoch: 14 [9216/50176]	Loss: 1.5893
Training Epoch: 14 [10240/50176]	Loss: 1.6165
Training Epoch: 14 [11264/50176]	Loss: 1.6025
Training Epoch: 14 [12288/50176]	Loss: 1.6964
Training Epoch: 14 [13312/50176]	Loss: 1.6635
Training Epoch: 14 [14336/50176]	Loss: 1.5946
Training Epoch: 14 [15360/50176]	Loss: 1.6152
Training Epoch: 14 [16384/50176]	Loss: 1.5429
Training Epoch: 14 [17408/50176]	Loss: 1.6715
Training Epoch: 14 [18432/50176]	Loss: 1.6502
Training Epoch: 14 [19456/50176]	Loss: 1.6417
Training Epoch: 14 [20480/50176]	Loss: 1.6677
Training Epoch: 14 [21504/50176]	Loss: 1.6437
Training Epoch: 14 [22528/50176]	Loss: 1.6022
Training Epoch: 14 [23552/50176]	Loss: 1.6784
Training Epoch: 14 [24576/50176]	Loss: 1.7006
Training Epoch: 14 [25600/50176]	Loss: 1.7566
Training Epoch: 14 [26624/50176]	Loss: 1.5873
Training Epoch: 14 [27648/50176]	Loss: 1.6062
Training Epoch: 14 [28672/50176]	Loss: 1.7189
Training Epoch: 14 [29696/50176]	Loss: 1.6130
Training Epoch: 14 [30720/50176]	Loss: 1.6523
Training Epoch: 14 [31744/50176]	Loss: 1.6231
Training Epoch: 14 [32768/50176]	Loss: 1.7701
Training Epoch: 14 [33792/50176]	Loss: 1.7180
Training Epoch: 14 [34816/50176]	Loss: 1.6605
Training Epoch: 14 [35840/50176]	Loss: 1.6641
Training Epoch: 14 [36864/50176]	Loss: 1.7503
Training Epoch: 14 [37888/50176]	Loss: 1.6544
Training Epoch: 14 [38912/50176]	Loss: 1.7287
Training Epoch: 14 [39936/50176]	Loss: 1.6775
Training Epoch: 14 [40960/50176]	Loss: 1.6670
Training Epoch: 14 [41984/50176]	Loss: 1.7811
Training Epoch: 14 [43008/50176]	Loss: 1.6810
Training Epoch: 14 [44032/50176]	Loss: 1.6709
Training Epoch: 14 [45056/50176]	Loss: 1.6844
Training Epoch: 14 [46080/50176]	Loss: 1.6261
Training Epoch: 14 [47104/50176]	Loss: 1.5781
Training Epoch: 14 [48128/50176]	Loss: 1.6281
Training Epoch: 14 [49152/50176]	Loss: 1.6692
Training Epoch: 14 [50176/50176]	Loss: 1.6262
2022-12-06 17:22:16.125 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:22:16,158 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.77 energy=478.38
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Up to epoch 15: time=771.82, energy=103548.34, cost=119308.52
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:22:16,158 [ZeusDataLoader(train)] Expected next epoch: time=819.10, energy=110332.29, cost=126836.97
2022-12-06 12:22:16,159 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0020, Accuracy: 0.4678
2022-12-06 12:22:16,378 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:22:16,378 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:22:16.380 [ZeusMonitor] Monitor started.
2022-12-06 17:22:16.380 [ZeusMonitor] Running indefinitely. 2022-12-06 17:22:16.380 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:22:16.380 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 12:23:00,379 [ZeusDataLoader(train)] train epoch 16 done: time=44.21 energy=6314.42
2022-12-06 12:23:00,383 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.6161
Training Epoch: 15 [2048/50176]	Loss: 1.5174
Training Epoch: 15 [3072/50176]	Loss: 1.5690
Training Epoch: 15 [4096/50176]	Loss: 1.5410
Training Epoch: 15 [5120/50176]	Loss: 1.5181
Training Epoch: 15 [6144/50176]	Loss: 1.5746
Training Epoch: 15 [7168/50176]	Loss: 1.5144
Training Epoch: 15 [8192/50176]	Loss: 1.6135
Training Epoch: 15 [9216/50176]	Loss: 1.5513
Training Epoch: 15 [10240/50176]	Loss: 1.5135
Training Epoch: 15 [11264/50176]	Loss: 1.5328
Training Epoch: 15 [12288/50176]	Loss: 1.6070
Training Epoch: 15 [13312/50176]	Loss: 1.5138
Training Epoch: 15 [14336/50176]	Loss: 1.5350
Training Epoch: 15 [15360/50176]	Loss: 1.5721
Training Epoch: 15 [16384/50176]	Loss: 1.6241
Training Epoch: 15 [17408/50176]	Loss: 1.5904
Training Epoch: 15 [18432/50176]	Loss: 1.5718
Training Epoch: 15 [19456/50176]	Loss: 1.5307
Training Epoch: 15 [20480/50176]	Loss: 1.5145
Training Epoch: 15 [21504/50176]	Loss: 1.5243
Training Epoch: 15 [22528/50176]	Loss: 1.6972
Training Epoch: 15 [23552/50176]	Loss: 1.6019
Training Epoch: 15 [24576/50176]	Loss: 1.5317
Training Epoch: 15 [25600/50176]	Loss: 1.5904
Training Epoch: 15 [26624/50176]	Loss: 1.5974
Training Epoch: 15 [27648/50176]	Loss: 1.6379
Training Epoch: 15 [28672/50176]	Loss: 1.5241
Training Epoch: 15 [29696/50176]	Loss: 1.5950
Training Epoch: 15 [30720/50176]	Loss: 1.5554
Training Epoch: 15 [31744/50176]	Loss: 1.6451
Training Epoch: 15 [32768/50176]	Loss: 1.5650
Training Epoch: 15 [33792/50176]	Loss: 1.5290
Training Epoch: 15 [34816/50176]	Loss: 1.6832
Training Epoch: 15 [35840/50176]	Loss: 1.6097
Training Epoch: 15 [36864/50176]	Loss: 1.5249
Training Epoch: 15 [37888/50176]	Loss: 1.5858
Training Epoch: 15 [38912/50176]	Loss: 1.5055
Training Epoch: 15 [39936/50176]	Loss: 1.5726
Training Epoch: 15 [40960/50176]	Loss: 1.6268
Training Epoch: 15 [41984/50176]	Loss: 1.6205
Training Epoch: 15 [43008/50176]	Loss: 1.6191
Training Epoch: 15 [44032/50176]	Loss: 1.5865
Training Epoch: 15 [45056/50176]	Loss: 1.5088
Training Epoch: 15 [46080/50176]	Loss: 1.5788
Training Epoch: 15 [47104/50176]	Loss: 1.5359
Training Epoch: 15 [48128/50176]	Loss: 1.6329
Training Epoch: 15 [49152/50176]	Loss: 1.5076
Training Epoch: 15 [50176/50176]	Loss: 1.5567
2022-12-06 17:23:04.137 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:23:04,185 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.79 energy=477.40
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Up to epoch 16: time=819.83, energy=110340.16, cost=126905.00
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:23:04,186 [ZeusDataLoader(train)] Expected next epoch: time=867.10, energy=117124.11, cost=134433.46
2022-12-06 12:23:04,187 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0018, Accuracy: 0.4964
2022-12-06 12:23:04,346 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:23:04,347 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:23:04.350 [ZeusMonitor] Monitor started.
2022-12-06 17:23:04.351 [ZeusMonitor] Running indefinitely. 2022-12-06 17:23:04.351 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:23:04.351 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 12:23:48,562 [ZeusDataLoader(train)] train epoch 17 done: time=44.37 energy=6324.15
2022-12-06 12:23:48,565 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.4721
Training Epoch: 16 [2048/50176]	Loss: 1.4755
Training Epoch: 16 [3072/50176]	Loss: 1.5033
Training Epoch: 16 [4096/50176]	Loss: 1.4711
Training Epoch: 16 [5120/50176]	Loss: 1.4875
Training Epoch: 16 [6144/50176]	Loss: 1.4559
Training Epoch: 16 [7168/50176]	Loss: 1.4783
Training Epoch: 16 [8192/50176]	Loss: 1.3940
Training Epoch: 16 [9216/50176]	Loss: 1.4604
Training Epoch: 16 [10240/50176]	Loss: 1.3689
Training Epoch: 16 [11264/50176]	Loss: 1.5578
Training Epoch: 16 [12288/50176]	Loss: 1.4800
Training Epoch: 16 [13312/50176]	Loss: 1.5174
Training Epoch: 16 [14336/50176]	Loss: 1.5315
Training Epoch: 16 [15360/50176]	Loss: 1.5048
Training Epoch: 16 [16384/50176]	Loss: 1.4848
Training Epoch: 16 [17408/50176]	Loss: 1.4348
Training Epoch: 16 [18432/50176]	Loss: 1.6198
Training Epoch: 16 [19456/50176]	Loss: 1.5043
Training Epoch: 16 [20480/50176]	Loss: 1.4669
Training Epoch: 16 [21504/50176]	Loss: 1.4312
Training Epoch: 16 [22528/50176]	Loss: 1.4729
Training Epoch: 16 [23552/50176]	Loss: 1.5206
Training Epoch: 16 [24576/50176]	Loss: 1.5003
Training Epoch: 16 [25600/50176]	Loss: 1.5064
Training Epoch: 16 [26624/50176]	Loss: 1.4474
Training Epoch: 16 [27648/50176]	Loss: 1.5253
Training Epoch: 16 [28672/50176]	Loss: 1.5310
Training Epoch: 16 [29696/50176]	Loss: 1.4339
Training Epoch: 16 [30720/50176]	Loss: 1.4333
Training Epoch: 16 [31744/50176]	Loss: 1.4652
Training Epoch: 16 [32768/50176]	Loss: 1.5342
Training Epoch: 16 [33792/50176]	Loss: 1.4703
Training Epoch: 16 [34816/50176]	Loss: 1.4510
Training Epoch: 16 [35840/50176]	Loss: 1.5104
Training Epoch: 16 [36864/50176]	Loss: 1.5347
Training Epoch: 16 [37888/50176]	Loss: 1.4285
Training Epoch: 16 [38912/50176]	Loss: 1.4851
Training Epoch: 16 [39936/50176]	Loss: 1.5755
Training Epoch: 16 [40960/50176]	Loss: 1.4905
Training Epoch: 16 [41984/50176]	Loss: 1.4935
Training Epoch: 16 [43008/50176]	Loss: 1.4622
Training Epoch: 16 [44032/50176]	Loss: 1.5616
Training Epoch: 16 [45056/50176]	Loss: 1.5976
Training Epoch: 16 [46080/50176]	Loss: 1.5192
Training Epoch: 16 [47104/50176]	Loss: 1.5097
Training Epoch: 16 [48128/50176]	Loss: 1.5630
Training Epoch: 16 [49152/50176]	Loss: 1.6030
Training Epoch: 16 [50176/50176]	Loss: 1.4910
2022-12-06 17:23:52.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:23:52,487 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.91 energy=495.88
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Up to epoch 17: time=868.11, energy=117160.20, cost=134539.65
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:23:52,488 [ZeusDataLoader(train)] Expected next epoch: time=915.38, energy=123944.15, cost=142068.10
2022-12-06 12:23:52,489 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0020, Accuracy: 0.4662
2022-12-06 12:23:52,685 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:23:52,686 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:23:52.700 [ZeusMonitor] Monitor started.
2022-12-06 17:23:52.700 [ZeusMonitor] Running indefinitely. 2022-12-06 17:23:52.700 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:23:52.700 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 12:24:36,935 [ZeusDataLoader(train)] train epoch 18 done: time=44.44 energy=6341.68
2022-12-06 12:24:36,939 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.4255
Training Epoch: 17 [2048/50176]	Loss: 1.3598
Training Epoch: 17 [3072/50176]	Loss: 1.3233
Training Epoch: 17 [4096/50176]	Loss: 1.3227
Training Epoch: 17 [5120/50176]	Loss: 1.5097
Training Epoch: 17 [6144/50176]	Loss: 1.4093
Training Epoch: 17 [7168/50176]	Loss: 1.3709
Training Epoch: 17 [8192/50176]	Loss: 1.3838
Training Epoch: 17 [9216/50176]	Loss: 1.4566
Training Epoch: 17 [10240/50176]	Loss: 1.3478
Training Epoch: 17 [11264/50176]	Loss: 1.3549
Training Epoch: 17 [12288/50176]	Loss: 1.4301
Training Epoch: 17 [13312/50176]	Loss: 1.3816
Training Epoch: 17 [14336/50176]	Loss: 1.4598
Training Epoch: 17 [15360/50176]	Loss: 1.4220
Training Epoch: 17 [16384/50176]	Loss: 1.3602
Training Epoch: 17 [17408/50176]	Loss: 1.5045
Training Epoch: 17 [18432/50176]	Loss: 1.4824
Training Epoch: 17 [19456/50176]	Loss: 1.3710
Training Epoch: 17 [20480/50176]	Loss: 1.3743
Training Epoch: 17 [21504/50176]	Loss: 1.4305
Training Epoch: 17 [22528/50176]	Loss: 1.4982
Training Epoch: 17 [23552/50176]	Loss: 1.5032
Training Epoch: 17 [24576/50176]	Loss: 1.4799
Training Epoch: 17 [25600/50176]	Loss: 1.4613
Training Epoch: 17 [26624/50176]	Loss: 1.3846
Training Epoch: 17 [27648/50176]	Loss: 1.3867
Training Epoch: 17 [28672/50176]	Loss: 1.5114
Training Epoch: 17 [29696/50176]	Loss: 1.5027
Training Epoch: 17 [30720/50176]	Loss: 1.5582
Training Epoch: 17 [31744/50176]	Loss: 1.4242
Training Epoch: 17 [32768/50176]	Loss: 1.4519
Training Epoch: 17 [33792/50176]	Loss: 1.5351
Training Epoch: 17 [34816/50176]	Loss: 1.4471
Training Epoch: 17 [35840/50176]	Loss: 1.3507
Training Epoch: 17 [36864/50176]	Loss: 1.4899
Training Epoch: 17 [37888/50176]	Loss: 1.4001
Training Epoch: 17 [38912/50176]	Loss: 1.5100
Training Epoch: 17 [39936/50176]	Loss: 1.5389
Training Epoch: 17 [40960/50176]	Loss: 1.4190
Training Epoch: 17 [41984/50176]	Loss: 1.4908
Training Epoch: 17 [43008/50176]	Loss: 1.4581
Training Epoch: 17 [44032/50176]	Loss: 1.5039
Training Epoch: 17 [45056/50176]	Loss: 1.4491
Training Epoch: 17 [46080/50176]	Loss: 1.3803
Training Epoch: 17 [47104/50176]	Loss: 1.3579
Training Epoch: 17 [48128/50176]	Loss: 1.4598
Training Epoch: 17 [49152/50176]	Loss: 1.4796
Training Epoch: 17 [50176/50176]	Loss: 1.4096
2022-12-06 17:24:40.720 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:24:40,747 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.80 energy=492.47
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Up to epoch 18: time=916.35, energy=123994.35, cost=142177.59
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:24:40,748 [ZeusDataLoader(train)] Expected next epoch: time=963.62, energy=130778.30, cost=149706.05
2022-12-06 12:24:40,749 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0017, Accuracy: 0.5153
2022-12-06 12:24:40,958 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:24:40,958 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:24:40.968 [ZeusMonitor] Monitor started.
2022-12-06 17:24:40.968 [ZeusMonitor] Running indefinitely. 2022-12-06 17:24:40.968 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:24:40.968 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 12:25:25,186 [ZeusDataLoader(train)] train epoch 19 done: time=44.43 energy=6326.57
2022-12-06 12:25:25,190 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.2747
Training Epoch: 18 [2048/50176]	Loss: 1.3536
Training Epoch: 18 [3072/50176]	Loss: 1.3736
Training Epoch: 18 [4096/50176]	Loss: 1.2906
Training Epoch: 18 [5120/50176]	Loss: 1.3456
Training Epoch: 18 [6144/50176]	Loss: 1.3660
Training Epoch: 18 [7168/50176]	Loss: 1.3025
Training Epoch: 18 [8192/50176]	Loss: 1.3470
Training Epoch: 18 [9216/50176]	Loss: 1.3200
Training Epoch: 18 [10240/50176]	Loss: 1.3174
Training Epoch: 18 [11264/50176]	Loss: 1.3480
Training Epoch: 18 [12288/50176]	Loss: 1.3294
Training Epoch: 18 [13312/50176]	Loss: 1.3815
Training Epoch: 18 [14336/50176]	Loss: 1.3424
Training Epoch: 18 [15360/50176]	Loss: 1.4091
Training Epoch: 18 [16384/50176]	Loss: 1.3833
Training Epoch: 18 [17408/50176]	Loss: 1.4272
Training Epoch: 18 [18432/50176]	Loss: 1.4172
Training Epoch: 18 [19456/50176]	Loss: 1.4182
Training Epoch: 18 [20480/50176]	Loss: 1.3548
Training Epoch: 18 [21504/50176]	Loss: 1.4219
Training Epoch: 18 [22528/50176]	Loss: 1.4015
Training Epoch: 18 [23552/50176]	Loss: 1.3032
Training Epoch: 18 [24576/50176]	Loss: 1.3380
Training Epoch: 18 [25600/50176]	Loss: 1.3070
Training Epoch: 18 [26624/50176]	Loss: 1.2694
Training Epoch: 18 [27648/50176]	Loss: 1.4035
Training Epoch: 18 [28672/50176]	Loss: 1.4074
Training Epoch: 18 [29696/50176]	Loss: 1.4040
Training Epoch: 18 [30720/50176]	Loss: 1.4381
Training Epoch: 18 [31744/50176]	Loss: 1.4630
Training Epoch: 18 [32768/50176]	Loss: 1.3922
Training Epoch: 18 [33792/50176]	Loss: 1.4161
Training Epoch: 18 [34816/50176]	Loss: 1.3998
Training Epoch: 18 [35840/50176]	Loss: 1.4767
Training Epoch: 18 [36864/50176]	Loss: 1.3944
Training Epoch: 18 [37888/50176]	Loss: 1.3496
Training Epoch: 18 [38912/50176]	Loss: 1.4032
Training Epoch: 18 [39936/50176]	Loss: 1.4201
Training Epoch: 18 [40960/50176]	Loss: 1.3597
Training Epoch: 18 [41984/50176]	Loss: 1.4166
Training Epoch: 18 [43008/50176]	Loss: 1.3991
Training Epoch: 18 [44032/50176]	Loss: 1.3800
Training Epoch: 18 [45056/50176]	Loss: 1.3854
Training Epoch: 18 [46080/50176]	Loss: 1.4066
Training Epoch: 18 [47104/50176]	Loss: 1.3843
Training Epoch: 18 [48128/50176]	Loss: 1.3188
Training Epoch: 18 [49152/50176]	Loss: 1.4005
Training Epoch: 18 [50176/50176]	Loss: 1.4375
2022-12-06 17:25:28.979 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:25:29,002 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.80 energy=488.07
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Up to epoch 19: time=964.58, energy=130808.99, cost=149805.37
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:25:29,002 [ZeusDataLoader(train)] Expected next epoch: time=1011.86, energy=137592.94, cost=157333.82
2022-12-06 12:25:29,003 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0023, Accuracy: 0.4264
2022-12-06 12:25:29,228 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:25:29,229 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:25:29.231 [ZeusMonitor] Monitor started.
2022-12-06 17:25:29.231 [ZeusMonitor] Running indefinitely. 2022-12-06 17:25:29.231 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:25:29.231 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 12:26:13,397 [ZeusDataLoader(train)] train epoch 20 done: time=44.39 energy=6321.33
2022-12-06 12:26:13,400 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.2642
Training Epoch: 19 [2048/50176]	Loss: 1.2886
Training Epoch: 19 [3072/50176]	Loss: 1.2619
Training Epoch: 19 [4096/50176]	Loss: 1.2741
Training Epoch: 19 [5120/50176]	Loss: 1.3335
Training Epoch: 19 [6144/50176]	Loss: 1.2899
Training Epoch: 19 [7168/50176]	Loss: 1.2820
Training Epoch: 19 [8192/50176]	Loss: 1.2450
Training Epoch: 19 [9216/50176]	Loss: 1.2865
Training Epoch: 19 [10240/50176]	Loss: 1.3383
Training Epoch: 19 [11264/50176]	Loss: 1.2873
Training Epoch: 19 [12288/50176]	Loss: 1.2496
Training Epoch: 19 [13312/50176]	Loss: 1.2875
Training Epoch: 19 [14336/50176]	Loss: 1.3094
Training Epoch: 19 [15360/50176]	Loss: 1.3426
Training Epoch: 19 [16384/50176]	Loss: 1.2655
Training Epoch: 19 [17408/50176]	Loss: 1.3409
Training Epoch: 19 [18432/50176]	Loss: 1.3313
Training Epoch: 19 [19456/50176]	Loss: 1.2406
Training Epoch: 19 [20480/50176]	Loss: 1.3967
Training Epoch: 19 [21504/50176]	Loss: 1.2155
Training Epoch: 19 [22528/50176]	Loss: 1.3672
Training Epoch: 19 [23552/50176]	Loss: 1.3811
Training Epoch: 19 [24576/50176]	Loss: 1.2847
Training Epoch: 19 [25600/50176]	Loss: 1.3338
Training Epoch: 19 [26624/50176]	Loss: 1.3435
Training Epoch: 19 [27648/50176]	Loss: 1.2440
Training Epoch: 19 [28672/50176]	Loss: 1.3106
Training Epoch: 19 [29696/50176]	Loss: 1.4361
Training Epoch: 19 [30720/50176]	Loss: 1.3243
Training Epoch: 19 [31744/50176]	Loss: 1.3257
Training Epoch: 19 [32768/50176]	Loss: 1.3819
Training Epoch: 19 [33792/50176]	Loss: 1.3558
Training Epoch: 19 [34816/50176]	Loss: 1.3178
Training Epoch: 19 [35840/50176]	Loss: 1.3250
Training Epoch: 19 [36864/50176]	Loss: 1.3840
Training Epoch: 19 [37888/50176]	Loss: 1.2577
Training Epoch: 19 [38912/50176]	Loss: 1.3955
Training Epoch: 19 [39936/50176]	Loss: 1.2591
Training Epoch: 19 [40960/50176]	Loss: 1.2498
Training Epoch: 19 [41984/50176]	Loss: 1.3718
Training Epoch: 19 [43008/50176]	Loss: 1.3811
Training Epoch: 19 [44032/50176]	Loss: 1.2747
Training Epoch: 19 [45056/50176]	Loss: 1.3526
Training Epoch: 19 [46080/50176]	Loss: 1.2696
Training Epoch: 19 [47104/50176]	Loss: 1.2982
Training Epoch: 19 [48128/50176]	Loss: 1.2572
Training Epoch: 19 [49152/50176]	Loss: 1.3599
Training Epoch: 19 [50176/50176]	Loss: 1.2819
2022-12-06 17:26:17.166 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:26:17,195 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.79 energy=490.03
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Up to epoch 20: time=1012.75, energy=137620.35, cost=157426.13
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:26:17,195 [ZeusDataLoader(train)] Expected next epoch: time=1060.03, energy=144404.30, cost=164954.59
2022-12-06 12:26:17,196 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0017, Accuracy: 0.5226
2022-12-06 12:26:17,418 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:26:17,419 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:26:17.420 [ZeusMonitor] Monitor started.
2022-12-06 17:26:17.420 [ZeusMonitor] Running indefinitely. 2022-12-06 17:26:17.420 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:26:17.420 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 12:27:02,170 [ZeusDataLoader(train)] train epoch 21 done: time=44.97 energy=6358.55
2022-12-06 12:27:02,173 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.2380
Training Epoch: 20 [2048/50176]	Loss: 1.2095
Training Epoch: 20 [3072/50176]	Loss: 1.2483
Training Epoch: 20 [4096/50176]	Loss: 1.1919
Training Epoch: 20 [5120/50176]	Loss: 1.2689
Training Epoch: 20 [6144/50176]	Loss: 1.2662
Training Epoch: 20 [7168/50176]	Loss: 1.1933
Training Epoch: 20 [8192/50176]	Loss: 1.2016
Training Epoch: 20 [9216/50176]	Loss: 1.2104
Training Epoch: 20 [10240/50176]	Loss: 1.1949
Training Epoch: 20 [11264/50176]	Loss: 1.2867
Training Epoch: 20 [12288/50176]	Loss: 1.2106
Training Epoch: 20 [13312/50176]	Loss: 1.2391
Training Epoch: 20 [14336/50176]	Loss: 1.2787
Training Epoch: 20 [15360/50176]	Loss: 1.2735
Training Epoch: 20 [16384/50176]	Loss: 1.2786
Training Epoch: 20 [17408/50176]	Loss: 1.2330
Training Epoch: 20 [18432/50176]	Loss: 1.2964
Training Epoch: 20 [19456/50176]	Loss: 1.2840
Training Epoch: 20 [20480/50176]	Loss: 1.2222
Training Epoch: 20 [21504/50176]	Loss: 1.3016
Training Epoch: 20 [22528/50176]	Loss: 1.2053
Training Epoch: 20 [23552/50176]	Loss: 1.1291
Training Epoch: 20 [24576/50176]	Loss: 1.2644
Training Epoch: 20 [25600/50176]	Loss: 1.3232
Training Epoch: 20 [26624/50176]	Loss: 1.2614
Training Epoch: 20 [27648/50176]	Loss: 1.1905
Training Epoch: 20 [28672/50176]	Loss: 1.3442
Training Epoch: 20 [29696/50176]	Loss: 1.2554
Training Epoch: 20 [30720/50176]	Loss: 1.2475
Training Epoch: 20 [31744/50176]	Loss: 1.2065
Training Epoch: 20 [32768/50176]	Loss: 1.2284
Training Epoch: 20 [33792/50176]	Loss: 1.2463
Training Epoch: 20 [34816/50176]	Loss: 1.2734
Training Epoch: 20 [35840/50176]	Loss: 1.2194
Training Epoch: 20 [36864/50176]	Loss: 1.2377
Training Epoch: 20 [37888/50176]	Loss: 1.2604
Training Epoch: 20 [38912/50176]	Loss: 1.2702
Training Epoch: 20 [39936/50176]	Loss: 1.2713
Training Epoch: 20 [40960/50176]	Loss: 1.3155
Training Epoch: 20 [41984/50176]	Loss: 1.2812
Training Epoch: 20 [43008/50176]	Loss: 1.2430
Training Epoch: 20 [44032/50176]	Loss: 1.2054
Training Epoch: 20 [45056/50176]	Loss: 1.2708
Training Epoch: 20 [46080/50176]	Loss: 1.2995
Training Epoch: 20 [47104/50176]	Loss: 1.3118
Training Epoch: 20 [48128/50176]	Loss: 1.2757
Training Epoch: 20 [49152/50176]	Loss: 1.3079
Training Epoch: 20 [50176/50176]	Loss: 1.2796
2022-12-06 17:27:05.890 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:27:05,925 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.74 energy=473.98
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Up to epoch 21: time=1061.46, energy=144452.88, cost=165104.45
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:27:05,925 [ZeusDataLoader(train)] Expected next epoch: time=1108.74, energy=151236.83, cost=172632.90
2022-12-06 12:27:05,926 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0019, Accuracy: 0.4920
2022-12-06 12:27:06,160 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:27:06,161 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:27:06.163 [ZeusMonitor] Monitor started.
2022-12-06 17:27:06.163 [ZeusMonitor] Running indefinitely. 2022-12-06 17:27:06.163 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:27:06.163 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 12:27:50,536 [ZeusDataLoader(train)] train epoch 22 done: time=44.60 energy=6336.83
2022-12-06 12:27:50,539 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.2282
Training Epoch: 21 [2048/50176]	Loss: 1.1548
Training Epoch: 21 [3072/50176]	Loss: 1.1690
Training Epoch: 21 [4096/50176]	Loss: 1.2001
Training Epoch: 21 [5120/50176]	Loss: 1.1447
Training Epoch: 21 [6144/50176]	Loss: 1.0901
Training Epoch: 21 [7168/50176]	Loss: 1.0788
Training Epoch: 21 [8192/50176]	Loss: 1.1531
Training Epoch: 21 [9216/50176]	Loss: 1.1823
Training Epoch: 21 [10240/50176]	Loss: 1.1673
Training Epoch: 21 [11264/50176]	Loss: 1.1780
Training Epoch: 21 [12288/50176]	Loss: 1.1707
Training Epoch: 21 [13312/50176]	Loss: 1.1837
Training Epoch: 21 [14336/50176]	Loss: 1.2128
Training Epoch: 21 [15360/50176]	Loss: 1.1441
Training Epoch: 21 [16384/50176]	Loss: 1.2172
Training Epoch: 21 [17408/50176]	Loss: 1.1697
Training Epoch: 21 [18432/50176]	Loss: 1.1047
Training Epoch: 21 [19456/50176]	Loss: 1.1566
Training Epoch: 21 [20480/50176]	Loss: 1.1311
Training Epoch: 21 [21504/50176]	Loss: 1.2216
Training Epoch: 21 [22528/50176]	Loss: 1.2375
Training Epoch: 21 [23552/50176]	Loss: 1.2706
Training Epoch: 21 [24576/50176]	Loss: 1.1523
Training Epoch: 21 [25600/50176]	Loss: 1.2764
Training Epoch: 21 [26624/50176]	Loss: 1.3117
Training Epoch: 21 [27648/50176]	Loss: 1.2223
Training Epoch: 21 [28672/50176]	Loss: 1.1983
Training Epoch: 21 [29696/50176]	Loss: 1.2556
Training Epoch: 21 [30720/50176]	Loss: 1.2369
Training Epoch: 21 [31744/50176]	Loss: 1.2925
Training Epoch: 21 [32768/50176]	Loss: 1.2497
Training Epoch: 21 [33792/50176]	Loss: 1.2417
Training Epoch: 21 [34816/50176]	Loss: 1.1636
Training Epoch: 21 [35840/50176]	Loss: 1.2604
Training Epoch: 21 [36864/50176]	Loss: 1.1678
Training Epoch: 21 [37888/50176]	Loss: 1.2944
Training Epoch: 21 [38912/50176]	Loss: 1.2104
Training Epoch: 21 [39936/50176]	Loss: 1.3090
Training Epoch: 21 [40960/50176]	Loss: 1.1852
Training Epoch: 21 [41984/50176]	Loss: 1.2529
Training Epoch: 21 [43008/50176]	Loss: 1.2444
Training Epoch: 21 [44032/50176]	Loss: 1.3172
Training Epoch: 21 [45056/50176]	Loss: 1.2022
Training Epoch: 21 [46080/50176]	Loss: 1.2559
Training Epoch: 21 [47104/50176]	Loss: 1.2631
Training Epoch: 21 [48128/50176]	Loss: 1.2217
Training Epoch: 21 [49152/50176]	Loss: 1.2466
Training Epoch: 21 [50176/50176]	Loss: 1.2902
2022-12-06 17:27:54.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:27:54,350 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.80 energy=484.13
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Up to epoch 22: time=1109.87, energy=151273.84, cost=172750.33
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:27:54,350 [ZeusDataLoader(train)] Expected next epoch: time=1157.14, energy=158057.79, cost=180278.78
2022-12-06 12:27:54,351 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0021, Accuracy: 0.4569
2022-12-06 12:27:54,584 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:27:54,585 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:27:54.587 [ZeusMonitor] Monitor started.
2022-12-06 17:27:54.587 [ZeusMonitor] Running indefinitely. 2022-12-06 17:27:54.587 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:27:54.587 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 12:28:38,899 [ZeusDataLoader(train)] train epoch 23 done: time=44.54 energy=6351.07
2022-12-06 12:28:38,902 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.1509
Training Epoch: 22 [2048/50176]	Loss: 1.1550
Training Epoch: 22 [3072/50176]	Loss: 1.1260
Training Epoch: 22 [4096/50176]	Loss: 1.0285
Training Epoch: 22 [5120/50176]	Loss: 1.1573
Training Epoch: 22 [6144/50176]	Loss: 1.1061
Training Epoch: 22 [7168/50176]	Loss: 1.1733
Training Epoch: 22 [8192/50176]	Loss: 1.1899
Training Epoch: 22 [9216/50176]	Loss: 1.0822
Training Epoch: 22 [10240/50176]	Loss: 1.0929
Training Epoch: 22 [11264/50176]	Loss: 1.1723
Training Epoch: 22 [12288/50176]	Loss: 1.1772
Training Epoch: 22 [13312/50176]	Loss: 1.0585
Training Epoch: 22 [14336/50176]	Loss: 1.2155
Training Epoch: 22 [15360/50176]	Loss: 1.0892
Training Epoch: 22 [16384/50176]	Loss: 1.1896
Training Epoch: 22 [17408/50176]	Loss: 1.1353
Training Epoch: 22 [18432/50176]	Loss: 1.1679
Training Epoch: 22 [19456/50176]	Loss: 1.1693
Training Epoch: 22 [20480/50176]	Loss: 1.1764
Training Epoch: 22 [21504/50176]	Loss: 1.1839
Training Epoch: 22 [22528/50176]	Loss: 1.2493
Training Epoch: 22 [23552/50176]	Loss: 1.1668
Training Epoch: 22 [24576/50176]	Loss: 1.1942
Training Epoch: 22 [25600/50176]	Loss: 1.1651
Training Epoch: 22 [26624/50176]	Loss: 1.1801
Training Epoch: 22 [27648/50176]	Loss: 1.1942
Training Epoch: 22 [28672/50176]	Loss: 1.2178
Training Epoch: 22 [29696/50176]	Loss: 1.2200
Training Epoch: 22 [30720/50176]	Loss: 1.1385
Training Epoch: 22 [31744/50176]	Loss: 1.2880
Training Epoch: 22 [32768/50176]	Loss: 1.1742
Training Epoch: 22 [33792/50176]	Loss: 1.1997
Training Epoch: 22 [34816/50176]	Loss: 1.2221
Training Epoch: 22 [35840/50176]	Loss: 1.1809
Training Epoch: 22 [36864/50176]	Loss: 1.1555
Training Epoch: 22 [37888/50176]	Loss: 1.1931
Training Epoch: 22 [38912/50176]	Loss: 1.1373
Training Epoch: 22 [39936/50176]	Loss: 1.1559
Training Epoch: 22 [40960/50176]	Loss: 1.2013
Training Epoch: 22 [41984/50176]	Loss: 1.2547
Training Epoch: 22 [43008/50176]	Loss: 1.1124
Training Epoch: 22 [44032/50176]	Loss: 1.1510
Training Epoch: 22 [45056/50176]	Loss: 1.1723
Training Epoch: 22 [46080/50176]	Loss: 1.1365
Training Epoch: 22 [47104/50176]	Loss: 1.1427
Training Epoch: 22 [48128/50176]	Loss: 1.3186
Training Epoch: 22 [49152/50176]	Loss: 1.2815
Training Epoch: 22 [50176/50176]	Loss: 1.1308
2022-12-06 17:28:42.744 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:28:42,794 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.88 energy=491.77
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Up to epoch 23: time=1158.29, energy=158116.68, cost=180408.82
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:28:42,794 [ZeusDataLoader(train)] Expected next epoch: time=1205.57, energy=164900.63, cost=187937.28
2022-12-06 12:28:42,795 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0019, Accuracy: 0.4860
2022-12-06 12:28:43,006 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:28:43,007 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:28:43.009 [ZeusMonitor] Monitor started.
2022-12-06 17:28:43.009 [ZeusMonitor] Running indefinitely. 2022-12-06 17:28:43.009 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:28:43.009 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 12:29:26,981 [ZeusDataLoader(train)] train epoch 24 done: time=44.18 energy=6304.69
2022-12-06 12:29:26,984 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.1240
Training Epoch: 23 [2048/50176]	Loss: 1.0512
Training Epoch: 23 [3072/50176]	Loss: 1.0347
Training Epoch: 23 [4096/50176]	Loss: 1.0858
Training Epoch: 23 [5120/50176]	Loss: 1.0548
Training Epoch: 23 [6144/50176]	Loss: 1.0871
Training Epoch: 23 [7168/50176]	Loss: 1.0885
Training Epoch: 23 [8192/50176]	Loss: 1.1403
Training Epoch: 23 [9216/50176]	Loss: 1.0628
Training Epoch: 23 [10240/50176]	Loss: 1.0388
Training Epoch: 23 [11264/50176]	Loss: 1.0433
Training Epoch: 23 [12288/50176]	Loss: 0.9969
Training Epoch: 23 [13312/50176]	Loss: 1.1546
Training Epoch: 23 [14336/50176]	Loss: 1.0779
Training Epoch: 23 [15360/50176]	Loss: 1.0534
Training Epoch: 23 [16384/50176]	Loss: 1.1209
Training Epoch: 23 [17408/50176]	Loss: 1.1103
Training Epoch: 23 [18432/50176]	Loss: 1.0817
Training Epoch: 23 [19456/50176]	Loss: 1.0736
Training Epoch: 23 [20480/50176]	Loss: 1.0887
Training Epoch: 23 [21504/50176]	Loss: 1.1602
Training Epoch: 23 [22528/50176]	Loss: 1.0769
Training Epoch: 23 [23552/50176]	Loss: 1.0469
Training Epoch: 23 [24576/50176]	Loss: 1.0792
Training Epoch: 23 [25600/50176]	Loss: 1.1250
Training Epoch: 23 [26624/50176]	Loss: 1.0351
Training Epoch: 23 [27648/50176]	Loss: 1.1094
Training Epoch: 23 [28672/50176]	Loss: 1.1030
Training Epoch: 23 [29696/50176]	Loss: 1.0535
Training Epoch: 23 [30720/50176]	Loss: 1.1250
Training Epoch: 23 [31744/50176]	Loss: 1.1780
Training Epoch: 23 [32768/50176]	Loss: 1.1491
Training Epoch: 23 [33792/50176]	Loss: 1.1020
Training Epoch: 23 [34816/50176]	Loss: 1.1667
Training Epoch: 23 [35840/50176]	Loss: 1.0965
Training Epoch: 23 [36864/50176]	Loss: 1.0840
Training Epoch: 23 [37888/50176]	Loss: 1.0936
Training Epoch: 23 [38912/50176]	Loss: 1.1741
Training Epoch: 23 [39936/50176]	Loss: 1.1650
Training Epoch: 23 [40960/50176]	Loss: 1.1873
Training Epoch: 23 [41984/50176]	Loss: 1.1356
Training Epoch: 23 [43008/50176]	Loss: 1.1417
Training Epoch: 23 [44032/50176]	Loss: 1.1929
Training Epoch: 23 [45056/50176]	Loss: 1.1611
Training Epoch: 23 [46080/50176]	Loss: 1.2130
Training Epoch: 23 [47104/50176]	Loss: 1.1752
Training Epoch: 23 [48128/50176]	Loss: 1.1113
Training Epoch: 23 [49152/50176]	Loss: 1.1194
Training Epoch: 23 [50176/50176]	Loss: 1.0872
2022-12-06 17:29:30.819 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:29:30,847 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.85 energy=483.17
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Up to epoch 24: time=1206.32, energy=164904.53, cost=188005.59
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:29:30,847 [ZeusDataLoader(train)] Expected next epoch: time=1253.60, energy=171688.49, cost=195534.04
2022-12-06 12:29:30,848 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0017, Accuracy: 0.5359
2022-12-06 12:29:31,075 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:29:31,076 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:29:31.077 [ZeusMonitor] Monitor started.
2022-12-06 17:29:31.078 [ZeusMonitor] Running indefinitely. 2022-12-06 17:29:31.078 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:29:31.078 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 12:30:15,392 [ZeusDataLoader(train)] train epoch 25 done: time=44.54 energy=6331.88
2022-12-06 12:30:15,395 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 1.0087
Training Epoch: 24 [2048/50176]	Loss: 0.9555
Training Epoch: 24 [3072/50176]	Loss: 1.0395
Training Epoch: 24 [4096/50176]	Loss: 1.0164
Training Epoch: 24 [5120/50176]	Loss: 0.9546
Training Epoch: 24 [6144/50176]	Loss: 0.9625
Training Epoch: 24 [7168/50176]	Loss: 1.0812
Training Epoch: 24 [8192/50176]	Loss: 1.0041
Training Epoch: 24 [9216/50176]	Loss: 1.0469
Training Epoch: 24 [10240/50176]	Loss: 1.0432
Training Epoch: 24 [11264/50176]	Loss: 0.9823
Training Epoch: 24 [12288/50176]	Loss: 1.0084
Training Epoch: 24 [13312/50176]	Loss: 1.0073
Training Epoch: 24 [14336/50176]	Loss: 1.0808
Training Epoch: 24 [15360/50176]	Loss: 0.9680
Training Epoch: 24 [16384/50176]	Loss: 0.9683
Training Epoch: 24 [17408/50176]	Loss: 1.0522
Training Epoch: 24 [18432/50176]	Loss: 1.0447
Training Epoch: 24 [19456/50176]	Loss: 1.1047
Training Epoch: 24 [20480/50176]	Loss: 1.0482
Training Epoch: 24 [21504/50176]	Loss: 1.0331
Training Epoch: 24 [22528/50176]	Loss: 1.0104
Training Epoch: 24 [23552/50176]	Loss: 1.1116
Training Epoch: 24 [24576/50176]	Loss: 1.0284
Training Epoch: 24 [25600/50176]	Loss: 1.0838
Training Epoch: 24 [26624/50176]	Loss: 1.0253
Training Epoch: 24 [27648/50176]	Loss: 1.1426
Training Epoch: 24 [28672/50176]	Loss: 1.0271
Training Epoch: 24 [29696/50176]	Loss: 1.0920
Training Epoch: 24 [30720/50176]	Loss: 1.1788
Training Epoch: 24 [31744/50176]	Loss: 1.1066
Training Epoch: 24 [32768/50176]	Loss: 1.0971
Training Epoch: 24 [33792/50176]	Loss: 1.0833
Training Epoch: 24 [34816/50176]	Loss: 1.1238
Training Epoch: 24 [35840/50176]	Loss: 1.1840
Training Epoch: 24 [36864/50176]	Loss: 1.1006
Training Epoch: 24 [37888/50176]	Loss: 1.1145
Training Epoch: 24 [38912/50176]	Loss: 1.1435
Training Epoch: 24 [39936/50176]	Loss: 0.9964
Training Epoch: 24 [40960/50176]	Loss: 1.0715
Training Epoch: 24 [41984/50176]	Loss: 1.1572
Training Epoch: 24 [43008/50176]	Loss: 1.1807
Training Epoch: 24 [44032/50176]	Loss: 1.0205
Training Epoch: 24 [45056/50176]	Loss: 1.1019
Training Epoch: 24 [46080/50176]	Loss: 1.0715
Training Epoch: 24 [47104/50176]	Loss: 1.2086
Training Epoch: 24 [48128/50176]	Loss: 1.2298
Training Epoch: 24 [49152/50176]	Loss: 1.0917
Training Epoch: 24 [50176/50176]	Loss: 1.0770
2022-12-06 17:30:19.081 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:30:19,100 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.70 energy=475.89
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Up to epoch 25: time=1254.56, energy=171712.31, cost=195629.86
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:30:19,101 [ZeusDataLoader(train)] Expected next epoch: time=1301.83, energy=178496.26, cost=203158.31
2022-12-06 12:30:19,102 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0018, Accuracy: 0.5284
2022-12-06 12:30:19,328 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:30:19,329 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:30:19.331 [ZeusMonitor] Monitor started.
2022-12-06 17:30:19.331 [ZeusMonitor] Running indefinitely. 2022-12-06 17:30:19.331 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:30:19.331 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 12:31:03,874 [ZeusDataLoader(train)] train epoch 26 done: time=44.76 energy=6355.46
2022-12-06 12:31:03,877 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.9314
Training Epoch: 25 [2048/50176]	Loss: 0.9417
Training Epoch: 25 [3072/50176]	Loss: 0.9894
Training Epoch: 25 [4096/50176]	Loss: 0.9847
Training Epoch: 25 [5120/50176]	Loss: 0.9606
Training Epoch: 25 [6144/50176]	Loss: 0.9758
Training Epoch: 25 [7168/50176]	Loss: 0.9786
Training Epoch: 25 [8192/50176]	Loss: 1.0143
Training Epoch: 25 [9216/50176]	Loss: 1.0568
Training Epoch: 25 [10240/50176]	Loss: 0.9838
Training Epoch: 25 [11264/50176]	Loss: 0.9688
Training Epoch: 25 [12288/50176]	Loss: 0.9270
Training Epoch: 25 [13312/50176]	Loss: 0.9332
Training Epoch: 25 [14336/50176]	Loss: 1.0044
Training Epoch: 25 [15360/50176]	Loss: 0.9923
Training Epoch: 25 [16384/50176]	Loss: 1.0611
Training Epoch: 25 [17408/50176]	Loss: 1.0049
Training Epoch: 25 [18432/50176]	Loss: 1.0237
Training Epoch: 25 [19456/50176]	Loss: 0.9874
Training Epoch: 25 [20480/50176]	Loss: 0.9564
Training Epoch: 25 [21504/50176]	Loss: 0.9979
Training Epoch: 25 [22528/50176]	Loss: 1.0759
Training Epoch: 25 [23552/50176]	Loss: 0.9483
Training Epoch: 25 [24576/50176]	Loss: 0.9849
Training Epoch: 25 [25600/50176]	Loss: 1.0076
Training Epoch: 25 [26624/50176]	Loss: 1.1405
Training Epoch: 25 [27648/50176]	Loss: 1.0791
Training Epoch: 25 [28672/50176]	Loss: 1.0914
Training Epoch: 25 [29696/50176]	Loss: 1.0671
Training Epoch: 25 [30720/50176]	Loss: 1.0416
Training Epoch: 25 [31744/50176]	Loss: 1.0079
Training Epoch: 25 [32768/50176]	Loss: 1.0595
Training Epoch: 25 [33792/50176]	Loss: 0.9845
Training Epoch: 25 [34816/50176]	Loss: 1.0668
Training Epoch: 25 [35840/50176]	Loss: 1.0417
Training Epoch: 25 [36864/50176]	Loss: 1.0300
Training Epoch: 25 [37888/50176]	Loss: 1.0384
Training Epoch: 25 [38912/50176]	Loss: 1.0397
Training Epoch: 25 [39936/50176]	Loss: 1.0602
Training Epoch: 25 [40960/50176]	Loss: 0.9910
Training Epoch: 25 [41984/50176]	Loss: 1.0477
Training Epoch: 25 [43008/50176]	Loss: 1.0956
Training Epoch: 25 [44032/50176]	Loss: 1.0558
Training Epoch: 25 [45056/50176]	Loss: 1.0821
Training Epoch: 25 [46080/50176]	Loss: 1.0295
Training Epoch: 25 [47104/50176]	Loss: 1.0941
Training Epoch: 25 [48128/50176]	Loss: 1.0764
Training Epoch: 25 [49152/50176]	Loss: 1.0824
Training Epoch: 25 [50176/50176]	Loss: 1.0919
2022-12-06 17:31:07.615 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:31:07,654 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.77 energy=476.21
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Up to epoch 26: time=1303.09, energy=178543.97, cost=203292.27
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:31:07,654 [ZeusDataLoader(train)] Expected next epoch: time=1350.36, energy=185327.92, cost=210820.73
2022-12-06 12:31:07,655 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0016, Accuracy: 0.5569
2022-12-06 12:31:07,895 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:31:07,895 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:31:07.897 [ZeusMonitor] Monitor started.
2022-12-06 17:31:07.897 [ZeusMonitor] Running indefinitely. 2022-12-06 17:31:07.897 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:31:07.897 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 12:31:52,069 [ZeusDataLoader(train)] train epoch 27 done: time=44.41 energy=6320.28
2022-12-06 12:31:52,072 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.9313
Training Epoch: 26 [2048/50176]	Loss: 0.9670
Training Epoch: 26 [3072/50176]	Loss: 0.9897
Training Epoch: 26 [4096/50176]	Loss: 0.9642
Training Epoch: 26 [5120/50176]	Loss: 0.9408
Training Epoch: 26 [6144/50176]	Loss: 0.9501
Training Epoch: 26 [7168/50176]	Loss: 0.9334
Training Epoch: 26 [8192/50176]	Loss: 0.9756
Training Epoch: 26 [9216/50176]	Loss: 0.8775
Training Epoch: 26 [10240/50176]	Loss: 0.9824
Training Epoch: 26 [11264/50176]	Loss: 0.9095
Training Epoch: 26 [12288/50176]	Loss: 0.9144
Training Epoch: 26 [13312/50176]	Loss: 0.9212
Training Epoch: 26 [14336/50176]	Loss: 0.9449
Training Epoch: 26 [15360/50176]	Loss: 0.8996
Training Epoch: 26 [16384/50176]	Loss: 0.8651
Training Epoch: 26 [17408/50176]	Loss: 0.9533
Training Epoch: 26 [18432/50176]	Loss: 0.9603
Training Epoch: 26 [19456/50176]	Loss: 0.9712
Training Epoch: 26 [20480/50176]	Loss: 0.9000
Training Epoch: 26 [21504/50176]	Loss: 0.9669
Training Epoch: 26 [22528/50176]	Loss: 0.8577
Training Epoch: 26 [23552/50176]	Loss: 0.9796
Training Epoch: 26 [24576/50176]	Loss: 0.9683
Training Epoch: 26 [25600/50176]	Loss: 0.9687
Training Epoch: 26 [26624/50176]	Loss: 0.9919
Training Epoch: 26 [27648/50176]	Loss: 0.9967
Training Epoch: 26 [28672/50176]	Loss: 0.9251
Training Epoch: 26 [29696/50176]	Loss: 1.0381
Training Epoch: 26 [30720/50176]	Loss: 1.0913
Training Epoch: 26 [31744/50176]	Loss: 0.9711
Training Epoch: 26 [32768/50176]	Loss: 1.0177
Training Epoch: 26 [33792/50176]	Loss: 1.0444
Training Epoch: 26 [34816/50176]	Loss: 1.0872
Training Epoch: 26 [35840/50176]	Loss: 1.0227
Training Epoch: 26 [36864/50176]	Loss: 1.0028
Training Epoch: 26 [37888/50176]	Loss: 1.0103
Training Epoch: 26 [38912/50176]	Loss: 1.0136
Training Epoch: 26 [39936/50176]	Loss: 1.1057
Training Epoch: 26 [40960/50176]	Loss: 0.9863
Training Epoch: 26 [41984/50176]	Loss: 1.0567
Training Epoch: 26 [43008/50176]	Loss: 1.0274
Training Epoch: 26 [44032/50176]	Loss: 1.0368
Training Epoch: 26 [45056/50176]	Loss: 1.0203
Training Epoch: 26 [46080/50176]	Loss: 1.0705
Training Epoch: 26 [47104/50176]	Loss: 1.0769
Training Epoch: 26 [48128/50176]	Loss: 1.0357
Training Epoch: 26 [49152/50176]	Loss: 0.9908
Training Epoch: 26 [50176/50176]	Loss: 1.0203
2022-12-06 17:31:55.836 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:31:55,857 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.78 energy=479.44
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Up to epoch 27: time=1351.27, energy=185343.69, cost=210908.19
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:31:55,858 [ZeusDataLoader(train)] Expected next epoch: time=1398.55, energy=192127.64, cost=218436.65
2022-12-06 12:31:55,859 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0017, Accuracy: 0.5475
2022-12-06 12:31:56,031 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:31:56,031 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:31:56.035 [ZeusMonitor] Monitor started.
2022-12-06 17:31:56.035 [ZeusMonitor] Running indefinitely. 2022-12-06 17:31:56.035 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:31:56.035 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 12:32:41,269 [ZeusDataLoader(train)] train epoch 28 done: time=45.40 energy=6392.82
2022-12-06 12:32:41,272 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.9036
Training Epoch: 27 [2048/50176]	Loss: 0.9075
Training Epoch: 27 [3072/50176]	Loss: 0.8437
Training Epoch: 27 [4096/50176]	Loss: 0.9719
Training Epoch: 27 [5120/50176]	Loss: 0.8983
Training Epoch: 27 [6144/50176]	Loss: 0.8806
Training Epoch: 27 [7168/50176]	Loss: 0.8570
Training Epoch: 27 [8192/50176]	Loss: 0.8709
Training Epoch: 27 [9216/50176]	Loss: 0.8953
Training Epoch: 27 [10240/50176]	Loss: 0.9188
Training Epoch: 27 [11264/50176]	Loss: 0.8897
Training Epoch: 27 [12288/50176]	Loss: 0.8792
Training Epoch: 27 [13312/50176]	Loss: 0.9021
Training Epoch: 27 [14336/50176]	Loss: 0.8972
Training Epoch: 27 [15360/50176]	Loss: 0.8717
Training Epoch: 27 [16384/50176]	Loss: 0.9097
Training Epoch: 27 [17408/50176]	Loss: 0.8991
Training Epoch: 27 [18432/50176]	Loss: 0.9472
Training Epoch: 27 [19456/50176]	Loss: 0.9319
Training Epoch: 27 [20480/50176]	Loss: 0.8543
Training Epoch: 27 [21504/50176]	Loss: 0.9340
Training Epoch: 27 [22528/50176]	Loss: 0.8853
Training Epoch: 27 [23552/50176]	Loss: 0.8815
Training Epoch: 27 [24576/50176]	Loss: 0.9446
Training Epoch: 27 [25600/50176]	Loss: 0.9115
Training Epoch: 27 [26624/50176]	Loss: 0.9587
Training Epoch: 27 [27648/50176]	Loss: 0.9547
Training Epoch: 27 [28672/50176]	Loss: 0.9358
Training Epoch: 27 [29696/50176]	Loss: 0.9324
Training Epoch: 27 [30720/50176]	Loss: 0.9381
Training Epoch: 27 [31744/50176]	Loss: 1.0364
Training Epoch: 27 [32768/50176]	Loss: 0.9196
Training Epoch: 27 [33792/50176]	Loss: 0.9023
Training Epoch: 27 [34816/50176]	Loss: 1.0417
Training Epoch: 27 [35840/50176]	Loss: 0.9972
Training Epoch: 27 [36864/50176]	Loss: 0.9817
Training Epoch: 27 [37888/50176]	Loss: 0.9319
Training Epoch: 27 [38912/50176]	Loss: 0.9973
Training Epoch: 27 [39936/50176]	Loss: 0.9844
Training Epoch: 27 [40960/50176]	Loss: 1.0000
Training Epoch: 27 [41984/50176]	Loss: 0.9443
Training Epoch: 27 [43008/50176]	Loss: 0.9401
Training Epoch: 27 [44032/50176]	Loss: 0.9613
Training Epoch: 27 [45056/50176]	Loss: 0.9271
Training Epoch: 27 [46080/50176]	Loss: 1.0277
Training Epoch: 27 [47104/50176]	Loss: 1.0458
Training Epoch: 27 [48128/50176]	Loss: 0.9602
Training Epoch: 27 [49152/50176]	Loss: 1.0111
Training Epoch: 27 [50176/50176]	Loss: 1.0609
2022-12-06 17:32:45.003 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:32:45,018 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=476.14
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Up to epoch 28: time=1400.41, energy=192212.64, cost=218642.44
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:32:45,019 [ZeusDataLoader(train)] Expected next epoch: time=1447.69, energy=198996.59, cost=226170.89
2022-12-06 12:32:45,020 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0019, Accuracy: 0.5021
2022-12-06 12:32:45,244 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:32:45,244 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:32:45.246 [ZeusMonitor] Monitor started.
2022-12-06 17:32:45.246 [ZeusMonitor] Running indefinitely. 2022-12-06 17:32:45.246 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:32:45.246 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 12:33:29,939 [ZeusDataLoader(train)] train epoch 29 done: time=44.91 energy=6363.10
2022-12-06 12:33:29,942 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.8400
Training Epoch: 28 [2048/50176]	Loss: 0.9262
Training Epoch: 28 [3072/50176]	Loss: 0.8649
Training Epoch: 28 [4096/50176]	Loss: 0.9454
Training Epoch: 28 [5120/50176]	Loss: 0.8116
Training Epoch: 28 [6144/50176]	Loss: 0.8252
Training Epoch: 28 [7168/50176]	Loss: 0.8224
Training Epoch: 28 [8192/50176]	Loss: 0.8534
Training Epoch: 28 [9216/50176]	Loss: 0.8871
Training Epoch: 28 [10240/50176]	Loss: 0.8494
Training Epoch: 28 [11264/50176]	Loss: 0.8203
Training Epoch: 28 [12288/50176]	Loss: 0.8516
Training Epoch: 28 [13312/50176]	Loss: 0.8126
Training Epoch: 28 [14336/50176]	Loss: 0.9281
Training Epoch: 28 [15360/50176]	Loss: 0.8636
Training Epoch: 28 [16384/50176]	Loss: 0.8707
Training Epoch: 28 [17408/50176]	Loss: 0.8730
Training Epoch: 28 [18432/50176]	Loss: 0.8651
Training Epoch: 28 [19456/50176]	Loss: 0.8871
Training Epoch: 28 [20480/50176]	Loss: 0.8279
Training Epoch: 28 [21504/50176]	Loss: 0.9056
Training Epoch: 28 [22528/50176]	Loss: 0.8845
Training Epoch: 28 [23552/50176]	Loss: 0.8953
Training Epoch: 28 [24576/50176]	Loss: 0.8024
Training Epoch: 28 [25600/50176]	Loss: 0.8646
Training Epoch: 28 [26624/50176]	Loss: 0.8248
Training Epoch: 28 [27648/50176]	Loss: 0.9868
Training Epoch: 28 [28672/50176]	Loss: 0.9033
Training Epoch: 28 [29696/50176]	Loss: 0.8636
Training Epoch: 28 [30720/50176]	Loss: 0.9344
Training Epoch: 28 [31744/50176]	Loss: 0.9601
Training Epoch: 28 [32768/50176]	Loss: 0.8559
Training Epoch: 28 [33792/50176]	Loss: 0.9337
Training Epoch: 28 [34816/50176]	Loss: 0.9373
Training Epoch: 28 [35840/50176]	Loss: 0.9071
Training Epoch: 28 [36864/50176]	Loss: 0.9751
Training Epoch: 28 [37888/50176]	Loss: 0.9273
Training Epoch: 28 [38912/50176]	Loss: 0.9381
Training Epoch: 28 [39936/50176]	Loss: 0.9333
Training Epoch: 28 [40960/50176]	Loss: 0.9910
Training Epoch: 28 [41984/50176]	Loss: 0.9220
Training Epoch: 28 [43008/50176]	Loss: 0.9154
Training Epoch: 28 [44032/50176]	Loss: 0.9361
Training Epoch: 28 [45056/50176]	Loss: 1.0764
Training Epoch: 28 [46080/50176]	Loss: 0.9393
Training Epoch: 28 [47104/50176]	Loss: 0.9556
Training Epoch: 28 [48128/50176]	Loss: 0.8806
Training Epoch: 28 [49152/50176]	Loss: 0.9613
Training Epoch: 28 [50176/50176]	Loss: 0.9272
2022-12-06 17:33:33.698 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:33:33,744 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.79 energy=487.61
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Up to epoch 29: time=1449.12, energy=199063.36, cost=226329.46
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:33:33,744 [ZeusDataLoader(train)] Expected next epoch: time=1496.39, energy=205847.31, cost=233857.91
2022-12-06 12:33:33,745 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0018, Accuracy: 0.5484
2022-12-06 12:33:33,976 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:33:33,977 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:33:33.979 [ZeusMonitor] Monitor started.
2022-12-06 17:33:33.979 [ZeusMonitor] Running indefinitely. 2022-12-06 17:33:33.979 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:33:33.979 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 12:34:18,330 [ZeusDataLoader(train)] train epoch 30 done: time=44.58 energy=6338.58
2022-12-06 12:34:18,333 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.8029
Training Epoch: 29 [2048/50176]	Loss: 0.8130
Training Epoch: 29 [3072/50176]	Loss: 0.8479
Training Epoch: 29 [4096/50176]	Loss: 0.8429
Training Epoch: 29 [5120/50176]	Loss: 0.9010
Training Epoch: 29 [6144/50176]	Loss: 0.8171
Training Epoch: 29 [7168/50176]	Loss: 0.7798
Training Epoch: 29 [8192/50176]	Loss: 0.7260
Training Epoch: 29 [9216/50176]	Loss: 0.8530
Training Epoch: 29 [10240/50176]	Loss: 0.8036
Training Epoch: 29 [11264/50176]	Loss: 0.8476
Training Epoch: 29 [12288/50176]	Loss: 0.8758
Training Epoch: 29 [13312/50176]	Loss: 0.7172
Training Epoch: 29 [14336/50176]	Loss: 0.8203
Training Epoch: 29 [15360/50176]	Loss: 0.9102
Training Epoch: 29 [16384/50176]	Loss: 0.8552
Training Epoch: 29 [17408/50176]	Loss: 0.7824
Training Epoch: 29 [18432/50176]	Loss: 0.8544
Training Epoch: 29 [19456/50176]	Loss: 0.8842
Training Epoch: 29 [20480/50176]	Loss: 0.8244
Training Epoch: 29 [21504/50176]	Loss: 0.8731
Training Epoch: 29 [22528/50176]	Loss: 0.7682
Training Epoch: 29 [23552/50176]	Loss: 0.8576
Training Epoch: 29 [24576/50176]	Loss: 0.8574
Training Epoch: 29 [25600/50176]	Loss: 0.8574
Training Epoch: 29 [26624/50176]	Loss: 0.8276
Training Epoch: 29 [27648/50176]	Loss: 0.8646
Training Epoch: 29 [28672/50176]	Loss: 0.8006
Training Epoch: 29 [29696/50176]	Loss: 0.7751
Training Epoch: 29 [30720/50176]	Loss: 0.8988
Training Epoch: 29 [31744/50176]	Loss: 0.8396
Training Epoch: 29 [32768/50176]	Loss: 0.8841
Training Epoch: 29 [33792/50176]	Loss: 0.8597
Training Epoch: 29 [34816/50176]	Loss: 0.8926
Training Epoch: 29 [35840/50176]	Loss: 0.7789
Training Epoch: 29 [36864/50176]	Loss: 0.9084
Training Epoch: 29 [37888/50176]	Loss: 0.8276
Training Epoch: 29 [38912/50176]	Loss: 0.8799
Training Epoch: 29 [39936/50176]	Loss: 0.8962
Training Epoch: 29 [40960/50176]	Loss: 0.9596
Training Epoch: 29 [41984/50176]	Loss: 0.8445
Training Epoch: 29 [43008/50176]	Loss: 0.8952
Training Epoch: 29 [44032/50176]	Loss: 0.9066
Training Epoch: 29 [45056/50176]	Loss: 0.8510
Training Epoch: 29 [46080/50176]	Loss: 0.9082
Training Epoch: 29 [47104/50176]	Loss: 0.9234
Training Epoch: 29 [48128/50176]	Loss: 0.9856
Training Epoch: 29 [49152/50176]	Loss: 0.9069
Training Epoch: 29 [50176/50176]	Loss: 0.9956
2022-12-06 17:34:22.040 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:34:22,066 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.73 energy=475.70
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Up to epoch 30: time=1497.42, energy=205877.63, cost=233963.00
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:34:22,067 [ZeusDataLoader(train)] Expected next epoch: time=1544.69, energy=212661.58, cost=241491.45
2022-12-06 12:34:22,068 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0021, Accuracy: 0.5033
2022-12-06 12:34:22,236 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:34:22,236 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:34:22.240 [ZeusMonitor] Monitor started.
2022-12-06 17:34:22.240 [ZeusMonitor] Running indefinitely. 2022-12-06 17:34:22.240 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:34:22.240 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 12:35:06,648 [ZeusDataLoader(train)] train epoch 31 done: time=44.57 energy=6334.34
2022-12-06 12:35:06,651 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.8875
Training Epoch: 30 [2048/50176]	Loss: 0.7763
Training Epoch: 30 [3072/50176]	Loss: 0.8399
Training Epoch: 30 [4096/50176]	Loss: 0.8471
Training Epoch: 30 [5120/50176]	Loss: 0.7519
Training Epoch: 30 [6144/50176]	Loss: 0.7745
Training Epoch: 30 [7168/50176]	Loss: 0.7994
Training Epoch: 30 [8192/50176]	Loss: 0.7673
Training Epoch: 30 [9216/50176]	Loss: 0.7978
Training Epoch: 30 [10240/50176]	Loss: 0.7849
Training Epoch: 30 [11264/50176]	Loss: 0.7933
Training Epoch: 30 [12288/50176]	Loss: 0.7748
Training Epoch: 30 [13312/50176]	Loss: 0.7582
Training Epoch: 30 [14336/50176]	Loss: 0.7802
Training Epoch: 30 [15360/50176]	Loss: 0.7871
Training Epoch: 30 [16384/50176]	Loss: 0.8104
Training Epoch: 30 [17408/50176]	Loss: 0.8170
Training Epoch: 30 [18432/50176]	Loss: 0.7876
Training Epoch: 30 [19456/50176]	Loss: 0.7597
Training Epoch: 30 [20480/50176]	Loss: 0.7709
Training Epoch: 30 [21504/50176]	Loss: 0.7756
Training Epoch: 30 [22528/50176]	Loss: 0.8127
Training Epoch: 30 [23552/50176]	Loss: 0.7888
Training Epoch: 30 [24576/50176]	Loss: 0.8152
Training Epoch: 30 [25600/50176]	Loss: 0.8124
Training Epoch: 30 [26624/50176]	Loss: 0.7482
Training Epoch: 30 [27648/50176]	Loss: 0.8353
Training Epoch: 30 [28672/50176]	Loss: 0.8493
Training Epoch: 30 [29696/50176]	Loss: 0.8376
Training Epoch: 30 [30720/50176]	Loss: 0.8197
Training Epoch: 30 [31744/50176]	Loss: 0.7729
Training Epoch: 30 [32768/50176]	Loss: 0.7870
Training Epoch: 30 [33792/50176]	Loss: 0.8658
Training Epoch: 30 [34816/50176]	Loss: 0.9132
Training Epoch: 30 [35840/50176]	Loss: 0.8444
Training Epoch: 30 [36864/50176]	Loss: 0.8541
Training Epoch: 30 [37888/50176]	Loss: 0.8500
Training Epoch: 30 [38912/50176]	Loss: 0.8369
Training Epoch: 30 [39936/50176]	Loss: 0.8112
Training Epoch: 30 [40960/50176]	Loss: 0.8351
Training Epoch: 30 [41984/50176]	Loss: 0.8867
Training Epoch: 30 [43008/50176]	Loss: 0.8751
Training Epoch: 30 [44032/50176]	Loss: 0.8156
Training Epoch: 30 [45056/50176]	Loss: 0.8696
Training Epoch: 30 [46080/50176]	Loss: 0.8676
Training Epoch: 30 [47104/50176]	Loss: 0.8093
Training Epoch: 30 [48128/50176]	Loss: 0.8123
Training Epoch: 30 [49152/50176]	Loss: 0.8943
Training Epoch: 30 [50176/50176]	Loss: 0.9287
2022-12-06 17:35:10.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:35:10,449 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.79 energy=486.24
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Up to epoch 31: time=1545.78, energy=212698.20, cost=241604.99
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:35:10,450 [ZeusDataLoader(train)] Expected next epoch: time=1593.06, energy=219482.15, cost=249133.44
2022-12-06 12:35:10,451 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0024, Accuracy: 0.4656
2022-12-06 12:35:10,663 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:35:10,663 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:35:10.665 [ZeusMonitor] Monitor started.
2022-12-06 17:35:10.665 [ZeusMonitor] Running indefinitely. 2022-12-06 17:35:10.665 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:35:10.665 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 12:35:55,001 [ZeusDataLoader(train)] train epoch 32 done: time=44.54 energy=6332.19
2022-12-06 12:35:55,005 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.7009
Training Epoch: 31 [2048/50176]	Loss: 0.6858
Training Epoch: 31 [3072/50176]	Loss: 0.7435
Training Epoch: 31 [4096/50176]	Loss: 0.6918
Training Epoch: 31 [5120/50176]	Loss: 0.7660
Training Epoch: 31 [6144/50176]	Loss: 0.6968
Training Epoch: 31 [7168/50176]	Loss: 0.7268
Training Epoch: 31 [8192/50176]	Loss: 0.7029
Training Epoch: 31 [9216/50176]	Loss: 0.7243
Training Epoch: 31 [10240/50176]	Loss: 0.7940
Training Epoch: 31 [11264/50176]	Loss: 0.6986
Training Epoch: 31 [12288/50176]	Loss: 0.7148
Training Epoch: 31 [13312/50176]	Loss: 0.7814
Training Epoch: 31 [14336/50176]	Loss: 0.6977
Training Epoch: 31 [15360/50176]	Loss: 0.7319
Training Epoch: 31 [16384/50176]	Loss: 0.7195
Training Epoch: 31 [17408/50176]	Loss: 0.7411
Training Epoch: 31 [18432/50176]	Loss: 0.7620
Training Epoch: 31 [19456/50176]	Loss: 0.7070
Training Epoch: 31 [20480/50176]	Loss: 0.7456
Training Epoch: 31 [21504/50176]	Loss: 0.8003
Training Epoch: 31 [22528/50176]	Loss: 0.8112
Training Epoch: 31 [23552/50176]	Loss: 0.7938
Training Epoch: 31 [24576/50176]	Loss: 0.7112
Training Epoch: 31 [25600/50176]	Loss: 0.7351
Training Epoch: 31 [26624/50176]	Loss: 0.8112
Training Epoch: 31 [27648/50176]	Loss: 0.7925
Training Epoch: 31 [28672/50176]	Loss: 0.7981
Training Epoch: 31 [29696/50176]	Loss: 0.7874
Training Epoch: 31 [30720/50176]	Loss: 0.7768
Training Epoch: 31 [31744/50176]	Loss: 0.7853
Training Epoch: 31 [32768/50176]	Loss: 0.8163
Training Epoch: 31 [33792/50176]	Loss: 0.7386
Training Epoch: 31 [34816/50176]	Loss: 0.8010
Training Epoch: 31 [35840/50176]	Loss: 0.8360
Training Epoch: 31 [36864/50176]	Loss: 0.8257
Training Epoch: 31 [37888/50176]	Loss: 0.7709
Training Epoch: 31 [38912/50176]	Loss: 0.8201
Training Epoch: 31 [39936/50176]	Loss: 0.8724
Training Epoch: 31 [40960/50176]	Loss: 0.8325
Training Epoch: 31 [41984/50176]	Loss: 0.7995
Training Epoch: 31 [43008/50176]	Loss: 0.7540
Training Epoch: 31 [44032/50176]	Loss: 0.7602
Training Epoch: 31 [45056/50176]	Loss: 0.8819
Training Epoch: 31 [46080/50176]	Loss: 0.8256
Training Epoch: 31 [47104/50176]	Loss: 0.7563
Training Epoch: 31 [48128/50176]	Loss: 0.9256
Training Epoch: 31 [49152/50176]	Loss: 0.7818
Training Epoch: 31 [50176/50176]	Loss: 0.7974
2022-12-06 17:35:58.795 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:35:58,804 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.79 energy=499.03
2022-12-06 12:35:58,804 [ZeusDataLoader(train)] Up to epoch 32: time=1594.11, energy=219529.42, cost=249249.75
2022-12-06 12:35:58,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:35:58,805 [ZeusDataLoader(train)] Expected next epoch: time=1641.39, energy=226313.38, cost=256778.21
2022-12-06 12:35:58,806 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0022, Accuracy: 0.5009
2022-12-06 12:35:59,017 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:35:59,018 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:35:59.019 [ZeusMonitor] Monitor started.
2022-12-06 17:35:59.020 [ZeusMonitor] Running indefinitely. 2022-12-06 17:35:59.020 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:35:59.020 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 12:36:44,238 [ZeusDataLoader(train)] train epoch 33 done: time=45.42 energy=6400.69
2022-12-06 12:36:44,243 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.6630
Training Epoch: 32 [2048/50176]	Loss: 0.6873
Training Epoch: 32 [3072/50176]	Loss: 0.7654
Training Epoch: 32 [4096/50176]	Loss: 0.6987
Training Epoch: 32 [5120/50176]	Loss: 0.7374
Training Epoch: 32 [6144/50176]	Loss: 0.7196
Training Epoch: 32 [7168/50176]	Loss: 0.7172
Training Epoch: 32 [8192/50176]	Loss: 0.7229
Training Epoch: 32 [9216/50176]	Loss: 0.6799
Training Epoch: 32 [10240/50176]	Loss: 0.6838
Training Epoch: 32 [11264/50176]	Loss: 0.7407
Training Epoch: 32 [12288/50176]	Loss: 0.7464
Training Epoch: 32 [13312/50176]	Loss: 0.7264
Training Epoch: 32 [14336/50176]	Loss: 0.7296
Training Epoch: 32 [15360/50176]	Loss: 0.6605
Training Epoch: 32 [16384/50176]	Loss: 0.6740
Training Epoch: 32 [17408/50176]	Loss: 0.7163
Training Epoch: 32 [18432/50176]	Loss: 0.7269
Training Epoch: 32 [19456/50176]	Loss: 0.7059
Training Epoch: 32 [20480/50176]	Loss: 0.7155
Training Epoch: 32 [21504/50176]	Loss: 0.7665
Training Epoch: 32 [22528/50176]	Loss: 0.7797
Training Epoch: 32 [23552/50176]	Loss: 0.7590
Training Epoch: 32 [24576/50176]	Loss: 0.7207
Training Epoch: 32 [25600/50176]	Loss: 0.7592
Training Epoch: 32 [26624/50176]	Loss: 0.6880
Training Epoch: 32 [27648/50176]	Loss: 0.6983
Training Epoch: 32 [28672/50176]	Loss: 0.6875
Training Epoch: 32 [29696/50176]	Loss: 0.7208
Training Epoch: 32 [30720/50176]	Loss: 0.6631
Training Epoch: 32 [31744/50176]	Loss: 0.7050
Training Epoch: 32 [32768/50176]	Loss: 0.7175
Training Epoch: 32 [33792/50176]	Loss: 0.7696
Training Epoch: 32 [34816/50176]	Loss: 0.8046
Training Epoch: 32 [35840/50176]	Loss: 0.7119
Training Epoch: 32 [36864/50176]	Loss: 0.8033
Training Epoch: 32 [37888/50176]	Loss: 0.7378
Training Epoch: 32 [38912/50176]	Loss: 0.7268
Training Epoch: 32 [39936/50176]	Loss: 0.7457
Training Epoch: 32 [40960/50176]	Loss: 0.7341
Training Epoch: 32 [41984/50176]	Loss: 0.6883
Training Epoch: 32 [43008/50176]	Loss: 0.8466
Training Epoch: 32 [44032/50176]	Loss: 0.7596
Training Epoch: 32 [45056/50176]	Loss: 0.7207
Training Epoch: 32 [46080/50176]	Loss: 0.8260
Training Epoch: 32 [47104/50176]	Loss: 0.7863
Training Epoch: 32 [48128/50176]	Loss: 0.7551
Training Epoch: 32 [49152/50176]	Loss: 0.7617
Training Epoch: 32 [50176/50176]	Loss: 0.7698
2022-12-06 17:36:48.036 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:36:48,046 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.80 energy=485.74
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Up to epoch 33: time=1643.33, energy=226415.86, cost=256999.74
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:36:48,046 [ZeusDataLoader(train)] Expected next epoch: time=1690.61, energy=233199.81, cost=264528.19
2022-12-06 12:36:48,047 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0019, Accuracy: 0.5354
2022-12-06 12:36:48,256 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:36:48,257 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:36:48.259 [ZeusMonitor] Monitor started.
2022-12-06 17:36:48.259 [ZeusMonitor] Running indefinitely. 2022-12-06 17:36:48.259 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:36:48.259 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 12:37:33,653 [ZeusDataLoader(train)] train epoch 34 done: time=45.60 energy=6412.67
2022-12-06 12:37:33,657 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.6775
Training Epoch: 33 [2048/50176]	Loss: 0.6262
Training Epoch: 33 [3072/50176]	Loss: 0.6932
Training Epoch: 33 [4096/50176]	Loss: 0.6916
Training Epoch: 33 [5120/50176]	Loss: 0.6900
Training Epoch: 33 [6144/50176]	Loss: 0.6727
Training Epoch: 33 [7168/50176]	Loss: 0.7011
Training Epoch: 33 [8192/50176]	Loss: 0.6085
Training Epoch: 33 [9216/50176]	Loss: 0.6297
Training Epoch: 33 [10240/50176]	Loss: 0.7028
Training Epoch: 33 [11264/50176]	Loss: 0.7099
Training Epoch: 33 [12288/50176]	Loss: 0.7174
Training Epoch: 33 [13312/50176]	Loss: 0.7315
Training Epoch: 33 [14336/50176]	Loss: 0.6486
Training Epoch: 33 [15360/50176]	Loss: 0.6816
Training Epoch: 33 [16384/50176]	Loss: 0.7047
Training Epoch: 33 [17408/50176]	Loss: 0.6472
Training Epoch: 33 [18432/50176]	Loss: 0.7314
Training Epoch: 33 [19456/50176]	Loss: 0.6864
Training Epoch: 33 [20480/50176]	Loss: 0.6745
Training Epoch: 33 [21504/50176]	Loss: 0.7314
Training Epoch: 33 [22528/50176]	Loss: 0.7062
Training Epoch: 33 [23552/50176]	Loss: 0.7527
Training Epoch: 33 [24576/50176]	Loss: 0.6547
Training Epoch: 33 [25600/50176]	Loss: 0.7138
Training Epoch: 33 [26624/50176]	Loss: 0.6515
Training Epoch: 33 [27648/50176]	Loss: 0.6949
Training Epoch: 33 [28672/50176]	Loss: 0.7180
Training Epoch: 33 [29696/50176]	Loss: 0.6777
Training Epoch: 33 [30720/50176]	Loss: 0.7534
Training Epoch: 33 [31744/50176]	Loss: 0.6907
Training Epoch: 33 [32768/50176]	Loss: 0.7437
Training Epoch: 33 [33792/50176]	Loss: 0.7680
Training Epoch: 33 [34816/50176]	Loss: 0.7025
Training Epoch: 33 [35840/50176]	Loss: 0.6707
Training Epoch: 33 [36864/50176]	Loss: 0.6641
Training Epoch: 33 [37888/50176]	Loss: 0.7303
Training Epoch: 33 [38912/50176]	Loss: 0.7635
Training Epoch: 33 [39936/50176]	Loss: 0.7239
Training Epoch: 33 [40960/50176]	Loss: 0.7193
Training Epoch: 33 [41984/50176]	Loss: 0.7259
Training Epoch: 33 [43008/50176]	Loss: 0.7161
Training Epoch: 33 [44032/50176]	Loss: 0.7266
Training Epoch: 33 [45056/50176]	Loss: 0.7686
Training Epoch: 33 [46080/50176]	Loss: 0.6925
Training Epoch: 33 [47104/50176]	Loss: 0.7606
Training Epoch: 33 [48128/50176]	Loss: 0.7443
Training Epoch: 33 [49152/50176]	Loss: 0.6840
Training Epoch: 33 [50176/50176]	Loss: 0.7509
2022-12-06 17:37:37.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:37:37,613 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.95 energy=489.97
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Up to epoch 34: time=1692.88, energy=233318.50, cost=264786.38
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:37:37,614 [ZeusDataLoader(train)] Expected next epoch: time=1740.16, energy=240102.45, cost=272314.83
2022-12-06 12:37:37,615 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0019, Accuracy: 0.5462
2022-12-06 12:37:37,786 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:37:37,786 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:37:37.790 [ZeusMonitor] Monitor started.
2022-12-06 17:37:37.790 [ZeusMonitor] Running indefinitely. 2022-12-06 17:37:37.790 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:37:37.790 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 12:38:23,293 [ZeusDataLoader(train)] train epoch 35 done: time=45.67 energy=6418.76
2022-12-06 12:38:23,297 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.6476
Training Epoch: 34 [2048/50176]	Loss: 0.6259
Training Epoch: 34 [3072/50176]	Loss: 0.6547
Training Epoch: 34 [4096/50176]	Loss: 0.6056
Training Epoch: 34 [5120/50176]	Loss: 0.6375
Training Epoch: 34 [6144/50176]	Loss: 0.6322
Training Epoch: 34 [7168/50176]	Loss: 0.6160
Training Epoch: 34 [8192/50176]	Loss: 0.6302
Training Epoch: 34 [9216/50176]	Loss: 0.5886
Training Epoch: 34 [10240/50176]	Loss: 0.7180
Training Epoch: 34 [11264/50176]	Loss: 0.6095
Training Epoch: 34 [12288/50176]	Loss: 0.6845
Training Epoch: 34 [13312/50176]	Loss: 0.6026
Training Epoch: 34 [14336/50176]	Loss: 0.6130
Training Epoch: 34 [15360/50176]	Loss: 0.6600
Training Epoch: 34 [16384/50176]	Loss: 0.7608
Training Epoch: 34 [17408/50176]	Loss: 0.5864
Training Epoch: 34 [18432/50176]	Loss: 0.6438
Training Epoch: 34 [19456/50176]	Loss: 0.5998
Training Epoch: 34 [20480/50176]	Loss: 0.6411
Training Epoch: 34 [21504/50176]	Loss: 0.7027
Training Epoch: 34 [22528/50176]	Loss: 0.6436
Training Epoch: 34 [23552/50176]	Loss: 0.6394
Training Epoch: 34 [24576/50176]	Loss: 0.5827
Training Epoch: 34 [25600/50176]	Loss: 0.6477
Training Epoch: 34 [26624/50176]	Loss: 0.7079
Training Epoch: 34 [27648/50176]	Loss: 0.6978
Training Epoch: 34 [28672/50176]	Loss: 0.6901
Training Epoch: 34 [29696/50176]	Loss: 0.6613
Training Epoch: 34 [30720/50176]	Loss: 0.7522
Training Epoch: 34 [31744/50176]	Loss: 0.6623
Training Epoch: 34 [32768/50176]	Loss: 0.7091
Training Epoch: 34 [33792/50176]	Loss: 0.6868
Training Epoch: 34 [34816/50176]	Loss: 0.6961
Training Epoch: 34 [35840/50176]	Loss: 0.6986
Training Epoch: 34 [36864/50176]	Loss: 0.6731
Training Epoch: 34 [37888/50176]	Loss: 0.7211
Training Epoch: 34 [38912/50176]	Loss: 0.6349
Training Epoch: 34 [39936/50176]	Loss: 0.6705
Training Epoch: 34 [40960/50176]	Loss: 0.6959
Training Epoch: 34 [41984/50176]	Loss: 0.6413
Training Epoch: 34 [43008/50176]	Loss: 0.7307
Training Epoch: 34 [44032/50176]	Loss: 0.6586
Training Epoch: 34 [45056/50176]	Loss: 0.7485
Training Epoch: 34 [46080/50176]	Loss: 0.6360
Training Epoch: 34 [47104/50176]	Loss: 0.7374
Training Epoch: 34 [48128/50176]	Loss: 0.7359
Training Epoch: 34 [49152/50176]	Loss: 0.7447
Training Epoch: 34 [50176/50176]	Loss: 0.7183
2022-12-06 17:38:27.023 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:38:27,042 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.74 energy=473.13
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Up to epoch 35: time=1742.29, energy=240210.39, cost=272555.48
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:38:27,042 [ZeusDataLoader(train)] Expected next epoch: time=1789.56, energy=246994.34, cost=280083.93
2022-12-06 12:38:27,043 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0019, Accuracy: 0.5517
2022-12-06 12:38:27,216 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:38:27,217 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:38:27.220 [ZeusMonitor] Monitor started.
2022-12-06 17:38:27.220 [ZeusMonitor] Running indefinitely. 2022-12-06 17:38:27.220 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:38:27.220 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 12:39:11,739 [ZeusDataLoader(train)] train epoch 36 done: time=44.69 energy=6339.17
2022-12-06 12:39:11,743 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.6057
Training Epoch: 35 [2048/50176]	Loss: 0.6387
Training Epoch: 35 [3072/50176]	Loss: 0.6062
Training Epoch: 35 [4096/50176]	Loss: 0.5890
Training Epoch: 35 [5120/50176]	Loss: 0.5871
Training Epoch: 35 [6144/50176]	Loss: 0.5799
Training Epoch: 35 [7168/50176]	Loss: 0.6287
Training Epoch: 35 [8192/50176]	Loss: 0.6076
Training Epoch: 35 [9216/50176]	Loss: 0.5768
Training Epoch: 35 [10240/50176]	Loss: 0.5873
Training Epoch: 35 [11264/50176]	Loss: 0.6316
Training Epoch: 35 [12288/50176]	Loss: 0.6574
Training Epoch: 35 [13312/50176]	Loss: 0.5957
Training Epoch: 35 [14336/50176]	Loss: 0.6247
Training Epoch: 35 [15360/50176]	Loss: 0.5966
Training Epoch: 35 [16384/50176]	Loss: 0.6291
Training Epoch: 35 [17408/50176]	Loss: 0.7003
Training Epoch: 35 [18432/50176]	Loss: 0.6405
Training Epoch: 35 [19456/50176]	Loss: 0.6712
Training Epoch: 35 [20480/50176]	Loss: 0.5880
Training Epoch: 35 [21504/50176]	Loss: 0.6070
Training Epoch: 35 [22528/50176]	Loss: 0.6519
Training Epoch: 35 [23552/50176]	Loss: 0.6518
Training Epoch: 35 [24576/50176]	Loss: 0.7127
Training Epoch: 35 [25600/50176]	Loss: 0.6540
Training Epoch: 35 [26624/50176]	Loss: 0.6140
Training Epoch: 35 [27648/50176]	Loss: 0.6394
Training Epoch: 35 [28672/50176]	Loss: 0.6632
Training Epoch: 35 [29696/50176]	Loss: 0.6315
Training Epoch: 35 [30720/50176]	Loss: 0.6586
Training Epoch: 35 [31744/50176]	Loss: 0.6624
Training Epoch: 35 [32768/50176]	Loss: 0.6179
Training Epoch: 35 [33792/50176]	Loss: 0.6063
Training Epoch: 35 [34816/50176]	Loss: 0.6393
Training Epoch: 35 [35840/50176]	Loss: 0.6778
Training Epoch: 35 [36864/50176]	Loss: 0.7243
Training Epoch: 35 [37888/50176]	Loss: 0.6901
Training Epoch: 35 [38912/50176]	Loss: 0.6267
Training Epoch: 35 [39936/50176]	Loss: 0.7467
Training Epoch: 35 [40960/50176]	Loss: 0.6322
Training Epoch: 35 [41984/50176]	Loss: 0.7142
Training Epoch: 35 [43008/50176]	Loss: 0.6459
Training Epoch: 35 [44032/50176]	Loss: 0.6635
Training Epoch: 35 [45056/50176]	Loss: 0.6451
Training Epoch: 35 [46080/50176]	Loss: 0.6851
Training Epoch: 35 [47104/50176]	Loss: 0.6743
Training Epoch: 35 [48128/50176]	Loss: 0.6862
Training Epoch: 35 [49152/50176]	Loss: 0.6765
Training Epoch: 35 [50176/50176]	Loss: 0.6694
2022-12-06 17:39:15.434 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:39:15,453 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.70 energy=475.87
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Up to epoch 36: time=1790.68, energy=247025.44, cost=280197.15
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:39:15,453 [ZeusDataLoader(train)] Expected next epoch: time=1837.95, energy=253809.39, cost=287725.61
2022-12-06 12:39:15,454 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0020, Accuracy: 0.5344
2022-12-06 12:39:15,679 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:39:15,679 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:39:15.681 [ZeusMonitor] Monitor started.
2022-12-06 17:39:15.681 [ZeusMonitor] Running indefinitely. 2022-12-06 17:39:15.681 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:39:15.681 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 12:40:00,189 [ZeusDataLoader(train)] train epoch 37 done: time=44.73 energy=6359.94
2022-12-06 12:40:00,193 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.5426
Training Epoch: 36 [2048/50176]	Loss: 0.5486
Training Epoch: 36 [3072/50176]	Loss: 0.5418
Training Epoch: 36 [4096/50176]	Loss: 0.5532
Training Epoch: 36 [5120/50176]	Loss: 0.5858
Training Epoch: 36 [6144/50176]	Loss: 0.5475
Training Epoch: 36 [7168/50176]	Loss: 0.6071
Training Epoch: 36 [8192/50176]	Loss: 0.6229
Training Epoch: 36 [9216/50176]	Loss: 0.5483
Training Epoch: 36 [10240/50176]	Loss: 0.6312
Training Epoch: 36 [11264/50176]	Loss: 0.5843
Training Epoch: 36 [12288/50176]	Loss: 0.6164
Training Epoch: 36 [13312/50176]	Loss: 0.5869
Training Epoch: 36 [14336/50176]	Loss: 0.5589
Training Epoch: 36 [15360/50176]	Loss: 0.6064
Training Epoch: 36 [16384/50176]	Loss: 0.5842
Training Epoch: 36 [17408/50176]	Loss: 0.6014
Training Epoch: 36 [18432/50176]	Loss: 0.6180
Training Epoch: 36 [19456/50176]	Loss: 0.5815
Training Epoch: 36 [20480/50176]	Loss: 0.5797
Training Epoch: 36 [21504/50176]	Loss: 0.6020
Training Epoch: 36 [22528/50176]	Loss: 0.6371
Training Epoch: 36 [23552/50176]	Loss: 0.5332
Training Epoch: 36 [24576/50176]	Loss: 0.6463
Training Epoch: 36 [25600/50176]	Loss: 0.6506
Training Epoch: 36 [26624/50176]	Loss: 0.6641
Training Epoch: 36 [27648/50176]	Loss: 0.6222
Training Epoch: 36 [28672/50176]	Loss: 0.6223
Training Epoch: 36 [29696/50176]	Loss: 0.6028
Training Epoch: 36 [30720/50176]	Loss: 0.6458
Training Epoch: 36 [31744/50176]	Loss: 0.5731
Training Epoch: 36 [32768/50176]	Loss: 0.6402
Training Epoch: 36 [33792/50176]	Loss: 0.6217
Training Epoch: 36 [34816/50176]	Loss: 0.6545
Training Epoch: 36 [35840/50176]	Loss: 0.6022
Training Epoch: 36 [36864/50176]	Loss: 0.6147
Training Epoch: 36 [37888/50176]	Loss: 0.6401
Training Epoch: 36 [38912/50176]	Loss: 0.6510
Training Epoch: 36 [39936/50176]	Loss: 0.6047
Training Epoch: 36 [40960/50176]	Loss: 0.6346
Training Epoch: 36 [41984/50176]	Loss: 0.6556
Training Epoch: 36 [43008/50176]	Loss: 0.6907
Training Epoch: 36 [44032/50176]	Loss: 0.6556
Training Epoch: 36 [45056/50176]	Loss: 0.5875
Training Epoch: 36 [46080/50176]	Loss: 0.6261
Training Epoch: 36 [47104/50176]	Loss: 0.6181
Training Epoch: 36 [48128/50176]	Loss: 0.6041
Training Epoch: 36 [49152/50176]	Loss: 0.6149
Training Epoch: 36 [50176/50176]	Loss: 0.6577
2022-12-06 17:40:04.009 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:40:04,038 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.84 energy=481.27
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Up to epoch 37: time=1839.24, energy=253866.65, cost=287867.14
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:40:04,038 [ZeusDataLoader(train)] Expected next epoch: time=1886.52, energy=260650.60, cost=295395.59
2022-12-06 12:40:04,039 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0019, Accuracy: 0.5499
2022-12-06 12:40:04,254 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:40:04,255 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:40:04.269 [ZeusMonitor] Monitor started.
2022-12-06 17:40:04.269 [ZeusMonitor] Running indefinitely. 2022-12-06 17:40:04.269 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:40:04.269 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 12:40:48,722 [ZeusDataLoader(train)] train epoch 38 done: time=44.67 energy=6342.13
2022-12-06 12:40:48,725 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.5025
Training Epoch: 37 [2048/50176]	Loss: 0.5787
Training Epoch: 37 [3072/50176]	Loss: 0.5339
Training Epoch: 37 [4096/50176]	Loss: 0.5511
Training Epoch: 37 [5120/50176]	Loss: 0.5672
Training Epoch: 37 [6144/50176]	Loss: 0.5333
Training Epoch: 37 [7168/50176]	Loss: 0.5321
Training Epoch: 37 [8192/50176]	Loss: 0.5188
Training Epoch: 37 [9216/50176]	Loss: 0.5320
Training Epoch: 37 [10240/50176]	Loss: 0.5610
Training Epoch: 37 [11264/50176]	Loss: 0.5490
Training Epoch: 37 [12288/50176]	Loss: 0.5585
Training Epoch: 37 [13312/50176]	Loss: 0.5294
Training Epoch: 37 [14336/50176]	Loss: 0.4968
Training Epoch: 37 [15360/50176]	Loss: 0.5688
Training Epoch: 37 [16384/50176]	Loss: 0.5684
Training Epoch: 37 [17408/50176]	Loss: 0.5816
Training Epoch: 37 [18432/50176]	Loss: 0.5292
Training Epoch: 37 [19456/50176]	Loss: 0.5304
Training Epoch: 37 [20480/50176]	Loss: 0.5770
Training Epoch: 37 [21504/50176]	Loss: 0.5667
Training Epoch: 37 [22528/50176]	Loss: 0.5347
Training Epoch: 37 [23552/50176]	Loss: 0.5631
Training Epoch: 37 [24576/50176]	Loss: 0.5560
Training Epoch: 37 [25600/50176]	Loss: 0.5527
Training Epoch: 37 [26624/50176]	Loss: 0.5966
Training Epoch: 37 [27648/50176]	Loss: 0.5792
Training Epoch: 37 [28672/50176]	Loss: 0.6197
Training Epoch: 37 [29696/50176]	Loss: 0.5783
Training Epoch: 37 [30720/50176]	Loss: 0.5379
Training Epoch: 37 [31744/50176]	Loss: 0.5274
Training Epoch: 37 [32768/50176]	Loss: 0.5577
Training Epoch: 37 [33792/50176]	Loss: 0.5693
Training Epoch: 37 [34816/50176]	Loss: 0.6573
Training Epoch: 37 [35840/50176]	Loss: 0.6026
Training Epoch: 37 [36864/50176]	Loss: 0.5515
Training Epoch: 37 [37888/50176]	Loss: 0.6687
Training Epoch: 37 [38912/50176]	Loss: 0.6344
Training Epoch: 37 [39936/50176]	Loss: 0.5717
Training Epoch: 37 [40960/50176]	Loss: 0.6106
Training Epoch: 37 [41984/50176]	Loss: 0.6070
Training Epoch: 37 [43008/50176]	Loss: 0.5974
Training Epoch: 37 [44032/50176]	Loss: 0.6431
Training Epoch: 37 [45056/50176]	Loss: 0.6807
Training Epoch: 37 [46080/50176]	Loss: 0.6157
Training Epoch: 37 [47104/50176]	Loss: 0.6138
Training Epoch: 37 [48128/50176]	Loss: 0.6438
Training Epoch: 37 [49152/50176]	Loss: 0.5941
Training Epoch: 37 [50176/50176]	Loss: 0.6437
2022-12-06 17:40:52.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:40:52,463 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.73 energy=478.21
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Up to epoch 38: time=1887.65, energy=260686.99, cost=295512.78
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:40:52,464 [ZeusDataLoader(train)] Expected next epoch: time=1934.92, energy=267470.94, cost=303041.24
2022-12-06 12:40:52,465 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0020, Accuracy: 0.5605
2022-12-06 12:40:52,676 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:40:52,676 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:40:52.678 [ZeusMonitor] Monitor started.
2022-12-06 17:40:52.678 [ZeusMonitor] Running indefinitely. 2022-12-06 17:40:52.678 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:40:52.678 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 12:41:36,951 [ZeusDataLoader(train)] train epoch 39 done: time=44.48 energy=6324.51
2022-12-06 12:41:36,954 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.5354
Training Epoch: 38 [2048/50176]	Loss: 0.4899
Training Epoch: 38 [3072/50176]	Loss: 0.5133
Training Epoch: 38 [4096/50176]	Loss: 0.4962
Training Epoch: 38 [5120/50176]	Loss: 0.5100
Training Epoch: 38 [6144/50176]	Loss: 0.4689
Training Epoch: 38 [7168/50176]	Loss: 0.5325
Training Epoch: 38 [8192/50176]	Loss: 0.4927
Training Epoch: 38 [9216/50176]	Loss: 0.5097
Training Epoch: 38 [10240/50176]	Loss: 0.5251
Training Epoch: 38 [11264/50176]	Loss: 0.5955
Training Epoch: 38 [12288/50176]	Loss: 0.5154
Training Epoch: 38 [13312/50176]	Loss: 0.5486
Training Epoch: 38 [14336/50176]	Loss: 0.5398
Training Epoch: 38 [15360/50176]	Loss: 0.5413
Training Epoch: 38 [16384/50176]	Loss: 0.5260
Training Epoch: 38 [17408/50176]	Loss: 0.5517
Training Epoch: 38 [18432/50176]	Loss: 0.5503
Training Epoch: 38 [19456/50176]	Loss: 0.5158
Training Epoch: 38 [20480/50176]	Loss: 0.5381
Training Epoch: 38 [21504/50176]	Loss: 0.5063
Training Epoch: 38 [22528/50176]	Loss: 0.5731
Training Epoch: 38 [23552/50176]	Loss: 0.5644
Training Epoch: 38 [24576/50176]	Loss: 0.5514
Training Epoch: 38 [25600/50176]	Loss: 0.4790
Training Epoch: 38 [26624/50176]	Loss: 0.5865
Training Epoch: 38 [27648/50176]	Loss: 0.5443
Training Epoch: 38 [28672/50176]	Loss: 0.6148
Training Epoch: 38 [29696/50176]	Loss: 0.5385
Training Epoch: 38 [30720/50176]	Loss: 0.5559
Training Epoch: 38 [31744/50176]	Loss: 0.5290
Training Epoch: 38 [32768/50176]	Loss: 0.5992
Training Epoch: 38 [33792/50176]	Loss: 0.5534
Training Epoch: 38 [34816/50176]	Loss: 0.5992
Training Epoch: 38 [35840/50176]	Loss: 0.5418
Training Epoch: 38 [36864/50176]	Loss: 0.5511
Training Epoch: 38 [37888/50176]	Loss: 0.5624
Training Epoch: 38 [38912/50176]	Loss: 0.5408
Training Epoch: 38 [39936/50176]	Loss: 0.5837
Training Epoch: 38 [40960/50176]	Loss: 0.6010
Training Epoch: 38 [41984/50176]	Loss: 0.5159
Training Epoch: 38 [43008/50176]	Loss: 0.6153
Training Epoch: 38 [44032/50176]	Loss: 0.5765
Training Epoch: 38 [45056/50176]	Loss: 0.5358
Training Epoch: 38 [46080/50176]	Loss: 0.5517
Training Epoch: 38 [47104/50176]	Loss: 0.6550
Training Epoch: 38 [48128/50176]	Loss: 0.5686
Training Epoch: 38 [49152/50176]	Loss: 0.6230
Training Epoch: 38 [50176/50176]	Loss: 0.5946
2022-12-06 17:41:40.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:41:40,765 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.80 energy=490.44
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Up to epoch 39: time=1935.93, energy=267501.94, cost=303144.85
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:41:40,765 [ZeusDataLoader(train)] Expected next epoch: time=1983.20, energy=274285.89, cost=310673.30
2022-12-06 12:41:40,766 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0019, Accuracy: 0.5514
2022-12-06 12:41:40,982 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:41:40,983 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:41:40.985 [ZeusMonitor] Monitor started.
2022-12-06 17:41:40.985 [ZeusMonitor] Running indefinitely. 2022-12-06 17:41:40.985 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:41:40.985 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 12:42:25,700 [ZeusDataLoader(train)] train epoch 40 done: time=44.93 energy=6362.34
2022-12-06 12:42:25,703 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.4319
Training Epoch: 39 [2048/50176]	Loss: 0.4684
Training Epoch: 39 [3072/50176]	Loss: 0.4932
Training Epoch: 39 [4096/50176]	Loss: 0.5099
Training Epoch: 39 [5120/50176]	Loss: 0.5107
Training Epoch: 39 [6144/50176]	Loss: 0.5102
Training Epoch: 39 [7168/50176]	Loss: 0.4494
Training Epoch: 39 [8192/50176]	Loss: 0.5128
Training Epoch: 39 [9216/50176]	Loss: 0.4987
Training Epoch: 39 [10240/50176]	Loss: 0.4845
Training Epoch: 39 [11264/50176]	Loss: 0.4680
Training Epoch: 39 [12288/50176]	Loss: 0.4789
Training Epoch: 39 [13312/50176]	Loss: 0.4796
Training Epoch: 39 [14336/50176]	Loss: 0.5228
Training Epoch: 39 [15360/50176]	Loss: 0.4938
Training Epoch: 39 [16384/50176]	Loss: 0.4914
Training Epoch: 39 [17408/50176]	Loss: 0.4741
Training Epoch: 39 [18432/50176]	Loss: 0.4768
Training Epoch: 39 [19456/50176]	Loss: 0.5402
Training Epoch: 39 [20480/50176]	Loss: 0.5174
Training Epoch: 39 [21504/50176]	Loss: 0.5450
Training Epoch: 39 [22528/50176]	Loss: 0.5003
Training Epoch: 39 [23552/50176]	Loss: 0.4624
Training Epoch: 39 [24576/50176]	Loss: 0.4680
Training Epoch: 39 [25600/50176]	Loss: 0.5590
Training Epoch: 39 [26624/50176]	Loss: 0.5511
Training Epoch: 39 [27648/50176]	Loss: 0.5657
Training Epoch: 39 [28672/50176]	Loss: 0.5030
Training Epoch: 39 [29696/50176]	Loss: 0.5958
Training Epoch: 39 [30720/50176]	Loss: 0.5254
Training Epoch: 39 [31744/50176]	Loss: 0.5896
Training Epoch: 39 [32768/50176]	Loss: 0.4809
Training Epoch: 39 [33792/50176]	Loss: 0.5281
Training Epoch: 39 [34816/50176]	Loss: 0.6181
Training Epoch: 39 [35840/50176]	Loss: 0.5370
Training Epoch: 39 [36864/50176]	Loss: 0.5161
Training Epoch: 39 [37888/50176]	Loss: 0.5314
Training Epoch: 39 [38912/50176]	Loss: 0.5436
Training Epoch: 39 [39936/50176]	Loss: 0.6255
Training Epoch: 39 [40960/50176]	Loss: 0.6235
Training Epoch: 39 [41984/50176]	Loss: 0.5754
Training Epoch: 39 [43008/50176]	Loss: 0.5459
Training Epoch: 39 [44032/50176]	Loss: 0.5556
Training Epoch: 39 [45056/50176]	Loss: 0.6082
Training Epoch: 39 [46080/50176]	Loss: 0.5385
Training Epoch: 39 [47104/50176]	Loss: 0.5602
Training Epoch: 39 [48128/50176]	Loss: 0.4780
Training Epoch: 39 [49152/50176]	Loss: 0.5225
Training Epoch: 39 [50176/50176]	Loss: 0.6544
2022-12-06 17:42:29.422 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:42:29,439 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.73 energy=479.74
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Up to epoch 40: time=1984.58, energy=274344.02, cost=310823.09
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:42:29,439 [ZeusDataLoader(train)] Expected next epoch: time=2031.86, energy=281127.97, cost=318351.54
2022-12-06 12:42:29,440 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0020, Accuracy: 0.5554
2022-12-06 12:42:29,659 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:42:29,659 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:42:29.661 [ZeusMonitor] Monitor started.
2022-12-06 17:42:29.661 [ZeusMonitor] Running indefinitely. 2022-12-06 17:42:29.661 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:42:29.661 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 12:43:13,855 [ZeusDataLoader(train)] train epoch 41 done: time=44.41 energy=6336.25
2022-12-06 12:43:13,859 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.4307
Training Epoch: 40 [2048/50176]	Loss: 0.4184
Training Epoch: 40 [3072/50176]	Loss: 0.4413
Training Epoch: 40 [4096/50176]	Loss: 0.4538
Training Epoch: 40 [5120/50176]	Loss: 0.4702
Training Epoch: 40 [6144/50176]	Loss: 0.4863
Training Epoch: 40 [7168/50176]	Loss: 0.4103
Training Epoch: 40 [8192/50176]	Loss: 0.4636
Training Epoch: 40 [9216/50176]	Loss: 0.4564
Training Epoch: 40 [10240/50176]	Loss: 0.4463
Training Epoch: 40 [11264/50176]	Loss: 0.4303
Training Epoch: 40 [12288/50176]	Loss: 0.5063
Training Epoch: 40 [13312/50176]	Loss: 0.4705
Training Epoch: 40 [14336/50176]	Loss: 0.4352
Training Epoch: 40 [15360/50176]	Loss: 0.4649
Training Epoch: 40 [16384/50176]	Loss: 0.4641
Training Epoch: 40 [17408/50176]	Loss: 0.4389
Training Epoch: 40 [18432/50176]	Loss: 0.4665
Training Epoch: 40 [19456/50176]	Loss: 0.5016
Training Epoch: 40 [20480/50176]	Loss: 0.4611
Training Epoch: 40 [21504/50176]	Loss: 0.4860
Training Epoch: 40 [22528/50176]	Loss: 0.4858
Training Epoch: 40 [23552/50176]	Loss: 0.5109
Training Epoch: 40 [24576/50176]	Loss: 0.5510
Training Epoch: 40 [25600/50176]	Loss: 0.5213
Training Epoch: 40 [26624/50176]	Loss: 0.4737
Training Epoch: 40 [27648/50176]	Loss: 0.4522
Training Epoch: 40 [28672/50176]	Loss: 0.4955
Training Epoch: 40 [29696/50176]	Loss: 0.4722
Training Epoch: 40 [30720/50176]	Loss: 0.4909
Training Epoch: 40 [31744/50176]	Loss: 0.4855
Training Epoch: 40 [32768/50176]	Loss: 0.5414
Training Epoch: 40 [33792/50176]	Loss: 0.5264
Training Epoch: 40 [34816/50176]	Loss: 0.4810
Training Epoch: 40 [35840/50176]	Loss: 0.4673
Training Epoch: 40 [36864/50176]	Loss: 0.5042
Training Epoch: 40 [37888/50176]	Loss: 0.4423
Training Epoch: 40 [38912/50176]	Loss: 0.5034
Training Epoch: 40 [39936/50176]	Loss: 0.5393
Training Epoch: 40 [40960/50176]	Loss: 0.5368
Training Epoch: 40 [41984/50176]	Loss: 0.5246
Training Epoch: 40 [43008/50176]	Loss: 0.5676
Training Epoch: 40 [44032/50176]	Loss: 0.5001
Training Epoch: 40 [45056/50176]	Loss: 0.5396
Training Epoch: 40 [46080/50176]	Loss: 0.5629
Training Epoch: 40 [47104/50176]	Loss: 0.5132
Training Epoch: 40 [48128/50176]	Loss: 0.5549
Training Epoch: 40 [49152/50176]	Loss: 0.5509
Training Epoch: 40 [50176/50176]	Loss: 0.5590
2022-12-06 17:43:17.638 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:43:17,661 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.79 energy=477.03
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Up to epoch 41: time=2032.79, energy=281157.29, cost=318447.41
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:43:17,662 [ZeusDataLoader(train)] Expected next epoch: time=2080.06, energy=287941.24, cost=325975.87
2022-12-06 12:43:17,663 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0020, Accuracy: 0.5716
2022-12-06 12:43:17,839 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:43:17,840 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:43:17.841 [ZeusMonitor] Monitor started.
2022-12-06 17:43:17.842 [ZeusMonitor] Running indefinitely. 2022-12-06 17:43:17.842 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:43:17.842 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 12:44:01,830 [ZeusDataLoader(train)] train epoch 42 done: time=44.16 energy=6307.78
2022-12-06 12:44:01,834 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.4208
Training Epoch: 41 [2048/50176]	Loss: 0.4316
Training Epoch: 41 [3072/50176]	Loss: 0.4191
Training Epoch: 41 [4096/50176]	Loss: 0.4459
Training Epoch: 41 [5120/50176]	Loss: 0.4343
Training Epoch: 41 [6144/50176]	Loss: 0.4890
Training Epoch: 41 [7168/50176]	Loss: 0.4755
Training Epoch: 41 [8192/50176]	Loss: 0.4317
Training Epoch: 41 [9216/50176]	Loss: 0.4925
Training Epoch: 41 [10240/50176]	Loss: 0.4851
Training Epoch: 41 [11264/50176]	Loss: 0.4281
Training Epoch: 41 [12288/50176]	Loss: 0.4352
Training Epoch: 41 [13312/50176]	Loss: 0.4485
Training Epoch: 41 [14336/50176]	Loss: 0.4323
Training Epoch: 41 [15360/50176]	Loss: 0.4575
Training Epoch: 41 [16384/50176]	Loss: 0.4157
Training Epoch: 41 [17408/50176]	Loss: 0.4814
Training Epoch: 41 [18432/50176]	Loss: 0.4706
Training Epoch: 41 [19456/50176]	Loss: 0.5154
Training Epoch: 41 [20480/50176]	Loss: 0.4423
Training Epoch: 41 [21504/50176]	Loss: 0.4511
Training Epoch: 41 [22528/50176]	Loss: 0.4535
Training Epoch: 41 [23552/50176]	Loss: 0.4713
Training Epoch: 41 [24576/50176]	Loss: 0.4649
Training Epoch: 41 [25600/50176]	Loss: 0.4151
Training Epoch: 41 [26624/50176]	Loss: 0.4600
Training Epoch: 41 [27648/50176]	Loss: 0.4459
Training Epoch: 41 [28672/50176]	Loss: 0.4971
Training Epoch: 41 [29696/50176]	Loss: 0.4807
Training Epoch: 41 [30720/50176]	Loss: 0.4618
Training Epoch: 41 [31744/50176]	Loss: 0.4997
Training Epoch: 41 [32768/50176]	Loss: 0.4664
Training Epoch: 41 [33792/50176]	Loss: 0.4837
Training Epoch: 41 [34816/50176]	Loss: 0.4453
Training Epoch: 41 [35840/50176]	Loss: 0.4955
Training Epoch: 41 [36864/50176]	Loss: 0.4736
Training Epoch: 41 [37888/50176]	Loss: 0.4733
Training Epoch: 41 [38912/50176]	Loss: 0.4548
Training Epoch: 41 [39936/50176]	Loss: 0.5016
Training Epoch: 41 [40960/50176]	Loss: 0.5581
Training Epoch: 41 [41984/50176]	Loss: 0.5092
Training Epoch: 41 [43008/50176]	Loss: 0.4771
Training Epoch: 41 [44032/50176]	Loss: 0.5180
Training Epoch: 41 [45056/50176]	Loss: 0.4912
Training Epoch: 41 [46080/50176]	Loss: 0.4978
Training Epoch: 41 [47104/50176]	Loss: 0.4926
Training Epoch: 41 [48128/50176]	Loss: 0.5067
Training Epoch: 41 [49152/50176]	Loss: 0.5394
Training Epoch: 41 [50176/50176]	Loss: 0.5145
2022-12-06 17:44:05.530 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:44:05,554 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.71 energy=473.44
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Up to epoch 42: time=2080.66, energy=287938.50, cost=326026.79
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:44:05,554 [ZeusDataLoader(train)] Expected next epoch: time=2127.93, energy=294722.45, cost=333555.25
2022-12-06 12:44:05,555 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0020, Accuracy: 0.5665
2022-12-06 12:44:05,733 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:44:05,734 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:44:05.738 [ZeusMonitor] Monitor started.
2022-12-06 17:44:05.738 [ZeusMonitor] Running indefinitely. 2022-12-06 17:44:05.738 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:44:05.738 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 12:44:49,828 [ZeusDataLoader(train)] train epoch 43 done: time=44.26 energy=6315.54
2022-12-06 12:44:49,831 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.3529
Training Epoch: 42 [2048/50176]	Loss: 0.3621
Training Epoch: 42 [3072/50176]	Loss: 0.4193
Training Epoch: 42 [4096/50176]	Loss: 0.4307
Training Epoch: 42 [5120/50176]	Loss: 0.4412
Training Epoch: 42 [6144/50176]	Loss: 0.4080
Training Epoch: 42 [7168/50176]	Loss: 0.4133
Training Epoch: 42 [8192/50176]	Loss: 0.4271
Training Epoch: 42 [9216/50176]	Loss: 0.4215
Training Epoch: 42 [10240/50176]	Loss: 0.4452
Training Epoch: 42 [11264/50176]	Loss: 0.4003
Training Epoch: 42 [12288/50176]	Loss: 0.4458
Training Epoch: 42 [13312/50176]	Loss: 0.4143
Training Epoch: 42 [14336/50176]	Loss: 0.4448
Training Epoch: 42 [15360/50176]	Loss: 0.4392
Training Epoch: 42 [16384/50176]	Loss: 0.3885
Training Epoch: 42 [17408/50176]	Loss: 0.4096
Training Epoch: 42 [18432/50176]	Loss: 0.4231
Training Epoch: 42 [19456/50176]	Loss: 0.4378
Training Epoch: 42 [20480/50176]	Loss: 0.4201
Training Epoch: 42 [21504/50176]	Loss: 0.4055
Training Epoch: 42 [22528/50176]	Loss: 0.4369
Training Epoch: 42 [23552/50176]	Loss: 0.4561
Training Epoch: 42 [24576/50176]	Loss: 0.3996
Training Epoch: 42 [25600/50176]	Loss: 0.4939
Training Epoch: 42 [26624/50176]	Loss: 0.4259
Training Epoch: 42 [27648/50176]	Loss: 0.4446
Training Epoch: 42 [28672/50176]	Loss: 0.4364
Training Epoch: 42 [29696/50176]	Loss: 0.4795
Training Epoch: 42 [30720/50176]	Loss: 0.4536
Training Epoch: 42 [31744/50176]	Loss: 0.4312
Training Epoch: 42 [32768/50176]	Loss: 0.4346
Training Epoch: 42 [33792/50176]	Loss: 0.4048
Training Epoch: 42 [34816/50176]	Loss: 0.4657
Training Epoch: 42 [35840/50176]	Loss: 0.5142
Training Epoch: 42 [36864/50176]	Loss: 0.5024
Training Epoch: 42 [37888/50176]	Loss: 0.4715
Training Epoch: 42 [38912/50176]	Loss: 0.4501
Training Epoch: 42 [39936/50176]	Loss: 0.4407
Training Epoch: 42 [40960/50176]	Loss: 0.5408
Training Epoch: 42 [41984/50176]	Loss: 0.4356
Training Epoch: 42 [43008/50176]	Loss: 0.5006
Training Epoch: 42 [44032/50176]	Loss: 0.5027
Training Epoch: 42 [45056/50176]	Loss: 0.4319
Training Epoch: 42 [46080/50176]	Loss: 0.5361
Training Epoch: 42 [47104/50176]	Loss: 0.4918
Training Epoch: 42 [48128/50176]	Loss: 0.4753
Training Epoch: 42 [49152/50176]	Loss: 0.5205
Training Epoch: 42 [50176/50176]	Loss: 0.4971
2022-12-06 17:44:53.648 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:44:53,672 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.83 energy=484.50
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Up to epoch 43: time=2128.76, energy=294738.55, cost=333635.39
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:44:53,673 [ZeusDataLoader(train)] Expected next epoch: time=2176.03, energy=301522.50, cost=341163.85
2022-12-06 12:44:53,674 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0021, Accuracy: 0.5643
2022-12-06 12:44:53,839 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:44:53,840 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:44:53.843 [ZeusMonitor] Monitor started.
2022-12-06 17:44:53.843 [ZeusMonitor] Running indefinitely. 2022-12-06 17:44:53.843 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:44:53.843 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 12:45:37,845 [ZeusDataLoader(train)] train epoch 44 done: time=44.16 energy=6302.70
2022-12-06 12:45:37,849 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.3433
Training Epoch: 43 [2048/50176]	Loss: 0.3880
Training Epoch: 43 [3072/50176]	Loss: 0.4185
Training Epoch: 43 [4096/50176]	Loss: 0.4117
Training Epoch: 43 [5120/50176]	Loss: 0.3927
Training Epoch: 43 [6144/50176]	Loss: 0.4034
Training Epoch: 43 [7168/50176]	Loss: 0.4223
Training Epoch: 43 [8192/50176]	Loss: 0.3847
Training Epoch: 43 [9216/50176]	Loss: 0.4165
Training Epoch: 43 [10240/50176]	Loss: 0.4140
Training Epoch: 43 [11264/50176]	Loss: 0.3946
Training Epoch: 43 [12288/50176]	Loss: 0.4118
Training Epoch: 43 [13312/50176]	Loss: 0.3880
Training Epoch: 43 [14336/50176]	Loss: 0.4319
Training Epoch: 43 [15360/50176]	Loss: 0.4282
Training Epoch: 43 [16384/50176]	Loss: 0.4443
Training Epoch: 43 [17408/50176]	Loss: 0.3914
Training Epoch: 43 [18432/50176]	Loss: 0.3859
Training Epoch: 43 [19456/50176]	Loss: 0.4524
Training Epoch: 43 [20480/50176]	Loss: 0.3864
Training Epoch: 43 [21504/50176]	Loss: 0.4516
Training Epoch: 43 [22528/50176]	Loss: 0.3955
Training Epoch: 43 [23552/50176]	Loss: 0.4041
Training Epoch: 43 [24576/50176]	Loss: 0.4085
Training Epoch: 43 [25600/50176]	Loss: 0.4679
Training Epoch: 43 [26624/50176]	Loss: 0.4143
Training Epoch: 43 [27648/50176]	Loss: 0.4134
Training Epoch: 43 [28672/50176]	Loss: 0.3947
Training Epoch: 43 [29696/50176]	Loss: 0.3869
Training Epoch: 43 [30720/50176]	Loss: 0.3804
Training Epoch: 43 [31744/50176]	Loss: 0.4443
Training Epoch: 43 [32768/50176]	Loss: 0.4297
Training Epoch: 43 [33792/50176]	Loss: 0.3885
Training Epoch: 43 [34816/50176]	Loss: 0.4308
Training Epoch: 43 [35840/50176]	Loss: 0.4376
Training Epoch: 43 [36864/50176]	Loss: 0.4387
Training Epoch: 43 [37888/50176]	Loss: 0.4361
Training Epoch: 43 [38912/50176]	Loss: 0.4417
Training Epoch: 43 [39936/50176]	Loss: 0.4062
Training Epoch: 43 [40960/50176]	Loss: 0.3772
Training Epoch: 43 [41984/50176]	Loss: 0.4035
Training Epoch: 43 [43008/50176]	Loss: 0.3958
Training Epoch: 43 [44032/50176]	Loss: 0.4620
Training Epoch: 43 [45056/50176]	Loss: 0.4521
Training Epoch: 43 [46080/50176]	Loss: 0.4098
Training Epoch: 43 [47104/50176]	Loss: 0.4305
Training Epoch: 43 [48128/50176]	Loss: 0.4672
Training Epoch: 43 [49152/50176]	Loss: 0.4342
Training Epoch: 43 [50176/50176]	Loss: 0.4181
2022-12-06 17:45:41.525 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:45:41,536 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.68 energy=459.63
2022-12-06 12:45:41,536 [ZeusDataLoader(train)] Up to epoch 44: time=2176.60, energy=301500.88, cost=341202.69
2022-12-06 12:45:41,536 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:45:41,537 [ZeusDataLoader(train)] Expected next epoch: time=2223.87, energy=308284.83, cost=348731.14
2022-12-06 12:45:41,537 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0021, Accuracy: 0.5706
2022-12-06 12:45:41,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:45:41,758 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:45:41.759 [ZeusMonitor] Monitor started.
2022-12-06 17:45:41.759 [ZeusMonitor] Running indefinitely. 2022-12-06 17:45:41.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:45:41.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 12:46:26,245 [ZeusDataLoader(train)] train epoch 45 done: time=44.70 energy=6349.69
2022-12-06 12:46:26,248 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.3820
Training Epoch: 44 [2048/50176]	Loss: 0.4101
Training Epoch: 44 [3072/50176]	Loss: 0.3711
Training Epoch: 44 [4096/50176]	Loss: 0.4356
Training Epoch: 44 [5120/50176]	Loss: 0.3859
Training Epoch: 44 [6144/50176]	Loss: 0.3442
Training Epoch: 44 [7168/50176]	Loss: 0.3597
Training Epoch: 44 [8192/50176]	Loss: 0.3290
Training Epoch: 44 [9216/50176]	Loss: 0.4071
Training Epoch: 44 [10240/50176]	Loss: 0.3804
Training Epoch: 44 [11264/50176]	Loss: 0.3650
Training Epoch: 44 [12288/50176]	Loss: 0.3735
Training Epoch: 44 [13312/50176]	Loss: 0.3739
Training Epoch: 44 [14336/50176]	Loss: 0.3802
Training Epoch: 44 [15360/50176]	Loss: 0.3748
Training Epoch: 44 [16384/50176]	Loss: 0.3426
Training Epoch: 44 [17408/50176]	Loss: 0.3821
Training Epoch: 44 [18432/50176]	Loss: 0.3669
Training Epoch: 44 [19456/50176]	Loss: 0.3806
Training Epoch: 44 [20480/50176]	Loss: 0.3802
Training Epoch: 44 [21504/50176]	Loss: 0.3952
Training Epoch: 44 [22528/50176]	Loss: 0.3581
Training Epoch: 44 [23552/50176]	Loss: 0.3939
Training Epoch: 44 [24576/50176]	Loss: 0.3987
Training Epoch: 44 [25600/50176]	Loss: 0.4250
Training Epoch: 44 [26624/50176]	Loss: 0.4016
Training Epoch: 44 [27648/50176]	Loss: 0.3582
Training Epoch: 44 [28672/50176]	Loss: 0.3975
Training Epoch: 44 [29696/50176]	Loss: 0.3710
Training Epoch: 44 [30720/50176]	Loss: 0.3587
Training Epoch: 44 [31744/50176]	Loss: 0.4422
Training Epoch: 44 [32768/50176]	Loss: 0.4015
Training Epoch: 44 [33792/50176]	Loss: 0.3838
Training Epoch: 44 [34816/50176]	Loss: 0.4160
Training Epoch: 44 [35840/50176]	Loss: 0.4174
Training Epoch: 44 [36864/50176]	Loss: 0.4433
Training Epoch: 44 [37888/50176]	Loss: 0.4807
Training Epoch: 44 [38912/50176]	Loss: 0.4024
Training Epoch: 44 [39936/50176]	Loss: 0.4094
Training Epoch: 44 [40960/50176]	Loss: 0.3957
Training Epoch: 44 [41984/50176]	Loss: 0.3850
Training Epoch: 44 [43008/50176]	Loss: 0.3961
Training Epoch: 44 [44032/50176]	Loss: 0.4023
Training Epoch: 44 [45056/50176]	Loss: 0.4617
Training Epoch: 44 [46080/50176]	Loss: 0.4211
Training Epoch: 44 [47104/50176]	Loss: 0.4489
Training Epoch: 44 [48128/50176]	Loss: 0.4686
Training Epoch: 44 [49152/50176]	Loss: 0.4945
Training Epoch: 44 [50176/50176]	Loss: 0.4234
2022-12-06 17:46:29.996 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:46:30,051 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.79 energy=489.31
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Up to epoch 45: time=2225.09, energy=308339.88, cost=348865.45
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:46:30,051 [ZeusDataLoader(train)] Expected next epoch: time=2272.37, energy=315123.83, cost=356393.90
2022-12-06 12:46:30,052 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0020, Accuracy: 0.5781
2022-12-06 12:46:30,261 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:46:30,262 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:46:30.276 [ZeusMonitor] Monitor started.
2022-12-06 17:46:30.276 [ZeusMonitor] Running indefinitely. 2022-12-06 17:46:30.276 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:46:30.276 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 12:47:14,766 [ZeusDataLoader(train)] train epoch 46 done: time=44.71 energy=6338.96
2022-12-06 12:47:14,769 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.3057
Training Epoch: 45 [2048/50176]	Loss: 0.3626
Training Epoch: 45 [3072/50176]	Loss: 0.3147
Training Epoch: 45 [4096/50176]	Loss: 0.3580
Training Epoch: 45 [5120/50176]	Loss: 0.3597
Training Epoch: 45 [6144/50176]	Loss: 0.3395
Training Epoch: 45 [7168/50176]	Loss: 0.3043
Training Epoch: 45 [8192/50176]	Loss: 0.4283
Training Epoch: 45 [9216/50176]	Loss: 0.3530
Training Epoch: 45 [10240/50176]	Loss: 0.3658
Training Epoch: 45 [11264/50176]	Loss: 0.4004
Training Epoch: 45 [12288/50176]	Loss: 0.3655
Training Epoch: 45 [13312/50176]	Loss: 0.3498
Training Epoch: 45 [14336/50176]	Loss: 0.3738
Training Epoch: 45 [15360/50176]	Loss: 0.3585
Training Epoch: 45 [16384/50176]	Loss: 0.3708
Training Epoch: 45 [17408/50176]	Loss: 0.3673
Training Epoch: 45 [18432/50176]	Loss: 0.3940
Training Epoch: 45 [19456/50176]	Loss: 0.3524
Training Epoch: 45 [20480/50176]	Loss: 0.3754
Training Epoch: 45 [21504/50176]	Loss: 0.3522
Training Epoch: 45 [22528/50176]	Loss: 0.3614
Training Epoch: 45 [23552/50176]	Loss: 0.3390
Training Epoch: 45 [24576/50176]	Loss: 0.3608
Training Epoch: 45 [25600/50176]	Loss: 0.4176
Training Epoch: 45 [26624/50176]	Loss: 0.3903
Training Epoch: 45 [27648/50176]	Loss: 0.3766
Training Epoch: 45 [28672/50176]	Loss: 0.3706
Training Epoch: 45 [29696/50176]	Loss: 0.3703
Training Epoch: 45 [30720/50176]	Loss: 0.3822
Training Epoch: 45 [31744/50176]	Loss: 0.3333
Training Epoch: 45 [32768/50176]	Loss: 0.4157
Training Epoch: 45 [33792/50176]	Loss: 0.3947
Training Epoch: 45 [34816/50176]	Loss: 0.3924
Training Epoch: 45 [35840/50176]	Loss: 0.4240
Training Epoch: 45 [36864/50176]	Loss: 0.3862
Training Epoch: 45 [37888/50176]	Loss: 0.4048
Training Epoch: 45 [38912/50176]	Loss: 0.4235
Training Epoch: 45 [39936/50176]	Loss: 0.4154
Training Epoch: 45 [40960/50176]	Loss: 0.4279
Training Epoch: 45 [41984/50176]	Loss: 0.3965
Training Epoch: 45 [43008/50176]	Loss: 0.4079
Training Epoch: 45 [44032/50176]	Loss: 0.4415
Training Epoch: 45 [45056/50176]	Loss: 0.4525
Training Epoch: 45 [46080/50176]	Loss: 0.4354
Training Epoch: 45 [47104/50176]	Loss: 0.4204
Training Epoch: 45 [48128/50176]	Loss: 0.3623
Training Epoch: 45 [49152/50176]	Loss: 0.4154
Training Epoch: 45 [50176/50176]	Loss: 0.4581
2022-12-06 17:47:18.480 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:47:18,509 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.73 energy=486.22
2022-12-06 12:47:18,509 [ZeusDataLoader(train)] Up to epoch 46: time=2273.53, energy=315165.06, cost=356516.32
2022-12-06 12:47:18,509 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:47:18,510 [ZeusDataLoader(train)] Expected next epoch: time=2320.80, energy=321949.01, cost=364044.77
2022-12-06 12:47:18,510 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0022, Accuracy: 0.5574
2022-12-06 12:47:18,718 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:47:18,719 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:47:18.737 [ZeusMonitor] Monitor started.
2022-12-06 17:47:18.737 [ZeusMonitor] Running indefinitely. 2022-12-06 17:47:18.737 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:47:18.737 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 12:48:02,903 [ZeusDataLoader(train)] train epoch 47 done: time=44.38 energy=6322.79
2022-12-06 12:48:02,906 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.3852
Training Epoch: 46 [2048/50176]	Loss: 0.3924
Training Epoch: 46 [3072/50176]	Loss: 0.3394
Training Epoch: 46 [4096/50176]	Loss: 0.3348
Training Epoch: 46 [5120/50176]	Loss: 0.3616
Training Epoch: 46 [6144/50176]	Loss: 0.3820
Training Epoch: 46 [7168/50176]	Loss: 0.3755
Training Epoch: 46 [8192/50176]	Loss: 0.3253
Training Epoch: 46 [9216/50176]	Loss: 0.3203
Training Epoch: 46 [10240/50176]	Loss: 0.3593
Training Epoch: 46 [11264/50176]	Loss: 0.3714
Training Epoch: 46 [12288/50176]	Loss: 0.3576
Training Epoch: 46 [13312/50176]	Loss: 0.3655
Training Epoch: 46 [14336/50176]	Loss: 0.4192
Training Epoch: 46 [15360/50176]	Loss: 0.3301
Training Epoch: 46 [16384/50176]	Loss: 0.3288
Training Epoch: 46 [17408/50176]	Loss: 0.3915
Training Epoch: 46 [18432/50176]	Loss: 0.3575
Training Epoch: 46 [19456/50176]	Loss: 0.3674
Training Epoch: 46 [20480/50176]	Loss: 0.3228
Training Epoch: 46 [21504/50176]	Loss: 0.3870
Training Epoch: 46 [22528/50176]	Loss: 0.3442
Training Epoch: 46 [23552/50176]	Loss: 0.3969
Training Epoch: 46 [24576/50176]	Loss: 0.4090
Training Epoch: 46 [25600/50176]	Loss: 0.3801
Training Epoch: 46 [26624/50176]	Loss: 0.3664
Training Epoch: 46 [27648/50176]	Loss: 0.3973
Training Epoch: 46 [28672/50176]	Loss: 0.3381
Training Epoch: 46 [29696/50176]	Loss: 0.3831
Training Epoch: 46 [30720/50176]	Loss: 0.3766
Training Epoch: 46 [31744/50176]	Loss: 0.4004
Training Epoch: 46 [32768/50176]	Loss: 0.3599
Training Epoch: 46 [33792/50176]	Loss: 0.3914
Training Epoch: 46 [34816/50176]	Loss: 0.3896
Training Epoch: 46 [35840/50176]	Loss: 0.3486
Training Epoch: 46 [36864/50176]	Loss: 0.4055
Training Epoch: 46 [37888/50176]	Loss: 0.3956
Training Epoch: 46 [38912/50176]	Loss: 0.4164
Training Epoch: 46 [39936/50176]	Loss: 0.4105
Training Epoch: 46 [40960/50176]	Loss: 0.4001
Training Epoch: 46 [41984/50176]	Loss: 0.3812
Training Epoch: 46 [43008/50176]	Loss: 0.3160
Training Epoch: 46 [44032/50176]	Loss: 0.3597
Training Epoch: 46 [45056/50176]	Loss: 0.4031
Training Epoch: 46 [46080/50176]	Loss: 0.3776
Training Epoch: 46 [47104/50176]	Loss: 0.3998
Training Epoch: 46 [48128/50176]	Loss: 0.3922
Training Epoch: 46 [49152/50176]	Loss: 0.3659
Training Epoch: 46 [50176/50176]	Loss: 0.4041
2022-12-06 17:48:06.661 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:48:06,698 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.78 energy=479.83
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Up to epoch 47: time=2321.70, energy=321967.68, cost=364132.33
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:48:06,698 [ZeusDataLoader(train)] Expected next epoch: time=2368.97, energy=328751.63, cost=371660.78
2022-12-06 12:48:06,699 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0021, Accuracy: 0.5827
2022-12-06 12:48:06,921 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:48:06,921 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:48:06.923 [ZeusMonitor] Monitor started.
2022-12-06 17:48:06.923 [ZeusMonitor] Running indefinitely. 2022-12-06 17:48:06.923 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:48:06.923 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 12:48:51,396 [ZeusDataLoader(train)] train epoch 48 done: time=44.69 energy=6339.79
2022-12-06 12:48:51,400 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.3412
Training Epoch: 47 [2048/50176]	Loss: 0.3167
Training Epoch: 47 [3072/50176]	Loss: 0.3312
Training Epoch: 47 [4096/50176]	Loss: 0.2801
Training Epoch: 47 [5120/50176]	Loss: 0.3092
Training Epoch: 47 [6144/50176]	Loss: 0.3121
Training Epoch: 47 [7168/50176]	Loss: 0.3343
Training Epoch: 47 [8192/50176]	Loss: 0.3180
Training Epoch: 47 [9216/50176]	Loss: 0.3246
Training Epoch: 47 [10240/50176]	Loss: 0.3422
Training Epoch: 47 [11264/50176]	Loss: 0.3360
Training Epoch: 47 [12288/50176]	Loss: 0.3288
Training Epoch: 47 [13312/50176]	Loss: 0.3180
Training Epoch: 47 [14336/50176]	Loss: 0.3430
Training Epoch: 47 [15360/50176]	Loss: 0.3135
Training Epoch: 47 [16384/50176]	Loss: 0.3595
Training Epoch: 47 [17408/50176]	Loss: 0.3273
Training Epoch: 47 [18432/50176]	Loss: 0.3204
Training Epoch: 47 [19456/50176]	Loss: 0.3645
Training Epoch: 47 [20480/50176]	Loss: 0.3453
Training Epoch: 47 [21504/50176]	Loss: 0.3360
Training Epoch: 47 [22528/50176]	Loss: 0.3036
Training Epoch: 47 [23552/50176]	Loss: 0.3276
Training Epoch: 47 [24576/50176]	Loss: 0.3387
Training Epoch: 47 [25600/50176]	Loss: 0.3356
Training Epoch: 47 [26624/50176]	Loss: 0.3567
Training Epoch: 47 [27648/50176]	Loss: 0.3314
Training Epoch: 47 [28672/50176]	Loss: 0.3525
Training Epoch: 47 [29696/50176]	Loss: 0.2941
Training Epoch: 47 [30720/50176]	Loss: 0.3625
Training Epoch: 47 [31744/50176]	Loss: 0.3622
Training Epoch: 47 [32768/50176]	Loss: 0.3462
Training Epoch: 47 [33792/50176]	Loss: 0.3914
Training Epoch: 47 [34816/50176]	Loss: 0.3846
Training Epoch: 47 [35840/50176]	Loss: 0.3597
Training Epoch: 47 [36864/50176]	Loss: 0.3531
Training Epoch: 47 [37888/50176]	Loss: 0.3770
Training Epoch: 47 [38912/50176]	Loss: 0.3572
Training Epoch: 47 [39936/50176]	Loss: 0.4006
Training Epoch: 47 [40960/50176]	Loss: 0.3551
Training Epoch: 47 [41984/50176]	Loss: 0.3716
Training Epoch: 47 [43008/50176]	Loss: 0.4174
Training Epoch: 47 [44032/50176]	Loss: 0.3952
Training Epoch: 47 [45056/50176]	Loss: 0.3697
Training Epoch: 47 [46080/50176]	Loss: 0.3976
Training Epoch: 47 [47104/50176]	Loss: 0.3214
Training Epoch: 47 [48128/50176]	Loss: 0.4032
Training Epoch: 47 [49152/50176]	Loss: 0.3644
Training Epoch: 47 [50176/50176]	Loss: 0.3815
2022-12-06 17:48:55.277 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:48:55,319 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.91 energy=492.60
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Up to epoch 48: time=2370.30, energy=328800.07, cost=371801.05
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:48:55,319 [ZeusDataLoader(train)] Expected next epoch: time=2417.57, energy=335584.02, cost=379329.51
2022-12-06 12:48:55,320 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0020, Accuracy: 0.5804
2022-12-06 12:48:55,493 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:48:55,494 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:48:55.495 [ZeusMonitor] Monitor started.
2022-12-06 17:48:55.496 [ZeusMonitor] Running indefinitely. 2022-12-06 17:48:55.496 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:48:55.496 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 12:49:40,074 [ZeusDataLoader(train)] train epoch 49 done: time=44.75 energy=6341.00
2022-12-06 12:49:40,077 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.3158
Training Epoch: 48 [2048/50176]	Loss: 0.3088
Training Epoch: 48 [3072/50176]	Loss: 0.2821
Training Epoch: 48 [4096/50176]	Loss: 0.3521
Training Epoch: 48 [5120/50176]	Loss: 0.2843
Training Epoch: 48 [6144/50176]	Loss: 0.2871
Training Epoch: 48 [7168/50176]	Loss: 0.3043
Training Epoch: 48 [8192/50176]	Loss: 0.2800
Training Epoch: 48 [9216/50176]	Loss: 0.3092
Training Epoch: 48 [10240/50176]	Loss: 0.3231
Training Epoch: 48 [11264/50176]	Loss: 0.2831
Training Epoch: 48 [12288/50176]	Loss: 0.3672
Training Epoch: 48 [13312/50176]	Loss: 0.3107
Training Epoch: 48 [14336/50176]	Loss: 0.3208
Training Epoch: 48 [15360/50176]	Loss: 0.3119
Training Epoch: 48 [16384/50176]	Loss: 0.2972
Training Epoch: 48 [17408/50176]	Loss: 0.2699
Training Epoch: 48 [18432/50176]	Loss: 0.3075
Training Epoch: 48 [19456/50176]	Loss: 0.3183
Training Epoch: 48 [20480/50176]	Loss: 0.3088
Training Epoch: 48 [21504/50176]	Loss: 0.3242
Training Epoch: 48 [22528/50176]	Loss: 0.3123
Training Epoch: 48 [23552/50176]	Loss: 0.3358
Training Epoch: 48 [24576/50176]	Loss: 0.3078
Training Epoch: 48 [25600/50176]	Loss: 0.3085
Training Epoch: 48 [26624/50176]	Loss: 0.3115
Training Epoch: 48 [27648/50176]	Loss: 0.3367
Training Epoch: 48 [28672/50176]	Loss: 0.2892
Training Epoch: 48 [29696/50176]	Loss: 0.3064
Training Epoch: 48 [30720/50176]	Loss: 0.2806
Training Epoch: 48 [31744/50176]	Loss: 0.3534
Training Epoch: 48 [32768/50176]	Loss: 0.3522
Training Epoch: 48 [33792/50176]	Loss: 0.3787
Training Epoch: 48 [34816/50176]	Loss: 0.3325
Training Epoch: 48 [35840/50176]	Loss: 0.3639
Training Epoch: 48 [36864/50176]	Loss: 0.3387
Training Epoch: 48 [37888/50176]	Loss: 0.3288
Training Epoch: 48 [38912/50176]	Loss: 0.3963
Training Epoch: 48 [39936/50176]	Loss: 0.3174
Training Epoch: 48 [40960/50176]	Loss: 0.3515
Training Epoch: 48 [41984/50176]	Loss: 0.3485
Training Epoch: 48 [43008/50176]	Loss: 0.3968
Training Epoch: 48 [44032/50176]	Loss: 0.3780
Training Epoch: 48 [45056/50176]	Loss: 0.3375
Training Epoch: 48 [46080/50176]	Loss: 0.3777
Training Epoch: 48 [47104/50176]	Loss: 0.3826
Training Epoch: 48 [48128/50176]	Loss: 0.3710
Training Epoch: 48 [49152/50176]	Loss: 0.4010
Training Epoch: 48 [50176/50176]	Loss: 0.3519
2022-12-06 17:49:43.781 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:49:43,794 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.71 energy=476.47
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Up to epoch 49: time=2418.75, energy=335617.54, cost=379449.58
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:49:43,795 [ZeusDataLoader(train)] Expected next epoch: time=2466.03, energy=342401.49, cost=386978.04
2022-12-06 12:49:43,796 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0020, Accuracy: 0.5890
2022-12-06 12:49:44,017 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:49:44,018 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:49:44.028 [ZeusMonitor] Monitor started.
2022-12-06 17:49:44.028 [ZeusMonitor] Running indefinitely. 2022-12-06 17:49:44.028 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:49:44.028 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 12:50:28,513 [ZeusDataLoader(train)] train epoch 50 done: time=44.71 energy=6343.00
2022-12-06 12:50:28,516 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 0.2724
Training Epoch: 49 [2048/50176]	Loss: 0.2926
Training Epoch: 49 [3072/50176]	Loss: 0.3054
Training Epoch: 49 [4096/50176]	Loss: 0.3062
Training Epoch: 49 [5120/50176]	Loss: 0.3014
Training Epoch: 49 [6144/50176]	Loss: 0.3103
Training Epoch: 49 [7168/50176]	Loss: 0.2805
Training Epoch: 49 [8192/50176]	Loss: 0.3458
Training Epoch: 49 [9216/50176]	Loss: 0.2927
Training Epoch: 49 [10240/50176]	Loss: 0.2956
Training Epoch: 49 [11264/50176]	Loss: 0.3248
Training Epoch: 49 [12288/50176]	Loss: 0.3346
Training Epoch: 49 [13312/50176]	Loss: 0.3193
Training Epoch: 49 [14336/50176]	Loss: 0.3004
Training Epoch: 49 [15360/50176]	Loss: 0.3175
Training Epoch: 49 [16384/50176]	Loss: 0.3002
Training Epoch: 49 [17408/50176]	Loss: 0.2900
Training Epoch: 49 [18432/50176]	Loss: 0.3314
Training Epoch: 49 [19456/50176]	Loss: 0.3131
Training Epoch: 49 [20480/50176]	Loss: 0.2923
Training Epoch: 49 [21504/50176]	Loss: 0.2837
Training Epoch: 49 [22528/50176]	Loss: 0.3334
Training Epoch: 49 [23552/50176]	Loss: 0.3014
Training Epoch: 49 [24576/50176]	Loss: 0.2827
Training Epoch: 49 [25600/50176]	Loss: 0.3145
Training Epoch: 49 [26624/50176]	Loss: 0.3174
Training Epoch: 49 [27648/50176]	Loss: 0.3360
Training Epoch: 49 [28672/50176]	Loss: 0.2877
Training Epoch: 49 [29696/50176]	Loss: 0.2943
Training Epoch: 49 [30720/50176]	Loss: 0.2836
Training Epoch: 49 [31744/50176]	Loss: 0.3353
Training Epoch: 49 [32768/50176]	Loss: 0.3327
Training Epoch: 49 [33792/50176]	Loss: 0.3329
Training Epoch: 49 [34816/50176]	Loss: 0.3147
Training Epoch: 49 [35840/50176]	Loss: 0.3081
Training Epoch: 49 [36864/50176]	Loss: 0.3183
Training Epoch: 49 [37888/50176]	Loss: 0.3374
Training Epoch: 49 [38912/50176]	Loss: 0.3874
Training Epoch: 49 [39936/50176]	Loss: 0.3417
Training Epoch: 49 [40960/50176]	Loss: 0.2843
Training Epoch: 49 [41984/50176]	Loss: 0.3549
Training Epoch: 49 [43008/50176]	Loss: 0.3500
Training Epoch: 49 [44032/50176]	Loss: 0.3099
Training Epoch: 49 [45056/50176]	Loss: 0.3337
Training Epoch: 49 [46080/50176]	Loss: 0.3506
Training Epoch: 49 [47104/50176]	Loss: 0.3692
Training Epoch: 49 [48128/50176]	Loss: 0.3226
Training Epoch: 49 [49152/50176]	Loss: 0.3369
Training Epoch: 49 [50176/50176]	Loss: 0.2967
2022-12-06 17:50:32.348 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:50:32,364 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.84 energy=481.73
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Up to epoch 50: time=2467.30, energy=342442.27, cost=387110.03
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:50:32,365 [ZeusDataLoader(train)] Expected next epoch: time=2514.58, energy=349226.22, cost=394638.48
2022-12-06 12:50:32,366 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0022, Accuracy: 0.5766
2022-12-06 12:50:32,577 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:50:32,578 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:50:32.592 [ZeusMonitor] Monitor started.
2022-12-06 17:50:32.592 [ZeusMonitor] Running indefinitely. 2022-12-06 17:50:32.592 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:50:32.592 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 12:51:16,843 [ZeusDataLoader(train)] train epoch 51 done: time=44.47 energy=6333.64
2022-12-06 12:51:16,847 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 0.2613
Training Epoch: 50 [2048/50176]	Loss: 0.2468
Training Epoch: 50 [3072/50176]	Loss: 0.2865
Training Epoch: 50 [4096/50176]	Loss: 0.3008
Training Epoch: 50 [5120/50176]	Loss: 0.3019
Training Epoch: 50 [6144/50176]	Loss: 0.2509
Training Epoch: 50 [7168/50176]	Loss: 0.2939
Training Epoch: 50 [8192/50176]	Loss: 0.3321
Training Epoch: 50 [9216/50176]	Loss: 0.2860
Training Epoch: 50 [10240/50176]	Loss: 0.2843
Training Epoch: 50 [11264/50176]	Loss: 0.2547
Training Epoch: 50 [12288/50176]	Loss: 0.2573
Training Epoch: 50 [13312/50176]	Loss: 0.2748
Training Epoch: 50 [14336/50176]	Loss: 0.2664
Training Epoch: 50 [15360/50176]	Loss: 0.2627
Training Epoch: 50 [16384/50176]	Loss: 0.3010
Training Epoch: 50 [17408/50176]	Loss: 0.2673
Training Epoch: 50 [18432/50176]	Loss: 0.2859
Training Epoch: 50 [19456/50176]	Loss: 0.2722
Training Epoch: 50 [20480/50176]	Loss: 0.3174
Training Epoch: 50 [21504/50176]	Loss: 0.2933
Training Epoch: 50 [22528/50176]	Loss: 0.2771
Training Epoch: 50 [23552/50176]	Loss: 0.2794
Training Epoch: 50 [24576/50176]	Loss: 0.2953
Training Epoch: 50 [25600/50176]	Loss: 0.2951
Training Epoch: 50 [26624/50176]	Loss: 0.2788
Training Epoch: 50 [27648/50176]	Loss: 0.3164
Training Epoch: 50 [28672/50176]	Loss: 0.2937
Training Epoch: 50 [29696/50176]	Loss: 0.3115
Training Epoch: 50 [30720/50176]	Loss: 0.3053
Training Epoch: 50 [31744/50176]	Loss: 0.2938
Training Epoch: 50 [32768/50176]	Loss: 0.3093
Training Epoch: 50 [33792/50176]	Loss: 0.2675
Training Epoch: 50 [34816/50176]	Loss: 0.2972
Training Epoch: 50 [35840/50176]	Loss: 0.3267
Training Epoch: 50 [36864/50176]	Loss: 0.3173
Training Epoch: 50 [37888/50176]	Loss: 0.2799
Training Epoch: 50 [38912/50176]	Loss: 0.3272
Training Epoch: 50 [39936/50176]	Loss: 0.3106
Training Epoch: 50 [40960/50176]	Loss: 0.3533
Training Epoch: 50 [41984/50176]	Loss: 0.2750
Training Epoch: 50 [43008/50176]	Loss: 0.3527
Training Epoch: 50 [44032/50176]	Loss: 0.3080
Training Epoch: 50 [45056/50176]	Loss: 0.3446
Training Epoch: 50 [46080/50176]	Loss: 0.3519
Training Epoch: 50 [47104/50176]	Loss: 0.3682
Training Epoch: 50 [48128/50176]	Loss: 0.3421
Training Epoch: 50 [49152/50176]	Loss: 0.2935
Training Epoch: 50 [50176/50176]	Loss: 0.3058
2022-12-06 17:51:20.583 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:51:20,602 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.75 energy=472.05
2022-12-06 12:51:20,602 [ZeusDataLoader(train)] Up to epoch 51: time=2515.52, energy=349247.96, cost=394731.93
2022-12-06 12:51:20,603 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:51:20,603 [ZeusDataLoader(train)] Expected next epoch: time=2562.79, energy=356031.91, cost=402260.38
2022-12-06 12:51:20,604 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0023, Accuracy: 0.5646
2022-12-06 12:51:20,817 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:51:20,818 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:51:20.820 [ZeusMonitor] Monitor started.
2022-12-06 17:51:20.820 [ZeusMonitor] Running indefinitely. 2022-12-06 17:51:20.820 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:51:20.820 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 12:52:05,272 [ZeusDataLoader(train)] train epoch 52 done: time=44.66 energy=6349.93
2022-12-06 12:52:05,275 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 0.2750
Training Epoch: 51 [2048/50176]	Loss: 0.3083
Training Epoch: 51 [3072/50176]	Loss: 0.2582
Training Epoch: 51 [4096/50176]	Loss: 0.2662
Training Epoch: 51 [5120/50176]	Loss: 0.2714
Training Epoch: 51 [6144/50176]	Loss: 0.2569
Training Epoch: 51 [7168/50176]	Loss: 0.2545
Training Epoch: 51 [8192/50176]	Loss: 0.2635
Training Epoch: 51 [9216/50176]	Loss: 0.2674
Training Epoch: 51 [10240/50176]	Loss: 0.2503
Training Epoch: 51 [11264/50176]	Loss: 0.2905
Training Epoch: 51 [12288/50176]	Loss: 0.2420
Training Epoch: 51 [13312/50176]	Loss: 0.2484
Training Epoch: 51 [14336/50176]	Loss: 0.2169
Training Epoch: 51 [15360/50176]	Loss: 0.3336
Training Epoch: 51 [16384/50176]	Loss: 0.3356
Training Epoch: 51 [17408/50176]	Loss: 0.3072
Training Epoch: 51 [18432/50176]	Loss: 0.2938
Training Epoch: 51 [19456/50176]	Loss: 0.2849
Training Epoch: 51 [20480/50176]	Loss: 0.2665
Training Epoch: 51 [21504/50176]	Loss: 0.2934
Training Epoch: 51 [22528/50176]	Loss: 0.3158
Training Epoch: 51 [23552/50176]	Loss: 0.2824
Training Epoch: 51 [24576/50176]	Loss: 0.3001
Training Epoch: 51 [25600/50176]	Loss: 0.3126
Training Epoch: 51 [26624/50176]	Loss: 0.3092
Training Epoch: 51 [27648/50176]	Loss: 0.3148
Training Epoch: 51 [28672/50176]	Loss: 0.2799
Training Epoch: 51 [29696/50176]	Loss: 0.3061
Training Epoch: 51 [30720/50176]	Loss: 0.2733
Training Epoch: 51 [31744/50176]	Loss: 0.2722
Training Epoch: 51 [32768/50176]	Loss: 0.2925
Training Epoch: 51 [33792/50176]	Loss: 0.3266
Training Epoch: 51 [34816/50176]	Loss: 0.2771
Training Epoch: 51 [35840/50176]	Loss: 0.2871
Training Epoch: 51 [36864/50176]	Loss: 0.2840
Training Epoch: 51 [37888/50176]	Loss: 0.3344
Training Epoch: 51 [38912/50176]	Loss: 0.2988
Training Epoch: 51 [39936/50176]	Loss: 0.2841
Training Epoch: 51 [40960/50176]	Loss: 0.3212
Training Epoch: 51 [41984/50176]	Loss: 0.3402
Training Epoch: 51 [43008/50176]	Loss: 0.3053
Training Epoch: 51 [44032/50176]	Loss: 0.2822
Training Epoch: 51 [45056/50176]	Loss: 0.3122
Training Epoch: 51 [46080/50176]	Loss: 0.3508
Training Epoch: 51 [47104/50176]	Loss: 0.3178
Training Epoch: 51 [48128/50176]	Loss: 0.3155
Training Epoch: 51 [49152/50176]	Loss: 0.3530
Training Epoch: 51 [50176/50176]	Loss: 0.3734
2022-12-06 17:52:09.023 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:52:09,050 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.77 energy=471.67
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Up to epoch 52: time=2563.95, energy=356069.55, cost=402380.12
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:52:09,051 [ZeusDataLoader(train)] Expected next epoch: time=2611.22, energy=362853.50, cost=409908.57
2022-12-06 12:52:09,052 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0023, Accuracy: 0.5745
2022-12-06 12:52:09,277 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:52:09,277 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:52:09.279 [ZeusMonitor] Monitor started.
2022-12-06 17:52:09.279 [ZeusMonitor] Running indefinitely. 2022-12-06 17:52:09.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:52:09.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 12:52:53,721 [ZeusDataLoader(train)] train epoch 53 done: time=44.66 energy=6341.47
2022-12-06 12:52:53,724 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 0.2395
Training Epoch: 52 [2048/50176]	Loss: 0.2005
Training Epoch: 52 [3072/50176]	Loss: 0.2829
Training Epoch: 52 [4096/50176]	Loss: 0.2271
Training Epoch: 52 [5120/50176]	Loss: 0.2630
Training Epoch: 52 [6144/50176]	Loss: 0.2402
Training Epoch: 52 [7168/50176]	Loss: 0.2196
Training Epoch: 52 [8192/50176]	Loss: 0.2378
Training Epoch: 52 [9216/50176]	Loss: 0.2171
Training Epoch: 52 [10240/50176]	Loss: 0.2589
Training Epoch: 52 [11264/50176]	Loss: 0.2609
Training Epoch: 52 [12288/50176]	Loss: 0.2347
Training Epoch: 52 [13312/50176]	Loss: 0.2287
Training Epoch: 52 [14336/50176]	Loss: 0.2449
Training Epoch: 52 [15360/50176]	Loss: 0.2638
Training Epoch: 52 [16384/50176]	Loss: 0.3007
Training Epoch: 52 [17408/50176]	Loss: 0.2295
Training Epoch: 52 [18432/50176]	Loss: 0.2665
Training Epoch: 52 [19456/50176]	Loss: 0.2785
Training Epoch: 52 [20480/50176]	Loss: 0.2838
Training Epoch: 52 [21504/50176]	Loss: 0.2903
Training Epoch: 52 [22528/50176]	Loss: 0.2929
Training Epoch: 52 [23552/50176]	Loss: 0.2545
Training Epoch: 52 [24576/50176]	Loss: 0.3094
Training Epoch: 52 [25600/50176]	Loss: 0.2768
Training Epoch: 52 [26624/50176]	Loss: 0.2356
Training Epoch: 52 [27648/50176]	Loss: 0.2896
Training Epoch: 52 [28672/50176]	Loss: 0.2704
Training Epoch: 52 [29696/50176]	Loss: 0.2760
Training Epoch: 52 [30720/50176]	Loss: 0.2428
Training Epoch: 52 [31744/50176]	Loss: 0.2727
Training Epoch: 52 [32768/50176]	Loss: 0.3150
Training Epoch: 52 [33792/50176]	Loss: 0.2891
Training Epoch: 52 [34816/50176]	Loss: 0.2525
Training Epoch: 52 [35840/50176]	Loss: 0.2785
Training Epoch: 52 [36864/50176]	Loss: 0.2942
Training Epoch: 52 [37888/50176]	Loss: 0.3149
Training Epoch: 52 [38912/50176]	Loss: 0.2677
Training Epoch: 52 [39936/50176]	Loss: 0.2788
Training Epoch: 52 [40960/50176]	Loss: 0.2803
Training Epoch: 52 [41984/50176]	Loss: 0.2524
Training Epoch: 52 [43008/50176]	Loss: 0.2818
Training Epoch: 52 [44032/50176]	Loss: 0.2882
Training Epoch: 52 [45056/50176]	Loss: 0.2472
Training Epoch: 52 [46080/50176]	Loss: 0.3361
Training Epoch: 52 [47104/50176]	Loss: 0.2738
Training Epoch: 52 [48128/50176]	Loss: 0.2717
Training Epoch: 52 [49152/50176]	Loss: 0.2751
Training Epoch: 52 [50176/50176]	Loss: 0.2646
2022-12-06 17:52:57.437 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:52:57,471 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.74 energy=474.03
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Up to epoch 53: time=2612.35, energy=362885.05, cost=410022.92
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:52:57,472 [ZeusDataLoader(train)] Expected next epoch: time=2659.62, energy=369669.00, cost=417551.38
2022-12-06 12:52:57,473 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0021, Accuracy: 0.5983
2022-12-06 12:52:57,681 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:52:57,682 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:52:57.696 [ZeusMonitor] Monitor started.
2022-12-06 17:52:57.696 [ZeusMonitor] Running indefinitely. 2022-12-06 17:52:57.696 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:52:57.696 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 12:53:41,985 [ZeusDataLoader(train)] train epoch 54 done: time=44.50 energy=6331.81
2022-12-06 12:53:41,988 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 0.2127
Training Epoch: 53 [2048/50176]	Loss: 0.2326
Training Epoch: 53 [3072/50176]	Loss: 0.2419
Training Epoch: 53 [4096/50176]	Loss: 0.2272
Training Epoch: 53 [5120/50176]	Loss: 0.2399
Training Epoch: 53 [6144/50176]	Loss: 0.2293
Training Epoch: 53 [7168/50176]	Loss: 0.2450
Training Epoch: 53 [8192/50176]	Loss: 0.2385
Training Epoch: 53 [9216/50176]	Loss: 0.2381
Training Epoch: 53 [10240/50176]	Loss: 0.2356
Training Epoch: 53 [11264/50176]	Loss: 0.2130
Training Epoch: 53 [12288/50176]	Loss: 0.2632
Training Epoch: 53 [13312/50176]	Loss: 0.2527
Training Epoch: 53 [14336/50176]	Loss: 0.2333
Training Epoch: 53 [15360/50176]	Loss: 0.2409
Training Epoch: 53 [16384/50176]	Loss: 0.2373
Training Epoch: 53 [17408/50176]	Loss: 0.2442
Training Epoch: 53 [18432/50176]	Loss: 0.2421
Training Epoch: 53 [19456/50176]	Loss: 0.2606
Training Epoch: 53 [20480/50176]	Loss: 0.2304
Training Epoch: 53 [21504/50176]	Loss: 0.2490
Training Epoch: 53 [22528/50176]	Loss: 0.2316
Training Epoch: 53 [23552/50176]	Loss: 0.2592
Training Epoch: 53 [24576/50176]	Loss: 0.2856
Training Epoch: 53 [25600/50176]	Loss: 0.2324
Training Epoch: 53 [26624/50176]	Loss: 0.2447
Training Epoch: 53 [27648/50176]	Loss: 0.2992
Training Epoch: 53 [28672/50176]	Loss: 0.2834
Training Epoch: 53 [29696/50176]	Loss: 0.2547
Training Epoch: 53 [30720/50176]	Loss: 0.2576
Training Epoch: 53 [31744/50176]	Loss: 0.2418
Training Epoch: 53 [32768/50176]	Loss: 0.2665
Training Epoch: 53 [33792/50176]	Loss: 0.2311
Training Epoch: 53 [34816/50176]	Loss: 0.2738
Training Epoch: 53 [35840/50176]	Loss: 0.2618
Training Epoch: 53 [36864/50176]	Loss: 0.2706
Training Epoch: 53 [37888/50176]	Loss: 0.2588
Training Epoch: 53 [38912/50176]	Loss: 0.2813
Training Epoch: 53 [39936/50176]	Loss: 0.2864
Training Epoch: 53 [40960/50176]	Loss: 0.2525
Training Epoch: 53 [41984/50176]	Loss: 0.2663
Training Epoch: 53 [43008/50176]	Loss: 0.2735
Training Epoch: 53 [44032/50176]	Loss: 0.3044
Training Epoch: 53 [45056/50176]	Loss: 0.3515
Training Epoch: 53 [46080/50176]	Loss: 0.2879
Training Epoch: 53 [47104/50176]	Loss: 0.2968
Training Epoch: 53 [48128/50176]	Loss: 0.2378
Training Epoch: 53 [49152/50176]	Loss: 0.3426
Training Epoch: 53 [50176/50176]	Loss: 0.3224
2022-12-06 17:53:45.677 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:53:45,699 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.70 energy=476.19
2022-12-06 12:53:45,699 [ZeusDataLoader(train)] Up to epoch 54: time=2660.55, energy=369693.05, cost=417645.00
2022-12-06 12:53:45,699 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:53:45,700 [ZeusDataLoader(train)] Expected next epoch: time=2707.83, energy=376477.01, cost=425173.46
2022-12-06 12:53:45,700 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0022, Accuracy: 0.5740
2022-12-06 12:53:45,912 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:53:45,913 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:53:45.914 [ZeusMonitor] Monitor started.
2022-12-06 17:53:45.914 [ZeusMonitor] Running indefinitely. 2022-12-06 17:53:45.915 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:53:45.915 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 12:54:30,162 [ZeusDataLoader(train)] train epoch 55 done: time=44.45 energy=6336.00
2022-12-06 12:54:30,165 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 0.2334
Training Epoch: 54 [2048/50176]	Loss: 0.2860
Training Epoch: 54 [3072/50176]	Loss: 0.2210
Training Epoch: 54 [4096/50176]	Loss: 0.2162
Training Epoch: 54 [5120/50176]	Loss: 0.2084
Training Epoch: 54 [6144/50176]	Loss: 0.2285
Training Epoch: 54 [7168/50176]	Loss: 0.2407
Training Epoch: 54 [8192/50176]	Loss: 0.2382
Training Epoch: 54 [9216/50176]	Loss: 0.2422
Training Epoch: 54 [10240/50176]	Loss: 0.2116
Training Epoch: 54 [11264/50176]	Loss: 0.2433
Training Epoch: 54 [12288/50176]	Loss: 0.2358
Training Epoch: 54 [13312/50176]	Loss: 0.2659
Training Epoch: 54 [14336/50176]	Loss: 0.2045
Training Epoch: 54 [15360/50176]	Loss: 0.2760
Training Epoch: 54 [16384/50176]	Loss: 0.2301
Training Epoch: 54 [17408/50176]	Loss: 0.2641
Training Epoch: 54 [18432/50176]	Loss: 0.2406
Training Epoch: 54 [19456/50176]	Loss: 0.2508
Training Epoch: 54 [20480/50176]	Loss: 0.2236
Training Epoch: 54 [21504/50176]	Loss: 0.2118
Training Epoch: 54 [22528/50176]	Loss: 0.2603
Training Epoch: 54 [23552/50176]	Loss: 0.2353
Training Epoch: 54 [24576/50176]	Loss: 0.2510
Training Epoch: 54 [25600/50176]	Loss: 0.2752
Training Epoch: 54 [26624/50176]	Loss: 0.2581
Training Epoch: 54 [27648/50176]	Loss: 0.2632
Training Epoch: 54 [28672/50176]	Loss: 0.2573
Training Epoch: 54 [29696/50176]	Loss: 0.2367
Training Epoch: 54 [30720/50176]	Loss: 0.2230
Training Epoch: 54 [31744/50176]	Loss: 0.2671
Training Epoch: 54 [32768/50176]	Loss: 0.2483
Training Epoch: 54 [33792/50176]	Loss: 0.2542
Training Epoch: 54 [34816/50176]	Loss: 0.3030
Training Epoch: 54 [35840/50176]	Loss: 0.2638
Training Epoch: 54 [36864/50176]	Loss: 0.2637
Training Epoch: 54 [37888/50176]	Loss: 0.2747
Training Epoch: 54 [38912/50176]	Loss: 0.3060
Training Epoch: 54 [39936/50176]	Loss: 0.2650
Training Epoch: 54 [40960/50176]	Loss: 0.2861
Training Epoch: 54 [41984/50176]	Loss: 0.2780
Training Epoch: 54 [43008/50176]	Loss: 0.2547
Training Epoch: 54 [44032/50176]	Loss: 0.2708
Training Epoch: 54 [45056/50176]	Loss: 0.2669
Training Epoch: 54 [46080/50176]	Loss: 0.2969
Training Epoch: 54 [47104/50176]	Loss: 0.3217
Training Epoch: 54 [48128/50176]	Loss: 0.2986
Training Epoch: 54 [49152/50176]	Loss: 0.3060
Training Epoch: 54 [50176/50176]	Loss: 0.2990
2022-12-06 17:54:33.917 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:54:33,963 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.79 energy=477.78
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Up to epoch 55: time=2708.80, energy=376506.83, cost=425273.20
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:54:33,963 [ZeusDataLoader(train)] Expected next epoch: time=2756.07, energy=383290.78, cost=432801.65
2022-12-06 12:54:33,964 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0023, Accuracy: 0.5806
2022-12-06 12:54:34,167 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:54:34,168 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:54:34.170 [ZeusMonitor] Monitor started.
2022-12-06 17:54:34.170 [ZeusMonitor] Running indefinitely. 2022-12-06 17:54:34.170 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:54:34.170 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 12:55:19,148 [ZeusDataLoader(train)] train epoch 56 done: time=45.18 energy=6388.09
2022-12-06 12:55:19,152 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 0.2377
Training Epoch: 55 [2048/50176]	Loss: 0.2271
Training Epoch: 55 [3072/50176]	Loss: 0.2208
Training Epoch: 55 [4096/50176]	Loss: 0.2187
Training Epoch: 55 [5120/50176]	Loss: 0.2532
Training Epoch: 55 [6144/50176]	Loss: 0.2075
Training Epoch: 55 [7168/50176]	Loss: 0.2167
Training Epoch: 55 [8192/50176]	Loss: 0.2126
Training Epoch: 55 [9216/50176]	Loss: 0.2107
Training Epoch: 55 [10240/50176]	Loss: 0.2748
Training Epoch: 55 [11264/50176]	Loss: 0.2395
Training Epoch: 55 [12288/50176]	Loss: 0.2389
Training Epoch: 55 [13312/50176]	Loss: 0.1952
Training Epoch: 55 [14336/50176]	Loss: 0.2471
Training Epoch: 55 [15360/50176]	Loss: 0.2500
Training Epoch: 55 [16384/50176]	Loss: 0.2347
Training Epoch: 55 [17408/50176]	Loss: 0.2611
Training Epoch: 55 [18432/50176]	Loss: 0.2298
Training Epoch: 55 [19456/50176]	Loss: 0.2941
Training Epoch: 55 [20480/50176]	Loss: 0.2592
Training Epoch: 55 [21504/50176]	Loss: 0.2464
Training Epoch: 55 [22528/50176]	Loss: 0.2467
Training Epoch: 55 [23552/50176]	Loss: 0.2869
Training Epoch: 55 [24576/50176]	Loss: 0.2464
Training Epoch: 55 [25600/50176]	Loss: 0.2575
Training Epoch: 55 [26624/50176]	Loss: 0.2491
Training Epoch: 55 [27648/50176]	Loss: 0.2484
Training Epoch: 55 [28672/50176]	Loss: 0.2666
Training Epoch: 55 [29696/50176]	Loss: 0.2360
Training Epoch: 55 [30720/50176]	Loss: 0.2296
Training Epoch: 55 [31744/50176]	Loss: 0.2306
Training Epoch: 55 [32768/50176]	Loss: 0.2659
Training Epoch: 55 [33792/50176]	Loss: 0.2842
Training Epoch: 55 [34816/50176]	Loss: 0.2262
Training Epoch: 55 [35840/50176]	Loss: 0.2870
Training Epoch: 55 [36864/50176]	Loss: 0.2562
Training Epoch: 55 [37888/50176]	Loss: 0.2848
Training Epoch: 55 [38912/50176]	Loss: 0.2440
Training Epoch: 55 [39936/50176]	Loss: 0.2593
Training Epoch: 55 [40960/50176]	Loss: 0.2191
Training Epoch: 55 [41984/50176]	Loss: 0.2373
Training Epoch: 55 [43008/50176]	Loss: 0.2438
Training Epoch: 55 [44032/50176]	Loss: 0.2839
Training Epoch: 55 [45056/50176]	Loss: 0.2305
Training Epoch: 55 [46080/50176]	Loss: 0.2888
Training Epoch: 55 [47104/50176]	Loss: 0.2471
Training Epoch: 55 [48128/50176]	Loss: 0.2732
Training Epoch: 55 [49152/50176]	Loss: 0.2507
Training Epoch: 55 [50176/50176]	Loss: 0.2428
2022-12-06 17:55:22.967 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:55:22,978 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.82 energy=490.98
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Up to epoch 56: time=2757.79, energy=383385.90, cost=432999.73
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:55:22,978 [ZeusDataLoader(train)] Expected next epoch: time=2805.07, energy=390169.85, cost=440528.18
2022-12-06 12:55:22,979 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0023, Accuracy: 0.5818
2022-12-06 12:55:23,197 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:55:23,197 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:55:23.199 [ZeusMonitor] Monitor started.
2022-12-06 17:55:23.199 [ZeusMonitor] Running indefinitely. 2022-12-06 17:55:23.199 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:55:23.199 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 12:56:08,394 [ZeusDataLoader(train)] train epoch 57 done: time=45.41 energy=6397.96
2022-12-06 12:56:08,397 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 0.1911
Training Epoch: 56 [2048/50176]	Loss: 0.2132
Training Epoch: 56 [3072/50176]	Loss: 0.2168
Training Epoch: 56 [4096/50176]	Loss: 0.1965
Training Epoch: 56 [5120/50176]	Loss: 0.2246
Training Epoch: 56 [6144/50176]	Loss: 0.2103
Training Epoch: 56 [7168/50176]	Loss: 0.2009
Training Epoch: 56 [8192/50176]	Loss: 0.1987
Training Epoch: 56 [9216/50176]	Loss: 0.2400
Training Epoch: 56 [10240/50176]	Loss: 0.2064
Training Epoch: 56 [11264/50176]	Loss: 0.2046
Training Epoch: 56 [12288/50176]	Loss: 0.2147
Training Epoch: 56 [13312/50176]	Loss: 0.2355
Training Epoch: 56 [14336/50176]	Loss: 0.1868
Training Epoch: 56 [15360/50176]	Loss: 0.2488
Training Epoch: 56 [16384/50176]	Loss: 0.2088
Training Epoch: 56 [17408/50176]	Loss: 0.1860
Training Epoch: 56 [18432/50176]	Loss: 0.2482
Training Epoch: 56 [19456/50176]	Loss: 0.2102
Training Epoch: 56 [20480/50176]	Loss: 0.2200
Training Epoch: 56 [21504/50176]	Loss: 0.2210
Training Epoch: 56 [22528/50176]	Loss: 0.2349
Training Epoch: 56 [23552/50176]	Loss: 0.2323
Training Epoch: 56 [24576/50176]	Loss: 0.2082
Training Epoch: 56 [25600/50176]	Loss: 0.2149
Training Epoch: 56 [26624/50176]	Loss: 0.1958
Training Epoch: 56 [27648/50176]	Loss: 0.2236
Training Epoch: 56 [28672/50176]	Loss: 0.2490
Training Epoch: 56 [29696/50176]	Loss: 0.1909
Training Epoch: 56 [30720/50176]	Loss: 0.2209
Training Epoch: 56 [31744/50176]	Loss: 0.2395
Training Epoch: 56 [32768/50176]	Loss: 0.2672
Training Epoch: 56 [33792/50176]	Loss: 0.2692
Training Epoch: 56 [34816/50176]	Loss: 0.2259
Training Epoch: 56 [35840/50176]	Loss: 0.2190
Training Epoch: 56 [36864/50176]	Loss: 0.2141
Training Epoch: 56 [37888/50176]	Loss: 0.2636
Training Epoch: 56 [38912/50176]	Loss: 0.2809
Training Epoch: 56 [39936/50176]	Loss: 0.2179
Training Epoch: 56 [40960/50176]	Loss: 0.2128
Training Epoch: 56 [41984/50176]	Loss: 0.2452
Training Epoch: 56 [43008/50176]	Loss: 0.2747
Training Epoch: 56 [44032/50176]	Loss: 0.2238
Training Epoch: 56 [45056/50176]	Loss: 0.2469
Training Epoch: 56 [46080/50176]	Loss: 0.2567
Training Epoch: 56 [47104/50176]	Loss: 0.2510
Training Epoch: 56 [48128/50176]	Loss: 0.2638
Training Epoch: 56 [49152/50176]	Loss: 0.2402
Training Epoch: 56 [50176/50176]	Loss: 0.2745
2022-12-06 17:56:12.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:56:12,228 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.82 energy=485.11
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Up to epoch 57: time=2807.02, energy=390268.98, cost=440748.84
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:56:12,228 [ZeusDataLoader(train)] Expected next epoch: time=2854.30, energy=397052.93, cost=448277.29
2022-12-06 12:56:12,229 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0022, Accuracy: 0.5967
2022-12-06 12:56:12,438 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:56:12,439 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:56:12.448 [ZeusMonitor] Monitor started.
2022-12-06 17:56:12.449 [ZeusMonitor] Running indefinitely. 2022-12-06 17:56:12.449 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:56:12.449 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 12:56:57,708 [ZeusDataLoader(train)] train epoch 58 done: time=45.47 energy=6398.58
2022-12-06 12:56:57,712 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 0.1799
Training Epoch: 57 [2048/50176]	Loss: 0.2322
Training Epoch: 57 [3072/50176]	Loss: 0.1995
Training Epoch: 57 [4096/50176]	Loss: 0.2112
Training Epoch: 57 [5120/50176]	Loss: 0.2152
Training Epoch: 57 [6144/50176]	Loss: 0.2032
Training Epoch: 57 [7168/50176]	Loss: 0.2599
Training Epoch: 57 [8192/50176]	Loss: 0.1853
Training Epoch: 57 [9216/50176]	Loss: 0.1919
Training Epoch: 57 [10240/50176]	Loss: 0.1612
Training Epoch: 57 [11264/50176]	Loss: 0.2001
Training Epoch: 57 [12288/50176]	Loss: 0.2060
Training Epoch: 57 [13312/50176]	Loss: 0.1889
Training Epoch: 57 [14336/50176]	Loss: 0.1958
Training Epoch: 57 [15360/50176]	Loss: 0.1888
Training Epoch: 57 [16384/50176]	Loss: 0.2164
Training Epoch: 57 [17408/50176]	Loss: 0.2394
Training Epoch: 57 [18432/50176]	Loss: 0.2033
Training Epoch: 57 [19456/50176]	Loss: 0.2331
Training Epoch: 57 [20480/50176]	Loss: 0.1722
Training Epoch: 57 [21504/50176]	Loss: 0.2390
Training Epoch: 57 [22528/50176]	Loss: 0.1856
Training Epoch: 57 [23552/50176]	Loss: 0.2259
Training Epoch: 57 [24576/50176]	Loss: 0.1822
Training Epoch: 57 [25600/50176]	Loss: 0.2202
Training Epoch: 57 [26624/50176]	Loss: 0.2431
Training Epoch: 57 [27648/50176]	Loss: 0.2160
Training Epoch: 57 [28672/50176]	Loss: 0.2155
Training Epoch: 57 [29696/50176]	Loss: 0.2210
Training Epoch: 57 [30720/50176]	Loss: 0.2231
Training Epoch: 57 [31744/50176]	Loss: 0.1978
Training Epoch: 57 [32768/50176]	Loss: 0.2381
Training Epoch: 57 [33792/50176]	Loss: 0.2506
Training Epoch: 57 [34816/50176]	Loss: 0.2582
Training Epoch: 57 [35840/50176]	Loss: 0.2236
Training Epoch: 57 [36864/50176]	Loss: 0.1953
Training Epoch: 57 [37888/50176]	Loss: 0.2165
Training Epoch: 57 [38912/50176]	Loss: 0.2220
Training Epoch: 57 [39936/50176]	Loss: 0.2243
Training Epoch: 57 [40960/50176]	Loss: 0.2280
Training Epoch: 57 [41984/50176]	Loss: 0.2527
Training Epoch: 57 [43008/50176]	Loss: 0.2606
Training Epoch: 57 [44032/50176]	Loss: 0.2253
Training Epoch: 57 [45056/50176]	Loss: 0.2526
Training Epoch: 57 [46080/50176]	Loss: 0.1924
Training Epoch: 57 [47104/50176]	Loss: 0.2566
Training Epoch: 57 [48128/50176]	Loss: 0.2329
Training Epoch: 57 [49152/50176]	Loss: 0.2416
Training Epoch: 57 [50176/50176]	Loss: 0.2515
2022-12-06 17:57:01.464 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:57:01,503 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.78 energy=478.28
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Up to epoch 58: time=2856.28, energy=397145.84, cost=448497.08
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:57:01,504 [ZeusDataLoader(train)] Expected next epoch: time=2903.55, energy=403929.79, cost=456025.54
2022-12-06 12:57:01,505 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0022, Accuracy: 0.5875
2022-12-06 12:57:01,739 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:57:01,740 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:57:01.741 [ZeusMonitor] Monitor started.
2022-12-06 17:57:01.742 [ZeusMonitor] Running indefinitely. 2022-12-06 17:57:01.742 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:57:01.742 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 12:57:46,125 [ZeusDataLoader(train)] train epoch 59 done: time=44.61 energy=6339.70
2022-12-06 12:57:46,128 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 0.1758
Training Epoch: 58 [2048/50176]	Loss: 0.1987
Training Epoch: 58 [3072/50176]	Loss: 0.2019
Training Epoch: 58 [4096/50176]	Loss: 0.1970
Training Epoch: 58 [5120/50176]	Loss: 0.2170
Training Epoch: 58 [6144/50176]	Loss: 0.1913
Training Epoch: 58 [7168/50176]	Loss: 0.1883
Training Epoch: 58 [8192/50176]	Loss: 0.1843
Training Epoch: 58 [9216/50176]	Loss: 0.2179
Training Epoch: 58 [10240/50176]	Loss: 0.1925
Training Epoch: 58 [11264/50176]	Loss: 0.2020
Training Epoch: 58 [12288/50176]	Loss: 0.2303
Training Epoch: 58 [13312/50176]	Loss: 0.1954
Training Epoch: 58 [14336/50176]	Loss: 0.1985
Training Epoch: 58 [15360/50176]	Loss: 0.1882
Training Epoch: 58 [16384/50176]	Loss: 0.2095
Training Epoch: 58 [17408/50176]	Loss: 0.2273
Training Epoch: 58 [18432/50176]	Loss: 0.1806
Training Epoch: 58 [19456/50176]	Loss: 0.1787
Training Epoch: 58 [20480/50176]	Loss: 0.1935
Training Epoch: 58 [21504/50176]	Loss: 0.2139
Training Epoch: 58 [22528/50176]	Loss: 0.1807
Training Epoch: 58 [23552/50176]	Loss: 0.2069
Training Epoch: 58 [24576/50176]	Loss: 0.2107
Training Epoch: 58 [25600/50176]	Loss: 0.2086
Training Epoch: 58 [26624/50176]	Loss: 0.2178
Training Epoch: 58 [27648/50176]	Loss: 0.2098
Training Epoch: 58 [28672/50176]	Loss: 0.2001
Training Epoch: 58 [29696/50176]	Loss: 0.2187
Training Epoch: 58 [30720/50176]	Loss: 0.2403
Training Epoch: 58 [31744/50176]	Loss: 0.2017
Training Epoch: 58 [32768/50176]	Loss: 0.2041
Training Epoch: 58 [33792/50176]	Loss: 0.2298
Training Epoch: 58 [34816/50176]	Loss: 0.1783
Training Epoch: 58 [35840/50176]	Loss: 0.2447
Training Epoch: 58 [36864/50176]	Loss: 0.1891
Training Epoch: 58 [37888/50176]	Loss: 0.2226
Training Epoch: 58 [38912/50176]	Loss: 0.2205
Training Epoch: 58 [39936/50176]	Loss: 0.2299
Training Epoch: 58 [40960/50176]	Loss: 0.2311
Training Epoch: 58 [41984/50176]	Loss: 0.2048
Training Epoch: 58 [43008/50176]	Loss: 0.2140
Training Epoch: 58 [44032/50176]	Loss: 0.2483
Training Epoch: 58 [45056/50176]	Loss: 0.2639
Training Epoch: 58 [46080/50176]	Loss: 0.2370
Training Epoch: 58 [47104/50176]	Loss: 0.2587
Training Epoch: 58 [48128/50176]	Loss: 0.2308
Training Epoch: 58 [49152/50176]	Loss: 0.2211
Training Epoch: 58 [50176/50176]	Loss: 0.2186
2022-12-06 17:57:49.810 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:57:49,819 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.68 energy=467.19
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Up to epoch 59: time=2904.57, energy=403952.73, cost=456126.35
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:57:49,819 [ZeusDataLoader(train)] Expected next epoch: time=2951.85, energy=410736.68, cost=463654.81
2022-12-06 12:57:49,820 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0024, Accuracy: 0.5806
2022-12-06 12:57:50,015 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:57:50,016 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:57:50.030 [ZeusMonitor] Monitor started.
2022-12-06 17:57:50.030 [ZeusMonitor] Running indefinitely. 2022-12-06 17:57:50.030 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:57:50.030 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 12:58:34,190 [ZeusDataLoader(train)] train epoch 60 done: time=44.36 energy=6317.62
2022-12-06 12:58:34,193 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 0.1864
Training Epoch: 59 [2048/50176]	Loss: 0.1866
Training Epoch: 59 [3072/50176]	Loss: 0.2137
Training Epoch: 59 [4096/50176]	Loss: 0.2005
Training Epoch: 59 [5120/50176]	Loss: 0.1959
Training Epoch: 59 [6144/50176]	Loss: 0.2057
Training Epoch: 59 [7168/50176]	Loss: 0.2183
Training Epoch: 59 [8192/50176]	Loss: 0.1998
Training Epoch: 59 [9216/50176]	Loss: 0.1863
Training Epoch: 59 [10240/50176]	Loss: 0.1771
Training Epoch: 59 [11264/50176]	Loss: 0.1615
Training Epoch: 59 [12288/50176]	Loss: 0.1788
Training Epoch: 59 [13312/50176]	Loss: 0.2383
Training Epoch: 59 [14336/50176]	Loss: 0.1872
Training Epoch: 59 [15360/50176]	Loss: 0.2099
Training Epoch: 59 [16384/50176]	Loss: 0.1869
Training Epoch: 59 [17408/50176]	Loss: 0.2238
Training Epoch: 59 [18432/50176]	Loss: 0.1755
Training Epoch: 59 [19456/50176]	Loss: 0.2133
Training Epoch: 59 [20480/50176]	Loss: 0.2139
Training Epoch: 59 [21504/50176]	Loss: 0.1984
Training Epoch: 59 [22528/50176]	Loss: 0.2093
Training Epoch: 59 [23552/50176]	Loss: 0.2257
Training Epoch: 59 [24576/50176]	Loss: 0.2298
Training Epoch: 59 [25600/50176]	Loss: 0.1791
Training Epoch: 59 [26624/50176]	Loss: 0.2175
Training Epoch: 59 [27648/50176]	Loss: 0.2482
Training Epoch: 59 [28672/50176]	Loss: 0.2059
Training Epoch: 59 [29696/50176]	Loss: 0.2129
Training Epoch: 59 [30720/50176]	Loss: 0.2079
Training Epoch: 59 [31744/50176]	Loss: 0.2317
Training Epoch: 59 [32768/50176]	Loss: 0.2098
Training Epoch: 59 [33792/50176]	Loss: 0.2171
Training Epoch: 59 [34816/50176]	Loss: 0.2457
Training Epoch: 59 [35840/50176]	Loss: 0.2085
Training Epoch: 59 [36864/50176]	Loss: 0.2419
Training Epoch: 59 [37888/50176]	Loss: 0.2058
Training Epoch: 59 [38912/50176]	Loss: 0.2110
Training Epoch: 59 [39936/50176]	Loss: 0.2047
Training Epoch: 59 [40960/50176]	Loss: 0.2361
Training Epoch: 59 [41984/50176]	Loss: 0.2019
Training Epoch: 59 [43008/50176]	Loss: 0.2198
Training Epoch: 59 [44032/50176]	Loss: 0.2658
Training Epoch: 59 [45056/50176]	Loss: 0.2241
Training Epoch: 59 [46080/50176]	Loss: 0.2485
Training Epoch: 59 [47104/50176]	Loss: 0.2191
Training Epoch: 59 [48128/50176]	Loss: 0.2373
Training Epoch: 59 [49152/50176]	Loss: 0.2625
Training Epoch: 59 [50176/50176]	Loss: 0.2138
2022-12-06 17:58:38.005 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:58:38,042 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.84 energy=485.41
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Up to epoch 60: time=2952.77, energy=410755.76, cost=463745.64
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:58:38,042 [ZeusDataLoader(train)] Expected next epoch: time=3000.05, energy=417539.71, cost=471274.09
2022-12-06 12:58:38,043 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0026, Accuracy: 0.5640
2022-12-06 12:58:38,259 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:58:38,260 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:58:38.274 [ZeusMonitor] Monitor started.
2022-12-06 17:58:38.274 [ZeusMonitor] Running indefinitely. 2022-12-06 17:58:38.274 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:58:38.274 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 12:59:22,645 [ZeusDataLoader(train)] train epoch 61 done: time=44.59 energy=6324.16
2022-12-06 12:59:22,648 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.1842
Training Epoch: 60 [2048/50176]	Loss: 0.1664
Training Epoch: 60 [3072/50176]	Loss: 0.1844
Training Epoch: 60 [4096/50176]	Loss: 0.1943
Training Epoch: 60 [5120/50176]	Loss: 0.2247
Training Epoch: 60 [6144/50176]	Loss: 0.1611
Training Epoch: 60 [7168/50176]	Loss: 0.2027
Training Epoch: 60 [8192/50176]	Loss: 0.1882
Training Epoch: 60 [9216/50176]	Loss: 0.1932
Training Epoch: 60 [10240/50176]	Loss: 0.1879
Training Epoch: 60 [11264/50176]	Loss: 0.1964
Training Epoch: 60 [12288/50176]	Loss: 0.2318
Training Epoch: 60 [13312/50176]	Loss: 0.2108
Training Epoch: 60 [14336/50176]	Loss: 0.2162
Training Epoch: 60 [15360/50176]	Loss: 0.2140
Training Epoch: 60 [16384/50176]	Loss: 0.1939
Training Epoch: 60 [17408/50176]	Loss: 0.1883
Training Epoch: 60 [18432/50176]	Loss: 0.1796
Training Epoch: 60 [19456/50176]	Loss: 0.2047
Training Epoch: 60 [20480/50176]	Loss: 0.1937
Training Epoch: 60 [21504/50176]	Loss: 0.2251
Training Epoch: 60 [22528/50176]	Loss: 0.2203
Training Epoch: 60 [23552/50176]	Loss: 0.1730
Training Epoch: 60 [24576/50176]	Loss: 0.2074
Training Epoch: 60 [25600/50176]	Loss: 0.2268
Training Epoch: 60 [26624/50176]	Loss: 0.1884
Training Epoch: 60 [27648/50176]	Loss: 0.2093
Training Epoch: 60 [28672/50176]	Loss: 0.1906
Training Epoch: 60 [29696/50176]	Loss: 0.2014
Training Epoch: 60 [30720/50176]	Loss: 0.2055
Training Epoch: 60 [31744/50176]	Loss: 0.2429
Training Epoch: 60 [32768/50176]	Loss: 0.1920
Training Epoch: 60 [33792/50176]	Loss: 0.2361
Training Epoch: 60 [34816/50176]	Loss: 0.2394
Training Epoch: 60 [35840/50176]	Loss: 0.1784
Training Epoch: 60 [36864/50176]	Loss: 0.2418
Training Epoch: 60 [37888/50176]	Loss: 0.2383
Training Epoch: 60 [38912/50176]	Loss: 0.2044
Training Epoch: 60 [39936/50176]	Loss: 0.1881
Training Epoch: 60 [40960/50176]	Loss: 0.2392
Training Epoch: 60 [41984/50176]	Loss: 0.2160
Training Epoch: 60 [43008/50176]	Loss: 0.2374
Training Epoch: 60 [44032/50176]	Loss: 0.2437
Training Epoch: 60 [45056/50176]	Loss: 0.2020
Training Epoch: 60 [46080/50176]	Loss: 0.2465
Training Epoch: 60 [47104/50176]	Loss: 0.2267
Training Epoch: 60 [48128/50176]	Loss: 0.2025
Training Epoch: 60 [49152/50176]	Loss: 0.2341
Training Epoch: 60 [50176/50176]	Loss: 0.2372
2022-12-06 17:59:26.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 12:59:26,356 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.70 energy=473.56
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Up to epoch 61: time=3001.07, energy=417553.47, cost=471370.18
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 12:59:26,357 [ZeusDataLoader(train)] Expected next epoch: time=3048.34, energy=424337.42, cost=478898.64
2022-12-06 12:59:26,358 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0023, Accuracy: 0.5823
2022-12-06 12:59:26,572 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 12:59:26,573 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 17:59:26.574 [ZeusMonitor] Monitor started.
2022-12-06 17:59:26.574 [ZeusMonitor] Running indefinitely. 2022-12-06 17:59:26.574 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 17:59:26.574 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 13:00:10,760 [ZeusDataLoader(train)] train epoch 62 done: time=44.39 energy=6328.35
2022-12-06 13:00:10,763 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.1883
Training Epoch: 61 [2048/50176]	Loss: 0.1907
Training Epoch: 61 [3072/50176]	Loss: 0.1815
Training Epoch: 61 [4096/50176]	Loss: 0.1814
Training Epoch: 61 [5120/50176]	Loss: 0.1706
Training Epoch: 61 [6144/50176]	Loss: 0.1972
Training Epoch: 61 [7168/50176]	Loss: 0.2138
Training Epoch: 61 [8192/50176]	Loss: 0.1866
Training Epoch: 61 [9216/50176]	Loss: 0.1931
Training Epoch: 61 [10240/50176]	Loss: 0.1845
Training Epoch: 61 [11264/50176]	Loss: 0.1737
Training Epoch: 61 [12288/50176]	Loss: 0.1791
Training Epoch: 61 [13312/50176]	Loss: 0.2025
Training Epoch: 61 [14336/50176]	Loss: 0.2141
Training Epoch: 61 [15360/50176]	Loss: 0.1991
Training Epoch: 61 [16384/50176]	Loss: 0.1816
Training Epoch: 61 [17408/50176]	Loss: 0.1807
Training Epoch: 61 [18432/50176]	Loss: 0.1893
Training Epoch: 61 [19456/50176]	Loss: 0.1669
Training Epoch: 61 [20480/50176]	Loss: 0.1941
Training Epoch: 61 [21504/50176]	Loss: 0.2125
Training Epoch: 61 [22528/50176]	Loss: 0.2025
Training Epoch: 61 [23552/50176]	Loss: 0.1911
Training Epoch: 61 [24576/50176]	Loss: 0.1837
Training Epoch: 61 [25600/50176]	Loss: 0.1837
Training Epoch: 61 [26624/50176]	Loss: 0.1807
Training Epoch: 61 [27648/50176]	Loss: 0.2156
Training Epoch: 61 [28672/50176]	Loss: 0.1808
Training Epoch: 61 [29696/50176]	Loss: 0.1770
Training Epoch: 61 [30720/50176]	Loss: 0.2035
Training Epoch: 61 [31744/50176]	Loss: 0.2098
Training Epoch: 61 [32768/50176]	Loss: 0.1850
Training Epoch: 61 [33792/50176]	Loss: 0.2189
Training Epoch: 61 [34816/50176]	Loss: 0.2020
Training Epoch: 61 [35840/50176]	Loss: 0.1748
Training Epoch: 61 [36864/50176]	Loss: 0.2114
Training Epoch: 61 [37888/50176]	Loss: 0.2203
Training Epoch: 61 [38912/50176]	Loss: 0.1880
Training Epoch: 61 [39936/50176]	Loss: 0.2271
Training Epoch: 61 [40960/50176]	Loss: 0.2094
Training Epoch: 61 [41984/50176]	Loss: 0.2134
Training Epoch: 61 [43008/50176]	Loss: 0.2164
Training Epoch: 61 [44032/50176]	Loss: 0.2006
Training Epoch: 61 [45056/50176]	Loss: 0.2089
Training Epoch: 61 [46080/50176]	Loss: 0.2217
Training Epoch: 61 [47104/50176]	Loss: 0.2079
Training Epoch: 61 [48128/50176]	Loss: 0.2062
Training Epoch: 61 [49152/50176]	Loss: 0.2168
Training Epoch: 61 [50176/50176]	Loss: 0.2288
2022-12-06 18:00:14.516 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:00:14,544 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.77 energy=481.50
2022-12-06 13:00:14,544 [ZeusDataLoader(train)] Up to epoch 62: time=3049.24, energy=424363.32, cost=478989.76
2022-12-06 13:00:14,545 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:00:14,545 [ZeusDataLoader(train)] Expected next epoch: time=3096.51, energy=431147.28, cost=486518.21
2022-12-06 13:00:14,546 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0024, Accuracy: 0.5899
2022-12-06 13:00:14,776 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:00:14,777 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:00:14.779 [ZeusMonitor] Monitor started.
2022-12-06 18:00:14.779 [ZeusMonitor] Running indefinitely. 2022-12-06 18:00:14.779 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:00:14.779 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 13:00:58,968 [ZeusDataLoader(train)] train epoch 63 done: time=44.41 energy=6318.96
2022-12-06 13:00:58,971 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.1576
Training Epoch: 62 [2048/50176]	Loss: 0.1854
Training Epoch: 62 [3072/50176]	Loss: 0.1578
Training Epoch: 62 [4096/50176]	Loss: 0.1853
Training Epoch: 62 [5120/50176]	Loss: 0.1889
Training Epoch: 62 [6144/50176]	Loss: 0.1733
Training Epoch: 62 [7168/50176]	Loss: 0.1894
Training Epoch: 62 [8192/50176]	Loss: 0.1784
Training Epoch: 62 [9216/50176]	Loss: 0.1897
Training Epoch: 62 [10240/50176]	Loss: 0.1850
Training Epoch: 62 [11264/50176]	Loss: 0.1806
Training Epoch: 62 [12288/50176]	Loss: 0.2005
Training Epoch: 62 [13312/50176]	Loss: 0.1757
Training Epoch: 62 [14336/50176]	Loss: 0.2279
Training Epoch: 62 [15360/50176]	Loss: 0.1968
Training Epoch: 62 [16384/50176]	Loss: 0.1817
Training Epoch: 62 [17408/50176]	Loss: 0.1598
Training Epoch: 62 [18432/50176]	Loss: 0.2288
Training Epoch: 62 [19456/50176]	Loss: 0.1879
Training Epoch: 62 [20480/50176]	Loss: 0.2207
Training Epoch: 62 [21504/50176]	Loss: 0.1804
Training Epoch: 62 [22528/50176]	Loss: 0.1865
Training Epoch: 62 [23552/50176]	Loss: 0.1664
Training Epoch: 62 [24576/50176]	Loss: 0.1957
Training Epoch: 62 [25600/50176]	Loss: 0.1786
Training Epoch: 62 [26624/50176]	Loss: 0.1494
Training Epoch: 62 [27648/50176]	Loss: 0.2373
Training Epoch: 62 [28672/50176]	Loss: 0.2086
Training Epoch: 62 [29696/50176]	Loss: 0.1889
Training Epoch: 62 [30720/50176]	Loss: 0.1885
Training Epoch: 62 [31744/50176]	Loss: 0.2234
Training Epoch: 62 [32768/50176]	Loss: 0.1790
Training Epoch: 62 [33792/50176]	Loss: 0.2252
Training Epoch: 62 [34816/50176]	Loss: 0.1948
Training Epoch: 62 [35840/50176]	Loss: 0.1876
Training Epoch: 62 [36864/50176]	Loss: 0.2123
Training Epoch: 62 [37888/50176]	Loss: 0.1778
Training Epoch: 62 [38912/50176]	Loss: 0.2028
Training Epoch: 62 [39936/50176]	Loss: 0.2054
Training Epoch: 62 [40960/50176]	Loss: 0.1540
Training Epoch: 62 [41984/50176]	Loss: 0.1978
Training Epoch: 62 [43008/50176]	Loss: 0.2164
Training Epoch: 62 [44032/50176]	Loss: 0.1934
Training Epoch: 62 [45056/50176]	Loss: 0.2064
Training Epoch: 62 [46080/50176]	Loss: 0.2139
Training Epoch: 62 [47104/50176]	Loss: 0.2025
Training Epoch: 62 [48128/50176]	Loss: 0.2248
Training Epoch: 62 [49152/50176]	Loss: 0.2055
Training Epoch: 62 [50176/50176]	Loss: 0.2200
2022-12-06 18:01:02.783 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:01:02,813 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.83 energy=496.84
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Up to epoch 63: time=3097.48, energy=431179.13, cost=486619.41
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:01:02,814 [ZeusDataLoader(train)] Expected next epoch: time=3144.76, energy=437963.08, cost=494147.86
2022-12-06 13:01:02,815 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0025, Accuracy: 0.5934
2022-12-06 13:01:02,989 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:01:02,990 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:01:02.993 [ZeusMonitor] Monitor started.
2022-12-06 18:01:02.993 [ZeusMonitor] Running indefinitely. 2022-12-06 18:01:02.994 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:01:02.994 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 13:01:47,276 [ZeusDataLoader(train)] train epoch 64 done: time=44.45 energy=6331.94
2022-12-06 13:01:47,280 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 0.1677
Training Epoch: 63 [2048/50176]	Loss: 0.1851
Training Epoch: 63 [3072/50176]	Loss: 0.1523
Training Epoch: 63 [4096/50176]	Loss: 0.1694
Training Epoch: 63 [5120/50176]	Loss: 0.1516
Training Epoch: 63 [6144/50176]	Loss: 0.1683
Training Epoch: 63 [7168/50176]	Loss: 0.2025
Training Epoch: 63 [8192/50176]	Loss: 0.1568
Training Epoch: 63 [9216/50176]	Loss: 0.1467
Training Epoch: 63 [10240/50176]	Loss: 0.1921
Training Epoch: 63 [11264/50176]	Loss: 0.1738
Training Epoch: 63 [12288/50176]	Loss: 0.1622
Training Epoch: 63 [13312/50176]	Loss: 0.1670
Training Epoch: 63 [14336/50176]	Loss: 0.1807
Training Epoch: 63 [15360/50176]	Loss: 0.1863
Training Epoch: 63 [16384/50176]	Loss: 0.1714
Training Epoch: 63 [17408/50176]	Loss: 0.1499
Training Epoch: 63 [18432/50176]	Loss: 0.1747
Training Epoch: 63 [19456/50176]	Loss: 0.1728
Training Epoch: 63 [20480/50176]	Loss: 0.1714
Training Epoch: 63 [21504/50176]	Loss: 0.1915
Training Epoch: 63 [22528/50176]	Loss: 0.1599
Training Epoch: 63 [23552/50176]	Loss: 0.1972
Training Epoch: 63 [24576/50176]	Loss: 0.1736
Training Epoch: 63 [25600/50176]	Loss: 0.1871
Training Epoch: 63 [26624/50176]	Loss: 0.1804
Training Epoch: 63 [27648/50176]	Loss: 0.1666
Training Epoch: 63 [28672/50176]	Loss: 0.1811
Training Epoch: 63 [29696/50176]	Loss: 0.2235
Training Epoch: 63 [30720/50176]	Loss: 0.2009
Training Epoch: 63 [31744/50176]	Loss: 0.1783
Training Epoch: 63 [32768/50176]	Loss: 0.2018
Training Epoch: 63 [33792/50176]	Loss: 0.1731
Training Epoch: 63 [34816/50176]	Loss: 0.1867
Training Epoch: 63 [35840/50176]	Loss: 0.1831
Training Epoch: 63 [36864/50176]	Loss: 0.2292
Training Epoch: 63 [37888/50176]	Loss: 0.2117
Training Epoch: 63 [38912/50176]	Loss: 0.1862
Training Epoch: 63 [39936/50176]	Loss: 0.1999
Training Epoch: 63 [40960/50176]	Loss: 0.2074
Training Epoch: 63 [41984/50176]	Loss: 0.2170
Training Epoch: 63 [43008/50176]	Loss: 0.2357
Training Epoch: 63 [44032/50176]	Loss: 0.1867
Training Epoch: 63 [45056/50176]	Loss: 0.1764
Training Epoch: 63 [46080/50176]	Loss: 0.1880
Training Epoch: 63 [47104/50176]	Loss: 0.1891
Training Epoch: 63 [48128/50176]	Loss: 0.2368
Training Epoch: 63 [49152/50176]	Loss: 0.1980
Training Epoch: 63 [50176/50176]	Loss: 0.1997
2022-12-06 18:01:51.000 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:01:51,019 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.73 energy=479.51
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Up to epoch 64: time=3145.67, energy=437990.57, cost=494241.38
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:01:51,020 [ZeusDataLoader(train)] Expected next epoch: time=3192.94, energy=444774.52, cost=501769.84
2022-12-06 13:01:51,021 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0024, Accuracy: 0.5896
2022-12-06 13:01:51,229 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:01:51,230 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:01:51.231 [ZeusMonitor] Monitor started.
2022-12-06 18:01:51.231 [ZeusMonitor] Running indefinitely. 2022-12-06 18:01:51.231 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:01:51.231 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 13:02:35,180 [ZeusDataLoader(train)] train epoch 65 done: time=44.15 energy=6300.03
2022-12-06 13:02:35,184 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 0.1721
Training Epoch: 64 [2048/50176]	Loss: 0.1307
Training Epoch: 64 [3072/50176]	Loss: 0.1839
Training Epoch: 64 [4096/50176]	Loss: 0.1766
Training Epoch: 64 [5120/50176]	Loss: 0.1714
Training Epoch: 64 [6144/50176]	Loss: 0.1534
Training Epoch: 64 [7168/50176]	Loss: 0.1642
Training Epoch: 64 [8192/50176]	Loss: 0.1561
Training Epoch: 64 [9216/50176]	Loss: 0.1479
Training Epoch: 64 [10240/50176]	Loss: 0.1777
Training Epoch: 64 [11264/50176]	Loss: 0.1426
Training Epoch: 64 [12288/50176]	Loss: 0.1593
Training Epoch: 64 [13312/50176]	Loss: 0.1518
Training Epoch: 64 [14336/50176]	Loss: 0.1563
Training Epoch: 64 [15360/50176]	Loss: 0.1214
Training Epoch: 64 [16384/50176]	Loss: 0.1745
Training Epoch: 64 [17408/50176]	Loss: 0.1600
Training Epoch: 64 [18432/50176]	Loss: 0.2244
Training Epoch: 64 [19456/50176]	Loss: 0.1608
Training Epoch: 64 [20480/50176]	Loss: 0.1988
Training Epoch: 64 [21504/50176]	Loss: 0.1592
Training Epoch: 64 [22528/50176]	Loss: 0.1842
Training Epoch: 64 [23552/50176]	Loss: 0.1552
Training Epoch: 64 [24576/50176]	Loss: 0.1575
Training Epoch: 64 [25600/50176]	Loss: 0.1816
Training Epoch: 64 [26624/50176]	Loss: 0.1990
Training Epoch: 64 [27648/50176]	Loss: 0.1494
Training Epoch: 64 [28672/50176]	Loss: 0.1732
Training Epoch: 64 [29696/50176]	Loss: 0.1945
Training Epoch: 64 [30720/50176]	Loss: 0.1924
Training Epoch: 64 [31744/50176]	Loss: 0.1952
Training Epoch: 64 [32768/50176]	Loss: 0.1742
Training Epoch: 64 [33792/50176]	Loss: 0.2014
Training Epoch: 64 [34816/50176]	Loss: 0.1564
Training Epoch: 64 [35840/50176]	Loss: 0.1887
Training Epoch: 64 [36864/50176]	Loss: 0.1872
Training Epoch: 64 [37888/50176]	Loss: 0.1617
Training Epoch: 64 [38912/50176]	Loss: 0.1867
Training Epoch: 64 [39936/50176]	Loss: 0.1820
Training Epoch: 64 [40960/50176]	Loss: 0.2187
Training Epoch: 64 [41984/50176]	Loss: 0.2035
Training Epoch: 64 [43008/50176]	Loss: 0.2091
Training Epoch: 64 [44032/50176]	Loss: 0.1724
Training Epoch: 64 [45056/50176]	Loss: 0.1975
Training Epoch: 64 [46080/50176]	Loss: 0.2058
Training Epoch: 64 [47104/50176]	Loss: 0.1685
Training Epoch: 64 [48128/50176]	Loss: 0.1790
Training Epoch: 64 [49152/50176]	Loss: 0.2075
Training Epoch: 64 [50176/50176]	Loss: 0.1723
2022-12-06 18:02:38.952 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:02:38,988 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.80 energy=486.41
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Up to epoch 65: time=3193.62, energy=444777.01, cost=501829.97
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:02:38,988 [ZeusDataLoader(train)] Expected next epoch: time=3240.89, energy=451560.96, cost=509358.42
2022-12-06 13:02:38,989 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0024, Accuracy: 0.5929
2022-12-06 13:02:39,221 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:02:39,222 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:02:39.232 [ZeusMonitor] Monitor started.
2022-12-06 18:02:39.232 [ZeusMonitor] Running indefinitely. 2022-12-06 18:02:39.232 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:02:39.232 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 13:03:23,579 [ZeusDataLoader(train)] train epoch 66 done: time=44.58 energy=6326.25
2022-12-06 13:03:23,582 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.1477
Training Epoch: 65 [2048/50176]	Loss: 0.1591
Training Epoch: 65 [3072/50176]	Loss: 0.1533
Training Epoch: 65 [4096/50176]	Loss: 0.1586
Training Epoch: 65 [5120/50176]	Loss: 0.1817
Training Epoch: 65 [6144/50176]	Loss: 0.1739
Training Epoch: 65 [7168/50176]	Loss: 0.1689
Training Epoch: 65 [8192/50176]	Loss: 0.1536
Training Epoch: 65 [9216/50176]	Loss: 0.1433
Training Epoch: 65 [10240/50176]	Loss: 0.1553
Training Epoch: 65 [11264/50176]	Loss: 0.1655
Training Epoch: 65 [12288/50176]	Loss: 0.1710
Training Epoch: 65 [13312/50176]	Loss: 0.1702
Training Epoch: 65 [14336/50176]	Loss: 0.1683
Training Epoch: 65 [15360/50176]	Loss: 0.1776
Training Epoch: 65 [16384/50176]	Loss: 0.1932
Training Epoch: 65 [17408/50176]	Loss: 0.1438
Training Epoch: 65 [18432/50176]	Loss: 0.1524
Training Epoch: 65 [19456/50176]	Loss: 0.1280
Training Epoch: 65 [20480/50176]	Loss: 0.1895
Training Epoch: 65 [21504/50176]	Loss: 0.2007
Training Epoch: 65 [22528/50176]	Loss: 0.1642
Training Epoch: 65 [23552/50176]	Loss: 0.1616
Training Epoch: 65 [24576/50176]	Loss: 0.1706
Training Epoch: 65 [25600/50176]	Loss: 0.1824
Training Epoch: 65 [26624/50176]	Loss: 0.1644
Training Epoch: 65 [27648/50176]	Loss: 0.2265
Training Epoch: 65 [28672/50176]	Loss: 0.1455
Training Epoch: 65 [29696/50176]	Loss: 0.1557
Training Epoch: 65 [30720/50176]	Loss: 0.1836
Training Epoch: 65 [31744/50176]	Loss: 0.1858
Training Epoch: 65 [32768/50176]	Loss: 0.1646
Training Epoch: 65 [33792/50176]	Loss: 0.1617
Training Epoch: 65 [34816/50176]	Loss: 0.1917
Training Epoch: 65 [35840/50176]	Loss: 0.1652
Training Epoch: 65 [36864/50176]	Loss: 0.1883
Training Epoch: 65 [37888/50176]	Loss: 0.1785
Training Epoch: 65 [38912/50176]	Loss: 0.2002
Training Epoch: 65 [39936/50176]	Loss: 0.1768
Training Epoch: 65 [40960/50176]	Loss: 0.1765
Training Epoch: 65 [41984/50176]	Loss: 0.1740
Training Epoch: 65 [43008/50176]	Loss: 0.1839
Training Epoch: 65 [44032/50176]	Loss: 0.1542
Training Epoch: 65 [45056/50176]	Loss: 0.1862
Training Epoch: 65 [46080/50176]	Loss: 0.1743
Training Epoch: 65 [47104/50176]	Loss: 0.1624
Training Epoch: 65 [48128/50176]	Loss: 0.1842
Training Epoch: 65 [49152/50176]	Loss: 0.2019
Training Epoch: 65 [50176/50176]	Loss: 0.2138
2022-12-06 18:03:27.375 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:03:27,387 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.80 energy=488.52
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Up to epoch 66: time=3242.00, energy=451591.79, cost=509470.46
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:03:27,387 [ZeusDataLoader(train)] Expected next epoch: time=3289.27, energy=458375.74, cost=516998.91
2022-12-06 13:03:27,388 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0024, Accuracy: 0.5945
2022-12-06 13:03:27,613 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:03:27,613 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:03:27.615 [ZeusMonitor] Monitor started.
2022-12-06 18:03:27.615 [ZeusMonitor] Running indefinitely. 2022-12-06 18:03:27.615 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:03:27.615 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 13:04:12,028 [ZeusDataLoader(train)] train epoch 67 done: time=44.63 energy=6339.96
2022-12-06 13:04:12,031 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.1652
Training Epoch: 66 [2048/50176]	Loss: 0.1464
Training Epoch: 66 [3072/50176]	Loss: 0.1496
Training Epoch: 66 [4096/50176]	Loss: 0.1696
Training Epoch: 66 [5120/50176]	Loss: 0.1625
Training Epoch: 66 [6144/50176]	Loss: 0.1356
Training Epoch: 66 [7168/50176]	Loss: 0.1652
Training Epoch: 66 [8192/50176]	Loss: 0.1936
Training Epoch: 66 [9216/50176]	Loss: 0.1793
Training Epoch: 66 [10240/50176]	Loss: 0.1837
Training Epoch: 66 [11264/50176]	Loss: 0.1553
Training Epoch: 66 [12288/50176]	Loss: 0.1503
Training Epoch: 66 [13312/50176]	Loss: 0.1841
Training Epoch: 66 [14336/50176]	Loss: 0.1580
Training Epoch: 66 [15360/50176]	Loss: 0.1441
Training Epoch: 66 [16384/50176]	Loss: 0.1436
Training Epoch: 66 [17408/50176]	Loss: 0.1928
Training Epoch: 66 [18432/50176]	Loss: 0.1626
Training Epoch: 66 [19456/50176]	Loss: 0.1753
Training Epoch: 66 [20480/50176]	Loss: 0.1923
Training Epoch: 66 [21504/50176]	Loss: 0.1486
Training Epoch: 66 [22528/50176]	Loss: 0.1530
Training Epoch: 66 [23552/50176]	Loss: 0.2095
Training Epoch: 66 [24576/50176]	Loss: 0.1649
Training Epoch: 66 [25600/50176]	Loss: 0.1601
Training Epoch: 66 [26624/50176]	Loss: 0.1783
Training Epoch: 66 [27648/50176]	Loss: 0.1940
Training Epoch: 66 [28672/50176]	Loss: 0.1891
Training Epoch: 66 [29696/50176]	Loss: 0.1483
Training Epoch: 66 [30720/50176]	Loss: 0.1518
Training Epoch: 66 [31744/50176]	Loss: 0.1852
Training Epoch: 66 [32768/50176]	Loss: 0.1539
Training Epoch: 66 [33792/50176]	Loss: 0.1773
Training Epoch: 66 [34816/50176]	Loss: 0.1887
Training Epoch: 66 [35840/50176]	Loss: 0.2072
Training Epoch: 66 [36864/50176]	Loss: 0.1629
Training Epoch: 66 [37888/50176]	Loss: 0.1665
Training Epoch: 66 [38912/50176]	Loss: 0.1723
Training Epoch: 66 [39936/50176]	Loss: 0.2175
Training Epoch: 66 [40960/50176]	Loss: 0.2006
Training Epoch: 66 [41984/50176]	Loss: 0.2154
Training Epoch: 66 [43008/50176]	Loss: 0.1819
Training Epoch: 66 [44032/50176]	Loss: 0.1697
Training Epoch: 66 [45056/50176]	Loss: 0.1809
Training Epoch: 66 [46080/50176]	Loss: 0.1863
Training Epoch: 66 [47104/50176]	Loss: 0.1754
Training Epoch: 66 [48128/50176]	Loss: 0.1928
Training Epoch: 66 [49152/50176]	Loss: 0.1745
Training Epoch: 66 [50176/50176]	Loss: 0.1904
2022-12-06 18:04:15.774 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:04:15,824 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.78 energy=490.77
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Up to epoch 67: time=3290.41, energy=458422.52, cost=517122.28
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:04:15,824 [ZeusDataLoader(train)] Expected next epoch: time=3337.69, energy=465206.47, cost=524650.74
2022-12-06 13:04:15,825 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0025, Accuracy: 0.5889
2022-12-06 13:04:16,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:04:16,033 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:04:16.047 [ZeusMonitor] Monitor started.
2022-12-06 18:04:16.047 [ZeusMonitor] Running indefinitely. 2022-12-06 18:04:16.047 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:04:16.047 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 13:05:00,217 [ZeusDataLoader(train)] train epoch 68 done: time=44.38 energy=6319.72
2022-12-06 13:05:00,220 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.1249
Training Epoch: 67 [2048/50176]	Loss: 0.1673
Training Epoch: 67 [3072/50176]	Loss: 0.1613
Training Epoch: 67 [4096/50176]	Loss: 0.1522
Training Epoch: 67 [5120/50176]	Loss: 0.1682
Training Epoch: 67 [6144/50176]	Loss: 0.1640
Training Epoch: 67 [7168/50176]	Loss: 0.1620
Training Epoch: 67 [8192/50176]	Loss: 0.1429
Training Epoch: 67 [9216/50176]	Loss: 0.1660
Training Epoch: 67 [10240/50176]	Loss: 0.1654
Training Epoch: 67 [11264/50176]	Loss: 0.1881
Training Epoch: 67 [12288/50176]	Loss: 0.1678
Training Epoch: 67 [13312/50176]	Loss: 0.1671
Training Epoch: 67 [14336/50176]	Loss: 0.1803
Training Epoch: 67 [15360/50176]	Loss: 0.1794
Training Epoch: 67 [16384/50176]	Loss: 0.1656
Training Epoch: 67 [17408/50176]	Loss: 0.1576
Training Epoch: 67 [18432/50176]	Loss: 0.1779
Training Epoch: 67 [19456/50176]	Loss: 0.2022
Training Epoch: 67 [20480/50176]	Loss: 0.1746
Training Epoch: 67 [21504/50176]	Loss: 0.1747
Training Epoch: 67 [22528/50176]	Loss: 0.1385
Training Epoch: 67 [23552/50176]	Loss: 0.1933
Training Epoch: 67 [24576/50176]	Loss: 0.1848
Training Epoch: 67 [25600/50176]	Loss: 0.1881
Training Epoch: 67 [26624/50176]	Loss: 0.1997
Training Epoch: 67 [27648/50176]	Loss: 0.1753
Training Epoch: 67 [28672/50176]	Loss: 0.1834
Training Epoch: 67 [29696/50176]	Loss: 0.1487
Training Epoch: 67 [30720/50176]	Loss: 0.1632
Training Epoch: 67 [31744/50176]	Loss: 0.2075
Training Epoch: 67 [32768/50176]	Loss: 0.1900
Training Epoch: 67 [33792/50176]	Loss: 0.1675
Training Epoch: 67 [34816/50176]	Loss: 0.1661
Training Epoch: 67 [35840/50176]	Loss: 0.1807
Training Epoch: 67 [36864/50176]	Loss: 0.1634
Training Epoch: 67 [37888/50176]	Loss: 0.1691
Training Epoch: 67 [38912/50176]	Loss: 0.1917
Training Epoch: 67 [39936/50176]	Loss: 0.1842
Training Epoch: 67 [40960/50176]	Loss: 0.1752
Training Epoch: 67 [41984/50176]	Loss: 0.2001
Training Epoch: 67 [43008/50176]	Loss: 0.1966
Training Epoch: 67 [44032/50176]	Loss: 0.1959
Training Epoch: 67 [45056/50176]	Loss: 0.1840
Training Epoch: 67 [46080/50176]	Loss: 0.1977
Training Epoch: 67 [47104/50176]	Loss: 0.1749
Training Epoch: 67 [48128/50176]	Loss: 0.1830
Training Epoch: 67 [49152/50176]	Loss: 0.1676
Training Epoch: 67 [50176/50176]	Loss: 0.1815
2022-12-06 18:05:03.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:05:03,955 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.73 energy=478.02
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Up to epoch 68: time=3338.52, energy=465220.26, cost=524730.88
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:05:03,955 [ZeusDataLoader(train)] Expected next epoch: time=3385.80, energy=472004.21, cost=532259.34
2022-12-06 13:05:03,956 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0025, Accuracy: 0.5895
2022-12-06 13:05:04,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:05:04,174 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:05:04.176 [ZeusMonitor] Monitor started.
2022-12-06 18:05:04.176 [ZeusMonitor] Running indefinitely. 2022-12-06 18:05:04.176 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:05:04.176 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 13:05:48,209 [ZeusDataLoader(train)] train epoch 69 done: time=44.24 energy=6323.26
2022-12-06 13:05:48,212 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.1722
Training Epoch: 68 [2048/50176]	Loss: 0.1594
Training Epoch: 68 [3072/50176]	Loss: 0.1537
Training Epoch: 68 [4096/50176]	Loss: 0.1311
Training Epoch: 68 [5120/50176]	Loss: 0.1343
Training Epoch: 68 [6144/50176]	Loss: 0.1345
Training Epoch: 68 [7168/50176]	Loss: 0.1672
Training Epoch: 68 [8192/50176]	Loss: 0.1522
Training Epoch: 68 [9216/50176]	Loss: 0.1874
Training Epoch: 68 [10240/50176]	Loss: 0.1516
Training Epoch: 68 [11264/50176]	Loss: 0.1306
Training Epoch: 68 [12288/50176]	Loss: 0.1444
Training Epoch: 68 [13312/50176]	Loss: 0.1589
Training Epoch: 68 [14336/50176]	Loss: 0.1695
Training Epoch: 68 [15360/50176]	Loss: 0.1486
Training Epoch: 68 [16384/50176]	Loss: 0.1648
Training Epoch: 68 [17408/50176]	Loss: 0.1403
Training Epoch: 68 [18432/50176]	Loss: 0.1600
Training Epoch: 68 [19456/50176]	Loss: 0.1626
Training Epoch: 68 [20480/50176]	Loss: 0.1444
Training Epoch: 68 [21504/50176]	Loss: 0.1746
Training Epoch: 68 [22528/50176]	Loss: 0.1645
Training Epoch: 68 [23552/50176]	Loss: 0.1421
Training Epoch: 68 [24576/50176]	Loss: 0.1635
Training Epoch: 68 [25600/50176]	Loss: 0.1788
Training Epoch: 68 [26624/50176]	Loss: 0.1902
Training Epoch: 68 [27648/50176]	Loss: 0.1629
Training Epoch: 68 [28672/50176]	Loss: 0.1521
Training Epoch: 68 [29696/50176]	Loss: 0.1480
Training Epoch: 68 [30720/50176]	Loss: 0.1673
Training Epoch: 68 [31744/50176]	Loss: 0.1842
Training Epoch: 68 [32768/50176]	Loss: 0.1938
Training Epoch: 68 [33792/50176]	Loss: 0.1428
Training Epoch: 68 [34816/50176]	Loss: 0.1606
Training Epoch: 68 [35840/50176]	Loss: 0.1642
Training Epoch: 68 [36864/50176]	Loss: 0.1922
Training Epoch: 68 [37888/50176]	Loss: 0.1556
Training Epoch: 68 [38912/50176]	Loss: 0.1555
Training Epoch: 68 [39936/50176]	Loss: 0.2104
Training Epoch: 68 [40960/50176]	Loss: 0.1929
Training Epoch: 68 [41984/50176]	Loss: 0.1778
Training Epoch: 68 [43008/50176]	Loss: 0.1882
Training Epoch: 68 [44032/50176]	Loss: 0.1761
Training Epoch: 68 [45056/50176]	Loss: 0.1790
Training Epoch: 68 [46080/50176]	Loss: 0.1646
Training Epoch: 68 [47104/50176]	Loss: 0.1896
Training Epoch: 68 [48128/50176]	Loss: 0.2159
Training Epoch: 68 [49152/50176]	Loss: 0.1878
Training Epoch: 68 [50176/50176]	Loss: 0.1841
2022-12-06 18:05:51.916 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:05:51,930 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.71 energy=473.11
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Up to epoch 69: time=3386.48, energy=472016.62, cost=532325.14
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:05:51,931 [ZeusDataLoader(train)] Expected next epoch: time=3433.75, energy=478800.58, cost=539853.60
2022-12-06 13:05:51,932 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0025, Accuracy: 0.5861
2022-12-06 13:05:52,153 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:05:52,154 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:05:52.156 [ZeusMonitor] Monitor started.
2022-12-06 18:05:52.156 [ZeusMonitor] Running indefinitely. 2022-12-06 18:05:52.156 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:05:52.156 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 13:06:36,492 [ZeusDataLoader(train)] train epoch 70 done: time=44.55 energy=6341.13
2022-12-06 13:06:36,495 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.1233
Training Epoch: 69 [2048/50176]	Loss: 0.1269
Training Epoch: 69 [3072/50176]	Loss: 0.1689
Training Epoch: 69 [4096/50176]	Loss: 0.1365
Training Epoch: 69 [5120/50176]	Loss: 0.1291
Training Epoch: 69 [6144/50176]	Loss: 0.1501
Training Epoch: 69 [7168/50176]	Loss: 0.1368
Training Epoch: 69 [8192/50176]	Loss: 0.1313
Training Epoch: 69 [9216/50176]	Loss: 0.1630
Training Epoch: 69 [10240/50176]	Loss: 0.1654
Training Epoch: 69 [11264/50176]	Loss: 0.1351
Training Epoch: 69 [12288/50176]	Loss: 0.1397
Training Epoch: 69 [13312/50176]	Loss: 0.1403
Training Epoch: 69 [14336/50176]	Loss: 0.1557
Training Epoch: 69 [15360/50176]	Loss: 0.1376
Training Epoch: 69 [16384/50176]	Loss: 0.1301
Training Epoch: 69 [17408/50176]	Loss: 0.1751
Training Epoch: 69 [18432/50176]	Loss: 0.1668
Training Epoch: 69 [19456/50176]	Loss: 0.1480
Training Epoch: 69 [20480/50176]	Loss: 0.1444
Training Epoch: 69 [21504/50176]	Loss: 0.1428
Training Epoch: 69 [22528/50176]	Loss: 0.2138
Training Epoch: 69 [23552/50176]	Loss: 0.1691
Training Epoch: 69 [24576/50176]	Loss: 0.1469
Training Epoch: 69 [25600/50176]	Loss: 0.1812
Training Epoch: 69 [26624/50176]	Loss: 0.1497
Training Epoch: 69 [27648/50176]	Loss: 0.1661
Training Epoch: 69 [28672/50176]	Loss: 0.1557
Training Epoch: 69 [29696/50176]	Loss: 0.1441
Training Epoch: 69 [30720/50176]	Loss: 0.1591
Training Epoch: 69 [31744/50176]	Loss: 0.1738
Training Epoch: 69 [32768/50176]	Loss: 0.1498
Training Epoch: 69 [33792/50176]	Loss: 0.1728
Training Epoch: 69 [34816/50176]	Loss: 0.1328
Training Epoch: 69 [35840/50176]	Loss: 0.1385
Training Epoch: 69 [36864/50176]	Loss: 0.1507
Training Epoch: 69 [37888/50176]	Loss: 0.1677
Training Epoch: 69 [38912/50176]	Loss: 0.1637
Training Epoch: 69 [39936/50176]	Loss: 0.1736
Training Epoch: 69 [40960/50176]	Loss: 0.1752
Training Epoch: 69 [41984/50176]	Loss: 0.1790
Training Epoch: 69 [43008/50176]	Loss: 0.1590
Training Epoch: 69 [44032/50176]	Loss: 0.1429
Training Epoch: 69 [45056/50176]	Loss: 0.1824
Training Epoch: 69 [46080/50176]	Loss: 0.1531
Training Epoch: 69 [47104/50176]	Loss: 0.1888
Training Epoch: 69 [48128/50176]	Loss: 0.1708
Training Epoch: 69 [49152/50176]	Loss: 0.1733
Training Epoch: 69 [50176/50176]	Loss: 0.2030
2022-12-06 18:06:40.173 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:06:40,192 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.69 energy=461.84
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Up to epoch 70: time=3434.72, energy=478819.60, cost=539947.75
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:06:40,193 [ZeusDataLoader(train)] Expected next epoch: time=3481.99, energy=485603.55, cost=547476.20
2022-12-06 13:06:40,194 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0024, Accuracy: 0.5967
2022-12-06 13:06:40,410 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:06:40,411 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:06:40.413 [ZeusMonitor] Monitor started.
2022-12-06 18:06:40.413 [ZeusMonitor] Running indefinitely. 2022-12-06 18:06:40.413 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:06:40.413 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 13:07:25,003 [ZeusDataLoader(train)] train epoch 71 done: time=44.80 energy=6344.43
2022-12-06 13:07:25,006 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.1248
Training Epoch: 70 [2048/50176]	Loss: 0.1334
Training Epoch: 70 [3072/50176]	Loss: 0.1283
Training Epoch: 70 [4096/50176]	Loss: 0.1334
Training Epoch: 70 [5120/50176]	Loss: 0.1815
Training Epoch: 70 [6144/50176]	Loss: 0.1141
Training Epoch: 70 [7168/50176]	Loss: 0.1691
Training Epoch: 70 [8192/50176]	Loss: 0.1542
Training Epoch: 70 [9216/50176]	Loss: 0.1631
Training Epoch: 70 [10240/50176]	Loss: 0.1656
Training Epoch: 70 [11264/50176]	Loss: 0.1183
Training Epoch: 70 [12288/50176]	Loss: 0.1472
Training Epoch: 70 [13312/50176]	Loss: 0.1502
Training Epoch: 70 [14336/50176]	Loss: 0.1802
Training Epoch: 70 [15360/50176]	Loss: 0.1925
Training Epoch: 70 [16384/50176]	Loss: 0.1528
Training Epoch: 70 [17408/50176]	Loss: 0.1530
Training Epoch: 70 [18432/50176]	Loss: 0.1299
Training Epoch: 70 [19456/50176]	Loss: 0.1679
Training Epoch: 70 [20480/50176]	Loss: 0.1717
Training Epoch: 70 [21504/50176]	Loss: 0.1727
Training Epoch: 70 [22528/50176]	Loss: 0.1691
Training Epoch: 70 [23552/50176]	Loss: 0.1716
Training Epoch: 70 [24576/50176]	Loss: 0.1530
Training Epoch: 70 [25600/50176]	Loss: 0.1470
Training Epoch: 70 [26624/50176]	Loss: 0.1712
Training Epoch: 70 [27648/50176]	Loss: 0.1801
Training Epoch: 70 [28672/50176]	Loss: 0.1391
Training Epoch: 70 [29696/50176]	Loss: 0.1761
Training Epoch: 70 [30720/50176]	Loss: 0.1261
Training Epoch: 70 [31744/50176]	Loss: 0.1622
Training Epoch: 70 [32768/50176]	Loss: 0.1767
Training Epoch: 70 [33792/50176]	Loss: 0.1604
Training Epoch: 70 [34816/50176]	Loss: 0.1448
Training Epoch: 70 [35840/50176]	Loss: 0.1766
Training Epoch: 70 [36864/50176]	Loss: 0.1903
Training Epoch: 70 [37888/50176]	Loss: 0.1796
Training Epoch: 70 [38912/50176]	Loss: 0.1751
Training Epoch: 70 [39936/50176]	Loss: 0.1632
Training Epoch: 70 [40960/50176]	Loss: 0.2042
Training Epoch: 70 [41984/50176]	Loss: 0.1701
Training Epoch: 70 [43008/50176]	Loss: 0.1535
Training Epoch: 70 [44032/50176]	Loss: 0.1782
Training Epoch: 70 [45056/50176]	Loss: 0.2004
Training Epoch: 70 [46080/50176]	Loss: 0.1520
Training Epoch: 70 [47104/50176]	Loss: 0.1605
Training Epoch: 70 [48128/50176]	Loss: 0.1559
Training Epoch: 70 [49152/50176]	Loss: 0.2130
Training Epoch: 70 [50176/50176]	Loss: 0.1892
2022-12-06 18:07:28.728 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:07:28,742 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.73 energy=478.58
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Up to epoch 71: time=3483.25, energy=485642.61, cost=547605.57
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:07:28,743 [ZeusDataLoader(train)] Expected next epoch: time=3530.52, energy=492426.56, cost=555134.02
2022-12-06 13:07:28,744 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0026, Accuracy: 0.5861
2022-12-06 13:07:28,944 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:07:28,945 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:07:28.947 [ZeusMonitor] Monitor started.
2022-12-06 18:07:28.947 [ZeusMonitor] Running indefinitely. 2022-12-06 18:07:28.947 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:07:28.947 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 13:08:13,010 [ZeusDataLoader(train)] train epoch 72 done: time=44.26 energy=6323.49
2022-12-06 13:08:13,013 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.1614
Training Epoch: 71 [2048/50176]	Loss: 0.1561
Training Epoch: 71 [3072/50176]	Loss: 0.1456
Training Epoch: 71 [4096/50176]	Loss: 0.1373
Training Epoch: 71 [5120/50176]	Loss: 0.1427
Training Epoch: 71 [6144/50176]	Loss: 0.1411
Training Epoch: 71 [7168/50176]	Loss: 0.1516
Training Epoch: 71 [8192/50176]	Loss: 0.1517
Training Epoch: 71 [9216/50176]	Loss: 0.1336
Training Epoch: 71 [10240/50176]	Loss: 0.1558
Training Epoch: 71 [11264/50176]	Loss: 0.1390
Training Epoch: 71 [12288/50176]	Loss: 0.1672
Training Epoch: 71 [13312/50176]	Loss: 0.1612
Training Epoch: 71 [14336/50176]	Loss: 0.1636
Training Epoch: 71 [15360/50176]	Loss: 0.1483
Training Epoch: 71 [16384/50176]	Loss: 0.1475
Training Epoch: 71 [17408/50176]	Loss: 0.1447
Training Epoch: 71 [18432/50176]	Loss: 0.1512
Training Epoch: 71 [19456/50176]	Loss: 0.1572
Training Epoch: 71 [20480/50176]	Loss: 0.1682
Training Epoch: 71 [21504/50176]	Loss: 0.1255
Training Epoch: 71 [22528/50176]	Loss: 0.1388
Training Epoch: 71 [23552/50176]	Loss: 0.1661
Training Epoch: 71 [24576/50176]	Loss: 0.1521
Training Epoch: 71 [25600/50176]	Loss: 0.1748
Training Epoch: 71 [26624/50176]	Loss: 0.1585
Training Epoch: 71 [27648/50176]	Loss: 0.1522
Training Epoch: 71 [28672/50176]	Loss: 0.1587
Training Epoch: 71 [29696/50176]	Loss: 0.1692
Training Epoch: 71 [30720/50176]	Loss: 0.1292
Training Epoch: 71 [31744/50176]	Loss: 0.1424
Training Epoch: 71 [32768/50176]	Loss: 0.1712
Training Epoch: 71 [33792/50176]	Loss: 0.1721
Training Epoch: 71 [34816/50176]	Loss: 0.1548
Training Epoch: 71 [35840/50176]	Loss: 0.1509
Training Epoch: 71 [36864/50176]	Loss: 0.1657
Training Epoch: 71 [37888/50176]	Loss: 0.1532
Training Epoch: 71 [38912/50176]	Loss: 0.1506
Training Epoch: 71 [39936/50176]	Loss: 0.1292
Training Epoch: 71 [40960/50176]	Loss: 0.1370
Training Epoch: 71 [41984/50176]	Loss: 0.1477
Training Epoch: 71 [43008/50176]	Loss: 0.1594
Training Epoch: 71 [44032/50176]	Loss: 0.1647
Training Epoch: 71 [45056/50176]	Loss: 0.1658
Training Epoch: 71 [46080/50176]	Loss: 0.1591
Training Epoch: 71 [47104/50176]	Loss: 0.1636
Training Epoch: 71 [48128/50176]	Loss: 0.1630
Training Epoch: 71 [49152/50176]	Loss: 0.1416
Training Epoch: 71 [50176/50176]	Loss: 0.1785
2022-12-06 18:08:16.750 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:08:16,793 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.77 energy=476.64
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Up to epoch 72: time=3531.28, energy=492442.73, cost=555208.25
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:08:16,793 [ZeusDataLoader(train)] Expected next epoch: time=3578.55, energy=499226.68, cost=562736.70
2022-12-06 13:08:16,794 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0024, Accuracy: 0.5970
2022-12-06 13:08:17,010 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:08:17,011 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:08:17.012 [ZeusMonitor] Monitor started.
2022-12-06 18:08:17.013 [ZeusMonitor] Running indefinitely. 2022-12-06 18:08:17.013 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:08:17.013 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 13:09:00,993 [ZeusDataLoader(train)] train epoch 73 done: time=44.19 energy=6305.67
2022-12-06 13:09:00,996 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.1752
Training Epoch: 72 [2048/50176]	Loss: 0.1348
Training Epoch: 72 [3072/50176]	Loss: 0.1255
Training Epoch: 72 [4096/50176]	Loss: 0.1592
Training Epoch: 72 [5120/50176]	Loss: 0.1024
Training Epoch: 72 [6144/50176]	Loss: 0.1181
Training Epoch: 72 [7168/50176]	Loss: 0.1452
Training Epoch: 72 [8192/50176]	Loss: 0.1151
Training Epoch: 72 [9216/50176]	Loss: 0.1594
Training Epoch: 72 [10240/50176]	Loss: 0.1433
Training Epoch: 72 [11264/50176]	Loss: 0.1431
Training Epoch: 72 [12288/50176]	Loss: 0.1418
Training Epoch: 72 [13312/50176]	Loss: 0.1558
Training Epoch: 72 [14336/50176]	Loss: 0.1281
Training Epoch: 72 [15360/50176]	Loss: 0.1183
Training Epoch: 72 [16384/50176]	Loss: 0.1633
Training Epoch: 72 [17408/50176]	Loss: 0.1504
Training Epoch: 72 [18432/50176]	Loss: 0.1492
Training Epoch: 72 [19456/50176]	Loss: 0.1358
Training Epoch: 72 [20480/50176]	Loss: 0.1410
Training Epoch: 72 [21504/50176]	Loss: 0.1338
Training Epoch: 72 [22528/50176]	Loss: 0.1673
Training Epoch: 72 [23552/50176]	Loss: 0.1365
Training Epoch: 72 [24576/50176]	Loss: 0.1626
Training Epoch: 72 [25600/50176]	Loss: 0.1289
Training Epoch: 72 [26624/50176]	Loss: 0.1555
Training Epoch: 72 [27648/50176]	Loss: 0.1454
Training Epoch: 72 [28672/50176]	Loss: 0.1324
Training Epoch: 72 [29696/50176]	Loss: 0.1743
Training Epoch: 72 [30720/50176]	Loss: 0.1518
Training Epoch: 72 [31744/50176]	Loss: 0.1289
Training Epoch: 72 [32768/50176]	Loss: 0.1567
Training Epoch: 72 [33792/50176]	Loss: 0.1227
Training Epoch: 72 [34816/50176]	Loss: 0.1304
Training Epoch: 72 [35840/50176]	Loss: 0.1762
Training Epoch: 72 [36864/50176]	Loss: 0.1771
Training Epoch: 72 [37888/50176]	Loss: 0.1478
Training Epoch: 72 [38912/50176]	Loss: 0.1636
Training Epoch: 72 [39936/50176]	Loss: 0.1477
Training Epoch: 72 [40960/50176]	Loss: 0.1635
Training Epoch: 72 [41984/50176]	Loss: 0.1585
Training Epoch: 72 [43008/50176]	Loss: 0.1643
Training Epoch: 72 [44032/50176]	Loss: 0.1547
Training Epoch: 72 [45056/50176]	Loss: 0.1621
Training Epoch: 72 [46080/50176]	Loss: 0.1952
Training Epoch: 72 [47104/50176]	Loss: 0.1492
Training Epoch: 72 [48128/50176]	Loss: 0.1532
Training Epoch: 72 [49152/50176]	Loss: 0.1846
Training Epoch: 72 [50176/50176]	Loss: 0.1527
2022-12-06 18:09:04.711 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:09:04,733 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.73 energy=473.96
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Up to epoch 73: time=3579.20, energy=499222.37, cost=562791.05
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:09:04,733 [ZeusDataLoader(train)] Expected next epoch: time=3626.47, energy=506006.32, cost=570319.50
2022-12-06 13:09:04,734 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0026, Accuracy: 0.5908
2022-12-06 13:09:04,897 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:09:04,897 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:09:04.901 [ZeusMonitor] Monitor started.
2022-12-06 18:09:04.901 [ZeusMonitor] Running indefinitely. 2022-12-06 18:09:04.901 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:09:04.901 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 13:09:49,210 [ZeusDataLoader(train)] train epoch 74 done: time=44.47 energy=6327.06
2022-12-06 13:09:49,213 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.1417
Training Epoch: 73 [2048/50176]	Loss: 0.1216
Training Epoch: 73 [3072/50176]	Loss: 0.1304
Training Epoch: 73 [4096/50176]	Loss: 0.1301
Training Epoch: 73 [5120/50176]	Loss: 0.1418
Training Epoch: 73 [6144/50176]	Loss: 0.1568
Training Epoch: 73 [7168/50176]	Loss: 0.1210
Training Epoch: 73 [8192/50176]	Loss: 0.1333
Training Epoch: 73 [9216/50176]	Loss: 0.1253
Training Epoch: 73 [10240/50176]	Loss: 0.1321
Training Epoch: 73 [11264/50176]	Loss: 0.1273
Training Epoch: 73 [12288/50176]	Loss: 0.1334
Training Epoch: 73 [13312/50176]	Loss: 0.1187
Training Epoch: 73 [14336/50176]	Loss: 0.1412
Training Epoch: 73 [15360/50176]	Loss: 0.1554
Training Epoch: 73 [16384/50176]	Loss: 0.1358
Training Epoch: 73 [17408/50176]	Loss: 0.1233
Training Epoch: 73 [18432/50176]	Loss: 0.1500
Training Epoch: 73 [19456/50176]	Loss: 0.1411
Training Epoch: 73 [20480/50176]	Loss: 0.1361
Training Epoch: 73 [21504/50176]	Loss: 0.1020
Training Epoch: 73 [22528/50176]	Loss: 0.1342
Training Epoch: 73 [23552/50176]	Loss: 0.1490
Training Epoch: 73 [24576/50176]	Loss: 0.1346
Training Epoch: 73 [25600/50176]	Loss: 0.1239
Training Epoch: 73 [26624/50176]	Loss: 0.1332
Training Epoch: 73 [27648/50176]	Loss: 0.1494
Training Epoch: 73 [28672/50176]	Loss: 0.1612
Training Epoch: 73 [29696/50176]	Loss: 0.1557
Training Epoch: 73 [30720/50176]	Loss: 0.1358
Training Epoch: 73 [31744/50176]	Loss: 0.1797
Training Epoch: 73 [32768/50176]	Loss: 0.1460
Training Epoch: 73 [33792/50176]	Loss: 0.1559
Training Epoch: 73 [34816/50176]	Loss: 0.1561
Training Epoch: 73 [35840/50176]	Loss: 0.1338
Training Epoch: 73 [36864/50176]	Loss: 0.1525
Training Epoch: 73 [37888/50176]	Loss: 0.1584
Training Epoch: 73 [38912/50176]	Loss: 0.1736
Training Epoch: 73 [39936/50176]	Loss: 0.1447
Training Epoch: 73 [40960/50176]	Loss: 0.1612
Training Epoch: 73 [41984/50176]	Loss: 0.1409
Training Epoch: 73 [43008/50176]	Loss: 0.1709
Training Epoch: 73 [44032/50176]	Loss: 0.1796
Training Epoch: 73 [45056/50176]	Loss: 0.1432
Training Epoch: 73 [46080/50176]	Loss: 0.1418
Training Epoch: 73 [47104/50176]	Loss: 0.1565
Training Epoch: 73 [48128/50176]	Loss: 0.1627
Training Epoch: 73 [49152/50176]	Loss: 0.1549
Training Epoch: 73 [50176/50176]	Loss: 0.1345
2022-12-06 18:09:52.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:09:53,009 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.79 energy=489.64
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Up to epoch 74: time=3627.45, energy=506039.07, cost=570421.82
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.27 energy=6783.95
2022-12-06 13:09:53,010 [ZeusDataLoader(train)] Expected next epoch: time=3674.73, energy=512823.02, cost=577950.27
2022-12-06 13:09:53,011 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0028, Accuracy: 0.5645
2022-12-06 13:09:53,177 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:09:53,178 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 18:09:53.181 [ZeusMonitor] Monitor started.
2022-12-06 18:09:53.181 [ZeusMonitor] Running indefinitely. 2022-12-06 18:09:53.181 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:09:53.181 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 13:10:37,742 [ZeusDataLoader(train)] train epoch 75 done: time=44.72 energy=6336.45
2022-12-06 13:10:37,747 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.1173
Training Epoch: 74 [2048/50176]	Loss: 0.1258
Training Epoch: 74 [3072/50176]	Loss: 0.1016
Training Epoch: 74 [4096/50176]	Loss: 0.1100
Training Epoch: 74 [5120/50176]	Loss: 0.1422
Training Epoch: 74 [6144/50176]	Loss: 0.1239
Training Epoch: 74 [7168/50176]	Loss: 0.0985
Training Epoch: 74 [8192/50176]	Loss: 0.1226
Training Epoch: 74 [9216/50176]	Loss: 0.1191
Training Epoch: 74 [10240/50176]	Loss: 0.1464
Training Epoch: 74 [11264/50176]	Loss: 0.1254
Training Epoch: 74 [12288/50176]	Loss: 0.1308
Training Epoch: 74 [13312/50176]	Loss: 0.1212
Training Epoch: 74 [14336/50176]	Loss: 0.1246
Training Epoch: 74 [15360/50176]	Loss: 0.1197
Training Epoch: 74 [16384/50176]	Loss: 0.1188
Training Epoch: 74 [17408/50176]	Loss: 0.1042
Training Epoch: 74 [18432/50176]	Loss: 0.1309
Training Epoch: 74 [19456/50176]	Loss: 0.1186
Training Epoch: 74 [20480/50176]	Loss: 0.1353
Training Epoch: 74 [21504/50176]	Loss: 0.1102
Training Epoch: 74 [22528/50176]	Loss: 0.1107
Training Epoch: 74 [23552/50176]	Loss: 0.1586
Training Epoch: 74 [24576/50176]	Loss: 0.1423
Training Epoch: 74 [25600/50176]	Loss: 0.1233
Training Epoch: 74 [26624/50176]	Loss: 0.1161
Training Epoch: 74 [27648/50176]	Loss: 0.1443
Training Epoch: 74 [28672/50176]	Loss: 0.1271
Training Epoch: 74 [29696/50176]	Loss: 0.1257
Training Epoch: 74 [30720/50176]	Loss: 0.1693
Training Epoch: 74 [31744/50176]	Loss: 0.1629
Training Epoch: 74 [32768/50176]	Loss: 0.1643
Training Epoch: 74 [33792/50176]	Loss: 0.1646
Training Epoch: 74 [34816/50176]	Loss: 0.1494
Training Epoch: 74 [35840/50176]	Loss: 0.1256
Training Epoch: 74 [36864/50176]	Loss: 0.1341
Training Epoch: 74 [37888/50176]	Loss: 0.1449
Training Epoch: 74 [38912/50176]	Loss: 0.1549
Training Epoch: 74 [39936/50176]	Loss: 0.1626
Training Epoch: 74 [40960/50176]	Loss: 0.1582
Training Epoch: 74 [41984/50176]	Loss: 0.1389
Training Epoch: 74 [43008/50176]	Loss: 0.1470
Training Epoch: 74 [44032/50176]	Loss: 0.1483
Training Epoch: 74 [45056/50176]	Loss: 0.1356
Training Epoch: 74 [46080/50176]	Loss: 0.1464
Training Epoch: 74 [47104/50176]	Loss: 0.1551
Training Epoch: 74 [48128/50176]	Loss: 0.1258
Training Epoch: 74 [49152/50176]	Loss: 0.1250
Training Epoch: 74 [50176/50176]	Loss: 0.1723
2022-12-06 18:10:41.517 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:10:41,550 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.80 energy=489.21
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Up to epoch 75: time=3675.97, energy=512864.73, cost=578080.10
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Training done.
2022-12-06 13:10:41,551 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec01+try01+bs1024+lr0.0100000.train.json: {"energy": 512864.726165234, "time": 3675.9740900210018, "cost": 578080.0959594547, "num_epochs": 75, "reached": true}
Validation Epoch: 74, Average loss: 0.0025, Accuracy: 0.6062

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 512864.726165234, 'time': 3675.9740900210018, 'cost': 578080.0959594547, 'num_epochs': 75, 'reached': True}
[run job; power] power_stats={'job_id': 'rec01+try01', 'train_power': {'175000': 144.87586386206175, '150000': 142.4413747226752, '125000': 122.47472127317002, '100000': 96.50525059382247}, 'train_throughput': {'175000': 1.1265477788311575, '150000': 1.1081640906025203, '125000': 1.0413129456183774, '100000': 0.5426340296975655}, 'eval_power': {'175000': 127.69507531813454, '150000': 126.8275325321136, '125000': 115.63754995827681}, 'eval_throughput': {'175000': 2.6466800540332938, '150000': 2.6311429884394997, '125000': 2.5047197850078424}, 'optimal_pl': 175000}
[Zeus Master] cost=578080.0959594547

[Zeus Master] Reached target metric in 1 try.
[run job] Launching job with BS 1024: and LR: 0.05
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec02+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.05']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec02+try01.train.log'
2022-12-06 13:10:46,042 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 13:10:46,042 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 13:10:46,043 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 13:10:46,085 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 13:10:46,085 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 13:10:48,189 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 13:10:48,190 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 13:10:48,354 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:10:48.356 [ZeusMonitor] Monitor started.
2022-12-06 18:10:48.356 [ZeusMonitor] Running indefinitely. 2022-12-06 18:10:48.356 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:10:48.356 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 13:10:49,039 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 13:10:49,040 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 13:10:57,656 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 13:11:31,383 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 13:11:33,032 [ZeusDataLoader(train)] train epoch 1 done: time=44.84 energy=6291.48
2022-12-06 13:11:33,035 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 18.3248
Training Epoch: 0 [3072/50176]	Loss: 9.6542
Training Epoch: 0 [4096/50176]	Loss: 8.4885
Training Epoch: 0 [5120/50176]	Loss: 9.8576
Training Epoch: 0 [6144/50176]	Loss: 10.6665
Training Epoch: 0 [7168/50176]	Loss: 7.0869
Training Epoch: 0 [8192/50176]	Loss: 7.3002
Training Epoch: 0 [9216/50176]	Loss: 5.6747
Training Epoch: 0 [10240/50176]	Loss: 5.6620
Training Epoch: 0 [11264/50176]	Loss: 5.8762
Training Epoch: 0 [12288/50176]	Loss: 5.1456
Training Epoch: 0 [13312/50176]	Loss: 5.2279
Training Epoch: 0 [14336/50176]	Loss: 4.6846
Training Epoch: 0 [15360/50176]	Loss: 5.2353
Training Epoch: 0 [16384/50176]	Loss: 5.2059
Training Epoch: 0 [17408/50176]	Loss: 4.6928
Training Epoch: 0 [18432/50176]	Loss: 4.8528
Training Epoch: 0 [19456/50176]	Loss: 4.6386
Training Epoch: 0 [20480/50176]	Loss: 4.7371
Training Epoch: 0 [21504/50176]	Loss: 4.7556
Training Epoch: 0 [22528/50176]	Loss: 5.0653
Training Epoch: 0 [23552/50176]	Loss: 5.1241
Training Epoch: 0 [24576/50176]	Loss: 4.9408
Training Epoch: 0 [25600/50176]	Loss: 4.7500
Training Epoch: 0 [26624/50176]	Loss: 4.6854
Training Epoch: 0 [27648/50176]	Loss: 4.6618
Training Epoch: 0 [28672/50176]	Loss: 4.6156
Training Epoch: 0 [29696/50176]	Loss: 4.6114
Training Epoch: 0 [30720/50176]	Loss: 4.6125
Training Epoch: 0 [31744/50176]	Loss: 4.6123
Training Epoch: 0 [32768/50176]	Loss: 4.6116
Training Epoch: 0 [33792/50176]	Loss: 4.6160
Training Epoch: 0 [34816/50176]	Loss: 4.6093
Training Epoch: 0 [35840/50176]	Loss: 4.6128
Training Epoch: 0 [36864/50176]	Loss: 4.6091
Training Epoch: 0 [37888/50176]	Loss: 4.6091
Training Epoch: 0 [38912/50176]	Loss: 4.6115
Training Epoch: 0 [39936/50176]	Loss: 4.6134
Training Epoch: 0 [40960/50176]	Loss: 4.6065
Training Epoch: 0 [41984/50176]	Loss: 4.6111
Training Epoch: 0 [43008/50176]	Loss: 4.6094
Training Epoch: 0 [44032/50176]	Loss: 4.6127
Training Epoch: 0 [45056/50176]	Loss: 4.6102
Training Epoch: 0 [46080/50176]	Loss: 4.6101
Training Epoch: 0 [47104/50176]	Loss: 4.6092
Training Epoch: 0 [48128/50176]	Loss: 4.6130
Training Epoch: 0 [49152/50176]	Loss: 4.6119
Training Epoch: 0 [50176/50176]	Loss: 4.6074
2022-12-06 18:11:36.698 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:11:36,709 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.67 energy=458.64
2022-12-06 13:11:36,709 [ZeusDataLoader(train)] Up to epoch 1: time=48.50, energy=6750.13, cost=7618.99
2022-12-06 13:11:36,710 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0045, Accuracy: 0.0099
2022-12-06 13:11:36,932 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:11:36.934 [ZeusMonitor] Monitor started.
2022-12-06 18:11:36.935 [ZeusMonitor] Running indefinitely. 2022-12-06 18:11:36.935 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:11:36.935 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 13:11:37,630 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 13:11:37,630 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 13:11:45,697 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 13:12:19,281 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 13:12:20,940 [ZeusDataLoader(train)] train epoch 2 done: time=44.22 energy=6197.37
2022-12-06 13:12:20,943 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.6100
Training Epoch: 1 [2048/50176]	Loss: 4.6059
Training Epoch: 1 [3072/50176]	Loss: 4.6088
Training Epoch: 1 [4096/50176]	Loss: 4.6063
Training Epoch: 1 [5120/50176]	Loss: 4.6098
Training Epoch: 1 [6144/50176]	Loss: 4.6078
Training Epoch: 1 [7168/50176]	Loss: 4.6071
Training Epoch: 1 [8192/50176]	Loss: 4.6068
Training Epoch: 1 [9216/50176]	Loss: 4.6119
Training Epoch: 1 [10240/50176]	Loss: 4.6093
Training Epoch: 1 [11264/50176]	Loss: 4.6076
Training Epoch: 1 [12288/50176]	Loss: 4.6057
Training Epoch: 1 [13312/50176]	Loss: 4.6111
Training Epoch: 1 [14336/50176]	Loss: 4.6057
Training Epoch: 1 [15360/50176]	Loss: 4.6097
Training Epoch: 1 [16384/50176]	Loss: 4.6103
Training Epoch: 1 [17408/50176]	Loss: 4.6089
Training Epoch: 1 [18432/50176]	Loss: 4.6070
Training Epoch: 1 [19456/50176]	Loss: 4.6092
Training Epoch: 1 [20480/50176]	Loss: 4.6126
Training Epoch: 1 [21504/50176]	Loss: 4.6079
Training Epoch: 1 [22528/50176]	Loss: 4.6068
Training Epoch: 1 [23552/50176]	Loss: 4.6095
Training Epoch: 1 [24576/50176]	Loss: 4.6063
Training Epoch: 1 [25600/50176]	Loss: 4.6092
Training Epoch: 1 [26624/50176]	Loss: 4.6104
Training Epoch: 1 [27648/50176]	Loss: 4.6109
Training Epoch: 1 [28672/50176]	Loss: 4.6076
Training Epoch: 1 [29696/50176]	Loss: 4.6105
Training Epoch: 1 [30720/50176]	Loss: 4.6071
Training Epoch: 1 [31744/50176]	Loss: 4.6116
Training Epoch: 1 [32768/50176]	Loss: 4.6098
Training Epoch: 1 [33792/50176]	Loss: 4.6083
Training Epoch: 1 [34816/50176]	Loss: 4.6082
Training Epoch: 1 [35840/50176]	Loss: 4.6095
Training Epoch: 1 [36864/50176]	Loss: 4.6091
Training Epoch: 1 [37888/50176]	Loss: 4.6104
Training Epoch: 1 [38912/50176]	Loss: 4.6070
Training Epoch: 1 [39936/50176]	Loss: 4.6081
Training Epoch: 1 [40960/50176]	Loss: 4.6089
Training Epoch: 1 [41984/50176]	Loss: 4.6101
Training Epoch: 1 [43008/50176]	Loss: 4.6083
Training Epoch: 1 [44032/50176]	Loss: 4.6106
Training Epoch: 1 [45056/50176]	Loss: 4.6087
Training Epoch: 1 [46080/50176]	Loss: 4.6095
Training Epoch: 1 [47104/50176]	Loss: 4.6086
Training Epoch: 1 [48128/50176]	Loss: 4.6092
Training Epoch: 1 [49152/50176]	Loss: 4.6070
Training Epoch: 1 [50176/50176]	Loss: 4.6065
2022-12-06 18:12:24.678 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:12:24,735 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.78 energy=472.13
2022-12-06 13:12:24,735 [ZeusDataLoader(train)] Up to epoch 2: time=96.51, energy=13419.63, cost=15154.39
2022-12-06 13:12:24,736 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0045, Accuracy: 0.0104
2022-12-06 13:12:24,968 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:12:24.970 [ZeusMonitor] Monitor started.
2022-12-06 18:12:24.970 [ZeusMonitor] Running indefinitely. 2022-12-06 18:12:24.970 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:12:24.970 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 13:12:25,667 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 13:12:25,667 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 13:12:34,341 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 13:13:10,547 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 13:13:12,344 [ZeusDataLoader(train)] train epoch 3 done: time=47.60 energy=5744.46
2022-12-06 13:13:12,348 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 4.6041
Training Epoch: 2 [2048/50176]	Loss: 4.6045
Training Epoch: 2 [3072/50176]	Loss: 4.6050
Training Epoch: 2 [4096/50176]	Loss: 4.6048
Training Epoch: 2 [5120/50176]	Loss: 4.6100
Training Epoch: 2 [6144/50176]	Loss: 4.6042
Training Epoch: 2 [7168/50176]	Loss: 4.6100
Training Epoch: 2 [8192/50176]	Loss: 4.6091
Training Epoch: 2 [9216/50176]	Loss: 4.6046
Training Epoch: 2 [10240/50176]	Loss: 4.6091
Training Epoch: 2 [11264/50176]	Loss: 4.6062
Training Epoch: 2 [12288/50176]	Loss: 4.6147
Training Epoch: 2 [13312/50176]	Loss: 4.6057
Training Epoch: 2 [14336/50176]	Loss: 4.6066
Training Epoch: 2 [15360/50176]	Loss: 4.6116
Training Epoch: 2 [16384/50176]	Loss: 4.6056
Training Epoch: 2 [17408/50176]	Loss: 4.6080
Training Epoch: 2 [18432/50176]	Loss: 4.6099
Training Epoch: 2 [19456/50176]	Loss: 4.6057
Training Epoch: 2 [20480/50176]	Loss: 4.6060
Training Epoch: 2 [21504/50176]	Loss: 4.6069
Training Epoch: 2 [22528/50176]	Loss: 4.6085
Training Epoch: 2 [23552/50176]	Loss: 4.5954
Training Epoch: 2 [24576/50176]	Loss: 4.6054
Training Epoch: 2 [25600/50176]	Loss: 4.6028
Training Epoch: 2 [26624/50176]	Loss: 4.6080
Training Epoch: 2 [27648/50176]	Loss: 4.6012
Training Epoch: 2 [28672/50176]	Loss: 4.5956
Training Epoch: 2 [29696/50176]	Loss: 4.5996
Training Epoch: 2 [30720/50176]	Loss: 4.6009
Training Epoch: 2 [31744/50176]	Loss: 4.6062
Training Epoch: 2 [32768/50176]	Loss: 4.5954
Training Epoch: 2 [33792/50176]	Loss: 4.5990
Training Epoch: 2 [34816/50176]	Loss: 4.5979
Training Epoch: 2 [35840/50176]	Loss: 4.5934
Training Epoch: 2 [36864/50176]	Loss: 4.5943
Training Epoch: 2 [37888/50176]	Loss: 4.5923
Training Epoch: 2 [38912/50176]	Loss: 4.5958
Training Epoch: 2 [39936/50176]	Loss: 4.5878
Training Epoch: 2 [40960/50176]	Loss: 4.5853
Training Epoch: 2 [41984/50176]	Loss: 4.5769
Training Epoch: 2 [43008/50176]	Loss: 4.5761
Training Epoch: 2 [44032/50176]	Loss: 4.5767
Training Epoch: 2 [45056/50176]	Loss: 4.5720
Training Epoch: 2 [46080/50176]	Loss: 4.5652
Training Epoch: 2 [47104/50176]	Loss: 4.5813
Training Epoch: 2 [48128/50176]	Loss: 4.5683
Training Epoch: 2 [49152/50176]	Loss: 4.5641
Training Epoch: 2 [50176/50176]	Loss: 4.5604
2022-12-06 18:13:16.248 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:13:16,270 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.91 energy=442.58
2022-12-06 13:13:16,270 [ZeusDataLoader(train)] Up to epoch 3: time=148.03, energy=19606.67, cost=22755.52
2022-12-06 13:13:16,271 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0045, Accuracy: 0.0096
2022-12-06 13:13:16,494 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:13:16.497 [ZeusMonitor] Monitor started.
2022-12-06 18:13:16.497 [ZeusMonitor] Running indefinitely. 2022-12-06 18:13:16.497 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:13:16.497 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 13:13:17,204 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 13:13:17,204 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 13:13:31,383 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] Cost-optimal power limit is 150W
2022-12-06 13:14:42,833 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 13:14:44,604 [ZeusDataLoader(train)] train epoch 4 done: time=88.32 energy=8477.40
2022-12-06 13:14:44,608 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 4.5546
Training Epoch: 3 [2048/50176]	Loss: 4.5400
Training Epoch: 3 [3072/50176]	Loss: 4.5409
Training Epoch: 3 [4096/50176]	Loss: 4.5386
Training Epoch: 3 [5120/50176]	Loss: 4.5368
Training Epoch: 3 [6144/50176]	Loss: 4.5295
Training Epoch: 3 [7168/50176]	Loss: 4.5255
Training Epoch: 3 [8192/50176]	Loss: 4.5267
Training Epoch: 3 [9216/50176]	Loss: 4.5127
Training Epoch: 3 [10240/50176]	Loss: 4.5111
Training Epoch: 3 [11264/50176]	Loss: 4.5181
Training Epoch: 3 [12288/50176]	Loss: 4.5275
Training Epoch: 3 [13312/50176]	Loss: 4.5051
Training Epoch: 3 [14336/50176]	Loss: 4.5430
Training Epoch: 3 [15360/50176]	Loss: 4.5179
Training Epoch: 3 [16384/50176]	Loss: 4.5008
Training Epoch: 3 [17408/50176]	Loss: 4.5007
Training Epoch: 3 [18432/50176]	Loss: 4.5071
Training Epoch: 3 [19456/50176]	Loss: 4.4909
Training Epoch: 3 [20480/50176]	Loss: 4.4857
Training Epoch: 3 [21504/50176]	Loss: 4.4944
Training Epoch: 3 [22528/50176]	Loss: 4.5224
Training Epoch: 3 [23552/50176]	Loss: 4.4823
Training Epoch: 3 [24576/50176]	Loss: 4.4610
Training Epoch: 3 [25600/50176]	Loss: 4.4714
Training Epoch: 3 [26624/50176]	Loss: 4.4762
Training Epoch: 3 [27648/50176]	Loss: 4.4962
Training Epoch: 3 [28672/50176]	Loss: 4.4876
Training Epoch: 3 [29696/50176]	Loss: 4.4937
Training Epoch: 3 [30720/50176]	Loss: 4.4834
Training Epoch: 3 [31744/50176]	Loss: 4.4987
Training Epoch: 3 [32768/50176]	Loss: 4.4708
Training Epoch: 3 [33792/50176]	Loss: 4.4667
Training Epoch: 3 [34816/50176]	Loss: 4.4746
Training Epoch: 3 [35840/50176]	Loss: 4.4729
Training Epoch: 3 [36864/50176]	Loss: 4.4979
Training Epoch: 3 [37888/50176]	Loss: 4.4790
Training Epoch: 3 [38912/50176]	Loss: 4.4548
Training Epoch: 3 [39936/50176]	Loss: 4.4672
Training Epoch: 3 [40960/50176]	Loss: 4.4553
Training Epoch: 3 [41984/50176]	Loss: 4.4356
Training Epoch: 3 [43008/50176]	Loss: 4.4459
Training Epoch: 3 [44032/50176]	Loss: 4.4417
Training Epoch: 3 [45056/50176]	Loss: 4.4565
Training Epoch: 3 [46080/50176]	Loss: 4.4689
Training Epoch: 3 [47104/50176]	Loss: 4.4303
Training Epoch: 3 [48128/50176]	Loss: 4.4885
Training Epoch: 3 [49152/50176]	Loss: 4.4463
Training Epoch: 3 [50176/50176]	Loss: 4.4546
2022-12-06 18:14:48.406 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0500000.power.json: {"job_id": "rec02+try01", "train_power": {"175000": 144.47546303251323, "150000": 143.5043538909716, "125000": 122.98543544465625, "100000": 96.15303472348029}, "train_throughput": {"175000": 1.1271092756166952, "150000": 1.1318246084833394, "125000": 1.049840007140111, "100000": 0.5319577495376839}, "eval_power": {"175000": 125.11089176100826, "150000": 124.69307695790027, "125000": 113.06620903588392}, "eval_throughput": {"175000": 2.7278581345566275, "150000": 2.624264534414073, "125000": 2.5546916558312223}, "optimal_pl": 150000}
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.81 energy=475.15
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Up to epoch 4: time=240.16, energy=28559.22, cost=35293.52
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Expected next epoch: time=287.26, energy=35247.09, cost=42759.02
2022-12-06 13:14:48,429 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0045, Accuracy: 0.0119
2022-12-06 13:14:48,661 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:14:48,661 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:14:48.675 [ZeusMonitor] Monitor started.
2022-12-06 18:14:48.675 [ZeusMonitor] Running indefinitely. 2022-12-06 18:14:48.676 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:14:48.676 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 13:15:32,991 [ZeusDataLoader(train)] train epoch 5 done: time=44.55 energy=6209.66
2022-12-06 13:15:32,994 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 4.4229
Training Epoch: 4 [2048/50176]	Loss: 4.4662
Training Epoch: 4 [3072/50176]	Loss: 4.4378
Training Epoch: 4 [4096/50176]	Loss: 4.4631
Training Epoch: 4 [5120/50176]	Loss: 4.4164
Training Epoch: 4 [6144/50176]	Loss: 4.4094
Training Epoch: 4 [7168/50176]	Loss: 4.4154
Training Epoch: 4 [8192/50176]	Loss: 4.3952
Training Epoch: 4 [9216/50176]	Loss: 4.4234
Training Epoch: 4 [10240/50176]	Loss: 4.4119
Training Epoch: 4 [11264/50176]	Loss: 4.4238
Training Epoch: 4 [12288/50176]	Loss: 4.4240
Training Epoch: 4 [13312/50176]	Loss: 4.4064
Training Epoch: 4 [14336/50176]	Loss: 4.4450
Training Epoch: 4 [15360/50176]	Loss: 4.4185
Training Epoch: 4 [16384/50176]	Loss: 4.3778
Training Epoch: 4 [17408/50176]	Loss: 4.4190
Training Epoch: 4 [18432/50176]	Loss: 4.4299
Training Epoch: 4 [19456/50176]	Loss: 4.4157
Training Epoch: 4 [20480/50176]	Loss: 4.4335
Training Epoch: 4 [21504/50176]	Loss: 4.4315
Training Epoch: 4 [22528/50176]	Loss: 4.3946
Training Epoch: 4 [23552/50176]	Loss: 4.4123
Training Epoch: 4 [24576/50176]	Loss: 4.4416
Training Epoch: 4 [25600/50176]	Loss: 4.4351
Training Epoch: 4 [26624/50176]	Loss: 4.3964
Training Epoch: 4 [27648/50176]	Loss: 4.3849
Training Epoch: 4 [28672/50176]	Loss: 4.3928
Training Epoch: 4 [29696/50176]	Loss: 4.4009
Training Epoch: 4 [30720/50176]	Loss: 4.3545
Training Epoch: 4 [31744/50176]	Loss: 4.4025
Training Epoch: 4 [32768/50176]	Loss: 4.3859
Training Epoch: 4 [33792/50176]	Loss: 4.3677
Training Epoch: 4 [34816/50176]	Loss: 4.3899
Training Epoch: 4 [35840/50176]	Loss: 4.3831
Training Epoch: 4 [36864/50176]	Loss: 4.3746
Training Epoch: 4 [37888/50176]	Loss: 4.4176
Training Epoch: 4 [38912/50176]	Loss: 4.3668
Training Epoch: 4 [39936/50176]	Loss: 4.3535
Training Epoch: 4 [40960/50176]	Loss: 4.3762
Training Epoch: 4 [41984/50176]	Loss: 4.3694
Training Epoch: 4 [43008/50176]	Loss: 4.3847
Training Epoch: 4 [44032/50176]	Loss: 4.3879
Training Epoch: 4 [45056/50176]	Loss: 4.3841
Training Epoch: 4 [46080/50176]	Loss: 4.3782
Training Epoch: 4 [47104/50176]	Loss: 4.3140
Training Epoch: 4 [48128/50176]	Loss: 4.4134
Training Epoch: 4 [49152/50176]	Loss: 4.3367
Training Epoch: 4 [50176/50176]	Loss: 4.4112
2022-12-06 18:15:36.685 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:15:36,704 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.70 energy=468.99
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Up to epoch 5: time=288.41, energy=35237.86, cost=42855.24
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Expected next epoch: time=335.52, energy=41925.74, cost=50320.74
2022-12-06 13:15:36,706 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0067, Accuracy: 0.0097
2022-12-06 13:15:36,934 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:15:36,935 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:15:36.954 [ZeusMonitor] Monitor started.
2022-12-06 18:15:36.954 [ZeusMonitor] Running indefinitely. 2022-12-06 18:15:36.954 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:15:36.954 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 13:16:21,194 [ZeusDataLoader(train)] train epoch 6 done: time=44.48 energy=6230.11
2022-12-06 13:16:21,197 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 4.3370
Training Epoch: 5 [2048/50176]	Loss: 4.3157
Training Epoch: 5 [3072/50176]	Loss: 4.3595
Training Epoch: 5 [4096/50176]	Loss: 4.3270
Training Epoch: 5 [5120/50176]	Loss: 4.3454
Training Epoch: 5 [6144/50176]	Loss: 4.3504
Training Epoch: 5 [7168/50176]	Loss: 4.3281
Training Epoch: 5 [8192/50176]	Loss: 4.3893
Training Epoch: 5 [9216/50176]	Loss: 4.3115
Training Epoch: 5 [10240/50176]	Loss: 4.3266
Training Epoch: 5 [11264/50176]	Loss: 4.3679
Training Epoch: 5 [12288/50176]	Loss: 4.3363
Training Epoch: 5 [13312/50176]	Loss: 4.3148
Training Epoch: 5 [14336/50176]	Loss: 4.3266
Training Epoch: 5 [15360/50176]	Loss: 4.3565
Training Epoch: 5 [16384/50176]	Loss: 4.3289
Training Epoch: 5 [17408/50176]	Loss: 4.3262
Training Epoch: 5 [18432/50176]	Loss: 4.3125
Training Epoch: 5 [19456/50176]	Loss: 4.3170
Training Epoch: 5 [20480/50176]	Loss: 4.2769
Training Epoch: 5 [21504/50176]	Loss: 4.2990
Training Epoch: 5 [22528/50176]	Loss: 4.3206
Training Epoch: 5 [23552/50176]	Loss: 4.3144
Training Epoch: 5 [24576/50176]	Loss: 4.3416
Training Epoch: 5 [25600/50176]	Loss: 4.2955
Training Epoch: 5 [26624/50176]	Loss: 4.2424
Training Epoch: 5 [27648/50176]	Loss: 4.2752
Training Epoch: 5 [28672/50176]	Loss: 4.2813
Training Epoch: 5 [29696/50176]	Loss: 4.2197
Training Epoch: 5 [30720/50176]	Loss: 4.2815
Training Epoch: 5 [31744/50176]	Loss: 4.2436
Training Epoch: 5 [32768/50176]	Loss: 4.2440
Training Epoch: 5 [33792/50176]	Loss: 4.1622
Training Epoch: 5 [34816/50176]	Loss: 4.2305
Training Epoch: 5 [35840/50176]	Loss: 4.2679
Training Epoch: 5 [36864/50176]	Loss: 4.1736
Training Epoch: 5 [37888/50176]	Loss: 4.2347
Training Epoch: 5 [38912/50176]	Loss: 4.1671
Training Epoch: 5 [39936/50176]	Loss: 4.1923
Training Epoch: 5 [40960/50176]	Loss: 4.2256
Training Epoch: 5 [41984/50176]	Loss: 4.1425
Training Epoch: 5 [43008/50176]	Loss: 4.1303
Training Epoch: 5 [44032/50176]	Loss: 4.1599
Training Epoch: 5 [45056/50176]	Loss: 4.2343
Training Epoch: 5 [46080/50176]	Loss: 4.1238
Training Epoch: 5 [47104/50176]	Loss: 4.1221
Training Epoch: 5 [48128/50176]	Loss: 4.1537
Training Epoch: 5 [49152/50176]	Loss: 4.1559
Training Epoch: 5 [50176/50176]	Loss: 4.1374
2022-12-06 18:16:24.948 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:16:24,995 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.79 energy=471.46
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Up to epoch 6: time=336.69, energy=41939.44, cost=50429.70
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Expected next epoch: time=383.79, energy=48627.32, cost=57895.20
2022-12-06 13:16:24,996 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0086, Accuracy: 0.0100
2022-12-06 13:16:25,238 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:16:25,239 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:16:25.249 [ZeusMonitor] Monitor started.
2022-12-06 18:16:25.249 [ZeusMonitor] Running indefinitely. 2022-12-06 18:16:25.249 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:16:25.249 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 13:17:09,348 [ZeusDataLoader(train)] train epoch 7 done: time=44.34 energy=6238.97
2022-12-06 13:17:09,352 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 4.0880
Training Epoch: 6 [2048/50176]	Loss: 4.1424
Training Epoch: 6 [3072/50176]	Loss: 4.1310
Training Epoch: 6 [4096/50176]	Loss: 4.0792
Training Epoch: 6 [5120/50176]	Loss: 4.0517
Training Epoch: 6 [6144/50176]	Loss: 4.0352
Training Epoch: 6 [7168/50176]	Loss: 4.0580
Training Epoch: 6 [8192/50176]	Loss: 4.0583
Training Epoch: 6 [9216/50176]	Loss: 4.1307
Training Epoch: 6 [10240/50176]	Loss: 3.9948
Training Epoch: 6 [11264/50176]	Loss: 4.0655
Training Epoch: 6 [12288/50176]	Loss: 4.0000
Training Epoch: 6 [13312/50176]	Loss: 4.0349
Training Epoch: 6 [14336/50176]	Loss: 3.9934
Training Epoch: 6 [15360/50176]	Loss: 3.9712
Training Epoch: 6 [16384/50176]	Loss: 3.9803
Training Epoch: 6 [17408/50176]	Loss: 3.9739
Training Epoch: 6 [18432/50176]	Loss: 4.0286
Training Epoch: 6 [19456/50176]	Loss: 3.9929
Training Epoch: 6 [20480/50176]	Loss: 3.9561
Training Epoch: 6 [21504/50176]	Loss: 3.9791
Training Epoch: 6 [22528/50176]	Loss: 3.9464
Training Epoch: 6 [23552/50176]	Loss: 3.9529
Training Epoch: 6 [24576/50176]	Loss: 3.9266
Training Epoch: 6 [25600/50176]	Loss: 3.9697
Training Epoch: 6 [26624/50176]	Loss: 3.8853
Training Epoch: 6 [27648/50176]	Loss: 3.9416
Training Epoch: 6 [28672/50176]	Loss: 3.9314
Training Epoch: 6 [29696/50176]	Loss: 3.9620
Training Epoch: 6 [30720/50176]	Loss: 3.9156
Training Epoch: 6 [31744/50176]	Loss: 3.9200
Training Epoch: 6 [32768/50176]	Loss: 3.9253
Training Epoch: 6 [33792/50176]	Loss: 3.9275
Training Epoch: 6 [34816/50176]	Loss: 3.8720
Training Epoch: 6 [35840/50176]	Loss: 3.8569
Training Epoch: 6 [36864/50176]	Loss: 3.9067
Training Epoch: 6 [37888/50176]	Loss: 3.9438
Training Epoch: 6 [38912/50176]	Loss: 3.8670
Training Epoch: 6 [39936/50176]	Loss: 3.8932
Training Epoch: 6 [40960/50176]	Loss: 3.9111
Training Epoch: 6 [41984/50176]	Loss: 3.8301
Training Epoch: 6 [43008/50176]	Loss: 3.8448
Training Epoch: 6 [44032/50176]	Loss: 3.8966
Training Epoch: 6 [45056/50176]	Loss: 3.8798
Training Epoch: 6 [46080/50176]	Loss: 3.9060
Training Epoch: 6 [47104/50176]	Loss: 3.8501
Training Epoch: 6 [48128/50176]	Loss: 3.9035
Training Epoch: 6 [49152/50176]	Loss: 3.8522
Training Epoch: 6 [50176/50176]	Loss: 3.9127
2022-12-06 18:17:13.079 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:17:13,109 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.75 energy=467.30
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Up to epoch 7: time=384.78, energy=48645.71, cost=57990.99
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Expected next epoch: time=431.88, energy=55333.59, cost=65456.49
2022-12-06 13:17:13,110 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0064, Accuracy: 0.0113
2022-12-06 13:17:13,304 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:17:13,305 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:17:13.308 [ZeusMonitor] Monitor started.
2022-12-06 18:17:13.309 [ZeusMonitor] Running indefinitely. 2022-12-06 18:17:13.309 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:17:13.309 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 13:17:57,371 [ZeusDataLoader(train)] train epoch 8 done: time=44.25 energy=6237.64
2022-12-06 13:17:57,375 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 3.8855
Training Epoch: 7 [2048/50176]	Loss: 3.8235
Training Epoch: 7 [3072/50176]	Loss: 3.8387
Training Epoch: 7 [4096/50176]	Loss: 3.8410
Training Epoch: 7 [5120/50176]	Loss: 3.8947
Training Epoch: 7 [6144/50176]	Loss: 3.8582
Training Epoch: 7 [7168/50176]	Loss: 3.7953
Training Epoch: 7 [8192/50176]	Loss: 3.7653
Training Epoch: 7 [9216/50176]	Loss: 3.6925
Training Epoch: 7 [10240/50176]	Loss: 3.7546
Training Epoch: 7 [11264/50176]	Loss: 3.8355
Training Epoch: 7 [12288/50176]	Loss: 3.7706
Training Epoch: 7 [13312/50176]	Loss: 3.7605
Training Epoch: 7 [14336/50176]	Loss: 3.8976
Training Epoch: 7 [15360/50176]	Loss: 3.8300
Training Epoch: 7 [16384/50176]	Loss: 3.7373
Training Epoch: 7 [17408/50176]	Loss: 3.7767
Training Epoch: 7 [18432/50176]	Loss: 3.8173
Training Epoch: 7 [19456/50176]	Loss: 3.8062
Training Epoch: 7 [20480/50176]	Loss: 3.8705
Training Epoch: 7 [21504/50176]	Loss: 3.8364
Training Epoch: 7 [22528/50176]	Loss: 3.8139
Training Epoch: 7 [23552/50176]	Loss: 3.7825
Training Epoch: 7 [24576/50176]	Loss: 3.7669
Training Epoch: 7 [25600/50176]	Loss: 3.7650
Training Epoch: 7 [26624/50176]	Loss: 3.7658
Training Epoch: 7 [27648/50176]	Loss: 3.8293
Training Epoch: 7 [28672/50176]	Loss: 3.7539
Training Epoch: 7 [29696/50176]	Loss: 3.7887
Training Epoch: 7 [30720/50176]	Loss: 3.7808
Training Epoch: 7 [31744/50176]	Loss: 3.7593
Training Epoch: 7 [32768/50176]	Loss: 3.7661
Training Epoch: 7 [33792/50176]	Loss: 3.8046
Training Epoch: 7 [34816/50176]	Loss: 3.7591
Training Epoch: 7 [35840/50176]	Loss: 3.7485
Training Epoch: 7 [36864/50176]	Loss: 3.7033
Training Epoch: 7 [37888/50176]	Loss: 3.6414
Training Epoch: 7 [38912/50176]	Loss: 3.7461
Training Epoch: 7 [39936/50176]	Loss: 3.7453
Training Epoch: 7 [40960/50176]	Loss: 3.7668
Training Epoch: 7 [41984/50176]	Loss: 3.7261
Training Epoch: 7 [43008/50176]	Loss: 3.7299
Training Epoch: 7 [44032/50176]	Loss: 3.5818
Training Epoch: 7 [45056/50176]	Loss: 3.6804
Training Epoch: 7 [46080/50176]	Loss: 3.7020
Training Epoch: 7 [47104/50176]	Loss: 3.6912
Training Epoch: 7 [48128/50176]	Loss: 3.6691
Training Epoch: 7 [49152/50176]	Loss: 3.7449
Training Epoch: 7 [50176/50176]	Loss: 3.7415
2022-12-06 18:18:01.141 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:18:01,184 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.80 energy=482.82
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Up to epoch 8: time=432.83, energy=55366.17, cost=65555.93
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Expected next epoch: time=479.94, energy=62054.05, cost=73021.43
2022-12-06 13:18:01,186 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0287, Accuracy: 0.0098
2022-12-06 13:18:01,435 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:18:01,436 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:18:01.437 [ZeusMonitor] Monitor started.
2022-12-06 18:18:01.438 [ZeusMonitor] Running indefinitely. 2022-12-06 18:18:01.438 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:18:01.438 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 13:18:45,383 [ZeusDataLoader(train)] train epoch 9 done: time=44.19 energy=6215.68
2022-12-06 13:18:45,386 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 3.7167
Training Epoch: 8 [2048/50176]	Loss: 3.7783
Training Epoch: 8 [3072/50176]	Loss: 3.6691
Training Epoch: 8 [4096/50176]	Loss: 3.6184
Training Epoch: 8 [5120/50176]	Loss: 3.5526
Training Epoch: 8 [6144/50176]	Loss: 3.6874
Training Epoch: 8 [7168/50176]	Loss: 3.6088
Training Epoch: 8 [8192/50176]	Loss: 3.6665
Training Epoch: 8 [9216/50176]	Loss: 3.6195
Training Epoch: 8 [10240/50176]	Loss: 3.6425
Training Epoch: 8 [11264/50176]	Loss: 3.6232
Training Epoch: 8 [12288/50176]	Loss: 3.6110
Training Epoch: 8 [13312/50176]	Loss: 3.6462
Training Epoch: 8 [14336/50176]	Loss: 3.6471
Training Epoch: 8 [15360/50176]	Loss: 3.6155
Training Epoch: 8 [16384/50176]	Loss: 3.5903
Training Epoch: 8 [17408/50176]	Loss: 3.6779
Training Epoch: 8 [18432/50176]	Loss: 3.5571
Training Epoch: 8 [19456/50176]	Loss: 3.6141
Training Epoch: 8 [20480/50176]	Loss: 3.5472
Training Epoch: 8 [21504/50176]	Loss: 3.5880
Training Epoch: 8 [22528/50176]	Loss: 3.5784
Training Epoch: 8 [23552/50176]	Loss: 3.5864
Training Epoch: 8 [24576/50176]	Loss: 3.6889
Training Epoch: 8 [25600/50176]	Loss: 3.6071
Training Epoch: 8 [26624/50176]	Loss: 3.6306
Training Epoch: 8 [27648/50176]	Loss: 3.6268
Training Epoch: 8 [28672/50176]	Loss: 3.6085
Training Epoch: 8 [29696/50176]	Loss: 3.5546
Training Epoch: 8 [30720/50176]	Loss: 3.6113
Training Epoch: 8 [31744/50176]	Loss: 3.5428
Training Epoch: 8 [32768/50176]	Loss: 3.5420
Training Epoch: 8 [33792/50176]	Loss: 3.6460
Training Epoch: 8 [34816/50176]	Loss: 3.6094
Training Epoch: 8 [35840/50176]	Loss: 3.5463
Training Epoch: 8 [36864/50176]	Loss: 3.5694
Training Epoch: 8 [37888/50176]	Loss: 3.5850
Training Epoch: 8 [38912/50176]	Loss: 3.6629
Training Epoch: 8 [39936/50176]	Loss: 3.5807
Training Epoch: 8 [40960/50176]	Loss: 3.5355
Training Epoch: 8 [41984/50176]	Loss: 3.5152
Training Epoch: 8 [43008/50176]	Loss: 3.5730
Training Epoch: 8 [44032/50176]	Loss: 3.6281
Training Epoch: 8 [45056/50176]	Loss: 3.6646
Training Epoch: 8 [46080/50176]	Loss: 3.5877
Training Epoch: 8 [47104/50176]	Loss: 3.6010
Training Epoch: 8 [48128/50176]	Loss: 3.5382
Training Epoch: 8 [49152/50176]	Loss: 3.5998
Training Epoch: 8 [50176/50176]	Loss: 3.5700
2022-12-06 18:18:49.157 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:18:49,183 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.79 energy=480.29
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Up to epoch 9: time=480.81, energy=62062.14, cost=73102.04
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Expected next epoch: time=527.91, energy=68750.02, cost=80567.53
2022-12-06 13:18:49,185 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0343, Accuracy: 0.0098
2022-12-06 13:18:49,422 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:18:49,423 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:18:49.424 [ZeusMonitor] Monitor started.
2022-12-06 18:18:49.424 [ZeusMonitor] Running indefinitely. 2022-12-06 18:18:49.424 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:18:49.424 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 13:19:33,687 [ZeusDataLoader(train)] train epoch 10 done: time=44.49 energy=6251.34
2022-12-06 13:19:33,690 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 3.5387
Training Epoch: 9 [2048/50176]	Loss: 3.5426
Training Epoch: 9 [3072/50176]	Loss: 3.5561
Training Epoch: 9 [4096/50176]	Loss: 3.5277
Training Epoch: 9 [5120/50176]	Loss: 3.4988
Training Epoch: 9 [6144/50176]	Loss: 3.5494
Training Epoch: 9 [7168/50176]	Loss: 3.5059
Training Epoch: 9 [8192/50176]	Loss: 3.5016
Training Epoch: 9 [9216/50176]	Loss: 3.4900
Training Epoch: 9 [10240/50176]	Loss: 3.5081
Training Epoch: 9 [11264/50176]	Loss: 3.4330
Training Epoch: 9 [12288/50176]	Loss: 3.4938
Training Epoch: 9 [13312/50176]	Loss: 3.5016
Training Epoch: 9 [14336/50176]	Loss: 3.5695
Training Epoch: 9 [15360/50176]	Loss: 3.5051
Training Epoch: 9 [16384/50176]	Loss: 3.5803
Training Epoch: 9 [17408/50176]	Loss: 3.5431
Training Epoch: 9 [18432/50176]	Loss: 3.4820
Training Epoch: 9 [19456/50176]	Loss: 3.5264
Training Epoch: 9 [20480/50176]	Loss: 3.4985
Training Epoch: 9 [21504/50176]	Loss: 3.4523
Training Epoch: 9 [22528/50176]	Loss: 3.4102
Training Epoch: 9 [23552/50176]	Loss: 3.3959
Training Epoch: 9 [24576/50176]	Loss: 3.4845
Training Epoch: 9 [25600/50176]	Loss: 3.4519
Training Epoch: 9 [26624/50176]	Loss: 3.4942
Training Epoch: 9 [27648/50176]	Loss: 3.4687
Training Epoch: 9 [28672/50176]	Loss: 3.4334
Training Epoch: 9 [29696/50176]	Loss: 3.4277
Training Epoch: 9 [30720/50176]	Loss: 3.4305
Training Epoch: 9 [31744/50176]	Loss: 3.4394
Training Epoch: 9 [32768/50176]	Loss: 3.4515
Training Epoch: 9 [33792/50176]	Loss: 3.4105
Training Epoch: 9 [34816/50176]	Loss: 3.4503
Training Epoch: 9 [35840/50176]	Loss: 3.4052
Training Epoch: 9 [36864/50176]	Loss: 3.4449
Training Epoch: 9 [37888/50176]	Loss: 3.4778
Training Epoch: 9 [38912/50176]	Loss: 3.5320
Training Epoch: 9 [39936/50176]	Loss: 3.4574
Training Epoch: 9 [40960/50176]	Loss: 3.5192
Training Epoch: 9 [41984/50176]	Loss: 3.4055
Training Epoch: 9 [43008/50176]	Loss: 3.4545
Training Epoch: 9 [44032/50176]	Loss: 3.3940
Training Epoch: 9 [45056/50176]	Loss: 3.3888
Training Epoch: 9 [46080/50176]	Loss: 3.4582
Training Epoch: 9 [47104/50176]	Loss: 3.4595
Training Epoch: 9 [48128/50176]	Loss: 3.4585
Training Epoch: 9 [49152/50176]	Loss: 3.3712
Training Epoch: 9 [50176/50176]	Loss: 3.3367
2022-12-06 18:19:37.560 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:19:37,610 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.91 energy=493.28
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Up to epoch 10: time=529.22, energy=68806.77, cost=80709.85
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Expected next epoch: time=576.32, energy=75494.64, cost=88175.35
2022-12-06 13:19:37,611 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0673, Accuracy: 0.0098
2022-12-06 13:19:37,853 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:19:37,854 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:19:37.856 [ZeusMonitor] Monitor started.
2022-12-06 18:19:37.856 [ZeusMonitor] Running indefinitely. 2022-12-06 18:19:37.856 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:19:37.856 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 13:20:22,039 [ZeusDataLoader(train)] train epoch 11 done: time=44.42 energy=6236.57
2022-12-06 13:20:22,043 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 3.4147
Training Epoch: 10 [2048/50176]	Loss: 3.3581
Training Epoch: 10 [3072/50176]	Loss: 3.3155
Training Epoch: 10 [4096/50176]	Loss: 3.3547
Training Epoch: 10 [5120/50176]	Loss: 3.4108
Training Epoch: 10 [6144/50176]	Loss: 3.3885
Training Epoch: 10 [7168/50176]	Loss: 3.3562
Training Epoch: 10 [8192/50176]	Loss: 3.3064
Training Epoch: 10 [9216/50176]	Loss: 3.2513
Training Epoch: 10 [10240/50176]	Loss: 3.2666
Training Epoch: 10 [11264/50176]	Loss: 3.3299
Training Epoch: 10 [12288/50176]	Loss: 3.3535
Training Epoch: 10 [13312/50176]	Loss: 3.4319
Training Epoch: 10 [14336/50176]	Loss: 3.3888
Training Epoch: 10 [15360/50176]	Loss: 3.3118
Training Epoch: 10 [16384/50176]	Loss: 3.4316
Training Epoch: 10 [17408/50176]	Loss: 3.3718
Training Epoch: 10 [18432/50176]	Loss: 3.2991
Training Epoch: 10 [19456/50176]	Loss: 3.3329
Training Epoch: 10 [20480/50176]	Loss: 3.3772
Training Epoch: 10 [21504/50176]	Loss: 3.3842
Training Epoch: 10 [22528/50176]	Loss: 3.3035
Training Epoch: 10 [23552/50176]	Loss: 3.2838
Training Epoch: 10 [24576/50176]	Loss: 3.2922
Training Epoch: 10 [25600/50176]	Loss: 3.3224
Training Epoch: 10 [26624/50176]	Loss: 3.3035
Training Epoch: 10 [27648/50176]	Loss: 3.2957
Training Epoch: 10 [28672/50176]	Loss: 3.2821
Training Epoch: 10 [29696/50176]	Loss: 3.3836
Training Epoch: 10 [30720/50176]	Loss: 3.3171
Training Epoch: 10 [31744/50176]	Loss: 3.4298
Training Epoch: 10 [32768/50176]	Loss: 3.3268
Training Epoch: 10 [33792/50176]	Loss: 3.3105
Training Epoch: 10 [34816/50176]	Loss: 3.3288
Training Epoch: 10 [35840/50176]	Loss: 3.3712
Training Epoch: 10 [36864/50176]	Loss: 3.3304
Training Epoch: 10 [37888/50176]	Loss: 3.2122
Training Epoch: 10 [38912/50176]	Loss: 3.2793
Training Epoch: 10 [39936/50176]	Loss: 3.3663
Training Epoch: 10 [40960/50176]	Loss: 3.2236
Training Epoch: 10 [41984/50176]	Loss: 3.2492
Training Epoch: 10 [43008/50176]	Loss: 3.3328
Training Epoch: 10 [44032/50176]	Loss: 3.2647
Training Epoch: 10 [45056/50176]	Loss: 3.2895
Training Epoch: 10 [46080/50176]	Loss: 3.1991
Training Epoch: 10 [47104/50176]	Loss: 3.2304
Training Epoch: 10 [48128/50176]	Loss: 3.2926
Training Epoch: 10 [49152/50176]	Loss: 3.2884
Training Epoch: 10 [50176/50176]	Loss: 3.2553
2022-12-06 18:20:25.768 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:20:25,787 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.74 energy=469.83
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Up to epoch 11: time=577.37, energy=75513.17, cost=88276.74
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Expected next epoch: time=624.48, energy=82201.05, cost=95742.23
2022-12-06 13:20:25,788 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.1097, Accuracy: 0.0098
2022-12-06 13:20:26,021 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:20:26,021 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:20:26.023 [ZeusMonitor] Monitor started.
2022-12-06 18:20:26.023 [ZeusMonitor] Running indefinitely. 2022-12-06 18:20:26.023 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:20:26.023 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 13:21:10,195 [ZeusDataLoader(train)] train epoch 12 done: time=44.40 energy=6255.34
2022-12-06 13:21:10,199 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 3.1916
Training Epoch: 11 [2048/50176]	Loss: 3.1975
Training Epoch: 11 [3072/50176]	Loss: 3.1710
Training Epoch: 11 [4096/50176]	Loss: 3.2554
Training Epoch: 11 [5120/50176]	Loss: 3.3353
Training Epoch: 11 [6144/50176]	Loss: 3.1413
Training Epoch: 11 [7168/50176]	Loss: 3.2715
Training Epoch: 11 [8192/50176]	Loss: 3.2078
Training Epoch: 11 [9216/50176]	Loss: 3.2155
Training Epoch: 11 [10240/50176]	Loss: 3.3048
Training Epoch: 11 [11264/50176]	Loss: 3.2656
Training Epoch: 11 [12288/50176]	Loss: 3.1847
Training Epoch: 11 [13312/50176]	Loss: 3.3653
Training Epoch: 11 [14336/50176]	Loss: 3.2306
Training Epoch: 11 [15360/50176]	Loss: 3.2507
Training Epoch: 11 [16384/50176]	Loss: 3.1903
Training Epoch: 11 [17408/50176]	Loss: 3.2020
Training Epoch: 11 [18432/50176]	Loss: 3.1738
Training Epoch: 11 [19456/50176]	Loss: 3.1806
Training Epoch: 11 [20480/50176]	Loss: 3.2296
Training Epoch: 11 [21504/50176]	Loss: 3.1704
Training Epoch: 11 [22528/50176]	Loss: 3.1999
Training Epoch: 11 [23552/50176]	Loss: 3.3470
Training Epoch: 11 [24576/50176]	Loss: 3.1717
Training Epoch: 11 [25600/50176]	Loss: 3.2275
Training Epoch: 11 [26624/50176]	Loss: 3.0844
Training Epoch: 11 [27648/50176]	Loss: 3.2539
Training Epoch: 11 [28672/50176]	Loss: 3.2392
Training Epoch: 11 [29696/50176]	Loss: 3.1402
Training Epoch: 11 [30720/50176]	Loss: 3.1781
Training Epoch: 11 [31744/50176]	Loss: 3.1775
Training Epoch: 11 [32768/50176]	Loss: 3.1969
Training Epoch: 11 [33792/50176]	Loss: 3.1047
Training Epoch: 11 [34816/50176]	Loss: 3.2270
Training Epoch: 11 [35840/50176]	Loss: 3.2368
Training Epoch: 11 [36864/50176]	Loss: 3.2464
Training Epoch: 11 [37888/50176]	Loss: 3.1733
Training Epoch: 11 [38912/50176]	Loss: 3.2188
Training Epoch: 11 [39936/50176]	Loss: 3.1699
Training Epoch: 11 [40960/50176]	Loss: 3.2008
Training Epoch: 11 [41984/50176]	Loss: 3.1797
Training Epoch: 11 [43008/50176]	Loss: 3.2759
Training Epoch: 11 [44032/50176]	Loss: 3.1192
Training Epoch: 11 [45056/50176]	Loss: 3.1691
Training Epoch: 11 [46080/50176]	Loss: 3.0474
Training Epoch: 11 [47104/50176]	Loss: 3.2486
Training Epoch: 11 [48128/50176]	Loss: 3.1426
Training Epoch: 11 [49152/50176]	Loss: 3.1231
Training Epoch: 11 [50176/50176]	Loss: 3.1871
2022-12-06 18:21:13.933 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:21:13,946 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.74 energy=476.57
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Up to epoch 12: time=625.51, energy=82245.08, cost=95854.82
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Expected next epoch: time=672.62, energy=88932.95, cost=103320.32
2022-12-06 13:21:13,947 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.2583, Accuracy: 0.0098
2022-12-06 13:21:14,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:21:14,139 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:21:14.142 [ZeusMonitor] Monitor started.
2022-12-06 18:21:14.142 [ZeusMonitor] Running indefinitely. 2022-12-06 18:21:14.142 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:21:14.142 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 13:21:58,181 [ZeusDataLoader(train)] train epoch 13 done: time=44.23 energy=6242.06
2022-12-06 13:21:58,185 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 3.1198
Training Epoch: 12 [2048/50176]	Loss: 3.1591
Training Epoch: 12 [3072/50176]	Loss: 3.1094
Training Epoch: 12 [4096/50176]	Loss: 3.0812
Training Epoch: 12 [5120/50176]	Loss: 2.9681
Training Epoch: 12 [6144/50176]	Loss: 3.1242
Training Epoch: 12 [7168/50176]	Loss: 3.2051
Training Epoch: 12 [8192/50176]	Loss: 3.0395
Training Epoch: 12 [9216/50176]	Loss: 3.0865
Training Epoch: 12 [10240/50176]	Loss: 3.0607
Training Epoch: 12 [11264/50176]	Loss: 3.2161
Training Epoch: 12 [12288/50176]	Loss: 3.0637
Training Epoch: 12 [13312/50176]	Loss: 3.0796
Training Epoch: 12 [14336/50176]	Loss: 3.1137
Training Epoch: 12 [15360/50176]	Loss: 2.9816
Training Epoch: 12 [16384/50176]	Loss: 3.0772
Training Epoch: 12 [17408/50176]	Loss: 3.0685
Training Epoch: 12 [18432/50176]	Loss: 3.0581
Training Epoch: 12 [19456/50176]	Loss: 3.0609
Training Epoch: 12 [20480/50176]	Loss: 3.1079
Training Epoch: 12 [21504/50176]	Loss: 3.0912
Training Epoch: 12 [22528/50176]	Loss: 3.0825
Training Epoch: 12 [23552/50176]	Loss: 3.0972
Training Epoch: 12 [24576/50176]	Loss: 2.9623
Training Epoch: 12 [25600/50176]	Loss: 3.0964
Training Epoch: 12 [26624/50176]	Loss: 3.0817
Training Epoch: 12 [27648/50176]	Loss: 3.0392
Training Epoch: 12 [28672/50176]	Loss: 3.0751
Training Epoch: 12 [29696/50176]	Loss: 3.0463
Training Epoch: 12 [30720/50176]	Loss: 3.0574
Training Epoch: 12 [31744/50176]	Loss: 3.0251
Training Epoch: 12 [32768/50176]	Loss: 3.1301
Training Epoch: 12 [33792/50176]	Loss: 2.9677
Training Epoch: 12 [34816/50176]	Loss: 3.0336
Training Epoch: 12 [35840/50176]	Loss: 3.0472
Training Epoch: 12 [36864/50176]	Loss: 3.0548
Training Epoch: 12 [37888/50176]	Loss: 3.0693
Training Epoch: 12 [38912/50176]	Loss: 3.0422
Training Epoch: 12 [39936/50176]	Loss: 3.1210
Training Epoch: 12 [40960/50176]	Loss: 3.0249
Training Epoch: 12 [41984/50176]	Loss: 3.0330
Training Epoch: 12 [43008/50176]	Loss: 3.0411
Training Epoch: 12 [44032/50176]	Loss: 3.1491
Training Epoch: 12 [45056/50176]	Loss: 2.9713
Training Epoch: 12 [46080/50176]	Loss: 3.0584
Training Epoch: 12 [47104/50176]	Loss: 2.9745
Training Epoch: 12 [48128/50176]	Loss: 2.9471
Training Epoch: 12 [49152/50176]	Loss: 3.0095
Training Epoch: 12 [50176/50176]	Loss: 2.8990
2022-12-06 18:22:02.034 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:22:02,082 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.89 energy=490.96
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Up to epoch 13: time=673.63, energy=88978.09, cost=103431.39
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Expected next epoch: time=720.73, energy=95665.97, cost=110896.89
2022-12-06 13:22:02,083 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0317, Accuracy: 0.0098
2022-12-06 13:22:02,317 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:22:02,318 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:22:02.328 [ZeusMonitor] Monitor started.
2022-12-06 18:22:02.328 [ZeusMonitor] Running indefinitely. 2022-12-06 18:22:02.328 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:22:02.328 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 13:22:46,710 [ZeusDataLoader(train)] train epoch 14 done: time=44.62 energy=6258.68
2022-12-06 13:22:46,714 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 2.9363
Training Epoch: 13 [2048/50176]	Loss: 2.9913
Training Epoch: 13 [3072/50176]	Loss: 2.9883
Training Epoch: 13 [4096/50176]	Loss: 3.0130
Training Epoch: 13 [5120/50176]	Loss: 2.9494
Training Epoch: 13 [6144/50176]	Loss: 2.9849
Training Epoch: 13 [7168/50176]	Loss: 2.9215
Training Epoch: 13 [8192/50176]	Loss: 2.9268
Training Epoch: 13 [9216/50176]	Loss: 2.9655
Training Epoch: 13 [10240/50176]	Loss: 3.0053
Training Epoch: 13 [11264/50176]	Loss: 3.0377
Training Epoch: 13 [12288/50176]	Loss: 2.9488
Training Epoch: 13 [13312/50176]	Loss: 2.9559
Training Epoch: 13 [14336/50176]	Loss: 3.0061
Training Epoch: 13 [15360/50176]	Loss: 2.9723
Training Epoch: 13 [16384/50176]	Loss: 2.9908
Training Epoch: 13 [17408/50176]	Loss: 2.9419
Training Epoch: 13 [18432/50176]	Loss: 2.9467
Training Epoch: 13 [19456/50176]	Loss: 2.9668
Training Epoch: 13 [20480/50176]	Loss: 2.8884
Training Epoch: 13 [21504/50176]	Loss: 3.0027
Training Epoch: 13 [22528/50176]	Loss: 3.0014
Training Epoch: 13 [23552/50176]	Loss: 2.9560
Training Epoch: 13 [24576/50176]	Loss: 2.9070
Training Epoch: 13 [25600/50176]	Loss: 2.9361
Training Epoch: 13 [26624/50176]	Loss: 2.9838
Training Epoch: 13 [27648/50176]	Loss: 2.9429
Training Epoch: 13 [28672/50176]	Loss: 2.9144
Training Epoch: 13 [29696/50176]	Loss: 2.9616
Training Epoch: 13 [30720/50176]	Loss: 2.9551
Training Epoch: 13 [31744/50176]	Loss: 3.0396
Training Epoch: 13 [32768/50176]	Loss: 2.9275
Training Epoch: 13 [33792/50176]	Loss: 2.9917
Training Epoch: 13 [34816/50176]	Loss: 2.9746
Training Epoch: 13 [35840/50176]	Loss: 3.0766
Training Epoch: 13 [36864/50176]	Loss: 3.0009
Training Epoch: 13 [37888/50176]	Loss: 2.9609
Training Epoch: 13 [38912/50176]	Loss: 2.8715
Training Epoch: 13 [39936/50176]	Loss: 2.8311
Training Epoch: 13 [40960/50176]	Loss: 2.8936
Training Epoch: 13 [41984/50176]	Loss: 2.9481
Training Epoch: 13 [43008/50176]	Loss: 2.8452
Training Epoch: 13 [44032/50176]	Loss: 2.9148
Training Epoch: 13 [45056/50176]	Loss: 2.9685
Training Epoch: 13 [46080/50176]	Loss: 2.8854
Training Epoch: 13 [47104/50176]	Loss: 2.9209
Training Epoch: 13 [48128/50176]	Loss: 2.8874
Training Epoch: 13 [49152/50176]	Loss: 2.8172
Training Epoch: 13 [50176/50176]	Loss: 2.8691
2022-12-06 18:22:50.458 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:22:50,511 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.79 energy=471.97
2022-12-06 13:22:50,511 [ZeusDataLoader(train)] Up to epoch 14: time=722.04, energy=95708.74, cost=111032.47
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Expected next epoch: time=769.14, energy=102396.62, cost=118497.97
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0679, Accuracy: 0.0098
2022-12-06 13:22:50,755 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:22:50,756 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:22:50.758 [ZeusMonitor] Monitor started.
2022-12-06 18:22:50.758 [ZeusMonitor] Running indefinitely. 2022-12-06 18:22:50.758 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:22:50.758 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 13:23:34,605 [ZeusDataLoader(train)] train epoch 15 done: time=44.08 energy=6220.13
2022-12-06 13:23:34,608 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 2.8693
Training Epoch: 14 [2048/50176]	Loss: 2.9065
Training Epoch: 14 [3072/50176]	Loss: 2.9251
Training Epoch: 14 [4096/50176]	Loss: 2.9835
Training Epoch: 14 [5120/50176]	Loss: 2.8382
Training Epoch: 14 [6144/50176]	Loss: 2.8396
Training Epoch: 14 [7168/50176]	Loss: 2.7924
Training Epoch: 14 [8192/50176]	Loss: 2.9131
Training Epoch: 14 [9216/50176]	Loss: 2.8666
Training Epoch: 14 [10240/50176]	Loss: 2.8282
Training Epoch: 14 [11264/50176]	Loss: 2.8434
Training Epoch: 14 [12288/50176]	Loss: 2.9130
Training Epoch: 14 [13312/50176]	Loss: 2.8170
Training Epoch: 14 [14336/50176]	Loss: 2.8367
Training Epoch: 14 [15360/50176]	Loss: 2.8085
Training Epoch: 14 [16384/50176]	Loss: 2.7618
Training Epoch: 14 [17408/50176]	Loss: 2.8155
Training Epoch: 14 [18432/50176]	Loss: 2.8510
Training Epoch: 14 [19456/50176]	Loss: 2.7615
Training Epoch: 14 [20480/50176]	Loss: 2.8778
Training Epoch: 14 [21504/50176]	Loss: 2.8236
Training Epoch: 14 [22528/50176]	Loss: 2.8409
Training Epoch: 14 [23552/50176]	Loss: 2.8305
Training Epoch: 14 [24576/50176]	Loss: 2.7840
Training Epoch: 14 [25600/50176]	Loss: 2.8725
Training Epoch: 14 [26624/50176]	Loss: 2.7904
Training Epoch: 14 [27648/50176]	Loss: 2.7450
Training Epoch: 14 [28672/50176]	Loss: 2.7953
Training Epoch: 14 [29696/50176]	Loss: 2.8503
Training Epoch: 14 [30720/50176]	Loss: 2.8700
Training Epoch: 14 [31744/50176]	Loss: 2.8180
Training Epoch: 14 [32768/50176]	Loss: 2.8769
Training Epoch: 14 [33792/50176]	Loss: 2.8771
Training Epoch: 14 [34816/50176]	Loss: 2.9095
Training Epoch: 14 [35840/50176]	Loss: 2.9009
Training Epoch: 14 [36864/50176]	Loss: 2.9538
Training Epoch: 14 [37888/50176]	Loss: 2.7268
Training Epoch: 14 [38912/50176]	Loss: 2.8197
Training Epoch: 14 [39936/50176]	Loss: 2.7596
Training Epoch: 14 [40960/50176]	Loss: 2.8158
Training Epoch: 14 [41984/50176]	Loss: 2.9200
Training Epoch: 14 [43008/50176]	Loss: 2.7906
Training Epoch: 14 [44032/50176]	Loss: 2.7744
Training Epoch: 14 [45056/50176]	Loss: 2.7915
Training Epoch: 14 [46080/50176]	Loss: 2.8891
Training Epoch: 14 [47104/50176]	Loss: 2.7466
Training Epoch: 14 [48128/50176]	Loss: 2.8169
Training Epoch: 14 [49152/50176]	Loss: 2.8233
Training Epoch: 14 [50176/50176]	Loss: 2.8078
2022-12-06 18:23:38.370 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:23:38,421 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.81 energy=487.70
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Up to epoch 15: time=769.93, energy=102416.57, cost=118576.76
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Expected next epoch: time=817.03, energy=109104.45, cost=126042.26
2022-12-06 13:23:38,423 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.5139, Accuracy: 0.0098
2022-12-06 13:23:38,683 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:23:38,684 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:23:38.686 [ZeusMonitor] Monitor started.
2022-12-06 18:23:38.686 [ZeusMonitor] Running indefinitely. 2022-12-06 18:23:38.686 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:23:38.686 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 13:24:23,070 [ZeusDataLoader(train)] train epoch 16 done: time=44.64 energy=6264.23
2022-12-06 13:24:23,074 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 2.8356
Training Epoch: 15 [2048/50176]	Loss: 2.7799
Training Epoch: 15 [3072/50176]	Loss: 2.7233
Training Epoch: 15 [4096/50176]	Loss: 2.7574
Training Epoch: 15 [5120/50176]	Loss: 2.7150
Training Epoch: 15 [6144/50176]	Loss: 2.7261
Training Epoch: 15 [7168/50176]	Loss: 2.7503
Training Epoch: 15 [8192/50176]	Loss: 2.8410
Training Epoch: 15 [9216/50176]	Loss: 2.7380
Training Epoch: 15 [10240/50176]	Loss: 2.7736
Training Epoch: 15 [11264/50176]	Loss: 2.7570
Training Epoch: 15 [12288/50176]	Loss: 2.9031
Training Epoch: 15 [13312/50176]	Loss: 2.6901
Training Epoch: 15 [14336/50176]	Loss: 2.7602
Training Epoch: 15 [15360/50176]	Loss: 2.7565
Training Epoch: 15 [16384/50176]	Loss: 2.8957
Training Epoch: 15 [17408/50176]	Loss: 2.7103
Training Epoch: 15 [18432/50176]	Loss: 2.7478
Training Epoch: 15 [19456/50176]	Loss: 2.6595
Training Epoch: 15 [20480/50176]	Loss: 2.7096
Training Epoch: 15 [21504/50176]	Loss: 2.6953
Training Epoch: 15 [22528/50176]	Loss: 2.8816
Training Epoch: 15 [23552/50176]	Loss: 2.7615
Training Epoch: 15 [24576/50176]	Loss: 2.7095
Training Epoch: 15 [25600/50176]	Loss: 2.7897
Training Epoch: 15 [26624/50176]	Loss: 2.7373
Training Epoch: 15 [27648/50176]	Loss: 2.7749
Training Epoch: 15 [28672/50176]	Loss: 2.6907
Training Epoch: 15 [29696/50176]	Loss: 2.7203
Training Epoch: 15 [30720/50176]	Loss: 2.7692
Training Epoch: 15 [31744/50176]	Loss: 2.7848
Training Epoch: 15 [32768/50176]	Loss: 2.7039
Training Epoch: 15 [33792/50176]	Loss: 2.7148
Training Epoch: 15 [34816/50176]	Loss: 2.7661
Training Epoch: 15 [35840/50176]	Loss: 2.7875
Training Epoch: 15 [36864/50176]	Loss: 2.5907
Training Epoch: 15 [37888/50176]	Loss: 2.7491
Training Epoch: 15 [38912/50176]	Loss: 2.6677
Training Epoch: 15 [39936/50176]	Loss: 2.6762
Training Epoch: 15 [40960/50176]	Loss: 2.7887
Training Epoch: 15 [41984/50176]	Loss: 2.7390
Training Epoch: 15 [43008/50176]	Loss: 2.7858
Training Epoch: 15 [44032/50176]	Loss: 2.7090
Training Epoch: 15 [45056/50176]	Loss: 2.6917
Training Epoch: 15 [46080/50176]	Loss: 2.6854
Training Epoch: 15 [47104/50176]	Loss: 2.7002
Training Epoch: 15 [48128/50176]	Loss: 2.7113
Training Epoch: 15 [49152/50176]	Loss: 2.6765
Training Epoch: 15 [50176/50176]	Loss: 2.6108
2022-12-06 18:24:26.778 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:24:26,788 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.71 energy=468.56
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Up to epoch 16: time=818.27, energy=109149.37, cost=126173.36
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Expected next epoch: time=865.37, energy=115837.25, cost=133638.85
2022-12-06 13:24:26,789 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.1142, Accuracy: 0.0084
2022-12-06 13:24:27,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:24:27,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:24:27.036 [ZeusMonitor] Monitor started.
2022-12-06 18:24:27.036 [ZeusMonitor] Running indefinitely. 2022-12-06 18:24:27.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:24:27.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 13:25:11,191 [ZeusDataLoader(train)] train epoch 17 done: time=44.39 energy=6252.33
2022-12-06 13:25:11,194 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 2.6719
Training Epoch: 16 [2048/50176]	Loss: 2.6244
Training Epoch: 16 [3072/50176]	Loss: 2.5834
Training Epoch: 16 [4096/50176]	Loss: 2.5874
Training Epoch: 16 [5120/50176]	Loss: 2.7244
Training Epoch: 16 [6144/50176]	Loss: 2.6537
Training Epoch: 16 [7168/50176]	Loss: 2.5910
Training Epoch: 16 [8192/50176]	Loss: 2.5344
Training Epoch: 16 [9216/50176]	Loss: 2.6206
Training Epoch: 16 [10240/50176]	Loss: 2.5906
Training Epoch: 16 [11264/50176]	Loss: 2.6626
Training Epoch: 16 [12288/50176]	Loss: 2.6425
Training Epoch: 16 [13312/50176]	Loss: 2.6515
Training Epoch: 16 [14336/50176]	Loss: 2.6229
Training Epoch: 16 [15360/50176]	Loss: 2.7348
Training Epoch: 16 [16384/50176]	Loss: 2.6258
Training Epoch: 16 [17408/50176]	Loss: 2.6552
Training Epoch: 16 [18432/50176]	Loss: 2.7643
Training Epoch: 16 [19456/50176]	Loss: 2.6582
Training Epoch: 16 [20480/50176]	Loss: 2.5817
Training Epoch: 16 [21504/50176]	Loss: 2.6895
Training Epoch: 16 [22528/50176]	Loss: 2.5878
Training Epoch: 16 [23552/50176]	Loss: 2.6856
Training Epoch: 16 [24576/50176]	Loss: 2.6103
Training Epoch: 16 [25600/50176]	Loss: 2.5905
Training Epoch: 16 [26624/50176]	Loss: 2.6143
Training Epoch: 16 [27648/50176]	Loss: 2.7192
Training Epoch: 16 [28672/50176]	Loss: 2.6511
Training Epoch: 16 [29696/50176]	Loss: 2.6089
Training Epoch: 16 [30720/50176]	Loss: 2.6262
Training Epoch: 16 [31744/50176]	Loss: 2.6211
Training Epoch: 16 [32768/50176]	Loss: 2.6520
Training Epoch: 16 [33792/50176]	Loss: 2.6046
Training Epoch: 16 [34816/50176]	Loss: 2.7132
Training Epoch: 16 [35840/50176]	Loss: 2.7565
Training Epoch: 16 [36864/50176]	Loss: 2.6472
Training Epoch: 16 [37888/50176]	Loss: 2.5292
Training Epoch: 16 [38912/50176]	Loss: 2.5609
Training Epoch: 16 [39936/50176]	Loss: 2.7421
Training Epoch: 16 [40960/50176]	Loss: 2.5953
Training Epoch: 16 [41984/50176]	Loss: 2.6450
Training Epoch: 16 [43008/50176]	Loss: 2.6192
Training Epoch: 16 [44032/50176]	Loss: 2.6051
Training Epoch: 16 [45056/50176]	Loss: 2.6076
Training Epoch: 16 [46080/50176]	Loss: 2.6619
Training Epoch: 16 [47104/50176]	Loss: 2.6394
Training Epoch: 16 [48128/50176]	Loss: 2.6579
Training Epoch: 16 [49152/50176]	Loss: 2.6109
Training Epoch: 16 [50176/50176]	Loss: 2.6249
2022-12-06 18:25:14.950 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:25:15,001 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=474.20
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Up to epoch 17: time=866.46, energy=115875.89, cost=133753.53
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Expected next epoch: time=913.57, energy=122563.77, cost=141219.03
2022-12-06 13:25:15,003 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 4.2636, Accuracy: 0.0107
2022-12-06 13:25:15,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:25:15,238 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:25:15.240 [ZeusMonitor] Monitor started.
2022-12-06 18:25:15.240 [ZeusMonitor] Running indefinitely. 2022-12-06 18:25:15.240 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:25:15.240 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 13:25:58,870 [ZeusDataLoader(train)] train epoch 18 done: time=43.86 energy=6211.20
2022-12-06 13:25:58,873 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 2.5583
Training Epoch: 17 [2048/50176]	Loss: 2.5444
Training Epoch: 17 [3072/50176]	Loss: 2.4287
Training Epoch: 17 [4096/50176]	Loss: 2.5388
Training Epoch: 17 [5120/50176]	Loss: 2.6707
Training Epoch: 17 [6144/50176]	Loss: 2.5082
Training Epoch: 17 [7168/50176]	Loss: 2.5658
Training Epoch: 17 [8192/50176]	Loss: 2.4826
Training Epoch: 17 [9216/50176]	Loss: 2.5460
Training Epoch: 17 [10240/50176]	Loss: 2.5146
Training Epoch: 17 [11264/50176]	Loss: 2.4838
Training Epoch: 17 [12288/50176]	Loss: 2.5662
Training Epoch: 17 [13312/50176]	Loss: 2.5906
Training Epoch: 17 [14336/50176]	Loss: 2.5878
Training Epoch: 17 [15360/50176]	Loss: 2.5924
Training Epoch: 17 [16384/50176]	Loss: 2.5646
Training Epoch: 17 [17408/50176]	Loss: 2.6018
Training Epoch: 17 [18432/50176]	Loss: 2.6401
Training Epoch: 17 [19456/50176]	Loss: 2.4757
Training Epoch: 17 [20480/50176]	Loss: 2.5697
Training Epoch: 17 [21504/50176]	Loss: 2.6031
Training Epoch: 17 [22528/50176]	Loss: 2.6460
Training Epoch: 17 [23552/50176]	Loss: 2.5445
Training Epoch: 17 [24576/50176]	Loss: 2.6533
Training Epoch: 17 [25600/50176]	Loss: 2.5663
Training Epoch: 17 [26624/50176]	Loss: 2.5321
Training Epoch: 17 [27648/50176]	Loss: 2.5515
Training Epoch: 17 [28672/50176]	Loss: 2.5158
Training Epoch: 17 [29696/50176]	Loss: 2.5945
Training Epoch: 17 [30720/50176]	Loss: 2.6148
Training Epoch: 17 [31744/50176]	Loss: 2.4940
Training Epoch: 17 [32768/50176]	Loss: 2.5287
Training Epoch: 17 [33792/50176]	Loss: 2.6950
Training Epoch: 17 [34816/50176]	Loss: 2.5467
Training Epoch: 17 [35840/50176]	Loss: 2.4873
Training Epoch: 17 [36864/50176]	Loss: 2.5756
Training Epoch: 17 [37888/50176]	Loss: 2.5146
Training Epoch: 17 [38912/50176]	Loss: 2.5907
Training Epoch: 17 [39936/50176]	Loss: 2.6683
Training Epoch: 17 [40960/50176]	Loss: 2.5523
Training Epoch: 17 [41984/50176]	Loss: 2.5370
Training Epoch: 17 [43008/50176]	Loss: 2.4923
Training Epoch: 17 [44032/50176]	Loss: 2.5591
Training Epoch: 17 [45056/50176]	Loss: 2.5443
Training Epoch: 17 [46080/50176]	Loss: 2.4525
Training Epoch: 17 [47104/50176]	Loss: 2.4882
Training Epoch: 17 [48128/50176]	Loss: 2.5506
Training Epoch: 17 [49152/50176]	Loss: 2.5103
Training Epoch: 17 [50176/50176]	Loss: 2.5528
2022-12-06 18:26:02.597 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:26:02,608 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.73 energy=471.25
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Up to epoch 18: time=914.05, energy=122558.35, cost=141258.54
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Expected next epoch: time=961.15, energy=129246.22, cost=148724.03
2022-12-06 13:26:02,610 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0537, Accuracy: 0.0098
2022-12-06 13:26:02,854 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:26:02,855 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:26:02.856 [ZeusMonitor] Monitor started.
2022-12-06 18:26:02.857 [ZeusMonitor] Running indefinitely. 2022-12-06 18:26:02.857 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:26:02.857 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 13:26:46,877 [ZeusDataLoader(train)] train epoch 19 done: time=44.26 energy=6236.97
2022-12-06 13:26:46,881 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 2.4687
Training Epoch: 18 [2048/50176]	Loss: 2.5182
Training Epoch: 18 [3072/50176]	Loss: 2.4959
Training Epoch: 18 [4096/50176]	Loss: 2.3882
Training Epoch: 18 [5120/50176]	Loss: 2.4640
Training Epoch: 18 [6144/50176]	Loss: 2.4895
Training Epoch: 18 [7168/50176]	Loss: 2.4555
Training Epoch: 18 [8192/50176]	Loss: 2.5092
Training Epoch: 18 [9216/50176]	Loss: 2.4876
Training Epoch: 18 [10240/50176]	Loss: 2.4444
Training Epoch: 18 [11264/50176]	Loss: 2.5029
Training Epoch: 18 [12288/50176]	Loss: 2.4967
Training Epoch: 18 [13312/50176]	Loss: 2.5149
Training Epoch: 18 [14336/50176]	Loss: 2.4708
Training Epoch: 18 [15360/50176]	Loss: 2.4464
Training Epoch: 18 [16384/50176]	Loss: 2.5486
Training Epoch: 18 [17408/50176]	Loss: 2.5349
Training Epoch: 18 [18432/50176]	Loss: 2.5312
Training Epoch: 18 [19456/50176]	Loss: 2.5242
Training Epoch: 18 [20480/50176]	Loss: 2.4571
Training Epoch: 18 [21504/50176]	Loss: 2.5308
Training Epoch: 18 [22528/50176]	Loss: 2.5425
Training Epoch: 18 [23552/50176]	Loss: 2.4670
Training Epoch: 18 [24576/50176]	Loss: 2.4502
Training Epoch: 18 [25600/50176]	Loss: 2.4647
Training Epoch: 18 [26624/50176]	Loss: 2.3465
Training Epoch: 18 [27648/50176]	Loss: 2.5155
Training Epoch: 18 [28672/50176]	Loss: 2.5132
Training Epoch: 18 [29696/50176]	Loss: 2.5120
Training Epoch: 18 [30720/50176]	Loss: 2.5076
Training Epoch: 18 [31744/50176]	Loss: 2.5076
Training Epoch: 18 [32768/50176]	Loss: 2.4129
Training Epoch: 18 [33792/50176]	Loss: 2.4612
Training Epoch: 18 [34816/50176]	Loss: 2.4555
Training Epoch: 18 [35840/50176]	Loss: 2.5346
Training Epoch: 18 [36864/50176]	Loss: 2.4576
Training Epoch: 18 [37888/50176]	Loss: 2.4097
Training Epoch: 18 [38912/50176]	Loss: 2.4363
Training Epoch: 18 [39936/50176]	Loss: 2.4690
Training Epoch: 18 [40960/50176]	Loss: 2.3737
Training Epoch: 18 [41984/50176]	Loss: 2.4018
Training Epoch: 18 [43008/50176]	Loss: 2.4780
Training Epoch: 18 [44032/50176]	Loss: 2.4611
Training Epoch: 18 [45056/50176]	Loss: 2.4337
Training Epoch: 18 [46080/50176]	Loss: 2.4027
Training Epoch: 18 [47104/50176]	Loss: 2.4485
Training Epoch: 18 [48128/50176]	Loss: 2.4754
Training Epoch: 18 [49152/50176]	Loss: 2.4364
Training Epoch: 18 [50176/50176]	Loss: 2.4578
2022-12-06 18:26:50.640 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:26:50,675 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.79 energy=482.60
2022-12-06 13:26:50,675 [ZeusDataLoader(train)] Up to epoch 19: time=962.10, energy=129277.91, cost=148822.30
2022-12-06 13:26:50,675 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:26:50,676 [ZeusDataLoader(train)] Expected next epoch: time=1009.20, energy=135965.79, cost=156287.80
2022-12-06 13:26:50,676 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0318, Accuracy: 0.0099
2022-12-06 13:26:50,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:26:50,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:26:50.925 [ZeusMonitor] Monitor started.
2022-12-06 18:26:50.925 [ZeusMonitor] Running indefinitely. 2022-12-06 18:26:50.925 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:26:50.925 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 13:27:35,077 [ZeusDataLoader(train)] train epoch 20 done: time=44.39 energy=6234.69
2022-12-06 13:27:35,081 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 2.3347
Training Epoch: 19 [2048/50176]	Loss: 2.4669
Training Epoch: 19 [3072/50176]	Loss: 2.3621
Training Epoch: 19 [4096/50176]	Loss: 2.4183
Training Epoch: 19 [5120/50176]	Loss: 2.2826
Training Epoch: 19 [6144/50176]	Loss: 2.3839
Training Epoch: 19 [7168/50176]	Loss: 2.2741
Training Epoch: 19 [8192/50176]	Loss: 2.3651
Training Epoch: 19 [9216/50176]	Loss: 2.4024
Training Epoch: 19 [10240/50176]	Loss: 2.4953
Training Epoch: 19 [11264/50176]	Loss: 2.4452
Training Epoch: 19 [12288/50176]	Loss: 2.3587
Training Epoch: 19 [13312/50176]	Loss: 2.4111
Training Epoch: 19 [14336/50176]	Loss: 2.4398
Training Epoch: 19 [15360/50176]	Loss: 2.4747
Training Epoch: 19 [16384/50176]	Loss: 2.3288
Training Epoch: 19 [17408/50176]	Loss: 2.4522
Training Epoch: 19 [18432/50176]	Loss: 2.3655
Training Epoch: 19 [19456/50176]	Loss: 2.3876
Training Epoch: 19 [20480/50176]	Loss: 2.4343
Training Epoch: 19 [21504/50176]	Loss: 2.4702
Training Epoch: 19 [22528/50176]	Loss: 2.4183
Training Epoch: 19 [23552/50176]	Loss: 2.4865
Training Epoch: 19 [24576/50176]	Loss: 2.4025
Training Epoch: 19 [25600/50176]	Loss: 2.3604
Training Epoch: 19 [26624/50176]	Loss: 2.4173
Training Epoch: 19 [27648/50176]	Loss: 2.3447
Training Epoch: 19 [28672/50176]	Loss: 2.3530
Training Epoch: 19 [29696/50176]	Loss: 2.4356
Training Epoch: 19 [30720/50176]	Loss: 2.3906
Training Epoch: 19 [31744/50176]	Loss: 2.3613
Training Epoch: 19 [32768/50176]	Loss: 2.4544
Training Epoch: 19 [33792/50176]	Loss: 2.3562
Training Epoch: 19 [34816/50176]	Loss: 2.3969
Training Epoch: 19 [35840/50176]	Loss: 2.3095
Training Epoch: 19 [36864/50176]	Loss: 2.3792
Training Epoch: 19 [37888/50176]	Loss: 2.3637
Training Epoch: 19 [38912/50176]	Loss: 2.4043
Training Epoch: 19 [39936/50176]	Loss: 2.3681
Training Epoch: 19 [40960/50176]	Loss: 2.2853
Training Epoch: 19 [41984/50176]	Loss: 2.4435
Training Epoch: 19 [43008/50176]	Loss: 2.4036
Training Epoch: 19 [44032/50176]	Loss: 2.3311
Training Epoch: 19 [45056/50176]	Loss: 2.3800
Training Epoch: 19 [46080/50176]	Loss: 2.3269
Training Epoch: 19 [47104/50176]	Loss: 2.3187
Training Epoch: 19 [48128/50176]	Loss: 2.3740
Training Epoch: 19 [49152/50176]	Loss: 2.4154
Training Epoch: 19 [50176/50176]	Loss: 2.3094
2022-12-06 18:27:38.848 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:27:38,886 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.80 energy=489.54
2022-12-06 13:27:38,886 [ZeusDataLoader(train)] Up to epoch 20: time=1010.29, energy=136002.15, cost=156401.02
2022-12-06 13:27:38,886 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:27:38,887 [ZeusDataLoader(train)] Expected next epoch: time=1057.39, energy=142690.03, cost=163866.51
2022-12-06 13:27:38,888 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0456, Accuracy: 0.0094
2022-12-06 13:27:39,160 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:27:39,161 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:27:39.162 [ZeusMonitor] Monitor started.
2022-12-06 18:27:39.162 [ZeusMonitor] Running indefinitely. 2022-12-06 18:27:39.162 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:27:39.162 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 13:28:23,444 [ZeusDataLoader(train)] train epoch 21 done: time=44.55 energy=6255.65
2022-12-06 13:28:23,447 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 2.2789
Training Epoch: 20 [2048/50176]	Loss: 2.3046
Training Epoch: 20 [3072/50176]	Loss: 2.3468
Training Epoch: 20 [4096/50176]	Loss: 2.2705
Training Epoch: 20 [5120/50176]	Loss: 2.2140
Training Epoch: 20 [6144/50176]	Loss: 2.3541
Training Epoch: 20 [7168/50176]	Loss: 2.2646
Training Epoch: 20 [8192/50176]	Loss: 2.4108
Training Epoch: 20 [9216/50176]	Loss: 2.3353
Training Epoch: 20 [10240/50176]	Loss: 2.2711
Training Epoch: 20 [11264/50176]	Loss: 2.3327
Training Epoch: 20 [12288/50176]	Loss: 2.2848
Training Epoch: 20 [13312/50176]	Loss: 2.2279
Training Epoch: 20 [14336/50176]	Loss: 2.4338
Training Epoch: 20 [15360/50176]	Loss: 2.4173
Training Epoch: 20 [16384/50176]	Loss: 2.3934
Training Epoch: 20 [17408/50176]	Loss: 2.3352
Training Epoch: 20 [18432/50176]	Loss: 2.2770
Training Epoch: 20 [19456/50176]	Loss: 2.3518
Training Epoch: 20 [20480/50176]	Loss: 2.3059
Training Epoch: 20 [21504/50176]	Loss: 2.3891
Training Epoch: 20 [22528/50176]	Loss: 2.3134
Training Epoch: 20 [23552/50176]	Loss: 2.2226
Training Epoch: 20 [24576/50176]	Loss: 2.3568
Training Epoch: 20 [25600/50176]	Loss: 2.4285
Training Epoch: 20 [26624/50176]	Loss: 2.2898
Training Epoch: 20 [27648/50176]	Loss: 2.2624
Training Epoch: 20 [28672/50176]	Loss: 2.3301
Training Epoch: 20 [29696/50176]	Loss: 2.2606
Training Epoch: 20 [30720/50176]	Loss: 2.3356
Training Epoch: 20 [31744/50176]	Loss: 2.3912
Training Epoch: 20 [32768/50176]	Loss: 2.3878
Training Epoch: 20 [33792/50176]	Loss: 2.2754
Training Epoch: 20 [34816/50176]	Loss: 2.4019
Training Epoch: 20 [35840/50176]	Loss: 2.2682
Training Epoch: 20 [36864/50176]	Loss: 2.4060
Training Epoch: 20 [37888/50176]	Loss: 2.2124
Training Epoch: 20 [38912/50176]	Loss: 2.3448
Training Epoch: 20 [39936/50176]	Loss: 2.3431
Training Epoch: 20 [40960/50176]	Loss: 2.3509
Training Epoch: 20 [41984/50176]	Loss: 2.2850
Training Epoch: 20 [43008/50176]	Loss: 2.2921
Training Epoch: 20 [44032/50176]	Loss: 2.2028
Training Epoch: 20 [45056/50176]	Loss: 2.2983
Training Epoch: 20 [46080/50176]	Loss: 2.3058
Training Epoch: 20 [47104/50176]	Loss: 2.3585
Training Epoch: 20 [48128/50176]	Loss: 2.3616
Training Epoch: 20 [49152/50176]	Loss: 2.3164
Training Epoch: 20 [50176/50176]	Loss: 2.2674
2022-12-06 18:28:27.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:28:27,263 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.81 energy=492.39
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Up to epoch 21: time=1058.64, energy=142750.18, cost=164006.23
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Expected next epoch: time=1105.75, energy=149438.06, cost=171471.72
2022-12-06 13:28:27,265 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.1832, Accuracy: 0.0098
2022-12-06 13:28:27,510 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:28:27,511 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:28:27.513 [ZeusMonitor] Monitor started.
2022-12-06 18:28:27.513 [ZeusMonitor] Running indefinitely. 2022-12-06 18:28:27.513 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:28:27.513 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 13:29:11,688 [ZeusDataLoader(train)] train epoch 22 done: time=44.42 energy=6244.03
2022-12-06 13:29:11,691 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 2.2492
Training Epoch: 21 [2048/50176]	Loss: 2.2148
Training Epoch: 21 [3072/50176]	Loss: 2.2290
Training Epoch: 21 [4096/50176]	Loss: 2.2914
Training Epoch: 21 [5120/50176]	Loss: 2.3007
Training Epoch: 21 [6144/50176]	Loss: 2.2385
Training Epoch: 21 [7168/50176]	Loss: 2.2189
Training Epoch: 21 [8192/50176]	Loss: 2.2819
Training Epoch: 21 [9216/50176]	Loss: 2.1977
Training Epoch: 21 [10240/50176]	Loss: 2.2003
Training Epoch: 21 [11264/50176]	Loss: 2.2351
Training Epoch: 21 [12288/50176]	Loss: 2.2513
Training Epoch: 21 [13312/50176]	Loss: 2.1895
Training Epoch: 21 [14336/50176]	Loss: 2.2641
Training Epoch: 21 [15360/50176]	Loss: 2.1991
Training Epoch: 21 [16384/50176]	Loss: 2.3187
Training Epoch: 21 [17408/50176]	Loss: 2.1764
Training Epoch: 21 [18432/50176]	Loss: 2.1697
Training Epoch: 21 [19456/50176]	Loss: 2.3302
Training Epoch: 21 [20480/50176]	Loss: 2.2072
Training Epoch: 21 [21504/50176]	Loss: 2.2613
Training Epoch: 21 [22528/50176]	Loss: 2.3176
Training Epoch: 21 [23552/50176]	Loss: 2.2654
Training Epoch: 21 [24576/50176]	Loss: 2.1361
Training Epoch: 21 [25600/50176]	Loss: 2.2576
Training Epoch: 21 [26624/50176]	Loss: 2.2701
Training Epoch: 21 [27648/50176]	Loss: 2.2681
Training Epoch: 21 [28672/50176]	Loss: 2.2378
Training Epoch: 21 [29696/50176]	Loss: 2.3373
Training Epoch: 21 [30720/50176]	Loss: 2.1854
Training Epoch: 21 [31744/50176]	Loss: 2.2095
Training Epoch: 21 [32768/50176]	Loss: 2.2034
Training Epoch: 21 [33792/50176]	Loss: 2.2387
Training Epoch: 21 [34816/50176]	Loss: 2.2216
Training Epoch: 21 [35840/50176]	Loss: 2.2394
Training Epoch: 21 [36864/50176]	Loss: 2.1296
Training Epoch: 21 [37888/50176]	Loss: 2.3355
Training Epoch: 21 [38912/50176]	Loss: 2.2759
Training Epoch: 21 [39936/50176]	Loss: 2.3663
Training Epoch: 21 [40960/50176]	Loss: 2.2109
Training Epoch: 21 [41984/50176]	Loss: 2.2495
Training Epoch: 21 [43008/50176]	Loss: 2.2255
Training Epoch: 21 [44032/50176]	Loss: 2.2700
Training Epoch: 21 [45056/50176]	Loss: 2.2590
Training Epoch: 21 [46080/50176]	Loss: 2.2446
Training Epoch: 21 [47104/50176]	Loss: 2.3132
Training Epoch: 21 [48128/50176]	Loss: 2.2322
Training Epoch: 21 [49152/50176]	Loss: 2.2462
Training Epoch: 21 [50176/50176]	Loss: 2.2756
2022-12-06 18:29:15.445 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:29:15,484 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.78 energy=479.59
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Up to epoch 22: time=1106.84, energy=149473.80, cost=171585.57
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Expected next epoch: time=1153.95, energy=156161.68, cost=179051.07
2022-12-06 13:29:15,485 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.2018, Accuracy: 0.0095
2022-12-06 13:29:15,722 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:29:15,722 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:29:15.724 [ZeusMonitor] Monitor started.
2022-12-06 18:29:15.724 [ZeusMonitor] Running indefinitely. 2022-12-06 18:29:15.724 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:29:15.724 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 13:29:59,579 [ZeusDataLoader(train)] train epoch 23 done: time=44.09 energy=6225.39
2022-12-06 13:29:59,583 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 2.1931
Training Epoch: 22 [2048/50176]	Loss: 2.2197
Training Epoch: 22 [3072/50176]	Loss: 2.2012
Training Epoch: 22 [4096/50176]	Loss: 2.0650
Training Epoch: 22 [5120/50176]	Loss: 2.2094
Training Epoch: 22 [6144/50176]	Loss: 2.1902
Training Epoch: 22 [7168/50176]	Loss: 2.2549
Training Epoch: 22 [8192/50176]	Loss: 2.2434
Training Epoch: 22 [9216/50176]	Loss: 2.1724
Training Epoch: 22 [10240/50176]	Loss: 2.1483
Training Epoch: 22 [11264/50176]	Loss: 2.2499
Training Epoch: 22 [12288/50176]	Loss: 2.2571
Training Epoch: 22 [13312/50176]	Loss: 2.0572
Training Epoch: 22 [14336/50176]	Loss: 2.1845
Training Epoch: 22 [15360/50176]	Loss: 2.1715
Training Epoch: 22 [16384/50176]	Loss: 2.2451
Training Epoch: 22 [17408/50176]	Loss: 2.0843
Training Epoch: 22 [18432/50176]	Loss: 2.1836
Training Epoch: 22 [19456/50176]	Loss: 2.1528
Training Epoch: 22 [20480/50176]	Loss: 2.2455
Training Epoch: 22 [21504/50176]	Loss: 2.2098
Training Epoch: 22 [22528/50176]	Loss: 2.1749
Training Epoch: 22 [23552/50176]	Loss: 2.1905
Training Epoch: 22 [24576/50176]	Loss: 2.2420
Training Epoch: 22 [25600/50176]	Loss: 2.2586
Training Epoch: 22 [26624/50176]	Loss: 2.1653
Training Epoch: 22 [27648/50176]	Loss: 2.1857
Training Epoch: 22 [28672/50176]	Loss: 2.2506
Training Epoch: 22 [29696/50176]	Loss: 2.1968
Training Epoch: 22 [30720/50176]	Loss: 2.0840
Training Epoch: 22 [31744/50176]	Loss: 2.2753
Training Epoch: 22 [32768/50176]	Loss: 2.1747
Training Epoch: 22 [33792/50176]	Loss: 2.1191
Training Epoch: 22 [34816/50176]	Loss: 2.2185
Training Epoch: 22 [35840/50176]	Loss: 2.2643
Training Epoch: 22 [36864/50176]	Loss: 2.1998
Training Epoch: 22 [37888/50176]	Loss: 2.1247
Training Epoch: 22 [38912/50176]	Loss: 2.1761
Training Epoch: 22 [39936/50176]	Loss: 2.1246
Training Epoch: 22 [40960/50176]	Loss: 2.2329
Training Epoch: 22 [41984/50176]	Loss: 2.2346
Training Epoch: 22 [43008/50176]	Loss: 2.1415
Training Epoch: 22 [44032/50176]	Loss: 2.1330
Training Epoch: 22 [45056/50176]	Loss: 2.1915
Training Epoch: 22 [46080/50176]	Loss: 2.1027
Training Epoch: 22 [47104/50176]	Loss: 2.0655
Training Epoch: 22 [48128/50176]	Loss: 2.3634
Training Epoch: 22 [49152/50176]	Loss: 2.2249
Training Epoch: 22 [50176/50176]	Loss: 2.0637
2022-12-06 18:30:03.397 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:30:03,414 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.82 energy=475.31
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Up to epoch 23: time=1154.75, energy=156174.50, cost=179127.90
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Expected next epoch: time=1201.85, energy=162862.38, cost=186593.40
2022-12-06 13:30:03,415 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.2828, Accuracy: 0.0098
2022-12-06 13:30:03,653 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:30:03,653 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:30:03.657 [ZeusMonitor] Monitor started.
2022-12-06 18:30:03.657 [ZeusMonitor] Running indefinitely. 2022-12-06 18:30:03.657 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:30:03.657 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 13:30:47,607 [ZeusDataLoader(train)] train epoch 24 done: time=44.18 energy=6225.80
2022-12-06 13:30:47,610 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 2.1250
Training Epoch: 23 [2048/50176]	Loss: 2.0631
Training Epoch: 23 [3072/50176]	Loss: 2.0986
Training Epoch: 23 [4096/50176]	Loss: 2.1593
Training Epoch: 23 [5120/50176]	Loss: 2.0955
Training Epoch: 23 [6144/50176]	Loss: 2.1507
Training Epoch: 23 [7168/50176]	Loss: 2.1952
Training Epoch: 23 [8192/50176]	Loss: 2.1329
Training Epoch: 23 [9216/50176]	Loss: 2.0663
Training Epoch: 23 [10240/50176]	Loss: 2.1367
Training Epoch: 23 [11264/50176]	Loss: 2.0788
Training Epoch: 23 [12288/50176]	Loss: 2.0717
Training Epoch: 23 [13312/50176]	Loss: 2.2207
Training Epoch: 23 [14336/50176]	Loss: 2.1719
Training Epoch: 23 [15360/50176]	Loss: 2.0176
Training Epoch: 23 [16384/50176]	Loss: 2.1308
Training Epoch: 23 [17408/50176]	Loss: 2.2031
Training Epoch: 23 [18432/50176]	Loss: 2.1154
Training Epoch: 23 [19456/50176]	Loss: 2.1917
Training Epoch: 23 [20480/50176]	Loss: 2.0671
Training Epoch: 23 [21504/50176]	Loss: 2.1081
Training Epoch: 23 [22528/50176]	Loss: 2.1698
Training Epoch: 23 [23552/50176]	Loss: 2.0428
Training Epoch: 23 [24576/50176]	Loss: 2.1523
Training Epoch: 23 [25600/50176]	Loss: 2.1698
Training Epoch: 23 [26624/50176]	Loss: 2.1723
Training Epoch: 23 [27648/50176]	Loss: 2.0708
Training Epoch: 23 [28672/50176]	Loss: 2.1366
Training Epoch: 23 [29696/50176]	Loss: 2.0821
Training Epoch: 23 [30720/50176]	Loss: 2.1795
Training Epoch: 23 [31744/50176]	Loss: 2.1657
Training Epoch: 23 [32768/50176]	Loss: 2.2280
Training Epoch: 23 [33792/50176]	Loss: 2.1502
Training Epoch: 23 [34816/50176]	Loss: 2.1472
Training Epoch: 23 [35840/50176]	Loss: 2.1968
Training Epoch: 23 [36864/50176]	Loss: 2.0794
Training Epoch: 23 [37888/50176]	Loss: 2.0796
Training Epoch: 23 [38912/50176]	Loss: 2.2069
Training Epoch: 23 [39936/50176]	Loss: 2.2064
Training Epoch: 23 [40960/50176]	Loss: 2.1805
Training Epoch: 23 [41984/50176]	Loss: 2.1787
Training Epoch: 23 [43008/50176]	Loss: 2.0684
Training Epoch: 23 [44032/50176]	Loss: 2.1647
Training Epoch: 23 [45056/50176]	Loss: 2.2161
Training Epoch: 23 [46080/50176]	Loss: 2.3027
Training Epoch: 23 [47104/50176]	Loss: 2.0822
Training Epoch: 23 [48128/50176]	Loss: 2.0465
Training Epoch: 23 [49152/50176]	Loss: 2.0802
Training Epoch: 23 [50176/50176]	Loss: 2.0953
2022-12-06 18:30:51.354 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:30:51,404 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.79 energy=487.12
2022-12-06 13:30:51,404 [ZeusDataLoader(train)] Up to epoch 24: time=1202.72, energy=162887.43, cost=186681.68
2022-12-06 13:30:51,405 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:30:51,405 [ZeusDataLoader(train)] Expected next epoch: time=1249.82, energy=169575.31, cost=194147.18
2022-12-06 13:30:51,406 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.1594, Accuracy: 0.0098
2022-12-06 13:30:51,596 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:30:51,597 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:30:51.600 [ZeusMonitor] Monitor started.
2022-12-06 18:30:51.600 [ZeusMonitor] Running indefinitely. 2022-12-06 18:30:51.600 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:30:51.600 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 13:31:35,975 [ZeusDataLoader(train)] train epoch 25 done: time=44.56 energy=6262.58
2022-12-06 13:31:35,979 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 2.0475
Training Epoch: 24 [2048/50176]	Loss: 1.9875
Training Epoch: 24 [3072/50176]	Loss: 2.0181
Training Epoch: 24 [4096/50176]	Loss: 1.9907
Training Epoch: 24 [5120/50176]	Loss: 2.0369
Training Epoch: 24 [6144/50176]	Loss: 1.9776
Training Epoch: 24 [7168/50176]	Loss: 2.0814
Training Epoch: 24 [8192/50176]	Loss: 2.0218
Training Epoch: 24 [9216/50176]	Loss: 2.1321
Training Epoch: 24 [10240/50176]	Loss: 2.0562
Training Epoch: 24 [11264/50176]	Loss: 2.0434
Training Epoch: 24 [12288/50176]	Loss: 2.0512
Training Epoch: 24 [13312/50176]	Loss: 2.0598
Training Epoch: 24 [14336/50176]	Loss: 2.1620
Training Epoch: 24 [15360/50176]	Loss: 1.9508
Training Epoch: 24 [16384/50176]	Loss: 1.9740
Training Epoch: 24 [17408/50176]	Loss: 2.0274
Training Epoch: 24 [18432/50176]	Loss: 2.1257
Training Epoch: 24 [19456/50176]	Loss: 2.0654
Training Epoch: 24 [20480/50176]	Loss: 2.0587
Training Epoch: 24 [21504/50176]	Loss: 2.0144
Training Epoch: 24 [22528/50176]	Loss: 2.0420
Training Epoch: 24 [23552/50176]	Loss: 2.1421
Training Epoch: 24 [24576/50176]	Loss: 1.9771
Training Epoch: 24 [25600/50176]	Loss: 2.0372
Training Epoch: 24 [26624/50176]	Loss: 2.0290
Training Epoch: 24 [27648/50176]	Loss: 2.2114
Training Epoch: 24 [28672/50176]	Loss: 2.0308
Training Epoch: 24 [29696/50176]	Loss: 2.0486
Training Epoch: 24 [30720/50176]	Loss: 2.0925
Training Epoch: 24 [31744/50176]	Loss: 2.1949
Training Epoch: 24 [32768/50176]	Loss: 2.1202
Training Epoch: 24 [33792/50176]	Loss: 2.0171
Training Epoch: 24 [34816/50176]	Loss: 2.1270
Training Epoch: 24 [35840/50176]	Loss: 2.1073
Training Epoch: 24 [36864/50176]	Loss: 2.0278
Training Epoch: 24 [37888/50176]	Loss: 2.1495
Training Epoch: 24 [38912/50176]	Loss: 2.1208
Training Epoch: 24 [39936/50176]	Loss: 1.9824
Training Epoch: 24 [40960/50176]	Loss: 1.9784
Training Epoch: 24 [41984/50176]	Loss: 2.1702
Training Epoch: 24 [43008/50176]	Loss: 2.1015
Training Epoch: 24 [44032/50176]	Loss: 1.9943
Training Epoch: 24 [45056/50176]	Loss: 2.0904
Training Epoch: 24 [46080/50176]	Loss: 2.1371
Training Epoch: 24 [47104/50176]	Loss: 2.1303
Training Epoch: 24 [48128/50176]	Loss: 2.2049
Training Epoch: 24 [49152/50176]	Loss: 2.0796
Training Epoch: 24 [50176/50176]	Loss: 2.0366
2022-12-06 18:31:39.732 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:31:39,744 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.76 energy=467.31
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Up to epoch 25: time=1251.04, energy=169617.32, cost=194274.58
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Expected next epoch: time=1298.14, energy=176305.20, cost=201740.08
2022-12-06 13:31:39,745 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0719, Accuracy: 0.0098
2022-12-06 13:31:39,989 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:31:39,990 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:31:39.992 [ZeusMonitor] Monitor started.
2022-12-06 18:31:39.992 [ZeusMonitor] Running indefinitely. 2022-12-06 18:31:39.992 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:31:39.992 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 13:32:23,841 [ZeusDataLoader(train)] train epoch 26 done: time=44.09 energy=6232.50
2022-12-06 13:32:23,845 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 2.0137
Training Epoch: 25 [2048/50176]	Loss: 2.0112
Training Epoch: 25 [3072/50176]	Loss: 2.0135
Training Epoch: 25 [4096/50176]	Loss: 2.1223
Training Epoch: 25 [5120/50176]	Loss: 2.0002
Training Epoch: 25 [6144/50176]	Loss: 2.0823
Training Epoch: 25 [7168/50176]	Loss: 2.0060
Training Epoch: 25 [8192/50176]	Loss: 2.0607
Training Epoch: 25 [9216/50176]	Loss: 2.0676
Training Epoch: 25 [10240/50176]	Loss: 1.9691
Training Epoch: 25 [11264/50176]	Loss: 2.0310
Training Epoch: 25 [12288/50176]	Loss: 2.0422
Training Epoch: 25 [13312/50176]	Loss: 1.9610
Training Epoch: 25 [14336/50176]	Loss: 1.9427
Training Epoch: 25 [15360/50176]	Loss: 1.9970
Training Epoch: 25 [16384/50176]	Loss: 2.1311
Training Epoch: 25 [17408/50176]	Loss: 2.0422
Training Epoch: 25 [18432/50176]	Loss: 2.0277
Training Epoch: 25 [19456/50176]	Loss: 1.9878
Training Epoch: 25 [20480/50176]	Loss: 2.0182
Training Epoch: 25 [21504/50176]	Loss: 1.9229
Training Epoch: 25 [22528/50176]	Loss: 2.0877
Training Epoch: 25 [23552/50176]	Loss: 1.9761
Training Epoch: 25 [24576/50176]	Loss: 1.9343
Training Epoch: 25 [25600/50176]	Loss: 1.9218
Training Epoch: 25 [26624/50176]	Loss: 2.0544
Training Epoch: 25 [27648/50176]	Loss: 1.9786
Training Epoch: 25 [28672/50176]	Loss: 2.0300
Training Epoch: 25 [29696/50176]	Loss: 2.0973
Training Epoch: 25 [30720/50176]	Loss: 2.0554
Training Epoch: 25 [31744/50176]	Loss: 1.9850
Training Epoch: 25 [32768/50176]	Loss: 1.9864
Training Epoch: 25 [33792/50176]	Loss: 1.9537
Training Epoch: 25 [34816/50176]	Loss: 1.9788
Training Epoch: 25 [35840/50176]	Loss: 1.9827
Training Epoch: 25 [36864/50176]	Loss: 2.0025
Training Epoch: 25 [37888/50176]	Loss: 1.9878
Training Epoch: 25 [38912/50176]	Loss: 2.0310
Training Epoch: 25 [39936/50176]	Loss: 1.9821
Training Epoch: 25 [40960/50176]	Loss: 2.0266
Training Epoch: 25 [41984/50176]	Loss: 2.0155
Training Epoch: 25 [43008/50176]	Loss: 2.0482
Training Epoch: 25 [44032/50176]	Loss: 2.0212
Training Epoch: 25 [45056/50176]	Loss: 2.0782
Training Epoch: 25 [46080/50176]	Loss: 2.0254
Training Epoch: 25 [47104/50176]	Loss: 1.9521
Training Epoch: 25 [48128/50176]	Loss: 2.0144
Training Epoch: 25 [49152/50176]	Loss: 2.0258
Training Epoch: 25 [50176/50176]	Loss: 2.0076
2022-12-06 18:32:27.600 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:32:27,654 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.80 energy=480.50
2022-12-06 13:32:27,654 [ZeusDataLoader(train)] Up to epoch 26: time=1298.93, energy=176330.32, cost=201821.37
2022-12-06 13:32:27,655 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:32:27,655 [ZeusDataLoader(train)] Expected next epoch: time=1346.03, energy=183018.20, cost=209286.87
2022-12-06 13:32:27,656 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.2032, Accuracy: 0.0098
2022-12-06 13:32:27,906 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:32:27,907 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:32:27.908 [ZeusMonitor] Monitor started.
2022-12-06 18:32:27.908 [ZeusMonitor] Running indefinitely. 2022-12-06 18:32:27.908 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:32:27.908 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 13:33:12,064 [ZeusDataLoader(train)] train epoch 27 done: time=44.40 energy=6250.21
2022-12-06 13:33:12,067 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 2.0236
Training Epoch: 26 [2048/50176]	Loss: 2.0283
Training Epoch: 26 [3072/50176]	Loss: 2.0341
Training Epoch: 26 [4096/50176]	Loss: 1.8853
Training Epoch: 26 [5120/50176]	Loss: 1.9645
Training Epoch: 26 [6144/50176]	Loss: 1.9338
Training Epoch: 26 [7168/50176]	Loss: 1.9545
Training Epoch: 26 [8192/50176]	Loss: 1.9452
Training Epoch: 26 [9216/50176]	Loss: 1.8696
Training Epoch: 26 [10240/50176]	Loss: 2.0314
Training Epoch: 26 [11264/50176]	Loss: 1.9021
Training Epoch: 26 [12288/50176]	Loss: 1.9429
Training Epoch: 26 [13312/50176]	Loss: 1.8615
Training Epoch: 26 [14336/50176]	Loss: 1.9606
Training Epoch: 26 [15360/50176]	Loss: 1.8990
Training Epoch: 26 [16384/50176]	Loss: 1.8832
Training Epoch: 26 [17408/50176]	Loss: 1.9411
Training Epoch: 26 [18432/50176]	Loss: 1.9606
Training Epoch: 26 [19456/50176]	Loss: 1.9707
Training Epoch: 26 [20480/50176]	Loss: 1.8992
Training Epoch: 26 [21504/50176]	Loss: 1.9101
Training Epoch: 26 [22528/50176]	Loss: 1.9806
Training Epoch: 26 [23552/50176]	Loss: 2.0272
Training Epoch: 26 [24576/50176]	Loss: 1.9276
Training Epoch: 26 [25600/50176]	Loss: 1.9266
Training Epoch: 26 [26624/50176]	Loss: 1.9826
Training Epoch: 26 [27648/50176]	Loss: 2.0051
Training Epoch: 26 [28672/50176]	Loss: 1.9468
Training Epoch: 26 [29696/50176]	Loss: 1.9619
Training Epoch: 26 [30720/50176]	Loss: 1.9997
Training Epoch: 26 [31744/50176]	Loss: 1.9708
Training Epoch: 26 [32768/50176]	Loss: 2.0630
Training Epoch: 26 [33792/50176]	Loss: 2.0749
Training Epoch: 26 [34816/50176]	Loss: 2.0184
Training Epoch: 26 [35840/50176]	Loss: 1.9443
Training Epoch: 26 [36864/50176]	Loss: 1.9452
Training Epoch: 26 [37888/50176]	Loss: 1.9374
Training Epoch: 26 [38912/50176]	Loss: 1.9412
Training Epoch: 26 [39936/50176]	Loss: 2.0566
Training Epoch: 26 [40960/50176]	Loss: 1.9542
Training Epoch: 26 [41984/50176]	Loss: 1.9850
Training Epoch: 26 [43008/50176]	Loss: 1.9585
Training Epoch: 26 [44032/50176]	Loss: 1.9532
Training Epoch: 26 [45056/50176]	Loss: 1.9529
Training Epoch: 26 [46080/50176]	Loss: 1.9824
Training Epoch: 26 [47104/50176]	Loss: 2.0626
Training Epoch: 26 [48128/50176]	Loss: 2.0524
Training Epoch: 26 [49152/50176]	Loss: 1.8681
Training Epoch: 26 [50176/50176]	Loss: 1.9107
2022-12-06 18:33:15.940 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:33:15,967 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.89 energy=483.93
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Up to epoch 27: time=1347.22, energy=183064.46, cost=209414.02
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Expected next epoch: time=1394.32, energy=189752.34, cost=216879.52
2022-12-06 13:33:15,968 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.1020, Accuracy: 0.0099
2022-12-06 13:33:16,216 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:33:16,217 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:33:16.219 [ZeusMonitor] Monitor started.
2022-12-06 18:33:16.219 [ZeusMonitor] Running indefinitely. 2022-12-06 18:33:16.219 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:33:16.219 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 13:34:00,184 [ZeusDataLoader(train)] train epoch 28 done: time=44.21 energy=6227.24
2022-12-06 13:34:00,189 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 1.8293
Training Epoch: 27 [2048/50176]	Loss: 1.8332
Training Epoch: 27 [3072/50176]	Loss: 1.8837
Training Epoch: 27 [4096/50176]	Loss: 1.8688
Training Epoch: 27 [5120/50176]	Loss: 1.8833
Training Epoch: 27 [6144/50176]	Loss: 1.8196
Training Epoch: 27 [7168/50176]	Loss: 1.7745
Training Epoch: 27 [8192/50176]	Loss: 1.9240
Training Epoch: 27 [9216/50176]	Loss: 1.8069
Training Epoch: 27 [10240/50176]	Loss: 1.9230
Training Epoch: 27 [11264/50176]	Loss: 1.8414
Training Epoch: 27 [12288/50176]	Loss: 1.8468
Training Epoch: 27 [13312/50176]	Loss: 1.8955
Training Epoch: 27 [14336/50176]	Loss: 1.8463
Training Epoch: 27 [15360/50176]	Loss: 1.8932
Training Epoch: 27 [16384/50176]	Loss: 1.9087
Training Epoch: 27 [17408/50176]	Loss: 1.8595
Training Epoch: 27 [18432/50176]	Loss: 2.0149
Training Epoch: 27 [19456/50176]	Loss: 1.8511
Training Epoch: 27 [20480/50176]	Loss: 1.7921
Training Epoch: 27 [21504/50176]	Loss: 2.0097
Training Epoch: 27 [22528/50176]	Loss: 1.8416
Training Epoch: 27 [23552/50176]	Loss: 1.8559
Training Epoch: 27 [24576/50176]	Loss: 1.8989
Training Epoch: 27 [25600/50176]	Loss: 1.9253
Training Epoch: 27 [26624/50176]	Loss: 1.9204
Training Epoch: 27 [27648/50176]	Loss: 1.9563
Training Epoch: 27 [28672/50176]	Loss: 1.9540
Training Epoch: 27 [29696/50176]	Loss: 1.9580
Training Epoch: 27 [30720/50176]	Loss: 1.9533
Training Epoch: 27 [31744/50176]	Loss: 1.9901
Training Epoch: 27 [32768/50176]	Loss: 1.9596
Training Epoch: 27 [33792/50176]	Loss: 1.8931
Training Epoch: 27 [34816/50176]	Loss: 2.0541
Training Epoch: 27 [35840/50176]	Loss: 1.9712
Training Epoch: 27 [36864/50176]	Loss: 1.8952
Training Epoch: 27 [37888/50176]	Loss: 1.8893
Training Epoch: 27 [38912/50176]	Loss: 1.8804
Training Epoch: 27 [39936/50176]	Loss: 1.9754
Training Epoch: 27 [40960/50176]	Loss: 1.8789
Training Epoch: 27 [41984/50176]	Loss: 1.9421
Training Epoch: 27 [43008/50176]	Loss: 1.9229
Training Epoch: 27 [44032/50176]	Loss: 1.9420
Training Epoch: 27 [45056/50176]	Loss: 1.8491
Training Epoch: 27 [46080/50176]	Loss: 1.9328
Training Epoch: 27 [47104/50176]	Loss: 1.9574
Training Epoch: 27 [48128/50176]	Loss: 1.9431
Training Epoch: 27 [49152/50176]	Loss: 2.0153
Training Epoch: 27 [50176/50176]	Loss: 2.0098
2022-12-06 18:34:03.924 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:34:03,938 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=469.80
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Up to epoch 28: time=1395.17, energy=189761.49, cost=216958.11
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Expected next epoch: time=1442.27, energy=196449.37, cost=224423.61
2022-12-06 13:34:03,940 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.4401, Accuracy: 0.0098
2022-12-06 13:34:04,178 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:34:04,178 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:34:04.188 [ZeusMonitor] Monitor started.
2022-12-06 18:34:04.189 [ZeusMonitor] Running indefinitely. 2022-12-06 18:34:04.189 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:34:04.189 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 13:34:48,175 [ZeusDataLoader(train)] train epoch 29 done: time=44.23 energy=6228.03
2022-12-06 13:34:48,178 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 1.8378
Training Epoch: 28 [2048/50176]	Loss: 1.9144
Training Epoch: 28 [3072/50176]	Loss: 1.8009
Training Epoch: 28 [4096/50176]	Loss: 1.9294
Training Epoch: 28 [5120/50176]	Loss: 1.8327
Training Epoch: 28 [6144/50176]	Loss: 1.8673
Training Epoch: 28 [7168/50176]	Loss: 1.7964
Training Epoch: 28 [8192/50176]	Loss: 1.7855
Training Epoch: 28 [9216/50176]	Loss: 1.9152
Training Epoch: 28 [10240/50176]	Loss: 1.8676
Training Epoch: 28 [11264/50176]	Loss: 1.8100
Training Epoch: 28 [12288/50176]	Loss: 1.8878
Training Epoch: 28 [13312/50176]	Loss: 1.8834
Training Epoch: 28 [14336/50176]	Loss: 1.9330
Training Epoch: 28 [15360/50176]	Loss: 1.8404
Training Epoch: 28 [16384/50176]	Loss: 1.8586
Training Epoch: 28 [17408/50176]	Loss: 1.9219
Training Epoch: 28 [18432/50176]	Loss: 1.8617
Training Epoch: 28 [19456/50176]	Loss: 1.9352
Training Epoch: 28 [20480/50176]	Loss: 1.7863
Training Epoch: 28 [21504/50176]	Loss: 1.8861
Training Epoch: 28 [22528/50176]	Loss: 1.9303
Training Epoch: 28 [23552/50176]	Loss: 1.9229
Training Epoch: 28 [24576/50176]	Loss: 1.7430
Training Epoch: 28 [25600/50176]	Loss: 1.8868
Training Epoch: 28 [26624/50176]	Loss: 1.8612
Training Epoch: 28 [27648/50176]	Loss: 1.9760
Training Epoch: 28 [28672/50176]	Loss: 1.8812
Training Epoch: 28 [29696/50176]	Loss: 1.8838
Training Epoch: 28 [30720/50176]	Loss: 1.8742
Training Epoch: 28 [31744/50176]	Loss: 1.9266
Training Epoch: 28 [32768/50176]	Loss: 1.8565
Training Epoch: 28 [33792/50176]	Loss: 1.9006
Training Epoch: 28 [34816/50176]	Loss: 1.8357
Training Epoch: 28 [35840/50176]	Loss: 1.8253
Training Epoch: 28 [36864/50176]	Loss: 1.8711
Training Epoch: 28 [37888/50176]	Loss: 1.8600
Training Epoch: 28 [38912/50176]	Loss: 1.8264
Training Epoch: 28 [39936/50176]	Loss: 1.9319
Training Epoch: 28 [40960/50176]	Loss: 2.0001
Training Epoch: 28 [41984/50176]	Loss: 1.8588
Training Epoch: 28 [43008/50176]	Loss: 1.8716
Training Epoch: 28 [44032/50176]	Loss: 1.7927
Training Epoch: 28 [45056/50176]	Loss: 2.0093
Training Epoch: 28 [46080/50176]	Loss: 1.9232
Training Epoch: 28 [47104/50176]	Loss: 1.8586
Training Epoch: 28 [48128/50176]	Loss: 1.8459
Training Epoch: 28 [49152/50176]	Loss: 1.8363
Training Epoch: 28 [50176/50176]	Loss: 1.8912
2022-12-06 18:34:51.872 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:34:51,908 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.72 energy=470.92
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Up to epoch 29: time=1443.12, energy=196460.45, cost=224503.10
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Expected next epoch: time=1490.22, energy=203148.33, cost=231968.60
2022-12-06 13:34:51,909 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.6465, Accuracy: 0.0098
2022-12-06 13:34:52,149 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:34:52,149 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:34:52.151 [ZeusMonitor] Monitor started.
2022-12-06 18:34:52.151 [ZeusMonitor] Running indefinitely. 2022-12-06 18:34:52.151 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:34:52.151 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 13:35:36,269 [ZeusDataLoader(train)] train epoch 30 done: time=44.35 energy=6236.09
2022-12-06 13:35:36,273 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 1.7547
Training Epoch: 29 [2048/50176]	Loss: 1.7895
Training Epoch: 29 [3072/50176]	Loss: 1.7466
Training Epoch: 29 [4096/50176]	Loss: 1.8221
Training Epoch: 29 [5120/50176]	Loss: 1.8557
Training Epoch: 29 [6144/50176]	Loss: 1.8434
Training Epoch: 29 [7168/50176]	Loss: 1.7766
Training Epoch: 29 [8192/50176]	Loss: 1.7287
Training Epoch: 29 [9216/50176]	Loss: 1.8457
Training Epoch: 29 [10240/50176]	Loss: 1.7624
Training Epoch: 29 [11264/50176]	Loss: 1.8064
Training Epoch: 29 [12288/50176]	Loss: 1.8002
Training Epoch: 29 [13312/50176]	Loss: 1.6956
Training Epoch: 29 [14336/50176]	Loss: 1.7162
Training Epoch: 29 [15360/50176]	Loss: 1.8894
Training Epoch: 29 [16384/50176]	Loss: 1.7685
Training Epoch: 29 [17408/50176]	Loss: 1.7219
Training Epoch: 29 [18432/50176]	Loss: 1.9360
Training Epoch: 29 [19456/50176]	Loss: 1.9449
Training Epoch: 29 [20480/50176]	Loss: 1.8249
Training Epoch: 29 [21504/50176]	Loss: 1.8543
Training Epoch: 29 [22528/50176]	Loss: 1.7514
Training Epoch: 29 [23552/50176]	Loss: 1.7999
Training Epoch: 29 [24576/50176]	Loss: 1.7998
Training Epoch: 29 [25600/50176]	Loss: 1.7854
Training Epoch: 29 [26624/50176]	Loss: 1.8370
Training Epoch: 29 [27648/50176]	Loss: 1.8698
Training Epoch: 29 [28672/50176]	Loss: 1.7519
Training Epoch: 29 [29696/50176]	Loss: 1.7714
Training Epoch: 29 [30720/50176]	Loss: 1.9042
Training Epoch: 29 [31744/50176]	Loss: 1.8741
Training Epoch: 29 [32768/50176]	Loss: 1.8607
Training Epoch: 29 [33792/50176]	Loss: 1.8372
Training Epoch: 29 [34816/50176]	Loss: 1.7966
Training Epoch: 29 [35840/50176]	Loss: 1.7405
Training Epoch: 29 [36864/50176]	Loss: 1.8332
Training Epoch: 29 [37888/50176]	Loss: 1.8169
Training Epoch: 29 [38912/50176]	Loss: 1.8598
Training Epoch: 29 [39936/50176]	Loss: 1.8592
Training Epoch: 29 [40960/50176]	Loss: 1.8296
Training Epoch: 29 [41984/50176]	Loss: 1.7986
Training Epoch: 29 [43008/50176]	Loss: 1.8381
Training Epoch: 29 [44032/50176]	Loss: 1.8478
Training Epoch: 29 [45056/50176]	Loss: 1.8681
Training Epoch: 29 [46080/50176]	Loss: 1.8516
Training Epoch: 29 [47104/50176]	Loss: 1.8325
Training Epoch: 29 [48128/50176]	Loss: 1.8976
Training Epoch: 29 [49152/50176]	Loss: 1.8418
Training Epoch: 29 [50176/50176]	Loss: 1.8727
2022-12-06 18:35:40.092 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:35:40,107 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.83 energy=478.75
2022-12-06 13:35:40,107 [ZeusDataLoader(train)] Up to epoch 30: time=1491.30, energy=203175.29, cost=232076.04
2022-12-06 13:35:40,108 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:35:40,108 [ZeusDataLoader(train)] Expected next epoch: time=1538.40, energy=209863.17, cost=239541.54
2022-12-06 13:35:40,109 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.1057, Accuracy: 0.0101
2022-12-06 13:35:40,350 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:35:40,350 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:35:40.352 [ZeusMonitor] Monitor started.
2022-12-06 18:35:40.352 [ZeusMonitor] Running indefinitely. 2022-12-06 18:35:40.352 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:35:40.352 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 13:36:24,429 [ZeusDataLoader(train)] train epoch 31 done: time=44.31 energy=6236.83
2022-12-06 13:36:24,433 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 1.8563
Training Epoch: 30 [2048/50176]	Loss: 1.8101
Training Epoch: 30 [3072/50176]	Loss: 1.8716
Training Epoch: 30 [4096/50176]	Loss: 1.7705
Training Epoch: 30 [5120/50176]	Loss: 1.7146
Training Epoch: 30 [6144/50176]	Loss: 1.7339
Training Epoch: 30 [7168/50176]	Loss: 1.7891
Training Epoch: 30 [8192/50176]	Loss: 1.7695
Training Epoch: 30 [9216/50176]	Loss: 1.7494
Training Epoch: 30 [10240/50176]	Loss: 1.8114
Training Epoch: 30 [11264/50176]	Loss: 1.7326
Training Epoch: 30 [12288/50176]	Loss: 1.8145
Training Epoch: 30 [13312/50176]	Loss: 1.8038
Training Epoch: 30 [14336/50176]	Loss: 1.7786
Training Epoch: 30 [15360/50176]	Loss: 1.8014
Training Epoch: 30 [16384/50176]	Loss: 1.8070
Training Epoch: 30 [17408/50176]	Loss: 1.7626
Training Epoch: 30 [18432/50176]	Loss: 1.7279
Training Epoch: 30 [19456/50176]	Loss: 1.7751
Training Epoch: 30 [20480/50176]	Loss: 1.7790
Training Epoch: 30 [21504/50176]	Loss: 1.7347
Training Epoch: 30 [22528/50176]	Loss: 1.7970
Training Epoch: 30 [23552/50176]	Loss: 1.7225
Training Epoch: 30 [24576/50176]	Loss: 1.7857
Training Epoch: 30 [25600/50176]	Loss: 1.7450
Training Epoch: 30 [26624/50176]	Loss: 1.6944
Training Epoch: 30 [27648/50176]	Loss: 1.7681
Training Epoch: 30 [28672/50176]	Loss: 1.8656
Training Epoch: 30 [29696/50176]	Loss: 1.7314
Training Epoch: 30 [30720/50176]	Loss: 1.7677
Training Epoch: 30 [31744/50176]	Loss: 1.7710
Training Epoch: 30 [32768/50176]	Loss: 1.7658
Training Epoch: 30 [33792/50176]	Loss: 1.8624
Training Epoch: 30 [34816/50176]	Loss: 1.8146
Training Epoch: 30 [35840/50176]	Loss: 1.8607
Training Epoch: 30 [36864/50176]	Loss: 1.7723
Training Epoch: 30 [37888/50176]	Loss: 1.7660
Training Epoch: 30 [38912/50176]	Loss: 1.8308
Training Epoch: 30 [39936/50176]	Loss: 1.7578
Training Epoch: 30 [40960/50176]	Loss: 1.8615
Training Epoch: 30 [41984/50176]	Loss: 1.8284
Training Epoch: 30 [43008/50176]	Loss: 1.8386
Training Epoch: 30 [44032/50176]	Loss: 1.7532
Training Epoch: 30 [45056/50176]	Loss: 1.7441
Training Epoch: 30 [46080/50176]	Loss: 1.7852
Training Epoch: 30 [47104/50176]	Loss: 1.7704
Training Epoch: 30 [48128/50176]	Loss: 1.7573
Training Epoch: 30 [49152/50176]	Loss: 1.9282
Training Epoch: 30 [50176/50176]	Loss: 1.8753
2022-12-06 18:36:28.189 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:36:28,234 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.79 energy=472.95
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Up to epoch 31: time=1539.40, energy=209885.07, cost=239640.19
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Expected next epoch: time=1586.51, energy=216572.95, cost=247105.69
2022-12-06 13:36:28,236 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0501, Accuracy: 0.0122
2022-12-06 13:36:28,477 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:36:28,478 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:36:28.480 [ZeusMonitor] Monitor started.
2022-12-06 18:36:28.480 [ZeusMonitor] Running indefinitely. 2022-12-06 18:36:28.480 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:36:28.480 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 13:37:12,541 [ZeusDataLoader(train)] train epoch 32 done: time=44.30 energy=6233.18
2022-12-06 13:37:12,545 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 1.7322
Training Epoch: 31 [2048/50176]	Loss: 1.6498
Training Epoch: 31 [3072/50176]	Loss: 1.7626
Training Epoch: 31 [4096/50176]	Loss: 1.7719
Training Epoch: 31 [5120/50176]	Loss: 1.7511
Training Epoch: 31 [6144/50176]	Loss: 1.7444
Training Epoch: 31 [7168/50176]	Loss: 1.6678
Training Epoch: 31 [8192/50176]	Loss: 1.7363
Training Epoch: 31 [9216/50176]	Loss: 1.6827
Training Epoch: 31 [10240/50176]	Loss: 1.7787
Training Epoch: 31 [11264/50176]	Loss: 1.7320
Training Epoch: 31 [12288/50176]	Loss: 1.7201
Training Epoch: 31 [13312/50176]	Loss: 1.7828
Training Epoch: 31 [14336/50176]	Loss: 1.6016
Training Epoch: 31 [15360/50176]	Loss: 1.6384
Training Epoch: 31 [16384/50176]	Loss: 1.7558
Training Epoch: 31 [17408/50176]	Loss: 1.7567
Training Epoch: 31 [18432/50176]	Loss: 1.7801
Training Epoch: 31 [19456/50176]	Loss: 1.7960
Training Epoch: 31 [20480/50176]	Loss: 1.8050
Training Epoch: 31 [21504/50176]	Loss: 1.8164
Training Epoch: 31 [22528/50176]	Loss: 1.7576
Training Epoch: 31 [23552/50176]	Loss: 1.7866
Training Epoch: 31 [24576/50176]	Loss: 1.7216
Training Epoch: 31 [25600/50176]	Loss: 1.8123
Training Epoch: 31 [26624/50176]	Loss: 1.7460
Training Epoch: 31 [27648/50176]	Loss: 1.6814
Training Epoch: 31 [28672/50176]	Loss: 1.7144
Training Epoch: 31 [29696/50176]	Loss: 1.7624
Training Epoch: 31 [30720/50176]	Loss: 1.7281
Training Epoch: 31 [31744/50176]	Loss: 1.7751
Training Epoch: 31 [32768/50176]	Loss: 1.8437
Training Epoch: 31 [33792/50176]	Loss: 1.7156
Training Epoch: 31 [34816/50176]	Loss: 1.7505
Training Epoch: 31 [35840/50176]	Loss: 1.7361
Training Epoch: 31 [36864/50176]	Loss: 1.8127
Training Epoch: 31 [37888/50176]	Loss: 1.8280
Training Epoch: 31 [38912/50176]	Loss: 1.8223
Training Epoch: 31 [39936/50176]	Loss: 1.8128
Training Epoch: 31 [40960/50176]	Loss: 1.7767
Training Epoch: 31 [41984/50176]	Loss: 1.7307
Training Epoch: 31 [43008/50176]	Loss: 1.6802
Training Epoch: 31 [44032/50176]	Loss: 1.7814
Training Epoch: 31 [45056/50176]	Loss: 1.7577
Training Epoch: 31 [46080/50176]	Loss: 1.7460
Training Epoch: 31 [47104/50176]	Loss: 1.7638
Training Epoch: 31 [48128/50176]	Loss: 1.7932
Training Epoch: 31 [49152/50176]	Loss: 1.7532
Training Epoch: 31 [50176/50176]	Loss: 1.7055
2022-12-06 18:37:16.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:37:16,465 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.91 energy=488.25
2022-12-06 13:37:16,465 [ZeusDataLoader(train)] Up to epoch 32: time=1587.61, energy=216606.51, cost=247219.20
2022-12-06 13:37:16,466 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:37:16,466 [ZeusDataLoader(train)] Expected next epoch: time=1634.71, energy=223294.39, cost=254684.70
2022-12-06 13:37:16,467 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0154, Accuracy: 0.0104
2022-12-06 13:37:16,655 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:37:16,656 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:37:16.660 [ZeusMonitor] Monitor started.
2022-12-06 18:37:16.660 [ZeusMonitor] Running indefinitely. 2022-12-06 18:37:16.660 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:37:16.660 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 13:38:00,809 [ZeusDataLoader(train)] train epoch 33 done: time=44.33 energy=6235.38
2022-12-06 13:38:00,812 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 1.6645
Training Epoch: 32 [2048/50176]	Loss: 1.5984
Training Epoch: 32 [3072/50176]	Loss: 1.7215
Training Epoch: 32 [4096/50176]	Loss: 1.7256
Training Epoch: 32 [5120/50176]	Loss: 1.7051
Training Epoch: 32 [6144/50176]	Loss: 1.7490
Training Epoch: 32 [7168/50176]	Loss: 1.7631
Training Epoch: 32 [8192/50176]	Loss: 1.6432
Training Epoch: 32 [9216/50176]	Loss: 1.6579
Training Epoch: 32 [10240/50176]	Loss: 1.7222
Training Epoch: 32 [11264/50176]	Loss: 1.7806
Training Epoch: 32 [12288/50176]	Loss: 1.7545
Training Epoch: 32 [13312/50176]	Loss: 1.7143
Training Epoch: 32 [14336/50176]	Loss: 1.7892
Training Epoch: 32 [15360/50176]	Loss: 1.6869
Training Epoch: 32 [16384/50176]	Loss: 1.6869
Training Epoch: 32 [17408/50176]	Loss: 1.7282
Training Epoch: 32 [18432/50176]	Loss: 1.7241
Training Epoch: 32 [19456/50176]	Loss: 1.7216
Training Epoch: 32 [20480/50176]	Loss: 1.7457
Training Epoch: 32 [21504/50176]	Loss: 1.7460
Training Epoch: 32 [22528/50176]	Loss: 1.7992
Training Epoch: 32 [23552/50176]	Loss: 1.8007
Training Epoch: 32 [24576/50176]	Loss: 1.7298
Training Epoch: 32 [25600/50176]	Loss: 1.7522
Training Epoch: 32 [26624/50176]	Loss: 1.6598
Training Epoch: 32 [27648/50176]	Loss: 1.6995
Training Epoch: 32 [28672/50176]	Loss: 1.7099
Training Epoch: 32 [29696/50176]	Loss: 1.7203
Training Epoch: 32 [30720/50176]	Loss: 1.7370
Training Epoch: 32 [31744/50176]	Loss: 1.6753
Training Epoch: 32 [32768/50176]	Loss: 1.6348
Training Epoch: 32 [33792/50176]	Loss: 1.7258
Training Epoch: 32 [34816/50176]	Loss: 1.7198
Training Epoch: 32 [35840/50176]	Loss: 1.6412
Training Epoch: 32 [36864/50176]	Loss: 1.7831
Training Epoch: 32 [37888/50176]	Loss: 1.6951
Training Epoch: 32 [38912/50176]	Loss: 1.7150
Training Epoch: 32 [39936/50176]	Loss: 1.7226
Training Epoch: 32 [40960/50176]	Loss: 1.6814
Training Epoch: 32 [41984/50176]	Loss: 1.6835
Training Epoch: 32 [43008/50176]	Loss: 1.6866
Training Epoch: 32 [44032/50176]	Loss: 1.8406
Training Epoch: 32 [45056/50176]	Loss: 1.7051
Training Epoch: 32 [46080/50176]	Loss: 1.7788
Training Epoch: 32 [47104/50176]	Loss: 1.7615
Training Epoch: 32 [48128/50176]	Loss: 1.7574
Training Epoch: 32 [49152/50176]	Loss: 1.7726
Training Epoch: 32 [50176/50176]	Loss: 1.7373
2022-12-06 18:38:04.505 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:38:04,516 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.70 energy=472.93
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Up to epoch 33: time=1635.64, energy=223314.82, cost=254775.99
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Expected next epoch: time=1682.74, energy=230002.69, cost=262241.49
2022-12-06 13:38:04,517 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0098, Accuracy: 0.0189
2022-12-06 13:38:04,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:38:04,758 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:38:04.759 [ZeusMonitor] Monitor started.
2022-12-06 18:38:04.759 [ZeusMonitor] Running indefinitely. 2022-12-06 18:38:04.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:38:04.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 13:38:48,703 [ZeusDataLoader(train)] train epoch 34 done: time=44.18 energy=6223.27
2022-12-06 13:38:48,706 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 1.5598
Training Epoch: 33 [2048/50176]	Loss: 1.5922
Training Epoch: 33 [3072/50176]	Loss: 1.7017
Training Epoch: 33 [4096/50176]	Loss: 1.6723
Training Epoch: 33 [5120/50176]	Loss: 1.7692
Training Epoch: 33 [6144/50176]	Loss: 1.5703
Training Epoch: 33 [7168/50176]	Loss: 1.7561
Training Epoch: 33 [8192/50176]	Loss: 1.6595
Training Epoch: 33 [9216/50176]	Loss: 1.7048
Training Epoch: 33 [10240/50176]	Loss: 1.6591
Training Epoch: 33 [11264/50176]	Loss: 1.7607
Training Epoch: 33 [12288/50176]	Loss: 1.6691
Training Epoch: 33 [13312/50176]	Loss: 1.7001
Training Epoch: 33 [14336/50176]	Loss: 1.7686
Training Epoch: 33 [15360/50176]	Loss: 1.6473
Training Epoch: 33 [16384/50176]	Loss: 1.6359
Training Epoch: 33 [17408/50176]	Loss: 1.5629
Training Epoch: 33 [18432/50176]	Loss: 1.7119
Training Epoch: 33 [19456/50176]	Loss: 1.7447
Training Epoch: 33 [20480/50176]	Loss: 1.6205
Training Epoch: 33 [21504/50176]	Loss: 1.7690
Training Epoch: 33 [22528/50176]	Loss: 1.6478
Training Epoch: 33 [23552/50176]	Loss: 1.7772
Training Epoch: 33 [24576/50176]	Loss: 1.6961
Training Epoch: 33 [25600/50176]	Loss: 1.6730
Training Epoch: 33 [26624/50176]	Loss: 1.6027
Training Epoch: 33 [27648/50176]	Loss: 1.6589
Training Epoch: 33 [28672/50176]	Loss: 1.7546
Training Epoch: 33 [29696/50176]	Loss: 1.6308
Training Epoch: 33 [30720/50176]	Loss: 1.7062
Training Epoch: 33 [31744/50176]	Loss: 1.6883
Training Epoch: 33 [32768/50176]	Loss: 1.6217
Training Epoch: 33 [33792/50176]	Loss: 1.7600
Training Epoch: 33 [34816/50176]	Loss: 1.7090
Training Epoch: 33 [35840/50176]	Loss: 1.6826
Training Epoch: 33 [36864/50176]	Loss: 1.6502
Training Epoch: 33 [37888/50176]	Loss: 1.7045
Training Epoch: 33 [38912/50176]	Loss: 1.6969
Training Epoch: 33 [39936/50176]	Loss: 1.6721
Training Epoch: 33 [40960/50176]	Loss: 1.7365
Training Epoch: 33 [41984/50176]	Loss: 1.7119
Training Epoch: 33 [43008/50176]	Loss: 1.7252
Training Epoch: 33 [44032/50176]	Loss: 1.6535
Training Epoch: 33 [45056/50176]	Loss: 1.7315
Training Epoch: 33 [46080/50176]	Loss: 1.6185
Training Epoch: 33 [47104/50176]	Loss: 1.6853
Training Epoch: 33 [48128/50176]	Loss: 1.6678
Training Epoch: 33 [49152/50176]	Loss: 1.7151
Training Epoch: 33 [50176/50176]	Loss: 1.7147
2022-12-06 18:38:52.453 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:38:52,482 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.77 energy=473.95
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Up to epoch 34: time=1683.59, energy=230012.04, cost=262319.80
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Expected next epoch: time=1730.69, energy=236699.92, cost=269785.29
2022-12-06 13:38:52,483 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0500, Accuracy: 0.0097
2022-12-06 13:38:52,672 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:38:52,673 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:38:52.676 [ZeusMonitor] Monitor started.
2022-12-06 18:38:52.676 [ZeusMonitor] Running indefinitely. 2022-12-06 18:38:52.676 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:38:52.676 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 13:39:37,062 [ZeusDataLoader(train)] train epoch 35 done: time=44.57 energy=6255.56
2022-12-06 13:39:37,066 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 1.6378
Training Epoch: 34 [2048/50176]	Loss: 1.6353
Training Epoch: 34 [3072/50176]	Loss: 1.6521
Training Epoch: 34 [4096/50176]	Loss: 1.5771
Training Epoch: 34 [5120/50176]	Loss: 1.6339
Training Epoch: 34 [6144/50176]	Loss: 1.7177
Training Epoch: 34 [7168/50176]	Loss: 1.5831
Training Epoch: 34 [8192/50176]	Loss: 1.6664
Training Epoch: 34 [9216/50176]	Loss: 1.6104
Training Epoch: 34 [10240/50176]	Loss: 1.7409
Training Epoch: 34 [11264/50176]	Loss: 1.6142
Training Epoch: 34 [12288/50176]	Loss: 1.6340
Training Epoch: 34 [13312/50176]	Loss: 1.6532
Training Epoch: 34 [14336/50176]	Loss: 1.5636
Training Epoch: 34 [15360/50176]	Loss: 1.6269
Training Epoch: 34 [16384/50176]	Loss: 1.8305
Training Epoch: 34 [17408/50176]	Loss: 1.6431
Training Epoch: 34 [18432/50176]	Loss: 1.6174
Training Epoch: 34 [19456/50176]	Loss: 1.6031
Training Epoch: 34 [20480/50176]	Loss: 1.6928
Training Epoch: 34 [21504/50176]	Loss: 1.7073
Training Epoch: 34 [22528/50176]	Loss: 1.7390
Training Epoch: 34 [23552/50176]	Loss: 1.6634
Training Epoch: 34 [24576/50176]	Loss: 1.6135
Training Epoch: 34 [25600/50176]	Loss: 1.6902
Training Epoch: 34 [26624/50176]	Loss: 1.7757
Training Epoch: 34 [27648/50176]	Loss: 1.6744
Training Epoch: 34 [28672/50176]	Loss: 1.7184
Training Epoch: 34 [29696/50176]	Loss: 1.7279
Training Epoch: 34 [30720/50176]	Loss: 1.7029
Training Epoch: 34 [31744/50176]	Loss: 1.7311
Training Epoch: 34 [32768/50176]	Loss: 1.6756
Training Epoch: 34 [33792/50176]	Loss: 1.6709
Training Epoch: 34 [34816/50176]	Loss: 1.6877
Training Epoch: 34 [35840/50176]	Loss: 1.6302
Training Epoch: 34 [36864/50176]	Loss: 1.7505
Training Epoch: 34 [37888/50176]	Loss: 1.6327
Training Epoch: 34 [38912/50176]	Loss: 1.6022
Training Epoch: 34 [39936/50176]	Loss: 1.6230
Training Epoch: 34 [40960/50176]	Loss: 1.6652
Training Epoch: 34 [41984/50176]	Loss: 1.6279
Training Epoch: 34 [43008/50176]	Loss: 1.5934
Training Epoch: 34 [44032/50176]	Loss: 1.6964
Training Epoch: 34 [45056/50176]	Loss: 1.7242
Training Epoch: 34 [46080/50176]	Loss: 1.6314
Training Epoch: 34 [47104/50176]	Loss: 1.6247
Training Epoch: 34 [48128/50176]	Loss: 1.6960
Training Epoch: 34 [49152/50176]	Loss: 1.6932
Training Epoch: 34 [50176/50176]	Loss: 1.6243
2022-12-06 18:39:40.790 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:39:40,806 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.73 energy=474.70
2022-12-06 13:39:40,806 [ZeusDataLoader(train)] Up to epoch 35: time=1731.89, energy=236742.30, cost=269911.45
2022-12-06 13:39:40,807 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:39:40,807 [ZeusDataLoader(train)] Expected next epoch: time=1778.99, energy=243430.17, cost=277376.95
2022-12-06 13:39:40,808 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0221, Accuracy: 0.0115
2022-12-06 13:39:41,044 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:39:41,044 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:39:41.046 [ZeusMonitor] Monitor started.
2022-12-06 18:39:41.046 [ZeusMonitor] Running indefinitely. 2022-12-06 18:39:41.046 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:39:41.046 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 13:40:25,507 [ZeusDataLoader(train)] train epoch 36 done: time=44.69 energy=6260.80
2022-12-06 13:40:25,511 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 1.6085
Training Epoch: 35 [2048/50176]	Loss: 1.6237
Training Epoch: 35 [3072/50176]	Loss: 1.5881
Training Epoch: 35 [4096/50176]	Loss: 1.5678
Training Epoch: 35 [5120/50176]	Loss: 1.6119
Training Epoch: 35 [6144/50176]	Loss: 1.5139
Training Epoch: 35 [7168/50176]	Loss: 1.6481
Training Epoch: 35 [8192/50176]	Loss: 1.6124
Training Epoch: 35 [9216/50176]	Loss: 1.4761
Training Epoch: 35 [10240/50176]	Loss: 1.6517
Training Epoch: 35 [11264/50176]	Loss: 1.6442
Training Epoch: 35 [12288/50176]	Loss: 1.7255
Training Epoch: 35 [13312/50176]	Loss: 1.6770
Training Epoch: 35 [14336/50176]	Loss: 1.5769
Training Epoch: 35 [15360/50176]	Loss: 1.5333
Training Epoch: 35 [16384/50176]	Loss: 1.6731
Training Epoch: 35 [17408/50176]	Loss: 1.6550
Training Epoch: 35 [18432/50176]	Loss: 1.5248
Training Epoch: 35 [19456/50176]	Loss: 1.6588
Training Epoch: 35 [20480/50176]	Loss: 1.4585
Training Epoch: 35 [21504/50176]	Loss: 1.5609
Training Epoch: 35 [22528/50176]	Loss: 1.6592
Training Epoch: 35 [23552/50176]	Loss: 1.5488
Training Epoch: 35 [24576/50176]	Loss: 1.6554
Training Epoch: 35 [25600/50176]	Loss: 1.6433
Training Epoch: 35 [26624/50176]	Loss: 1.5783
Training Epoch: 35 [27648/50176]	Loss: 1.6153
Training Epoch: 35 [28672/50176]	Loss: 1.6561
Training Epoch: 35 [29696/50176]	Loss: 1.5862
Training Epoch: 35 [30720/50176]	Loss: 1.6246
Training Epoch: 35 [31744/50176]	Loss: 1.5518
Training Epoch: 35 [32768/50176]	Loss: 1.5772
Training Epoch: 35 [33792/50176]	Loss: 1.5970
Training Epoch: 35 [34816/50176]	Loss: 1.5155
Training Epoch: 35 [35840/50176]	Loss: 1.5786
Training Epoch: 35 [36864/50176]	Loss: 1.6222
Training Epoch: 35 [37888/50176]	Loss: 1.6630
Training Epoch: 35 [38912/50176]	Loss: 1.6285
Training Epoch: 35 [39936/50176]	Loss: 1.6797
Training Epoch: 35 [40960/50176]	Loss: 1.5629
Training Epoch: 35 [41984/50176]	Loss: 1.7461
Training Epoch: 35 [43008/50176]	Loss: 1.5434
Training Epoch: 35 [44032/50176]	Loss: 1.6407
Training Epoch: 35 [45056/50176]	Loss: 1.6989
Training Epoch: 35 [46080/50176]	Loss: 1.6335
Training Epoch: 35 [47104/50176]	Loss: 1.7115
Training Epoch: 35 [48128/50176]	Loss: 1.6773
Training Epoch: 35 [49152/50176]	Loss: 1.6345
Training Epoch: 35 [50176/50176]	Loss: 1.6472
2022-12-06 18:40:29.255 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:40:29,279 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.76 energy=467.13
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Up to epoch 36: time=1780.34, energy=243470.23, cost=277514.91
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Expected next epoch: time=1827.44, energy=250158.10, cost=284980.40
2022-12-06 13:40:29,280 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0655, Accuracy: 0.0124
2022-12-06 13:40:29,507 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:40:29,508 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:40:29.509 [ZeusMonitor] Monitor started.
2022-12-06 18:40:29.510 [ZeusMonitor] Running indefinitely. 2022-12-06 18:40:29.510 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:40:29.510 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 13:41:13,546 [ZeusDataLoader(train)] train epoch 37 done: time=44.26 energy=6221.96
2022-12-06 13:41:13,549 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 1.5121
Training Epoch: 36 [2048/50176]	Loss: 1.5035
Training Epoch: 36 [3072/50176]	Loss: 1.5243
Training Epoch: 36 [4096/50176]	Loss: 1.5380
Training Epoch: 36 [5120/50176]	Loss: 1.5938
Training Epoch: 36 [6144/50176]	Loss: 1.5464
Training Epoch: 36 [7168/50176]	Loss: 1.5802
Training Epoch: 36 [8192/50176]	Loss: 1.5528
Training Epoch: 36 [9216/50176]	Loss: 1.5708
Training Epoch: 36 [10240/50176]	Loss: 1.6977
Training Epoch: 36 [11264/50176]	Loss: 1.6333
Training Epoch: 36 [12288/50176]	Loss: 1.6262
Training Epoch: 36 [13312/50176]	Loss: 1.5801
Training Epoch: 36 [14336/50176]	Loss: 1.5377
Training Epoch: 36 [15360/50176]	Loss: 1.5954
Training Epoch: 36 [16384/50176]	Loss: 1.5728
Training Epoch: 36 [17408/50176]	Loss: 1.5150
Training Epoch: 36 [18432/50176]	Loss: 1.6184
Training Epoch: 36 [19456/50176]	Loss: 1.6248
Training Epoch: 36 [20480/50176]	Loss: 1.6011
Training Epoch: 36 [21504/50176]	Loss: 1.5950
Training Epoch: 36 [22528/50176]	Loss: 1.6438
Training Epoch: 36 [23552/50176]	Loss: 1.5748
Training Epoch: 36 [24576/50176]	Loss: 1.5905
Training Epoch: 36 [25600/50176]	Loss: 1.6821
Training Epoch: 36 [26624/50176]	Loss: 1.6349
Training Epoch: 36 [27648/50176]	Loss: 1.5733
Training Epoch: 36 [28672/50176]	Loss: 1.6239
Training Epoch: 36 [29696/50176]	Loss: 1.6375
Training Epoch: 36 [30720/50176]	Loss: 1.5849
Training Epoch: 36 [31744/50176]	Loss: 1.5928
Training Epoch: 36 [32768/50176]	Loss: 1.5926
Training Epoch: 36 [33792/50176]	Loss: 1.5837
Training Epoch: 36 [34816/50176]	Loss: 1.5862
Training Epoch: 36 [35840/50176]	Loss: 1.5282
Training Epoch: 36 [36864/50176]	Loss: 1.6001
Training Epoch: 36 [37888/50176]	Loss: 1.5901
Training Epoch: 36 [38912/50176]	Loss: 1.5175
Training Epoch: 36 [39936/50176]	Loss: 1.5658
Training Epoch: 36 [40960/50176]	Loss: 1.5843
Training Epoch: 36 [41984/50176]	Loss: 1.5848
Training Epoch: 36 [43008/50176]	Loss: 1.6217
Training Epoch: 36 [44032/50176]	Loss: 1.6365
Training Epoch: 36 [45056/50176]	Loss: 1.6668
Training Epoch: 36 [46080/50176]	Loss: 1.5735
Training Epoch: 36 [47104/50176]	Loss: 1.6007
Training Epoch: 36 [48128/50176]	Loss: 1.5419
Training Epoch: 36 [49152/50176]	Loss: 1.5856
Training Epoch: 36 [50176/50176]	Loss: 1.5270
2022-12-06 18:41:17.321 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:41:17,347 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.79 energy=494.05
2022-12-06 13:41:17,347 [ZeusDataLoader(train)] Up to epoch 37: time=1828.39, energy=250186.23, cost=285076.99
2022-12-06 13:41:17,347 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:41:17,348 [ZeusDataLoader(train)] Expected next epoch: time=1875.49, energy=256874.11, cost=292542.48
2022-12-06 13:41:17,348 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0495, Accuracy: 0.0164
2022-12-06 13:41:17,535 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:41:17,535 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:41:17.539 [ZeusMonitor] Monitor started.
2022-12-06 18:41:17.539 [ZeusMonitor] Running indefinitely. 2022-12-06 18:41:17.539 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:41:17.539 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 13:42:01,434 [ZeusDataLoader(train)] train epoch 38 done: time=44.08 energy=6221.68
2022-12-06 13:42:01,438 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 1.4872
Training Epoch: 37 [2048/50176]	Loss: 1.5410
Training Epoch: 37 [3072/50176]	Loss: 1.4828
Training Epoch: 37 [4096/50176]	Loss: 1.5733
Training Epoch: 37 [5120/50176]	Loss: 1.4362
Training Epoch: 37 [6144/50176]	Loss: 1.4338
Training Epoch: 37 [7168/50176]	Loss: 1.4860
Training Epoch: 37 [8192/50176]	Loss: 1.4970
Training Epoch: 37 [9216/50176]	Loss: 1.4805
Training Epoch: 37 [10240/50176]	Loss: 1.5154
Training Epoch: 37 [11264/50176]	Loss: 1.5660
Training Epoch: 37 [12288/50176]	Loss: 1.6284
Training Epoch: 37 [13312/50176]	Loss: 1.5019
Training Epoch: 37 [14336/50176]	Loss: 1.4905
Training Epoch: 37 [15360/50176]	Loss: 1.5985
Training Epoch: 37 [16384/50176]	Loss: 1.5046
Training Epoch: 37 [17408/50176]	Loss: 1.5776
Training Epoch: 37 [18432/50176]	Loss: 1.4884
Training Epoch: 37 [19456/50176]	Loss: 1.5355
Training Epoch: 37 [20480/50176]	Loss: 1.4746
Training Epoch: 37 [21504/50176]	Loss: 1.5991
Training Epoch: 37 [22528/50176]	Loss: 1.5581
Training Epoch: 37 [23552/50176]	Loss: 1.4579
Training Epoch: 37 [24576/50176]	Loss: 1.5061
Training Epoch: 37 [25600/50176]	Loss: 1.5045
Training Epoch: 37 [26624/50176]	Loss: 1.5695
Training Epoch: 37 [27648/50176]	Loss: 1.6364
Training Epoch: 37 [28672/50176]	Loss: 1.6242
Training Epoch: 37 [29696/50176]	Loss: 1.5557
Training Epoch: 37 [30720/50176]	Loss: 1.5433
Training Epoch: 37 [31744/50176]	Loss: 1.4814
Training Epoch: 37 [32768/50176]	Loss: 1.5896
Training Epoch: 37 [33792/50176]	Loss: 1.5897
Training Epoch: 37 [34816/50176]	Loss: 1.6066
Training Epoch: 37 [35840/50176]	Loss: 1.5363
Training Epoch: 37 [36864/50176]	Loss: 1.5874
Training Epoch: 37 [37888/50176]	Loss: 1.6103
Training Epoch: 37 [38912/50176]	Loss: 1.5537
Training Epoch: 37 [39936/50176]	Loss: 1.4723
Training Epoch: 37 [40960/50176]	Loss: 1.5637
Training Epoch: 37 [41984/50176]	Loss: 1.5493
Training Epoch: 37 [43008/50176]	Loss: 1.6678
Training Epoch: 37 [44032/50176]	Loss: 1.6075
Training Epoch: 37 [45056/50176]	Loss: 1.6766
Training Epoch: 37 [46080/50176]	Loss: 1.5541
Training Epoch: 37 [47104/50176]	Loss: 1.6508
Training Epoch: 37 [48128/50176]	Loss: 1.6641
Training Epoch: 37 [49152/50176]	Loss: 1.5705
Training Epoch: 37 [50176/50176]	Loss: 1.6164
2022-12-06 18:42:05.165 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:42:05,190 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.74 energy=470.38
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Up to epoch 38: time=1876.21, energy=256878.28, cost=292607.45
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Expected next epoch: time=1923.31, energy=263566.16, cost=300072.95
2022-12-06 13:42:05,191 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0400, Accuracy: 0.0118
2022-12-06 13:42:05,433 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:42:05,434 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:42:05.436 [ZeusMonitor] Monitor started.
2022-12-06 18:42:05.436 [ZeusMonitor] Running indefinitely. 2022-12-06 18:42:05.436 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:42:05.436 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 13:42:49,231 [ZeusDataLoader(train)] train epoch 39 done: time=44.03 energy=6209.49
2022-12-06 13:42:49,234 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 1.5362
Training Epoch: 38 [2048/50176]	Loss: 1.5031
Training Epoch: 38 [3072/50176]	Loss: 1.4976
Training Epoch: 38 [4096/50176]	Loss: 1.4150
Training Epoch: 38 [5120/50176]	Loss: 1.5650
Training Epoch: 38 [6144/50176]	Loss: 1.4657
Training Epoch: 38 [7168/50176]	Loss: 1.5765
Training Epoch: 38 [8192/50176]	Loss: 1.5344
Training Epoch: 38 [9216/50176]	Loss: 1.5041
Training Epoch: 38 [10240/50176]	Loss: 1.5859
Training Epoch: 38 [11264/50176]	Loss: 1.6042
Training Epoch: 38 [12288/50176]	Loss: 1.4652
Training Epoch: 38 [13312/50176]	Loss: 1.5191
Training Epoch: 38 [14336/50176]	Loss: 1.4672
Training Epoch: 38 [15360/50176]	Loss: 1.5529
Training Epoch: 38 [16384/50176]	Loss: 1.4975
Training Epoch: 38 [17408/50176]	Loss: 1.4944
Training Epoch: 38 [18432/50176]	Loss: 1.6240
Training Epoch: 38 [19456/50176]	Loss: 1.5449
Training Epoch: 38 [20480/50176]	Loss: 1.4871
Training Epoch: 38 [21504/50176]	Loss: 1.5245
Training Epoch: 38 [22528/50176]	Loss: 1.5214
Training Epoch: 38 [23552/50176]	Loss: 1.5852
Training Epoch: 38 [24576/50176]	Loss: 1.5314
Training Epoch: 38 [25600/50176]	Loss: 1.4621
Training Epoch: 38 [26624/50176]	Loss: 1.5637
Training Epoch: 38 [27648/50176]	Loss: 1.5393
Training Epoch: 38 [28672/50176]	Loss: 1.5523
Training Epoch: 38 [29696/50176]	Loss: 1.4491
Training Epoch: 38 [30720/50176]	Loss: 1.5182
Training Epoch: 38 [31744/50176]	Loss: 1.5544
Training Epoch: 38 [32768/50176]	Loss: 1.5690
Training Epoch: 38 [33792/50176]	Loss: 1.6019
Training Epoch: 38 [34816/50176]	Loss: 1.5690
Training Epoch: 38 [35840/50176]	Loss: 1.4381
Training Epoch: 38 [36864/50176]	Loss: 1.5349
Training Epoch: 38 [37888/50176]	Loss: 1.5734
Training Epoch: 38 [38912/50176]	Loss: 1.4513
Training Epoch: 38 [39936/50176]	Loss: 1.5969
Training Epoch: 38 [40960/50176]	Loss: 1.6223
Training Epoch: 38 [41984/50176]	Loss: 1.5784
Training Epoch: 38 [43008/50176]	Loss: 1.7026
Training Epoch: 38 [44032/50176]	Loss: 1.5161
Training Epoch: 38 [45056/50176]	Loss: 1.5264
Training Epoch: 38 [46080/50176]	Loss: 1.4976
Training Epoch: 38 [47104/50176]	Loss: 1.5557
Training Epoch: 38 [48128/50176]	Loss: 1.5815
Training Epoch: 38 [49152/50176]	Loss: 1.6058
Training Epoch: 38 [50176/50176]	Loss: 1.5501
2022-12-06 18:42:53.025 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:42:53,050 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.81 energy=475.54
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Up to epoch 39: time=1924.05, energy=263563.31, cost=300135.88
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Expected next epoch: time=1971.15, energy=270251.19, cost=307601.38
2022-12-06 13:42:53,051 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0429, Accuracy: 0.0099
2022-12-06 13:42:53,328 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:42:53,329 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:42:53.330 [ZeusMonitor] Monitor started.
2022-12-06 18:42:53.331 [ZeusMonitor] Running indefinitely. 2022-12-06 18:42:53.331 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:42:53.331 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 13:43:37,464 [ZeusDataLoader(train)] train epoch 40 done: time=44.40 energy=6238.41
2022-12-06 13:43:37,467 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 1.4511
Training Epoch: 39 [2048/50176]	Loss: 1.4870
Training Epoch: 39 [3072/50176]	Loss: 1.4926
Training Epoch: 39 [4096/50176]	Loss: 1.5809
Training Epoch: 39 [5120/50176]	Loss: 1.6259
Training Epoch: 39 [6144/50176]	Loss: 1.5634
Training Epoch: 39 [7168/50176]	Loss: 1.4176
Training Epoch: 39 [8192/50176]	Loss: 1.4818
Training Epoch: 39 [9216/50176]	Loss: 1.5183
Training Epoch: 39 [10240/50176]	Loss: 1.5319
Training Epoch: 39 [11264/50176]	Loss: 1.5005
Training Epoch: 39 [12288/50176]	Loss: 1.4728
Training Epoch: 39 [13312/50176]	Loss: 1.4914
Training Epoch: 39 [14336/50176]	Loss: 1.4027
Training Epoch: 39 [15360/50176]	Loss: 1.5366
Training Epoch: 39 [16384/50176]	Loss: 1.4030
Training Epoch: 39 [17408/50176]	Loss: 1.4541
Training Epoch: 39 [18432/50176]	Loss: 1.5012
Training Epoch: 39 [19456/50176]	Loss: 1.4854
Training Epoch: 39 [20480/50176]	Loss: 1.5707
Training Epoch: 39 [21504/50176]	Loss: 1.5655
Training Epoch: 39 [22528/50176]	Loss: 1.4420
Training Epoch: 39 [23552/50176]	Loss: 1.4875
Training Epoch: 39 [24576/50176]	Loss: 1.4492
Training Epoch: 39 [25600/50176]	Loss: 1.4811
Training Epoch: 39 [26624/50176]	Loss: 1.5420
Training Epoch: 39 [27648/50176]	Loss: 1.5908
Training Epoch: 39 [28672/50176]	Loss: 1.4151
Training Epoch: 39 [29696/50176]	Loss: 1.5564
Training Epoch: 39 [30720/50176]	Loss: 1.5276
Training Epoch: 39 [31744/50176]	Loss: 1.6015
Training Epoch: 39 [32768/50176]	Loss: 1.4256
Training Epoch: 39 [33792/50176]	Loss: 1.5807
Training Epoch: 39 [34816/50176]	Loss: 1.6445
Training Epoch: 39 [35840/50176]	Loss: 1.4837
Training Epoch: 39 [36864/50176]	Loss: 1.5166
Training Epoch: 39 [37888/50176]	Loss: 1.5257
Training Epoch: 39 [38912/50176]	Loss: 1.5366
Training Epoch: 39 [39936/50176]	Loss: 1.5851
Training Epoch: 39 [40960/50176]	Loss: 1.5895
Training Epoch: 39 [41984/50176]	Loss: 1.5695
Training Epoch: 39 [43008/50176]	Loss: 1.4679
Training Epoch: 39 [44032/50176]	Loss: 1.4472
Training Epoch: 39 [45056/50176]	Loss: 1.6267
Training Epoch: 39 [46080/50176]	Loss: 1.5585
Training Epoch: 39 [47104/50176]	Loss: 1.5937
Training Epoch: 39 [48128/50176]	Loss: 1.4756
Training Epoch: 39 [49152/50176]	Loss: 1.5154
Training Epoch: 39 [50176/50176]	Loss: 1.5411
2022-12-06 18:43:41.219 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:43:41,272 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.80 energy=473.54
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Up to epoch 40: time=1972.25, energy=270275.26, cost=307709.52
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Expected next epoch: time=2019.35, energy=276963.14, cost=315175.01
2022-12-06 13:43:41,273 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0150, Accuracy: 0.0204
2022-12-06 13:43:41,465 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:43:41,466 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:43:41.469 [ZeusMonitor] Monitor started.
2022-12-06 18:43:41.469 [ZeusMonitor] Running indefinitely. 2022-12-06 18:43:41.470 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:43:41.470 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 13:44:25,442 [ZeusDataLoader(train)] train epoch 41 done: time=44.16 energy=6226.46
2022-12-06 13:44:25,446 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 1.4150
Training Epoch: 40 [2048/50176]	Loss: 1.4391
Training Epoch: 40 [3072/50176]	Loss: 1.3935
Training Epoch: 40 [4096/50176]	Loss: 1.4147
Training Epoch: 40 [5120/50176]	Loss: 1.4408
Training Epoch: 40 [6144/50176]	Loss: 1.4300
Training Epoch: 40 [7168/50176]	Loss: 1.4528
Training Epoch: 40 [8192/50176]	Loss: 1.3903
Training Epoch: 40 [9216/50176]	Loss: 1.4172
Training Epoch: 40 [10240/50176]	Loss: 1.4732
Training Epoch: 40 [11264/50176]	Loss: 1.4170
Training Epoch: 40 [12288/50176]	Loss: 1.4522
Training Epoch: 40 [13312/50176]	Loss: 1.4205
Training Epoch: 40 [14336/50176]	Loss: 1.4640
Training Epoch: 40 [15360/50176]	Loss: 1.4268
Training Epoch: 40 [16384/50176]	Loss: 1.4557
Training Epoch: 40 [17408/50176]	Loss: 1.3798
Training Epoch: 40 [18432/50176]	Loss: 1.5047
Training Epoch: 40 [19456/50176]	Loss: 1.4306
Training Epoch: 40 [20480/50176]	Loss: 1.5176
Training Epoch: 40 [21504/50176]	Loss: 1.4275
Training Epoch: 40 [22528/50176]	Loss: 1.4238
Training Epoch: 40 [23552/50176]	Loss: 1.5544
Training Epoch: 40 [24576/50176]	Loss: 1.4647
Training Epoch: 40 [25600/50176]	Loss: 1.4326
Training Epoch: 40 [26624/50176]	Loss: 1.5378
Training Epoch: 40 [27648/50176]	Loss: 1.4803
Training Epoch: 40 [28672/50176]	Loss: 1.4981
Training Epoch: 40 [29696/50176]	Loss: 1.4215
Training Epoch: 40 [30720/50176]	Loss: 1.4043
Training Epoch: 40 [31744/50176]	Loss: 1.4701
Training Epoch: 40 [32768/50176]	Loss: 1.5614
Training Epoch: 40 [33792/50176]	Loss: 1.5709
Training Epoch: 40 [34816/50176]	Loss: 1.3735
Training Epoch: 40 [35840/50176]	Loss: 1.4559
Training Epoch: 40 [36864/50176]	Loss: 1.4498
Training Epoch: 40 [37888/50176]	Loss: 1.4297
Training Epoch: 40 [38912/50176]	Loss: 1.4500
Training Epoch: 40 [39936/50176]	Loss: 1.5214
Training Epoch: 40 [40960/50176]	Loss: 1.5550
Training Epoch: 40 [41984/50176]	Loss: 1.4174
Training Epoch: 40 [43008/50176]	Loss: 1.6328
Training Epoch: 40 [44032/50176]	Loss: 1.5051
Training Epoch: 40 [45056/50176]	Loss: 1.6033
Training Epoch: 40 [46080/50176]	Loss: 1.5366
Training Epoch: 40 [47104/50176]	Loss: 1.4799
Training Epoch: 40 [48128/50176]	Loss: 1.5659
Training Epoch: 40 [49152/50176]	Loss: 1.5175
Training Epoch: 40 [50176/50176]	Loss: 1.5053
2022-12-06 18:44:29.146 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:44:29,156 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.70 energy=471.30
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Up to epoch 41: time=2020.11, energy=276973.02, cost=315246.39
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Expected next epoch: time=2067.22, energy=283660.90, cost=322711.88
2022-12-06 13:44:29,157 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0253, Accuracy: 0.0164
2022-12-06 13:44:29,403 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:44:29,404 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:44:29.406 [ZeusMonitor] Monitor started.
2022-12-06 18:44:29.406 [ZeusMonitor] Running indefinitely. 2022-12-06 18:44:29.406 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:44:29.406 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 13:45:13,669 [ZeusDataLoader(train)] train epoch 42 done: time=44.50 energy=6246.97
2022-12-06 13:45:13,672 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 1.4418
Training Epoch: 41 [2048/50176]	Loss: 1.4356
Training Epoch: 41 [3072/50176]	Loss: 1.4645
Training Epoch: 41 [4096/50176]	Loss: 1.3903
Training Epoch: 41 [5120/50176]	Loss: 1.3821
Training Epoch: 41 [6144/50176]	Loss: 1.4546
Training Epoch: 41 [7168/50176]	Loss: 1.4773
Training Epoch: 41 [8192/50176]	Loss: 1.4560
Training Epoch: 41 [9216/50176]	Loss: 1.4740
Training Epoch: 41 [10240/50176]	Loss: 1.4838
Training Epoch: 41 [11264/50176]	Loss: 1.3910
Training Epoch: 41 [12288/50176]	Loss: 1.4306
Training Epoch: 41 [13312/50176]	Loss: 1.4334
Training Epoch: 41 [14336/50176]	Loss: 1.4935
Training Epoch: 41 [15360/50176]	Loss: 1.5324
Training Epoch: 41 [16384/50176]	Loss: 1.4628
Training Epoch: 41 [17408/50176]	Loss: 1.5494
Training Epoch: 41 [18432/50176]	Loss: 1.4442
Training Epoch: 41 [19456/50176]	Loss: 1.4886
Training Epoch: 41 [20480/50176]	Loss: 1.4597
Training Epoch: 41 [21504/50176]	Loss: 1.4109
Training Epoch: 41 [22528/50176]	Loss: 1.3875
Training Epoch: 41 [23552/50176]	Loss: 1.4550
Training Epoch: 41 [24576/50176]	Loss: 1.4647
Training Epoch: 41 [25600/50176]	Loss: 1.4659
Training Epoch: 41 [26624/50176]	Loss: 1.3614
Training Epoch: 41 [27648/50176]	Loss: 1.4683
Training Epoch: 41 [28672/50176]	Loss: 1.4864
Training Epoch: 41 [29696/50176]	Loss: 1.4622
Training Epoch: 41 [30720/50176]	Loss: 1.4712
Training Epoch: 41 [31744/50176]	Loss: 1.4677
Training Epoch: 41 [32768/50176]	Loss: 1.3983
Training Epoch: 41 [33792/50176]	Loss: 1.3996
Training Epoch: 41 [34816/50176]	Loss: 1.4479
Training Epoch: 41 [35840/50176]	Loss: 1.4737
Training Epoch: 41 [36864/50176]	Loss: 1.4944
Training Epoch: 41 [37888/50176]	Loss: 1.4988
Training Epoch: 41 [38912/50176]	Loss: 1.4128
Training Epoch: 41 [39936/50176]	Loss: 1.4759
Training Epoch: 41 [40960/50176]	Loss: 1.4714
Training Epoch: 41 [41984/50176]	Loss: 1.4161
Training Epoch: 41 [43008/50176]	Loss: 1.4679
Training Epoch: 41 [44032/50176]	Loss: 1.5388
Training Epoch: 41 [45056/50176]	Loss: 1.5355
Training Epoch: 41 [46080/50176]	Loss: 1.4481
Training Epoch: 41 [47104/50176]	Loss: 1.4020
Training Epoch: 41 [48128/50176]	Loss: 1.4898
Training Epoch: 41 [49152/50176]	Loss: 1.4197
Training Epoch: 41 [50176/50176]	Loss: 1.4332
2022-12-06 18:45:17.389 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:45:17,410 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.73 energy=471.17
2022-12-06 13:45:17,410 [ZeusDataLoader(train)] Up to epoch 42: time=2068.35, energy=283691.16, cost=322825.94
2022-12-06 13:45:17,410 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:45:17,411 [ZeusDataLoader(train)] Expected next epoch: time=2115.45, energy=290379.04, cost=330291.44
2022-12-06 13:45:17,412 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 3.1221, Accuracy: 0.0098
2022-12-06 13:45:17,654 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:45:17,654 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:45:17.656 [ZeusMonitor] Monitor started.
2022-12-06 18:45:17.656 [ZeusMonitor] Running indefinitely. 2022-12-06 18:45:17.656 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:45:17.656 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 13:46:01,715 [ZeusDataLoader(train)] train epoch 43 done: time=44.30 energy=6228.50
2022-12-06 13:46:01,719 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 1.3448
Training Epoch: 42 [2048/50176]	Loss: 1.2900
Training Epoch: 42 [3072/50176]	Loss: 1.4060
Training Epoch: 42 [4096/50176]	Loss: 1.4332
Training Epoch: 42 [5120/50176]	Loss: 1.4010
Training Epoch: 42 [6144/50176]	Loss: 1.4554
Training Epoch: 42 [7168/50176]	Loss: 1.3385
Training Epoch: 42 [8192/50176]	Loss: 1.3614
Training Epoch: 42 [9216/50176]	Loss: 1.4054
Training Epoch: 42 [10240/50176]	Loss: 1.4566
Training Epoch: 42 [11264/50176]	Loss: 1.3822
Training Epoch: 42 [12288/50176]	Loss: 1.4535
Training Epoch: 42 [13312/50176]	Loss: 1.3324
Training Epoch: 42 [14336/50176]	Loss: 1.4194
Training Epoch: 42 [15360/50176]	Loss: 1.3638
Training Epoch: 42 [16384/50176]	Loss: 1.3688
Training Epoch: 42 [17408/50176]	Loss: 1.3735
Training Epoch: 42 [18432/50176]	Loss: 1.3656
Training Epoch: 42 [19456/50176]	Loss: 1.3871
Training Epoch: 42 [20480/50176]	Loss: 1.3705
Training Epoch: 42 [21504/50176]	Loss: 1.4101
Training Epoch: 42 [22528/50176]	Loss: 1.4214
Training Epoch: 42 [23552/50176]	Loss: 1.4027
Training Epoch: 42 [24576/50176]	Loss: 1.4535
Training Epoch: 42 [25600/50176]	Loss: 1.5187
Training Epoch: 42 [26624/50176]	Loss: 1.3679
Training Epoch: 42 [27648/50176]	Loss: 1.4027
Training Epoch: 42 [28672/50176]	Loss: 1.3328
Training Epoch: 42 [29696/50176]	Loss: 1.4230
Training Epoch: 42 [30720/50176]	Loss: 1.3697
Training Epoch: 42 [31744/50176]	Loss: 1.4956
Training Epoch: 42 [32768/50176]	Loss: 1.3786
Training Epoch: 42 [33792/50176]	Loss: 1.3842
Training Epoch: 42 [34816/50176]	Loss: 1.4452
Training Epoch: 42 [35840/50176]	Loss: 1.4313
Training Epoch: 42 [36864/50176]	Loss: 1.5037
Training Epoch: 42 [37888/50176]	Loss: 1.5071
Training Epoch: 42 [38912/50176]	Loss: 1.4852
Training Epoch: 42 [39936/50176]	Loss: 1.3604
Training Epoch: 42 [40960/50176]	Loss: 1.4922
Training Epoch: 42 [41984/50176]	Loss: 1.3975
Training Epoch: 42 [43008/50176]	Loss: 1.4984
Training Epoch: 42 [44032/50176]	Loss: 1.4858
Training Epoch: 42 [45056/50176]	Loss: 1.4798
Training Epoch: 42 [46080/50176]	Loss: 1.4175
Training Epoch: 42 [47104/50176]	Loss: 1.4118
Training Epoch: 42 [48128/50176]	Loss: 1.4387
Training Epoch: 42 [49152/50176]	Loss: 1.4480
Training Epoch: 42 [50176/50176]	Loss: 1.5245
2022-12-06 18:46:05.454 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:46:05,512 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.79 energy=485.39
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Up to epoch 43: time=2116.43, energy=290405.05, cost=330390.00
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Expected next epoch: time=2163.53, energy=297092.93, cost=337855.49
2022-12-06 13:46:05,514 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0211, Accuracy: 0.0104
2022-12-06 13:46:05,749 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:46:05,749 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:46:05.763 [ZeusMonitor] Monitor started.
2022-12-06 18:46:05.763 [ZeusMonitor] Running indefinitely. 2022-12-06 18:46:05.763 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:46:05.763 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 13:46:49,640 [ZeusDataLoader(train)] train epoch 44 done: time=44.12 energy=6221.07
2022-12-06 13:46:49,643 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 1.2928
Training Epoch: 43 [2048/50176]	Loss: 1.3129
Training Epoch: 43 [3072/50176]	Loss: 1.3428
Training Epoch: 43 [4096/50176]	Loss: 1.4413
Training Epoch: 43 [5120/50176]	Loss: 1.3704
Training Epoch: 43 [6144/50176]	Loss: 1.3472
Training Epoch: 43 [7168/50176]	Loss: 1.4143
Training Epoch: 43 [8192/50176]	Loss: 1.3285
Training Epoch: 43 [9216/50176]	Loss: 1.4342
Training Epoch: 43 [10240/50176]	Loss: 1.4770
Training Epoch: 43 [11264/50176]	Loss: 1.3935
Training Epoch: 43 [12288/50176]	Loss: 1.3911
Training Epoch: 43 [13312/50176]	Loss: 1.3390
Training Epoch: 43 [14336/50176]	Loss: 1.3317
Training Epoch: 43 [15360/50176]	Loss: 1.3996
Training Epoch: 43 [16384/50176]	Loss: 1.4749
Training Epoch: 43 [17408/50176]	Loss: 1.4163
Training Epoch: 43 [18432/50176]	Loss: 1.4137
Training Epoch: 43 [19456/50176]	Loss: 1.5459
Training Epoch: 43 [20480/50176]	Loss: 1.4452
Training Epoch: 43 [21504/50176]	Loss: 1.5105
Training Epoch: 43 [22528/50176]	Loss: 1.3912
Training Epoch: 43 [23552/50176]	Loss: 1.3557
Training Epoch: 43 [24576/50176]	Loss: 1.3901
Training Epoch: 43 [25600/50176]	Loss: 1.4956
Training Epoch: 43 [26624/50176]	Loss: 1.4189
Training Epoch: 43 [27648/50176]	Loss: 1.3816
Training Epoch: 43 [28672/50176]	Loss: 1.3918
Training Epoch: 43 [29696/50176]	Loss: 1.3028
Training Epoch: 43 [30720/50176]	Loss: 1.3762
Training Epoch: 43 [31744/50176]	Loss: 1.3927
Training Epoch: 43 [32768/50176]	Loss: 1.4235
Training Epoch: 43 [33792/50176]	Loss: 1.3742
Training Epoch: 43 [34816/50176]	Loss: 1.5141
Training Epoch: 43 [35840/50176]	Loss: 1.4811
Training Epoch: 43 [36864/50176]	Loss: 1.4625
Training Epoch: 43 [37888/50176]	Loss: 1.4431
Training Epoch: 43 [38912/50176]	Loss: 1.3260
Training Epoch: 43 [39936/50176]	Loss: 1.3572
Training Epoch: 43 [40960/50176]	Loss: 1.3288
Training Epoch: 43 [41984/50176]	Loss: 1.4494
Training Epoch: 43 [43008/50176]	Loss: 1.3853
Training Epoch: 43 [44032/50176]	Loss: 1.4242
Training Epoch: 43 [45056/50176]	Loss: 1.4222
Training Epoch: 43 [46080/50176]	Loss: 1.4208
Training Epoch: 43 [47104/50176]	Loss: 1.4713
Training Epoch: 43 [48128/50176]	Loss: 1.4158
Training Epoch: 43 [49152/50176]	Loss: 1.3676
Training Epoch: 43 [50176/50176]	Loss: 1.4212
2022-12-06 18:46:53.400 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:46:53,434 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.78 energy=481.71
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Up to epoch 44: time=2164.33, energy=297107.83, cost=337932.72
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Expected next epoch: time=2211.43, energy=303795.71, cost=345398.22
2022-12-06 13:46:53,435 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0402, Accuracy: 0.0087
2022-12-06 13:46:53,671 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:46:53,671 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:46:53.673 [ZeusMonitor] Monitor started.
2022-12-06 18:46:53.673 [ZeusMonitor] Running indefinitely. 2022-12-06 18:46:53.673 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:46:53.673 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 13:47:37,583 [ZeusDataLoader(train)] train epoch 45 done: time=44.14 energy=6221.38
2022-12-06 13:47:37,586 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 1.3066
Training Epoch: 44 [2048/50176]	Loss: 1.4356
Training Epoch: 44 [3072/50176]	Loss: 1.2739
Training Epoch: 44 [4096/50176]	Loss: 1.3183
Training Epoch: 44 [5120/50176]	Loss: 1.3063
Training Epoch: 44 [6144/50176]	Loss: 1.2650
Training Epoch: 44 [7168/50176]	Loss: 1.3521
Training Epoch: 44 [8192/50176]	Loss: 1.2880
Training Epoch: 44 [9216/50176]	Loss: 1.3085
Training Epoch: 44 [10240/50176]	Loss: 1.2637
Training Epoch: 44 [11264/50176]	Loss: 1.3904
Training Epoch: 44 [12288/50176]	Loss: 1.2229
Training Epoch: 44 [13312/50176]	Loss: 1.4262
Training Epoch: 44 [14336/50176]	Loss: 1.4238
Training Epoch: 44 [15360/50176]	Loss: 1.3387
Training Epoch: 44 [16384/50176]	Loss: 1.3578
Training Epoch: 44 [17408/50176]	Loss: 1.3577
Training Epoch: 44 [18432/50176]	Loss: 1.3252
Training Epoch: 44 [19456/50176]	Loss: 1.3791
Training Epoch: 44 [20480/50176]	Loss: 1.3591
Training Epoch: 44 [21504/50176]	Loss: 1.4304
Training Epoch: 44 [22528/50176]	Loss: 1.3398
Training Epoch: 44 [23552/50176]	Loss: 1.3453
Training Epoch: 44 [24576/50176]	Loss: 1.3995
Training Epoch: 44 [25600/50176]	Loss: 1.3963
Training Epoch: 44 [26624/50176]	Loss: 1.4472
Training Epoch: 44 [27648/50176]	Loss: 1.3932
Training Epoch: 44 [28672/50176]	Loss: 1.3842
Training Epoch: 44 [29696/50176]	Loss: 1.3776
Training Epoch: 44 [30720/50176]	Loss: 1.3175
Training Epoch: 44 [31744/50176]	Loss: 1.4021
Training Epoch: 44 [32768/50176]	Loss: 1.3908
Training Epoch: 44 [33792/50176]	Loss: 1.3978
Training Epoch: 44 [34816/50176]	Loss: 1.3499
Training Epoch: 44 [35840/50176]	Loss: 1.3886
Training Epoch: 44 [36864/50176]	Loss: 1.3895
Training Epoch: 44 [37888/50176]	Loss: 1.4464
Training Epoch: 44 [38912/50176]	Loss: 1.4374
Training Epoch: 44 [39936/50176]	Loss: 1.4369
Training Epoch: 44 [40960/50176]	Loss: 1.3704
Training Epoch: 44 [41984/50176]	Loss: 1.2727
Training Epoch: 44 [43008/50176]	Loss: 1.4023
Training Epoch: 44 [44032/50176]	Loss: 1.4812
Training Epoch: 44 [45056/50176]	Loss: 1.4024
Training Epoch: 44 [46080/50176]	Loss: 1.4577
Training Epoch: 44 [47104/50176]	Loss: 1.3923
Training Epoch: 44 [48128/50176]	Loss: 1.3891
Training Epoch: 44 [49152/50176]	Loss: 1.4286
Training Epoch: 44 [50176/50176]	Loss: 1.3846
2022-12-06 18:47:41.336 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:47:41,373 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.78 energy=483.45
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Up to epoch 45: time=2212.25, energy=303812.66, cost=345478.02
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Expected next epoch: time=2259.35, energy=310500.54, cost=352943.51
2022-12-06 13:47:41,374 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0279, Accuracy: 0.0128
2022-12-06 13:47:41,619 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:47:41,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:47:41.621 [ZeusMonitor] Monitor started.
2022-12-06 18:47:41.621 [ZeusMonitor] Running indefinitely. 2022-12-06 18:47:41.621 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:47:41.621 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 13:48:25,434 [ZeusDataLoader(train)] train epoch 46 done: time=44.05 energy=6215.15
2022-12-06 13:48:25,438 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 1.3335
Training Epoch: 45 [2048/50176]	Loss: 1.3298
Training Epoch: 45 [3072/50176]	Loss: 1.2939
Training Epoch: 45 [4096/50176]	Loss: 1.4136
Training Epoch: 45 [5120/50176]	Loss: 1.2413
Training Epoch: 45 [6144/50176]	Loss: 1.3410
Training Epoch: 45 [7168/50176]	Loss: 1.3209
Training Epoch: 45 [8192/50176]	Loss: 1.4199
Training Epoch: 45 [9216/50176]	Loss: 1.2851
Training Epoch: 45 [10240/50176]	Loss: 1.3676
Training Epoch: 45 [11264/50176]	Loss: 1.4051
Training Epoch: 45 [12288/50176]	Loss: 1.3657
Training Epoch: 45 [13312/50176]	Loss: 1.3145
Training Epoch: 45 [14336/50176]	Loss: 1.3491
Training Epoch: 45 [15360/50176]	Loss: 1.2979
Training Epoch: 45 [16384/50176]	Loss: 1.3034
Training Epoch: 45 [17408/50176]	Loss: 1.3085
Training Epoch: 45 [18432/50176]	Loss: 1.4092
Training Epoch: 45 [19456/50176]	Loss: 1.3835
Training Epoch: 45 [20480/50176]	Loss: 1.3175
Training Epoch: 45 [21504/50176]	Loss: 1.3059
Training Epoch: 45 [22528/50176]	Loss: 1.3174
Training Epoch: 45 [23552/50176]	Loss: 1.3071
Training Epoch: 45 [24576/50176]	Loss: 1.2939
Training Epoch: 45 [25600/50176]	Loss: 1.3548
Training Epoch: 45 [26624/50176]	Loss: 1.3429
Training Epoch: 45 [27648/50176]	Loss: 1.3299
Training Epoch: 45 [28672/50176]	Loss: 1.3796
Training Epoch: 45 [29696/50176]	Loss: 1.3930
Training Epoch: 45 [30720/50176]	Loss: 1.3763
Training Epoch: 45 [31744/50176]	Loss: 1.2999
Training Epoch: 45 [32768/50176]	Loss: 1.3443
Training Epoch: 45 [33792/50176]	Loss: 1.3729
Training Epoch: 45 [34816/50176]	Loss: 1.4143
Training Epoch: 45 [35840/50176]	Loss: 1.3459
Training Epoch: 45 [36864/50176]	Loss: 1.3793
Training Epoch: 45 [37888/50176]	Loss: 1.4023
Training Epoch: 45 [38912/50176]	Loss: 1.3285
Training Epoch: 45 [39936/50176]	Loss: 1.3613
Training Epoch: 45 [40960/50176]	Loss: 1.4466
Training Epoch: 45 [41984/50176]	Loss: 1.3409
Training Epoch: 45 [43008/50176]	Loss: 1.4071
Training Epoch: 45 [44032/50176]	Loss: 1.3834
Training Epoch: 45 [45056/50176]	Loss: 1.4735
Training Epoch: 45 [46080/50176]	Loss: 1.3524
Training Epoch: 45 [47104/50176]	Loss: 1.3338
Training Epoch: 45 [48128/50176]	Loss: 1.2996
Training Epoch: 45 [49152/50176]	Loss: 1.3266
Training Epoch: 45 [50176/50176]	Loss: 1.4442
2022-12-06 18:48:29.190 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:48:29,226 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.78 energy=485.27
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Up to epoch 46: time=2260.08, energy=310513.08, cost=353013.54
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Expected next epoch: time=2307.18, energy=317200.95, cost=360479.04
2022-12-06 13:48:29,228 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0456, Accuracy: 0.0138
2022-12-06 13:48:29,424 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:48:29,425 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:48:29.428 [ZeusMonitor] Monitor started.
2022-12-06 18:48:29.429 [ZeusMonitor] Running indefinitely. 2022-12-06 18:48:29.429 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:48:29.429 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 13:49:13,600 [ZeusDataLoader(train)] train epoch 47 done: time=44.36 energy=6241.73
2022-12-06 13:49:13,603 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 1.3085
Training Epoch: 46 [2048/50176]	Loss: 1.3878
Training Epoch: 46 [3072/50176]	Loss: 1.2803
Training Epoch: 46 [4096/50176]	Loss: 1.3137
Training Epoch: 46 [5120/50176]	Loss: 1.2936
Training Epoch: 46 [6144/50176]	Loss: 1.3421
Training Epoch: 46 [7168/50176]	Loss: 1.2254
Training Epoch: 46 [8192/50176]	Loss: 1.2660
Training Epoch: 46 [9216/50176]	Loss: 1.2354
Training Epoch: 46 [10240/50176]	Loss: 1.3189
Training Epoch: 46 [11264/50176]	Loss: 1.3371
Training Epoch: 46 [12288/50176]	Loss: 1.2908
Training Epoch: 46 [13312/50176]	Loss: 1.2877
Training Epoch: 46 [14336/50176]	Loss: 1.3372
Training Epoch: 46 [15360/50176]	Loss: 1.2925
Training Epoch: 46 [16384/50176]	Loss: 1.3600
Training Epoch: 46 [17408/50176]	Loss: 1.3588
Training Epoch: 46 [18432/50176]	Loss: 1.3619
Training Epoch: 46 [19456/50176]	Loss: 1.2924
Training Epoch: 46 [20480/50176]	Loss: 1.3501
Training Epoch: 46 [21504/50176]	Loss: 1.3526
Training Epoch: 46 [22528/50176]	Loss: 1.3576
Training Epoch: 46 [23552/50176]	Loss: 1.4313
Training Epoch: 46 [24576/50176]	Loss: 1.4600
Training Epoch: 46 [25600/50176]	Loss: 1.3313
Training Epoch: 46 [26624/50176]	Loss: 1.3539
Training Epoch: 46 [27648/50176]	Loss: 1.3801
Training Epoch: 46 [28672/50176]	Loss: 1.2807
Training Epoch: 46 [29696/50176]	Loss: 1.2665
Training Epoch: 46 [30720/50176]	Loss: 1.3588
Training Epoch: 46 [31744/50176]	Loss: 1.3368
Training Epoch: 46 [32768/50176]	Loss: 1.3083
Training Epoch: 46 [33792/50176]	Loss: 1.3808
Training Epoch: 46 [34816/50176]	Loss: 1.4109
Training Epoch: 46 [35840/50176]	Loss: 1.3762
Training Epoch: 46 [36864/50176]	Loss: 1.3301
Training Epoch: 46 [37888/50176]	Loss: 1.3535
Training Epoch: 46 [38912/50176]	Loss: 1.3716
Training Epoch: 46 [39936/50176]	Loss: 1.3902
Training Epoch: 46 [40960/50176]	Loss: 1.3468
Training Epoch: 46 [41984/50176]	Loss: 1.3643
Training Epoch: 46 [43008/50176]	Loss: 1.2284
Training Epoch: 46 [44032/50176]	Loss: 1.3113
Training Epoch: 46 [45056/50176]	Loss: 1.3821
Training Epoch: 46 [46080/50176]	Loss: 1.3382
Training Epoch: 46 [47104/50176]	Loss: 1.3580
Training Epoch: 46 [48128/50176]	Loss: 1.3708
Training Epoch: 46 [49152/50176]	Loss: 1.3703
Training Epoch: 46 [50176/50176]	Loss: 1.3353
2022-12-06 18:49:17.370 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:49:17,397 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.79 energy=473.39
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Up to epoch 47: time=2308.23, energy=317228.19, cost=360584.23
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Expected next epoch: time=2355.33, energy=323916.07, cost=368049.72
2022-12-06 13:49:17,399 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0500, Accuracy: 0.0165
2022-12-06 13:49:17,638 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:49:17,638 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:49:17.640 [ZeusMonitor] Monitor started.
2022-12-06 18:49:17.640 [ZeusMonitor] Running indefinitely. 2022-12-06 18:49:17.640 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:49:17.640 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 13:50:01,796 [ZeusDataLoader(train)] train epoch 48 done: time=44.39 energy=6246.24
2022-12-06 13:50:01,800 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 1.2303
Training Epoch: 47 [2048/50176]	Loss: 1.2424
Training Epoch: 47 [3072/50176]	Loss: 1.2734
Training Epoch: 47 [4096/50176]	Loss: 1.3091
Training Epoch: 47 [5120/50176]	Loss: 1.2810
Training Epoch: 47 [6144/50176]	Loss: 1.2881
Training Epoch: 47 [7168/50176]	Loss: 1.2324
Training Epoch: 47 [8192/50176]	Loss: 1.3228
Training Epoch: 47 [9216/50176]	Loss: 1.3109
Training Epoch: 47 [10240/50176]	Loss: 1.3194
Training Epoch: 47 [11264/50176]	Loss: 1.3613
Training Epoch: 47 [12288/50176]	Loss: 1.3383
Training Epoch: 47 [13312/50176]	Loss: 1.2767
Training Epoch: 47 [14336/50176]	Loss: 1.3271
Training Epoch: 47 [15360/50176]	Loss: 1.2437
Training Epoch: 47 [16384/50176]	Loss: 1.2932
Training Epoch: 47 [17408/50176]	Loss: 1.2509
Training Epoch: 47 [18432/50176]	Loss: 1.2123
Training Epoch: 47 [19456/50176]	Loss: 1.3945
Training Epoch: 47 [20480/50176]	Loss: 1.3334
Training Epoch: 47 [21504/50176]	Loss: 1.3328
Training Epoch: 47 [22528/50176]	Loss: 1.2786
Training Epoch: 47 [23552/50176]	Loss: 1.2826
Training Epoch: 47 [24576/50176]	Loss: 1.2633
Training Epoch: 47 [25600/50176]	Loss: 1.3519
Training Epoch: 47 [26624/50176]	Loss: 1.2212
Training Epoch: 47 [27648/50176]	Loss: 1.2608
Training Epoch: 47 [28672/50176]	Loss: 1.2714
Training Epoch: 47 [29696/50176]	Loss: 1.2734
Training Epoch: 47 [30720/50176]	Loss: 1.3931
Training Epoch: 47 [31744/50176]	Loss: 1.2688
Training Epoch: 47 [32768/50176]	Loss: 1.4009
Training Epoch: 47 [33792/50176]	Loss: 1.3892
Training Epoch: 47 [34816/50176]	Loss: 1.2907
Training Epoch: 47 [35840/50176]	Loss: 1.3478
Training Epoch: 47 [36864/50176]	Loss: 1.3133
Training Epoch: 47 [37888/50176]	Loss: 1.3024
Training Epoch: 47 [38912/50176]	Loss: 1.3500
Training Epoch: 47 [39936/50176]	Loss: 1.3414
Training Epoch: 47 [40960/50176]	Loss: 1.2144
Training Epoch: 47 [41984/50176]	Loss: 1.4376
Training Epoch: 47 [43008/50176]	Loss: 1.3718
Training Epoch: 47 [44032/50176]	Loss: 1.2703
Training Epoch: 47 [45056/50176]	Loss: 1.3359
Training Epoch: 47 [46080/50176]	Loss: 1.3696
Training Epoch: 47 [47104/50176]	Loss: 1.2403
Training Epoch: 47 [48128/50176]	Loss: 1.3121
Training Epoch: 47 [49152/50176]	Loss: 1.3170
Training Epoch: 47 [50176/50176]	Loss: 1.3844
2022-12-06 18:50:05.554 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:50:05,565 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.76 energy=466.33
2022-12-06 13:50:05,565 [ZeusDataLoader(train)] Up to epoch 48: time=2356.38, energy=323940.76, cost=368153.35
2022-12-06 13:50:05,566 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:50:05,566 [ZeusDataLoader(train)] Expected next epoch: time=2403.48, energy=330628.64, cost=375618.85
2022-12-06 13:50:05,567 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.9088, Accuracy: 0.0093
2022-12-06 13:50:05,818 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:50:05,819 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:50:05.821 [ZeusMonitor] Monitor started.
2022-12-06 18:50:05.821 [ZeusMonitor] Running indefinitely. 2022-12-06 18:50:05.821 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:50:05.821 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 13:50:49,958 [ZeusDataLoader(train)] train epoch 49 done: time=44.38 energy=6224.26
2022-12-06 13:50:49,962 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 1.2758
Training Epoch: 48 [2048/50176]	Loss: 1.2273
Training Epoch: 48 [3072/50176]	Loss: 1.2165
Training Epoch: 48 [4096/50176]	Loss: 1.2825
Training Epoch: 48 [5120/50176]	Loss: 1.2584
Training Epoch: 48 [6144/50176]	Loss: 1.2374
Training Epoch: 48 [7168/50176]	Loss: 1.1686
Training Epoch: 48 [8192/50176]	Loss: 1.2083
Training Epoch: 48 [9216/50176]	Loss: 1.2426
Training Epoch: 48 [10240/50176]	Loss: 1.2892
Training Epoch: 48 [11264/50176]	Loss: 1.2234
Training Epoch: 48 [12288/50176]	Loss: 1.2655
Training Epoch: 48 [13312/50176]	Loss: 1.2660
Training Epoch: 48 [14336/50176]	Loss: 1.2706
Training Epoch: 48 [15360/50176]	Loss: 1.3671
Training Epoch: 48 [16384/50176]	Loss: 1.2434
Training Epoch: 48 [17408/50176]	Loss: 1.2304
Training Epoch: 48 [18432/50176]	Loss: 1.2624
Training Epoch: 48 [19456/50176]	Loss: 1.2683
Training Epoch: 48 [20480/50176]	Loss: 1.2971
Training Epoch: 48 [21504/50176]	Loss: 1.3209
Training Epoch: 48 [22528/50176]	Loss: 1.2161
Training Epoch: 48 [23552/50176]	Loss: 1.3116
Training Epoch: 48 [24576/50176]	Loss: 1.3006
Training Epoch: 48 [25600/50176]	Loss: 1.2862
Training Epoch: 48 [26624/50176]	Loss: 1.2086
Training Epoch: 48 [27648/50176]	Loss: 1.4320
Training Epoch: 48 [28672/50176]	Loss: 1.2621
Training Epoch: 48 [29696/50176]	Loss: 1.2489
Training Epoch: 48 [30720/50176]	Loss: 1.3093
Training Epoch: 48 [31744/50176]	Loss: 1.2827
Training Epoch: 48 [32768/50176]	Loss: 1.2905
Training Epoch: 48 [33792/50176]	Loss: 1.3884
Training Epoch: 48 [34816/50176]	Loss: 1.2517
Training Epoch: 48 [35840/50176]	Loss: 1.3164
Training Epoch: 48 [36864/50176]	Loss: 1.2886
Training Epoch: 48 [37888/50176]	Loss: 1.2894
Training Epoch: 48 [38912/50176]	Loss: 1.2476
Training Epoch: 48 [39936/50176]	Loss: 1.2054
Training Epoch: 48 [40960/50176]	Loss: 1.3414
Training Epoch: 48 [41984/50176]	Loss: 1.3471
Training Epoch: 48 [43008/50176]	Loss: 1.3320
Training Epoch: 48 [44032/50176]	Loss: 1.3069
Training Epoch: 48 [45056/50176]	Loss: 1.2759
Training Epoch: 48 [46080/50176]	Loss: 1.3778
Training Epoch: 48 [47104/50176]	Loss: 1.3020
Training Epoch: 48 [48128/50176]	Loss: 1.3257
Training Epoch: 48 [49152/50176]	Loss: 1.3086
Training Epoch: 48 [50176/50176]	Loss: 1.3093
2022-12-06 18:50:53.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:50:53,769 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.80 energy=485.67
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Up to epoch 49: time=2404.56, energy=330650.68, cost=375724.32
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Expected next epoch: time=2451.66, energy=337338.56, cost=383189.82
2022-12-06 13:50:53,770 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0481, Accuracy: 0.0116
2022-12-06 13:50:54,011 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:50:54,012 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:50:54.014 [ZeusMonitor] Monitor started.
2022-12-06 18:50:54.014 [ZeusMonitor] Running indefinitely. 2022-12-06 18:50:54.014 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:50:54.014 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 13:51:38,264 [ZeusDataLoader(train)] train epoch 50 done: time=44.49 energy=6251.62
2022-12-06 13:51:38,268 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 1.1842
Training Epoch: 49 [2048/50176]	Loss: 1.2198
Training Epoch: 49 [3072/50176]	Loss: 1.2537
Training Epoch: 49 [4096/50176]	Loss: 1.2967
Training Epoch: 49 [5120/50176]	Loss: 1.2593
Training Epoch: 49 [6144/50176]	Loss: 1.1486
Training Epoch: 49 [7168/50176]	Loss: 1.2104
Training Epoch: 49 [8192/50176]	Loss: 1.2623
Training Epoch: 49 [9216/50176]	Loss: 1.2931
Training Epoch: 49 [10240/50176]	Loss: 1.2644
Training Epoch: 49 [11264/50176]	Loss: 1.3363
Training Epoch: 49 [12288/50176]	Loss: 1.3334
Training Epoch: 49 [13312/50176]	Loss: 1.2528
Training Epoch: 49 [14336/50176]	Loss: 1.2968
Training Epoch: 49 [15360/50176]	Loss: 1.3655
Training Epoch: 49 [16384/50176]	Loss: 1.3728
Training Epoch: 49 [17408/50176]	Loss: 1.1876
Training Epoch: 49 [18432/50176]	Loss: 1.2675
Training Epoch: 49 [19456/50176]	Loss: 1.2388
Training Epoch: 49 [20480/50176]	Loss: 1.2132
Training Epoch: 49 [21504/50176]	Loss: 1.2417
Training Epoch: 49 [22528/50176]	Loss: 1.2804
Training Epoch: 49 [23552/50176]	Loss: 1.2994
Training Epoch: 49 [24576/50176]	Loss: 1.2315
Training Epoch: 49 [25600/50176]	Loss: 1.3087
Training Epoch: 49 [26624/50176]	Loss: 1.3293
Training Epoch: 49 [27648/50176]	Loss: 1.3119
Training Epoch: 49 [28672/50176]	Loss: 1.2274
Training Epoch: 49 [29696/50176]	Loss: 1.2431
Training Epoch: 49 [30720/50176]	Loss: 1.3010
Training Epoch: 49 [31744/50176]	Loss: 1.3181
Training Epoch: 49 [32768/50176]	Loss: 1.2119
Training Epoch: 49 [33792/50176]	Loss: 1.2482
Training Epoch: 49 [34816/50176]	Loss: 1.3386
Training Epoch: 49 [35840/50176]	Loss: 1.3756
Training Epoch: 49 [36864/50176]	Loss: 1.3243
Training Epoch: 49 [37888/50176]	Loss: 1.2357
Training Epoch: 49 [38912/50176]	Loss: 1.2860
Training Epoch: 49 [39936/50176]	Loss: 1.3412
Training Epoch: 49 [40960/50176]	Loss: 1.1872
Training Epoch: 49 [41984/50176]	Loss: 1.4475
Training Epoch: 49 [43008/50176]	Loss: 1.3275
Training Epoch: 49 [44032/50176]	Loss: 1.2425
Training Epoch: 49 [45056/50176]	Loss: 1.3082
Training Epoch: 49 [46080/50176]	Loss: 1.2756
Training Epoch: 49 [47104/50176]	Loss: 1.3165
Training Epoch: 49 [48128/50176]	Loss: 1.2813
Training Epoch: 49 [49152/50176]	Loss: 1.3616
Training Epoch: 49 [50176/50176]	Loss: 1.2845
2022-12-06 18:51:42.037 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:51:42,070 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.79 energy=495.10
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Up to epoch 50: time=2452.84, energy=337397.41, cost=383322.18
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Expected next epoch: time=2499.94, energy=344085.29, cost=390787.68
2022-12-06 13:51:42,071 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.1582, Accuracy: 0.0098
2022-12-06 13:51:42,334 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:51:42,335 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:51:42.336 [ZeusMonitor] Monitor started.
2022-12-06 18:51:42.336 [ZeusMonitor] Running indefinitely. 2022-12-06 18:51:42.337 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:51:42.337 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 13:52:26,743 [ZeusDataLoader(train)] train epoch 51 done: time=44.66 energy=6258.73
2022-12-06 13:52:26,746 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 1.1492
Training Epoch: 50 [2048/50176]	Loss: 1.1802
Training Epoch: 50 [3072/50176]	Loss: 1.3094
Training Epoch: 50 [4096/50176]	Loss: 1.2962
Training Epoch: 50 [5120/50176]	Loss: 1.2871
Training Epoch: 50 [6144/50176]	Loss: 1.2301
Training Epoch: 50 [7168/50176]	Loss: 1.2479
Training Epoch: 50 [8192/50176]	Loss: 1.2523
Training Epoch: 50 [9216/50176]	Loss: 1.2555
Training Epoch: 50 [10240/50176]	Loss: 1.2466
Training Epoch: 50 [11264/50176]	Loss: 1.1604
Training Epoch: 50 [12288/50176]	Loss: 1.2153
Training Epoch: 50 [13312/50176]	Loss: 1.2396
Training Epoch: 50 [14336/50176]	Loss: 1.2108
Training Epoch: 50 [15360/50176]	Loss: 1.2592
Training Epoch: 50 [16384/50176]	Loss: 1.2149
Training Epoch: 50 [17408/50176]	Loss: 1.2238
Training Epoch: 50 [18432/50176]	Loss: 1.3003
Training Epoch: 50 [19456/50176]	Loss: 1.2476
Training Epoch: 50 [20480/50176]	Loss: 1.2794
Training Epoch: 50 [21504/50176]	Loss: 1.1742
Training Epoch: 50 [22528/50176]	Loss: 1.1979
Training Epoch: 50 [23552/50176]	Loss: 1.2136
Training Epoch: 50 [24576/50176]	Loss: 1.2616
Training Epoch: 50 [25600/50176]	Loss: 1.2779
Training Epoch: 50 [26624/50176]	Loss: 1.2485
Training Epoch: 50 [27648/50176]	Loss: 1.2544
Training Epoch: 50 [28672/50176]	Loss: 1.3372
Training Epoch: 50 [29696/50176]	Loss: 1.2231
Training Epoch: 50 [30720/50176]	Loss: 1.2511
Training Epoch: 50 [31744/50176]	Loss: 1.2123
Training Epoch: 50 [32768/50176]	Loss: 1.3136
Training Epoch: 50 [33792/50176]	Loss: 1.2316
Training Epoch: 50 [34816/50176]	Loss: 1.3311
Training Epoch: 50 [35840/50176]	Loss: 1.2154
Training Epoch: 50 [36864/50176]	Loss: 1.3581
Training Epoch: 50 [37888/50176]	Loss: 1.1701
Training Epoch: 50 [38912/50176]	Loss: 1.2564
Training Epoch: 50 [39936/50176]	Loss: 1.2177
Training Epoch: 50 [40960/50176]	Loss: 1.2769
Training Epoch: 50 [41984/50176]	Loss: 1.2630
Training Epoch: 50 [43008/50176]	Loss: 1.2551
Training Epoch: 50 [44032/50176]	Loss: 1.3165
Training Epoch: 50 [45056/50176]	Loss: 1.3362
Training Epoch: 50 [46080/50176]	Loss: 1.3225
Training Epoch: 50 [47104/50176]	Loss: 1.2879
Training Epoch: 50 [48128/50176]	Loss: 1.2497
Training Epoch: 50 [49152/50176]	Loss: 1.2690
Training Epoch: 50 [50176/50176]	Loss: 1.3089
2022-12-06 18:52:30.455 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:52:30,476 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.72 energy=473.27
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Up to epoch 51: time=2501.22, energy=344129.41, cost=390921.89
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Expected next epoch: time=2548.33, energy=350817.29, cost=398387.39
2022-12-06 13:52:30,478 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0189, Accuracy: 0.0135
2022-12-06 13:52:30,720 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:52:30,721 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:52:30.722 [ZeusMonitor] Monitor started.
2022-12-06 18:52:30.722 [ZeusMonitor] Running indefinitely. 2022-12-06 18:52:30.722 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:52:30.723 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 13:53:15,023 [ZeusDataLoader(train)] train epoch 52 done: time=44.54 energy=6239.86
2022-12-06 13:53:15,027 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 1.1018
Training Epoch: 51 [2048/50176]	Loss: 1.2788
Training Epoch: 51 [3072/50176]	Loss: 1.2085
Training Epoch: 51 [4096/50176]	Loss: 1.1910
Training Epoch: 51 [5120/50176]	Loss: 1.1903
Training Epoch: 51 [6144/50176]	Loss: 1.1790
Training Epoch: 51 [7168/50176]	Loss: 1.2170
Training Epoch: 51 [8192/50176]	Loss: 1.2865
Training Epoch: 51 [9216/50176]	Loss: 1.1884
Training Epoch: 51 [10240/50176]	Loss: 1.1753
Training Epoch: 51 [11264/50176]	Loss: 1.2608
Training Epoch: 51 [12288/50176]	Loss: 1.2642
Training Epoch: 51 [13312/50176]	Loss: 1.2405
Training Epoch: 51 [14336/50176]	Loss: 1.1625
Training Epoch: 51 [15360/50176]	Loss: 1.2582
Training Epoch: 51 [16384/50176]	Loss: 1.3080
Training Epoch: 51 [17408/50176]	Loss: 1.2198
Training Epoch: 51 [18432/50176]	Loss: 1.3662
Training Epoch: 51 [19456/50176]	Loss: 1.2223
Training Epoch: 51 [20480/50176]	Loss: 1.2228
Training Epoch: 51 [21504/50176]	Loss: 1.1636
Training Epoch: 51 [22528/50176]	Loss: 1.2145
Training Epoch: 51 [23552/50176]	Loss: 1.2445
Training Epoch: 51 [24576/50176]	Loss: 1.3094
Training Epoch: 51 [25600/50176]	Loss: 1.2437
Training Epoch: 51 [26624/50176]	Loss: 1.2449
Training Epoch: 51 [27648/50176]	Loss: 1.2953
Training Epoch: 51 [28672/50176]	Loss: 1.1849
Training Epoch: 51 [29696/50176]	Loss: 1.3412
Training Epoch: 51 [30720/50176]	Loss: 1.2239
Training Epoch: 51 [31744/50176]	Loss: 1.3006
Training Epoch: 51 [32768/50176]	Loss: 1.2144
Training Epoch: 51 [33792/50176]	Loss: 1.2845
Training Epoch: 51 [34816/50176]	Loss: 1.2257
Training Epoch: 51 [35840/50176]	Loss: 1.2264
Training Epoch: 51 [36864/50176]	Loss: 1.1655
Training Epoch: 51 [37888/50176]	Loss: 1.3241
Training Epoch: 51 [38912/50176]	Loss: 1.2161
Training Epoch: 51 [39936/50176]	Loss: 1.1780
Training Epoch: 51 [40960/50176]	Loss: 1.2511
Training Epoch: 51 [41984/50176]	Loss: 1.3164
Training Epoch: 51 [43008/50176]	Loss: 1.2709
Training Epoch: 51 [44032/50176]	Loss: 1.2135
Training Epoch: 51 [45056/50176]	Loss: 1.3265
Training Epoch: 51 [46080/50176]	Loss: 1.3445
Training Epoch: 51 [47104/50176]	Loss: 1.2971
Training Epoch: 51 [48128/50176]	Loss: 1.1802
Training Epoch: 51 [49152/50176]	Loss: 1.3040
Training Epoch: 51 [50176/50176]	Loss: 1.3197
2022-12-06 18:53:18.915 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:53:18,936 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.90 energy=496.41
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Up to epoch 52: time=2549.66, energy=350865.68, cost=398528.34
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Expected next epoch: time=2596.77, energy=357553.56, cost=405993.84
2022-12-06 13:53:18,937 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0227, Accuracy: 0.0130
2022-12-06 13:53:19,178 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:53:19,179 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:53:19.180 [ZeusMonitor] Monitor started.
2022-12-06 18:53:19.181 [ZeusMonitor] Running indefinitely. 2022-12-06 18:53:19.181 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:53:19.181 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 13:54:03,501 [ZeusDataLoader(train)] train epoch 53 done: time=44.56 energy=6247.85
2022-12-06 13:54:03,504 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 1.1792
Training Epoch: 52 [2048/50176]	Loss: 1.1727
Training Epoch: 52 [3072/50176]	Loss: 1.1579
Training Epoch: 52 [4096/50176]	Loss: 1.1303
Training Epoch: 52 [5120/50176]	Loss: 1.1771
Training Epoch: 52 [6144/50176]	Loss: 1.1917
Training Epoch: 52 [7168/50176]	Loss: 1.1574
Training Epoch: 52 [8192/50176]	Loss: 1.2285
Training Epoch: 52 [9216/50176]	Loss: 1.1317
Training Epoch: 52 [10240/50176]	Loss: 1.1983
Training Epoch: 52 [11264/50176]	Loss: 1.1817
Training Epoch: 52 [12288/50176]	Loss: 1.1599
Training Epoch: 52 [13312/50176]	Loss: 1.1588
Training Epoch: 52 [14336/50176]	Loss: 1.1289
Training Epoch: 52 [15360/50176]	Loss: 1.1273
Training Epoch: 52 [16384/50176]	Loss: 1.2113
Training Epoch: 52 [17408/50176]	Loss: 1.1912
Training Epoch: 52 [18432/50176]	Loss: 1.2387
Training Epoch: 52 [19456/50176]	Loss: 1.1615
Training Epoch: 52 [20480/50176]	Loss: 1.2496
Training Epoch: 52 [21504/50176]	Loss: 1.1873
Training Epoch: 52 [22528/50176]	Loss: 1.3094
Training Epoch: 52 [23552/50176]	Loss: 1.2609
Training Epoch: 52 [24576/50176]	Loss: 1.2725
Training Epoch: 52 [25600/50176]	Loss: 1.2545
Training Epoch: 52 [26624/50176]	Loss: 1.2498
Training Epoch: 52 [27648/50176]	Loss: 1.3175
Training Epoch: 52 [28672/50176]	Loss: 1.2581
Training Epoch: 52 [29696/50176]	Loss: 1.2450
Training Epoch: 52 [30720/50176]	Loss: 1.2843
Training Epoch: 52 [31744/50176]	Loss: 1.2108
Training Epoch: 52 [32768/50176]	Loss: 1.2675
Training Epoch: 52 [33792/50176]	Loss: 1.2598
Training Epoch: 52 [34816/50176]	Loss: 1.1983
Training Epoch: 52 [35840/50176]	Loss: 1.2653
Training Epoch: 52 [36864/50176]	Loss: 1.3654
Training Epoch: 52 [37888/50176]	Loss: 1.2929
Training Epoch: 52 [38912/50176]	Loss: 1.1939
Training Epoch: 52 [39936/50176]	Loss: 1.2310
Training Epoch: 52 [40960/50176]	Loss: 1.2379
Training Epoch: 52 [41984/50176]	Loss: 1.2032
Training Epoch: 52 [43008/50176]	Loss: 1.2487
Training Epoch: 52 [44032/50176]	Loss: 1.3435
Training Epoch: 52 [45056/50176]	Loss: 1.2515
Training Epoch: 52 [46080/50176]	Loss: 1.3057
Training Epoch: 52 [47104/50176]	Loss: 1.2361
Training Epoch: 52 [48128/50176]	Loss: 1.2720
Training Epoch: 52 [49152/50176]	Loss: 1.2548
Training Epoch: 52 [50176/50176]	Loss: 1.4103
2022-12-06 18:54:07.183 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:54:07,203 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.69 energy=459.58
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Up to epoch 53: time=2597.91, energy=357573.12, cost=406103.65
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Expected next epoch: time=2645.01, energy=364260.99, cost=413569.15
2022-12-06 13:54:07,204 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0275, Accuracy: 0.0117
2022-12-06 13:54:07,502 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:54:07,503 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:54:07.516 [ZeusMonitor] Monitor started.
2022-12-06 18:54:07.517 [ZeusMonitor] Running indefinitely. 2022-12-06 18:54:07.517 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:54:07.517 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 13:54:51,701 [ZeusDataLoader(train)] train epoch 54 done: time=44.49 energy=6231.40
2022-12-06 13:54:51,705 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 1.1342
Training Epoch: 53 [2048/50176]	Loss: 1.0997
Training Epoch: 53 [3072/50176]	Loss: 1.1551
Training Epoch: 53 [4096/50176]	Loss: 1.1690
Training Epoch: 53 [5120/50176]	Loss: 1.1771
Training Epoch: 53 [6144/50176]	Loss: 1.1111
Training Epoch: 53 [7168/50176]	Loss: 1.1788
Training Epoch: 53 [8192/50176]	Loss: 1.1702
Training Epoch: 53 [9216/50176]	Loss: 1.1891
Training Epoch: 53 [10240/50176]	Loss: 1.2295
Training Epoch: 53 [11264/50176]	Loss: 1.0520
Training Epoch: 53 [12288/50176]	Loss: 1.1587
Training Epoch: 53 [13312/50176]	Loss: 1.0893
Training Epoch: 53 [14336/50176]	Loss: 1.2022
Training Epoch: 53 [15360/50176]	Loss: 1.1580
Training Epoch: 53 [16384/50176]	Loss: 1.2151
Training Epoch: 53 [17408/50176]	Loss: 1.1289
Training Epoch: 53 [18432/50176]	Loss: 1.1424
Training Epoch: 53 [19456/50176]	Loss: 1.3138
Training Epoch: 53 [20480/50176]	Loss: 1.1673
Training Epoch: 53 [21504/50176]	Loss: 1.1671
Training Epoch: 53 [22528/50176]	Loss: 1.2282
Training Epoch: 53 [23552/50176]	Loss: 1.1246
Training Epoch: 53 [24576/50176]	Loss: 1.1804
Training Epoch: 53 [25600/50176]	Loss: 1.1479
Training Epoch: 53 [26624/50176]	Loss: 1.1563
Training Epoch: 53 [27648/50176]	Loss: 1.2565
Training Epoch: 53 [28672/50176]	Loss: 1.1602
Training Epoch: 53 [29696/50176]	Loss: 1.2186
Training Epoch: 53 [30720/50176]	Loss: 1.2926
Training Epoch: 53 [31744/50176]	Loss: 1.1838
Training Epoch: 53 [32768/50176]	Loss: 1.2437
Training Epoch: 53 [33792/50176]	Loss: 1.1897
Training Epoch: 53 [34816/50176]	Loss: 1.1165
Training Epoch: 53 [35840/50176]	Loss: 1.1696
Training Epoch: 53 [36864/50176]	Loss: 1.2360
Training Epoch: 53 [37888/50176]	Loss: 1.2926
Training Epoch: 53 [38912/50176]	Loss: 1.2581
Training Epoch: 53 [39936/50176]	Loss: 1.2357
Training Epoch: 53 [40960/50176]	Loss: 1.2369
Training Epoch: 53 [41984/50176]	Loss: 1.2430
Training Epoch: 53 [43008/50176]	Loss: 1.2866
Training Epoch: 53 [44032/50176]	Loss: 1.2603
Training Epoch: 53 [45056/50176]	Loss: 1.2539
Training Epoch: 53 [46080/50176]	Loss: 1.2510
Training Epoch: 53 [47104/50176]	Loss: 1.2301
Training Epoch: 53 [48128/50176]	Loss: 1.2423
Training Epoch: 53 [49152/50176]	Loss: 1.2099
Training Epoch: 53 [50176/50176]	Loss: 1.2760
2022-12-06 18:54:55.431 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:54:55,451 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.74 energy=474.25
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Up to epoch 54: time=2646.14, energy=364278.76, cost=413676.39
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Expected next epoch: time=2693.24, energy=370966.64, cost=421141.89
2022-12-06 13:54:55,453 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0276, Accuracy: 0.0177
2022-12-06 13:54:55,693 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:54:55,693 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:54:55.695 [ZeusMonitor] Monitor started.
2022-12-06 18:54:55.695 [ZeusMonitor] Running indefinitely. 2022-12-06 18:54:55.695 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:54:55.695 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 13:55:39,486 [ZeusDataLoader(train)] train epoch 55 done: time=44.03 energy=6209.77
2022-12-06 13:55:39,489 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 1.2580
Training Epoch: 54 [2048/50176]	Loss: 1.2188
Training Epoch: 54 [3072/50176]	Loss: 1.1106
Training Epoch: 54 [4096/50176]	Loss: 1.1063
Training Epoch: 54 [5120/50176]	Loss: 1.0801
Training Epoch: 54 [6144/50176]	Loss: 1.1688
Training Epoch: 54 [7168/50176]	Loss: 1.1086
Training Epoch: 54 [8192/50176]	Loss: 1.1558
Training Epoch: 54 [9216/50176]	Loss: 1.1587
Training Epoch: 54 [10240/50176]	Loss: 1.1621
Training Epoch: 54 [11264/50176]	Loss: 1.1897
Training Epoch: 54 [12288/50176]	Loss: 1.0830
Training Epoch: 54 [13312/50176]	Loss: 1.1927
Training Epoch: 54 [14336/50176]	Loss: 1.1596
Training Epoch: 54 [15360/50176]	Loss: 1.2660
Training Epoch: 54 [16384/50176]	Loss: 1.0909
Training Epoch: 54 [17408/50176]	Loss: 1.1760
Training Epoch: 54 [18432/50176]	Loss: 1.1527
Training Epoch: 54 [19456/50176]	Loss: 1.2486
Training Epoch: 54 [20480/50176]	Loss: 1.1174
Training Epoch: 54 [21504/50176]	Loss: 1.1648
Training Epoch: 54 [22528/50176]	Loss: 1.2283
Training Epoch: 54 [23552/50176]	Loss: 1.1429
Training Epoch: 54 [24576/50176]	Loss: 1.1406
Training Epoch: 54 [25600/50176]	Loss: 1.1821
Training Epoch: 54 [26624/50176]	Loss: 1.1288
Training Epoch: 54 [27648/50176]	Loss: 1.2355
Training Epoch: 54 [28672/50176]	Loss: 1.2012
Training Epoch: 54 [29696/50176]	Loss: 1.0868
Training Epoch: 54 [30720/50176]	Loss: 1.1648
Training Epoch: 54 [31744/50176]	Loss: 1.1979
Training Epoch: 54 [32768/50176]	Loss: 1.1129
Training Epoch: 54 [33792/50176]	Loss: 1.2442
Training Epoch: 54 [34816/50176]	Loss: 1.2127
Training Epoch: 54 [35840/50176]	Loss: 1.3166
Training Epoch: 54 [36864/50176]	Loss: 1.2462
Training Epoch: 54 [37888/50176]	Loss: 1.1483
Training Epoch: 54 [38912/50176]	Loss: 1.1804
Training Epoch: 54 [39936/50176]	Loss: 1.2919
Training Epoch: 54 [40960/50176]	Loss: 1.2236
Training Epoch: 54 [41984/50176]	Loss: 1.1848
Training Epoch: 54 [43008/50176]	Loss: 1.1772
Training Epoch: 54 [44032/50176]	Loss: 1.1357
Training Epoch: 54 [45056/50176]	Loss: 1.2120
Training Epoch: 54 [46080/50176]	Loss: 1.2384
Training Epoch: 54 [47104/50176]	Loss: 1.1986
Training Epoch: 54 [48128/50176]	Loss: 1.1271
Training Epoch: 54 [49152/50176]	Loss: 1.2021
Training Epoch: 54 [50176/50176]	Loss: 1.2454
2022-12-06 18:55:43.297 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:55:43,318 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.82 energy=480.93
2022-12-06 13:55:43,318 [ZeusDataLoader(train)] Up to epoch 55: time=2693.98, energy=370969.47, cost=421208.29
2022-12-06 13:55:43,319 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:55:43,319 [ZeusDataLoader(train)] Expected next epoch: time=2741.09, energy=377657.34, cost=428673.79
2022-12-06 13:55:43,320 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0406, Accuracy: 0.0097
2022-12-06 13:55:43,509 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:55:43,510 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:55:43.513 [ZeusMonitor] Monitor started.
2022-12-06 18:55:43.513 [ZeusMonitor] Running indefinitely. 2022-12-06 18:55:43.513 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:55:43.513 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 13:56:27,258 [ZeusDataLoader(train)] train epoch 56 done: time=43.93 energy=6202.41
2022-12-06 13:56:27,262 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 1.1161
Training Epoch: 55 [2048/50176]	Loss: 1.1735
Training Epoch: 55 [3072/50176]	Loss: 1.1362
Training Epoch: 55 [4096/50176]	Loss: 1.1363
Training Epoch: 55 [5120/50176]	Loss: 1.0866
Training Epoch: 55 [6144/50176]	Loss: 1.1300
Training Epoch: 55 [7168/50176]	Loss: 1.1257
Training Epoch: 55 [8192/50176]	Loss: 1.1934
Training Epoch: 55 [9216/50176]	Loss: 1.1130
Training Epoch: 55 [10240/50176]	Loss: 1.1845
Training Epoch: 55 [11264/50176]	Loss: 1.1698
Training Epoch: 55 [12288/50176]	Loss: 1.0636
Training Epoch: 55 [13312/50176]	Loss: 1.1597
Training Epoch: 55 [14336/50176]	Loss: 1.1821
Training Epoch: 55 [15360/50176]	Loss: 1.1396
Training Epoch: 55 [16384/50176]	Loss: 1.1126
Training Epoch: 55 [17408/50176]	Loss: 1.2024
Training Epoch: 55 [18432/50176]	Loss: 1.2018
Training Epoch: 55 [19456/50176]	Loss: 1.1444
Training Epoch: 55 [20480/50176]	Loss: 1.1894
Training Epoch: 55 [21504/50176]	Loss: 1.1515
Training Epoch: 55 [22528/50176]	Loss: 1.1244
Training Epoch: 55 [23552/50176]	Loss: 1.2395
Training Epoch: 55 [24576/50176]	Loss: 1.1792
Training Epoch: 55 [25600/50176]	Loss: 1.2077
Training Epoch: 55 [26624/50176]	Loss: 1.1427
Training Epoch: 55 [27648/50176]	Loss: 1.1047
Training Epoch: 55 [28672/50176]	Loss: 1.1467
Training Epoch: 55 [29696/50176]	Loss: 1.2074
Training Epoch: 55 [30720/50176]	Loss: 1.1836
Training Epoch: 55 [31744/50176]	Loss: 1.1825
Training Epoch: 55 [32768/50176]	Loss: 1.2901
Training Epoch: 55 [33792/50176]	Loss: 1.1443
Training Epoch: 55 [34816/50176]	Loss: 1.1728
Training Epoch: 55 [35840/50176]	Loss: 1.2223
Training Epoch: 55 [36864/50176]	Loss: 1.2288
Training Epoch: 55 [37888/50176]	Loss: 1.2890
Training Epoch: 55 [38912/50176]	Loss: 1.1763
Training Epoch: 55 [39936/50176]	Loss: 1.2335
Training Epoch: 55 [40960/50176]	Loss: 1.1456
Training Epoch: 55 [41984/50176]	Loss: 1.1888
Training Epoch: 55 [43008/50176]	Loss: 1.2226
Training Epoch: 55 [44032/50176]	Loss: 1.1074
Training Epoch: 55 [45056/50176]	Loss: 1.2245
Training Epoch: 55 [46080/50176]	Loss: 1.1973
Training Epoch: 55 [47104/50176]	Loss: 1.1910
Training Epoch: 55 [48128/50176]	Loss: 1.2826
Training Epoch: 55 [49152/50176]	Loss: 1.2222
Training Epoch: 55 [50176/50176]	Loss: 1.2744
2022-12-06 18:56:31.018 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:56:31,073 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.80 energy=476.65
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Up to epoch 56: time=2741.72, energy=377648.53, cost=428724.59
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Expected next epoch: time=2788.82, energy=384336.40, cost=436190.09
2022-12-06 13:56:31,075 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0562, Accuracy: 0.0160
2022-12-06 13:56:31,314 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:56:31,314 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:56:31.330 [ZeusMonitor] Monitor started.
2022-12-06 18:56:31.330 [ZeusMonitor] Running indefinitely. 2022-12-06 18:56:31.330 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:56:31.330 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 13:57:15,447 [ZeusDataLoader(train)] train epoch 57 done: time=44.36 energy=6245.50
2022-12-06 13:57:15,450 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 1.1175
Training Epoch: 56 [2048/50176]	Loss: 1.1649
Training Epoch: 56 [3072/50176]	Loss: 1.0873
Training Epoch: 56 [4096/50176]	Loss: 1.0613
Training Epoch: 56 [5120/50176]	Loss: 1.0945
Training Epoch: 56 [6144/50176]	Loss: 1.0774
Training Epoch: 56 [7168/50176]	Loss: 1.0950
Training Epoch: 56 [8192/50176]	Loss: 1.0844
Training Epoch: 56 [9216/50176]	Loss: 1.1739
Training Epoch: 56 [10240/50176]	Loss: 1.0974
Training Epoch: 56 [11264/50176]	Loss: 1.0987
Training Epoch: 56 [12288/50176]	Loss: 1.0587
Training Epoch: 56 [13312/50176]	Loss: 1.1588
Training Epoch: 56 [14336/50176]	Loss: 1.1051
Training Epoch: 56 [15360/50176]	Loss: 1.1422
Training Epoch: 56 [16384/50176]	Loss: 1.0836
Training Epoch: 56 [17408/50176]	Loss: 1.0969
Training Epoch: 56 [18432/50176]	Loss: 1.1909
Training Epoch: 56 [19456/50176]	Loss: 1.1188
Training Epoch: 56 [20480/50176]	Loss: 1.1126
Training Epoch: 56 [21504/50176]	Loss: 1.1166
Training Epoch: 56 [22528/50176]	Loss: 1.1722
Training Epoch: 56 [23552/50176]	Loss: 1.1208
Training Epoch: 56 [24576/50176]	Loss: 1.1658
Training Epoch: 56 [25600/50176]	Loss: 1.0826
Training Epoch: 56 [26624/50176]	Loss: 1.1439
Training Epoch: 56 [27648/50176]	Loss: 1.0545
Training Epoch: 56 [28672/50176]	Loss: 1.1630
Training Epoch: 56 [29696/50176]	Loss: 1.0540
Training Epoch: 56 [30720/50176]	Loss: 1.2135
Training Epoch: 56 [31744/50176]	Loss: 1.1803
Training Epoch: 56 [32768/50176]	Loss: 1.1959
Training Epoch: 56 [33792/50176]	Loss: 1.1144
Training Epoch: 56 [34816/50176]	Loss: 1.1140
Training Epoch: 56 [35840/50176]	Loss: 1.1642
Training Epoch: 56 [36864/50176]	Loss: 1.0800
Training Epoch: 56 [37888/50176]	Loss: 1.2397
Training Epoch: 56 [38912/50176]	Loss: 1.1782
Training Epoch: 56 [39936/50176]	Loss: 1.1279
Training Epoch: 56 [40960/50176]	Loss: 1.1720
Training Epoch: 56 [41984/50176]	Loss: 1.1729
Training Epoch: 56 [43008/50176]	Loss: 1.1603
Training Epoch: 56 [44032/50176]	Loss: 1.1783
Training Epoch: 56 [45056/50176]	Loss: 1.1841
Training Epoch: 56 [46080/50176]	Loss: 1.1252
Training Epoch: 56 [47104/50176]	Loss: 1.1968
Training Epoch: 56 [48128/50176]	Loss: 1.1483
Training Epoch: 56 [49152/50176]	Loss: 1.2436
Training Epoch: 56 [50176/50176]	Loss: 1.1468
2022-12-06 18:57:19.209 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:57:19,239 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.78 energy=484.13
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Up to epoch 57: time=2789.86, energy=384378.15, cost=436302.09
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Expected next epoch: time=2836.97, energy=391066.02, cost=443767.59
2022-12-06 13:57:19,241 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0280, Accuracy: 0.0119
2022-12-06 13:57:19,425 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:57:19,426 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:57:19.428 [ZeusMonitor] Monitor started.
2022-12-06 18:57:19.428 [ZeusMonitor] Running indefinitely. 2022-12-06 18:57:19.428 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:57:19.428 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 13:58:03,604 [ZeusDataLoader(train)] train epoch 58 done: time=44.36 energy=6233.64
2022-12-06 13:58:03,607 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 1.1504
Training Epoch: 57 [2048/50176]	Loss: 1.0693
Training Epoch: 57 [3072/50176]	Loss: 1.1106
Training Epoch: 57 [4096/50176]	Loss: 1.0582
Training Epoch: 57 [5120/50176]	Loss: 1.1234
Training Epoch: 57 [6144/50176]	Loss: 1.1608
Training Epoch: 57 [7168/50176]	Loss: 1.1431
Training Epoch: 57 [8192/50176]	Loss: 1.0983
Training Epoch: 57 [9216/50176]	Loss: 1.0259
Training Epoch: 57 [10240/50176]	Loss: 1.0510
Training Epoch: 57 [11264/50176]	Loss: 1.1385
Training Epoch: 57 [12288/50176]	Loss: 1.0631
Training Epoch: 57 [13312/50176]	Loss: 1.0163
Training Epoch: 57 [14336/50176]	Loss: 1.2078
Training Epoch: 57 [15360/50176]	Loss: 1.0363
Training Epoch: 57 [16384/50176]	Loss: 1.0993
Training Epoch: 57 [17408/50176]	Loss: 1.1246
Training Epoch: 57 [18432/50176]	Loss: 1.1000
Training Epoch: 57 [19456/50176]	Loss: 1.0527
Training Epoch: 57 [20480/50176]	Loss: 1.0630
Training Epoch: 57 [21504/50176]	Loss: 1.1657
Training Epoch: 57 [22528/50176]	Loss: 1.0902
Training Epoch: 57 [23552/50176]	Loss: 1.1360
Training Epoch: 57 [24576/50176]	Loss: 1.0759
Training Epoch: 57 [25600/50176]	Loss: 1.0876
Training Epoch: 57 [26624/50176]	Loss: 1.1053
Training Epoch: 57 [27648/50176]	Loss: 1.1578
Training Epoch: 57 [28672/50176]	Loss: 1.1525
Training Epoch: 57 [29696/50176]	Loss: 1.2037
Training Epoch: 57 [30720/50176]	Loss: 1.0753
Training Epoch: 57 [31744/50176]	Loss: 1.0589
Training Epoch: 57 [32768/50176]	Loss: 1.1723
Training Epoch: 57 [33792/50176]	Loss: 1.1819
Training Epoch: 57 [34816/50176]	Loss: 1.2294
Training Epoch: 57 [35840/50176]	Loss: 1.1462
Training Epoch: 57 [36864/50176]	Loss: 1.1198
Training Epoch: 57 [37888/50176]	Loss: 1.1445
Training Epoch: 57 [38912/50176]	Loss: 1.1002
Training Epoch: 57 [39936/50176]	Loss: 1.1219
Training Epoch: 57 [40960/50176]	Loss: 1.1763
Training Epoch: 57 [41984/50176]	Loss: 1.1198
Training Epoch: 57 [43008/50176]	Loss: 1.1043
Training Epoch: 57 [44032/50176]	Loss: 1.1983
Training Epoch: 57 [45056/50176]	Loss: 1.2251
Training Epoch: 57 [46080/50176]	Loss: 1.1714
Training Epoch: 57 [47104/50176]	Loss: 1.1881
Training Epoch: 57 [48128/50176]	Loss: 1.1750
Training Epoch: 57 [49152/50176]	Loss: 1.2182
Training Epoch: 57 [50176/50176]	Loss: 1.2236
2022-12-06 18:58:07.318 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:58:07,336 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.72 energy=474.92
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Up to epoch 58: time=2837.94, energy=391086.71, cost=443863.02
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Expected next epoch: time=2885.04, energy=397774.59, cost=451328.52
2022-12-06 13:58:07,337 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0404, Accuracy: 0.0208
2022-12-06 13:58:07,574 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:58:07,575 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:58:07.585 [ZeusMonitor] Monitor started.
2022-12-06 18:58:07.585 [ZeusMonitor] Running indefinitely. 2022-12-06 18:58:07.585 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:58:07.585 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 13:58:51,842 [ZeusDataLoader(train)] train epoch 59 done: time=44.50 energy=6242.78
2022-12-06 13:58:51,846 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 1.0346
Training Epoch: 58 [2048/50176]	Loss: 1.0107
Training Epoch: 58 [3072/50176]	Loss: 1.0623
Training Epoch: 58 [4096/50176]	Loss: 1.0089
Training Epoch: 58 [5120/50176]	Loss: 1.0043
Training Epoch: 58 [6144/50176]	Loss: 1.0486
Training Epoch: 58 [7168/50176]	Loss: 1.0117
Training Epoch: 58 [8192/50176]	Loss: 1.0715
Training Epoch: 58 [9216/50176]	Loss: 1.1931
Training Epoch: 58 [10240/50176]	Loss: 1.0744
Training Epoch: 58 [11264/50176]	Loss: 1.0875
Training Epoch: 58 [12288/50176]	Loss: 1.1609
Training Epoch: 58 [13312/50176]	Loss: 1.0311
Training Epoch: 58 [14336/50176]	Loss: 1.0565
Training Epoch: 58 [15360/50176]	Loss: 0.9889
Training Epoch: 58 [16384/50176]	Loss: 1.0275
Training Epoch: 58 [17408/50176]	Loss: 1.1068
Training Epoch: 58 [18432/50176]	Loss: 1.0952
Training Epoch: 58 [19456/50176]	Loss: 1.0570
Training Epoch: 58 [20480/50176]	Loss: 1.0430
Training Epoch: 58 [21504/50176]	Loss: 1.1146
Training Epoch: 58 [22528/50176]	Loss: 1.1319
Training Epoch: 58 [23552/50176]	Loss: 1.1557
Training Epoch: 58 [24576/50176]	Loss: 1.0834
Training Epoch: 58 [25600/50176]	Loss: 1.1167
Training Epoch: 58 [26624/50176]	Loss: 1.1289
Training Epoch: 58 [27648/50176]	Loss: 1.1356
Training Epoch: 58 [28672/50176]	Loss: 1.0820
Training Epoch: 58 [29696/50176]	Loss: 1.1419
Training Epoch: 58 [30720/50176]	Loss: 1.1000
Training Epoch: 58 [31744/50176]	Loss: 1.1730
Training Epoch: 58 [32768/50176]	Loss: 1.1269
Training Epoch: 58 [33792/50176]	Loss: 1.1302
Training Epoch: 58 [34816/50176]	Loss: 1.0883
Training Epoch: 58 [35840/50176]	Loss: 1.0813
Training Epoch: 58 [36864/50176]	Loss: 1.1580
Training Epoch: 58 [37888/50176]	Loss: 1.1747
Training Epoch: 58 [38912/50176]	Loss: 1.1731
Training Epoch: 58 [39936/50176]	Loss: 1.1607
Training Epoch: 58 [40960/50176]	Loss: 1.1562
Training Epoch: 58 [41984/50176]	Loss: 1.1164
Training Epoch: 58 [43008/50176]	Loss: 1.2739
Training Epoch: 58 [44032/50176]	Loss: 1.1564
Training Epoch: 58 [45056/50176]	Loss: 1.1888
Training Epoch: 58 [46080/50176]	Loss: 1.1311
Training Epoch: 58 [47104/50176]	Loss: 1.1688
Training Epoch: 58 [48128/50176]	Loss: 1.1899
Training Epoch: 58 [49152/50176]	Loss: 1.1977
Training Epoch: 58 [50176/50176]	Loss: 1.1754
2022-12-06 18:58:55.575 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:58:55,595 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.74 energy=478.71
2022-12-06 13:58:55,595 [ZeusDataLoader(train)] Up to epoch 59: time=2886.18, energy=397808.21, cost=451444.64
2022-12-06 13:58:55,595 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:58:55,596 [ZeusDataLoader(train)] Expected next epoch: time=2933.28, energy=404496.08, cost=458910.13
2022-12-06 13:58:55,596 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0482, Accuracy: 0.0293
2022-12-06 13:58:55,825 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:58:55,826 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:58:55.828 [ZeusMonitor] Monitor started.
2022-12-06 18:58:55.828 [ZeusMonitor] Running indefinitely. 2022-12-06 18:58:55.828 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:58:55.828 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 13:59:39,580 [ZeusDataLoader(train)] train epoch 60 done: time=43.97 energy=6209.32
2022-12-06 13:59:39,583 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 1.0385
Training Epoch: 59 [2048/50176]	Loss: 1.1787
Training Epoch: 59 [3072/50176]	Loss: 1.0963
Training Epoch: 59 [4096/50176]	Loss: 1.0743
Training Epoch: 59 [5120/50176]	Loss: 0.9267
Training Epoch: 59 [6144/50176]	Loss: 1.1174
Training Epoch: 59 [7168/50176]	Loss: 1.1012
Training Epoch: 59 [8192/50176]	Loss: 1.0913
Training Epoch: 59 [9216/50176]	Loss: 1.0595
Training Epoch: 59 [10240/50176]	Loss: 1.1085
Training Epoch: 59 [11264/50176]	Loss: 1.0053
Training Epoch: 59 [12288/50176]	Loss: 1.0780
Training Epoch: 59 [13312/50176]	Loss: 1.0691
Training Epoch: 59 [14336/50176]	Loss: 1.0925
Training Epoch: 59 [15360/50176]	Loss: 1.0501
Training Epoch: 59 [16384/50176]	Loss: 1.0495
Training Epoch: 59 [17408/50176]	Loss: 1.0884
Training Epoch: 59 [18432/50176]	Loss: 1.0543
Training Epoch: 59 [19456/50176]	Loss: 1.0702
Training Epoch: 59 [20480/50176]	Loss: 1.1431
Training Epoch: 59 [21504/50176]	Loss: 1.1453
Training Epoch: 59 [22528/50176]	Loss: 1.1179
Training Epoch: 59 [23552/50176]	Loss: 1.1162
Training Epoch: 59 [24576/50176]	Loss: 1.0724
Training Epoch: 59 [25600/50176]	Loss: 1.1233
Training Epoch: 59 [26624/50176]	Loss: 1.0851
Training Epoch: 59 [27648/50176]	Loss: 1.0990
Training Epoch: 59 [28672/50176]	Loss: 1.1001
Training Epoch: 59 [29696/50176]	Loss: 1.1222
Training Epoch: 59 [30720/50176]	Loss: 1.1803
Training Epoch: 59 [31744/50176]	Loss: 1.0695
Training Epoch: 59 [32768/50176]	Loss: 1.0395
Training Epoch: 59 [33792/50176]	Loss: 1.1666
Training Epoch: 59 [34816/50176]	Loss: 1.1202
Training Epoch: 59 [35840/50176]	Loss: 1.2064
Training Epoch: 59 [36864/50176]	Loss: 1.2289
Training Epoch: 59 [37888/50176]	Loss: 1.2045
Training Epoch: 59 [38912/50176]	Loss: 1.1227
Training Epoch: 59 [39936/50176]	Loss: 1.1209
Training Epoch: 59 [40960/50176]	Loss: 1.1713
Training Epoch: 59 [41984/50176]	Loss: 1.1436
Training Epoch: 59 [43008/50176]	Loss: 1.1474
Training Epoch: 59 [44032/50176]	Loss: 1.1342
Training Epoch: 59 [45056/50176]	Loss: 1.1181
Training Epoch: 59 [46080/50176]	Loss: 1.1698
Training Epoch: 59 [47104/50176]	Loss: 1.1450
Training Epoch: 59 [48128/50176]	Loss: 1.1370
Training Epoch: 59 [49152/50176]	Loss: 1.1340
Training Epoch: 59 [50176/50176]	Loss: 1.1498
2022-12-06 18:59:43.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:59:43,388 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.80 energy=482.69
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Up to epoch 60: time=2933.95, energy=404500.22, cost=458970.64
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Expected next epoch: time=2981.05, energy=411188.10, cost=466436.14
2022-12-06 13:59:43,389 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0458, Accuracy: 0.0282
2022-12-06 13:59:43,630 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:59:43,631 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:59:43.632 [ZeusMonitor] Monitor started.
2022-12-06 18:59:43.633 [ZeusMonitor] Running indefinitely. 2022-12-06 18:59:43.633 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:59:43.633 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 14:00:27,396 [ZeusDataLoader(train)] train epoch 61 done: time=44.00 energy=6211.22
2022-12-06 14:00:27,401 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.9926
Training Epoch: 60 [2048/50176]	Loss: 1.0860
Training Epoch: 60 [3072/50176]	Loss: 1.0454
Training Epoch: 60 [4096/50176]	Loss: 0.9666
Training Epoch: 60 [5120/50176]	Loss: 1.1595
Training Epoch: 60 [6144/50176]	Loss: 1.0380
Training Epoch: 60 [7168/50176]	Loss: 1.0592
Training Epoch: 60 [8192/50176]	Loss: 1.0066
Training Epoch: 60 [9216/50176]	Loss: 1.1188
Training Epoch: 60 [10240/50176]	Loss: 1.0441
Training Epoch: 60 [11264/50176]	Loss: 1.0610
Training Epoch: 60 [12288/50176]	Loss: 1.1789
Training Epoch: 60 [13312/50176]	Loss: 1.1154
Training Epoch: 60 [14336/50176]	Loss: 1.0891
Training Epoch: 60 [15360/50176]	Loss: 1.0017
Training Epoch: 60 [16384/50176]	Loss: 1.0816
Training Epoch: 60 [17408/50176]	Loss: 1.0981
Training Epoch: 60 [18432/50176]	Loss: 1.0974
Training Epoch: 60 [19456/50176]	Loss: 1.0536
Training Epoch: 60 [20480/50176]	Loss: 1.0137
Training Epoch: 60 [21504/50176]	Loss: 1.0453
Training Epoch: 60 [22528/50176]	Loss: 1.0802
Training Epoch: 60 [23552/50176]	Loss: 1.0153
Training Epoch: 60 [24576/50176]	Loss: 1.1071
Training Epoch: 60 [25600/50176]	Loss: 1.2191
Training Epoch: 60 [26624/50176]	Loss: 1.0575
Training Epoch: 60 [27648/50176]	Loss: 1.0837
Training Epoch: 60 [28672/50176]	Loss: 1.0882
Training Epoch: 60 [29696/50176]	Loss: 1.0826
Training Epoch: 60 [30720/50176]	Loss: 1.0803
Training Epoch: 60 [31744/50176]	Loss: 1.1113
Training Epoch: 60 [32768/50176]	Loss: 1.0505
Training Epoch: 60 [33792/50176]	Loss: 1.1531
Training Epoch: 60 [34816/50176]	Loss: 1.0703
Training Epoch: 60 [35840/50176]	Loss: 1.0400
Training Epoch: 60 [36864/50176]	Loss: 1.1777
Training Epoch: 60 [37888/50176]	Loss: 1.1320
Training Epoch: 60 [38912/50176]	Loss: 1.1313
Training Epoch: 60 [39936/50176]	Loss: 1.0850
Training Epoch: 60 [40960/50176]	Loss: 1.0991
Training Epoch: 60 [41984/50176]	Loss: 1.1100
Training Epoch: 60 [43008/50176]	Loss: 1.1362
Training Epoch: 60 [44032/50176]	Loss: 1.1122
Training Epoch: 60 [45056/50176]	Loss: 1.0782
Training Epoch: 60 [46080/50176]	Loss: 1.1014
Training Epoch: 60 [47104/50176]	Loss: 1.0498
Training Epoch: 60 [48128/50176]	Loss: 1.1158
Training Epoch: 60 [49152/50176]	Loss: 1.0590
Training Epoch: 60 [50176/50176]	Loss: 1.1462
2022-12-06 19:00:31.141 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:00:31,156 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.75 energy=473.52
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Up to epoch 61: time=2981.70, energy=411184.96, cost=466490.82
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Expected next epoch: time=3028.80, energy=417872.84, cost=473956.31
2022-12-06 14:00:31,158 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0167, Accuracy: 0.0314
2022-12-06 14:00:31,349 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:00:31,349 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:00:31.351 [ZeusMonitor] Monitor started.
2022-12-06 19:00:31.351 [ZeusMonitor] Running indefinitely. 2022-12-06 19:00:31.351 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:00:31.351 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 14:01:15,316 [ZeusDataLoader(train)] train epoch 62 done: time=44.15 energy=6219.02
2022-12-06 14:01:15,320 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.9914
Training Epoch: 61 [2048/50176]	Loss: 0.9917
Training Epoch: 61 [3072/50176]	Loss: 0.9425
Training Epoch: 61 [4096/50176]	Loss: 1.0903
Training Epoch: 61 [5120/50176]	Loss: 1.0030
Training Epoch: 61 [6144/50176]	Loss: 1.1179
Training Epoch: 61 [7168/50176]	Loss: 1.1143
Training Epoch: 61 [8192/50176]	Loss: 0.9665
Training Epoch: 61 [9216/50176]	Loss: 1.0162
Training Epoch: 61 [10240/50176]	Loss: 0.9429
Training Epoch: 61 [11264/50176]	Loss: 1.0241
Training Epoch: 61 [12288/50176]	Loss: 1.0394
Training Epoch: 61 [13312/50176]	Loss: 1.1281
Training Epoch: 61 [14336/50176]	Loss: 1.1380
Training Epoch: 61 [15360/50176]	Loss: 0.9633
Training Epoch: 61 [16384/50176]	Loss: 1.0660
Training Epoch: 61 [17408/50176]	Loss: 1.0081
Training Epoch: 61 [18432/50176]	Loss: 1.0779
Training Epoch: 61 [19456/50176]	Loss: 0.9652
Training Epoch: 61 [20480/50176]	Loss: 1.0414
Training Epoch: 61 [21504/50176]	Loss: 1.0830
Training Epoch: 61 [22528/50176]	Loss: 1.1028
Training Epoch: 61 [23552/50176]	Loss: 0.9612
Training Epoch: 61 [24576/50176]	Loss: 1.0312
Training Epoch: 61 [25600/50176]	Loss: 1.1178
Training Epoch: 61 [26624/50176]	Loss: 1.1137
Training Epoch: 61 [27648/50176]	Loss: 1.0856
Training Epoch: 61 [28672/50176]	Loss: 1.0739
Training Epoch: 61 [29696/50176]	Loss: 1.0346
Training Epoch: 61 [30720/50176]	Loss: 1.0859
Training Epoch: 61 [31744/50176]	Loss: 1.0025
Training Epoch: 61 [32768/50176]	Loss: 1.0845
Training Epoch: 61 [33792/50176]	Loss: 1.2118
Training Epoch: 61 [34816/50176]	Loss: 1.0499
Training Epoch: 61 [35840/50176]	Loss: 1.0434
Training Epoch: 61 [36864/50176]	Loss: 1.0875
Training Epoch: 61 [37888/50176]	Loss: 1.1183
Training Epoch: 61 [38912/50176]	Loss: 1.1856
Training Epoch: 61 [39936/50176]	Loss: 1.0809
Training Epoch: 61 [40960/50176]	Loss: 1.1480
Training Epoch: 61 [41984/50176]	Loss: 1.1197
Training Epoch: 61 [43008/50176]	Loss: 1.1380
Training Epoch: 61 [44032/50176]	Loss: 1.1432
Training Epoch: 61 [45056/50176]	Loss: 1.1526
Training Epoch: 61 [46080/50176]	Loss: 1.1332
Training Epoch: 61 [47104/50176]	Loss: 1.1347
Training Epoch: 61 [48128/50176]	Loss: 1.0612
Training Epoch: 61 [49152/50176]	Loss: 1.2190
Training Epoch: 61 [50176/50176]	Loss: 1.0842
2022-12-06 19:01:19.079 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:01:19,112 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.78 energy=475.83
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Up to epoch 62: time=3029.63, energy=417879.82, cost=474032.53
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Expected next epoch: time=3076.73, energy=424567.69, cost=481498.03
2022-12-06 14:01:19,114 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0115, Accuracy: 0.0412
2022-12-06 14:01:19,309 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:01:19,310 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:01:19.313 [ZeusMonitor] Monitor started.
2022-12-06 19:01:19.313 [ZeusMonitor] Running indefinitely. 2022-12-06 19:01:19.313 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:01:19.313 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 14:02:03,352 [ZeusDataLoader(train)] train epoch 63 done: time=44.23 energy=6232.87
2022-12-06 14:02:03,355 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.9952
Training Epoch: 62 [2048/50176]	Loss: 0.9914
Training Epoch: 62 [3072/50176]	Loss: 0.9966
Training Epoch: 62 [4096/50176]	Loss: 1.0720
Training Epoch: 62 [5120/50176]	Loss: 1.0388
Training Epoch: 62 [6144/50176]	Loss: 0.9879
Training Epoch: 62 [7168/50176]	Loss: 1.0338
Training Epoch: 62 [8192/50176]	Loss: 1.1398
Training Epoch: 62 [9216/50176]	Loss: 0.9582
Training Epoch: 62 [10240/50176]	Loss: 0.9940
Training Epoch: 62 [11264/50176]	Loss: 1.0338
Training Epoch: 62 [12288/50176]	Loss: 0.9962
Training Epoch: 62 [13312/50176]	Loss: 1.0255
Training Epoch: 62 [14336/50176]	Loss: 1.0374
Training Epoch: 62 [15360/50176]	Loss: 1.0264
Training Epoch: 62 [16384/50176]	Loss: 1.0180
Training Epoch: 62 [17408/50176]	Loss: 1.0256
Training Epoch: 62 [18432/50176]	Loss: 1.1123
Training Epoch: 62 [19456/50176]	Loss: 1.0553
Training Epoch: 62 [20480/50176]	Loss: 1.1286
Training Epoch: 62 [21504/50176]	Loss: 1.0118
Training Epoch: 62 [22528/50176]	Loss: 1.1010
Training Epoch: 62 [23552/50176]	Loss: 1.0512
Training Epoch: 62 [24576/50176]	Loss: 1.1541
Training Epoch: 62 [25600/50176]	Loss: 0.9505
Training Epoch: 62 [26624/50176]	Loss: 0.9928
Training Epoch: 62 [27648/50176]	Loss: 1.1295
Training Epoch: 62 [28672/50176]	Loss: 1.0159
Training Epoch: 62 [29696/50176]	Loss: 1.0322
Training Epoch: 62 [30720/50176]	Loss: 1.0492
Training Epoch: 62 [31744/50176]	Loss: 1.1064
Training Epoch: 62 [32768/50176]	Loss: 1.1508
Training Epoch: 62 [33792/50176]	Loss: 1.0049
Training Epoch: 62 [34816/50176]	Loss: 1.0573
Training Epoch: 62 [35840/50176]	Loss: 1.0461
Training Epoch: 62 [36864/50176]	Loss: 1.1165
Training Epoch: 62 [37888/50176]	Loss: 1.0927
Training Epoch: 62 [38912/50176]	Loss: 1.0592
Training Epoch: 62 [39936/50176]	Loss: 1.0685
Training Epoch: 62 [40960/50176]	Loss: 1.1025
Training Epoch: 62 [41984/50176]	Loss: 1.0679
Training Epoch: 62 [43008/50176]	Loss: 1.1594
Training Epoch: 62 [44032/50176]	Loss: 1.0358
Training Epoch: 62 [45056/50176]	Loss: 1.1613
Training Epoch: 62 [46080/50176]	Loss: 1.0737
Training Epoch: 62 [47104/50176]	Loss: 1.1696
Training Epoch: 62 [48128/50176]	Loss: 1.1805
Training Epoch: 62 [49152/50176]	Loss: 1.1553
Training Epoch: 62 [50176/50176]	Loss: 1.1902
2022-12-06 19:02:07.133 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:02:07,169 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.81 energy=489.18
2022-12-06 14:02:07,169 [ZeusDataLoader(train)] Up to epoch 63: time=3077.67, energy=424601.86, cost=481596.69
2022-12-06 14:02:07,170 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:02:07,170 [ZeusDataLoader(train)] Expected next epoch: time=3124.77, energy=431289.74, cost=489062.19
2022-12-06 14:02:07,171 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0148, Accuracy: 0.0339
2022-12-06 14:02:07,407 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:02:07,407 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:02:07.409 [ZeusMonitor] Monitor started.
2022-12-06 19:02:07.409 [ZeusMonitor] Running indefinitely. 2022-12-06 19:02:07.409 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:02:07.409 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 14:02:51,630 [ZeusDataLoader(train)] train epoch 64 done: time=44.45 energy=6236.69
2022-12-06 14:02:51,634 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 1.0447
Training Epoch: 63 [2048/50176]	Loss: 1.0120
Training Epoch: 63 [3072/50176]	Loss: 1.0635
Training Epoch: 63 [4096/50176]	Loss: 1.0735
Training Epoch: 63 [5120/50176]	Loss: 1.0083
Training Epoch: 63 [6144/50176]	Loss: 0.9827
Training Epoch: 63 [7168/50176]	Loss: 1.0128
Training Epoch: 63 [8192/50176]	Loss: 1.0541
Training Epoch: 63 [9216/50176]	Loss: 0.9929
Training Epoch: 63 [10240/50176]	Loss: 1.0211
Training Epoch: 63 [11264/50176]	Loss: 1.0579
Training Epoch: 63 [12288/50176]	Loss: 1.0056
Training Epoch: 63 [13312/50176]	Loss: 0.9902
Training Epoch: 63 [14336/50176]	Loss: 1.1393
Training Epoch: 63 [15360/50176]	Loss: 1.0195
Training Epoch: 63 [16384/50176]	Loss: 1.0287
Training Epoch: 63 [17408/50176]	Loss: 0.9238
Training Epoch: 63 [18432/50176]	Loss: 1.0193
Training Epoch: 63 [19456/50176]	Loss: 1.0355
Training Epoch: 63 [20480/50176]	Loss: 1.0271
Training Epoch: 63 [21504/50176]	Loss: 1.1465
Training Epoch: 63 [22528/50176]	Loss: 1.0055
Training Epoch: 63 [23552/50176]	Loss: 1.0590
Training Epoch: 63 [24576/50176]	Loss: 0.9713
Training Epoch: 63 [25600/50176]	Loss: 1.0369
Training Epoch: 63 [26624/50176]	Loss: 1.0223
Training Epoch: 63 [27648/50176]	Loss: 1.0098
Training Epoch: 63 [28672/50176]	Loss: 1.0700
Training Epoch: 63 [29696/50176]	Loss: 1.0489
Training Epoch: 63 [30720/50176]	Loss: 1.0429
Training Epoch: 63 [31744/50176]	Loss: 1.0892
Training Epoch: 63 [32768/50176]	Loss: 1.1486
Training Epoch: 63 [33792/50176]	Loss: 1.0858
Training Epoch: 63 [34816/50176]	Loss: 0.9691
Training Epoch: 63 [35840/50176]	Loss: 0.9987
Training Epoch: 63 [36864/50176]	Loss: 1.0665
Training Epoch: 63 [37888/50176]	Loss: 1.0802
Training Epoch: 63 [38912/50176]	Loss: 1.0722
Training Epoch: 63 [39936/50176]	Loss: 1.0371
Training Epoch: 63 [40960/50176]	Loss: 1.0498
Training Epoch: 63 [41984/50176]	Loss: 1.0797
Training Epoch: 63 [43008/50176]	Loss: 1.1317
Training Epoch: 63 [44032/50176]	Loss: 1.0184
Training Epoch: 63 [45056/50176]	Loss: 0.9830
Training Epoch: 63 [46080/50176]	Loss: 1.0299
Training Epoch: 63 [47104/50176]	Loss: 1.0739
Training Epoch: 63 [48128/50176]	Loss: 1.0393
Training Epoch: 63 [49152/50176]	Loss: 1.0843
Training Epoch: 63 [50176/50176]	Loss: 1.0258
2022-12-06 19:02:55.342 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:02:55,380 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.74 energy=473.26
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Up to epoch 64: time=3125.85, energy=431311.81, cost=489168.21
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Expected next epoch: time=3172.96, energy=437999.69, cost=496633.71
2022-12-06 14:02:55,381 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0197, Accuracy: 0.0271
2022-12-06 14:02:55,613 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:02:55,614 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:02:55.632 [ZeusMonitor] Monitor started.
2022-12-06 19:02:55.632 [ZeusMonitor] Running indefinitely. 2022-12-06 19:02:55.632 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:02:55.632 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 14:03:39,832 [ZeusDataLoader(train)] train epoch 65 done: time=44.44 energy=6239.38
2022-12-06 14:03:39,835 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 1.0048
Training Epoch: 64 [2048/50176]	Loss: 0.9348
Training Epoch: 64 [3072/50176]	Loss: 0.9348
Training Epoch: 64 [4096/50176]	Loss: 0.9694
Training Epoch: 64 [5120/50176]	Loss: 1.0026
Training Epoch: 64 [6144/50176]	Loss: 0.9543
Training Epoch: 64 [7168/50176]	Loss: 1.0299
Training Epoch: 64 [8192/50176]	Loss: 0.9063
Training Epoch: 64 [9216/50176]	Loss: 0.9722
Training Epoch: 64 [10240/50176]	Loss: 1.0051
Training Epoch: 64 [11264/50176]	Loss: 0.9458
Training Epoch: 64 [12288/50176]	Loss: 0.9993
Training Epoch: 64 [13312/50176]	Loss: 1.0037
Training Epoch: 64 [14336/50176]	Loss: 0.9843
Training Epoch: 64 [15360/50176]	Loss: 0.9568
Training Epoch: 64 [16384/50176]	Loss: 0.9605
Training Epoch: 64 [17408/50176]	Loss: 0.9465
Training Epoch: 64 [18432/50176]	Loss: 0.9851
Training Epoch: 64 [19456/50176]	Loss: 1.0611
Training Epoch: 64 [20480/50176]	Loss: 1.0299
Training Epoch: 64 [21504/50176]	Loss: 0.9944
Training Epoch: 64 [22528/50176]	Loss: 1.0370
Training Epoch: 64 [23552/50176]	Loss: 1.0890
Training Epoch: 64 [24576/50176]	Loss: 0.9420
Training Epoch: 64 [25600/50176]	Loss: 0.9657
Training Epoch: 64 [26624/50176]	Loss: 1.0208
Training Epoch: 64 [27648/50176]	Loss: 1.0369
Training Epoch: 64 [28672/50176]	Loss: 1.0283
Training Epoch: 64 [29696/50176]	Loss: 1.0247
Training Epoch: 64 [30720/50176]	Loss: 1.0846
Training Epoch: 64 [31744/50176]	Loss: 0.9501
Training Epoch: 64 [32768/50176]	Loss: 1.0794
Training Epoch: 64 [33792/50176]	Loss: 1.1592
Training Epoch: 64 [34816/50176]	Loss: 1.0090
Training Epoch: 64 [35840/50176]	Loss: 1.0515
Training Epoch: 64 [36864/50176]	Loss: 1.0879
Training Epoch: 64 [37888/50176]	Loss: 1.0777
Training Epoch: 64 [38912/50176]	Loss: 1.0715
Training Epoch: 64 [39936/50176]	Loss: 0.9994
Training Epoch: 64 [40960/50176]	Loss: 1.0427
Training Epoch: 64 [41984/50176]	Loss: 1.0185
Training Epoch: 64 [43008/50176]	Loss: 1.0442
Training Epoch: 64 [44032/50176]	Loss: 1.0530
Training Epoch: 64 [45056/50176]	Loss: 1.1019
Training Epoch: 64 [46080/50176]	Loss: 1.1289
Training Epoch: 64 [47104/50176]	Loss: 1.0460
Training Epoch: 64 [48128/50176]	Loss: 1.0262
Training Epoch: 64 [49152/50176]	Loss: 1.0720
Training Epoch: 64 [50176/50176]	Loss: 1.0727
2022-12-06 19:03:43.572 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:03:43,598 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.75 energy=472.29
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Up to epoch 65: time=3174.05, energy=438023.48, cost=496741.31
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Expected next epoch: time=3221.16, energy=444711.36, cost=504206.80
2022-12-06 14:03:43,599 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0232, Accuracy: 0.0222
2022-12-06 14:03:43,845 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:03:43,846 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:03:43.848 [ZeusMonitor] Monitor started.
2022-12-06 19:03:43.848 [ZeusMonitor] Running indefinitely. 2022-12-06 19:03:43.848 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:03:43.848 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 14:04:28,312 [ZeusDataLoader(train)] train epoch 66 done: time=44.71 energy=6262.44
2022-12-06 14:04:28,315 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.9303
Training Epoch: 65 [2048/50176]	Loss: 0.8908
Training Epoch: 65 [3072/50176]	Loss: 0.9718
Training Epoch: 65 [4096/50176]	Loss: 0.9082
Training Epoch: 65 [5120/50176]	Loss: 0.9742
Training Epoch: 65 [6144/50176]	Loss: 1.0175
Training Epoch: 65 [7168/50176]	Loss: 0.9209
Training Epoch: 65 [8192/50176]	Loss: 0.9310
Training Epoch: 65 [9216/50176]	Loss: 0.9363
Training Epoch: 65 [10240/50176]	Loss: 1.0333
Training Epoch: 65 [11264/50176]	Loss: 0.9918
Training Epoch: 65 [12288/50176]	Loss: 0.9453
Training Epoch: 65 [13312/50176]	Loss: 0.9875
Training Epoch: 65 [14336/50176]	Loss: 0.9625
Training Epoch: 65 [15360/50176]	Loss: 0.9581
Training Epoch: 65 [16384/50176]	Loss: 1.0058
Training Epoch: 65 [17408/50176]	Loss: 0.9097
Training Epoch: 65 [18432/50176]	Loss: 1.0570
Training Epoch: 65 [19456/50176]	Loss: 0.9844
Training Epoch: 65 [20480/50176]	Loss: 0.9666
Training Epoch: 65 [21504/50176]	Loss: 1.0511
Training Epoch: 65 [22528/50176]	Loss: 1.0171
Training Epoch: 65 [23552/50176]	Loss: 1.0861
Training Epoch: 65 [24576/50176]	Loss: 0.9204
Training Epoch: 65 [25600/50176]	Loss: 0.9860
Training Epoch: 65 [26624/50176]	Loss: 1.0488
Training Epoch: 65 [27648/50176]	Loss: 1.0494
Training Epoch: 65 [28672/50176]	Loss: 0.9193
Training Epoch: 65 [29696/50176]	Loss: 1.0188
Training Epoch: 65 [30720/50176]	Loss: 1.0301
Training Epoch: 65 [31744/50176]	Loss: 1.0130
Training Epoch: 65 [32768/50176]	Loss: 0.9652
Training Epoch: 65 [33792/50176]	Loss: 1.0358
Training Epoch: 65 [34816/50176]	Loss: 1.0560
Training Epoch: 65 [35840/50176]	Loss: 0.9818
Training Epoch: 65 [36864/50176]	Loss: 1.0525
Training Epoch: 65 [37888/50176]	Loss: 0.9576
Training Epoch: 65 [38912/50176]	Loss: 1.0495
Training Epoch: 65 [39936/50176]	Loss: 1.0239
Training Epoch: 65 [40960/50176]	Loss: 1.0587
Training Epoch: 65 [41984/50176]	Loss: 1.0698
Training Epoch: 65 [43008/50176]	Loss: 1.0394
Training Epoch: 65 [44032/50176]	Loss: 1.0417
Training Epoch: 65 [45056/50176]	Loss: 1.0814
Training Epoch: 65 [46080/50176]	Loss: 1.0558
Training Epoch: 65 [47104/50176]	Loss: 1.0453
Training Epoch: 65 [48128/50176]	Loss: 1.0973
Training Epoch: 65 [49152/50176]	Loss: 1.1397
Training Epoch: 65 [50176/50176]	Loss: 1.1339
2022-12-06 19:04:32.071 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:04:32,114 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.79 energy=482.34
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Up to epoch 66: time=3222.55, energy=444768.26, cost=504357.11
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Expected next epoch: time=3269.65, energy=451456.14, cost=511822.60
2022-12-06 14:04:32,116 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0136, Accuracy: 0.0614
2022-12-06 14:04:32,364 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:04:32,364 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:04:32.366 [ZeusMonitor] Monitor started.
2022-12-06 19:04:32.366 [ZeusMonitor] Running indefinitely. 2022-12-06 19:04:32.366 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:04:32.366 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 14:05:16,974 [ZeusDataLoader(train)] train epoch 67 done: time=44.85 energy=6271.98
2022-12-06 14:05:16,978 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.9098
Training Epoch: 66 [2048/50176]	Loss: 0.9574
Training Epoch: 66 [3072/50176]	Loss: 0.9156
Training Epoch: 66 [4096/50176]	Loss: 1.0043
Training Epoch: 66 [5120/50176]	Loss: 1.0769
Training Epoch: 66 [6144/50176]	Loss: 0.8489
Training Epoch: 66 [7168/50176]	Loss: 1.0042
Training Epoch: 66 [8192/50176]	Loss: 0.9955
Training Epoch: 66 [9216/50176]	Loss: 0.8813
Training Epoch: 66 [10240/50176]	Loss: 0.9815
Training Epoch: 66 [11264/50176]	Loss: 1.0227
Training Epoch: 66 [12288/50176]	Loss: 0.9894
Training Epoch: 66 [13312/50176]	Loss: 0.9377
Training Epoch: 66 [14336/50176]	Loss: 0.9456
Training Epoch: 66 [15360/50176]	Loss: 0.8771
Training Epoch: 66 [16384/50176]	Loss: 1.0656
Training Epoch: 66 [17408/50176]	Loss: 0.9481
Training Epoch: 66 [18432/50176]	Loss: 0.9618
Training Epoch: 66 [19456/50176]	Loss: 0.9863
Training Epoch: 66 [20480/50176]	Loss: 0.9548
Training Epoch: 66 [21504/50176]	Loss: 0.9740
Training Epoch: 66 [22528/50176]	Loss: 0.9232
Training Epoch: 66 [23552/50176]	Loss: 0.9556
Training Epoch: 66 [24576/50176]	Loss: 0.9889
Training Epoch: 66 [25600/50176]	Loss: 1.1094
Training Epoch: 66 [26624/50176]	Loss: 1.0133
Training Epoch: 66 [27648/50176]	Loss: 1.0916
Training Epoch: 66 [28672/50176]	Loss: 1.0939
Training Epoch: 66 [29696/50176]	Loss: 0.9967
Training Epoch: 66 [30720/50176]	Loss: 1.0592
Training Epoch: 66 [31744/50176]	Loss: 0.9358
Training Epoch: 66 [32768/50176]	Loss: 1.0458
Training Epoch: 66 [33792/50176]	Loss: 1.0111
Training Epoch: 66 [34816/50176]	Loss: 1.0412
Training Epoch: 66 [35840/50176]	Loss: 1.0219
Training Epoch: 66 [36864/50176]	Loss: 1.0239
Training Epoch: 66 [37888/50176]	Loss: 1.0330
Training Epoch: 66 [38912/50176]	Loss: 0.9884
Training Epoch: 66 [39936/50176]	Loss: 1.0376
Training Epoch: 66 [40960/50176]	Loss: 1.0464
Training Epoch: 66 [41984/50176]	Loss: 0.9882
Training Epoch: 66 [43008/50176]	Loss: 1.0646
Training Epoch: 66 [44032/50176]	Loss: 1.0204
Training Epoch: 66 [45056/50176]	Loss: 0.9939
Training Epoch: 66 [46080/50176]	Loss: 1.0586
Training Epoch: 66 [47104/50176]	Loss: 1.0554
Training Epoch: 66 [48128/50176]	Loss: 1.0484
Training Epoch: 66 [49152/50176]	Loss: 0.9987
Training Epoch: 66 [50176/50176]	Loss: 1.0816
2022-12-06 19:05:20.728 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:05:20,762 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.78 energy=474.03
2022-12-06 14:05:20,762 [ZeusDataLoader(train)] Up to epoch 67: time=3271.18, energy=451514.27, cost=511984.99
2022-12-06 14:05:20,763 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:05:20,763 [ZeusDataLoader(train)] Expected next epoch: time=3318.28, energy=458202.14, cost=519450.48
2022-12-06 14:05:20,764 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0218, Accuracy: 0.0258
2022-12-06 14:05:21,001 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:05:21,002 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:05:21.003 [ZeusMonitor] Monitor started.
2022-12-06 19:05:21.004 [ZeusMonitor] Running indefinitely. 2022-12-06 19:05:21.004 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:05:21.004 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 14:06:05,365 [ZeusDataLoader(train)] train epoch 68 done: time=44.59 energy=6260.79
2022-12-06 14:06:05,368 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.9295
Training Epoch: 67 [2048/50176]	Loss: 0.9807
Training Epoch: 67 [3072/50176]	Loss: 0.9563
Training Epoch: 67 [4096/50176]	Loss: 0.9693
Training Epoch: 67 [5120/50176]	Loss: 0.9767
Training Epoch: 67 [6144/50176]	Loss: 0.9830
Training Epoch: 67 [7168/50176]	Loss: 0.9440
Training Epoch: 67 [8192/50176]	Loss: 0.9700
Training Epoch: 67 [9216/50176]	Loss: 0.9499
Training Epoch: 67 [10240/50176]	Loss: 0.9532
Training Epoch: 67 [11264/50176]	Loss: 0.9435
Training Epoch: 67 [12288/50176]	Loss: 0.9016
Training Epoch: 67 [13312/50176]	Loss: 0.9989
Training Epoch: 67 [14336/50176]	Loss: 0.9037
Training Epoch: 67 [15360/50176]	Loss: 0.8840
Training Epoch: 67 [16384/50176]	Loss: 0.9797
Training Epoch: 67 [17408/50176]	Loss: 0.9356
Training Epoch: 67 [18432/50176]	Loss: 1.1034
Training Epoch: 67 [19456/50176]	Loss: 1.0201
Training Epoch: 67 [20480/50176]	Loss: 0.9876
Training Epoch: 67 [21504/50176]	Loss: 0.9921
Training Epoch: 67 [22528/50176]	Loss: 0.9795
Training Epoch: 67 [23552/50176]	Loss: 0.9361
Training Epoch: 67 [24576/50176]	Loss: 0.9627
Training Epoch: 67 [25600/50176]	Loss: 1.0250
Training Epoch: 67 [26624/50176]	Loss: 0.9895
Training Epoch: 67 [27648/50176]	Loss: 0.9788
Training Epoch: 67 [28672/50176]	Loss: 1.0111
Training Epoch: 67 [29696/50176]	Loss: 0.9951
Training Epoch: 67 [30720/50176]	Loss: 1.0109
Training Epoch: 67 [31744/50176]	Loss: 1.0245
Training Epoch: 67 [32768/50176]	Loss: 0.9451
Training Epoch: 67 [33792/50176]	Loss: 0.9769
Training Epoch: 67 [34816/50176]	Loss: 0.9843
Training Epoch: 67 [35840/50176]	Loss: 0.9946
Training Epoch: 67 [36864/50176]	Loss: 0.9508
Training Epoch: 67 [37888/50176]	Loss: 1.0413
Training Epoch: 67 [38912/50176]	Loss: 1.0058
Training Epoch: 67 [39936/50176]	Loss: 1.0456
Training Epoch: 67 [40960/50176]	Loss: 1.0704
Training Epoch: 67 [41984/50176]	Loss: 0.9679
Training Epoch: 67 [43008/50176]	Loss: 1.0199
Training Epoch: 67 [44032/50176]	Loss: 1.0289
Training Epoch: 67 [45056/50176]	Loss: 1.0940
Training Epoch: 67 [46080/50176]	Loss: 1.0706
Training Epoch: 67 [47104/50176]	Loss: 0.9919
Training Epoch: 67 [48128/50176]	Loss: 0.9812
Training Epoch: 67 [49152/50176]	Loss: 1.0231
Training Epoch: 67 [50176/50176]	Loss: 0.9545
2022-12-06 19:06:09.036 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:06:09,048 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.67 energy=461.69
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Up to epoch 68: time=3319.44, energy=458236.74, cost=519569.40
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Expected next epoch: time=3366.54, energy=464924.62, cost=527034.90
2022-12-06 14:06:09,049 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0717, Accuracy: 0.0158
2022-12-06 14:06:09,241 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:06:09,242 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:06:09.245 [ZeusMonitor] Monitor started.
2022-12-06 19:06:09.245 [ZeusMonitor] Running indefinitely. 2022-12-06 19:06:09.245 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:06:09.245 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 14:06:53,530 [ZeusDataLoader(train)] train epoch 69 done: time=44.47 energy=6255.08
2022-12-06 14:06:53,533 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.8941
Training Epoch: 68 [2048/50176]	Loss: 0.8841
Training Epoch: 68 [3072/50176]	Loss: 0.9077
Training Epoch: 68 [4096/50176]	Loss: 0.8932
Training Epoch: 68 [5120/50176]	Loss: 0.9385
Training Epoch: 68 [6144/50176]	Loss: 0.9754
Training Epoch: 68 [7168/50176]	Loss: 0.9930
Training Epoch: 68 [8192/50176]	Loss: 0.9432
Training Epoch: 68 [9216/50176]	Loss: 0.9593
Training Epoch: 68 [10240/50176]	Loss: 0.8456
Training Epoch: 68 [11264/50176]	Loss: 0.9112
Training Epoch: 68 [12288/50176]	Loss: 0.9865
Training Epoch: 68 [13312/50176]	Loss: 1.0024
Training Epoch: 68 [14336/50176]	Loss: 0.9287
Training Epoch: 68 [15360/50176]	Loss: 0.9112
Training Epoch: 68 [16384/50176]	Loss: 1.0367
Training Epoch: 68 [17408/50176]	Loss: 0.9498
Training Epoch: 68 [18432/50176]	Loss: 0.9255
Training Epoch: 68 [19456/50176]	Loss: 0.8853
Training Epoch: 68 [20480/50176]	Loss: 0.9516
Training Epoch: 68 [21504/50176]	Loss: 0.9557
Training Epoch: 68 [22528/50176]	Loss: 0.9471
Training Epoch: 68 [23552/50176]	Loss: 0.8478
Training Epoch: 68 [24576/50176]	Loss: 0.9772
Training Epoch: 68 [25600/50176]	Loss: 0.9151
Training Epoch: 68 [26624/50176]	Loss: 0.9491
Training Epoch: 68 [27648/50176]	Loss: 0.9272
Training Epoch: 68 [28672/50176]	Loss: 0.9974
Training Epoch: 68 [29696/50176]	Loss: 1.0693
Training Epoch: 68 [30720/50176]	Loss: 1.0131
Training Epoch: 68 [31744/50176]	Loss: 0.9581
Training Epoch: 68 [32768/50176]	Loss: 0.9901
Training Epoch: 68 [33792/50176]	Loss: 0.9451
Training Epoch: 68 [34816/50176]	Loss: 0.9873
Training Epoch: 68 [35840/50176]	Loss: 1.0187
Training Epoch: 68 [36864/50176]	Loss: 0.9375
Training Epoch: 68 [37888/50176]	Loss: 0.9583
Training Epoch: 68 [38912/50176]	Loss: 0.9801
Training Epoch: 68 [39936/50176]	Loss: 1.0330
Training Epoch: 68 [40960/50176]	Loss: 1.0123
Training Epoch: 68 [41984/50176]	Loss: 1.0120
Training Epoch: 68 [43008/50176]	Loss: 1.0735
Training Epoch: 68 [44032/50176]	Loss: 1.0115
Training Epoch: 68 [45056/50176]	Loss: 1.0136
Training Epoch: 68 [46080/50176]	Loss: 0.9810
Training Epoch: 68 [47104/50176]	Loss: 0.9354
Training Epoch: 68 [48128/50176]	Loss: 1.0041
Training Epoch: 68 [49152/50176]	Loss: 1.0281
Training Epoch: 68 [50176/50176]	Loss: 0.9714
2022-12-06 19:06:57.274 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:06:57,293 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.75 energy=475.26
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Up to epoch 69: time=3367.66, energy=464967.08, cost=527154.19
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Expected next epoch: time=3414.77, energy=471654.96, cost=534619.69
2022-12-06 14:06:57,294 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0175, Accuracy: 0.0446
2022-12-06 14:06:57,534 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:06:57,535 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:06:57.549 [ZeusMonitor] Monitor started.
2022-12-06 19:06:57.549 [ZeusMonitor] Running indefinitely. 2022-12-06 19:06:57.549 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:06:57.549 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 14:07:41,780 [ZeusDataLoader(train)] train epoch 70 done: time=44.48 energy=6237.52
2022-12-06 14:07:41,783 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.8959
Training Epoch: 69 [2048/50176]	Loss: 0.9224
Training Epoch: 69 [3072/50176]	Loss: 0.9015
Training Epoch: 69 [4096/50176]	Loss: 0.9489
Training Epoch: 69 [5120/50176]	Loss: 0.9359
Training Epoch: 69 [6144/50176]	Loss: 0.9326
Training Epoch: 69 [7168/50176]	Loss: 0.8679
Training Epoch: 69 [8192/50176]	Loss: 0.9100
Training Epoch: 69 [9216/50176]	Loss: 0.9293
Training Epoch: 69 [10240/50176]	Loss: 0.8673
Training Epoch: 69 [11264/50176]	Loss: 0.8760
Training Epoch: 69 [12288/50176]	Loss: 0.8755
Training Epoch: 69 [13312/50176]	Loss: 0.8462
Training Epoch: 69 [14336/50176]	Loss: 0.8583
Training Epoch: 69 [15360/50176]	Loss: 0.9318
Training Epoch: 69 [16384/50176]	Loss: 0.8667
Training Epoch: 69 [17408/50176]	Loss: 0.9524
Training Epoch: 69 [18432/50176]	Loss: 0.8225
Training Epoch: 69 [19456/50176]	Loss: 0.9428
Training Epoch: 69 [20480/50176]	Loss: 0.8840
Training Epoch: 69 [21504/50176]	Loss: 0.8733
Training Epoch: 69 [22528/50176]	Loss: 0.9187
Training Epoch: 69 [23552/50176]	Loss: 0.8811
Training Epoch: 69 [24576/50176]	Loss: 0.8140
Training Epoch: 69 [25600/50176]	Loss: 0.9550
Training Epoch: 69 [26624/50176]	Loss: 0.8681
Training Epoch: 69 [27648/50176]	Loss: 0.9458
Training Epoch: 69 [28672/50176]	Loss: 0.8613
Training Epoch: 69 [29696/50176]	Loss: 0.9819
Training Epoch: 69 [30720/50176]	Loss: 0.9543
Training Epoch: 69 [31744/50176]	Loss: 1.0714
Training Epoch: 69 [32768/50176]	Loss: 0.9767
Training Epoch: 69 [33792/50176]	Loss: 1.0782
Training Epoch: 69 [34816/50176]	Loss: 0.9357
Training Epoch: 69 [35840/50176]	Loss: 0.9663
Training Epoch: 69 [36864/50176]	Loss: 1.0093
Training Epoch: 69 [37888/50176]	Loss: 0.9484
Training Epoch: 69 [38912/50176]	Loss: 0.9850
Training Epoch: 69 [39936/50176]	Loss: 1.0630
Training Epoch: 69 [40960/50176]	Loss: 0.9538
Training Epoch: 69 [41984/50176]	Loss: 0.9901
Training Epoch: 69 [43008/50176]	Loss: 0.9804
Training Epoch: 69 [44032/50176]	Loss: 0.9876
Training Epoch: 69 [45056/50176]	Loss: 1.0683
Training Epoch: 69 [46080/50176]	Loss: 1.1024
Training Epoch: 69 [47104/50176]	Loss: 1.0133
Training Epoch: 69 [48128/50176]	Loss: 1.0555
Training Epoch: 69 [49152/50176]	Loss: 0.9551
Training Epoch: 69 [50176/50176]	Loss: 1.0701
2022-12-06 19:07:45.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:07:45,583 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.79 energy=485.62
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Up to epoch 70: time=3415.93, energy=471690.22, cost=534739.35
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Expected next epoch: time=3463.04, energy=478378.09, cost=542204.85
2022-12-06 14:07:45,585 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0546, Accuracy: 0.0135
2022-12-06 14:07:45,778 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:07:45,779 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:07:45.782 [ZeusMonitor] Monitor started.
2022-12-06 19:07:45.783 [ZeusMonitor] Running indefinitely. 2022-12-06 19:07:45.783 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:07:45.783 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 14:08:30,088 [ZeusDataLoader(train)] train epoch 71 done: time=44.50 energy=6254.25
2022-12-06 14:08:30,092 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.9198
Training Epoch: 70 [2048/50176]	Loss: 0.9216
Training Epoch: 70 [3072/50176]	Loss: 0.8660
Training Epoch: 70 [4096/50176]	Loss: 0.8421
Training Epoch: 70 [5120/50176]	Loss: 1.0015
Training Epoch: 70 [6144/50176]	Loss: 0.8967
Training Epoch: 70 [7168/50176]	Loss: 0.9414
Training Epoch: 70 [8192/50176]	Loss: 0.8732
Training Epoch: 70 [9216/50176]	Loss: 0.8931
Training Epoch: 70 [10240/50176]	Loss: 0.9586
Training Epoch: 70 [11264/50176]	Loss: 0.8443
Training Epoch: 70 [12288/50176]	Loss: 0.8638
Training Epoch: 70 [13312/50176]	Loss: 0.9572
Training Epoch: 70 [14336/50176]	Loss: 0.8954
Training Epoch: 70 [15360/50176]	Loss: 0.8570
Training Epoch: 70 [16384/50176]	Loss: 0.9425
Training Epoch: 70 [17408/50176]	Loss: 0.8954
Training Epoch: 70 [18432/50176]	Loss: 0.9127
Training Epoch: 70 [19456/50176]	Loss: 0.9452
Training Epoch: 70 [20480/50176]	Loss: 0.8435
Training Epoch: 70 [21504/50176]	Loss: 0.9355
Training Epoch: 70 [22528/50176]	Loss: 1.0213
Training Epoch: 70 [23552/50176]	Loss: 0.9408
Training Epoch: 70 [24576/50176]	Loss: 0.8873
Training Epoch: 70 [25600/50176]	Loss: 0.8886
Training Epoch: 70 [26624/50176]	Loss: 0.9075
Training Epoch: 70 [27648/50176]	Loss: 0.9407
Training Epoch: 70 [28672/50176]	Loss: 0.9603
Training Epoch: 70 [29696/50176]	Loss: 0.8803
Training Epoch: 70 [30720/50176]	Loss: 0.9621
Training Epoch: 70 [31744/50176]	Loss: 0.9352
Training Epoch: 70 [32768/50176]	Loss: 0.9611
Training Epoch: 70 [33792/50176]	Loss: 0.9492
Training Epoch: 70 [34816/50176]	Loss: 0.8881
Training Epoch: 70 [35840/50176]	Loss: 0.9077
Training Epoch: 70 [36864/50176]	Loss: 0.9589
Training Epoch: 70 [37888/50176]	Loss: 0.9284
Training Epoch: 70 [38912/50176]	Loss: 1.0150
Training Epoch: 70 [39936/50176]	Loss: 1.1335
Training Epoch: 70 [40960/50176]	Loss: 0.9776
Training Epoch: 70 [41984/50176]	Loss: 1.0019
Training Epoch: 70 [43008/50176]	Loss: 0.9947
Training Epoch: 70 [44032/50176]	Loss: 0.9733
Training Epoch: 70 [45056/50176]	Loss: 0.9930
Training Epoch: 70 [46080/50176]	Loss: 0.9987
Training Epoch: 70 [47104/50176]	Loss: 0.9734
Training Epoch: 70 [48128/50176]	Loss: 0.9583
Training Epoch: 70 [49152/50176]	Loss: 0.9414
Training Epoch: 70 [50176/50176]	Loss: 0.9365
2022-12-06 19:08:33.879 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:08:33,895 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.79 energy=480.46
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Up to epoch 71: time=3464.22, energy=478424.92, cost=542332.08
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Expected next epoch: time=3511.33, energy=485112.80, cost=549797.58
2022-12-06 14:08:33,896 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0195, Accuracy: 0.0582
2022-12-06 14:08:34,133 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:08:34,133 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:08:34.135 [ZeusMonitor] Monitor started.
2022-12-06 19:08:34.135 [ZeusMonitor] Running indefinitely. 2022-12-06 19:08:34.135 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:08:34.135 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 14:09:18,643 [ZeusDataLoader(train)] train epoch 72 done: time=44.74 energy=6265.62
2022-12-06 14:09:18,646 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.8752
Training Epoch: 71 [2048/50176]	Loss: 0.9661
Training Epoch: 71 [3072/50176]	Loss: 0.9033
Training Epoch: 71 [4096/50176]	Loss: 0.9200
Training Epoch: 71 [5120/50176]	Loss: 0.8866
Training Epoch: 71 [6144/50176]	Loss: 0.8742
Training Epoch: 71 [7168/50176]	Loss: 0.9479
Training Epoch: 71 [8192/50176]	Loss: 0.8926
Training Epoch: 71 [9216/50176]	Loss: 0.8475
Training Epoch: 71 [10240/50176]	Loss: 0.8844
Training Epoch: 71 [11264/50176]	Loss: 0.8259
Training Epoch: 71 [12288/50176]	Loss: 0.8445
Training Epoch: 71 [13312/50176]	Loss: 0.9258
Training Epoch: 71 [14336/50176]	Loss: 0.8851
Training Epoch: 71 [15360/50176]	Loss: 0.8821
Training Epoch: 71 [16384/50176]	Loss: 0.9544
Training Epoch: 71 [17408/50176]	Loss: 0.9767
Training Epoch: 71 [18432/50176]	Loss: 0.8649
Training Epoch: 71 [19456/50176]	Loss: 0.8818
Training Epoch: 71 [20480/50176]	Loss: 0.9308
Training Epoch: 71 [21504/50176]	Loss: 0.9489
Training Epoch: 71 [22528/50176]	Loss: 0.9038
Training Epoch: 71 [23552/50176]	Loss: 0.8886
Training Epoch: 71 [24576/50176]	Loss: 0.9181
Training Epoch: 71 [25600/50176]	Loss: 0.9031
Training Epoch: 71 [26624/50176]	Loss: 0.9711
Training Epoch: 71 [27648/50176]	Loss: 0.8847
Training Epoch: 71 [28672/50176]	Loss: 0.9159
Training Epoch: 71 [29696/50176]	Loss: 0.9200
Training Epoch: 71 [30720/50176]	Loss: 0.9151
Training Epoch: 71 [31744/50176]	Loss: 0.9350
Training Epoch: 71 [32768/50176]	Loss: 1.0235
Training Epoch: 71 [33792/50176]	Loss: 0.9585
Training Epoch: 71 [34816/50176]	Loss: 1.0059
Training Epoch: 71 [35840/50176]	Loss: 0.9401
Training Epoch: 71 [36864/50176]	Loss: 0.9615
Training Epoch: 71 [37888/50176]	Loss: 0.9112
Training Epoch: 71 [38912/50176]	Loss: 0.9707
Training Epoch: 71 [39936/50176]	Loss: 0.8978
Training Epoch: 71 [40960/50176]	Loss: 0.8800
Training Epoch: 71 [41984/50176]	Loss: 0.9219
Training Epoch: 71 [43008/50176]	Loss: 1.0000
Training Epoch: 71 [44032/50176]	Loss: 0.9346
Training Epoch: 71 [45056/50176]	Loss: 0.9146
Training Epoch: 71 [46080/50176]	Loss: 0.9335
Training Epoch: 71 [47104/50176]	Loss: 0.9821
Training Epoch: 71 [48128/50176]	Loss: 1.0095
Training Epoch: 71 [49152/50176]	Loss: 1.0101
Training Epoch: 71 [50176/50176]	Loss: 0.9851
2022-12-06 19:09:22.523 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:09:22,569 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.92 energy=495.00
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Up to epoch 72: time=3512.88, energy=485185.54, cost=549969.61
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Expected next epoch: time=3559.98, energy=491873.42, cost=557435.11
2022-12-06 14:09:22,571 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0103, Accuracy: 0.0953
2022-12-06 14:09:22,816 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:09:22,817 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:09:22.819 [ZeusMonitor] Monitor started.
2022-12-06 19:09:22.819 [ZeusMonitor] Running indefinitely. 2022-12-06 19:09:22.819 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:09:22.819 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 14:10:06,761 [ZeusDataLoader(train)] train epoch 73 done: time=44.18 energy=6220.32
2022-12-06 14:10:06,765 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.8737
Training Epoch: 72 [2048/50176]	Loss: 0.8957
Training Epoch: 72 [3072/50176]	Loss: 0.8888
Training Epoch: 72 [4096/50176]	Loss: 0.8598
Training Epoch: 72 [5120/50176]	Loss: 0.9178
Training Epoch: 72 [6144/50176]	Loss: 0.8140
Training Epoch: 72 [7168/50176]	Loss: 0.8849
Training Epoch: 72 [8192/50176]	Loss: 0.8155
Training Epoch: 72 [9216/50176]	Loss: 0.9055
Training Epoch: 72 [10240/50176]	Loss: 0.8755
Training Epoch: 72 [11264/50176]	Loss: 0.9117
Training Epoch: 72 [12288/50176]	Loss: 0.9086
Training Epoch: 72 [13312/50176]	Loss: 0.8702
Training Epoch: 72 [14336/50176]	Loss: 0.8211
Training Epoch: 72 [15360/50176]	Loss: 0.8262
Training Epoch: 72 [16384/50176]	Loss: 0.9314
Training Epoch: 72 [17408/50176]	Loss: 0.9927
Training Epoch: 72 [18432/50176]	Loss: 0.9004
Training Epoch: 72 [19456/50176]	Loss: 0.8718
Training Epoch: 72 [20480/50176]	Loss: 0.9065
Training Epoch: 72 [21504/50176]	Loss: 0.9290
Training Epoch: 72 [22528/50176]	Loss: 0.8905
Training Epoch: 72 [23552/50176]	Loss: 0.9051
Training Epoch: 72 [24576/50176]	Loss: 0.9219
Training Epoch: 72 [25600/50176]	Loss: 0.9209
Training Epoch: 72 [26624/50176]	Loss: 0.9226
Training Epoch: 72 [27648/50176]	Loss: 0.8908
Training Epoch: 72 [28672/50176]	Loss: 0.9643
Training Epoch: 72 [29696/50176]	Loss: 0.9048
Training Epoch: 72 [30720/50176]	Loss: 0.9245
Training Epoch: 72 [31744/50176]	Loss: 0.8760
Training Epoch: 72 [32768/50176]	Loss: 0.9126
Training Epoch: 72 [33792/50176]	Loss: 0.8947
Training Epoch: 72 [34816/50176]	Loss: 0.9724
Training Epoch: 72 [35840/50176]	Loss: 0.9153
Training Epoch: 72 [36864/50176]	Loss: 0.9369
Training Epoch: 72 [37888/50176]	Loss: 0.9956
Training Epoch: 72 [38912/50176]	Loss: 0.9991
Training Epoch: 72 [39936/50176]	Loss: 0.9015
Training Epoch: 72 [40960/50176]	Loss: 0.9524
Training Epoch: 72 [41984/50176]	Loss: 0.9867
Training Epoch: 72 [43008/50176]	Loss: 1.0217
Training Epoch: 72 [44032/50176]	Loss: 0.9852
Training Epoch: 72 [45056/50176]	Loss: 0.9931
Training Epoch: 72 [46080/50176]	Loss: 1.0234
Training Epoch: 72 [47104/50176]	Loss: 0.9472
Training Epoch: 72 [48128/50176]	Loss: 0.9493
Training Epoch: 72 [49152/50176]	Loss: 0.9198
Training Epoch: 72 [50176/50176]	Loss: 1.0358
2022-12-06 19:10:10.610 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:10:10,666 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.89 energy=493.97
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Up to epoch 73: time=3560.95, energy=491899.83, cost=557533.36
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Expected next epoch: time=3608.06, energy=498587.71, cost=564998.86
2022-12-06 14:10:10,667 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0235, Accuracy: 0.0511
2022-12-06 14:10:10,913 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:10:10,913 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:10:10.915 [ZeusMonitor] Monitor started.
2022-12-06 19:10:10.915 [ZeusMonitor] Running indefinitely. 2022-12-06 19:10:10.915 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:10:10.915 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 14:10:54,711 [ZeusDataLoader(train)] train epoch 74 done: time=44.04 energy=6209.94
2022-12-06 14:10:54,715 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.8593
Training Epoch: 73 [2048/50176]	Loss: 0.8588
Training Epoch: 73 [3072/50176]	Loss: 0.8718
Training Epoch: 73 [4096/50176]	Loss: 0.9034
Training Epoch: 73 [5120/50176]	Loss: 0.7987
Training Epoch: 73 [6144/50176]	Loss: 0.8936
Training Epoch: 73 [7168/50176]	Loss: 0.8281
Training Epoch: 73 [8192/50176]	Loss: 0.8882
Training Epoch: 73 [9216/50176]	Loss: 0.8248
Training Epoch: 73 [10240/50176]	Loss: 0.9528
Training Epoch: 73 [11264/50176]	Loss: 0.8322
Training Epoch: 73 [12288/50176]	Loss: 0.8406
Training Epoch: 73 [13312/50176]	Loss: 0.8067
Training Epoch: 73 [14336/50176]	Loss: 0.8587
Training Epoch: 73 [15360/50176]	Loss: 0.9056
Training Epoch: 73 [16384/50176]	Loss: 0.8967
Training Epoch: 73 [17408/50176]	Loss: 0.7896
Training Epoch: 73 [18432/50176]	Loss: 0.8387
Training Epoch: 73 [19456/50176]	Loss: 0.8587
Training Epoch: 73 [20480/50176]	Loss: 0.8948
Training Epoch: 73 [21504/50176]	Loss: 0.8528
Training Epoch: 73 [22528/50176]	Loss: 0.9427
Training Epoch: 73 [23552/50176]	Loss: 0.8596
Training Epoch: 73 [24576/50176]	Loss: 0.8257
Training Epoch: 73 [25600/50176]	Loss: 0.8534
Training Epoch: 73 [26624/50176]	Loss: 0.9135
Training Epoch: 73 [27648/50176]	Loss: 0.8475
Training Epoch: 73 [28672/50176]	Loss: 0.9394
Training Epoch: 73 [29696/50176]	Loss: 0.9660
Training Epoch: 73 [30720/50176]	Loss: 0.9006
Training Epoch: 73 [31744/50176]	Loss: 0.9180
Training Epoch: 73 [32768/50176]	Loss: 0.9437
Training Epoch: 73 [33792/50176]	Loss: 0.9484
Training Epoch: 73 [34816/50176]	Loss: 0.9203
Training Epoch: 73 [35840/50176]	Loss: 0.9493
Training Epoch: 73 [36864/50176]	Loss: 0.8669
Training Epoch: 73 [37888/50176]	Loss: 0.8929
Training Epoch: 73 [38912/50176]	Loss: 0.9031
Training Epoch: 73 [39936/50176]	Loss: 0.9451
Training Epoch: 73 [40960/50176]	Loss: 0.8913
Training Epoch: 73 [41984/50176]	Loss: 1.0053
Training Epoch: 73 [43008/50176]	Loss: 0.9633
Training Epoch: 73 [44032/50176]	Loss: 0.8952
Training Epoch: 73 [45056/50176]	Loss: 0.8644
Training Epoch: 73 [46080/50176]	Loss: 0.9262
Training Epoch: 73 [47104/50176]	Loss: 0.9936
Training Epoch: 73 [48128/50176]	Loss: 0.9358
Training Epoch: 73 [49152/50176]	Loss: 0.8928
Training Epoch: 73 [50176/50176]	Loss: 0.9572
2022-12-06 19:10:58.407 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:10:58,418 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.69 energy=471.99
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Up to epoch 74: time=3608.68, energy=498581.75, cost=565050.77
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Expected next epoch: time=3655.79, energy=505269.63, cost=572516.27
2022-12-06 14:10:58,419 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0216, Accuracy: 0.0175
2022-12-06 14:10:58,618 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:10:58,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:10:58.622 [ZeusMonitor] Monitor started.
2022-12-06 19:10:58.622 [ZeusMonitor] Running indefinitely. 2022-12-06 19:10:58.622 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:10:58.623 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 14:11:42,777 [ZeusDataLoader(train)] train epoch 75 done: time=44.35 energy=6246.57
2022-12-06 14:11:42,780 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.8202
Training Epoch: 74 [2048/50176]	Loss: 0.8116
Training Epoch: 74 [3072/50176]	Loss: 0.7397
Training Epoch: 74 [4096/50176]	Loss: 0.8548
Training Epoch: 74 [5120/50176]	Loss: 0.7951
Training Epoch: 74 [6144/50176]	Loss: 0.8159
Training Epoch: 74 [7168/50176]	Loss: 0.8850
Training Epoch: 74 [8192/50176]	Loss: 0.8359
Training Epoch: 74 [9216/50176]	Loss: 0.8710
Training Epoch: 74 [10240/50176]	Loss: 0.8996
Training Epoch: 74 [11264/50176]	Loss: 0.8709
Training Epoch: 74 [12288/50176]	Loss: 0.8135
Training Epoch: 74 [13312/50176]	Loss: 0.8817
Training Epoch: 74 [14336/50176]	Loss: 0.8955
Training Epoch: 74 [15360/50176]	Loss: 0.7942
Training Epoch: 74 [16384/50176]	Loss: 0.8742
Training Epoch: 74 [17408/50176]	Loss: 0.8876
Training Epoch: 74 [18432/50176]	Loss: 0.9061
Training Epoch: 74 [19456/50176]	Loss: 0.8692
Training Epoch: 74 [20480/50176]	Loss: 0.9088
Training Epoch: 74 [21504/50176]	Loss: 0.8276
Training Epoch: 74 [22528/50176]	Loss: 0.8416
Training Epoch: 74 [23552/50176]	Loss: 0.9322
Training Epoch: 74 [24576/50176]	Loss: 0.8762
Training Epoch: 74 [25600/50176]	Loss: 0.8589
Training Epoch: 74 [26624/50176]	Loss: 0.9161
Training Epoch: 74 [27648/50176]	Loss: 0.9491
Training Epoch: 74 [28672/50176]	Loss: 0.8539
Training Epoch: 74 [29696/50176]	Loss: 0.8997
Training Epoch: 74 [30720/50176]	Loss: 0.7772
Training Epoch: 74 [31744/50176]	Loss: 0.9446
Training Epoch: 74 [32768/50176]	Loss: 0.9704
Training Epoch: 74 [33792/50176]	Loss: 0.8862
Training Epoch: 74 [34816/50176]	Loss: 0.9639
Training Epoch: 74 [35840/50176]	Loss: 0.9211
Training Epoch: 74 [36864/50176]	Loss: 0.8796
Training Epoch: 74 [37888/50176]	Loss: 0.8961
Training Epoch: 74 [38912/50176]	Loss: 0.9915
Training Epoch: 74 [39936/50176]	Loss: 0.8830
Training Epoch: 74 [40960/50176]	Loss: 0.9026
Training Epoch: 74 [41984/50176]	Loss: 0.8922
Training Epoch: 74 [43008/50176]	Loss: 0.9393
Training Epoch: 74 [44032/50176]	Loss: 0.9311
Training Epoch: 74 [45056/50176]	Loss: 0.9543
Training Epoch: 74 [46080/50176]	Loss: 0.9417
Training Epoch: 74 [47104/50176]	Loss: 0.9581
Training Epoch: 74 [48128/50176]	Loss: 0.9325
Training Epoch: 74 [49152/50176]	Loss: 1.0464
Training Epoch: 74 [50176/50176]	Loss: 0.9447
2022-12-06 19:11:46.538 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:11:46,586 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.80 energy=485.61
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Up to epoch 75: time=3656.83, energy=505313.94, cost=572629.82
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Expected next epoch: time=3703.94, energy=512001.82, cost=580095.31
2022-12-06 14:11:46,588 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 0.0131, Accuracy: 0.0782
2022-12-06 14:11:46,844 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:11:46,845 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:11:46.847 [ZeusMonitor] Monitor started.
2022-12-06 19:11:46.847 [ZeusMonitor] Running indefinitely. 2022-12-06 19:11:46.847 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:11:46.847 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e76+gpu0.power.log
2022-12-06 14:12:31,205 [ZeusDataLoader(train)] train epoch 76 done: time=44.61 energy=6257.69
2022-12-06 14:12:31,209 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 0.8114
Training Epoch: 75 [2048/50176]	Loss: 0.9027
Training Epoch: 75 [3072/50176]	Loss: 0.7759
Training Epoch: 75 [4096/50176]	Loss: 0.8172
Training Epoch: 75 [5120/50176]	Loss: 0.8230
Training Epoch: 75 [6144/50176]	Loss: 0.9142
Training Epoch: 75 [7168/50176]	Loss: 0.8358
Training Epoch: 75 [8192/50176]	Loss: 0.8202
Training Epoch: 75 [9216/50176]	Loss: 0.7986
Training Epoch: 75 [10240/50176]	Loss: 0.7783
Training Epoch: 75 [11264/50176]	Loss: 0.8638
Training Epoch: 75 [12288/50176]	Loss: 0.8087
Training Epoch: 75 [13312/50176]	Loss: 0.8636
Training Epoch: 75 [14336/50176]	Loss: 0.8845
Training Epoch: 75 [15360/50176]	Loss: 0.7646
Training Epoch: 75 [16384/50176]	Loss: 0.8906
Training Epoch: 75 [17408/50176]	Loss: 0.8280
Training Epoch: 75 [18432/50176]	Loss: 0.8278
Training Epoch: 75 [19456/50176]	Loss: 0.8269
Training Epoch: 75 [20480/50176]	Loss: 0.8407
Training Epoch: 75 [21504/50176]	Loss: 0.8576
Training Epoch: 75 [22528/50176]	Loss: 0.8782
Training Epoch: 75 [23552/50176]	Loss: 0.9103
Training Epoch: 75 [24576/50176]	Loss: 0.7728
Training Epoch: 75 [25600/50176]	Loss: 0.8646
Training Epoch: 75 [26624/50176]	Loss: 0.8772
Training Epoch: 75 [27648/50176]	Loss: 0.8197
Training Epoch: 75 [28672/50176]	Loss: 0.9106
Training Epoch: 75 [29696/50176]	Loss: 1.0075
Training Epoch: 75 [30720/50176]	Loss: 0.8833
Training Epoch: 75 [31744/50176]	Loss: 0.9702
Training Epoch: 75 [32768/50176]	Loss: 0.8861
Training Epoch: 75 [33792/50176]	Loss: 0.8475
Training Epoch: 75 [34816/50176]	Loss: 0.9169
Training Epoch: 75 [35840/50176]	Loss: 0.9198
Training Epoch: 75 [36864/50176]	Loss: 0.9575
Training Epoch: 75 [37888/50176]	Loss: 0.9110
Training Epoch: 75 [38912/50176]	Loss: 1.0080
Training Epoch: 75 [39936/50176]	Loss: 0.9256
Training Epoch: 75 [40960/50176]	Loss: 0.8299
Training Epoch: 75 [41984/50176]	Loss: 0.8563
Training Epoch: 75 [43008/50176]	Loss: 0.9287
Training Epoch: 75 [44032/50176]	Loss: 0.9088
Training Epoch: 75 [45056/50176]	Loss: 0.9435
Training Epoch: 75 [46080/50176]	Loss: 0.8780
Training Epoch: 75 [47104/50176]	Loss: 0.9329
Training Epoch: 75 [48128/50176]	Loss: 0.9070
Training Epoch: 75 [49152/50176]	Loss: 0.8780
Training Epoch: 75 [50176/50176]	Loss: 0.8658
2022-12-06 19:12:35.050 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:12:35,078 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.86 energy=482.88
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Up to epoch 76: time=3705.30, energy=512054.51, cost=580241.27
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Expected next epoch: time=3752.41, energy=518742.39, cost=587706.77
2022-12-06 14:12:35,080 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 0.0107, Accuracy: 0.1086
2022-12-06 14:12:35,269 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:12:35,270 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:12:35.271 [ZeusMonitor] Monitor started.
2022-12-06 19:12:35.272 [ZeusMonitor] Running indefinitely. 2022-12-06 19:12:35.272 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:12:35.272 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e77+gpu0.power.log
2022-12-06 14:13:19,416 [ZeusDataLoader(train)] train epoch 77 done: time=44.33 energy=6237.22
2022-12-06 14:13:19,419 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 0.8227
Training Epoch: 76 [2048/50176]	Loss: 0.8805
Training Epoch: 76 [3072/50176]	Loss: 0.7535
Training Epoch: 76 [4096/50176]	Loss: 0.8079
Training Epoch: 76 [5120/50176]	Loss: 0.8531
Training Epoch: 76 [6144/50176]	Loss: 0.8146
Training Epoch: 76 [7168/50176]	Loss: 0.8198
Training Epoch: 76 [8192/50176]	Loss: 0.7590
Training Epoch: 76 [9216/50176]	Loss: 0.7211
Training Epoch: 76 [10240/50176]	Loss: 0.8033
Training Epoch: 76 [11264/50176]	Loss: 0.8674
Training Epoch: 76 [12288/50176]	Loss: 0.8606
Training Epoch: 76 [13312/50176]	Loss: 0.7751
Training Epoch: 76 [14336/50176]	Loss: 0.8645
Training Epoch: 76 [15360/50176]	Loss: 0.7914
Training Epoch: 76 [16384/50176]	Loss: 0.7745
Training Epoch: 76 [17408/50176]	Loss: 0.8924
Training Epoch: 76 [18432/50176]	Loss: 0.8244
Training Epoch: 76 [19456/50176]	Loss: 0.8409
Training Epoch: 76 [20480/50176]	Loss: 0.8744
Training Epoch: 76 [21504/50176]	Loss: 0.8885
Training Epoch: 76 [22528/50176]	Loss: 0.8365
Training Epoch: 76 [23552/50176]	Loss: 0.8468
Training Epoch: 76 [24576/50176]	Loss: 0.8569
Training Epoch: 76 [25600/50176]	Loss: 0.8212
Training Epoch: 76 [26624/50176]	Loss: 0.9358
Training Epoch: 76 [27648/50176]	Loss: 0.9416
Training Epoch: 76 [28672/50176]	Loss: 0.8594
Training Epoch: 76 [29696/50176]	Loss: 0.9324
Training Epoch: 76 [30720/50176]	Loss: 0.9407
Training Epoch: 76 [31744/50176]	Loss: 0.8635
Training Epoch: 76 [32768/50176]	Loss: 0.8730
Training Epoch: 76 [33792/50176]	Loss: 0.9690
Training Epoch: 76 [34816/50176]	Loss: 0.8888
Training Epoch: 76 [35840/50176]	Loss: 0.9193
Training Epoch: 76 [36864/50176]	Loss: 0.8181
Training Epoch: 76 [37888/50176]	Loss: 0.9001
Training Epoch: 76 [38912/50176]	Loss: 0.8774
Training Epoch: 76 [39936/50176]	Loss: 0.8135
Training Epoch: 76 [40960/50176]	Loss: 0.9446
Training Epoch: 76 [41984/50176]	Loss: 0.8731
Training Epoch: 76 [43008/50176]	Loss: 0.9732
Training Epoch: 76 [44032/50176]	Loss: 0.9105
Training Epoch: 76 [45056/50176]	Loss: 0.8150
Training Epoch: 76 [46080/50176]	Loss: 0.9400
Training Epoch: 76 [47104/50176]	Loss: 0.8544
Training Epoch: 76 [48128/50176]	Loss: 0.8835
Training Epoch: 76 [49152/50176]	Loss: 0.8758
Training Epoch: 76 [50176/50176]	Loss: 0.9386
2022-12-06 19:13:23.156 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:13:23,184 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.76 energy=470.83
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Up to epoch 77: time=3753.39, energy=518762.56, cost=587802.71
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Expected next epoch: time=3800.49, energy=525450.43, cost=595268.21
2022-12-06 14:13:23,185 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0062, Accuracy: 0.1666
2022-12-06 14:13:23,435 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:13:23,436 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:13:23.446 [ZeusMonitor] Monitor started.
2022-12-06 19:13:23.446 [ZeusMonitor] Running indefinitely. 2022-12-06 19:13:23.446 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:13:23.446 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e78+gpu0.power.log
2022-12-06 14:14:07,657 [ZeusDataLoader(train)] train epoch 78 done: time=44.46 energy=6237.17
2022-12-06 14:14:07,660 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 0.7987
Training Epoch: 77 [2048/50176]	Loss: 0.8225
Training Epoch: 77 [3072/50176]	Loss: 0.8029
Training Epoch: 77 [4096/50176]	Loss: 0.7820
Training Epoch: 77 [5120/50176]	Loss: 0.8057
Training Epoch: 77 [6144/50176]	Loss: 0.7652
Training Epoch: 77 [7168/50176]	Loss: 0.7889
Training Epoch: 77 [8192/50176]	Loss: 0.7991
Training Epoch: 77 [9216/50176]	Loss: 0.8475
Training Epoch: 77 [10240/50176]	Loss: 0.8315
Training Epoch: 77 [11264/50176]	Loss: 0.7273
Training Epoch: 77 [12288/50176]	Loss: 0.7744
Training Epoch: 77 [13312/50176]	Loss: 0.8265
Training Epoch: 77 [14336/50176]	Loss: 0.8419
Training Epoch: 77 [15360/50176]	Loss: 0.9028
Training Epoch: 77 [16384/50176]	Loss: 0.8273
Training Epoch: 77 [17408/50176]	Loss: 0.8728
Training Epoch: 77 [18432/50176]	Loss: 0.8375
Training Epoch: 77 [19456/50176]	Loss: 0.8122
Training Epoch: 77 [20480/50176]	Loss: 0.8210
Training Epoch: 77 [21504/50176]	Loss: 0.7881
Training Epoch: 77 [22528/50176]	Loss: 0.8915
Training Epoch: 77 [23552/50176]	Loss: 0.8440
Training Epoch: 77 [24576/50176]	Loss: 0.8691
Training Epoch: 77 [25600/50176]	Loss: 0.8209
Training Epoch: 77 [26624/50176]	Loss: 0.8107
Training Epoch: 77 [27648/50176]	Loss: 0.8664
Training Epoch: 77 [28672/50176]	Loss: 0.9098
Training Epoch: 77 [29696/50176]	Loss: 0.8905
Training Epoch: 77 [30720/50176]	Loss: 0.8289
Training Epoch: 77 [31744/50176]	Loss: 0.7998
Training Epoch: 77 [32768/50176]	Loss: 0.8858
Training Epoch: 77 [33792/50176]	Loss: 0.8306
Training Epoch: 77 [34816/50176]	Loss: 0.9461
Training Epoch: 77 [35840/50176]	Loss: 1.0024
Training Epoch: 77 [36864/50176]	Loss: 0.8935
Training Epoch: 77 [37888/50176]	Loss: 0.9788
Training Epoch: 77 [38912/50176]	Loss: 0.8976
Training Epoch: 77 [39936/50176]	Loss: 0.9343
Training Epoch: 77 [40960/50176]	Loss: 0.8705
Training Epoch: 77 [41984/50176]	Loss: 0.8955
Training Epoch: 77 [43008/50176]	Loss: 0.9084
Training Epoch: 77 [44032/50176]	Loss: 0.8329
Training Epoch: 77 [45056/50176]	Loss: 0.9245
Training Epoch: 77 [46080/50176]	Loss: 0.9041
Training Epoch: 77 [47104/50176]	Loss: 0.8506
Training Epoch: 77 [48128/50176]	Loss: 0.9568
Training Epoch: 77 [49152/50176]	Loss: 0.8838
Training Epoch: 77 [50176/50176]	Loss: 0.8713
2022-12-06 19:14:11.388 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:14:11,400 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.73 energy=474.58
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Up to epoch 78: time=3801.58, energy=525474.30, cost=595375.71
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Expected next epoch: time=3848.69, energy=532162.18, cost=602841.21
2022-12-06 14:14:11,401 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0396, Accuracy: 0.0395
2022-12-06 14:14:11,636 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:14:11,637 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:14:11.639 [ZeusMonitor] Monitor started.
2022-12-06 19:14:11.639 [ZeusMonitor] Running indefinitely. 2022-12-06 19:14:11.639 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:14:11.639 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e79+gpu0.power.log
2022-12-06 14:14:56,101 [ZeusDataLoader(train)] train epoch 79 done: time=44.69 energy=6271.48
2022-12-06 14:14:56,104 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 0.7922
Training Epoch: 78 [2048/50176]	Loss: 0.7499
Training Epoch: 78 [3072/50176]	Loss: 0.7599
Training Epoch: 78 [4096/50176]	Loss: 0.8063
Training Epoch: 78 [5120/50176]	Loss: 0.7944
Training Epoch: 78 [6144/50176]	Loss: 0.8249
Training Epoch: 78 [7168/50176]	Loss: 0.8028
Training Epoch: 78 [8192/50176]	Loss: 0.8715
Training Epoch: 78 [9216/50176]	Loss: 0.7972
Training Epoch: 78 [10240/50176]	Loss: 0.8306
Training Epoch: 78 [11264/50176]	Loss: 0.8107
Training Epoch: 78 [12288/50176]	Loss: 0.8098
Training Epoch: 78 [13312/50176]	Loss: 0.8853
Training Epoch: 78 [14336/50176]	Loss: 0.8125
Training Epoch: 78 [15360/50176]	Loss: 0.7826
Training Epoch: 78 [16384/50176]	Loss: 0.8427
Training Epoch: 78 [17408/50176]	Loss: 0.8321
Training Epoch: 78 [18432/50176]	Loss: 0.8182
Training Epoch: 78 [19456/50176]	Loss: 0.8031
Training Epoch: 78 [20480/50176]	Loss: 0.7813
Training Epoch: 78 [21504/50176]	Loss: 0.8185
Training Epoch: 78 [22528/50176]	Loss: 0.8101
Training Epoch: 78 [23552/50176]	Loss: 0.8843
Training Epoch: 78 [24576/50176]	Loss: 0.8966
Training Epoch: 78 [25600/50176]	Loss: 0.9037
Training Epoch: 78 [26624/50176]	Loss: 0.8824
Training Epoch: 78 [27648/50176]	Loss: 0.7943
Training Epoch: 78 [28672/50176]	Loss: 0.8169
Training Epoch: 78 [29696/50176]	Loss: 0.8806
Training Epoch: 78 [30720/50176]	Loss: 0.8500
Training Epoch: 78 [31744/50176]	Loss: 0.8057
Training Epoch: 78 [32768/50176]	Loss: 0.9540
Training Epoch: 78 [33792/50176]	Loss: 0.8740
Training Epoch: 78 [34816/50176]	Loss: 0.9034
Training Epoch: 78 [35840/50176]	Loss: 0.7519
Training Epoch: 78 [36864/50176]	Loss: 0.9233
Training Epoch: 78 [37888/50176]	Loss: 0.8243
Training Epoch: 78 [38912/50176]	Loss: 0.8672
Training Epoch: 78 [39936/50176]	Loss: 0.8842
Training Epoch: 78 [40960/50176]	Loss: 0.8223
Training Epoch: 78 [41984/50176]	Loss: 0.7813
Training Epoch: 78 [43008/50176]	Loss: 0.9154
Training Epoch: 78 [44032/50176]	Loss: 0.8658
Training Epoch: 78 [45056/50176]	Loss: 0.9148
Training Epoch: 78 [46080/50176]	Loss: 0.8817
Training Epoch: 78 [47104/50176]	Loss: 0.8700
Training Epoch: 78 [48128/50176]	Loss: 0.8214
Training Epoch: 78 [49152/50176]	Loss: 0.8533
Training Epoch: 78 [50176/50176]	Loss: 0.9024
2022-12-06 19:14:59.779 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:14:59,791 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.68 energy=462.25
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Up to epoch 79: time=3849.95, energy=532208.03, cost=602974.96
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Expected next epoch: time=3897.06, energy=538895.91, cost=610440.45
2022-12-06 14:14:59,793 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 0.0115, Accuracy: 0.0953
2022-12-06 14:15:00,054 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:15:00,054 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:15:00.058 [ZeusMonitor] Monitor started.
2022-12-06 19:15:00.058 [ZeusMonitor] Running indefinitely. 2022-12-06 19:15:00.058 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:15:00.058 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e80+gpu0.power.log
2022-12-06 14:15:44,268 [ZeusDataLoader(train)] train epoch 80 done: time=44.47 energy=6240.85
2022-12-06 14:15:44,272 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 0.8145
Training Epoch: 79 [2048/50176]	Loss: 0.7824
Training Epoch: 79 [3072/50176]	Loss: 0.7477
Training Epoch: 79 [4096/50176]	Loss: 0.7842
Training Epoch: 79 [5120/50176]	Loss: 0.7163
Training Epoch: 79 [6144/50176]	Loss: 0.8183
Training Epoch: 79 [7168/50176]	Loss: 0.8397
Training Epoch: 79 [8192/50176]	Loss: 0.7999
Training Epoch: 79 [9216/50176]	Loss: 0.7268
Training Epoch: 79 [10240/50176]	Loss: 0.7907
Training Epoch: 79 [11264/50176]	Loss: 0.8149
Training Epoch: 79 [12288/50176]	Loss: 0.8465
Training Epoch: 79 [13312/50176]	Loss: 0.7865
Training Epoch: 79 [14336/50176]	Loss: 0.7596
Training Epoch: 79 [15360/50176]	Loss: 0.7353
Training Epoch: 79 [16384/50176]	Loss: 0.8724
Training Epoch: 79 [17408/50176]	Loss: 0.7210
Training Epoch: 79 [18432/50176]	Loss: 0.7321
Training Epoch: 79 [19456/50176]	Loss: 0.9101
Training Epoch: 79 [20480/50176]	Loss: 0.7687
Training Epoch: 79 [21504/50176]	Loss: 0.8829
Training Epoch: 79 [22528/50176]	Loss: 0.8026
Training Epoch: 79 [23552/50176]	Loss: 0.8150
Training Epoch: 79 [24576/50176]	Loss: 0.7751
Training Epoch: 79 [25600/50176]	Loss: 0.7249
Training Epoch: 79 [26624/50176]	Loss: 0.9186
Training Epoch: 79 [27648/50176]	Loss: 0.8572
Training Epoch: 79 [28672/50176]	Loss: 0.8371
Training Epoch: 79 [29696/50176]	Loss: 0.8296
Training Epoch: 79 [30720/50176]	Loss: 0.8133
Training Epoch: 79 [31744/50176]	Loss: 0.8027
Training Epoch: 79 [32768/50176]	Loss: 0.8184
Training Epoch: 79 [33792/50176]	Loss: 0.8032
Training Epoch: 79 [34816/50176]	Loss: 0.7837
Training Epoch: 79 [35840/50176]	Loss: 0.8839
Training Epoch: 79 [36864/50176]	Loss: 0.8318
Training Epoch: 79 [37888/50176]	Loss: 0.8396
Training Epoch: 79 [38912/50176]	Loss: 0.8916
Training Epoch: 79 [39936/50176]	Loss: 0.8426
Training Epoch: 79 [40960/50176]	Loss: 0.8547
Training Epoch: 79 [41984/50176]	Loss: 0.7853
Training Epoch: 79 [43008/50176]	Loss: 0.8888
Training Epoch: 79 [44032/50176]	Loss: 0.8971
Training Epoch: 79 [45056/50176]	Loss: 0.7887
Training Epoch: 79 [46080/50176]	Loss: 0.9013
Training Epoch: 79 [47104/50176]	Loss: 0.8269
Training Epoch: 79 [48128/50176]	Loss: 0.8559
Training Epoch: 79 [49152/50176]	Loss: 0.8294
Training Epoch: 79 [50176/50176]	Loss: 0.9025
2022-12-06 19:15:48.207 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:15:48,237 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.96 energy=491.99
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Up to epoch 80: time=3898.38, energy=538940.86, cost=610578.57
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Expected next epoch: time=3945.48, energy=545628.74, cost=618044.07
2022-12-06 14:15:48,239 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 0.0203, Accuracy: 0.0410
2022-12-06 14:15:48,469 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:15:48,470 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:15:48.472 [ZeusMonitor] Monitor started.
2022-12-06 19:15:48.472 [ZeusMonitor] Running indefinitely. 2022-12-06 19:15:48.472 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:15:48.472 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e81+gpu0.power.log
2022-12-06 14:16:32,838 [ZeusDataLoader(train)] train epoch 81 done: time=44.59 energy=6251.47
2022-12-06 14:16:32,842 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 0.7796
Training Epoch: 80 [2048/50176]	Loss: 0.7504
Training Epoch: 80 [3072/50176]	Loss: 0.7273
Training Epoch: 80 [4096/50176]	Loss: 0.7464
Training Epoch: 80 [5120/50176]	Loss: 0.7927
Training Epoch: 80 [6144/50176]	Loss: 0.7247
Training Epoch: 80 [7168/50176]	Loss: 0.8245
Training Epoch: 80 [8192/50176]	Loss: 0.8061
Training Epoch: 80 [9216/50176]	Loss: 0.8037
Training Epoch: 80 [10240/50176]	Loss: 0.7827
Training Epoch: 80 [11264/50176]	Loss: 0.7625
Training Epoch: 80 [12288/50176]	Loss: 0.8128
Training Epoch: 80 [13312/50176]	Loss: 0.7497
Training Epoch: 80 [14336/50176]	Loss: 0.8427
Training Epoch: 80 [15360/50176]	Loss: 0.7338
Training Epoch: 80 [16384/50176]	Loss: 0.8418
Training Epoch: 80 [17408/50176]	Loss: 0.8946
Training Epoch: 80 [18432/50176]	Loss: 0.8161
Training Epoch: 80 [19456/50176]	Loss: 0.7750
Training Epoch: 80 [20480/50176]	Loss: 0.7252
Training Epoch: 80 [21504/50176]	Loss: 0.8285
Training Epoch: 80 [22528/50176]	Loss: 0.8639
Training Epoch: 80 [23552/50176]	Loss: 0.8905
Training Epoch: 80 [24576/50176]	Loss: 0.8173
Training Epoch: 80 [25600/50176]	Loss: 0.7789
Training Epoch: 80 [26624/50176]	Loss: 0.8062
Training Epoch: 80 [27648/50176]	Loss: 0.8796
Training Epoch: 80 [28672/50176]	Loss: 0.8031
Training Epoch: 80 [29696/50176]	Loss: 0.8573
Training Epoch: 80 [30720/50176]	Loss: 0.7765
Training Epoch: 80 [31744/50176]	Loss: 0.8329
Training Epoch: 80 [32768/50176]	Loss: 0.7804
Training Epoch: 80 [33792/50176]	Loss: 0.8658
Training Epoch: 80 [34816/50176]	Loss: 0.8088
Training Epoch: 80 [35840/50176]	Loss: 0.8388
Training Epoch: 80 [36864/50176]	Loss: 0.8128
Training Epoch: 80 [37888/50176]	Loss: 0.7307
Training Epoch: 80 [38912/50176]	Loss: 0.8188
Training Epoch: 80 [39936/50176]	Loss: 0.8820
Training Epoch: 80 [40960/50176]	Loss: 0.8853
Training Epoch: 80 [41984/50176]	Loss: 0.9230
Training Epoch: 80 [43008/50176]	Loss: 0.8567
Training Epoch: 80 [44032/50176]	Loss: 0.9108
Training Epoch: 80 [45056/50176]	Loss: 0.8005
Training Epoch: 80 [46080/50176]	Loss: 0.8629
Training Epoch: 80 [47104/50176]	Loss: 0.8359
Training Epoch: 80 [48128/50176]	Loss: 0.8067
Training Epoch: 80 [49152/50176]	Loss: 0.8325
Training Epoch: 80 [50176/50176]	Loss: 0.9182
2022-12-06 19:16:36.598 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:16:36,626 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.78 energy=478.13
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Up to epoch 81: time=3946.75, energy=545670.46, cost=618175.58
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Expected next epoch: time=3993.85, energy=552358.34, cost=625641.08
2022-12-06 14:16:36,627 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0109, Accuracy: 0.1751
2022-12-06 14:16:36,868 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:16:36,869 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:16:36.871 [ZeusMonitor] Monitor started.
2022-12-06 19:16:36.871 [ZeusMonitor] Running indefinitely. 2022-12-06 19:16:36.871 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:16:36.871 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e82+gpu0.power.log
2022-12-06 14:17:20,837 [ZeusDataLoader(train)] train epoch 82 done: time=44.20 energy=6226.79
2022-12-06 14:17:20,841 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 0.7340
Training Epoch: 81 [2048/50176]	Loss: 0.7783
Training Epoch: 81 [3072/50176]	Loss: 0.7755
Training Epoch: 81 [4096/50176]	Loss: 0.7993
Training Epoch: 81 [5120/50176]	Loss: 0.8403
Training Epoch: 81 [6144/50176]	Loss: 0.7538
Training Epoch: 81 [7168/50176]	Loss: 0.8065
Training Epoch: 81 [8192/50176]	Loss: 0.7852
Training Epoch: 81 [9216/50176]	Loss: 0.8123
Training Epoch: 81 [10240/50176]	Loss: 0.7525
Training Epoch: 81 [11264/50176]	Loss: 0.8242
Training Epoch: 81 [12288/50176]	Loss: 0.7610
Training Epoch: 81 [13312/50176]	Loss: 0.7411
Training Epoch: 81 [14336/50176]	Loss: 0.7934
Training Epoch: 81 [15360/50176]	Loss: 0.7640
Training Epoch: 81 [16384/50176]	Loss: 0.7409
Training Epoch: 81 [17408/50176]	Loss: 0.8234
Training Epoch: 81 [18432/50176]	Loss: 0.7348
Training Epoch: 81 [19456/50176]	Loss: 0.7211
Training Epoch: 81 [20480/50176]	Loss: 0.8479
Training Epoch: 81 [21504/50176]	Loss: 0.7610
Training Epoch: 81 [22528/50176]	Loss: 0.7589
Training Epoch: 81 [23552/50176]	Loss: 0.7813
Training Epoch: 81 [24576/50176]	Loss: 0.7680
Training Epoch: 81 [25600/50176]	Loss: 0.8653
Training Epoch: 81 [26624/50176]	Loss: 0.8301
Training Epoch: 81 [27648/50176]	Loss: 0.7921
Training Epoch: 81 [28672/50176]	Loss: 0.8291
Training Epoch: 81 [29696/50176]	Loss: 0.7829
Training Epoch: 81 [30720/50176]	Loss: 0.7381
Training Epoch: 81 [31744/50176]	Loss: 0.8416
Training Epoch: 81 [32768/50176]	Loss: 0.8797
Training Epoch: 81 [33792/50176]	Loss: 0.7988
Training Epoch: 81 [34816/50176]	Loss: 0.7695
Training Epoch: 81 [35840/50176]	Loss: 0.8632
Training Epoch: 81 [36864/50176]	Loss: 0.8125
Training Epoch: 81 [37888/50176]	Loss: 0.9085
Training Epoch: 81 [38912/50176]	Loss: 0.8351
Training Epoch: 81 [39936/50176]	Loss: 0.7793
Training Epoch: 81 [40960/50176]	Loss: 0.8632
Training Epoch: 81 [41984/50176]	Loss: 0.7904
Training Epoch: 81 [43008/50176]	Loss: 0.8110
Training Epoch: 81 [44032/50176]	Loss: 0.8717
Training Epoch: 81 [45056/50176]	Loss: 0.8884
Training Epoch: 81 [46080/50176]	Loss: 0.8776
Training Epoch: 81 [47104/50176]	Loss: 0.8239
Training Epoch: 81 [48128/50176]	Loss: 0.8548
Training Epoch: 81 [49152/50176]	Loss: 0.7792
Training Epoch: 81 [50176/50176]	Loss: 0.8422
2022-12-06 19:17:24.598 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:17:24,653 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.80 energy=489.03
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Up to epoch 82: time=3994.75, energy=552386.28, cost=625733.98
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Expected next epoch: time=4041.86, energy=559074.15, cost=633199.48
2022-12-06 14:17:24,654 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 0.0106, Accuracy: 0.1024
2022-12-06 14:17:24,903 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:17:24,904 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:17:24.906 [ZeusMonitor] Monitor started.
2022-12-06 19:17:24.906 [ZeusMonitor] Running indefinitely. 2022-12-06 19:17:24.906 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:17:24.906 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e83+gpu0.power.log
2022-12-06 14:18:09,288 [ZeusDataLoader(train)] train epoch 83 done: time=44.63 energy=6256.47
2022-12-06 14:18:09,292 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 0.6953
Training Epoch: 82 [2048/50176]	Loss: 0.7319
Training Epoch: 82 [3072/50176]	Loss: 0.7032
Training Epoch: 82 [4096/50176]	Loss: 0.7144
Training Epoch: 82 [5120/50176]	Loss: 0.7666
Training Epoch: 82 [6144/50176]	Loss: 0.7285
Training Epoch: 82 [7168/50176]	Loss: 0.7811
Training Epoch: 82 [8192/50176]	Loss: 0.7722
Training Epoch: 82 [9216/50176]	Loss: 0.7439
Training Epoch: 82 [10240/50176]	Loss: 0.6942
Training Epoch: 82 [11264/50176]	Loss: 0.7289
Training Epoch: 82 [12288/50176]	Loss: 0.6914
Training Epoch: 82 [13312/50176]	Loss: 0.7662
Training Epoch: 82 [14336/50176]	Loss: 0.7178
Training Epoch: 82 [15360/50176]	Loss: 0.7665
Training Epoch: 82 [16384/50176]	Loss: 0.7666
Training Epoch: 82 [17408/50176]	Loss: 0.6741
Training Epoch: 82 [18432/50176]	Loss: 0.7832
Training Epoch: 82 [19456/50176]	Loss: 0.7462
Training Epoch: 82 [20480/50176]	Loss: 0.8331
Training Epoch: 82 [21504/50176]	Loss: 0.7920
Training Epoch: 82 [22528/50176]	Loss: 0.7608
Training Epoch: 82 [23552/50176]	Loss: 0.8217
Training Epoch: 82 [24576/50176]	Loss: 0.7713
Training Epoch: 82 [25600/50176]	Loss: 0.7729
Training Epoch: 82 [26624/50176]	Loss: 0.8998
Training Epoch: 82 [27648/50176]	Loss: 0.7805
Training Epoch: 82 [28672/50176]	Loss: 0.6931
Training Epoch: 82 [29696/50176]	Loss: 0.7480
Training Epoch: 82 [30720/50176]	Loss: 0.7752
Training Epoch: 82 [31744/50176]	Loss: 0.7993
Training Epoch: 82 [32768/50176]	Loss: 0.7024
Training Epoch: 82 [33792/50176]	Loss: 0.7655
Training Epoch: 82 [34816/50176]	Loss: 0.7760
Training Epoch: 82 [35840/50176]	Loss: 0.8417
Training Epoch: 82 [36864/50176]	Loss: 0.8239
Training Epoch: 82 [37888/50176]	Loss: 0.7561
Training Epoch: 82 [38912/50176]	Loss: 0.8230
Training Epoch: 82 [39936/50176]	Loss: 0.8149
Training Epoch: 82 [40960/50176]	Loss: 0.9296
Training Epoch: 82 [41984/50176]	Loss: 0.7772
Training Epoch: 82 [43008/50176]	Loss: 0.8768
Training Epoch: 82 [44032/50176]	Loss: 0.7777
Training Epoch: 82 [45056/50176]	Loss: 0.8437
Training Epoch: 82 [46080/50176]	Loss: 0.8558
Training Epoch: 82 [47104/50176]	Loss: 0.8681
Training Epoch: 82 [48128/50176]	Loss: 0.8398
Training Epoch: 82 [49152/50176]	Loss: 0.7910
Training Epoch: 82 [50176/50176]	Loss: 0.8530
2022-12-06 19:18:13.014 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:18:13,023 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.72 energy=471.47
2022-12-06 14:18:13,023 [ZeusDataLoader(train)] Up to epoch 83: time=4043.10, energy=559114.21, cost=633328.49
2022-12-06 14:18:13,023 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:18:13,024 [ZeusDataLoader(train)] Expected next epoch: time=4090.21, energy=565802.09, cost=640793.99
2022-12-06 14:18:13,024 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 0.0091, Accuracy: 0.1307
2022-12-06 14:18:13,291 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:18:13,291 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:18:13.293 [ZeusMonitor] Monitor started.
2022-12-06 19:18:13.293 [ZeusMonitor] Running indefinitely. 2022-12-06 19:18:13.293 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:18:13.293 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e84+gpu0.power.log
2022-12-06 14:18:57,926 [ZeusDataLoader(train)] train epoch 84 done: time=44.89 energy=6267.55
2022-12-06 14:18:57,929 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 0.7259
Training Epoch: 83 [2048/50176]	Loss: 0.6962
Training Epoch: 83 [3072/50176]	Loss: 0.7457
Training Epoch: 83 [4096/50176]	Loss: 0.7200
Training Epoch: 83 [5120/50176]	Loss: 0.7698
Training Epoch: 83 [6144/50176]	Loss: 0.6555
Training Epoch: 83 [7168/50176]	Loss: 0.8001
Training Epoch: 83 [8192/50176]	Loss: 0.7480
Training Epoch: 83 [9216/50176]	Loss: 0.7905
Training Epoch: 83 [10240/50176]	Loss: 0.7339
Training Epoch: 83 [11264/50176]	Loss: 0.7841
Training Epoch: 83 [12288/50176]	Loss: 0.8358
Training Epoch: 83 [13312/50176]	Loss: 0.7446
Training Epoch: 83 [14336/50176]	Loss: 0.7804
Training Epoch: 83 [15360/50176]	Loss: 0.7325
Training Epoch: 83 [16384/50176]	Loss: 0.7677
Training Epoch: 83 [17408/50176]	Loss: 0.7421
Training Epoch: 83 [18432/50176]	Loss: 0.7078
Training Epoch: 83 [19456/50176]	Loss: 0.9144
Training Epoch: 83 [20480/50176]	Loss: 0.8672
Training Epoch: 83 [21504/50176]	Loss: 0.8081
Training Epoch: 83 [22528/50176]	Loss: 0.7171
Training Epoch: 83 [23552/50176]	Loss: 0.6587
Training Epoch: 83 [24576/50176]	Loss: 0.7431
Training Epoch: 83 [25600/50176]	Loss: 0.7699
Training Epoch: 83 [26624/50176]	Loss: 0.8045
Training Epoch: 83 [27648/50176]	Loss: 0.7863
Training Epoch: 83 [28672/50176]	Loss: 0.7370
Training Epoch: 83 [29696/50176]	Loss: 0.7634
Training Epoch: 83 [30720/50176]	Loss: 0.7986
Training Epoch: 83 [31744/50176]	Loss: 0.7844
Training Epoch: 83 [32768/50176]	Loss: 0.8665
Training Epoch: 83 [33792/50176]	Loss: 0.8098
Training Epoch: 83 [34816/50176]	Loss: 0.7583
Training Epoch: 83 [35840/50176]	Loss: 0.8043
Training Epoch: 83 [36864/50176]	Loss: 0.7706
Training Epoch: 83 [37888/50176]	Loss: 0.7212
Training Epoch: 83 [38912/50176]	Loss: 0.7570
Training Epoch: 83 [39936/50176]	Loss: 0.8824
Training Epoch: 83 [40960/50176]	Loss: 0.8000
Training Epoch: 83 [41984/50176]	Loss: 0.8403
Training Epoch: 83 [43008/50176]	Loss: 0.7550
Training Epoch: 83 [44032/50176]	Loss: 0.7728
Training Epoch: 83 [45056/50176]	Loss: 0.8909
Training Epoch: 83 [46080/50176]	Loss: 0.7618
Training Epoch: 83 [47104/50176]	Loss: 0.7919
Training Epoch: 83 [48128/50176]	Loss: 0.7664
Training Epoch: 83 [49152/50176]	Loss: 0.8065
Training Epoch: 83 [50176/50176]	Loss: 0.8255
2022-12-06 19:19:01.615 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:19:01,629 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.69 energy=472.23
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Up to epoch 84: time=4091.69, energy=565853.99, cost=640949.63
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Expected next epoch: time=4138.79, energy=572541.86, cost=648415.12
2022-12-06 14:19:01,631 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 0.0106, Accuracy: 0.1046
2022-12-06 14:19:01,872 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:19:01,873 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:19:01.875 [ZeusMonitor] Monitor started.
2022-12-06 19:19:01.875 [ZeusMonitor] Running indefinitely. 2022-12-06 19:19:01.875 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:19:01.875 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e85+gpu0.power.log
2022-12-06 14:19:45,839 [ZeusDataLoader(train)] train epoch 85 done: time=44.20 energy=6237.37
2022-12-06 14:19:45,843 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 0.7269
Training Epoch: 84 [2048/50176]	Loss: 0.7529
Training Epoch: 84 [3072/50176]	Loss: 0.7336
Training Epoch: 84 [4096/50176]	Loss: 0.7187
Training Epoch: 84 [5120/50176]	Loss: 0.8208
Training Epoch: 84 [6144/50176]	Loss: 0.7250
Training Epoch: 84 [7168/50176]	Loss: 0.6824
Training Epoch: 84 [8192/50176]	Loss: 0.7927
Training Epoch: 84 [9216/50176]	Loss: 0.7421
Training Epoch: 84 [10240/50176]	Loss: 0.7303
Training Epoch: 84 [11264/50176]	Loss: 0.6998
Training Epoch: 84 [12288/50176]	Loss: 0.7556
Training Epoch: 84 [13312/50176]	Loss: 0.7796
Training Epoch: 84 [14336/50176]	Loss: 0.7287
Training Epoch: 84 [15360/50176]	Loss: 0.6846
Training Epoch: 84 [16384/50176]	Loss: 0.7844
Training Epoch: 84 [17408/50176]	Loss: 0.7417
Training Epoch: 84 [18432/50176]	Loss: 0.7712
Training Epoch: 84 [19456/50176]	Loss: 0.7555
Training Epoch: 84 [20480/50176]	Loss: 0.7764
Training Epoch: 84 [21504/50176]	Loss: 0.7553
Training Epoch: 84 [22528/50176]	Loss: 0.7584
Training Epoch: 84 [23552/50176]	Loss: 0.7786
Training Epoch: 84 [24576/50176]	Loss: 0.7591
Training Epoch: 84 [25600/50176]	Loss: 0.7515
Training Epoch: 84 [26624/50176]	Loss: 0.8407
Training Epoch: 84 [27648/50176]	Loss: 0.7997
Training Epoch: 84 [28672/50176]	Loss: 0.7578
Training Epoch: 84 [29696/50176]	Loss: 0.8762
Training Epoch: 84 [30720/50176]	Loss: 0.8385
Training Epoch: 84 [31744/50176]	Loss: 0.6895
Training Epoch: 84 [32768/50176]	Loss: 0.7199
Training Epoch: 84 [33792/50176]	Loss: 0.7853
Training Epoch: 84 [34816/50176]	Loss: 0.7577
Training Epoch: 84 [35840/50176]	Loss: 0.7899
Training Epoch: 84 [36864/50176]	Loss: 0.8331
Training Epoch: 84 [37888/50176]	Loss: 0.7577
Training Epoch: 84 [38912/50176]	Loss: 0.7980
Training Epoch: 84 [39936/50176]	Loss: 0.7498
Training Epoch: 84 [40960/50176]	Loss: 0.8055
Training Epoch: 84 [41984/50176]	Loss: 0.8107
Training Epoch: 84 [43008/50176]	Loss: 0.7894
Training Epoch: 84 [44032/50176]	Loss: 0.8856
Training Epoch: 84 [45056/50176]	Loss: 0.7999
Training Epoch: 84 [46080/50176]	Loss: 0.8177
Training Epoch: 84 [47104/50176]	Loss: 0.8240
Training Epoch: 84 [48128/50176]	Loss: 0.9050
Training Epoch: 84 [49152/50176]	Loss: 0.8585
Training Epoch: 84 [50176/50176]	Loss: 0.8175
2022-12-06 19:19:49.610 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:19:49,662 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.81 energy=491.32
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Up to epoch 85: time=4139.70, energy=572582.67, cost=648514.95
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Expected next epoch: time=4186.80, energy=579270.55, cost=655980.45
2022-12-06 14:19:49,663 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 0.0185, Accuracy: 0.0945
2022-12-06 14:19:49,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:19:49,909 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:19:49.911 [ZeusMonitor] Monitor started.
2022-12-06 19:19:49.911 [ZeusMonitor] Running indefinitely. 2022-12-06 19:19:49.911 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:19:49.911 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e86+gpu0.power.log
2022-12-06 14:20:34,131 [ZeusDataLoader(train)] train epoch 86 done: time=44.46 energy=6241.40
2022-12-06 14:20:34,135 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 0.7269
Training Epoch: 85 [2048/50176]	Loss: 0.7339
Training Epoch: 85 [3072/50176]	Loss: 0.7547
Training Epoch: 85 [4096/50176]	Loss: 0.6464
Training Epoch: 85 [5120/50176]	Loss: 0.7393
Training Epoch: 85 [6144/50176]	Loss: 0.7224
Training Epoch: 85 [7168/50176]	Loss: 0.7509
Training Epoch: 85 [8192/50176]	Loss: 0.7160
Training Epoch: 85 [9216/50176]	Loss: 0.7325
Training Epoch: 85 [10240/50176]	Loss: 0.7282
Training Epoch: 85 [11264/50176]	Loss: 0.6844
Training Epoch: 85 [12288/50176]	Loss: 0.7268
Training Epoch: 85 [13312/50176]	Loss: 0.6799
Training Epoch: 85 [14336/50176]	Loss: 0.6968
Training Epoch: 85 [15360/50176]	Loss: 0.7398
Training Epoch: 85 [16384/50176]	Loss: 0.7030
Training Epoch: 85 [17408/50176]	Loss: 0.7419
Training Epoch: 85 [18432/50176]	Loss: 0.7383
Training Epoch: 85 [19456/50176]	Loss: 0.7605
Training Epoch: 85 [20480/50176]	Loss: 0.7555
Training Epoch: 85 [21504/50176]	Loss: 0.7955
Training Epoch: 85 [22528/50176]	Loss: 0.7435
Training Epoch: 85 [23552/50176]	Loss: 0.7404
Training Epoch: 85 [24576/50176]	Loss: 0.7998
Training Epoch: 85 [25600/50176]	Loss: 0.7277
Training Epoch: 85 [26624/50176]	Loss: 0.7537
Training Epoch: 85 [27648/50176]	Loss: 0.7171
Training Epoch: 85 [28672/50176]	Loss: 0.7359
Training Epoch: 85 [29696/50176]	Loss: 0.7985
Training Epoch: 85 [30720/50176]	Loss: 0.7351
Training Epoch: 85 [31744/50176]	Loss: 0.7495
Training Epoch: 85 [32768/50176]	Loss: 0.8377
Training Epoch: 85 [33792/50176]	Loss: 0.8277
Training Epoch: 85 [34816/50176]	Loss: 0.7726
Training Epoch: 85 [35840/50176]	Loss: 0.8320
Training Epoch: 85 [36864/50176]	Loss: 0.8072
Training Epoch: 85 [37888/50176]	Loss: 0.7657
Training Epoch: 85 [38912/50176]	Loss: 0.8194
Training Epoch: 85 [39936/50176]	Loss: 0.8490
Training Epoch: 85 [40960/50176]	Loss: 0.7566
Training Epoch: 85 [41984/50176]	Loss: 0.6735
Training Epoch: 85 [43008/50176]	Loss: 0.8236
Training Epoch: 85 [44032/50176]	Loss: 0.8443
Training Epoch: 85 [45056/50176]	Loss: 0.7971
Training Epoch: 85 [46080/50176]	Loss: 0.8678
Training Epoch: 85 [47104/50176]	Loss: 0.7630
Training Epoch: 85 [48128/50176]	Loss: 0.8007
Training Epoch: 85 [49152/50176]	Loss: 0.7927
Training Epoch: 85 [50176/50176]	Loss: 0.8563
2022-12-06 19:20:38.028 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:20:38,050 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.91 energy=494.85
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Up to epoch 86: time=4188.07, energy=579318.93, cost=656115.17
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Expected next epoch: time=4235.17, energy=586006.80, cost=663580.67
2022-12-06 14:20:38,051 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 0.0062, Accuracy: 0.1580
2022-12-06 14:20:38,284 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:20:38,285 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:20:38.287 [ZeusMonitor] Monitor started.
2022-12-06 19:20:38.287 [ZeusMonitor] Running indefinitely. 2022-12-06 19:20:38.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:20:38.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e87+gpu0.power.log
2022-12-06 14:21:22,564 [ZeusDataLoader(train)] train epoch 87 done: time=44.50 energy=6245.11
2022-12-06 14:21:22,567 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 0.6650
Training Epoch: 86 [2048/50176]	Loss: 0.6881
Training Epoch: 86 [3072/50176]	Loss: 0.7664
Training Epoch: 86 [4096/50176]	Loss: 0.7293
Training Epoch: 86 [5120/50176]	Loss: 0.6985
Training Epoch: 86 [6144/50176]	Loss: 0.7192
Training Epoch: 86 [7168/50176]	Loss: 0.6936
Training Epoch: 86 [8192/50176]	Loss: 0.7766
Training Epoch: 86 [9216/50176]	Loss: 0.7261
Training Epoch: 86 [10240/50176]	Loss: 0.7210
Training Epoch: 86 [11264/50176]	Loss: 0.6881
Training Epoch: 86 [12288/50176]	Loss: 0.7059
Training Epoch: 86 [13312/50176]	Loss: 0.6793
Training Epoch: 86 [14336/50176]	Loss: 0.7129
Training Epoch: 86 [15360/50176]	Loss: 0.8220
Training Epoch: 86 [16384/50176]	Loss: 0.6542
Training Epoch: 86 [17408/50176]	Loss: 0.7141
Training Epoch: 86 [18432/50176]	Loss: 0.6792
Training Epoch: 86 [19456/50176]	Loss: 0.6902
Training Epoch: 86 [20480/50176]	Loss: 0.7728
Training Epoch: 86 [21504/50176]	Loss: 0.7689
Training Epoch: 86 [22528/50176]	Loss: 0.7859
Training Epoch: 86 [23552/50176]	Loss: 0.7439
Training Epoch: 86 [24576/50176]	Loss: 0.7796
Training Epoch: 86 [25600/50176]	Loss: 0.8403
Training Epoch: 86 [26624/50176]	Loss: 0.7266
Training Epoch: 86 [27648/50176]	Loss: 0.7879
Training Epoch: 86 [28672/50176]	Loss: 0.8131
Training Epoch: 86 [29696/50176]	Loss: 0.7516
Training Epoch: 86 [30720/50176]	Loss: 0.7786
Training Epoch: 86 [31744/50176]	Loss: 0.8063
Training Epoch: 86 [32768/50176]	Loss: 0.7810
Training Epoch: 86 [33792/50176]	Loss: 0.7429
Training Epoch: 86 [34816/50176]	Loss: 0.7302
Training Epoch: 86 [35840/50176]	Loss: 0.7548
Training Epoch: 86 [36864/50176]	Loss: 0.7494
Training Epoch: 86 [37888/50176]	Loss: 0.7975
Training Epoch: 86 [38912/50176]	Loss: 0.7510
Training Epoch: 86 [39936/50176]	Loss: 0.7950
Training Epoch: 86 [40960/50176]	Loss: 0.7851
Training Epoch: 86 [41984/50176]	Loss: 0.7431
Training Epoch: 86 [43008/50176]	Loss: 0.7213
Training Epoch: 86 [44032/50176]	Loss: 0.7780
Training Epoch: 86 [45056/50176]	Loss: 0.7840
Training Epoch: 86 [46080/50176]	Loss: 0.7798
Training Epoch: 86 [47104/50176]	Loss: 0.8040
Training Epoch: 86 [48128/50176]	Loss: 0.7539
Training Epoch: 86 [49152/50176]	Loss: 0.7537
Training Epoch: 86 [50176/50176]	Loss: 0.8215
2022-12-06 19:21:26.393 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:21:26,412 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.84 energy=478.82
2022-12-06 14:21:26,412 [ZeusDataLoader(train)] Up to epoch 87: time=4236.41, energy=586042.86, cost=663707.10
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Expected next epoch: time=4283.51, energy=592730.74, cost=671172.60
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 0.0130, Accuracy: 0.1219
2022-12-06 14:21:26,649 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:21:26,649 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:21:26.659 [ZeusMonitor] Monitor started.
2022-12-06 19:21:26.659 [ZeusMonitor] Running indefinitely. 2022-12-06 19:21:26.660 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:21:26.660 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e88+gpu0.power.log
2022-12-06 14:22:10,813 [ZeusDataLoader(train)] train epoch 88 done: time=44.39 energy=6239.37
2022-12-06 14:22:10,817 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 0.6559
Training Epoch: 87 [2048/50176]	Loss: 0.7084
Training Epoch: 87 [3072/50176]	Loss: 0.6907
Training Epoch: 87 [4096/50176]	Loss: 0.6724
Training Epoch: 87 [5120/50176]	Loss: 0.7129
Training Epoch: 87 [6144/50176]	Loss: 0.7108
Training Epoch: 87 [7168/50176]	Loss: 0.6538
Training Epoch: 87 [8192/50176]	Loss: 0.7083
Training Epoch: 87 [9216/50176]	Loss: 0.7284
Training Epoch: 87 [10240/50176]	Loss: 0.6943
Training Epoch: 87 [11264/50176]	Loss: 0.8182
Training Epoch: 87 [12288/50176]	Loss: 0.7075
Training Epoch: 87 [13312/50176]	Loss: 0.6951
Training Epoch: 87 [14336/50176]	Loss: 0.7157
Training Epoch: 87 [15360/50176]	Loss: 0.7516
Training Epoch: 87 [16384/50176]	Loss: 0.7879
Training Epoch: 87 [17408/50176]	Loss: 0.7432
Training Epoch: 87 [18432/50176]	Loss: 0.7199
Training Epoch: 87 [19456/50176]	Loss: 0.7653
Training Epoch: 87 [20480/50176]	Loss: 0.7205
Training Epoch: 87 [21504/50176]	Loss: 0.7636
Training Epoch: 87 [22528/50176]	Loss: 0.7099
Training Epoch: 87 [23552/50176]	Loss: 0.7051
Training Epoch: 87 [24576/50176]	Loss: 0.8037
Training Epoch: 87 [25600/50176]	Loss: 0.8134
Training Epoch: 87 [26624/50176]	Loss: 0.7228
Training Epoch: 87 [27648/50176]	Loss: 0.6925
Training Epoch: 87 [28672/50176]	Loss: 0.7442
Training Epoch: 87 [29696/50176]	Loss: 0.7954
Training Epoch: 87 [30720/50176]	Loss: 0.7539
Training Epoch: 87 [31744/50176]	Loss: 0.6935
Training Epoch: 87 [32768/50176]	Loss: 0.7894
Training Epoch: 87 [33792/50176]	Loss: 0.7539
Training Epoch: 87 [34816/50176]	Loss: 0.7534
Training Epoch: 87 [35840/50176]	Loss: 0.8092
Training Epoch: 87 [36864/50176]	Loss: 0.7160
Training Epoch: 87 [37888/50176]	Loss: 0.8265
Training Epoch: 87 [38912/50176]	Loss: 0.7347
Training Epoch: 87 [39936/50176]	Loss: 0.7385
Training Epoch: 87 [40960/50176]	Loss: 0.7192
Training Epoch: 87 [41984/50176]	Loss: 0.6630
Training Epoch: 87 [43008/50176]	Loss: 0.8222
Training Epoch: 87 [44032/50176]	Loss: 0.7694
Training Epoch: 87 [45056/50176]	Loss: 0.7818
Training Epoch: 87 [46080/50176]	Loss: 0.8125
Training Epoch: 87 [47104/50176]	Loss: 0.7927
Training Epoch: 87 [48128/50176]	Loss: 0.7821
Training Epoch: 87 [49152/50176]	Loss: 0.7772
Training Epoch: 87 [50176/50176]	Loss: 0.7907
2022-12-06 19:22:14.581 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:22:14,624 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.80 energy=485.31
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Up to epoch 88: time=4284.60, energy=592767.54, cost=671286.16
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Expected next epoch: time=4331.70, energy=599455.42, cost=678751.66
2022-12-06 14:22:14,626 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0093, Accuracy: 0.1143
2022-12-06 14:22:14,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:22:14,836 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:22:14.838 [ZeusMonitor] Monitor started.
2022-12-06 19:22:14.838 [ZeusMonitor] Running indefinitely. 2022-12-06 19:22:14.838 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:22:14.838 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e89+gpu0.power.log
2022-12-06 14:22:58,886 [ZeusDataLoader(train)] train epoch 89 done: time=44.25 energy=6236.96
2022-12-06 14:22:58,890 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 0.6965
Training Epoch: 88 [2048/50176]	Loss: 0.6740
Training Epoch: 88 [3072/50176]	Loss: 0.6036
Training Epoch: 88 [4096/50176]	Loss: 0.6634
Training Epoch: 88 [5120/50176]	Loss: 0.6540
Training Epoch: 88 [6144/50176]	Loss: 0.7002
Training Epoch: 88 [7168/50176]	Loss: 0.7137
Training Epoch: 88 [8192/50176]	Loss: 0.6493
Training Epoch: 88 [9216/50176]	Loss: 0.6570
Training Epoch: 88 [10240/50176]	Loss: 0.6700
Training Epoch: 88 [11264/50176]	Loss: 0.6792
Training Epoch: 88 [12288/50176]	Loss: 0.7021
Training Epoch: 88 [13312/50176]	Loss: 0.6286
Training Epoch: 88 [14336/50176]	Loss: 0.6739
Training Epoch: 88 [15360/50176]	Loss: 0.7657
Training Epoch: 88 [16384/50176]	Loss: 0.7331
Training Epoch: 88 [17408/50176]	Loss: 0.7125
Training Epoch: 88 [18432/50176]	Loss: 0.7325
Training Epoch: 88 [19456/50176]	Loss: 0.7351
Training Epoch: 88 [20480/50176]	Loss: 0.6787
Training Epoch: 88 [21504/50176]	Loss: 0.6569
Training Epoch: 88 [22528/50176]	Loss: 0.6456
Training Epoch: 88 [23552/50176]	Loss: 0.7018
Training Epoch: 88 [24576/50176]	Loss: 0.6848
Training Epoch: 88 [25600/50176]	Loss: 0.6563
Training Epoch: 88 [26624/50176]	Loss: 0.7373
Training Epoch: 88 [27648/50176]	Loss: 0.7395
Training Epoch: 88 [28672/50176]	Loss: 0.7202
Training Epoch: 88 [29696/50176]	Loss: 0.6585
Training Epoch: 88 [30720/50176]	Loss: 0.7325
Training Epoch: 88 [31744/50176]	Loss: 0.7258
Training Epoch: 88 [32768/50176]	Loss: 0.7769
Training Epoch: 88 [33792/50176]	Loss: 0.8100
Training Epoch: 88 [34816/50176]	Loss: 0.7647
Training Epoch: 88 [35840/50176]	Loss: 0.7984
Training Epoch: 88 [36864/50176]	Loss: 0.7486
Training Epoch: 88 [37888/50176]	Loss: 0.7200
Training Epoch: 88 [38912/50176]	Loss: 0.7896
Training Epoch: 88 [39936/50176]	Loss: 0.7598
Training Epoch: 88 [40960/50176]	Loss: 0.7556
Training Epoch: 88 [41984/50176]	Loss: 0.7777
Training Epoch: 88 [43008/50176]	Loss: 0.8336
Training Epoch: 88 [44032/50176]	Loss: 0.7915
Training Epoch: 88 [45056/50176]	Loss: 0.7870
Training Epoch: 88 [46080/50176]	Loss: 0.7633
Training Epoch: 88 [47104/50176]	Loss: 0.7459
Training Epoch: 88 [48128/50176]	Loss: 0.7239
Training Epoch: 88 [49152/50176]	Loss: 0.7911
Training Epoch: 88 [50176/50176]	Loss: 0.8256
2022-12-06 19:23:02.641 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:23:02,659 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.76 energy=470.20
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Up to epoch 89: time=4332.61, energy=599474.70, cost=678841.00
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Expected next epoch: time=4379.72, energy=606162.58, cost=686306.50
2022-12-06 14:23:02,660 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 0.0170, Accuracy: 0.0243
2022-12-06 14:23:02,917 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:23:02,917 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:23:02.919 [ZeusMonitor] Monitor started.
2022-12-06 19:23:02.919 [ZeusMonitor] Running indefinitely. 2022-12-06 19:23:02.919 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:23:02.919 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e90+gpu0.power.log
2022-12-06 14:23:46,958 [ZeusDataLoader(train)] train epoch 90 done: time=44.29 energy=6223.77
2022-12-06 14:23:46,962 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 0.6058
Training Epoch: 89 [2048/50176]	Loss: 0.6553
Training Epoch: 89 [3072/50176]	Loss: 0.6678
Training Epoch: 89 [4096/50176]	Loss: 0.6831
Training Epoch: 89 [5120/50176]	Loss: 0.6368
Training Epoch: 89 [6144/50176]	Loss: 0.7060
Training Epoch: 89 [7168/50176]	Loss: 0.6655
Training Epoch: 89 [8192/50176]	Loss: 0.6472
Training Epoch: 89 [9216/50176]	Loss: 0.6889
Training Epoch: 89 [10240/50176]	Loss: 0.7470
Training Epoch: 89 [11264/50176]	Loss: 0.6983
Training Epoch: 89 [12288/50176]	Loss: 0.6820
Training Epoch: 89 [13312/50176]	Loss: 0.7173
Training Epoch: 89 [14336/50176]	Loss: 0.7387
Training Epoch: 89 [15360/50176]	Loss: 0.6934
Training Epoch: 89 [16384/50176]	Loss: 0.6869
Training Epoch: 89 [17408/50176]	Loss: 0.7647
Training Epoch: 89 [18432/50176]	Loss: 0.6526
Training Epoch: 89 [19456/50176]	Loss: 0.6557
Training Epoch: 89 [20480/50176]	Loss: 0.6515
Training Epoch: 89 [21504/50176]	Loss: 0.7544
Training Epoch: 89 [22528/50176]	Loss: 0.6284
Training Epoch: 89 [23552/50176]	Loss: 0.7807
Training Epoch: 89 [24576/50176]	Loss: 0.7237
Training Epoch: 89 [25600/50176]	Loss: 0.6612
Training Epoch: 89 [26624/50176]	Loss: 0.7028
Training Epoch: 89 [27648/50176]	Loss: 0.6516
Training Epoch: 89 [28672/50176]	Loss: 0.6870
Training Epoch: 89 [29696/50176]	Loss: 0.6863
Training Epoch: 89 [30720/50176]	Loss: 0.7477
Training Epoch: 89 [31744/50176]	Loss: 0.7604
Training Epoch: 89 [32768/50176]	Loss: 0.7783
Training Epoch: 89 [33792/50176]	Loss: 0.6714
Training Epoch: 89 [34816/50176]	Loss: 0.7891
Training Epoch: 89 [35840/50176]	Loss: 0.7665
Training Epoch: 89 [36864/50176]	Loss: 0.7621
Training Epoch: 89 [37888/50176]	Loss: 0.7601
Training Epoch: 89 [38912/50176]	Loss: 0.8097
Training Epoch: 89 [39936/50176]	Loss: 0.6931
Training Epoch: 89 [40960/50176]	Loss: 0.7594
Training Epoch: 89 [41984/50176]	Loss: 0.7617
Training Epoch: 89 [43008/50176]	Loss: 0.7986
Training Epoch: 89 [44032/50176]	Loss: 0.7082
Training Epoch: 89 [45056/50176]	Loss: 0.7347
Training Epoch: 89 [46080/50176]	Loss: 0.7396
Training Epoch: 89 [47104/50176]	Loss: 0.7126
Training Epoch: 89 [48128/50176]	Loss: 0.7327
Training Epoch: 89 [49152/50176]	Loss: 0.8621
Training Epoch: 89 [50176/50176]	Loss: 0.7619
2022-12-06 19:23:50.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:23:50,779 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.81 energy=484.37
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Up to epoch 90: time=4380.71, energy=606182.84, cost=686403.78
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Expected next epoch: time=4427.82, energy=612870.72, cost=693869.28
2022-12-06 14:23:50,780 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0110, Accuracy: 0.1212
2022-12-06 14:23:51,013 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:23:51,014 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:23:51.036 [ZeusMonitor] Monitor started.
2022-12-06 19:23:51.036 [ZeusMonitor] Running indefinitely. 2022-12-06 19:23:51.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:23:51.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e91+gpu0.power.log
2022-12-06 14:24:35,436 [ZeusDataLoader(train)] train epoch 91 done: time=44.65 energy=6257.02
2022-12-06 14:24:35,440 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 0.6646
Training Epoch: 90 [2048/50176]	Loss: 0.6327
Training Epoch: 90 [3072/50176]	Loss: 0.6310
Training Epoch: 90 [4096/50176]	Loss: 0.6645
Training Epoch: 90 [5120/50176]	Loss: 0.6459
Training Epoch: 90 [6144/50176]	Loss: 0.6466
Training Epoch: 90 [7168/50176]	Loss: 0.6659
Training Epoch: 90 [8192/50176]	Loss: 0.7141
Training Epoch: 90 [9216/50176]	Loss: 0.6767
Training Epoch: 90 [10240/50176]	Loss: 0.6688
Training Epoch: 90 [11264/50176]	Loss: 0.6366
Training Epoch: 90 [12288/50176]	Loss: 0.6928
Training Epoch: 90 [13312/50176]	Loss: 0.6495
Training Epoch: 90 [14336/50176]	Loss: 0.7060
Training Epoch: 90 [15360/50176]	Loss: 0.6755
Training Epoch: 90 [16384/50176]	Loss: 0.6803
Training Epoch: 90 [17408/50176]	Loss: 0.7093
Training Epoch: 90 [18432/50176]	Loss: 0.6574
Training Epoch: 90 [19456/50176]	Loss: 0.7128
Training Epoch: 90 [20480/50176]	Loss: 0.6248
Training Epoch: 90 [21504/50176]	Loss: 0.7302
Training Epoch: 90 [22528/50176]	Loss: 0.6581
Training Epoch: 90 [23552/50176]	Loss: 0.6761
Training Epoch: 90 [24576/50176]	Loss: 0.6559
Training Epoch: 90 [25600/50176]	Loss: 0.7127
Training Epoch: 90 [26624/50176]	Loss: 0.7596
Training Epoch: 90 [27648/50176]	Loss: 0.6869
Training Epoch: 90 [28672/50176]	Loss: 0.7115
Training Epoch: 90 [29696/50176]	Loss: 0.6765
Training Epoch: 90 [30720/50176]	Loss: 0.6832
Training Epoch: 90 [31744/50176]	Loss: 0.7422
Training Epoch: 90 [32768/50176]	Loss: 0.6973
Training Epoch: 90 [33792/50176]	Loss: 0.7178
Training Epoch: 90 [34816/50176]	Loss: 0.7136
Training Epoch: 90 [35840/50176]	Loss: 0.8142
Training Epoch: 90 [36864/50176]	Loss: 0.6378
Training Epoch: 90 [37888/50176]	Loss: 0.7136
Training Epoch: 90 [38912/50176]	Loss: 0.8554
Training Epoch: 90 [39936/50176]	Loss: 0.7751
Training Epoch: 90 [40960/50176]	Loss: 0.7656
Training Epoch: 90 [41984/50176]	Loss: 0.6809
Training Epoch: 90 [43008/50176]	Loss: 0.7070
Training Epoch: 90 [44032/50176]	Loss: 0.7637
Training Epoch: 90 [45056/50176]	Loss: 0.7202
Training Epoch: 90 [46080/50176]	Loss: 0.7365
Training Epoch: 90 [47104/50176]	Loss: 0.7208
Training Epoch: 90 [48128/50176]	Loss: 0.7870
Training Epoch: 90 [49152/50176]	Loss: 0.7701
Training Epoch: 90 [50176/50176]	Loss: 0.7252
2022-12-06 19:24:39.307 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:24:39,346 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.90 energy=494.31
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Up to epoch 91: time=4429.26, energy=612934.17, cost=694027.24
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Expected next epoch: time=4476.36, energy=619622.05, cost=701492.74
2022-12-06 14:24:39,347 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 0.0085, Accuracy: 0.2354
2022-12-06 14:24:39,596 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:24:39,597 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:24:39.599 [ZeusMonitor] Monitor started.
2022-12-06 19:24:39.599 [ZeusMonitor] Running indefinitely. 2022-12-06 19:24:39.599 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:24:39.599 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e92+gpu0.power.log
2022-12-06 14:25:23,883 [ZeusDataLoader(train)] train epoch 92 done: time=44.53 energy=6254.16
2022-12-06 14:25:23,887 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 0.6439
Training Epoch: 91 [2048/50176]	Loss: 0.6367
Training Epoch: 91 [3072/50176]	Loss: 0.7222
Training Epoch: 91 [4096/50176]	Loss: 0.6185
Training Epoch: 91 [5120/50176]	Loss: 0.6928
Training Epoch: 91 [6144/50176]	Loss: 0.6750
Training Epoch: 91 [7168/50176]	Loss: 0.6927
Training Epoch: 91 [8192/50176]	Loss: 0.7536
Training Epoch: 91 [9216/50176]	Loss: 0.7216
Training Epoch: 91 [10240/50176]	Loss: 0.6770
Training Epoch: 91 [11264/50176]	Loss: 0.7166
Training Epoch: 91 [12288/50176]	Loss: 0.6878
Training Epoch: 91 [13312/50176]	Loss: 0.6907
Training Epoch: 91 [14336/50176]	Loss: 0.6466
Training Epoch: 91 [15360/50176]	Loss: 0.6660
Training Epoch: 91 [16384/50176]	Loss: 0.7543
Training Epoch: 91 [17408/50176]	Loss: 0.6855
Training Epoch: 91 [18432/50176]	Loss: 0.6835
Training Epoch: 91 [19456/50176]	Loss: 0.6821
Training Epoch: 91 [20480/50176]	Loss: 0.7449
Training Epoch: 91 [21504/50176]	Loss: 0.6788
Training Epoch: 91 [22528/50176]	Loss: 0.6399
Training Epoch: 91 [23552/50176]	Loss: 0.7424
Training Epoch: 91 [24576/50176]	Loss: 0.6572
Training Epoch: 91 [25600/50176]	Loss: 0.6565
Training Epoch: 91 [26624/50176]	Loss: 0.7252
Training Epoch: 91 [27648/50176]	Loss: 0.5822
Training Epoch: 91 [28672/50176]	Loss: 0.6707
Training Epoch: 91 [29696/50176]	Loss: 0.7445
Training Epoch: 91 [30720/50176]	Loss: 0.7044
Training Epoch: 91 [31744/50176]	Loss: 0.7015
Training Epoch: 91 [32768/50176]	Loss: 0.6928
Training Epoch: 91 [33792/50176]	Loss: 0.6787
Training Epoch: 91 [34816/50176]	Loss: 0.6863
Training Epoch: 91 [35840/50176]	Loss: 0.6988
Training Epoch: 91 [36864/50176]	Loss: 0.7069
Training Epoch: 91 [37888/50176]	Loss: 0.8245
Training Epoch: 91 [38912/50176]	Loss: 0.6856
Training Epoch: 91 [39936/50176]	Loss: 0.7295
Training Epoch: 91 [40960/50176]	Loss: 0.7086
Training Epoch: 91 [41984/50176]	Loss: 0.7092
Training Epoch: 91 [43008/50176]	Loss: 0.7636
Training Epoch: 91 [44032/50176]	Loss: 0.6904
Training Epoch: 91 [45056/50176]	Loss: 0.7681
Training Epoch: 91 [46080/50176]	Loss: 0.7252
Training Epoch: 91 [47104/50176]	Loss: 0.7197
Training Epoch: 91 [48128/50176]	Loss: 0.7294
Training Epoch: 91 [49152/50176]	Loss: 0.6769
Training Epoch: 91 [50176/50176]	Loss: 0.7413
2022-12-06 19:25:27.674 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:25:27,690 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.80 energy=464.18
2022-12-06 14:25:27,690 [ZeusDataLoader(train)] Up to epoch 92: time=4477.58, energy=619652.51, cost=701614.70
2022-12-06 14:25:27,690 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:25:27,691 [ZeusDataLoader(train)] Expected next epoch: time=4524.69, energy=626340.39, cost=709080.20
2022-12-06 14:25:27,691 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 0.0287, Accuracy: 0.0604
2022-12-06 14:25:27,929 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:25:27,930 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:25:27.932 [ZeusMonitor] Monitor started.
2022-12-06 19:25:27.932 [ZeusMonitor] Running indefinitely. 2022-12-06 19:25:27.932 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:25:27.932 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e93+gpu0.power.log
2022-12-06 14:26:12,238 [ZeusDataLoader(train)] train epoch 93 done: time=44.54 energy=6239.11
2022-12-06 14:26:12,241 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 0.7169
Training Epoch: 92 [2048/50176]	Loss: 0.6417
Training Epoch: 92 [3072/50176]	Loss: 0.6469
Training Epoch: 92 [4096/50176]	Loss: 0.6171
Training Epoch: 92 [5120/50176]	Loss: 0.6876
Training Epoch: 92 [6144/50176]	Loss: 0.6485
Training Epoch: 92 [7168/50176]	Loss: 0.6683
Training Epoch: 92 [8192/50176]	Loss: 0.6293
Training Epoch: 92 [9216/50176]	Loss: 0.6456
Training Epoch: 92 [10240/50176]	Loss: 0.6021
Training Epoch: 92 [11264/50176]	Loss: 0.6060
Training Epoch: 92 [12288/50176]	Loss: 0.6770
Training Epoch: 92 [13312/50176]	Loss: 0.6710
Training Epoch: 92 [14336/50176]	Loss: 0.6773
Training Epoch: 92 [15360/50176]	Loss: 0.7008
Training Epoch: 92 [16384/50176]	Loss: 0.6097
Training Epoch: 92 [17408/50176]	Loss: 0.6359
Training Epoch: 92 [18432/50176]	Loss: 0.6715
Training Epoch: 92 [19456/50176]	Loss: 0.7501
Training Epoch: 92 [20480/50176]	Loss: 0.6873
Training Epoch: 92 [21504/50176]	Loss: 0.6750
Training Epoch: 92 [22528/50176]	Loss: 0.6930
Training Epoch: 92 [23552/50176]	Loss: 0.6959
Training Epoch: 92 [24576/50176]	Loss: 0.6257
Training Epoch: 92 [25600/50176]	Loss: 0.6787
Training Epoch: 92 [26624/50176]	Loss: 0.7316
Training Epoch: 92 [27648/50176]	Loss: 0.6929
Training Epoch: 92 [28672/50176]	Loss: 0.6931
Training Epoch: 92 [29696/50176]	Loss: 0.6216
Training Epoch: 92 [30720/50176]	Loss: 0.6576
Training Epoch: 92 [31744/50176]	Loss: 0.6713
Training Epoch: 92 [32768/50176]	Loss: 0.7067
Training Epoch: 92 [33792/50176]	Loss: 0.7006
Training Epoch: 92 [34816/50176]	Loss: 0.7505
Training Epoch: 92 [35840/50176]	Loss: 0.6943
Training Epoch: 92 [36864/50176]	Loss: 0.6393
Training Epoch: 92 [37888/50176]	Loss: 0.7015
Training Epoch: 92 [38912/50176]	Loss: 0.7390
Training Epoch: 92 [39936/50176]	Loss: 0.6876
Training Epoch: 92 [40960/50176]	Loss: 0.6726
Training Epoch: 92 [41984/50176]	Loss: 0.7506
Training Epoch: 92 [43008/50176]	Loss: 0.6441
Training Epoch: 92 [44032/50176]	Loss: 0.7319
Training Epoch: 92 [45056/50176]	Loss: 0.7230
Training Epoch: 92 [46080/50176]	Loss: 0.7017
Training Epoch: 92 [47104/50176]	Loss: 0.7426
Training Epoch: 92 [48128/50176]	Loss: 0.6725
Training Epoch: 92 [49152/50176]	Loss: 0.6818
Training Epoch: 92 [50176/50176]	Loss: 0.6798
2022-12-06 19:26:15.958 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:26:15,976 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.73 energy=472.78
2022-12-06 14:26:15,976 [ZeusDataLoader(train)] Up to epoch 93: time=4525.85, energy=626364.40, cost=709193.88
2022-12-06 14:26:15,977 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:26:15,977 [ZeusDataLoader(train)] Expected next epoch: time=4572.95, energy=633052.27, cost=716659.37
2022-12-06 14:26:15,978 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0073, Accuracy: 0.2205
2022-12-06 14:26:16,226 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:26:16,226 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:26:16.230 [ZeusMonitor] Monitor started.
2022-12-06 19:26:16.230 [ZeusMonitor] Running indefinitely. 2022-12-06 19:26:16.230 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:26:16.230 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e94+gpu0.power.log
2022-12-06 14:27:00,213 [ZeusDataLoader(train)] train epoch 94 done: time=44.23 energy=6227.59
2022-12-06 14:27:00,217 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 0.6070
Training Epoch: 93 [2048/50176]	Loss: 0.5753
Training Epoch: 93 [3072/50176]	Loss: 0.5715
Training Epoch: 93 [4096/50176]	Loss: 0.6394
Training Epoch: 93 [5120/50176]	Loss: 0.7135
Training Epoch: 93 [6144/50176]	Loss: 0.6488
Training Epoch: 93 [7168/50176]	Loss: 0.5658
Training Epoch: 93 [8192/50176]	Loss: 0.5745
Training Epoch: 93 [9216/50176]	Loss: 0.6568
Training Epoch: 93 [10240/50176]	Loss: 0.6026
Training Epoch: 93 [11264/50176]	Loss: 0.6697
Training Epoch: 93 [12288/50176]	Loss: 0.6159
Training Epoch: 93 [13312/50176]	Loss: 0.6692
Training Epoch: 93 [14336/50176]	Loss: 0.7035
Training Epoch: 93 [15360/50176]	Loss: 0.6442
Training Epoch: 93 [16384/50176]	Loss: 0.5884
Training Epoch: 93 [17408/50176]	Loss: 0.6567
Training Epoch: 93 [18432/50176]	Loss: 0.6282
Training Epoch: 93 [19456/50176]	Loss: 0.6777
Training Epoch: 93 [20480/50176]	Loss: 0.6658
Training Epoch: 93 [21504/50176]	Loss: 0.7118
Training Epoch: 93 [22528/50176]	Loss: 0.6085
Training Epoch: 93 [23552/50176]	Loss: 0.6665
Training Epoch: 93 [24576/50176]	Loss: 0.6709
Training Epoch: 93 [25600/50176]	Loss: 0.6919
Training Epoch: 93 [26624/50176]	Loss: 0.6973
Training Epoch: 93 [27648/50176]	Loss: 0.6484
Training Epoch: 93 [28672/50176]	Loss: 0.6444
Training Epoch: 93 [29696/50176]	Loss: 0.6654
Training Epoch: 93 [30720/50176]	Loss: 0.6829
Training Epoch: 93 [31744/50176]	Loss: 0.6750
Training Epoch: 93 [32768/50176]	Loss: 0.6854
Training Epoch: 93 [33792/50176]	Loss: 0.7097
Training Epoch: 93 [34816/50176]	Loss: 0.6770
Training Epoch: 93 [35840/50176]	Loss: 0.5991
Training Epoch: 93 [36864/50176]	Loss: 0.7007
Training Epoch: 93 [37888/50176]	Loss: 0.7307
Training Epoch: 93 [38912/50176]	Loss: 0.7305
Training Epoch: 93 [39936/50176]	Loss: 0.6562
Training Epoch: 93 [40960/50176]	Loss: 0.7287
Training Epoch: 93 [41984/50176]	Loss: 0.7261
Training Epoch: 93 [43008/50176]	Loss: 0.7425
Training Epoch: 93 [44032/50176]	Loss: 0.7544
Training Epoch: 93 [45056/50176]	Loss: 0.7456
Training Epoch: 93 [46080/50176]	Loss: 0.7214
Training Epoch: 93 [47104/50176]	Loss: 0.6572
Training Epoch: 93 [48128/50176]	Loss: 0.6479
Training Epoch: 93 [49152/50176]	Loss: 0.7475
Training Epoch: 93 [50176/50176]	Loss: 0.7547
2022-12-06 19:27:03.969 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:27:04,015 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.79 energy=480.65
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Up to epoch 94: time=4573.87, energy=633072.63, cost=716749.61
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Expected next epoch: time=4620.97, energy=639760.51, cost=724215.11
2022-12-06 14:27:04,016 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 0.0184, Accuracy: 0.0847
2022-12-06 14:27:04,209 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:27:04,210 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:27:04.213 [ZeusMonitor] Monitor started.
2022-12-06 19:27:04.213 [ZeusMonitor] Running indefinitely. 2022-12-06 19:27:04.213 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:27:04.213 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e95+gpu0.power.log
2022-12-06 14:27:48,277 [ZeusDataLoader(train)] train epoch 95 done: time=44.25 energy=6232.27
2022-12-06 14:27:48,280 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 0.5970
Training Epoch: 94 [2048/50176]	Loss: 0.6546
Training Epoch: 94 [3072/50176]	Loss: 0.5799
Training Epoch: 94 [4096/50176]	Loss: 0.6133
Training Epoch: 94 [5120/50176]	Loss: 0.5844
Training Epoch: 94 [6144/50176]	Loss: 0.6076
Training Epoch: 94 [7168/50176]	Loss: 0.6032
Training Epoch: 94 [8192/50176]	Loss: 0.6118
Training Epoch: 94 [9216/50176]	Loss: 0.6218
Training Epoch: 94 [10240/50176]	Loss: 0.6865
Training Epoch: 94 [11264/50176]	Loss: 0.5332
Training Epoch: 94 [12288/50176]	Loss: 0.5679
Training Epoch: 94 [13312/50176]	Loss: 0.6495
Training Epoch: 94 [14336/50176]	Loss: 0.6264
Training Epoch: 94 [15360/50176]	Loss: 0.6596
Training Epoch: 94 [16384/50176]	Loss: 0.6050
Training Epoch: 94 [17408/50176]	Loss: 0.6248
Training Epoch: 94 [18432/50176]	Loss: 0.6791
Training Epoch: 94 [19456/50176]	Loss: 0.6396
Training Epoch: 94 [20480/50176]	Loss: 0.6915
Training Epoch: 94 [21504/50176]	Loss: 0.6084
Training Epoch: 94 [22528/50176]	Loss: 0.7165
Training Epoch: 94 [23552/50176]	Loss: 0.6722
Training Epoch: 94 [24576/50176]	Loss: 0.6545
Training Epoch: 94 [25600/50176]	Loss: 0.6040
Training Epoch: 94 [26624/50176]	Loss: 0.6929
Training Epoch: 94 [27648/50176]	Loss: 0.6666
Training Epoch: 94 [28672/50176]	Loss: 0.6522
Training Epoch: 94 [29696/50176]	Loss: 0.6551
Training Epoch: 94 [30720/50176]	Loss: 0.6480
Training Epoch: 94 [31744/50176]	Loss: 0.7120
Training Epoch: 94 [32768/50176]	Loss: 0.6886
Training Epoch: 94 [33792/50176]	Loss: 0.6324
Training Epoch: 94 [34816/50176]	Loss: 0.7520
Training Epoch: 94 [35840/50176]	Loss: 0.6624
Training Epoch: 94 [36864/50176]	Loss: 0.7290
Training Epoch: 94 [37888/50176]	Loss: 0.6074
Training Epoch: 94 [38912/50176]	Loss: 0.7194
Training Epoch: 94 [39936/50176]	Loss: 0.6665
Training Epoch: 94 [40960/50176]	Loss: 0.7241
Training Epoch: 94 [41984/50176]	Loss: 0.7179
Training Epoch: 94 [43008/50176]	Loss: 0.6791
Training Epoch: 94 [44032/50176]	Loss: 0.7574
Training Epoch: 94 [45056/50176]	Loss: 0.7634
Training Epoch: 94 [46080/50176]	Loss: 0.7387
Training Epoch: 94 [47104/50176]	Loss: 0.6211
Training Epoch: 94 [48128/50176]	Loss: 0.7291
Training Epoch: 94 [49152/50176]	Loss: 0.6651
Training Epoch: 94 [50176/50176]	Loss: 0.7190
2022-12-06 19:27:52.027 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:27:52,076 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.79 energy=476.19
2022-12-06 14:27:52,076 [ZeusDataLoader(train)] Up to epoch 95: time=4621.91, energy=639781.10, cost=724307.36
2022-12-06 14:27:52,076 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:27:52,077 [ZeusDataLoader(train)] Expected next epoch: time=4669.01, energy=646468.98, cost=731772.86
2022-12-06 14:27:52,077 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 0.0155, Accuracy: 0.0940
2022-12-06 14:27:52,308 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:27:52,309 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:27:52.311 [ZeusMonitor] Monitor started.
2022-12-06 19:27:52.311 [ZeusMonitor] Running indefinitely. 2022-12-06 19:27:52.311 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:27:52.311 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e96+gpu0.power.log
2022-12-06 14:28:36,359 [ZeusDataLoader(train)] train epoch 96 done: time=44.27 energy=6226.11
2022-12-06 14:28:36,362 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 0.5591
Training Epoch: 95 [2048/50176]	Loss: 0.5889
Training Epoch: 95 [3072/50176]	Loss: 0.6502
Training Epoch: 95 [4096/50176]	Loss: 0.6051
Training Epoch: 95 [5120/50176]	Loss: 0.6593
Training Epoch: 95 [6144/50176]	Loss: 0.6465
Training Epoch: 95 [7168/50176]	Loss: 0.6058
Training Epoch: 95 [8192/50176]	Loss: 0.6639
Training Epoch: 95 [9216/50176]	Loss: 0.5978
Training Epoch: 95 [10240/50176]	Loss: 0.5944
Training Epoch: 95 [11264/50176]	Loss: 0.6571
Training Epoch: 95 [12288/50176]	Loss: 0.6294
Training Epoch: 95 [13312/50176]	Loss: 0.6969
Training Epoch: 95 [14336/50176]	Loss: 0.5916
Training Epoch: 95 [15360/50176]	Loss: 0.6423
Training Epoch: 95 [16384/50176]	Loss: 0.6257
Training Epoch: 95 [17408/50176]	Loss: 0.6355
Training Epoch: 95 [18432/50176]	Loss: 0.6214
Training Epoch: 95 [19456/50176]	Loss: 0.6956
Training Epoch: 95 [20480/50176]	Loss: 0.6640
Training Epoch: 95 [21504/50176]	Loss: 0.6702
Training Epoch: 95 [22528/50176]	Loss: 0.6310
Training Epoch: 95 [23552/50176]	Loss: 0.6381
Training Epoch: 95 [24576/50176]	Loss: 0.6545
Training Epoch: 95 [25600/50176]	Loss: 0.6881
Training Epoch: 95 [26624/50176]	Loss: 0.7047
Training Epoch: 95 [27648/50176]	Loss: 0.6329
Training Epoch: 95 [28672/50176]	Loss: 0.6224
Training Epoch: 95 [29696/50176]	Loss: 0.7010
Training Epoch: 95 [30720/50176]	Loss: 0.6812
Training Epoch: 95 [31744/50176]	Loss: 0.7132
Training Epoch: 95 [32768/50176]	Loss: 0.7178
Training Epoch: 95 [33792/50176]	Loss: 0.6882
Training Epoch: 95 [34816/50176]	Loss: 0.6631
Training Epoch: 95 [35840/50176]	Loss: 0.7195
Training Epoch: 95 [36864/50176]	Loss: 0.6265
Training Epoch: 95 [37888/50176]	Loss: 0.6832
Training Epoch: 95 [38912/50176]	Loss: 0.6821
Training Epoch: 95 [39936/50176]	Loss: 0.6878
Training Epoch: 95 [40960/50176]	Loss: 0.6483
Training Epoch: 95 [41984/50176]	Loss: 0.7668
Training Epoch: 95 [43008/50176]	Loss: 0.6536
Training Epoch: 95 [44032/50176]	Loss: 0.6736
Training Epoch: 95 [45056/50176]	Loss: 0.6752
Training Epoch: 95 [46080/50176]	Loss: 0.6348
Training Epoch: 95 [47104/50176]	Loss: 0.7291
Training Epoch: 95 [48128/50176]	Loss: 0.6626
Training Epoch: 95 [49152/50176]	Loss: 0.6349
Training Epoch: 95 [50176/50176]	Loss: 0.6450
2022-12-06 19:28:40.045 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:28:40,058 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.69 energy=471.83
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Up to epoch 96: time=4669.87, energy=646479.03, cost=731852.92
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Expected next epoch: time=4716.97, energy=653166.91, cost=739318.41
2022-12-06 14:28:40,059 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 0.0113, Accuracy: 0.0443
2022-12-06 14:28:40,299 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:28:40,299 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:28:40.301 [ZeusMonitor] Monitor started.
2022-12-06 19:28:40.301 [ZeusMonitor] Running indefinitely. 2022-12-06 19:28:40.301 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:28:40.301 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e97+gpu0.power.log
2022-12-06 14:29:24,141 [ZeusDataLoader(train)] train epoch 97 done: time=44.07 energy=6215.18
2022-12-06 14:29:24,145 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 0.5812
Training Epoch: 96 [2048/50176]	Loss: 0.6084
Training Epoch: 96 [3072/50176]	Loss: 0.6263
Training Epoch: 96 [4096/50176]	Loss: 0.5543
Training Epoch: 96 [5120/50176]	Loss: 0.5743
Training Epoch: 96 [6144/50176]	Loss: 0.6084
Training Epoch: 96 [7168/50176]	Loss: 0.6320
Training Epoch: 96 [8192/50176]	Loss: 0.5844
Training Epoch: 96 [9216/50176]	Loss: 0.6284
Training Epoch: 96 [10240/50176]	Loss: 0.5835
Training Epoch: 96 [11264/50176]	Loss: 0.6151
Training Epoch: 96 [12288/50176]	Loss: 0.6111
Training Epoch: 96 [13312/50176]	Loss: 0.5941
Training Epoch: 96 [14336/50176]	Loss: 0.6779
Training Epoch: 96 [15360/50176]	Loss: 0.6502
Training Epoch: 96 [16384/50176]	Loss: 0.6609
Training Epoch: 96 [17408/50176]	Loss: 0.6296
Training Epoch: 96 [18432/50176]	Loss: 0.5960
Training Epoch: 96 [19456/50176]	Loss: 0.6622
Training Epoch: 96 [20480/50176]	Loss: 0.6340
Training Epoch: 96 [21504/50176]	Loss: 0.7045
Training Epoch: 96 [22528/50176]	Loss: 0.6640
Training Epoch: 96 [23552/50176]	Loss: 0.6529
Training Epoch: 96 [24576/50176]	Loss: 0.6422
Training Epoch: 96 [25600/50176]	Loss: 0.6715
Training Epoch: 96 [26624/50176]	Loss: 0.5953
Training Epoch: 96 [27648/50176]	Loss: 0.6506
Training Epoch: 96 [28672/50176]	Loss: 0.7133
Training Epoch: 96 [29696/50176]	Loss: 0.6752
Training Epoch: 96 [30720/50176]	Loss: 0.6776
Training Epoch: 96 [31744/50176]	Loss: 0.6052
Training Epoch: 96 [32768/50176]	Loss: 0.6442
Training Epoch: 96 [33792/50176]	Loss: 0.6269
Training Epoch: 96 [34816/50176]	Loss: 0.7002
Training Epoch: 96 [35840/50176]	Loss: 0.6823
Training Epoch: 96 [36864/50176]	Loss: 0.6702
Training Epoch: 96 [37888/50176]	Loss: 0.7315
Training Epoch: 96 [38912/50176]	Loss: 0.7512
Training Epoch: 96 [39936/50176]	Loss: 0.7056
Training Epoch: 96 [40960/50176]	Loss: 0.6619
Training Epoch: 96 [41984/50176]	Loss: 0.6666
Training Epoch: 96 [43008/50176]	Loss: 0.7296
Training Epoch: 96 [44032/50176]	Loss: 0.6917
Training Epoch: 96 [45056/50176]	Loss: 0.7185
Training Epoch: 96 [46080/50176]	Loss: 0.6978
Training Epoch: 96 [47104/50176]	Loss: 0.6958
Training Epoch: 96 [48128/50176]	Loss: 0.6693
Training Epoch: 96 [49152/50176]	Loss: 0.6428
Training Epoch: 96 [50176/50176]	Loss: 0.7295
2022-12-06 19:29:28.008 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:29:28,064 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.91 energy=490.12
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Up to epoch 97: time=4717.85, energy=653184.33, cost=739404.29
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Expected next epoch: time=4764.96, energy=659872.21, cost=746869.78
2022-12-06 14:29:28,065 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 0.0139, Accuracy: 0.1463
2022-12-06 14:29:28,358 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:29:28,358 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:29:28.360 [ZeusMonitor] Monitor started.
2022-12-06 19:29:28.360 [ZeusMonitor] Running indefinitely. 2022-12-06 19:29:28.360 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:29:28.360 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e98+gpu0.power.log
2022-12-06 14:30:12,163 [ZeusDataLoader(train)] train epoch 98 done: time=44.09 energy=6215.38
2022-12-06 14:30:12,167 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 0.5763
Training Epoch: 97 [2048/50176]	Loss: 0.5667
Training Epoch: 97 [3072/50176]	Loss: 0.6655
Training Epoch: 97 [4096/50176]	Loss: 0.6051
Training Epoch: 97 [5120/50176]	Loss: 0.6232
Training Epoch: 97 [6144/50176]	Loss: 0.6017
Training Epoch: 97 [7168/50176]	Loss: 0.6250
Training Epoch: 97 [8192/50176]	Loss: 0.6186
Training Epoch: 97 [9216/50176]	Loss: 0.6068
Training Epoch: 97 [10240/50176]	Loss: 0.6235
Training Epoch: 97 [11264/50176]	Loss: 0.5829
Training Epoch: 97 [12288/50176]	Loss: 0.5880
Training Epoch: 97 [13312/50176]	Loss: 0.6159
Training Epoch: 97 [14336/50176]	Loss: 0.6457
Training Epoch: 97 [15360/50176]	Loss: 0.6355
Training Epoch: 97 [16384/50176]	Loss: 0.6029
Training Epoch: 97 [17408/50176]	Loss: 0.6038
Training Epoch: 97 [18432/50176]	Loss: 0.5852
Training Epoch: 97 [19456/50176]	Loss: 0.6391
Training Epoch: 97 [20480/50176]	Loss: 0.6503
Training Epoch: 97 [21504/50176]	Loss: 0.6516
Training Epoch: 97 [22528/50176]	Loss: 0.6485
Training Epoch: 97 [23552/50176]	Loss: 0.6319
Training Epoch: 97 [24576/50176]	Loss: 0.6145
Training Epoch: 97 [25600/50176]	Loss: 0.6962
Training Epoch: 97 [26624/50176]	Loss: 0.5972
Training Epoch: 97 [27648/50176]	Loss: 0.6044
Training Epoch: 97 [28672/50176]	Loss: 0.5922
Training Epoch: 97 [29696/50176]	Loss: 0.6963
Training Epoch: 97 [30720/50176]	Loss: 0.6220
Training Epoch: 97 [31744/50176]	Loss: 0.6705
Training Epoch: 97 [32768/50176]	Loss: 0.6225
Training Epoch: 97 [33792/50176]	Loss: 0.6504
Training Epoch: 97 [34816/50176]	Loss: 0.6809
Training Epoch: 97 [35840/50176]	Loss: 0.6741
Training Epoch: 97 [36864/50176]	Loss: 0.6993
Training Epoch: 97 [37888/50176]	Loss: 0.6632
Training Epoch: 97 [38912/50176]	Loss: 0.7134
Training Epoch: 97 [39936/50176]	Loss: 0.6464
Training Epoch: 97 [40960/50176]	Loss: 0.5995
Training Epoch: 97 [41984/50176]	Loss: 0.5877
Training Epoch: 97 [43008/50176]	Loss: 0.6464
Training Epoch: 97 [44032/50176]	Loss: 0.7304
Training Epoch: 97 [45056/50176]	Loss: 0.7282
Training Epoch: 97 [46080/50176]	Loss: 0.6617
Training Epoch: 97 [47104/50176]	Loss: 0.6661
Training Epoch: 97 [48128/50176]	Loss: 0.5900
Training Epoch: 97 [49152/50176]	Loss: 0.6963
Training Epoch: 97 [50176/50176]	Loss: 0.7139
2022-12-06 19:30:16.022 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:30:16,046 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.87 energy=479.89
2022-12-06 14:30:16,046 [ZeusDataLoader(train)] Up to epoch 98: time=4765.82, energy=659879.60, cost=746948.61
2022-12-06 14:30:16,047 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:30:16,047 [ZeusDataLoader(train)] Expected next epoch: time=4812.92, energy=666567.48, cost=754414.11
2022-12-06 14:30:16,048 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0093, Accuracy: 0.2004
2022-12-06 14:30:16,273 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:30:16,274 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:30:16.288 [ZeusMonitor] Monitor started.
2022-12-06 19:30:16.288 [ZeusMonitor] Running indefinitely. 2022-12-06 19:30:16.288 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:30:16.288 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e99+gpu0.power.log
2022-12-06 14:31:00,311 [ZeusDataLoader(train)] train epoch 99 done: time=44.26 energy=6228.17
2022-12-06 14:31:00,314 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 0.5753
Training Epoch: 98 [2048/50176]	Loss: 0.4817
Training Epoch: 98 [3072/50176]	Loss: 0.5622
Training Epoch: 98 [4096/50176]	Loss: 0.5233
Training Epoch: 98 [5120/50176]	Loss: 0.6122
Training Epoch: 98 [6144/50176]	Loss: 0.5838
Training Epoch: 98 [7168/50176]	Loss: 0.5585
Training Epoch: 98 [8192/50176]	Loss: 0.6276
Training Epoch: 98 [9216/50176]	Loss: 0.5573
Training Epoch: 98 [10240/50176]	Loss: 0.5964
Training Epoch: 98 [11264/50176]	Loss: 0.6041
Training Epoch: 98 [12288/50176]	Loss: 0.6077
Training Epoch: 98 [13312/50176]	Loss: 0.5915
Training Epoch: 98 [14336/50176]	Loss: 0.5536
Training Epoch: 98 [15360/50176]	Loss: 0.5702
Training Epoch: 98 [16384/50176]	Loss: 0.6430
Training Epoch: 98 [17408/50176]	Loss: 0.6487
Training Epoch: 98 [18432/50176]	Loss: 0.5856
Training Epoch: 98 [19456/50176]	Loss: 0.6006
Training Epoch: 98 [20480/50176]	Loss: 0.5764
Training Epoch: 98 [21504/50176]	Loss: 0.6261
Training Epoch: 98 [22528/50176]	Loss: 0.6431
Training Epoch: 98 [23552/50176]	Loss: 0.6579
Training Epoch: 98 [24576/50176]	Loss: 0.6259
Training Epoch: 98 [25600/50176]	Loss: 0.6237
Training Epoch: 98 [26624/50176]	Loss: 0.6326
Training Epoch: 98 [27648/50176]	Loss: 0.6560
Training Epoch: 98 [28672/50176]	Loss: 0.6274
Training Epoch: 98 [29696/50176]	Loss: 0.6523
Training Epoch: 98 [30720/50176]	Loss: 0.6841
Training Epoch: 98 [31744/50176]	Loss: 0.7224
Training Epoch: 98 [32768/50176]	Loss: 0.6199
Training Epoch: 98 [33792/50176]	Loss: 0.6675
Training Epoch: 98 [34816/50176]	Loss: 0.6379
Training Epoch: 98 [35840/50176]	Loss: 0.6607
Training Epoch: 98 [36864/50176]	Loss: 0.7056
Training Epoch: 98 [37888/50176]	Loss: 0.6557
Training Epoch: 98 [38912/50176]	Loss: 0.6267
Training Epoch: 98 [39936/50176]	Loss: 0.5814
Training Epoch: 98 [40960/50176]	Loss: 0.6041
Training Epoch: 98 [41984/50176]	Loss: 0.6318
Training Epoch: 98 [43008/50176]	Loss: 0.6632
Training Epoch: 98 [44032/50176]	Loss: 0.6911
Training Epoch: 98 [45056/50176]	Loss: 0.6966
Training Epoch: 98 [46080/50176]	Loss: 0.7140
Training Epoch: 98 [47104/50176]	Loss: 0.6225
Training Epoch: 98 [48128/50176]	Loss: 0.6932
Training Epoch: 98 [49152/50176]	Loss: 0.6443
Training Epoch: 98 [50176/50176]	Loss: 0.6196
2022-12-06 19:31:04.066 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:31:04,114 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.79 energy=495.31
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Up to epoch 99: time=4813.86, energy=666603.08, cost=754514.50
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Expected next epoch: time=4860.97, energy=673290.96, cost=761979.99
2022-12-06 14:31:04,115 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0223, Accuracy: 0.0962
2022-12-06 14:31:04,304 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:31:04,305 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:31:04.309 [ZeusMonitor] Monitor started.
2022-12-06 19:31:04.309 [ZeusMonitor] Running indefinitely. 2022-12-06 19:31:04.309 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:31:04.309 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e100+gpu0.power.log
2022-12-06 14:31:48,659 [ZeusDataLoader(train)] train epoch 100 done: time=44.54 energy=6246.90
2022-12-06 14:31:48,662 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 0.5675
Training Epoch: 99 [2048/50176]	Loss: 0.5855
Training Epoch: 99 [3072/50176]	Loss: 0.5545
Training Epoch: 99 [4096/50176]	Loss: 0.6313
Training Epoch: 99 [5120/50176]	Loss: 0.5909
Training Epoch: 99 [6144/50176]	Loss: 0.5373
Training Epoch: 99 [7168/50176]	Loss: 0.5761
Training Epoch: 99 [8192/50176]	Loss: 0.5754
Training Epoch: 99 [9216/50176]	Loss: 0.5276
Training Epoch: 99 [10240/50176]	Loss: 0.5933
Training Epoch: 99 [11264/50176]	Loss: 0.5395
Training Epoch: 99 [12288/50176]	Loss: 0.6421
Training Epoch: 99 [13312/50176]	Loss: 0.6092
Training Epoch: 99 [14336/50176]	Loss: 0.5673
Training Epoch: 99 [15360/50176]	Loss: 0.5262
Training Epoch: 99 [16384/50176]	Loss: 0.5515
Training Epoch: 99 [17408/50176]	Loss: 0.6108
Training Epoch: 99 [18432/50176]	Loss: 0.5733
Training Epoch: 99 [19456/50176]	Loss: 0.5832
Training Epoch: 99 [20480/50176]	Loss: 0.6359
Training Epoch: 99 [21504/50176]	Loss: 0.6189
Training Epoch: 99 [22528/50176]	Loss: 0.6002
Training Epoch: 99 [23552/50176]	Loss: 0.6269
Training Epoch: 99 [24576/50176]	Loss: 0.5917
Training Epoch: 99 [25600/50176]	Loss: 0.6372
Training Epoch: 99 [26624/50176]	Loss: 0.6471
Training Epoch: 99 [27648/50176]	Loss: 0.6324
Training Epoch: 99 [28672/50176]	Loss: 0.6225
Training Epoch: 99 [29696/50176]	Loss: 0.5676
Training Epoch: 99 [30720/50176]	Loss: 0.6047
Training Epoch: 99 [31744/50176]	Loss: 0.6343
Training Epoch: 99 [32768/50176]	Loss: 0.5899
Training Epoch: 99 [33792/50176]	Loss: 0.6422
Training Epoch: 99 [34816/50176]	Loss: 0.6361
Training Epoch: 99 [35840/50176]	Loss: 0.6796
Training Epoch: 99 [36864/50176]	Loss: 0.6621
Training Epoch: 99 [37888/50176]	Loss: 0.5907
Training Epoch: 99 [38912/50176]	Loss: 0.6338
Training Epoch: 99 [39936/50176]	Loss: 0.6259
Training Epoch: 99 [40960/50176]	Loss: 0.6003
Training Epoch: 99 [41984/50176]	Loss: 0.6893
Training Epoch: 99 [43008/50176]	Loss: 0.6678
Training Epoch: 99 [44032/50176]	Loss: 0.6645
Training Epoch: 99 [45056/50176]	Loss: 0.6079
Training Epoch: 99 [46080/50176]	Loss: 0.5939
Training Epoch: 99 [47104/50176]	Loss: 0.5896
Training Epoch: 99 [48128/50176]	Loss: 0.7329
Training Epoch: 99 [49152/50176]	Loss: 0.6759
Training Epoch: 99 [50176/50176]	Loss: 0.6956
2022-12-06 19:31:52.333 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:31:52,344 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.67 energy=458.13
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Up to epoch 100: time=4862.07, energy=673308.11, cost=762085.34
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Training done.
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec02+try01+bs1024+lr0.0500000.train.json: {"energy": 673308.1082976655, "time": 4862.071877154984, "cost": 762085.3433998938, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 0.0133, Accuracy: 0.1025

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 673308.1082976655, 'time': 4862.071877154984, 'cost': 762085.3433998938, 'num_epochs': 100, 'reached': False}
[run job; power] power_stats={'job_id': 'rec02+try01', 'train_power': {'175000': 144.47546303251323, '150000': 143.5043538909716, '125000': 122.98543544465625, '100000': 96.15303472348029}, 'train_throughput': {'175000': 1.1271092756166952, '150000': 1.1318246084833394, '125000': 1.049840007140111, '100000': 0.5319577495376839}, 'eval_power': {'175000': 125.11089176100826, '150000': 124.69307695790027, '125000': 113.06620903588392}, 'eval_throughput': {'175000': 2.7278581345566275, '150000': 2.624264534414073, '125000': 2.5546916558312223}, 'optimal_pl': 150000}
[Zeus Master] cost=762085.3433998938

[Zeus Master] Job did not reach the target metric!
[run job] Launching job with BS 1024: and LR: 0.5
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec03+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.5']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec03+try01.train.log'
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 14:31:56,836 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 14:31:56,836 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 14:31:58,997 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 14:31:58,998 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 14:31:59,187 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:31:59.191 [ZeusMonitor] Monitor started.
2022-12-06 19:31:59.191 [ZeusMonitor] Running indefinitely. 2022-12-06 19:31:59.191 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:31:59.191 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 14:31:59,888 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 14:31:59,889 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 14:32:08,655 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 14:32:42,805 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 14:32:44,455 [ZeusDataLoader(train)] train epoch 1 done: time=45.45 energy=6246.86
2022-12-06 14:32:44,458 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 182.1425
Training Epoch: 0 [3072/50176]	Loss: 48.1428
Training Epoch: 0 [4096/50176]	Loss: 12.7722
Training Epoch: 0 [5120/50176]	Loss: 17.6722
Training Epoch: 0 [6144/50176]	Loss: 4.9360
Training Epoch: 0 [7168/50176]	Loss: 5.6275
Training Epoch: 0 [8192/50176]	Loss: 8.5320
Training Epoch: 0 [9216/50176]	Loss: 5.1642
Training Epoch: 0 [10240/50176]	Loss: 6.1835
Training Epoch: 0 [11264/50176]	Loss: 4.9697
Training Epoch: 0 [12288/50176]	Loss: 4.7855
Training Epoch: 0 [13312/50176]	Loss: 4.8630
Training Epoch: 0 [14336/50176]	Loss: 4.7613
Training Epoch: 0 [15360/50176]	Loss: 4.6853
Training Epoch: 0 [16384/50176]	Loss: 4.6704
Training Epoch: 0 [17408/50176]	Loss: 4.7377
Training Epoch: 0 [18432/50176]	Loss: 4.6797
Training Epoch: 0 [19456/50176]	Loss: 4.6488
Training Epoch: 0 [20480/50176]	Loss: 4.6987
Training Epoch: 0 [21504/50176]	Loss: 4.6691
Training Epoch: 0 [22528/50176]	Loss: 4.6910
Training Epoch: 0 [23552/50176]	Loss: 4.6831
Training Epoch: 0 [24576/50176]	Loss: 4.6858
Training Epoch: 0 [25600/50176]	Loss: 4.6520
Training Epoch: 0 [26624/50176]	Loss: 4.6496
Training Epoch: 0 [27648/50176]	Loss: 4.6470
Training Epoch: 0 [28672/50176]	Loss: 4.6366
Training Epoch: 0 [29696/50176]	Loss: 4.6378
Training Epoch: 0 [30720/50176]	Loss: 4.6450
Training Epoch: 0 [31744/50176]	Loss: 4.6867
Training Epoch: 0 [32768/50176]	Loss: 4.6452
Training Epoch: 0 [33792/50176]	Loss: 4.6546
Training Epoch: 0 [34816/50176]	Loss: 4.6552
Training Epoch: 0 [35840/50176]	Loss: 4.6530
Training Epoch: 0 [36864/50176]	Loss: 4.6351
Training Epoch: 0 [37888/50176]	Loss: 4.6331
Training Epoch: 0 [38912/50176]	Loss: 4.6310
Training Epoch: 0 [39936/50176]	Loss: 4.6494
Training Epoch: 0 [40960/50176]	Loss: 4.6435
Training Epoch: 0 [41984/50176]	Loss: 4.6470
Training Epoch: 0 [43008/50176]	Loss: 4.6597
Training Epoch: 0 [44032/50176]	Loss: 4.6391
Training Epoch: 0 [45056/50176]	Loss: 4.6448
Training Epoch: 0 [46080/50176]	Loss: 4.6392
Training Epoch: 0 [47104/50176]	Loss: 4.6307
Training Epoch: 0 [48128/50176]	Loss: 4.6309
Training Epoch: 0 [49152/50176]	Loss: 4.6326
Training Epoch: 0 [50176/50176]	Loss: 4.6314
2022-12-06 19:32:48.202 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:32:48,222 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.76 energy=472.02
2022-12-06 14:32:48,222 [ZeusDataLoader(train)] Up to epoch 1: time=49.21, energy=6718.87, cost=7664.98
2022-12-06 14:32:48,223 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0046, Accuracy: 0.0101
2022-12-06 14:32:48,479 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:32:48.481 [ZeusMonitor] Monitor started.
2022-12-06 19:32:48.481 [ZeusMonitor] Running indefinitely. 2022-12-06 19:32:48.482 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:32:48.482 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 14:32:49,168 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 14:32:49,169 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 14:32:57,275 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 14:33:30,475 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 14:33:32,125 [ZeusDataLoader(train)] train epoch 2 done: time=43.90 energy=5915.11
2022-12-06 14:33:32,128 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.6400
Training Epoch: 1 [2048/50176]	Loss: 4.6316
Training Epoch: 1 [3072/50176]	Loss: 4.6408
Training Epoch: 1 [4096/50176]	Loss: 4.6283
Training Epoch: 1 [5120/50176]	Loss: 4.6458
Training Epoch: 1 [6144/50176]	Loss: 4.6296
Training Epoch: 1 [7168/50176]	Loss: 4.6313
Training Epoch: 1 [8192/50176]	Loss: 4.6324
Training Epoch: 1 [9216/50176]	Loss: 4.6340
Training Epoch: 1 [10240/50176]	Loss: 4.6399
Training Epoch: 1 [11264/50176]	Loss: 4.6301
Training Epoch: 1 [12288/50176]	Loss: 4.6290
Training Epoch: 1 [13312/50176]	Loss: 4.6348
Training Epoch: 1 [14336/50176]	Loss: 4.6360
Training Epoch: 1 [15360/50176]	Loss: 4.6303
Training Epoch: 1 [16384/50176]	Loss: 4.6395
Training Epoch: 1 [17408/50176]	Loss: 4.6394
Training Epoch: 1 [18432/50176]	Loss: 4.6387
Training Epoch: 1 [19456/50176]	Loss: 4.6254
Training Epoch: 1 [20480/50176]	Loss: 4.6237
Training Epoch: 1 [21504/50176]	Loss: 4.6362
Training Epoch: 1 [22528/50176]	Loss: 4.6342
Training Epoch: 1 [23552/50176]	Loss: 4.6335
Training Epoch: 1 [24576/50176]	Loss: 4.6499
Training Epoch: 1 [25600/50176]	Loss: 4.6361
Training Epoch: 1 [26624/50176]	Loss: 4.6254
Training Epoch: 1 [27648/50176]	Loss: 4.6316
Training Epoch: 1 [28672/50176]	Loss: 4.6289
Training Epoch: 1 [29696/50176]	Loss: 4.6251
Training Epoch: 1 [30720/50176]	Loss: 4.6519
Training Epoch: 1 [31744/50176]	Loss: 4.6309
Training Epoch: 1 [32768/50176]	Loss: 4.6348
Training Epoch: 1 [33792/50176]	Loss: 4.6348
Training Epoch: 1 [34816/50176]	Loss: 4.6366
Training Epoch: 1 [35840/50176]	Loss: 4.6399
Training Epoch: 1 [36864/50176]	Loss: 4.6418
Training Epoch: 1 [37888/50176]	Loss: 4.6373
Training Epoch: 1 [38912/50176]	Loss: 4.6189
Training Epoch: 1 [39936/50176]	Loss: 4.6395
Training Epoch: 1 [40960/50176]	Loss: 4.6364
Training Epoch: 1 [41984/50176]	Loss: 4.6400
Training Epoch: 1 [43008/50176]	Loss: 4.6315
Training Epoch: 1 [44032/50176]	Loss: 4.6488
Training Epoch: 1 [45056/50176]	Loss: 4.6275
Training Epoch: 1 [46080/50176]	Loss: 4.6090
Training Epoch: 1 [47104/50176]	Loss: 4.6334
Training Epoch: 1 [48128/50176]	Loss: 4.6315
Training Epoch: 1 [49152/50176]	Loss: 4.6354
Training Epoch: 1 [50176/50176]	Loss: 4.6294
2022-12-06 19:33:35.864 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:33:35,894 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.76 energy=466.13
2022-12-06 14:33:35,895 [ZeusDataLoader(train)] Up to epoch 2: time=96.86, energy=13100.11, cost=15025.30
2022-12-06 14:33:35,896 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:33:36,090 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:33:36.094 [ZeusMonitor] Monitor started.
2022-12-06 19:33:36.094 [ZeusMonitor] Running indefinitely. 2022-12-06 19:33:36.094 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:33:36.094 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 14:33:36,782 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 14:33:36,782 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 14:33:45,211 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 14:34:20,183 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 14:34:21,918 [ZeusDataLoader(train)] train epoch 3 done: time=46.02 energy=5527.60
2022-12-06 14:34:21,921 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 4.6320
Training Epoch: 2 [2048/50176]	Loss: 4.6556
Training Epoch: 2 [3072/50176]	Loss: 4.6322
Training Epoch: 2 [4096/50176]	Loss: 4.6298
Training Epoch: 2 [5120/50176]	Loss: 4.6395
Training Epoch: 2 [6144/50176]	Loss: 4.6272
Training Epoch: 2 [7168/50176]	Loss: 4.6517
Training Epoch: 2 [8192/50176]	Loss: 4.6330
Training Epoch: 2 [9216/50176]	Loss: 4.6292
Training Epoch: 2 [10240/50176]	Loss: 4.6335
Training Epoch: 2 [11264/50176]	Loss: 4.6309
Training Epoch: 2 [12288/50176]	Loss: 4.6384
Training Epoch: 2 [13312/50176]	Loss: 4.6331
Training Epoch: 2 [14336/50176]	Loss: 4.6429
Training Epoch: 2 [15360/50176]	Loss: 4.6290
Training Epoch: 2 [16384/50176]	Loss: 4.6423
Training Epoch: 2 [17408/50176]	Loss: 4.6357
Training Epoch: 2 [18432/50176]	Loss: 4.6397
Training Epoch: 2 [19456/50176]	Loss: 4.6405
Training Epoch: 2 [20480/50176]	Loss: 4.6352
Training Epoch: 2 [21504/50176]	Loss: 4.6367
Training Epoch: 2 [22528/50176]	Loss: 4.6241
Training Epoch: 2 [23552/50176]	Loss: 4.6295
Training Epoch: 2 [24576/50176]	Loss: 4.6418
Training Epoch: 2 [25600/50176]	Loss: 4.6436
Training Epoch: 2 [26624/50176]	Loss: 4.6333
Training Epoch: 2 [27648/50176]	Loss: 4.6367
Training Epoch: 2 [28672/50176]	Loss: 4.6313
Training Epoch: 2 [29696/50176]	Loss: 4.6267
Training Epoch: 2 [30720/50176]	Loss: 4.6367
Training Epoch: 2 [31744/50176]	Loss: 4.6288
Training Epoch: 2 [32768/50176]	Loss: 4.6288
Training Epoch: 2 [33792/50176]	Loss: 4.6420
Training Epoch: 2 [34816/50176]	Loss: 4.6168
Training Epoch: 2 [35840/50176]	Loss: 4.6311
Training Epoch: 2 [36864/50176]	Loss: 4.6307
Training Epoch: 2 [37888/50176]	Loss: 4.6388
Training Epoch: 2 [38912/50176]	Loss: 4.6388
Training Epoch: 2 [39936/50176]	Loss: 4.6316
Training Epoch: 2 [40960/50176]	Loss: 4.6385
Training Epoch: 2 [41984/50176]	Loss: 4.6293
Training Epoch: 2 [43008/50176]	Loss: 4.6224
Training Epoch: 2 [44032/50176]	Loss: 4.6302
Training Epoch: 2 [45056/50176]	Loss: 4.6388
Training Epoch: 2 [46080/50176]	Loss: 4.6456
Training Epoch: 2 [47104/50176]	Loss: 4.6324
Training Epoch: 2 [48128/50176]	Loss: 4.6443
Training Epoch: 2 [49152/50176]	Loss: 4.6440
Training Epoch: 2 [50176/50176]	Loss: 4.6193
2022-12-06 19:34:25.854 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:34:25,880 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.95 energy=442.33
2022-12-06 14:34:25,881 [ZeusDataLoader(train)] Up to epoch 3: time=146.83, energy=19070.04, cost=22382.38
2022-12-06 14:34:25,882 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0066, Accuracy: 0.0099
2022-12-06 14:34:26,144 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:34:26.147 [ZeusMonitor] Monitor started.
2022-12-06 19:34:26.147 [ZeusMonitor] Running indefinitely. 2022-12-06 19:34:26.147 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:34:26.147 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 14:34:26,818 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 14:34:26,819 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 14:34:36,816 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] Cost-optimal power limit is 150W
2022-12-06 14:35:19,053 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 14:35:20,835 [ZeusDataLoader(train)] train epoch 4 done: time=54.95 energy=5362.67
2022-12-06 14:35:20,838 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 4.6282
Training Epoch: 3 [2048/50176]	Loss: 4.6226
Training Epoch: 3 [3072/50176]	Loss: 4.6413
Training Epoch: 3 [4096/50176]	Loss: 4.6407
Training Epoch: 3 [5120/50176]	Loss: 4.6382
Training Epoch: 3 [6144/50176]	Loss: 4.6322
Training Epoch: 3 [7168/50176]	Loss: 4.6378
Training Epoch: 3 [8192/50176]	Loss: 4.6235
Training Epoch: 3 [9216/50176]	Loss: 4.6321
Training Epoch: 3 [10240/50176]	Loss: 4.6297
Training Epoch: 3 [11264/50176]	Loss: 4.6396
Training Epoch: 3 [12288/50176]	Loss: 4.6367
Training Epoch: 3 [13312/50176]	Loss: 4.6275
Training Epoch: 3 [14336/50176]	Loss: 4.6403
Training Epoch: 3 [15360/50176]	Loss: 4.6481
Training Epoch: 3 [16384/50176]	Loss: 4.6263
Training Epoch: 3 [17408/50176]	Loss: 4.6331
Training Epoch: 3 [18432/50176]	Loss: 4.6184
Training Epoch: 3 [19456/50176]	Loss: 4.6249
Training Epoch: 3 [20480/50176]	Loss: 4.6338
Training Epoch: 3 [21504/50176]	Loss: 4.6353
Training Epoch: 3 [22528/50176]	Loss: 4.6242
Training Epoch: 3 [23552/50176]	Loss: 4.6491
Training Epoch: 3 [24576/50176]	Loss: 4.6414
Training Epoch: 3 [25600/50176]	Loss: 4.6340
Training Epoch: 3 [26624/50176]	Loss: 4.6243
Training Epoch: 3 [27648/50176]	Loss: 4.6356
Training Epoch: 3 [28672/50176]	Loss: 4.6255
Training Epoch: 3 [29696/50176]	Loss: 4.6374
Training Epoch: 3 [30720/50176]	Loss: 4.6301
Training Epoch: 3 [31744/50176]	Loss: 4.6434
Training Epoch: 3 [32768/50176]	Loss: 4.6414
Training Epoch: 3 [33792/50176]	Loss: 4.6327
Training Epoch: 3 [34816/50176]	Loss: 4.6293
Training Epoch: 3 [35840/50176]	Loss: 4.6245
Training Epoch: 3 [36864/50176]	Loss: 4.6267
Training Epoch: 3 [37888/50176]	Loss: 4.6430
Training Epoch: 3 [38912/50176]	Loss: 4.6246
Training Epoch: 3 [39936/50176]	Loss: 4.6478
Training Epoch: 3 [40960/50176]	Loss: 4.6282
Training Epoch: 3 [41984/50176]	Loss: 4.6379
Training Epoch: 3 [43008/50176]	Loss: 4.6204
Training Epoch: 3 [44032/50176]	Loss: 4.6244
Training Epoch: 3 [45056/50176]	Loss: 4.6314
Training Epoch: 3 [46080/50176]	Loss: 4.6210
Training Epoch: 3 [47104/50176]	Loss: 4.6185
Training Epoch: 3 [48128/50176]	Loss: 4.6407
Training Epoch: 3 [49152/50176]	Loss: 4.6422
Training Epoch: 3 [50176/50176]	Loss: 4.6297
2022-12-06 19:35:24.602 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:35:24,656 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 14:35:24,656 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.5000000.power.json: {"job_id": "rec03+try01", "train_power": {"175000": 141.93837297518056, "150000": 137.5711933424961, "125000": 122.45263058940533, "100000": 98.39104404902801}, "train_throughput": {"175000": 1.1131630264555321, "150000": 1.1449147533158621, "125000": 1.086906289817731, "100000": 0.8999782655864567}, "eval_power": {"175000": 125.66587303669519, "150000": 125.63847713019706, "125000": 111.94785245414742}, "eval_throughput": {"175000": 2.662326664559453, "150000": 2.6255096010426673, "125000": 2.5308668007617996}, "optimal_pl": 150000}
2022-12-06 14:35:24,657 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.81 energy=478.53
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Up to epoch 4: time=205.58, energy=24911.24, cost=30444.05
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Expected next epoch: time=252.19, energy=31277.54, cost=37705.28
2022-12-06 14:35:24,658 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 20987.3145, Accuracy: 0.0098
2022-12-06 14:35:24,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:35:24,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:35:24.911 [ZeusMonitor] Monitor started.
2022-12-06 19:35:24.912 [ZeusMonitor] Running indefinitely. 2022-12-06 19:35:24.912 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:35:24.912 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 14:36:08,631 [ZeusDataLoader(train)] train epoch 5 done: time=43.96 energy=5847.50
2022-12-06 14:36:08,634 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 4.6281
Training Epoch: 4 [2048/50176]	Loss: 4.6492
Training Epoch: 4 [3072/50176]	Loss: 4.6327
Training Epoch: 4 [4096/50176]	Loss: 4.6265
Training Epoch: 4 [5120/50176]	Loss: 4.6373
Training Epoch: 4 [6144/50176]	Loss: 4.6380
Training Epoch: 4 [7168/50176]	Loss: 4.6348
Training Epoch: 4 [8192/50176]	Loss: 4.6372
Training Epoch: 4 [9216/50176]	Loss: 4.6323
Training Epoch: 4 [10240/50176]	Loss: 4.6243
Training Epoch: 4 [11264/50176]	Loss: 4.6291
Training Epoch: 4 [12288/50176]	Loss: 4.6226
Training Epoch: 4 [13312/50176]	Loss: 4.6279
Training Epoch: 4 [14336/50176]	Loss: 4.6355
Training Epoch: 4 [15360/50176]	Loss: 4.6262
Training Epoch: 4 [16384/50176]	Loss: 4.6288
Training Epoch: 4 [17408/50176]	Loss: 4.6436
Training Epoch: 4 [18432/50176]	Loss: 4.6282
Training Epoch: 4 [19456/50176]	Loss: 4.6191
Training Epoch: 4 [20480/50176]	Loss: 4.6379
Training Epoch: 4 [21504/50176]	Loss: 4.6429
Training Epoch: 4 [22528/50176]	Loss: 4.6320
Training Epoch: 4 [23552/50176]	Loss: 4.6368
Training Epoch: 4 [24576/50176]	Loss: 4.6353
Training Epoch: 4 [25600/50176]	Loss: 4.6235
Training Epoch: 4 [26624/50176]	Loss: 4.6278
Training Epoch: 4 [27648/50176]	Loss: 4.6413
Training Epoch: 4 [28672/50176]	Loss: 4.6475
Training Epoch: 4 [29696/50176]	Loss: 4.6554
Training Epoch: 4 [30720/50176]	Loss: 4.6401
Training Epoch: 4 [31744/50176]	Loss: 4.6567
Training Epoch: 4 [32768/50176]	Loss: 4.6294
Training Epoch: 4 [33792/50176]	Loss: 4.6276
Training Epoch: 4 [34816/50176]	Loss: 4.6403
Training Epoch: 4 [35840/50176]	Loss: 4.6384
Training Epoch: 4 [36864/50176]	Loss: 4.6431
Training Epoch: 4 [37888/50176]	Loss: 4.6204
Training Epoch: 4 [38912/50176]	Loss: 4.6335
Training Epoch: 4 [39936/50176]	Loss: 4.6268
Training Epoch: 4 [40960/50176]	Loss: 4.6175
Training Epoch: 4 [41984/50176]	Loss: 4.6348
Training Epoch: 4 [43008/50176]	Loss: 4.6313
Training Epoch: 4 [44032/50176]	Loss: 4.6301
Training Epoch: 4 [45056/50176]	Loss: 4.6323
Training Epoch: 4 [46080/50176]	Loss: 4.6282
Training Epoch: 4 [47104/50176]	Loss: 4.6267
Training Epoch: 4 [48128/50176]	Loss: 4.6353
Training Epoch: 4 [49152/50176]	Loss: 4.6430
Training Epoch: 4 [50176/50176]	Loss: 4.6257
2022-12-06 19:36:12.349 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:36:12,358 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.72 energy=464.10
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Up to epoch 5: time=253.26, energy=31222.85, cost=37771.90
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Expected next epoch: time=299.87, energy=37589.14, cost=45033.14
2022-12-06 14:36:12,359 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 7844883877121229.0000, Accuracy: 0.0100
2022-12-06 14:36:12,607 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:36:12,608 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:36:12.609 [ZeusMonitor] Monitor started.
2022-12-06 19:36:12.609 [ZeusMonitor] Running indefinitely. 2022-12-06 19:36:12.609 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:36:12.609 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 14:36:56,182 [ZeusDataLoader(train)] train epoch 6 done: time=43.81 energy=5828.14
2022-12-06 14:36:56,185 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 4.6232
Training Epoch: 5 [2048/50176]	Loss: 4.6379
Training Epoch: 5 [3072/50176]	Loss: 4.6217
Training Epoch: 5 [4096/50176]	Loss: 4.6306
Training Epoch: 5 [5120/50176]	Loss: 4.6304
Training Epoch: 5 [6144/50176]	Loss: 4.6243
Training Epoch: 5 [7168/50176]	Loss: 4.6429
Training Epoch: 5 [8192/50176]	Loss: 4.6286
Training Epoch: 5 [9216/50176]	Loss: 4.6350
Training Epoch: 5 [10240/50176]	Loss: 4.6381
Training Epoch: 5 [11264/50176]	Loss: 4.6396
Training Epoch: 5 [12288/50176]	Loss: 4.6285
Training Epoch: 5 [13312/50176]	Loss: 4.6297
Training Epoch: 5 [14336/50176]	Loss: 4.6229
Training Epoch: 5 [15360/50176]	Loss: 4.6376
Training Epoch: 5 [16384/50176]	Loss: 4.6444
Training Epoch: 5 [17408/50176]	Loss: 4.6533
Training Epoch: 5 [18432/50176]	Loss: 4.6365
Training Epoch: 5 [19456/50176]	Loss: 4.6465
Training Epoch: 5 [20480/50176]	Loss: 4.6386
Training Epoch: 5 [21504/50176]	Loss: 4.6277
Training Epoch: 5 [22528/50176]	Loss: 4.6314
Training Epoch: 5 [23552/50176]	Loss: 4.6323
Training Epoch: 5 [24576/50176]	Loss: 4.6322
Training Epoch: 5 [25600/50176]	Loss: 4.6447
Training Epoch: 5 [26624/50176]	Loss: 4.6380
Training Epoch: 5 [27648/50176]	Loss: 4.6360
Training Epoch: 5 [28672/50176]	Loss: 4.6423
Training Epoch: 5 [29696/50176]	Loss: 4.6308
Training Epoch: 5 [30720/50176]	Loss: 4.6392
Training Epoch: 5 [31744/50176]	Loss: 4.6403
Training Epoch: 5 [32768/50176]	Loss: 4.6409
Training Epoch: 5 [33792/50176]	Loss: 4.6397
Training Epoch: 5 [34816/50176]	Loss: 4.6490
Training Epoch: 5 [35840/50176]	Loss: 4.6558
Training Epoch: 5 [36864/50176]	Loss: 4.6408
Training Epoch: 5 [37888/50176]	Loss: 4.6519
Training Epoch: 5 [38912/50176]	Loss: 4.6424
Training Epoch: 5 [39936/50176]	Loss: 4.6299
Training Epoch: 5 [40960/50176]	Loss: 4.6291
Training Epoch: 5 [41984/50176]	Loss: 4.6398
Training Epoch: 5 [43008/50176]	Loss: 4.6303
Training Epoch: 5 [44032/50176]	Loss: 4.6301
Training Epoch: 5 [45056/50176]	Loss: 4.6457
Training Epoch: 5 [46080/50176]	Loss: 4.6335
Training Epoch: 5 [47104/50176]	Loss: 4.6348
Training Epoch: 5 [48128/50176]	Loss: 4.6282
Training Epoch: 5 [49152/50176]	Loss: 4.6313
Training Epoch: 5 [50176/50176]	Loss: 4.6344
2022-12-06 19:36:59.983 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:37:00,018 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.83 energy=476.45
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Up to epoch 6: time=300.90, energy=37527.43, cost=45092.66
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Expected next epoch: time=347.51, energy=43893.73, cost=52353.90
2022-12-06 14:37:00,019 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0049, Accuracy: 0.0098
2022-12-06 14:37:00,254 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:37:00,255 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:37:00.257 [ZeusMonitor] Monitor started.
2022-12-06 19:37:00.257 [ZeusMonitor] Running indefinitely. 2022-12-06 19:37:00.257 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:37:00.257 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 14:37:43,616 [ZeusDataLoader(train)] train epoch 7 done: time=43.59 energy=5815.69
2022-12-06 14:37:43,619 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 4.6237
Training Epoch: 6 [2048/50176]	Loss: 4.6439
Training Epoch: 6 [3072/50176]	Loss: 4.6323
Training Epoch: 6 [4096/50176]	Loss: 4.6345
Training Epoch: 6 [5120/50176]	Loss: 4.6316
Training Epoch: 6 [6144/50176]	Loss: 4.6334
Training Epoch: 6 [7168/50176]	Loss: 4.6252
Training Epoch: 6 [8192/50176]	Loss: 4.6488
Training Epoch: 6 [9216/50176]	Loss: 4.6352
Training Epoch: 6 [10240/50176]	Loss: 4.6317
Training Epoch: 6 [11264/50176]	Loss: 4.6259
Training Epoch: 6 [12288/50176]	Loss: 4.6260
Training Epoch: 6 [13312/50176]	Loss: 4.6274
Training Epoch: 6 [14336/50176]	Loss: 4.6289
Training Epoch: 6 [15360/50176]	Loss: 4.6374
Training Epoch: 6 [16384/50176]	Loss: 4.6415
Training Epoch: 6 [17408/50176]	Loss: 4.6236
Training Epoch: 6 [18432/50176]	Loss: 4.6403
Training Epoch: 6 [19456/50176]	Loss: 4.6337
Training Epoch: 6 [20480/50176]	Loss: 4.6357
Training Epoch: 6 [21504/50176]	Loss: 4.6308
Training Epoch: 6 [22528/50176]	Loss: 4.6388
Training Epoch: 6 [23552/50176]	Loss: 4.6356
Training Epoch: 6 [24576/50176]	Loss: 4.6259
Training Epoch: 6 [25600/50176]	Loss: 4.6383
Training Epoch: 6 [26624/50176]	Loss: 4.6249
Training Epoch: 6 [27648/50176]	Loss: 4.6298
Training Epoch: 6 [28672/50176]	Loss: 4.6389
Training Epoch: 6 [29696/50176]	Loss: 4.6307
Training Epoch: 6 [30720/50176]	Loss: 4.6521
Training Epoch: 6 [31744/50176]	Loss: 4.6252
Training Epoch: 6 [32768/50176]	Loss: 4.6337
Training Epoch: 6 [33792/50176]	Loss: 4.6415
Training Epoch: 6 [34816/50176]	Loss: 4.6380
Training Epoch: 6 [35840/50176]	Loss: 4.6389
Training Epoch: 6 [36864/50176]	Loss: 4.6327
Training Epoch: 6 [37888/50176]	Loss: 4.6321
Training Epoch: 6 [38912/50176]	Loss: 4.6291
Training Epoch: 6 [39936/50176]	Loss: 4.6324
Training Epoch: 6 [40960/50176]	Loss: 4.6408
Training Epoch: 6 [41984/50176]	Loss: 4.6466
Training Epoch: 6 [43008/50176]	Loss: 4.6268
Training Epoch: 6 [44032/50176]	Loss: 4.6311
Training Epoch: 6 [45056/50176]	Loss: 4.6203
Training Epoch: 6 [46080/50176]	Loss: 4.6287
Training Epoch: 6 [47104/50176]	Loss: 4.6421
Training Epoch: 6 [48128/50176]	Loss: 4.6441
Training Epoch: 6 [49152/50176]	Loss: 4.6402
Training Epoch: 6 [50176/50176]	Loss: 4.6300
2022-12-06 19:37:47.318 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:37:47,341 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.71 energy=464.21
2022-12-06 14:37:47,341 [ZeusDataLoader(train)] Up to epoch 7: time=348.20, energy=43807.34, cost=52371.53
2022-12-06 14:37:47,342 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:37:47,342 [ZeusDataLoader(train)] Expected next epoch: time=394.81, energy=50173.63, cost=59632.76
2022-12-06 14:37:47,343 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 2.1486, Accuracy: 0.0097
2022-12-06 14:37:47,587 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:37:47,588 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:37:47.590 [ZeusMonitor] Monitor started.
2022-12-06 19:37:47.590 [ZeusMonitor] Running indefinitely. 2022-12-06 19:37:47.590 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:37:47.590 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 14:38:30,970 [ZeusDataLoader(train)] train epoch 8 done: time=43.62 energy=5824.02
2022-12-06 14:38:30,974 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 4.6265
Training Epoch: 7 [2048/50176]	Loss: 4.6358
Training Epoch: 7 [3072/50176]	Loss: 4.6284
Training Epoch: 7 [4096/50176]	Loss: 4.6192
Training Epoch: 7 [5120/50176]	Loss: 4.6257
Training Epoch: 7 [6144/50176]	Loss: 4.6388
Training Epoch: 7 [7168/50176]	Loss: 4.6282
Training Epoch: 7 [8192/50176]	Loss: 4.6321
Training Epoch: 7 [9216/50176]	Loss: 4.6185
Training Epoch: 7 [10240/50176]	Loss: 4.6311
Training Epoch: 7 [11264/50176]	Loss: 4.6277
Training Epoch: 7 [12288/50176]	Loss: 4.6519
Training Epoch: 7 [13312/50176]	Loss: 4.6240
Training Epoch: 7 [14336/50176]	Loss: 4.6286
Training Epoch: 7 [15360/50176]	Loss: 4.6311
Training Epoch: 7 [16384/50176]	Loss: 4.6259
Training Epoch: 7 [17408/50176]	Loss: 4.6359
Training Epoch: 7 [18432/50176]	Loss: 4.6344
Training Epoch: 7 [19456/50176]	Loss: 4.6263
Training Epoch: 7 [20480/50176]	Loss: 4.6336
Training Epoch: 7 [21504/50176]	Loss: 4.6240
Training Epoch: 7 [22528/50176]	Loss: 4.6311
Training Epoch: 7 [23552/50176]	Loss: 4.6315
Training Epoch: 7 [24576/50176]	Loss: 4.6223
Training Epoch: 7 [25600/50176]	Loss: 4.6319
Training Epoch: 7 [26624/50176]	Loss: 4.6366
Training Epoch: 7 [27648/50176]	Loss: 4.6328
Training Epoch: 7 [28672/50176]	Loss: 4.6223
Training Epoch: 7 [29696/50176]	Loss: 4.6172
Training Epoch: 7 [30720/50176]	Loss: 4.6337
Training Epoch: 7 [31744/50176]	Loss: 4.6313
Training Epoch: 7 [32768/50176]	Loss: 4.6282
Training Epoch: 7 [33792/50176]	Loss: 4.6371
Training Epoch: 7 [34816/50176]	Loss: 4.6334
Training Epoch: 7 [35840/50176]	Loss: 4.6285
Training Epoch: 7 [36864/50176]	Loss: 4.6443
Training Epoch: 7 [37888/50176]	Loss: 4.6246
Training Epoch: 7 [38912/50176]	Loss: 4.6290
Training Epoch: 7 [39936/50176]	Loss: 4.6289
Training Epoch: 7 [40960/50176]	Loss: 4.6221
Training Epoch: 7 [41984/50176]	Loss: 4.6442
Training Epoch: 7 [43008/50176]	Loss: 4.6305
Training Epoch: 7 [44032/50176]	Loss: 4.6309
Training Epoch: 7 [45056/50176]	Loss: 4.6222
Training Epoch: 7 [46080/50176]	Loss: 4.6262
Training Epoch: 7 [47104/50176]	Loss: 4.6289
Training Epoch: 7 [48128/50176]	Loss: 4.6378
Training Epoch: 7 [49152/50176]	Loss: 4.6282
Training Epoch: 7 [50176/50176]	Loss: 4.6578
2022-12-06 19:38:34.732 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:38:34,772 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.79 energy=463.35
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Up to epoch 8: time=395.61, energy=50094.71, cost=59663.53
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Expected next epoch: time=442.22, energy=56461.00, cost=66924.76
2022-12-06 14:38:34,774 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 1.7477, Accuracy: 0.0098
2022-12-06 14:38:35,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:38:35,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:38:35.036 [ZeusMonitor] Monitor started.
2022-12-06 19:38:35.036 [ZeusMonitor] Running indefinitely. 2022-12-06 19:38:35.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:38:35.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 14:39:18,454 [ZeusDataLoader(train)] train epoch 9 done: time=43.67 energy=5817.13
2022-12-06 14:39:18,457 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 4.6326
Training Epoch: 8 [2048/50176]	Loss: 4.6422
Training Epoch: 8 [3072/50176]	Loss: 4.6167
Training Epoch: 8 [4096/50176]	Loss: 4.6450
Training Epoch: 8 [5120/50176]	Loss: 4.6375
Training Epoch: 8 [6144/50176]	Loss: 4.6378
Training Epoch: 8 [7168/50176]	Loss: 4.6368
Training Epoch: 8 [8192/50176]	Loss: 4.6400
Training Epoch: 8 [9216/50176]	Loss: 4.6440
Training Epoch: 8 [10240/50176]	Loss: 4.6299
Training Epoch: 8 [11264/50176]	Loss: 4.6391
Training Epoch: 8 [12288/50176]	Loss: 4.6192
Training Epoch: 8 [13312/50176]	Loss: 4.6290
Training Epoch: 8 [14336/50176]	Loss: 4.6408
Training Epoch: 8 [15360/50176]	Loss: 4.6411
Training Epoch: 8 [16384/50176]	Loss: 4.6403
Training Epoch: 8 [17408/50176]	Loss: 4.6453
Training Epoch: 8 [18432/50176]	Loss: 4.6454
Training Epoch: 8 [19456/50176]	Loss: 4.6348
Training Epoch: 8 [20480/50176]	Loss: 4.6297
Training Epoch: 8 [21504/50176]	Loss: 4.6327
Training Epoch: 8 [22528/50176]	Loss: 4.6382
Training Epoch: 8 [23552/50176]	Loss: 4.6257
Training Epoch: 8 [24576/50176]	Loss: 4.6298
Training Epoch: 8 [25600/50176]	Loss: 4.6391
Training Epoch: 8 [26624/50176]	Loss: 4.6544
Training Epoch: 8 [27648/50176]	Loss: 4.6345
Training Epoch: 8 [28672/50176]	Loss: 4.6301
Training Epoch: 8 [29696/50176]	Loss: 4.6247
Training Epoch: 8 [30720/50176]	Loss: 4.6452
Training Epoch: 8 [31744/50176]	Loss: 4.6477
Training Epoch: 8 [32768/50176]	Loss: 4.6370
Training Epoch: 8 [33792/50176]	Loss: 4.6231
Training Epoch: 8 [34816/50176]	Loss: 4.6480
Training Epoch: 8 [35840/50176]	Loss: 4.6438
Training Epoch: 8 [36864/50176]	Loss: 4.6366
Training Epoch: 8 [37888/50176]	Loss: 4.6393
Training Epoch: 8 [38912/50176]	Loss: 4.6230
Training Epoch: 8 [39936/50176]	Loss: 4.6328
Training Epoch: 8 [40960/50176]	Loss: 4.6342
Training Epoch: 8 [41984/50176]	Loss: 4.6403
Training Epoch: 8 [43008/50176]	Loss: 4.6259
Training Epoch: 8 [44032/50176]	Loss: 4.6409
Training Epoch: 8 [45056/50176]	Loss: 4.6333
Training Epoch: 8 [46080/50176]	Loss: 4.6378
Training Epoch: 8 [47104/50176]	Loss: 4.6212
Training Epoch: 8 [48128/50176]	Loss: 4.6343
Training Epoch: 8 [49152/50176]	Loss: 4.6229
Training Epoch: 8 [50176/50176]	Loss: 4.6495
2022-12-06 19:39:22.222 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:39:22,265 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.80 energy=479.63
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Up to epoch 9: time=443.09, energy=56391.47, cost=66965.70
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Expected next epoch: time=489.69, energy=62757.77, cost=74226.93
2022-12-06 14:39:22,266 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.2182, Accuracy: 0.0099
2022-12-06 14:39:22,480 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:39:22,481 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:39:22.484 [ZeusMonitor] Monitor started.
2022-12-06 19:39:22.484 [ZeusMonitor] Running indefinitely. 2022-12-06 19:39:22.484 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:39:22.484 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 14:40:05,890 [ZeusDataLoader(train)] train epoch 10 done: time=43.62 energy=5831.72
2022-12-06 14:40:05,893 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 4.6233
Training Epoch: 9 [2048/50176]	Loss: 4.6330
Training Epoch: 9 [3072/50176]	Loss: 4.6495
Training Epoch: 9 [4096/50176]	Loss: 4.6369
Training Epoch: 9 [5120/50176]	Loss: 4.6288
Training Epoch: 9 [6144/50176]	Loss: 4.6314
Training Epoch: 9 [7168/50176]	Loss: 4.6331
Training Epoch: 9 [8192/50176]	Loss: 4.6333
Training Epoch: 9 [9216/50176]	Loss: 4.6439
Training Epoch: 9 [10240/50176]	Loss: 4.6390
Training Epoch: 9 [11264/50176]	Loss: 4.6364
Training Epoch: 9 [12288/50176]	Loss: 4.6248
Training Epoch: 9 [13312/50176]	Loss: 4.6320
Training Epoch: 9 [14336/50176]	Loss: 4.6639
Training Epoch: 9 [15360/50176]	Loss: 4.6399
Training Epoch: 9 [16384/50176]	Loss: 4.6300
Training Epoch: 9 [17408/50176]	Loss: 4.6363
Training Epoch: 9 [18432/50176]	Loss: 4.6272
Training Epoch: 9 [19456/50176]	Loss: 4.6324
Training Epoch: 9 [20480/50176]	Loss: 4.6344
Training Epoch: 9 [21504/50176]	Loss: 4.6222
Training Epoch: 9 [22528/50176]	Loss: 4.6326
Training Epoch: 9 [23552/50176]	Loss: 4.6442
Training Epoch: 9 [24576/50176]	Loss: 4.6387
Training Epoch: 9 [25600/50176]	Loss: 4.6574
Training Epoch: 9 [26624/50176]	Loss: 4.6405
Training Epoch: 9 [27648/50176]	Loss: 4.6311
Training Epoch: 9 [28672/50176]	Loss: 4.6371
Training Epoch: 9 [29696/50176]	Loss: 4.6310
Training Epoch: 9 [30720/50176]	Loss: 4.6439
Training Epoch: 9 [31744/50176]	Loss: 4.6417
Training Epoch: 9 [32768/50176]	Loss: 4.6339
Training Epoch: 9 [33792/50176]	Loss: 4.6453
Training Epoch: 9 [34816/50176]	Loss: 4.6392
Training Epoch: 9 [35840/50176]	Loss: 4.6349
Training Epoch: 9 [36864/50176]	Loss: 4.6453
Training Epoch: 9 [37888/50176]	Loss: 4.6399
Training Epoch: 9 [38912/50176]	Loss: 4.6339
Training Epoch: 9 [39936/50176]	Loss: 4.6250
Training Epoch: 9 [40960/50176]	Loss: 4.6437
Training Epoch: 9 [41984/50176]	Loss: 4.6445
Training Epoch: 9 [43008/50176]	Loss: 4.6462
Training Epoch: 9 [44032/50176]	Loss: 4.6478
Training Epoch: 9 [45056/50176]	Loss: 4.6459
Training Epoch: 9 [46080/50176]	Loss: 4.6421
Training Epoch: 9 [47104/50176]	Loss: 4.6369
Training Epoch: 9 [48128/50176]	Loss: 4.6498
Training Epoch: 9 [49152/50176]	Loss: 4.6258
Training Epoch: 9 [50176/50176]	Loss: 4.6368
2022-12-06 19:40:09.681 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:40:09,704 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.80 energy=483.26
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Up to epoch 10: time=490.50, energy=62706.44, cost=74272.21
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Expected next epoch: time=537.11, energy=69072.74, cost=81533.45
2022-12-06 14:40:09,705 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 7544442700641075.0000, Accuracy: 0.0095
2022-12-06 14:40:10,001 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:40:10,002 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:40:10.013 [ZeusMonitor] Monitor started.
2022-12-06 19:40:10.014 [ZeusMonitor] Running indefinitely. 2022-12-06 19:40:10.014 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:40:10.014 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 14:40:53,602 [ZeusDataLoader(train)] train epoch 11 done: time=43.89 energy=5827.85
2022-12-06 14:40:53,606 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 4.6460
Training Epoch: 10 [2048/50176]	Loss: 4.6240
Training Epoch: 10 [3072/50176]	Loss: 4.6331
Training Epoch: 10 [4096/50176]	Loss: 4.6280
Training Epoch: 10 [5120/50176]	Loss: 4.6534
Training Epoch: 10 [6144/50176]	Loss: 4.6488
Training Epoch: 10 [7168/50176]	Loss: 4.6277
Training Epoch: 10 [8192/50176]	Loss: 4.6496
Training Epoch: 10 [9216/50176]	Loss: 4.6331
Training Epoch: 10 [10240/50176]	Loss: 4.6356
Training Epoch: 10 [11264/50176]	Loss: 4.6390
Training Epoch: 10 [12288/50176]	Loss: 4.6465
Training Epoch: 10 [13312/50176]	Loss: 4.6449
Training Epoch: 10 [14336/50176]	Loss: 4.6476
Training Epoch: 10 [15360/50176]	Loss: 4.6251
Training Epoch: 10 [16384/50176]	Loss: 4.6314
Training Epoch: 10 [17408/50176]	Loss: 4.6234
Training Epoch: 10 [18432/50176]	Loss: 4.6322
Training Epoch: 10 [19456/50176]	Loss: 4.6274
Training Epoch: 10 [20480/50176]	Loss: 4.6349
Training Epoch: 10 [21504/50176]	Loss: 4.6409
Training Epoch: 10 [22528/50176]	Loss: 4.6459
Training Epoch: 10 [23552/50176]	Loss: 4.6176
Training Epoch: 10 [24576/50176]	Loss: 4.6380
Training Epoch: 10 [25600/50176]	Loss: 4.6491
Training Epoch: 10 [26624/50176]	Loss: 4.6311
Training Epoch: 10 [27648/50176]	Loss: 4.6457
Training Epoch: 10 [28672/50176]	Loss: 4.6382
Training Epoch: 10 [29696/50176]	Loss: 4.6570
Training Epoch: 10 [30720/50176]	Loss: 4.6346
Training Epoch: 10 [31744/50176]	Loss: 4.6339
Training Epoch: 10 [32768/50176]	Loss: 4.6300
Training Epoch: 10 [33792/50176]	Loss: 4.6439
Training Epoch: 10 [34816/50176]	Loss: 4.6510
Training Epoch: 10 [35840/50176]	Loss: 4.6420
Training Epoch: 10 [36864/50176]	Loss: 4.6441
Training Epoch: 10 [37888/50176]	Loss: 4.6286
Training Epoch: 10 [38912/50176]	Loss: 4.6341
Training Epoch: 10 [39936/50176]	Loss: 4.6115
Training Epoch: 10 [40960/50176]	Loss: 4.6331
Training Epoch: 10 [41984/50176]	Loss: 4.6377
Training Epoch: 10 [43008/50176]	Loss: 4.6472
Training Epoch: 10 [44032/50176]	Loss: 4.6286
Training Epoch: 10 [45056/50176]	Loss: 4.6198
Training Epoch: 10 [46080/50176]	Loss: 4.6396
Training Epoch: 10 [47104/50176]	Loss: 4.6382
Training Epoch: 10 [48128/50176]	Loss: 4.6313
Training Epoch: 10 [49152/50176]	Loss: 4.6386
Training Epoch: 10 [50176/50176]	Loss: 4.6315
2022-12-06 19:40:57.395 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:40:57,423 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.81 energy=477.08
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Up to epoch 11: time=538.20, energy=69011.38, cost=81598.31
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Expected next epoch: time=584.81, energy=75377.67, cost=88859.54
2022-12-06 14:40:57,424 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 6.1862, Accuracy: 0.0098
2022-12-06 14:40:57,661 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:40:57,662 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:40:57.663 [ZeusMonitor] Monitor started.
2022-12-06 19:40:57.664 [ZeusMonitor] Running indefinitely. 2022-12-06 19:40:57.664 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:40:57.664 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 14:41:41,051 [ZeusDataLoader(train)] train epoch 12 done: time=43.62 energy=5818.89
2022-12-06 14:41:41,054 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 4.6443
Training Epoch: 11 [2048/50176]	Loss: 4.6477
Training Epoch: 11 [3072/50176]	Loss: 4.6215
Training Epoch: 11 [4096/50176]	Loss: 4.6537
Training Epoch: 11 [5120/50176]	Loss: 4.6385
Training Epoch: 11 [6144/50176]	Loss: 4.6232
Training Epoch: 11 [7168/50176]	Loss: 4.6417
Training Epoch: 11 [8192/50176]	Loss: 4.6455
Training Epoch: 11 [9216/50176]	Loss: 4.6495
Training Epoch: 11 [10240/50176]	Loss: 4.6382
Training Epoch: 11 [11264/50176]	Loss: 4.6277
Training Epoch: 11 [12288/50176]	Loss: 4.6335
Training Epoch: 11 [13312/50176]	Loss: 4.6381
Training Epoch: 11 [14336/50176]	Loss: 4.6370
Training Epoch: 11 [15360/50176]	Loss: 4.6289
Training Epoch: 11 [16384/50176]	Loss: 4.6259
Training Epoch: 11 [17408/50176]	Loss: 4.6211
Training Epoch: 11 [18432/50176]	Loss: 4.6447
Training Epoch: 11 [19456/50176]	Loss: 4.6393
Training Epoch: 11 [20480/50176]	Loss: 4.6291
Training Epoch: 11 [21504/50176]	Loss: 4.6405
Training Epoch: 11 [22528/50176]	Loss: 4.6237
Training Epoch: 11 [23552/50176]	Loss: 4.6359
Training Epoch: 11 [24576/50176]	Loss: 4.6435
Training Epoch: 11 [25600/50176]	Loss: 4.6255
Training Epoch: 11 [26624/50176]	Loss: 4.6361
Training Epoch: 11 [27648/50176]	Loss: 4.6346
Training Epoch: 11 [28672/50176]	Loss: 4.6305
Training Epoch: 11 [29696/50176]	Loss: 4.6205
Training Epoch: 11 [30720/50176]	Loss: 4.6380
Training Epoch: 11 [31744/50176]	Loss: 4.6419
Training Epoch: 11 [32768/50176]	Loss: 4.6486
Training Epoch: 11 [33792/50176]	Loss: 4.6379
Training Epoch: 11 [34816/50176]	Loss: 4.6364
Training Epoch: 11 [35840/50176]	Loss: 4.6346
Training Epoch: 11 [36864/50176]	Loss: 4.6452
Training Epoch: 11 [37888/50176]	Loss: 4.6607
Training Epoch: 11 [38912/50176]	Loss: 4.6340
Training Epoch: 11 [39936/50176]	Loss: 4.6415
Training Epoch: 11 [40960/50176]	Loss: 4.6547
Training Epoch: 11 [41984/50176]	Loss: 4.6534
Training Epoch: 11 [43008/50176]	Loss: 4.6399
Training Epoch: 11 [44032/50176]	Loss: 4.6648
Training Epoch: 11 [45056/50176]	Loss: 4.6404
Training Epoch: 11 [46080/50176]	Loss: 4.6306
Training Epoch: 11 [47104/50176]	Loss: 4.6419
Training Epoch: 11 [48128/50176]	Loss: 4.6478
Training Epoch: 11 [49152/50176]	Loss: 4.6528
Training Epoch: 11 [50176/50176]	Loss: 4.6364
2022-12-06 19:41:44.818 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:41:44,870 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.81 energy=476.94
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Up to epoch 12: time=585.63, energy=75307.21, cost=88896.08
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Expected next epoch: time=632.23, energy=81673.50, cost=96157.31
2022-12-06 14:41:44,872 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 1.1281, Accuracy: 0.0098
2022-12-06 14:41:45,121 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:41:45,122 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:41:45.123 [ZeusMonitor] Monitor started.
2022-12-06 19:41:45.124 [ZeusMonitor] Running indefinitely. 2022-12-06 19:41:45.124 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:41:45.124 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 14:42:28,658 [ZeusDataLoader(train)] train epoch 13 done: time=43.78 energy=5819.24
2022-12-06 14:42:28,661 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 4.6331
Training Epoch: 12 [2048/50176]	Loss: 4.6369
Training Epoch: 12 [3072/50176]	Loss: 4.6544
Training Epoch: 12 [4096/50176]	Loss: 4.6383
Training Epoch: 12 [5120/50176]	Loss: 4.6315
Training Epoch: 12 [6144/50176]	Loss: 4.6406
Training Epoch: 12 [7168/50176]	Loss: 4.6337
Training Epoch: 12 [8192/50176]	Loss: 4.6380
Training Epoch: 12 [9216/50176]	Loss: 4.6248
Training Epoch: 12 [10240/50176]	Loss: 4.6413
Training Epoch: 12 [11264/50176]	Loss: 4.6264
Training Epoch: 12 [12288/50176]	Loss: 4.6327
Training Epoch: 12 [13312/50176]	Loss: 4.6286
Training Epoch: 12 [14336/50176]	Loss: 4.6284
Training Epoch: 12 [15360/50176]	Loss: 4.6242
Training Epoch: 12 [16384/50176]	Loss: 4.6318
Training Epoch: 12 [17408/50176]	Loss: 4.6387
Training Epoch: 12 [18432/50176]	Loss: 4.6393
Training Epoch: 12 [19456/50176]	Loss: 4.6293
Training Epoch: 12 [20480/50176]	Loss: 4.6297
Training Epoch: 12 [21504/50176]	Loss: 4.6347
Training Epoch: 12 [22528/50176]	Loss: 4.6297
Training Epoch: 12 [23552/50176]	Loss: 4.6294
Training Epoch: 12 [24576/50176]	Loss: 4.6353
Training Epoch: 12 [25600/50176]	Loss: 4.6162
Training Epoch: 12 [26624/50176]	Loss: 4.6300
Training Epoch: 12 [27648/50176]	Loss: 4.6360
Training Epoch: 12 [28672/50176]	Loss: 4.6406
Training Epoch: 12 [29696/50176]	Loss: 4.6452
Training Epoch: 12 [30720/50176]	Loss: 4.6242
Training Epoch: 12 [31744/50176]	Loss: 4.6380
Training Epoch: 12 [32768/50176]	Loss: 4.6297
Training Epoch: 12 [33792/50176]	Loss: 4.6362
Training Epoch: 12 [34816/50176]	Loss: 4.6440
Training Epoch: 12 [35840/50176]	Loss: 4.6324
Training Epoch: 12 [36864/50176]	Loss: 4.6327
Training Epoch: 12 [37888/50176]	Loss: 4.6318
Training Epoch: 12 [38912/50176]	Loss: 4.6208
Training Epoch: 12 [39936/50176]	Loss: 4.6237
Training Epoch: 12 [40960/50176]	Loss: 4.6507
Training Epoch: 12 [41984/50176]	Loss: 4.6451
Training Epoch: 12 [43008/50176]	Loss: 4.6501
Training Epoch: 12 [44032/50176]	Loss: 4.6565
Training Epoch: 12 [45056/50176]	Loss: 4.6469
Training Epoch: 12 [46080/50176]	Loss: 4.6333
Training Epoch: 12 [47104/50176]	Loss: 4.6275
Training Epoch: 12 [48128/50176]	Loss: 4.6445
Training Epoch: 12 [49152/50176]	Loss: 4.6376
Training Epoch: 12 [50176/50176]	Loss: 4.6289
2022-12-06 19:42:32.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:42:32,480 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.81 energy=476.56
2022-12-06 14:42:32,480 [ZeusDataLoader(train)] Up to epoch 13: time=633.22, energy=81603.01, cost=96208.02
2022-12-06 14:42:32,481 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:42:32,481 [ZeusDataLoader(train)] Expected next epoch: time=679.82, energy=87969.31, cost=103469.25
2022-12-06 14:42:32,482 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0421, Accuracy: 0.0098
2022-12-06 14:42:32,730 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:42:32,731 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:42:32.733 [ZeusMonitor] Monitor started.
2022-12-06 19:42:32.733 [ZeusMonitor] Running indefinitely. 2022-12-06 19:42:32.733 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:42:32.733 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 14:43:16,468 [ZeusDataLoader(train)] train epoch 14 done: time=43.98 energy=5869.77
2022-12-06 14:43:16,472 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 4.6281
Training Epoch: 13 [2048/50176]	Loss: 4.6233
Training Epoch: 13 [3072/50176]	Loss: 4.6380
Training Epoch: 13 [4096/50176]	Loss: 4.6396
Training Epoch: 13 [5120/50176]	Loss: 4.6322
Training Epoch: 13 [6144/50176]	Loss: 4.6335
Training Epoch: 13 [7168/50176]	Loss: 4.6470
Training Epoch: 13 [8192/50176]	Loss: 4.6238
Training Epoch: 13 [9216/50176]	Loss: 4.6529
Training Epoch: 13 [10240/50176]	Loss: 4.6477
Training Epoch: 13 [11264/50176]	Loss: 4.6322
Training Epoch: 13 [12288/50176]	Loss: 4.6465
Training Epoch: 13 [13312/50176]	Loss: 4.6525
Training Epoch: 13 [14336/50176]	Loss: 4.6286
Training Epoch: 13 [15360/50176]	Loss: 4.6340
Training Epoch: 13 [16384/50176]	Loss: 4.6187
Training Epoch: 13 [17408/50176]	Loss: 4.6309
Training Epoch: 13 [18432/50176]	Loss: 4.6371
Training Epoch: 13 [19456/50176]	Loss: 4.6407
Training Epoch: 13 [20480/50176]	Loss: 4.6433
Training Epoch: 13 [21504/50176]	Loss: 4.6244
Training Epoch: 13 [22528/50176]	Loss: 4.6233
Training Epoch: 13 [23552/50176]	Loss: 4.6324
Training Epoch: 13 [24576/50176]	Loss: 4.6296
Training Epoch: 13 [25600/50176]	Loss: 4.6333
Training Epoch: 13 [26624/50176]	Loss: 4.6398
Training Epoch: 13 [27648/50176]	Loss: 4.6240
Training Epoch: 13 [28672/50176]	Loss: 4.6306
Training Epoch: 13 [29696/50176]	Loss: 4.6320
Training Epoch: 13 [30720/50176]	Loss: 4.6379
Training Epoch: 13 [31744/50176]	Loss: 4.6457
Training Epoch: 13 [32768/50176]	Loss: 4.6403
Training Epoch: 13 [33792/50176]	Loss: 4.6451
Training Epoch: 13 [34816/50176]	Loss: 4.6316
Training Epoch: 13 [35840/50176]	Loss: 4.6152
Training Epoch: 13 [36864/50176]	Loss: 4.6370
Training Epoch: 13 [37888/50176]	Loss: 4.6298
Training Epoch: 13 [38912/50176]	Loss: 4.6334
Training Epoch: 13 [39936/50176]	Loss: 4.6311
Training Epoch: 13 [40960/50176]	Loss: 4.6474
Training Epoch: 13 [41984/50176]	Loss: 4.6352
Training Epoch: 13 [43008/50176]	Loss: 4.6370
Training Epoch: 13 [44032/50176]	Loss: 4.6402
Training Epoch: 13 [45056/50176]	Loss: 4.6344
Training Epoch: 13 [46080/50176]	Loss: 4.6337
Training Epoch: 13 [47104/50176]	Loss: 4.6558
Training Epoch: 13 [48128/50176]	Loss: 4.6373
Training Epoch: 13 [49152/50176]	Loss: 4.6448
Training Epoch: 13 [50176/50176]	Loss: 4.6451
2022-12-06 19:43:20.231 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:43:20,270 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.79 energy=485.93
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Up to epoch 14: time=680.99, energy=87958.71, cost=103565.64
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Expected next epoch: time=727.59, energy=94325.01, cost=110826.88
2022-12-06 14:43:20,271 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 493841416401715.1875, Accuracy: 0.0091
2022-12-06 14:43:20,522 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:43:20,523 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:43:20.525 [ZeusMonitor] Monitor started.
2022-12-06 19:43:20.525 [ZeusMonitor] Running indefinitely. 2022-12-06 19:43:20.525 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:43:20.525 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 14:44:04,056 [ZeusDataLoader(train)] train epoch 15 done: time=43.78 energy=5876.40
2022-12-06 14:44:04,060 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 4.6334
Training Epoch: 14 [2048/50176]	Loss: 4.6414
Training Epoch: 14 [3072/50176]	Loss: 4.6352
Training Epoch: 14 [4096/50176]	Loss: 4.6331
Training Epoch: 14 [5120/50176]	Loss: 4.6501
Training Epoch: 14 [6144/50176]	Loss: 4.6317
Training Epoch: 14 [7168/50176]	Loss: 4.6338
Training Epoch: 14 [8192/50176]	Loss: 4.6211
Training Epoch: 14 [9216/50176]	Loss: 4.6321
Training Epoch: 14 [10240/50176]	Loss: 4.6389
Training Epoch: 14 [11264/50176]	Loss: 4.6303
Training Epoch: 14 [12288/50176]	Loss: 4.6385
Training Epoch: 14 [13312/50176]	Loss: 4.6444
Training Epoch: 14 [14336/50176]	Loss: 4.6392
Training Epoch: 14 [15360/50176]	Loss: 4.6379
Training Epoch: 14 [16384/50176]	Loss: 4.6317
Training Epoch: 14 [17408/50176]	Loss: 4.6332
Training Epoch: 14 [18432/50176]	Loss: 4.6247
Training Epoch: 14 [19456/50176]	Loss: 4.6225
Training Epoch: 14 [20480/50176]	Loss: 4.6404
Training Epoch: 14 [21504/50176]	Loss: 4.6371
Training Epoch: 14 [22528/50176]	Loss: 4.6394
Training Epoch: 14 [23552/50176]	Loss: 4.6533
Training Epoch: 14 [24576/50176]	Loss: 4.6429
Training Epoch: 14 [25600/50176]	Loss: 4.6531
Training Epoch: 14 [26624/50176]	Loss: 4.6328
Training Epoch: 14 [27648/50176]	Loss: 4.6312
Training Epoch: 14 [28672/50176]	Loss: 4.6318
Training Epoch: 14 [29696/50176]	Loss: 4.6388
Training Epoch: 14 [30720/50176]	Loss: 4.6452
Training Epoch: 14 [31744/50176]	Loss: 4.6488
Training Epoch: 14 [32768/50176]	Loss: 4.6409
Training Epoch: 14 [33792/50176]	Loss: 4.6484
Training Epoch: 14 [34816/50176]	Loss: 4.6297
Training Epoch: 14 [35840/50176]	Loss: 4.6380
Training Epoch: 14 [36864/50176]	Loss: 4.6390
Training Epoch: 14 [37888/50176]	Loss: 4.6307
Training Epoch: 14 [38912/50176]	Loss: 4.6367
Training Epoch: 14 [39936/50176]	Loss: 4.6254
Training Epoch: 14 [40960/50176]	Loss: 4.6267
Training Epoch: 14 [41984/50176]	Loss: 4.6452
Training Epoch: 14 [43008/50176]	Loss: 4.6332
Training Epoch: 14 [44032/50176]	Loss: 4.6265
Training Epoch: 14 [45056/50176]	Loss: 4.6291
Training Epoch: 14 [46080/50176]	Loss: 4.6375
Training Epoch: 14 [47104/50176]	Loss: 4.6325
Training Epoch: 14 [48128/50176]	Loss: 4.6410
Training Epoch: 14 [49152/50176]	Loss: 4.6412
Training Epoch: 14 [50176/50176]	Loss: 4.6270
2022-12-06 19:44:07.757 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:44:07,772 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.70 energy=466.94
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Up to epoch 15: time=728.47, energy=94302.06, cost=110891.80
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Expected next epoch: time=775.07, energy=100668.35, cost=118153.04
2022-12-06 14:44:07,773 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 165129022.2422, Accuracy: 0.0106
2022-12-06 14:44:08,019 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:44:08,020 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:44:08.022 [ZeusMonitor] Monitor started.
2022-12-06 19:44:08.022 [ZeusMonitor] Running indefinitely. 2022-12-06 19:44:08.022 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:44:08.022 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 14:44:51,619 [ZeusDataLoader(train)] train epoch 16 done: time=43.84 energy=5837.39
2022-12-06 14:44:51,622 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 4.6472
Training Epoch: 15 [2048/50176]	Loss: 4.6323
Training Epoch: 15 [3072/50176]	Loss: 4.6343
Training Epoch: 15 [4096/50176]	Loss: 4.6373
Training Epoch: 15 [5120/50176]	Loss: 4.6437
Training Epoch: 15 [6144/50176]	Loss: 4.6332
Training Epoch: 15 [7168/50176]	Loss: 4.6333
Training Epoch: 15 [8192/50176]	Loss: 4.6388
Training Epoch: 15 [9216/50176]	Loss: 4.6213
Training Epoch: 15 [10240/50176]	Loss: 4.6397
Training Epoch: 15 [11264/50176]	Loss: 4.6428
Training Epoch: 15 [12288/50176]	Loss: 4.6346
Training Epoch: 15 [13312/50176]	Loss: 4.6281
Training Epoch: 15 [14336/50176]	Loss: 4.6328
Training Epoch: 15 [15360/50176]	Loss: 4.6374
Training Epoch: 15 [16384/50176]	Loss: 4.6513
Training Epoch: 15 [17408/50176]	Loss: 4.6360
Training Epoch: 15 [18432/50176]	Loss: 4.6393
Training Epoch: 15 [19456/50176]	Loss: 4.6404
Training Epoch: 15 [20480/50176]	Loss: 4.6408
Training Epoch: 15 [21504/50176]	Loss: 4.6227
Training Epoch: 15 [22528/50176]	Loss: 4.6304
Training Epoch: 15 [23552/50176]	Loss: 4.6306
Training Epoch: 15 [24576/50176]	Loss: 4.6330
Training Epoch: 15 [25600/50176]	Loss: 4.6387
Training Epoch: 15 [26624/50176]	Loss: 4.6254
Training Epoch: 15 [27648/50176]	Loss: 4.6358
Training Epoch: 15 [28672/50176]	Loss: 4.6285
Training Epoch: 15 [29696/50176]	Loss: 4.6354
Training Epoch: 15 [30720/50176]	Loss: 4.6300
Training Epoch: 15 [31744/50176]	Loss: 4.6291
Training Epoch: 15 [32768/50176]	Loss: 4.6388
Training Epoch: 15 [33792/50176]	Loss: 4.6587
Training Epoch: 15 [34816/50176]	Loss: 4.6457
Training Epoch: 15 [35840/50176]	Loss: 4.6547
Training Epoch: 15 [36864/50176]	Loss: 4.6289
Training Epoch: 15 [37888/50176]	Loss: 4.6383
Training Epoch: 15 [38912/50176]	Loss: 4.6216
Training Epoch: 15 [39936/50176]	Loss: 4.6222
Training Epoch: 15 [40960/50176]	Loss: 4.6330
Training Epoch: 15 [41984/50176]	Loss: 4.6310
Training Epoch: 15 [43008/50176]	Loss: 4.6515
Training Epoch: 15 [44032/50176]	Loss: 4.6396
Training Epoch: 15 [45056/50176]	Loss: 4.6324
Training Epoch: 15 [46080/50176]	Loss: 4.6246
Training Epoch: 15 [47104/50176]	Loss: 4.6357
Training Epoch: 15 [48128/50176]	Loss: 4.6291
Training Epoch: 15 [49152/50176]	Loss: 4.6285
Training Epoch: 15 [50176/50176]	Loss: 4.6316
2022-12-06 19:44:55.433 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:44:55,445 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.81 energy=470.07
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Up to epoch 16: time=776.12, energy=100609.52, cost=118215.02
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Expected next epoch: time=822.72, energy=106975.81, cost=125476.25
2022-12-06 14:44:55,446 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0045, Accuracy: 0.0100
2022-12-06 14:44:55,649 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:44:55,650 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:44:55.653 [ZeusMonitor] Monitor started.
2022-12-06 19:44:55.654 [ZeusMonitor] Running indefinitely. 2022-12-06 19:44:55.654 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:44:55.654 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 14:45:39,205 [ZeusDataLoader(train)] train epoch 17 done: time=43.75 energy=5915.61
2022-12-06 14:45:39,209 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 4.6444
Training Epoch: 16 [2048/50176]	Loss: 4.6440
Training Epoch: 16 [3072/50176]	Loss: 4.6343
Training Epoch: 16 [4096/50176]	Loss: 4.6378
Training Epoch: 16 [5120/50176]	Loss: 4.6464
Training Epoch: 16 [6144/50176]	Loss: 4.6375
Training Epoch: 16 [7168/50176]	Loss: 4.6304
Training Epoch: 16 [8192/50176]	Loss: 4.6295
Training Epoch: 16 [9216/50176]	Loss: 4.6369
Training Epoch: 16 [10240/50176]	Loss: 4.6426
Training Epoch: 16 [11264/50176]	Loss: 4.6547
Training Epoch: 16 [12288/50176]	Loss: 4.6458
Training Epoch: 16 [13312/50176]	Loss: 4.6390
Training Epoch: 16 [14336/50176]	Loss: 4.6386
Training Epoch: 16 [15360/50176]	Loss: 4.6442
Training Epoch: 16 [16384/50176]	Loss: 4.6438
Training Epoch: 16 [17408/50176]	Loss: 4.6294
Training Epoch: 16 [18432/50176]	Loss: 4.6299
Training Epoch: 16 [19456/50176]	Loss: 4.6294
Training Epoch: 16 [20480/50176]	Loss: 4.6266
Training Epoch: 16 [21504/50176]	Loss: 4.6446
Training Epoch: 16 [22528/50176]	Loss: 4.6251
Training Epoch: 16 [23552/50176]	Loss: 4.6316
Training Epoch: 16 [24576/50176]	Loss: 4.6328
Training Epoch: 16 [25600/50176]	Loss: 4.6226
Training Epoch: 16 [26624/50176]	Loss: 4.6409
Training Epoch: 16 [27648/50176]	Loss: 4.6372
Training Epoch: 16 [28672/50176]	Loss: 4.6434
Training Epoch: 16 [29696/50176]	Loss: 4.6282
Training Epoch: 16 [30720/50176]	Loss: 4.6291
Training Epoch: 16 [31744/50176]	Loss: 4.6471
Training Epoch: 16 [32768/50176]	Loss: 4.8911
Training Epoch: 16 [33792/50176]	Loss: 4.6268
Training Epoch: 16 [34816/50176]	Loss: 4.6416
Training Epoch: 16 [35840/50176]	Loss: 4.6812
Training Epoch: 16 [36864/50176]	Loss: 4.6288
Training Epoch: 16 [37888/50176]	Loss: 4.6359
Training Epoch: 16 [38912/50176]	Loss: 4.7113
Training Epoch: 16 [39936/50176]	Loss: 4.6393
Training Epoch: 16 [40960/50176]	Loss: 4.6443
Training Epoch: 16 [41984/50176]	Loss: 4.6955
Training Epoch: 16 [43008/50176]	Loss: 4.6309
Training Epoch: 16 [44032/50176]	Loss: 4.6220
Training Epoch: 16 [45056/50176]	Loss: 4.6171
Training Epoch: 16 [46080/50176]	Loss: 4.6417
Training Epoch: 16 [47104/50176]	Loss: 4.6511
Training Epoch: 16 [48128/50176]	Loss: 4.6359
Training Epoch: 16 [49152/50176]	Loss: 4.6555
Training Epoch: 16 [50176/50176]	Loss: 4.6498
2022-12-06 19:45:42.966 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:45:43,020 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=480.63
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Up to epoch 17: time=823.67, energy=107005.76, cost=125574.16
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Expected next epoch: time=870.28, energy=113372.05, cost=132835.39
2022-12-06 14:45:43,022 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 37787832995020.7969, Accuracy: 0.0102
2022-12-06 14:45:43,271 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:45:43,271 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:45:43.273 [ZeusMonitor] Monitor started.
2022-12-06 19:45:43.273 [ZeusMonitor] Running indefinitely. 2022-12-06 19:45:43.273 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:45:43.273 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 14:46:27,035 [ZeusDataLoader(train)] train epoch 18 done: time=44.01 energy=5981.57
2022-12-06 14:46:27,039 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 4.7553
Training Epoch: 17 [2048/50176]	Loss: 4.6324
Training Epoch: 17 [3072/50176]	Loss: 4.6286
Training Epoch: 17 [4096/50176]	Loss: 4.6579
Training Epoch: 17 [5120/50176]	Loss: 4.6308
Training Epoch: 17 [6144/50176]	Loss: 4.6253
Training Epoch: 17 [7168/50176]	Loss: 4.6717
Training Epoch: 17 [8192/50176]	Loss: 4.6279
Training Epoch: 17 [9216/50176]	Loss: 4.6900
Training Epoch: 17 [10240/50176]	Loss: 4.6274
Training Epoch: 17 [11264/50176]	Loss: 4.6384
Training Epoch: 17 [12288/50176]	Loss: 4.6359
Training Epoch: 17 [13312/50176]	Loss: 4.6352
Training Epoch: 17 [14336/50176]	Loss: 4.6385
Training Epoch: 17 [15360/50176]	Loss: 4.7151
Training Epoch: 17 [16384/50176]	Loss: 4.6355
Training Epoch: 17 [17408/50176]	Loss: 4.6340
Training Epoch: 17 [18432/50176]	Loss: 4.6721
Training Epoch: 17 [19456/50176]	Loss: 4.7020
Training Epoch: 17 [20480/50176]	Loss: 4.6473
Training Epoch: 17 [21504/50176]	Loss: 4.7838
Training Epoch: 17 [22528/50176]	Loss: 4.7014
Training Epoch: 17 [23552/50176]	Loss: 4.6956
Training Epoch: 17 [24576/50176]	Loss: 4.6379
Training Epoch: 17 [25600/50176]	Loss: 4.6347
Training Epoch: 17 [26624/50176]	Loss: 4.6394
Training Epoch: 17 [27648/50176]	Loss: 4.6483
Training Epoch: 17 [28672/50176]	Loss: 4.6549
Training Epoch: 17 [29696/50176]	Loss: 4.6408
Training Epoch: 17 [30720/50176]	Loss: 4.6305
Training Epoch: 17 [31744/50176]	Loss: 4.6317
Training Epoch: 17 [32768/50176]	Loss: 4.6477
Training Epoch: 17 [33792/50176]	Loss: 4.6355
Training Epoch: 17 [34816/50176]	Loss: 4.6274
Training Epoch: 17 [35840/50176]	Loss: 4.6286
Training Epoch: 17 [36864/50176]	Loss: 4.6291
Training Epoch: 17 [37888/50176]	Loss: 4.6355
Training Epoch: 17 [38912/50176]	Loss: 4.6520
Training Epoch: 17 [39936/50176]	Loss: 4.6353
Training Epoch: 17 [40960/50176]	Loss: 4.6288
Training Epoch: 17 [41984/50176]	Loss: 4.6411
Training Epoch: 17 [43008/50176]	Loss: 4.6459
Training Epoch: 17 [44032/50176]	Loss: 4.6273
Training Epoch: 17 [45056/50176]	Loss: 4.6202
Training Epoch: 17 [46080/50176]	Loss: 4.6410
Training Epoch: 17 [47104/50176]	Loss: 4.6417
Training Epoch: 17 [48128/50176]	Loss: 4.6537
Training Epoch: 17 [49152/50176]	Loss: 4.6355
Training Epoch: 17 [50176/50176]	Loss: 4.6352
2022-12-06 19:46:30.793 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:46:30,804 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.76 energy=467.85
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Up to epoch 18: time=871.43, energy=113455.18, cost=132978.13
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Expected next epoch: time=918.04, energy=119821.47, cost=140239.37
2022-12-06 14:46:30,806 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 316454054395904.0000, Accuracy: 0.0096
2022-12-06 14:46:31,053 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:46:31,054 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:46:31.056 [ZeusMonitor] Monitor started.
2022-12-06 19:46:31.056 [ZeusMonitor] Running indefinitely. 2022-12-06 19:46:31.056 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:46:31.056 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 14:47:14,687 [ZeusDataLoader(train)] train epoch 19 done: time=43.87 energy=5868.23
2022-12-06 14:47:14,690 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 4.6149
Training Epoch: 18 [2048/50176]	Loss: 4.6300
Training Epoch: 18 [3072/50176]	Loss: 4.6421
Training Epoch: 18 [4096/50176]	Loss: 4.6549
Training Epoch: 18 [5120/50176]	Loss: 4.6402
Training Epoch: 18 [6144/50176]	Loss: 4.6384
Training Epoch: 18 [7168/50176]	Loss: 4.6301
Training Epoch: 18 [8192/50176]	Loss: 4.6244
Training Epoch: 18 [9216/50176]	Loss: 4.6434
Training Epoch: 18 [10240/50176]	Loss: 4.6408
Training Epoch: 18 [11264/50176]	Loss: 4.6409
Training Epoch: 18 [12288/50176]	Loss: 4.6309
Training Epoch: 18 [13312/50176]	Loss: 4.6340
Training Epoch: 18 [14336/50176]	Loss: 4.6498
Training Epoch: 18 [15360/50176]	Loss: 4.6435
Training Epoch: 18 [16384/50176]	Loss: 4.6308
Training Epoch: 18 [17408/50176]	Loss: 4.6229
Training Epoch: 18 [18432/50176]	Loss: 4.6354
Training Epoch: 18 [19456/50176]	Loss: 4.6167
Training Epoch: 18 [20480/50176]	Loss: 4.6422
Training Epoch: 18 [21504/50176]	Loss: 4.6329
Training Epoch: 18 [22528/50176]	Loss: 4.6321
Training Epoch: 18 [23552/50176]	Loss: 4.6319
Training Epoch: 18 [24576/50176]	Loss: 4.6408
Training Epoch: 18 [25600/50176]	Loss: 4.6317
Training Epoch: 18 [26624/50176]	Loss: 4.6306
Training Epoch: 18 [27648/50176]	Loss: 4.6264
Training Epoch: 18 [28672/50176]	Loss: 4.6412
Training Epoch: 18 [29696/50176]	Loss: 4.6472
Training Epoch: 18 [30720/50176]	Loss: 4.6378
Training Epoch: 18 [31744/50176]	Loss: 4.6381
Training Epoch: 18 [32768/50176]	Loss: 4.6302
Training Epoch: 18 [33792/50176]	Loss: 4.6361
Training Epoch: 18 [34816/50176]	Loss: 4.6298
Training Epoch: 18 [35840/50176]	Loss: 4.6251
Training Epoch: 18 [36864/50176]	Loss: 4.6334
Training Epoch: 18 [37888/50176]	Loss: 4.6382
Training Epoch: 18 [38912/50176]	Loss: 4.6293
Training Epoch: 18 [39936/50176]	Loss: 4.6325
Training Epoch: 18 [40960/50176]	Loss: 4.6501
Training Epoch: 18 [41984/50176]	Loss: 4.6420
Training Epoch: 18 [43008/50176]	Loss: 4.6291
Training Epoch: 18 [44032/50176]	Loss: 4.6373
Training Epoch: 18 [45056/50176]	Loss: 4.6215
Training Epoch: 18 [46080/50176]	Loss: 4.6292
Training Epoch: 18 [47104/50176]	Loss: 4.6429
Training Epoch: 18 [48128/50176]	Loss: 4.6427
Training Epoch: 18 [49152/50176]	Loss: 4.6378
Training Epoch: 18 [50176/50176]	Loss: 4.6339
2022-12-06 19:47:18.452 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:47:18,467 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.77 energy=463.94
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Up to epoch 19: time=919.08, energy=119787.35, cost=140312.77
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Expected next epoch: time=965.68, energy=126153.64, cost=147574.00
2022-12-06 14:47:18,468 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 202628612441.6000, Accuracy: 0.0090
2022-12-06 14:47:18,724 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:47:18,725 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:47:18.726 [ZeusMonitor] Monitor started.
2022-12-06 19:47:18.727 [ZeusMonitor] Running indefinitely. 2022-12-06 19:47:18.727 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:47:18.727 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 14:48:02,483 [ZeusDataLoader(train)] train epoch 20 done: time=44.01 energy=5847.68
2022-12-06 14:48:02,487 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 4.6266
Training Epoch: 19 [2048/50176]	Loss: 4.6415
Training Epoch: 19 [3072/50176]	Loss: 4.6222
Training Epoch: 19 [4096/50176]	Loss: 4.6367
Training Epoch: 19 [5120/50176]	Loss: 4.6368
Training Epoch: 19 [6144/50176]	Loss: 4.6319
Training Epoch: 19 [7168/50176]	Loss: 4.6573
Training Epoch: 19 [8192/50176]	Loss: 4.6293
Training Epoch: 19 [9216/50176]	Loss: 4.6392
Training Epoch: 19 [10240/50176]	Loss: 4.6407
Training Epoch: 19 [11264/50176]	Loss: 4.6452
Training Epoch: 19 [12288/50176]	Loss: 4.6384
Training Epoch: 19 [13312/50176]	Loss: 4.6195
Training Epoch: 19 [14336/50176]	Loss: 4.6256
Training Epoch: 19 [15360/50176]	Loss: 4.6318
Training Epoch: 19 [16384/50176]	Loss: 4.6334
Training Epoch: 19 [17408/50176]	Loss: 4.6350
Training Epoch: 19 [18432/50176]	Loss: 4.6471
Training Epoch: 19 [19456/50176]	Loss: 4.6379
Training Epoch: 19 [20480/50176]	Loss: 4.6322
Training Epoch: 19 [21504/50176]	Loss: 4.6257
Training Epoch: 19 [22528/50176]	Loss: 4.6335
Training Epoch: 19 [23552/50176]	Loss: 4.6342
Training Epoch: 19 [24576/50176]	Loss: 4.6370
Training Epoch: 19 [25600/50176]	Loss: 4.6201
Training Epoch: 19 [26624/50176]	Loss: 4.6412
Training Epoch: 19 [27648/50176]	Loss: 4.6377
Training Epoch: 19 [28672/50176]	Loss: 4.6311
Training Epoch: 19 [29696/50176]	Loss: 4.6420
Training Epoch: 19 [30720/50176]	Loss: 4.6395
Training Epoch: 19 [31744/50176]	Loss: 4.6290
Training Epoch: 19 [32768/50176]	Loss: 4.6385
Training Epoch: 19 [33792/50176]	Loss: 4.6445
Training Epoch: 19 [34816/50176]	Loss: 4.6310
Training Epoch: 19 [35840/50176]	Loss: 4.6275
Training Epoch: 19 [36864/50176]	Loss: 4.6432
Training Epoch: 19 [37888/50176]	Loss: 4.6374
Training Epoch: 19 [38912/50176]	Loss: 4.6465
Training Epoch: 19 [39936/50176]	Loss: 4.6234
Training Epoch: 19 [40960/50176]	Loss: 4.6396
Training Epoch: 19 [41984/50176]	Loss: 4.6407
Training Epoch: 19 [43008/50176]	Loss: 4.6359
Training Epoch: 19 [44032/50176]	Loss: 4.6324
Training Epoch: 19 [45056/50176]	Loss: 4.6376
Training Epoch: 19 [46080/50176]	Loss: 4.6220
Training Epoch: 19 [47104/50176]	Loss: 4.6514
Training Epoch: 19 [48128/50176]	Loss: 4.6292
Training Epoch: 19 [49152/50176]	Loss: 4.6437
Training Epoch: 19 [50176/50176]	Loss: 4.6291
2022-12-06 19:48:06.232 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:48:06,261 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.77 energy=463.24
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Up to epoch 20: time=966.85, energy=126098.27, cost=147648.45
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Expected next epoch: time=1013.46, energy=132464.56, cost=154909.69
2022-12-06 14:48:06,263 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 11548.6541, Accuracy: 0.0098
2022-12-06 14:48:06,519 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:48:06,520 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:48:06.522 [ZeusMonitor] Monitor started.
2022-12-06 19:48:06.522 [ZeusMonitor] Running indefinitely. 2022-12-06 19:48:06.522 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:48:06.522 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 14:48:50,059 [ZeusDataLoader(train)] train epoch 21 done: time=43.79 energy=5819.91
2022-12-06 14:48:50,062 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 4.6322
Training Epoch: 20 [2048/50176]	Loss: 4.6415
Training Epoch: 20 [3072/50176]	Loss: 4.6476
Training Epoch: 20 [4096/50176]	Loss: 4.6416
Training Epoch: 20 [5120/50176]	Loss: 4.6520
Training Epoch: 20 [6144/50176]	Loss: 4.6182
Training Epoch: 20 [7168/50176]	Loss: 4.6279
Training Epoch: 20 [8192/50176]	Loss: 4.6597
Training Epoch: 20 [9216/50176]	Loss: 4.6475
Training Epoch: 20 [10240/50176]	Loss: 4.6460
Training Epoch: 20 [11264/50176]	Loss: 4.6363
Training Epoch: 20 [12288/50176]	Loss: 4.6393
Training Epoch: 20 [13312/50176]	Loss: 4.6354
Training Epoch: 20 [14336/50176]	Loss: 4.6424
Training Epoch: 20 [15360/50176]	Loss: 4.6462
Training Epoch: 20 [16384/50176]	Loss: 4.6421
Training Epoch: 20 [17408/50176]	Loss: 4.6516
Training Epoch: 20 [18432/50176]	Loss: 4.6518
Training Epoch: 20 [19456/50176]	Loss: 4.6265
Training Epoch: 20 [20480/50176]	Loss: 4.6417
Training Epoch: 20 [21504/50176]	Loss: 4.6183
Training Epoch: 20 [22528/50176]	Loss: 4.6411
Training Epoch: 20 [23552/50176]	Loss: 4.6199
Training Epoch: 20 [24576/50176]	Loss: 4.6363
Training Epoch: 20 [25600/50176]	Loss: 4.6413
Training Epoch: 20 [26624/50176]	Loss: 4.6244
Training Epoch: 20 [27648/50176]	Loss: 4.6283
Training Epoch: 20 [28672/50176]	Loss: 4.6420
Training Epoch: 20 [29696/50176]	Loss: 4.6374
Training Epoch: 20 [30720/50176]	Loss: 4.6525
Training Epoch: 20 [31744/50176]	Loss: 4.6479
Training Epoch: 20 [32768/50176]	Loss: 4.6453
Training Epoch: 20 [33792/50176]	Loss: 4.6260
Training Epoch: 20 [34816/50176]	Loss: 4.6294
Training Epoch: 20 [35840/50176]	Loss: 4.6327
Training Epoch: 20 [36864/50176]	Loss: 4.6393
Training Epoch: 20 [37888/50176]	Loss: 4.6414
Training Epoch: 20 [38912/50176]	Loss: 4.6415
Training Epoch: 20 [39936/50176]	Loss: 4.6387
Training Epoch: 20 [40960/50176]	Loss: 4.6323
Training Epoch: 20 [41984/50176]	Loss: 4.6450
Training Epoch: 20 [43008/50176]	Loss: 4.6392
Training Epoch: 20 [44032/50176]	Loss: 4.6291
Training Epoch: 20 [45056/50176]	Loss: 4.6458
Training Epoch: 20 [46080/50176]	Loss: 4.6395
Training Epoch: 20 [47104/50176]	Loss: 4.6433
Training Epoch: 20 [48128/50176]	Loss: 4.6340
Training Epoch: 20 [49152/50176]	Loss: 4.6374
Training Epoch: 20 [50176/50176]	Loss: 4.6291
2022-12-06 19:48:53.855 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:48:53,882 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.81 energy=476.91
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Up to epoch 21: time=1014.45, energy=132395.09, cost=154961.82
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Expected next epoch: time=1061.06, energy=138761.38, cost=162223.05
2022-12-06 14:48:53,883 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 7359.5478, Accuracy: 0.0098
2022-12-06 14:48:54,131 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:48:54,132 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:48:54.134 [ZeusMonitor] Monitor started.
2022-12-06 19:48:54.134 [ZeusMonitor] Running indefinitely. 2022-12-06 19:48:54.134 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:48:54.134 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 14:49:37,538 [ZeusDataLoader(train)] train epoch 22 done: time=43.65 energy=5821.03
2022-12-06 14:49:37,541 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 4.6512
Training Epoch: 21 [2048/50176]	Loss: 4.6429
Training Epoch: 21 [3072/50176]	Loss: 4.6292
Training Epoch: 21 [4096/50176]	Loss: 4.6510
Training Epoch: 21 [5120/50176]	Loss: 4.6296
Training Epoch: 21 [6144/50176]	Loss: 4.6475
Training Epoch: 21 [7168/50176]	Loss: 4.6344
Training Epoch: 21 [8192/50176]	Loss: 4.6396
Training Epoch: 21 [9216/50176]	Loss: 4.6457
Training Epoch: 21 [10240/50176]	Loss: 4.6347
Training Epoch: 21 [11264/50176]	Loss: 4.6309
Training Epoch: 21 [12288/50176]	Loss: 4.6414
Training Epoch: 21 [13312/50176]	Loss: 4.6483
Training Epoch: 21 [14336/50176]	Loss: 4.6312
Training Epoch: 21 [15360/50176]	Loss: 4.6260
Training Epoch: 21 [16384/50176]	Loss: 4.6462
Training Epoch: 21 [17408/50176]	Loss: 4.6493
Training Epoch: 21 [18432/50176]	Loss: 4.6502
Training Epoch: 21 [19456/50176]	Loss: 4.6426
Training Epoch: 21 [20480/50176]	Loss: 4.6291
Training Epoch: 21 [21504/50176]	Loss: 4.6294
Training Epoch: 21 [22528/50176]	Loss: 4.6473
Training Epoch: 21 [23552/50176]	Loss: 4.6333
Training Epoch: 21 [24576/50176]	Loss: 4.6328
Training Epoch: 21 [25600/50176]	Loss: 4.6476
Training Epoch: 21 [26624/50176]	Loss: 4.6366
Training Epoch: 21 [27648/50176]	Loss: 4.6362
Training Epoch: 21 [28672/50176]	Loss: 4.6372
Training Epoch: 21 [29696/50176]	Loss: 4.6401
Training Epoch: 21 [30720/50176]	Loss: 4.6346
Training Epoch: 21 [31744/50176]	Loss: 4.6355
Training Epoch: 21 [32768/50176]	Loss: 4.6281
Training Epoch: 21 [33792/50176]	Loss: 4.6325
Training Epoch: 21 [34816/50176]	Loss: 4.6318
Training Epoch: 21 [35840/50176]	Loss: 4.6388
Training Epoch: 21 [36864/50176]	Loss: 4.6291
Training Epoch: 21 [37888/50176]	Loss: 4.6225
Training Epoch: 21 [38912/50176]	Loss: 4.6312
Training Epoch: 21 [39936/50176]	Loss: 4.6361
Training Epoch: 21 [40960/50176]	Loss: 4.6315
Training Epoch: 21 [41984/50176]	Loss: 4.6461
Training Epoch: 21 [43008/50176]	Loss: 4.6362
Training Epoch: 21 [44032/50176]	Loss: 4.6326
Training Epoch: 21 [45056/50176]	Loss: 4.6384
Training Epoch: 21 [46080/50176]	Loss: 4.6373
Training Epoch: 21 [47104/50176]	Loss: 4.6314
Training Epoch: 21 [48128/50176]	Loss: 4.6362
Training Epoch: 21 [49152/50176]	Loss: 4.6292
Training Epoch: 21 [50176/50176]	Loss: 4.6429
2022-12-06 19:49:41.302 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:49:41,360 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=478.00
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Up to epoch 22: time=1061.91, energy=138694.12, cost=162263.78
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Expected next epoch: time=1108.51, energy=145060.41, cost=169525.01
2022-12-06 14:49:41,361 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:49:41,603 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:49:41,603 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:49:41.617 [ZeusMonitor] Monitor started.
2022-12-06 19:49:41.617 [ZeusMonitor] Running indefinitely. 2022-12-06 19:49:41.617 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:49:41.617 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 14:50:25,263 [ZeusDataLoader(train)] train epoch 23 done: time=43.89 energy=5826.14
2022-12-06 14:50:25,267 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 4.6312
Training Epoch: 22 [2048/50176]	Loss: 4.6266
Training Epoch: 22 [3072/50176]	Loss: 4.6320
Training Epoch: 22 [4096/50176]	Loss: 4.6302
Training Epoch: 22 [5120/50176]	Loss: 4.6298
Training Epoch: 22 [6144/50176]	Loss: 4.6329
Training Epoch: 22 [7168/50176]	Loss: 4.6455
Training Epoch: 22 [8192/50176]	Loss: 4.6367
Training Epoch: 22 [9216/50176]	Loss: 4.6468
Training Epoch: 22 [10240/50176]	Loss: 4.6479
Training Epoch: 22 [11264/50176]	Loss: 4.6228
Training Epoch: 22 [12288/50176]	Loss: 4.6334
Training Epoch: 22 [13312/50176]	Loss: 4.6317
Training Epoch: 22 [14336/50176]	Loss: 4.6508
Training Epoch: 22 [15360/50176]	Loss: 4.6478
Training Epoch: 22 [16384/50176]	Loss: 4.6419
Training Epoch: 22 [17408/50176]	Loss: 4.6266
Training Epoch: 22 [18432/50176]	Loss: 4.6340
Training Epoch: 22 [19456/50176]	Loss: 4.6370
Training Epoch: 22 [20480/50176]	Loss: 4.6364
Training Epoch: 22 [21504/50176]	Loss: 4.6221
Training Epoch: 22 [22528/50176]	Loss: 4.6330
Training Epoch: 22 [23552/50176]	Loss: 4.6368
Training Epoch: 22 [24576/50176]	Loss: 4.6433
Training Epoch: 22 [25600/50176]	Loss: 4.6383
Training Epoch: 22 [26624/50176]	Loss: 4.6308
Training Epoch: 22 [27648/50176]	Loss: 4.6407
Training Epoch: 22 [28672/50176]	Loss: 4.6387
Training Epoch: 22 [29696/50176]	Loss: 4.6334
Training Epoch: 22 [30720/50176]	Loss: 4.6396
Training Epoch: 22 [31744/50176]	Loss: 4.6253
Training Epoch: 22 [32768/50176]	Loss: 4.6400
Training Epoch: 22 [33792/50176]	Loss: 4.6389
Training Epoch: 22 [34816/50176]	Loss: 4.6356
Training Epoch: 22 [35840/50176]	Loss: 4.6387
Training Epoch: 22 [36864/50176]	Loss: 4.6431
Training Epoch: 22 [37888/50176]	Loss: 4.6295
Training Epoch: 22 [38912/50176]	Loss: 4.6369
Training Epoch: 22 [39936/50176]	Loss: 4.6425
Training Epoch: 22 [40960/50176]	Loss: 4.6450
Training Epoch: 22 [41984/50176]	Loss: 4.6412
Training Epoch: 22 [43008/50176]	Loss: 4.6353
Training Epoch: 22 [44032/50176]	Loss: 4.6411
Training Epoch: 22 [45056/50176]	Loss: 4.6274
Training Epoch: 22 [46080/50176]	Loss: 4.6415
Training Epoch: 22 [47104/50176]	Loss: 4.6315
Training Epoch: 22 [48128/50176]	Loss: 4.6380
Training Epoch: 22 [49152/50176]	Loss: 4.6290
Training Epoch: 22 [50176/50176]	Loss: 4.6331
2022-12-06 19:50:29.034 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:50:29,088 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.81 energy=476.94
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Up to epoch 23: time=1109.61, energy=144997.20, cost=169589.66
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Expected next epoch: time=1156.22, energy=151363.50, cost=176850.89
2022-12-06 14:50:29,090 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 4158.7793, Accuracy: 0.0098
2022-12-06 14:50:29,297 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:50:29,298 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:50:29.302 [ZeusMonitor] Monitor started.
2022-12-06 19:50:29.302 [ZeusMonitor] Running indefinitely. 2022-12-06 19:50:29.302 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:50:29.302 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 14:51:12,800 [ZeusDataLoader(train)] train epoch 24 done: time=43.70 energy=5825.36
2022-12-06 14:51:12,803 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 4.6389
Training Epoch: 23 [2048/50176]	Loss: 4.6192
Training Epoch: 23 [3072/50176]	Loss: 4.6261
Training Epoch: 23 [4096/50176]	Loss: 4.6411
Training Epoch: 23 [5120/50176]	Loss: 4.6234
Training Epoch: 23 [6144/50176]	Loss: 4.6277
Training Epoch: 23 [7168/50176]	Loss: 4.6505
Training Epoch: 23 [8192/50176]	Loss: 4.6444
Training Epoch: 23 [9216/50176]	Loss: 4.6186
Training Epoch: 23 [10240/50176]	Loss: 4.6337
Training Epoch: 23 [11264/50176]	Loss: 4.6320
Training Epoch: 23 [12288/50176]	Loss: 4.6297
Training Epoch: 23 [13312/50176]	Loss: 4.6387
Training Epoch: 23 [14336/50176]	Loss: 4.6518
Training Epoch: 23 [15360/50176]	Loss: 4.6505
Training Epoch: 23 [16384/50176]	Loss: 4.6545
Training Epoch: 23 [17408/50176]	Loss: 4.6272
Training Epoch: 23 [18432/50176]	Loss: 4.6278
Training Epoch: 23 [19456/50176]	Loss: 4.6410
Training Epoch: 23 [20480/50176]	Loss: 4.6342
Training Epoch: 23 [21504/50176]	Loss: 4.6401
Training Epoch: 23 [22528/50176]	Loss: 4.6365
Training Epoch: 23 [23552/50176]	Loss: 4.6450
Training Epoch: 23 [24576/50176]	Loss: 4.6489
Training Epoch: 23 [25600/50176]	Loss: 4.6302
Training Epoch: 23 [26624/50176]	Loss: 4.6262
Training Epoch: 23 [27648/50176]	Loss: 4.6359
Training Epoch: 23 [28672/50176]	Loss: 4.6436
Training Epoch: 23 [29696/50176]	Loss: 4.6424
Training Epoch: 23 [30720/50176]	Loss: 4.6548
Training Epoch: 23 [31744/50176]	Loss: 4.6490
Training Epoch: 23 [32768/50176]	Loss: 4.6494
Training Epoch: 23 [33792/50176]	Loss: 4.6498
Training Epoch: 23 [34816/50176]	Loss: 4.6345
Training Epoch: 23 [35840/50176]	Loss: 4.6369
Training Epoch: 23 [36864/50176]	Loss: 4.6454
Training Epoch: 23 [37888/50176]	Loss: 4.6326
Training Epoch: 23 [38912/50176]	Loss: 4.6446
Training Epoch: 23 [39936/50176]	Loss: 4.6360
Training Epoch: 23 [40960/50176]	Loss: 4.6374
Training Epoch: 23 [41984/50176]	Loss: 4.6345
Training Epoch: 23 [43008/50176]	Loss: 4.6338
Training Epoch: 23 [44032/50176]	Loss: 4.6230
Training Epoch: 23 [45056/50176]	Loss: 4.6457
Training Epoch: 23 [46080/50176]	Loss: 4.6428
Training Epoch: 23 [47104/50176]	Loss: 4.6329
Training Epoch: 23 [48128/50176]	Loss: 4.6324
Training Epoch: 23 [49152/50176]	Loss: 4.6329
Training Epoch: 23 [50176/50176]	Loss: 4.6312
2022-12-06 19:51:16.536 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:51:16,576 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.76 energy=464.83
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Up to epoch 24: time=1157.08, energy=151287.39, cost=176888.09
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Expected next epoch: time=1203.69, energy=157653.69, cost=184149.33
2022-12-06 14:51:16,577 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 147.0823, Accuracy: 0.0098
2022-12-06 14:51:16,818 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:51:16,819 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:51:16.820 [ZeusMonitor] Monitor started.
2022-12-06 19:51:16.821 [ZeusMonitor] Running indefinitely. 2022-12-06 19:51:16.821 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:51:16.821 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 14:52:00,480 [ZeusDataLoader(train)] train epoch 25 done: time=43.89 energy=5834.70
2022-12-06 14:52:00,483 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 4.6235
Training Epoch: 24 [2048/50176]	Loss: 4.6368
Training Epoch: 24 [3072/50176]	Loss: 4.6344
Training Epoch: 24 [4096/50176]	Loss: 4.6339
Training Epoch: 24 [5120/50176]	Loss: 4.6331
Training Epoch: 24 [6144/50176]	Loss: 4.6356
Training Epoch: 24 [7168/50176]	Loss: 4.6426
Training Epoch: 24 [8192/50176]	Loss: 4.6404
Training Epoch: 24 [9216/50176]	Loss: 4.6396
Training Epoch: 24 [10240/50176]	Loss: 4.6299
Training Epoch: 24 [11264/50176]	Loss: 4.6202
Training Epoch: 24 [12288/50176]	Loss: 4.6419
Training Epoch: 24 [13312/50176]	Loss: 4.6400
Training Epoch: 24 [14336/50176]	Loss: 4.6485
Training Epoch: 24 [15360/50176]	Loss: 4.6519
Training Epoch: 24 [16384/50176]	Loss: 4.6271
Training Epoch: 24 [17408/50176]	Loss: 4.6132
Training Epoch: 24 [18432/50176]	Loss: 4.6366
Training Epoch: 24 [19456/50176]	Loss: 4.6365
Training Epoch: 24 [20480/50176]	Loss: 4.6353
Training Epoch: 24 [21504/50176]	Loss: 4.6460
Training Epoch: 24 [22528/50176]	Loss: 4.6423
Training Epoch: 24 [23552/50176]	Loss: 4.6361
Training Epoch: 24 [24576/50176]	Loss: 4.6429
Training Epoch: 24 [25600/50176]	Loss: 4.6330
Training Epoch: 24 [26624/50176]	Loss: 4.6501
Training Epoch: 24 [27648/50176]	Loss: 4.6462
Training Epoch: 24 [28672/50176]	Loss: 4.6458
Training Epoch: 24 [29696/50176]	Loss: 4.6381
Training Epoch: 24 [30720/50176]	Loss: 4.6418
Training Epoch: 24 [31744/50176]	Loss: 4.6390
Training Epoch: 24 [32768/50176]	Loss: 4.6566
Training Epoch: 24 [33792/50176]	Loss: 4.6306
Training Epoch: 24 [34816/50176]	Loss: 4.6513
Training Epoch: 24 [35840/50176]	Loss: 4.6227
Training Epoch: 24 [36864/50176]	Loss: 4.6463
Training Epoch: 24 [37888/50176]	Loss: 4.6488
Training Epoch: 24 [38912/50176]	Loss: 4.6520
Training Epoch: 24 [39936/50176]	Loss: 4.6269
Training Epoch: 24 [40960/50176]	Loss: 4.6266
Training Epoch: 24 [41984/50176]	Loss: 4.6510
Training Epoch: 24 [43008/50176]	Loss: 4.6332
Training Epoch: 24 [44032/50176]	Loss: 4.6442
Training Epoch: 24 [45056/50176]	Loss: 4.6395
Training Epoch: 24 [46080/50176]	Loss: 4.6433
Training Epoch: 24 [47104/50176]	Loss: 4.6425
Training Epoch: 24 [48128/50176]	Loss: 4.6498
Training Epoch: 24 [49152/50176]	Loss: 4.6357
Training Epoch: 24 [50176/50176]	Loss: 4.6292
2022-12-06 19:52:04.214 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:52:04,252 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.76 energy=462.26
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Up to epoch 25: time=1204.73, energy=157584.34, cost=184206.46
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Expected next epoch: time=1251.34, energy=163950.64, cost=191467.69
2022-12-06 14:52:04,254 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 67.7428, Accuracy: 0.0098
2022-12-06 14:52:04,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:52:04,502 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:52:04.511 [ZeusMonitor] Monitor started.
2022-12-06 19:52:04.512 [ZeusMonitor] Running indefinitely. 2022-12-06 19:52:04.512 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:52:04.512 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 14:52:48,031 [ZeusDataLoader(train)] train epoch 26 done: time=43.77 energy=5827.48
2022-12-06 14:52:48,034 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 4.6410
Training Epoch: 25 [2048/50176]	Loss: 4.6341
Training Epoch: 25 [3072/50176]	Loss: 4.6388
Training Epoch: 25 [4096/50176]	Loss: 4.6327
Training Epoch: 25 [5120/50176]	Loss: 4.6366
Training Epoch: 25 [6144/50176]	Loss: 4.6328
Training Epoch: 25 [7168/50176]	Loss: 4.6290
Training Epoch: 25 [8192/50176]	Loss: 4.6245
Training Epoch: 25 [9216/50176]	Loss: 4.6470
Training Epoch: 25 [10240/50176]	Loss: 4.6225
Training Epoch: 25 [11264/50176]	Loss: 4.6318
Training Epoch: 25 [12288/50176]	Loss: 4.6313
Training Epoch: 25 [13312/50176]	Loss: 4.6273
Training Epoch: 25 [14336/50176]	Loss: 4.6330
Training Epoch: 25 [15360/50176]	Loss: 4.6388
Training Epoch: 25 [16384/50176]	Loss: 4.6267
Training Epoch: 25 [17408/50176]	Loss: 4.6381
Training Epoch: 25 [18432/50176]	Loss: 4.6549
Training Epoch: 25 [19456/50176]	Loss: 4.6409
Training Epoch: 25 [20480/50176]	Loss: 4.6400
Training Epoch: 25 [21504/50176]	Loss: 4.6362
Training Epoch: 25 [22528/50176]	Loss: 4.6393
Training Epoch: 25 [23552/50176]	Loss: 4.6407
Training Epoch: 25 [24576/50176]	Loss: 4.6302
Training Epoch: 25 [25600/50176]	Loss: 4.6461
Training Epoch: 25 [26624/50176]	Loss: 4.6285
Training Epoch: 25 [27648/50176]	Loss: 4.6306
Training Epoch: 25 [28672/50176]	Loss: 4.6329
Training Epoch: 25 [29696/50176]	Loss: 4.6371
Training Epoch: 25 [30720/50176]	Loss: 4.6330
Training Epoch: 25 [31744/50176]	Loss: 4.6569
Training Epoch: 25 [32768/50176]	Loss: 4.6542
Training Epoch: 25 [33792/50176]	Loss: 4.6359
Training Epoch: 25 [34816/50176]	Loss: 4.6359
Training Epoch: 25 [35840/50176]	Loss: 4.6370
Training Epoch: 25 [36864/50176]	Loss: 4.6428
Training Epoch: 25 [37888/50176]	Loss: 4.6403
Training Epoch: 25 [38912/50176]	Loss: 4.6287
Training Epoch: 25 [39936/50176]	Loss: 4.6279
Training Epoch: 25 [40960/50176]	Loss: 4.6457
Training Epoch: 25 [41984/50176]	Loss: 4.6480
Training Epoch: 25 [43008/50176]	Loss: 4.6355
Training Epoch: 25 [44032/50176]	Loss: 4.6435
Training Epoch: 25 [45056/50176]	Loss: 4.6409
Training Epoch: 25 [46080/50176]	Loss: 4.6410
Training Epoch: 25 [47104/50176]	Loss: 4.6376
Training Epoch: 25 [48128/50176]	Loss: 4.6440
Training Epoch: 25 [49152/50176]	Loss: 4.6433
Training Epoch: 25 [50176/50176]	Loss: 4.6272
2022-12-06 19:52:51.790 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:52:51,821 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.78 energy=483.69
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Up to epoch 26: time=1252.28, energy=163895.51, cost=191522.59
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Expected next epoch: time=1298.89, energy=170261.81, cost=198783.82
2022-12-06 14:52:51,823 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 10796.0790, Accuracy: 0.0099
2022-12-06 14:52:52,071 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:52:52,072 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:52:52.073 [ZeusMonitor] Monitor started.
2022-12-06 19:52:52.073 [ZeusMonitor] Running indefinitely. 2022-12-06 19:52:52.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:52:52.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 14:53:35,704 [ZeusDataLoader(train)] train epoch 27 done: time=43.87 energy=5825.93
2022-12-06 14:53:35,707 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 4.6369
Training Epoch: 26 [2048/50176]	Loss: 4.6321
Training Epoch: 26 [3072/50176]	Loss: 4.6512
Training Epoch: 26 [4096/50176]	Loss: 4.6407
Training Epoch: 26 [5120/50176]	Loss: 4.6402
Training Epoch: 26 [6144/50176]	Loss: 4.6465
Training Epoch: 26 [7168/50176]	Loss: 4.6390
Training Epoch: 26 [8192/50176]	Loss: 4.6495
Training Epoch: 26 [9216/50176]	Loss: 4.6460
Training Epoch: 26 [10240/50176]	Loss: 4.6374
Training Epoch: 26 [11264/50176]	Loss: 4.6275
Training Epoch: 26 [12288/50176]	Loss: 4.6449
Training Epoch: 26 [13312/50176]	Loss: 4.6492
Training Epoch: 26 [14336/50176]	Loss: 4.6321
Training Epoch: 26 [15360/50176]	Loss: 4.6466
Training Epoch: 26 [16384/50176]	Loss: 4.6402
Training Epoch: 26 [17408/50176]	Loss: 4.6281
Training Epoch: 26 [18432/50176]	Loss: 4.6268
Training Epoch: 26 [19456/50176]	Loss: 4.6342
Training Epoch: 26 [20480/50176]	Loss: 4.6416
Training Epoch: 26 [21504/50176]	Loss: 4.6396
Training Epoch: 26 [22528/50176]	Loss: 4.6312
Training Epoch: 26 [23552/50176]	Loss: 4.6377
Training Epoch: 26 [24576/50176]	Loss: 4.6345
Training Epoch: 26 [25600/50176]	Loss: 4.6460
Training Epoch: 26 [26624/50176]	Loss: 4.6378
Training Epoch: 26 [27648/50176]	Loss: 4.6512
Training Epoch: 26 [28672/50176]	Loss: 4.6570
Training Epoch: 26 [29696/50176]	Loss: 4.6387
Training Epoch: 26 [30720/50176]	Loss: 4.6492
Training Epoch: 26 [31744/50176]	Loss: 4.6322
Training Epoch: 26 [32768/50176]	Loss: 4.6364
Training Epoch: 26 [33792/50176]	Loss: 4.6424
Training Epoch: 26 [34816/50176]	Loss: 4.6484
Training Epoch: 26 [35840/50176]	Loss: 4.6469
Training Epoch: 26 [36864/50176]	Loss: 4.6297
Training Epoch: 26 [37888/50176]	Loss: 4.6512
Training Epoch: 26 [38912/50176]	Loss: 4.6385
Training Epoch: 26 [39936/50176]	Loss: 4.6315
Training Epoch: 26 [40960/50176]	Loss: 4.6460
Training Epoch: 26 [41984/50176]	Loss: 4.6461
Training Epoch: 26 [43008/50176]	Loss: 4.6380
Training Epoch: 26 [44032/50176]	Loss: 4.6301
Training Epoch: 26 [45056/50176]	Loss: 4.6303
Training Epoch: 26 [46080/50176]	Loss: 4.6395
Training Epoch: 26 [47104/50176]	Loss: 4.6347
Training Epoch: 26 [48128/50176]	Loss: 4.6292
Training Epoch: 26 [49152/50176]	Loss: 4.6448
Training Epoch: 26 [50176/50176]	Loss: 4.6420
2022-12-06 19:53:39.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:53:39,458 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.74 energy=466.08
2022-12-06 14:53:39,458 [ZeusDataLoader(train)] Up to epoch 27: time=1299.90, energy=170187.52, cost=198835.03
2022-12-06 14:53:39,458 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:53:39,459 [ZeusDataLoader(train)] Expected next epoch: time=1346.51, energy=176553.82, cost=206096.27
2022-12-06 14:53:39,459 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 31.0042, Accuracy: 0.0098
2022-12-06 14:53:39,711 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:53:39,712 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:53:39.714 [ZeusMonitor] Monitor started.
2022-12-06 19:53:39.714 [ZeusMonitor] Running indefinitely. 2022-12-06 19:53:39.714 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:53:39.714 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 14:54:23,622 [ZeusDataLoader(train)] train epoch 28 done: time=44.15 energy=5847.75
2022-12-06 14:54:23,625 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 4.6356
Training Epoch: 27 [2048/50176]	Loss: 4.6255
Training Epoch: 27 [3072/50176]	Loss: 4.6220
Training Epoch: 27 [4096/50176]	Loss: 4.6343
Training Epoch: 27 [5120/50176]	Loss: 4.6251
Training Epoch: 27 [6144/50176]	Loss: 4.6325
Training Epoch: 27 [7168/50176]	Loss: 4.6359
Training Epoch: 27 [8192/50176]	Loss: 4.6344
Training Epoch: 27 [9216/50176]	Loss: 4.6442
Training Epoch: 27 [10240/50176]	Loss: 4.6319
Training Epoch: 27 [11264/50176]	Loss: 4.6254
Training Epoch: 27 [12288/50176]	Loss: 4.6365
Training Epoch: 27 [13312/50176]	Loss: 4.6500
Training Epoch: 27 [14336/50176]	Loss: 4.6220
Training Epoch: 27 [15360/50176]	Loss: 4.6283
Training Epoch: 27 [16384/50176]	Loss: 4.6291
Training Epoch: 27 [17408/50176]	Loss: 4.6298
Training Epoch: 27 [18432/50176]	Loss: 4.6585
Training Epoch: 27 [19456/50176]	Loss: 4.6332
Training Epoch: 27 [20480/50176]	Loss: 4.6426
Training Epoch: 27 [21504/50176]	Loss: 4.6441
Training Epoch: 27 [22528/50176]	Loss: 4.6409
Training Epoch: 27 [23552/50176]	Loss: 4.6328
Training Epoch: 27 [24576/50176]	Loss: 4.6400
Training Epoch: 27 [25600/50176]	Loss: 4.6514
Training Epoch: 27 [26624/50176]	Loss: 4.6534
Training Epoch: 27 [27648/50176]	Loss: 4.6318
Training Epoch: 27 [28672/50176]	Loss: 4.6443
Training Epoch: 27 [29696/50176]	Loss: 4.6188
Training Epoch: 27 [30720/50176]	Loss: 4.6237
Training Epoch: 27 [31744/50176]	Loss: 4.6475
Training Epoch: 27 [32768/50176]	Loss: 4.6334
Training Epoch: 27 [33792/50176]	Loss: 4.6486
Training Epoch: 27 [34816/50176]	Loss: 4.6390
Training Epoch: 27 [35840/50176]	Loss: 4.6318
Training Epoch: 27 [36864/50176]	Loss: 4.6319
Training Epoch: 27 [37888/50176]	Loss: 4.6245
Training Epoch: 27 [38912/50176]	Loss: 4.6442
Training Epoch: 27 [39936/50176]	Loss: 4.6320
Training Epoch: 27 [40960/50176]	Loss: 4.6457
Training Epoch: 27 [41984/50176]	Loss: 4.6429
Training Epoch: 27 [43008/50176]	Loss: 4.6313
Training Epoch: 27 [44032/50176]	Loss: 4.6300
Training Epoch: 27 [45056/50176]	Loss: 4.6363
Training Epoch: 27 [46080/50176]	Loss: 4.6355
Training Epoch: 27 [47104/50176]	Loss: 4.6246
Training Epoch: 27 [48128/50176]	Loss: 4.6440
Training Epoch: 27 [49152/50176]	Loss: 4.6481
Training Epoch: 27 [50176/50176]	Loss: 4.6411
2022-12-06 19:54:27.374 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:54:27,396 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.76 energy=470.71
2022-12-06 14:54:27,396 [ZeusDataLoader(train)] Up to epoch 28: time=1347.82, energy=176505.99, cost=206187.05
2022-12-06 14:54:27,397 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:54:27,397 [ZeusDataLoader(train)] Expected next epoch: time=1394.42, energy=182872.28, cost=213448.28
2022-12-06 14:54:27,398 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:54:27,634 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:54:27,634 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:54:27.636 [ZeusMonitor] Monitor started.
2022-12-06 19:54:27.636 [ZeusMonitor] Running indefinitely. 2022-12-06 19:54:27.636 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:54:27.636 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 14:55:11,201 [ZeusDataLoader(train)] train epoch 29 done: time=43.80 energy=5821.48
2022-12-06 14:55:11,204 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 4.6296
Training Epoch: 28 [2048/50176]	Loss: 4.6282
Training Epoch: 28 [3072/50176]	Loss: 4.6416
Training Epoch: 28 [4096/50176]	Loss: 4.6412
Training Epoch: 28 [5120/50176]	Loss: 4.6326
Training Epoch: 28 [6144/50176]	Loss: 4.6345
Training Epoch: 28 [7168/50176]	Loss: 4.6403
Training Epoch: 28 [8192/50176]	Loss: 4.6328
Training Epoch: 28 [9216/50176]	Loss: 4.6237
Training Epoch: 28 [10240/50176]	Loss: 4.6224
Training Epoch: 28 [11264/50176]	Loss: 4.6572
Training Epoch: 28 [12288/50176]	Loss: 4.6290
Training Epoch: 28 [13312/50176]	Loss: 4.6403
Training Epoch: 28 [14336/50176]	Loss: 4.6277
Training Epoch: 28 [15360/50176]	Loss: 4.6238
Training Epoch: 28 [16384/50176]	Loss: 4.6372
Training Epoch: 28 [17408/50176]	Loss: 4.6421
Training Epoch: 28 [18432/50176]	Loss: 4.6214
Training Epoch: 28 [19456/50176]	Loss: 4.6223
Training Epoch: 28 [20480/50176]	Loss: 4.6368
Training Epoch: 28 [21504/50176]	Loss: 4.6202
Training Epoch: 28 [22528/50176]	Loss: 4.6409
Training Epoch: 28 [23552/50176]	Loss: 4.6489
Training Epoch: 28 [24576/50176]	Loss: 4.6435
Training Epoch: 28 [25600/50176]	Loss: 4.6332
Training Epoch: 28 [26624/50176]	Loss: 4.6264
Training Epoch: 28 [27648/50176]	Loss: 4.6347
Training Epoch: 28 [28672/50176]	Loss: 4.6429
Training Epoch: 28 [29696/50176]	Loss: 4.6428
Training Epoch: 28 [30720/50176]	Loss: 4.6345
Training Epoch: 28 [31744/50176]	Loss: 4.6351
Training Epoch: 28 [32768/50176]	Loss: 4.6523
Training Epoch: 28 [33792/50176]	Loss: 4.6264
Training Epoch: 28 [34816/50176]	Loss: 4.6396
Training Epoch: 28 [35840/50176]	Loss: 4.6353
Training Epoch: 28 [36864/50176]	Loss: 4.6574
Training Epoch: 28 [37888/50176]	Loss: 4.6615
Training Epoch: 28 [38912/50176]	Loss: 4.6426
Training Epoch: 28 [39936/50176]	Loss: 4.6407
Training Epoch: 28 [40960/50176]	Loss: 4.6401
Training Epoch: 28 [41984/50176]	Loss: 4.6165
Training Epoch: 28 [43008/50176]	Loss: 4.6342
Training Epoch: 28 [44032/50176]	Loss: 4.6522
Training Epoch: 28 [45056/50176]	Loss: 4.6502
Training Epoch: 28 [46080/50176]	Loss: 4.6526
Training Epoch: 28 [47104/50176]	Loss: 4.6357
Training Epoch: 28 [48128/50176]	Loss: 4.6431
Training Epoch: 28 [49152/50176]	Loss: 4.6449
Training Epoch: 28 [50176/50176]	Loss: 4.6481
2022-12-06 19:55:14.990 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:55:15,010 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.80 energy=477.19
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Up to epoch 29: time=1395.41, energy=182804.66, cost=213500.78
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Expected next epoch: time=1442.02, energy=189170.95, cost=220762.01
2022-12-06 14:55:15,011 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:55:15,249 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:55:15,250 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:55:15.271 [ZeusMonitor] Monitor started.
2022-12-06 19:55:15.271 [ZeusMonitor] Running indefinitely. 2022-12-06 19:55:15.271 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:55:15.271 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 14:55:58,790 [ZeusDataLoader(train)] train epoch 30 done: time=43.77 energy=5826.74
2022-12-06 14:55:58,793 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 4.6309
Training Epoch: 29 [2048/50176]	Loss: 4.6570
Training Epoch: 29 [3072/50176]	Loss: 4.6360
Training Epoch: 29 [4096/50176]	Loss: 4.6238
Training Epoch: 29 [5120/50176]	Loss: 4.6436
Training Epoch: 29 [6144/50176]	Loss: 4.6315
Training Epoch: 29 [7168/50176]	Loss: 4.6302
Training Epoch: 29 [8192/50176]	Loss: 4.6346
Training Epoch: 29 [9216/50176]	Loss: 4.6335
Training Epoch: 29 [10240/50176]	Loss: 4.6430
Training Epoch: 29 [11264/50176]	Loss: 4.6393
Training Epoch: 29 [12288/50176]	Loss: 4.6387
Training Epoch: 29 [13312/50176]	Loss: 4.6317
Training Epoch: 29 [14336/50176]	Loss: 4.6334
Training Epoch: 29 [15360/50176]	Loss: 4.6178
Training Epoch: 29 [16384/50176]	Loss: 4.6371
Training Epoch: 29 [17408/50176]	Loss: 4.6411
Training Epoch: 29 [18432/50176]	Loss: 4.6656
Training Epoch: 29 [19456/50176]	Loss: 4.6415
Training Epoch: 29 [20480/50176]	Loss: 4.6382
Training Epoch: 29 [21504/50176]	Loss: 4.6456
Training Epoch: 29 [22528/50176]	Loss: 4.6389
Training Epoch: 29 [23552/50176]	Loss: 4.6201
Training Epoch: 29 [24576/50176]	Loss: 4.6318
Training Epoch: 29 [25600/50176]	Loss: 4.6474
Training Epoch: 29 [26624/50176]	Loss: 4.6466
Training Epoch: 29 [27648/50176]	Loss: 4.6381
Training Epoch: 29 [28672/50176]	Loss: 4.6327
Training Epoch: 29 [29696/50176]	Loss: 4.6481
Training Epoch: 29 [30720/50176]	Loss: 4.6542
Training Epoch: 29 [31744/50176]	Loss: 4.6426
Training Epoch: 29 [32768/50176]	Loss: 4.6386
Training Epoch: 29 [33792/50176]	Loss: 4.6165
Training Epoch: 29 [34816/50176]	Loss: 4.6405
Training Epoch: 29 [35840/50176]	Loss: 4.6303
Training Epoch: 29 [36864/50176]	Loss: 4.6333
Training Epoch: 29 [37888/50176]	Loss: 4.6407
Training Epoch: 29 [38912/50176]	Loss: 4.6402
Training Epoch: 29 [39936/50176]	Loss: 4.6202
Training Epoch: 29 [40960/50176]	Loss: 4.6272
Training Epoch: 29 [41984/50176]	Loss: 4.6393
Training Epoch: 29 [43008/50176]	Loss: 4.6435
Training Epoch: 29 [44032/50176]	Loss: 4.6436
Training Epoch: 29 [45056/50176]	Loss: 4.6404
Training Epoch: 29 [46080/50176]	Loss: 4.6379
Training Epoch: 29 [47104/50176]	Loss: 4.6389
Training Epoch: 29 [48128/50176]	Loss: 4.6401
Training Epoch: 29 [49152/50176]	Loss: 4.6292
Training Epoch: 29 [50176/50176]	Loss: 4.6358
2022-12-06 19:56:02.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:56:02,584 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.78 energy=467.95
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Up to epoch 30: time=1442.97, energy=189099.35, cost=220809.11
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Expected next epoch: time=1489.57, energy=195465.64, cost=228070.35
2022-12-06 14:56:02,586 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:56:02,780 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:56:02,781 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:56:02.784 [ZeusMonitor] Monitor started.
2022-12-06 19:56:02.784 [ZeusMonitor] Running indefinitely. 2022-12-06 19:56:02.784 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:56:02.784 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 14:56:46,327 [ZeusDataLoader(train)] train epoch 31 done: time=43.73 energy=5834.92
2022-12-06 14:56:46,331 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 4.6375
Training Epoch: 30 [2048/50176]	Loss: 4.6257
Training Epoch: 30 [3072/50176]	Loss: 4.6402
Training Epoch: 30 [4096/50176]	Loss: 4.6328
Training Epoch: 30 [5120/50176]	Loss: 4.6263
Training Epoch: 30 [6144/50176]	Loss: 4.6445
Training Epoch: 30 [7168/50176]	Loss: 4.6324
Training Epoch: 30 [8192/50176]	Loss: 4.6358
Training Epoch: 30 [9216/50176]	Loss: 4.6271
Training Epoch: 30 [10240/50176]	Loss: 4.6368
Training Epoch: 30 [11264/50176]	Loss: 4.6214
Training Epoch: 30 [12288/50176]	Loss: 4.6189
Training Epoch: 30 [13312/50176]	Loss: 4.6348
Training Epoch: 30 [14336/50176]	Loss: 4.6387
Training Epoch: 30 [15360/50176]	Loss: 4.6389
Training Epoch: 30 [16384/50176]	Loss: 4.6245
Training Epoch: 30 [17408/50176]	Loss: 4.6425
Training Epoch: 30 [18432/50176]	Loss: 4.6231
Training Epoch: 30 [19456/50176]	Loss: 4.6465
Training Epoch: 30 [20480/50176]	Loss: 4.6369
Training Epoch: 30 [21504/50176]	Loss: 4.6361
Training Epoch: 30 [22528/50176]	Loss: 4.6308
Training Epoch: 30 [23552/50176]	Loss: 4.6467
Training Epoch: 30 [24576/50176]	Loss: 4.6347
Training Epoch: 30 [25600/50176]	Loss: 4.6364
Training Epoch: 30 [26624/50176]	Loss: 4.6377
Training Epoch: 30 [27648/50176]	Loss: 4.6228
Training Epoch: 30 [28672/50176]	Loss: 4.6408
Training Epoch: 30 [29696/50176]	Loss: 4.6425
Training Epoch: 30 [30720/50176]	Loss: 4.6280
Training Epoch: 30 [31744/50176]	Loss: 4.6324
Training Epoch: 30 [32768/50176]	Loss: 4.6365
Training Epoch: 30 [33792/50176]	Loss: 4.6408
Training Epoch: 30 [34816/50176]	Loss: 4.6380
Training Epoch: 30 [35840/50176]	Loss: 4.6338
Training Epoch: 30 [36864/50176]	Loss: 4.6419
Training Epoch: 30 [37888/50176]	Loss: 4.6307
Training Epoch: 30 [38912/50176]	Loss: 4.6367
Training Epoch: 30 [39936/50176]	Loss: 4.6351
Training Epoch: 30 [40960/50176]	Loss: 4.6377
Training Epoch: 30 [41984/50176]	Loss: 4.6414
Training Epoch: 30 [43008/50176]	Loss: 4.6456
Training Epoch: 30 [44032/50176]	Loss: 4.6315
Training Epoch: 30 [45056/50176]	Loss: 4.6300
Training Epoch: 30 [46080/50176]	Loss: 4.6492
Training Epoch: 30 [47104/50176]	Loss: 4.6306
Training Epoch: 30 [48128/50176]	Loss: 4.6285
Training Epoch: 30 [49152/50176]	Loss: 4.6392
Training Epoch: 30 [50176/50176]	Loss: 4.6412
2022-12-06 19:56:50.117 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:56:50,161 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.82 energy=484.26
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Up to epoch 31: time=1490.52, energy=195418.52, cost=228129.89
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Expected next epoch: time=1537.13, energy=201784.82, cost=235391.12
2022-12-06 14:56:50,163 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.4744, Accuracy: 0.0097
2022-12-06 14:56:50,397 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:56:50,398 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:56:50.400 [ZeusMonitor] Monitor started.
2022-12-06 19:56:50.400 [ZeusMonitor] Running indefinitely. 2022-12-06 19:56:50.400 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:56:50.400 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 14:57:33,831 [ZeusDataLoader(train)] train epoch 32 done: time=43.66 energy=5819.36
2022-12-06 14:57:33,835 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 4.6357
Training Epoch: 31 [2048/50176]	Loss: 4.6263
Training Epoch: 31 [3072/50176]	Loss: 4.6254
Training Epoch: 31 [4096/50176]	Loss: 4.6372
Training Epoch: 31 [5120/50176]	Loss: 4.6333
Training Epoch: 31 [6144/50176]	Loss: 4.6242
Training Epoch: 31 [7168/50176]	Loss: 4.6404
Training Epoch: 31 [8192/50176]	Loss: 4.6359
Training Epoch: 31 [9216/50176]	Loss: 4.6350
Training Epoch: 31 [10240/50176]	Loss: 4.6348
Training Epoch: 31 [11264/50176]	Loss: 4.6274
Training Epoch: 31 [12288/50176]	Loss: 4.6273
Training Epoch: 31 [13312/50176]	Loss: 4.6339
Training Epoch: 31 [14336/50176]	Loss: 4.6180
Training Epoch: 31 [15360/50176]	Loss: 4.6352
Training Epoch: 31 [16384/50176]	Loss: 4.6430
Training Epoch: 31 [17408/50176]	Loss: 4.6286
Training Epoch: 31 [18432/50176]	Loss: 4.6308
Training Epoch: 31 [19456/50176]	Loss: 4.6323
Training Epoch: 31 [20480/50176]	Loss: 4.6392
Training Epoch: 31 [21504/50176]	Loss: 4.6284
Training Epoch: 31 [22528/50176]	Loss: 4.6399
Training Epoch: 31 [23552/50176]	Loss: 4.6478
Training Epoch: 31 [24576/50176]	Loss: 4.6377
Training Epoch: 31 [25600/50176]	Loss: 4.6297
Training Epoch: 31 [26624/50176]	Loss: 4.6389
Training Epoch: 31 [27648/50176]	Loss: 4.6338
Training Epoch: 31 [28672/50176]	Loss: 4.6432
Training Epoch: 31 [29696/50176]	Loss: 4.6261
Training Epoch: 31 [30720/50176]	Loss: 4.6424
Training Epoch: 31 [31744/50176]	Loss: 4.6367
Training Epoch: 31 [32768/50176]	Loss: 4.6485
Training Epoch: 31 [33792/50176]	Loss: 4.6271
Training Epoch: 31 [34816/50176]	Loss: 4.6311
Training Epoch: 31 [35840/50176]	Loss: 4.6440
Training Epoch: 31 [36864/50176]	Loss: 4.6530
Training Epoch: 31 [37888/50176]	Loss: 4.6416
Training Epoch: 31 [38912/50176]	Loss: 4.6311
Training Epoch: 31 [39936/50176]	Loss: 4.6314
Training Epoch: 31 [40960/50176]	Loss: 4.6246
Training Epoch: 31 [41984/50176]	Loss: 4.6289
Training Epoch: 31 [43008/50176]	Loss: 4.6459
Training Epoch: 31 [44032/50176]	Loss: 4.6588
Training Epoch: 31 [45056/50176]	Loss: 4.6368
Training Epoch: 31 [46080/50176]	Loss: 4.6351
Training Epoch: 31 [47104/50176]	Loss: 4.6337
Training Epoch: 31 [48128/50176]	Loss: 4.6391
Training Epoch: 31 [49152/50176]	Loss: 4.6229
Training Epoch: 31 [50176/50176]	Loss: 4.6288
2022-12-06 19:57:37.618 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:57:37,646 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.80 energy=479.02
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Up to epoch 32: time=1537.98, energy=201716.91, cost=235432.14
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Expected next epoch: time=1584.59, energy=208083.21, cost=242693.38
2022-12-06 14:57:37,647 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.1006, Accuracy: 0.0098
2022-12-06 14:57:37,887 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:57:37,888 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:57:37.902 [ZeusMonitor] Monitor started.
2022-12-06 19:57:37.902 [ZeusMonitor] Running indefinitely. 2022-12-06 19:57:37.902 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:57:37.902 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 14:58:21,294 [ZeusDataLoader(train)] train epoch 33 done: time=43.64 energy=5817.67
2022-12-06 14:58:21,297 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 4.6404
Training Epoch: 32 [2048/50176]	Loss: 4.6314
Training Epoch: 32 [3072/50176]	Loss: 4.6274
Training Epoch: 32 [4096/50176]	Loss: 4.6285
Training Epoch: 32 [5120/50176]	Loss: 4.6502
Training Epoch: 32 [6144/50176]	Loss: 4.6486
Training Epoch: 32 [7168/50176]	Loss: 4.6309
Training Epoch: 32 [8192/50176]	Loss: 4.6294
Training Epoch: 32 [9216/50176]	Loss: 4.6325
Training Epoch: 32 [10240/50176]	Loss: 4.6443
Training Epoch: 32 [11264/50176]	Loss: 4.6336
Training Epoch: 32 [12288/50176]	Loss: 4.6307
Training Epoch: 32 [13312/50176]	Loss: 4.6491
Training Epoch: 32 [14336/50176]	Loss: 4.6458
Training Epoch: 32 [15360/50176]	Loss: 4.6138
Training Epoch: 32 [16384/50176]	Loss: 4.6284
Training Epoch: 32 [17408/50176]	Loss: 4.6406
Training Epoch: 32 [18432/50176]	Loss: 4.6376
Training Epoch: 32 [19456/50176]	Loss: 4.6413
Training Epoch: 32 [20480/50176]	Loss: 4.6389
Training Epoch: 32 [21504/50176]	Loss: 4.6460
Training Epoch: 32 [22528/50176]	Loss: 4.6500
Training Epoch: 32 [23552/50176]	Loss: 4.6215
Training Epoch: 32 [24576/50176]	Loss: 4.6360
Training Epoch: 32 [25600/50176]	Loss: 4.6324
Training Epoch: 32 [26624/50176]	Loss: 4.6425
Training Epoch: 32 [27648/50176]	Loss: 4.6595
Training Epoch: 32 [28672/50176]	Loss: 4.6485
Training Epoch: 32 [29696/50176]	Loss: 4.6466
Training Epoch: 32 [30720/50176]	Loss: 4.6319
Training Epoch: 32 [31744/50176]	Loss: 4.6287
Training Epoch: 32 [32768/50176]	Loss: 4.6259
Training Epoch: 32 [33792/50176]	Loss: 4.6313
Training Epoch: 32 [34816/50176]	Loss: 4.6508
Training Epoch: 32 [35840/50176]	Loss: 4.6495
Training Epoch: 32 [36864/50176]	Loss: 4.6359
Training Epoch: 32 [37888/50176]	Loss: 4.6434
Training Epoch: 32 [38912/50176]	Loss: 4.6370
Training Epoch: 32 [39936/50176]	Loss: 4.6367
Training Epoch: 32 [40960/50176]	Loss: 4.6341
Training Epoch: 32 [41984/50176]	Loss: 4.6321
Training Epoch: 32 [43008/50176]	Loss: 4.6691
Training Epoch: 32 [44032/50176]	Loss: 4.6503
Training Epoch: 32 [45056/50176]	Loss: 4.6369
Training Epoch: 32 [46080/50176]	Loss: 4.6325
Training Epoch: 32 [47104/50176]	Loss: 4.6376
Training Epoch: 32 [48128/50176]	Loss: 4.6301
Training Epoch: 32 [49152/50176]	Loss: 4.6465
Training Epoch: 32 [50176/50176]	Loss: 4.6435
2022-12-06 19:58:25.046 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:58:25,063 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=463.51
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Up to epoch 33: time=1585.38, energy=207998.09, cost=242719.92
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Expected next epoch: time=1631.99, energy=214364.38, cost=249981.16
2022-12-06 14:58:25,064 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 5220.7918, Accuracy: 0.0098
2022-12-06 14:58:25,307 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:58:25,308 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:58:25.322 [ZeusMonitor] Monitor started.
2022-12-06 19:58:25.322 [ZeusMonitor] Running indefinitely. 2022-12-06 19:58:25.322 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:58:25.322 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 14:59:08,770 [ZeusDataLoader(train)] train epoch 34 done: time=43.70 energy=5820.20
2022-12-06 14:59:08,773 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 4.6378
Training Epoch: 33 [2048/50176]	Loss: 4.6465
Training Epoch: 33 [3072/50176]	Loss: 4.6281
Training Epoch: 33 [4096/50176]	Loss: 4.6293
Training Epoch: 33 [5120/50176]	Loss: 4.6429
Training Epoch: 33 [6144/50176]	Loss: 4.6252
Training Epoch: 33 [7168/50176]	Loss: 4.6349
Training Epoch: 33 [8192/50176]	Loss: 4.6411
Training Epoch: 33 [9216/50176]	Loss: 4.6267
Training Epoch: 33 [10240/50176]	Loss: 4.6430
Training Epoch: 33 [11264/50176]	Loss: 4.6559
Training Epoch: 33 [12288/50176]	Loss: 4.6373
Training Epoch: 33 [13312/50176]	Loss: 4.6248
Training Epoch: 33 [14336/50176]	Loss: 4.6206
Training Epoch: 33 [15360/50176]	Loss: 4.6269
Training Epoch: 33 [16384/50176]	Loss: 4.6341
Training Epoch: 33 [17408/50176]	Loss: 4.6382
Training Epoch: 33 [18432/50176]	Loss: 4.6137
Training Epoch: 33 [19456/50176]	Loss: 4.6501
Training Epoch: 33 [20480/50176]	Loss: 4.6337
Training Epoch: 33 [21504/50176]	Loss: 4.6473
Training Epoch: 33 [22528/50176]	Loss: 4.6365
Training Epoch: 33 [23552/50176]	Loss: 4.6452
Training Epoch: 33 [24576/50176]	Loss: 4.6342
Training Epoch: 33 [25600/50176]	Loss: 4.6268
Training Epoch: 33 [26624/50176]	Loss: 4.6250
Training Epoch: 33 [27648/50176]	Loss: 4.6292
Training Epoch: 33 [28672/50176]	Loss: 4.6398
Training Epoch: 33 [29696/50176]	Loss: 4.6344
Training Epoch: 33 [30720/50176]	Loss: 4.6447
Training Epoch: 33 [31744/50176]	Loss: 4.6348
Training Epoch: 33 [32768/50176]	Loss: 4.6333
Training Epoch: 33 [33792/50176]	Loss: 4.6162
Training Epoch: 33 [34816/50176]	Loss: 4.6284
Training Epoch: 33 [35840/50176]	Loss: 4.6385
Training Epoch: 33 [36864/50176]	Loss: 4.6250
Training Epoch: 33 [37888/50176]	Loss: 4.6422
Training Epoch: 33 [38912/50176]	Loss: 4.6552
Training Epoch: 33 [39936/50176]	Loss: 4.6556
Training Epoch: 33 [40960/50176]	Loss: 4.6489
Training Epoch: 33 [41984/50176]	Loss: 4.6400
Training Epoch: 33 [43008/50176]	Loss: 4.6245
Training Epoch: 33 [44032/50176]	Loss: 4.6309
Training Epoch: 33 [45056/50176]	Loss: 4.6398
Training Epoch: 33 [46080/50176]	Loss: 4.6572
Training Epoch: 33 [47104/50176]	Loss: 4.6463
Training Epoch: 33 [48128/50176]	Loss: 4.6439
Training Epoch: 33 [49152/50176]	Loss: 4.6424
Training Epoch: 33 [50176/50176]	Loss: 4.6284
2022-12-06 19:59:12.530 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:59:12,545 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.76 energy=474.37
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Up to epoch 34: time=1632.84, energy=214292.66, cost=250020.04
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Expected next epoch: time=1679.45, energy=220658.95, cost=257281.27
2022-12-06 14:59:12,546 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 8974.5149, Accuracy: 0.0098
2022-12-06 14:59:12,747 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:59:12,748 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:59:12.750 [ZeusMonitor] Monitor started.
2022-12-06 19:59:12.750 [ZeusMonitor] Running indefinitely. 2022-12-06 19:59:12.750 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:59:12.750 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 14:59:56,151 [ZeusDataLoader(train)] train epoch 35 done: time=43.60 energy=5822.93
2022-12-06 14:59:56,154 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 4.6264
Training Epoch: 34 [2048/50176]	Loss: 4.6337
Training Epoch: 34 [3072/50176]	Loss: 4.6327
Training Epoch: 34 [4096/50176]	Loss: 4.6343
Training Epoch: 34 [5120/50176]	Loss: 4.6277
Training Epoch: 34 [6144/50176]	Loss: 4.6376
Training Epoch: 34 [7168/50176]	Loss: 4.6454
Training Epoch: 34 [8192/50176]	Loss: 4.6469
Training Epoch: 34 [9216/50176]	Loss: 4.6348
Training Epoch: 34 [10240/50176]	Loss: 4.6432
Training Epoch: 34 [11264/50176]	Loss: 4.6293
Training Epoch: 34 [12288/50176]	Loss: 4.6361
Training Epoch: 34 [13312/50176]	Loss: 4.6432
Training Epoch: 34 [14336/50176]	Loss: 4.6358
Training Epoch: 34 [15360/50176]	Loss: 4.6304
Training Epoch: 34 [16384/50176]	Loss: 4.6482
Training Epoch: 34 [17408/50176]	Loss: 4.6145
Training Epoch: 34 [18432/50176]	Loss: 4.6444
Training Epoch: 34 [19456/50176]	Loss: 4.6490
Training Epoch: 34 [20480/50176]	Loss: 4.6436
Training Epoch: 34 [21504/50176]	Loss: 4.6432
Training Epoch: 34 [22528/50176]	Loss: 4.6528
Training Epoch: 34 [23552/50176]	Loss: 4.6352
Training Epoch: 34 [24576/50176]	Loss: 4.6234
Training Epoch: 34 [25600/50176]	Loss: 4.6297
Training Epoch: 34 [26624/50176]	Loss: 4.6520
Training Epoch: 34 [27648/50176]	Loss: 4.6539
Training Epoch: 34 [28672/50176]	Loss: 4.6279
Training Epoch: 34 [29696/50176]	Loss: 4.6428
Training Epoch: 34 [30720/50176]	Loss: 4.6387
Training Epoch: 34 [31744/50176]	Loss: 4.6480
Training Epoch: 34 [32768/50176]	Loss: 4.6455
Training Epoch: 34 [33792/50176]	Loss: 4.6481
Training Epoch: 34 [34816/50176]	Loss: 4.6391
Training Epoch: 34 [35840/50176]	Loss: 4.6503
Training Epoch: 34 [36864/50176]	Loss: 4.6475
Training Epoch: 34 [37888/50176]	Loss: 4.6543
Training Epoch: 34 [38912/50176]	Loss: 4.6589
Training Epoch: 34 [39936/50176]	Loss: 4.6321
Training Epoch: 34 [40960/50176]	Loss: 4.6421
Training Epoch: 34 [41984/50176]	Loss: 4.6281
Training Epoch: 34 [43008/50176]	Loss: 4.6357
Training Epoch: 34 [44032/50176]	Loss: 4.6329
Training Epoch: 34 [45056/50176]	Loss: 4.6467
Training Epoch: 34 [46080/50176]	Loss: 4.6379
Training Epoch: 34 [47104/50176]	Loss: 4.6399
Training Epoch: 34 [48128/50176]	Loss: 4.6279
Training Epoch: 34 [49152/50176]	Loss: 4.6403
Training Epoch: 34 [50176/50176]	Loss: 4.6378
2022-12-06 19:59:59.900 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:59:59,909 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.75 energy=464.30
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Up to epoch 35: time=1680.19, energy=220579.89, cost=257306.24
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Expected next epoch: time=1726.79, energy=226946.18, cost=264567.48
2022-12-06 14:59:59,910 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 1268.7010, Accuracy: 0.0098
2022-12-06 15:00:00,104 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:00:00,105 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:00:00.108 [ZeusMonitor] Monitor started.
2022-12-06 20:00:00.108 [ZeusMonitor] Running indefinitely. 2022-12-06 20:00:00.108 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:00:00.108 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 15:00:43,573 [ZeusDataLoader(train)] train epoch 36 done: time=43.66 energy=5823.63
2022-12-06 15:00:43,576 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 4.6329
Training Epoch: 35 [2048/50176]	Loss: 4.6432
Training Epoch: 35 [3072/50176]	Loss: 4.6439
Training Epoch: 35 [4096/50176]	Loss: 4.6461
Training Epoch: 35 [5120/50176]	Loss: 4.6488
Training Epoch: 35 [6144/50176]	Loss: 4.6287
Training Epoch: 35 [7168/50176]	Loss: 4.6329
Training Epoch: 35 [8192/50176]	Loss: 4.6413
Training Epoch: 35 [9216/50176]	Loss: 4.6382
Training Epoch: 35 [10240/50176]	Loss: 4.6380
Training Epoch: 35 [11264/50176]	Loss: 4.6521
Training Epoch: 35 [12288/50176]	Loss: 4.6375
Training Epoch: 35 [13312/50176]	Loss: 4.6371
Training Epoch: 35 [14336/50176]	Loss: 4.6367
Training Epoch: 35 [15360/50176]	Loss: 4.6227
Training Epoch: 35 [16384/50176]	Loss: 4.6451
Training Epoch: 35 [17408/50176]	Loss: 4.6330
Training Epoch: 35 [18432/50176]	Loss: 4.6373
Training Epoch: 35 [19456/50176]	Loss: 4.6276
Training Epoch: 35 [20480/50176]	Loss: 4.6429
Training Epoch: 35 [21504/50176]	Loss: 4.6328
Training Epoch: 35 [22528/50176]	Loss: 4.6343
Training Epoch: 35 [23552/50176]	Loss: 4.6404
Training Epoch: 35 [24576/50176]	Loss: 4.6468
Training Epoch: 35 [25600/50176]	Loss: 4.6170
Training Epoch: 35 [26624/50176]	Loss: 4.6280
Training Epoch: 35 [27648/50176]	Loss: 4.6547
Training Epoch: 35 [28672/50176]	Loss: 4.6377
Training Epoch: 35 [29696/50176]	Loss: 4.6424
Training Epoch: 35 [30720/50176]	Loss: 4.6435
Training Epoch: 35 [31744/50176]	Loss: 4.6444
Training Epoch: 35 [32768/50176]	Loss: 4.6239
Training Epoch: 35 [33792/50176]	Loss: 4.6286
Training Epoch: 35 [34816/50176]	Loss: 4.6420
Training Epoch: 35 [35840/50176]	Loss: 4.6451
Training Epoch: 35 [36864/50176]	Loss: 4.6480
Training Epoch: 35 [37888/50176]	Loss: 4.6509
Training Epoch: 35 [38912/50176]	Loss: 4.6476
Training Epoch: 35 [39936/50176]	Loss: 4.6577
Training Epoch: 35 [40960/50176]	Loss: 4.6226
Training Epoch: 35 [41984/50176]	Loss: 4.6387
Training Epoch: 35 [43008/50176]	Loss: 4.6430
Training Epoch: 35 [44032/50176]	Loss: 4.6247
Training Epoch: 35 [45056/50176]	Loss: 4.6586
Training Epoch: 35 [46080/50176]	Loss: 4.6513
Training Epoch: 35 [47104/50176]	Loss: 4.6288
Training Epoch: 35 [48128/50176]	Loss: 4.6351
Training Epoch: 35 [49152/50176]	Loss: 4.6618
Training Epoch: 35 [50176/50176]	Loss: 4.6253
2022-12-06 20:00:47.338 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:00:47,378 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.79 energy=477.71
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Up to epoch 36: time=1727.64, energy=226881.23, cost=264608.71
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Expected next epoch: time=1774.24, energy=233247.52, cost=271869.95
2022-12-06 15:00:47,379 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 10626.0593, Accuracy: 0.0098
2022-12-06 15:00:47,663 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:00:47,664 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:00:47.665 [ZeusMonitor] Monitor started.
2022-12-06 20:00:47.665 [ZeusMonitor] Running indefinitely. 2022-12-06 20:00:47.665 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:00:47.665 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 15:01:31,162 [ZeusDataLoader(train)] train epoch 37 done: time=43.78 energy=5818.37
2022-12-06 15:01:31,165 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 4.6498
Training Epoch: 36 [2048/50176]	Loss: 4.6255
Training Epoch: 36 [3072/50176]	Loss: 4.6430
Training Epoch: 36 [4096/50176]	Loss: 4.6470
Training Epoch: 36 [5120/50176]	Loss: 4.6288
Training Epoch: 36 [6144/50176]	Loss: 4.6411
Training Epoch: 36 [7168/50176]	Loss: 4.6516
Training Epoch: 36 [8192/50176]	Loss: 4.6469
Training Epoch: 36 [9216/50176]	Loss: 4.6300
Training Epoch: 36 [10240/50176]	Loss: 4.6350
Training Epoch: 36 [11264/50176]	Loss: 4.6282
Training Epoch: 36 [12288/50176]	Loss: 4.6286
Training Epoch: 36 [13312/50176]	Loss: 4.6331
Training Epoch: 36 [14336/50176]	Loss: 4.6390
Training Epoch: 36 [15360/50176]	Loss: 4.6452
Training Epoch: 36 [16384/50176]	Loss: 4.6407
Training Epoch: 36 [17408/50176]	Loss: 4.6393
Training Epoch: 36 [18432/50176]	Loss: 4.6414
Training Epoch: 36 [19456/50176]	Loss: 4.6440
Training Epoch: 36 [20480/50176]	Loss: 4.6361
Training Epoch: 36 [21504/50176]	Loss: 4.6551
Training Epoch: 36 [22528/50176]	Loss: 4.6359
Training Epoch: 36 [23552/50176]	Loss: 4.6187
Training Epoch: 36 [24576/50176]	Loss: 4.6355
Training Epoch: 36 [25600/50176]	Loss: 4.6400
Training Epoch: 36 [26624/50176]	Loss: 4.6531
Training Epoch: 36 [27648/50176]	Loss: 4.6275
Training Epoch: 36 [28672/50176]	Loss: 4.6321
Training Epoch: 36 [29696/50176]	Loss: 4.6342
Training Epoch: 36 [30720/50176]	Loss: 4.6498
Training Epoch: 36 [31744/50176]	Loss: 4.6312
Training Epoch: 36 [32768/50176]	Loss: 4.6423
Training Epoch: 36 [33792/50176]	Loss: 4.6305
Training Epoch: 36 [34816/50176]	Loss: 4.6198
Training Epoch: 36 [35840/50176]	Loss: 4.6355
Training Epoch: 36 [36864/50176]	Loss: 4.6188
Training Epoch: 36 [37888/50176]	Loss: 4.6450
Training Epoch: 36 [38912/50176]	Loss: 4.6425
Training Epoch: 36 [39936/50176]	Loss: 4.6356
Training Epoch: 36 [40960/50176]	Loss: 4.6395
Training Epoch: 36 [41984/50176]	Loss: 4.6184
Training Epoch: 36 [43008/50176]	Loss: 4.6366
Training Epoch: 36 [44032/50176]	Loss: 4.6301
Training Epoch: 36 [45056/50176]	Loss: 4.6388
Training Epoch: 36 [46080/50176]	Loss: 4.6480
Training Epoch: 36 [47104/50176]	Loss: 4.6441
Training Epoch: 36 [48128/50176]	Loss: 4.6482
Training Epoch: 36 [49152/50176]	Loss: 4.6350
Training Epoch: 36 [50176/50176]	Loss: 4.6323
2022-12-06 20:01:34.882 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:01:34,916 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.74 energy=466.88
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Up to epoch 37: time=1775.15, energy=233166.48, cost=271909.11
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Expected next epoch: time=1821.76, energy=239532.77, cost=279170.35
2022-12-06 15:01:34,917 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 66.7765, Accuracy: 0.0098
2022-12-06 15:01:35,163 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:01:35,164 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:01:35.167 [ZeusMonitor] Monitor started.
2022-12-06 20:01:35.168 [ZeusMonitor] Running indefinitely. 2022-12-06 20:01:35.168 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:01:35.168 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 15:02:18,673 [ZeusDataLoader(train)] train epoch 38 done: time=43.75 energy=5827.34
2022-12-06 15:02:18,676 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 4.6245
Training Epoch: 37 [2048/50176]	Loss: 4.6399
Training Epoch: 37 [3072/50176]	Loss: 4.6392
Training Epoch: 37 [4096/50176]	Loss: 4.6442
Training Epoch: 37 [5120/50176]	Loss: 4.6506
Training Epoch: 37 [6144/50176]	Loss: 4.6235
Training Epoch: 37 [7168/50176]	Loss: 4.6309
Training Epoch: 37 [8192/50176]	Loss: 4.6372
Training Epoch: 37 [9216/50176]	Loss: 4.6260
Training Epoch: 37 [10240/50176]	Loss: 4.6317
Training Epoch: 37 [11264/50176]	Loss: 4.6272
Training Epoch: 37 [12288/50176]	Loss: 4.6320
Training Epoch: 37 [13312/50176]	Loss: 4.6257
Training Epoch: 37 [14336/50176]	Loss: 4.6458
Training Epoch: 37 [15360/50176]	Loss: 4.6466
Training Epoch: 37 [16384/50176]	Loss: 4.6294
Training Epoch: 37 [17408/50176]	Loss: 4.6333
Training Epoch: 37 [18432/50176]	Loss: 4.6160
Training Epoch: 37 [19456/50176]	Loss: 4.6276
Training Epoch: 37 [20480/50176]	Loss: 4.6512
Training Epoch: 37 [21504/50176]	Loss: 4.6330
Training Epoch: 37 [22528/50176]	Loss: 4.6704
Training Epoch: 37 [23552/50176]	Loss: 4.6471
Training Epoch: 37 [24576/50176]	Loss: 4.6342
Training Epoch: 37 [25600/50176]	Loss: 4.6373
Training Epoch: 37 [26624/50176]	Loss: 4.6388
Training Epoch: 37 [27648/50176]	Loss: 4.6562
Training Epoch: 37 [28672/50176]	Loss: 4.6422
Training Epoch: 37 [29696/50176]	Loss: 4.6303
Training Epoch: 37 [30720/50176]	Loss: 4.6403
Training Epoch: 37 [31744/50176]	Loss: 4.6484
Training Epoch: 37 [32768/50176]	Loss: 4.6367
Training Epoch: 37 [33792/50176]	Loss: 4.6430
Training Epoch: 37 [34816/50176]	Loss: 4.6285
Training Epoch: 37 [35840/50176]	Loss: 4.6353
Training Epoch: 37 [36864/50176]	Loss: 4.6425
Training Epoch: 37 [37888/50176]	Loss: 4.6654
Training Epoch: 37 [38912/50176]	Loss: 4.6371
Training Epoch: 37 [39936/50176]	Loss: 4.6327
Training Epoch: 37 [40960/50176]	Loss: 4.6327
Training Epoch: 37 [41984/50176]	Loss: 4.6348
Training Epoch: 37 [43008/50176]	Loss: 4.6393
Training Epoch: 37 [44032/50176]	Loss: 4.6424
Training Epoch: 37 [45056/50176]	Loss: 4.6447
Training Epoch: 37 [46080/50176]	Loss: 4.6335
Training Epoch: 37 [47104/50176]	Loss: 4.6470
Training Epoch: 37 [48128/50176]	Loss: 4.6375
Training Epoch: 37 [49152/50176]	Loss: 4.6535
Training Epoch: 37 [50176/50176]	Loss: 4.6331
2022-12-06 20:02:22.414 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:02:22,431 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.75 energy=463.82
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Up to epoch 38: time=1822.65, energy=239457.63, cost=279210.50
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Expected next epoch: time=1869.25, energy=245823.93, cost=286471.74
2022-12-06 15:02:22,432 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:02:22,675 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:02:22,676 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:02:22.678 [ZeusMonitor] Monitor started.
2022-12-06 20:02:22.678 [ZeusMonitor] Running indefinitely. 2022-12-06 20:02:22.678 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:02:22.678 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 15:03:06,332 [ZeusDataLoader(train)] train epoch 39 done: time=43.89 energy=5834.10
2022-12-06 15:03:06,335 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 4.6304
Training Epoch: 38 [2048/50176]	Loss: 4.6327
Training Epoch: 38 [3072/50176]	Loss: 4.6390
Training Epoch: 38 [4096/50176]	Loss: 4.6419
Training Epoch: 38 [5120/50176]	Loss: 4.6408
Training Epoch: 38 [6144/50176]	Loss: 4.6303
Training Epoch: 38 [7168/50176]	Loss: 4.6409
Training Epoch: 38 [8192/50176]	Loss: 4.6319
Training Epoch: 38 [9216/50176]	Loss: 4.6401
Training Epoch: 38 [10240/50176]	Loss: 4.6296
Training Epoch: 38 [11264/50176]	Loss: 4.6402
Training Epoch: 38 [12288/50176]	Loss: 4.6399
Training Epoch: 38 [13312/50176]	Loss: 4.6340
Training Epoch: 38 [14336/50176]	Loss: 4.6374
Training Epoch: 38 [15360/50176]	Loss: 4.6420
Training Epoch: 38 [16384/50176]	Loss: 4.6466
Training Epoch: 38 [17408/50176]	Loss: 4.6322
Training Epoch: 38 [18432/50176]	Loss: 4.6469
Training Epoch: 38 [19456/50176]	Loss: 4.6322
Training Epoch: 38 [20480/50176]	Loss: 4.6258
Training Epoch: 38 [21504/50176]	Loss: 4.6437
Training Epoch: 38 [22528/50176]	Loss: 4.6651
Training Epoch: 38 [23552/50176]	Loss: 4.6352
Training Epoch: 38 [24576/50176]	Loss: 4.6461
Training Epoch: 38 [25600/50176]	Loss: 4.6510
Training Epoch: 38 [26624/50176]	Loss: 4.6328
Training Epoch: 38 [27648/50176]	Loss: 4.6485
Training Epoch: 38 [28672/50176]	Loss: 4.6497
Training Epoch: 38 [29696/50176]	Loss: 4.6496
Training Epoch: 38 [30720/50176]	Loss: 4.6406
Training Epoch: 38 [31744/50176]	Loss: 4.6303
Training Epoch: 38 [32768/50176]	Loss: 4.6455
Training Epoch: 38 [33792/50176]	Loss: 4.6538
Training Epoch: 38 [34816/50176]	Loss: 4.6383
Training Epoch: 38 [35840/50176]	Loss: 4.6388
Training Epoch: 38 [36864/50176]	Loss: 4.6294
Training Epoch: 38 [37888/50176]	Loss: 4.6411
Training Epoch: 38 [38912/50176]	Loss: 4.6394
Training Epoch: 38 [39936/50176]	Loss: 4.6445
Training Epoch: 38 [40960/50176]	Loss: 4.6661
Training Epoch: 38 [41984/50176]	Loss: 4.6518
Training Epoch: 38 [43008/50176]	Loss: 4.6482
Training Epoch: 38 [44032/50176]	Loss: 4.6442
Training Epoch: 38 [45056/50176]	Loss: 4.6510
Training Epoch: 38 [46080/50176]	Loss: 4.6398
Training Epoch: 38 [47104/50176]	Loss: 4.6523
Training Epoch: 38 [48128/50176]	Loss: 4.6372
Training Epoch: 38 [49152/50176]	Loss: 4.6533
Training Epoch: 38 [50176/50176]	Loss: 4.6413
2022-12-06 20:03:10.063 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:03:10,079 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.74 energy=462.53
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Up to epoch 39: time=1870.27, energy=245754.27, cost=286526.17
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Expected next epoch: time=1916.88, energy=252120.56, cost=293787.41
2022-12-06 15:03:10,080 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:03:10,334 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:03:10,334 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:03:10.336 [ZeusMonitor] Monitor started.
2022-12-06 20:03:10.336 [ZeusMonitor] Running indefinitely. 2022-12-06 20:03:10.336 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:03:10.336 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 15:03:53,817 [ZeusDataLoader(train)] train epoch 40 done: time=43.73 energy=5824.47
2022-12-06 15:03:53,821 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 4.6516
Training Epoch: 39 [2048/50176]	Loss: 4.6252
Training Epoch: 39 [3072/50176]	Loss: 4.6538
Training Epoch: 39 [4096/50176]	Loss: 4.6497
Training Epoch: 39 [5120/50176]	Loss: 4.6476
Training Epoch: 39 [6144/50176]	Loss: 4.6446
Training Epoch: 39 [7168/50176]	Loss: 4.6487
Training Epoch: 39 [8192/50176]	Loss: 4.6275
Training Epoch: 39 [9216/50176]	Loss: 4.6527
Training Epoch: 39 [10240/50176]	Loss: 4.6510
Training Epoch: 39 [11264/50176]	Loss: 4.6525
Training Epoch: 39 [12288/50176]	Loss: 4.6555
Training Epoch: 39 [13312/50176]	Loss: 4.6406
Training Epoch: 39 [14336/50176]	Loss: 4.6306
Training Epoch: 39 [15360/50176]	Loss: 4.6433
Training Epoch: 39 [16384/50176]	Loss: 4.6484
Training Epoch: 39 [17408/50176]	Loss: 4.6185
Training Epoch: 39 [18432/50176]	Loss: 4.6455
Training Epoch: 39 [19456/50176]	Loss: 4.6591
Training Epoch: 39 [20480/50176]	Loss: 4.6407
Training Epoch: 39 [21504/50176]	Loss: 4.6466
Training Epoch: 39 [22528/50176]	Loss: 4.6362
Training Epoch: 39 [23552/50176]	Loss: 4.6237
Training Epoch: 39 [24576/50176]	Loss: 4.6352
Training Epoch: 39 [25600/50176]	Loss: 4.6370
Training Epoch: 39 [26624/50176]	Loss: 4.6361
Training Epoch: 39 [27648/50176]	Loss: 4.6461
Training Epoch: 39 [28672/50176]	Loss: 4.6402
Training Epoch: 39 [29696/50176]	Loss: 4.6313
Training Epoch: 39 [30720/50176]	Loss: 4.6338
Training Epoch: 39 [31744/50176]	Loss: 4.6296
Training Epoch: 39 [32768/50176]	Loss: 4.6486
Training Epoch: 39 [33792/50176]	Loss: 4.6349
Training Epoch: 39 [34816/50176]	Loss: 4.6300
Training Epoch: 39 [35840/50176]	Loss: 4.6422
Training Epoch: 39 [36864/50176]	Loss: 4.6298
Training Epoch: 39 [37888/50176]	Loss: 4.6465
Training Epoch: 39 [38912/50176]	Loss: 4.6422
Training Epoch: 39 [39936/50176]	Loss: 4.6292
Training Epoch: 39 [40960/50176]	Loss: 4.6497
Training Epoch: 39 [41984/50176]	Loss: 4.6347
Training Epoch: 39 [43008/50176]	Loss: 4.6258
Training Epoch: 39 [44032/50176]	Loss: 4.6275
Training Epoch: 39 [45056/50176]	Loss: 4.6303
Training Epoch: 39 [46080/50176]	Loss: 4.6403
Training Epoch: 39 [47104/50176]	Loss: 4.6384
Training Epoch: 39 [48128/50176]	Loss: 4.6429
Training Epoch: 39 [49152/50176]	Loss: 4.6396
Training Epoch: 39 [50176/50176]	Loss: 4.6485
2022-12-06 20:03:57.562 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:03:57,583 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.75 energy=463.45
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Up to epoch 40: time=1917.76, energy=252042.19, cost=293824.95
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Expected next epoch: time=1964.37, energy=258408.49, cost=301086.18
2022-12-06 15:03:57,584 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:03:57,777 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:03:57,778 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:03:57.781 [ZeusMonitor] Monitor started.
2022-12-06 20:03:57.781 [ZeusMonitor] Running indefinitely. 2022-12-06 20:03:57.781 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:03:57.781 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 15:04:41,323 [ZeusDataLoader(train)] train epoch 41 done: time=43.73 energy=5825.69
2022-12-06 15:04:41,326 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 4.6429
Training Epoch: 40 [2048/50176]	Loss: 4.6346
Training Epoch: 40 [3072/50176]	Loss: 4.6345
Training Epoch: 40 [4096/50176]	Loss: 4.6227
Training Epoch: 40 [5120/50176]	Loss: 4.6375
Training Epoch: 40 [6144/50176]	Loss: 4.6462
Training Epoch: 40 [7168/50176]	Loss: 4.6440
Training Epoch: 40 [8192/50176]	Loss: 4.6339
Training Epoch: 40 [9216/50176]	Loss: 4.6352
Training Epoch: 40 [10240/50176]	Loss: 4.6286
Training Epoch: 40 [11264/50176]	Loss: 4.6381
Training Epoch: 40 [12288/50176]	Loss: 4.6286
Training Epoch: 40 [13312/50176]	Loss: 4.6267
Training Epoch: 40 [14336/50176]	Loss: 4.6306
Training Epoch: 40 [15360/50176]	Loss: 4.6322
Training Epoch: 40 [16384/50176]	Loss: 4.6332
Training Epoch: 40 [17408/50176]	Loss: 4.6345
Training Epoch: 40 [18432/50176]	Loss: 4.6394
Training Epoch: 40 [19456/50176]	Loss: 4.6421
Training Epoch: 40 [20480/50176]	Loss: 4.6261
Training Epoch: 40 [21504/50176]	Loss: 4.6259
Training Epoch: 40 [22528/50176]	Loss: 4.6329
Training Epoch: 40 [23552/50176]	Loss: 4.6379
Training Epoch: 40 [24576/50176]	Loss: 4.6311
Training Epoch: 40 [25600/50176]	Loss: 4.6199
Training Epoch: 40 [26624/50176]	Loss: 4.6459
Training Epoch: 40 [27648/50176]	Loss: 4.6296
Training Epoch: 40 [28672/50176]	Loss: 4.6362
Training Epoch: 40 [29696/50176]	Loss: 4.6402
Training Epoch: 40 [30720/50176]	Loss: 4.6357
Training Epoch: 40 [31744/50176]	Loss: 4.6199
Training Epoch: 40 [32768/50176]	Loss: 4.6241
Training Epoch: 40 [33792/50176]	Loss: 4.6411
Training Epoch: 40 [34816/50176]	Loss: 4.6403
Training Epoch: 40 [35840/50176]	Loss: 4.6495
Training Epoch: 40 [36864/50176]	Loss: 4.6456
Training Epoch: 40 [37888/50176]	Loss: 4.6387
Training Epoch: 40 [38912/50176]	Loss: 4.6438
Training Epoch: 40 [39936/50176]	Loss: 4.6331
Training Epoch: 40 [40960/50176]	Loss: 4.6518
Training Epoch: 40 [41984/50176]	Loss: 4.6456
Training Epoch: 40 [43008/50176]	Loss: 4.6356
Training Epoch: 40 [44032/50176]	Loss: 4.6346
Training Epoch: 40 [45056/50176]	Loss: 4.6371
Training Epoch: 40 [46080/50176]	Loss: 4.6447
Training Epoch: 40 [47104/50176]	Loss: 4.6337
Training Epoch: 40 [48128/50176]	Loss: 4.6358
Training Epoch: 40 [49152/50176]	Loss: 4.6338
Training Epoch: 40 [50176/50176]	Loss: 4.6297
2022-12-06 20:04:45.076 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:04:45,122 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.79 energy=468.24
2022-12-06 15:04:45,122 [ZeusDataLoader(train)] Up to epoch 41: time=1965.28, energy=258336.12, cost=301129.81
2022-12-06 15:04:45,123 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:04:45,123 [ZeusDataLoader(train)] Expected next epoch: time=2011.88, energy=264702.41, cost=308391.04
2022-12-06 15:04:45,124 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:04:45,375 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:04:45,376 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:04:45.377 [ZeusMonitor] Monitor started.
2022-12-06 20:04:45.378 [ZeusMonitor] Running indefinitely. 2022-12-06 20:04:45.378 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:04:45.378 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 15:05:29,098 [ZeusDataLoader(train)] train epoch 42 done: time=43.97 energy=5846.00
2022-12-06 15:05:29,101 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 4.6501
Training Epoch: 41 [2048/50176]	Loss: 4.6260
Training Epoch: 41 [3072/50176]	Loss: 4.6350
Training Epoch: 41 [4096/50176]	Loss: 4.6244
Training Epoch: 41 [5120/50176]	Loss: 4.6321
Training Epoch: 41 [6144/50176]	Loss: 4.6376
Training Epoch: 41 [7168/50176]	Loss: 4.6452
Training Epoch: 41 [8192/50176]	Loss: 4.6262
Training Epoch: 41 [9216/50176]	Loss: 4.6307
Training Epoch: 41 [10240/50176]	Loss: 4.6442
Training Epoch: 41 [11264/50176]	Loss: 4.6319
Training Epoch: 41 [12288/50176]	Loss: 4.6398
Training Epoch: 41 [13312/50176]	Loss: 4.6600
Training Epoch: 41 [14336/50176]	Loss: 4.6485
Training Epoch: 41 [15360/50176]	Loss: 4.6416
Training Epoch: 41 [16384/50176]	Loss: 4.6568
Training Epoch: 41 [17408/50176]	Loss: 4.6418
Training Epoch: 41 [18432/50176]	Loss: 4.6238
Training Epoch: 41 [19456/50176]	Loss: 4.6357
Training Epoch: 41 [20480/50176]	Loss: 4.6309
Training Epoch: 41 [21504/50176]	Loss: 4.6377
Training Epoch: 41 [22528/50176]	Loss: 4.6516
Training Epoch: 41 [23552/50176]	Loss: 4.6618
Training Epoch: 41 [24576/50176]	Loss: 4.6431
Training Epoch: 41 [25600/50176]	Loss: 4.6377
Training Epoch: 41 [26624/50176]	Loss: 4.6204
Training Epoch: 41 [27648/50176]	Loss: 4.6342
Training Epoch: 41 [28672/50176]	Loss: 4.6540
Training Epoch: 41 [29696/50176]	Loss: 4.6373
Training Epoch: 41 [30720/50176]	Loss: 4.6439
Training Epoch: 41 [31744/50176]	Loss: 4.6419
Training Epoch: 41 [32768/50176]	Loss: 4.6355
Training Epoch: 41 [33792/50176]	Loss: 4.6351
Training Epoch: 41 [34816/50176]	Loss: 4.6323
Training Epoch: 41 [35840/50176]	Loss: 4.6446
Training Epoch: 41 [36864/50176]	Loss: 4.6474
Training Epoch: 41 [37888/50176]	Loss: 4.6368
Training Epoch: 41 [38912/50176]	Loss: 4.6409
Training Epoch: 41 [39936/50176]	Loss: 4.6507
Training Epoch: 41 [40960/50176]	Loss: 4.6437
Training Epoch: 41 [41984/50176]	Loss: 4.6442
Training Epoch: 41 [43008/50176]	Loss: 4.6356
Training Epoch: 41 [44032/50176]	Loss: 4.6508
Training Epoch: 41 [45056/50176]	Loss: 4.6353
Training Epoch: 41 [46080/50176]	Loss: 4.6403
Training Epoch: 41 [47104/50176]	Loss: 4.6315
Training Epoch: 41 [48128/50176]	Loss: 4.6347
Training Epoch: 41 [49152/50176]	Loss: 4.6378
Training Epoch: 41 [50176/50176]	Loss: 4.6364
2022-12-06 20:05:32.870 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:05:32,915 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.81 energy=480.13
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Up to epoch 42: time=2013.05, energy=264662.25, cost=308472.94
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Expected next epoch: time=2059.66, energy=271028.54, cost=315734.18
2022-12-06 15:05:32,916 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 401.2048, Accuracy: 0.0098
2022-12-06 15:05:33,153 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:05:33,154 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:05:33.156 [ZeusMonitor] Monitor started.
2022-12-06 20:05:33.156 [ZeusMonitor] Running indefinitely. 2022-12-06 20:05:33.156 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:05:33.156 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 15:06:16,941 [ZeusDataLoader(train)] train epoch 43 done: time=44.02 energy=5834.75
2022-12-06 15:06:16,944 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 4.6342
Training Epoch: 42 [2048/50176]	Loss: 4.6369
Training Epoch: 42 [3072/50176]	Loss: 4.6416
Training Epoch: 42 [4096/50176]	Loss: 4.6467
Training Epoch: 42 [5120/50176]	Loss: 4.6531
Training Epoch: 42 [6144/50176]	Loss: 4.6442
Training Epoch: 42 [7168/50176]	Loss: 4.6338
Training Epoch: 42 [8192/50176]	Loss: 4.6371
Training Epoch: 42 [9216/50176]	Loss: 4.6428
Training Epoch: 42 [10240/50176]	Loss: 4.6368
Training Epoch: 42 [11264/50176]	Loss: 4.6537
Training Epoch: 42 [12288/50176]	Loss: 4.6317
Training Epoch: 42 [13312/50176]	Loss: 4.6320
Training Epoch: 42 [14336/50176]	Loss: 4.6595
Training Epoch: 42 [15360/50176]	Loss: 4.6351
Training Epoch: 42 [16384/50176]	Loss: 4.6196
Training Epoch: 42 [17408/50176]	Loss: 4.6382
Training Epoch: 42 [18432/50176]	Loss: 4.6600
Training Epoch: 42 [19456/50176]	Loss: 4.6508
Training Epoch: 42 [20480/50176]	Loss: 4.6374
Training Epoch: 42 [21504/50176]	Loss: 4.6392
Training Epoch: 42 [22528/50176]	Loss: 4.6318
Training Epoch: 42 [23552/50176]	Loss: 4.6341
Training Epoch: 42 [24576/50176]	Loss: 4.6368
Training Epoch: 42 [25600/50176]	Loss: 4.6523
Training Epoch: 42 [26624/50176]	Loss: 4.6400
Training Epoch: 42 [27648/50176]	Loss: 4.6279
Training Epoch: 42 [28672/50176]	Loss: 4.6158
Training Epoch: 42 [29696/50176]	Loss: 4.6520
Training Epoch: 42 [30720/50176]	Loss: 4.6427
Training Epoch: 42 [31744/50176]	Loss: 4.6388
Training Epoch: 42 [32768/50176]	Loss: 4.6390
Training Epoch: 42 [33792/50176]	Loss: 4.6295
Training Epoch: 42 [34816/50176]	Loss: 4.6304
Training Epoch: 42 [35840/50176]	Loss: 4.6412
Training Epoch: 42 [36864/50176]	Loss: 4.6423
Training Epoch: 42 [37888/50176]	Loss: 4.6258
Training Epoch: 42 [38912/50176]	Loss: 4.6320
Training Epoch: 42 [39936/50176]	Loss: 4.6306
Training Epoch: 42 [40960/50176]	Loss: 4.6295
Training Epoch: 42 [41984/50176]	Loss: 4.6351
Training Epoch: 42 [43008/50176]	Loss: 4.6311
Training Epoch: 42 [44032/50176]	Loss: 4.6294
Training Epoch: 42 [45056/50176]	Loss: 4.6299
Training Epoch: 42 [46080/50176]	Loss: 4.6364
Training Epoch: 42 [47104/50176]	Loss: 4.6470
Training Epoch: 42 [48128/50176]	Loss: 4.6292
Training Epoch: 42 [49152/50176]	Loss: 4.6269
Training Epoch: 42 [50176/50176]	Loss: 4.6287
2022-12-06 20:06:20.721 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:06:20,768 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.82 energy=477.27
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Up to epoch 43: time=2060.88, energy=270974.26, cost=315814.30
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Expected next epoch: time=2107.49, energy=277340.56, cost=323075.54
2022-12-06 15:06:20,770 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 6442.1594, Accuracy: 0.0098
2022-12-06 15:06:21,018 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:06:21,019 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:06:21.021 [ZeusMonitor] Monitor started.
2022-12-06 20:06:21.021 [ZeusMonitor] Running indefinitely. 2022-12-06 20:06:21.021 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:06:21.021 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 15:07:04,461 [ZeusDataLoader(train)] train epoch 44 done: time=43.68 energy=5820.78
2022-12-06 15:07:04,465 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 4.6293
Training Epoch: 43 [2048/50176]	Loss: 4.6420
Training Epoch: 43 [3072/50176]	Loss: 4.6394
Training Epoch: 43 [4096/50176]	Loss: 4.6297
Training Epoch: 43 [5120/50176]	Loss: 4.6239
Training Epoch: 43 [6144/50176]	Loss: 4.6333
Training Epoch: 43 [7168/50176]	Loss: 4.6268
Training Epoch: 43 [8192/50176]	Loss: 4.6329
Training Epoch: 43 [9216/50176]	Loss: 4.6303
Training Epoch: 43 [10240/50176]	Loss: 4.6378
Training Epoch: 43 [11264/50176]	Loss: 4.6419
Training Epoch: 43 [12288/50176]	Loss: 4.6389
Training Epoch: 43 [13312/50176]	Loss: 4.6262
Training Epoch: 43 [14336/50176]	Loss: 4.6402
Training Epoch: 43 [15360/50176]	Loss: 4.6422
Training Epoch: 43 [16384/50176]	Loss: 4.6368
Training Epoch: 43 [17408/50176]	Loss: 4.6300
Training Epoch: 43 [18432/50176]	Loss: 4.6514
Training Epoch: 43 [19456/50176]	Loss: 4.6416
Training Epoch: 43 [20480/50176]	Loss: 4.6358
Training Epoch: 43 [21504/50176]	Loss: 4.6418
Training Epoch: 43 [22528/50176]	Loss: 4.6287
Training Epoch: 43 [23552/50176]	Loss: 4.6305
Training Epoch: 43 [24576/50176]	Loss: 4.6478
Training Epoch: 43 [25600/50176]	Loss: 4.6447
Training Epoch: 43 [26624/50176]	Loss: 4.6200
Training Epoch: 43 [27648/50176]	Loss: 4.6427
Training Epoch: 43 [28672/50176]	Loss: 4.6343
Training Epoch: 43 [29696/50176]	Loss: 4.6157
Training Epoch: 43 [30720/50176]	Loss: 4.6382
Training Epoch: 43 [31744/50176]	Loss: 4.6309
Training Epoch: 43 [32768/50176]	Loss: 4.6446
Training Epoch: 43 [33792/50176]	Loss: 4.6429
Training Epoch: 43 [34816/50176]	Loss: 4.6390
Training Epoch: 43 [35840/50176]	Loss: 4.6214
Training Epoch: 43 [36864/50176]	Loss: 4.6270
Training Epoch: 43 [37888/50176]	Loss: 4.6381
Training Epoch: 43 [38912/50176]	Loss: 4.6435
Training Epoch: 43 [39936/50176]	Loss: 4.6422
Training Epoch: 43 [40960/50176]	Loss: 4.6469
Training Epoch: 43 [41984/50176]	Loss: 4.6461
Training Epoch: 43 [43008/50176]	Loss: 4.6264
Training Epoch: 43 [44032/50176]	Loss: 4.6347
Training Epoch: 43 [45056/50176]	Loss: 4.6200
Training Epoch: 43 [46080/50176]	Loss: 4.6331
Training Epoch: 43 [47104/50176]	Loss: 4.6405
Training Epoch: 43 [48128/50176]	Loss: 4.6410
Training Epoch: 43 [49152/50176]	Loss: 4.6502
Training Epoch: 43 [50176/50176]	Loss: 4.6458
2022-12-06 20:07:08.218 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:07:08,227 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.75 energy=462.07
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Up to epoch 44: time=2108.32, energy=277257.11, cost=323106.56
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Expected next epoch: time=2154.93, energy=283623.40, cost=330367.80
2022-12-06 15:07:08,229 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0045, Accuracy: 0.0097
2022-12-06 15:07:08,463 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:07:08,464 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:07:08.478 [ZeusMonitor] Monitor started.
2022-12-06 20:07:08.478 [ZeusMonitor] Running indefinitely. 2022-12-06 20:07:08.478 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:07:08.478 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 15:07:51,992 [ZeusDataLoader(train)] train epoch 45 done: time=43.75 energy=5824.97
2022-12-06 15:07:51,995 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 4.6368
Training Epoch: 44 [2048/50176]	Loss: 4.6273
Training Epoch: 44 [3072/50176]	Loss: 4.6218
Training Epoch: 44 [4096/50176]	Loss: 4.6299
Training Epoch: 44 [5120/50176]	Loss: 4.6429
Training Epoch: 44 [6144/50176]	Loss: 4.6475
Training Epoch: 44 [7168/50176]	Loss: 4.6329
Training Epoch: 44 [8192/50176]	Loss: 4.6460
Training Epoch: 44 [9216/50176]	Loss: 4.6257
Training Epoch: 44 [10240/50176]	Loss: 4.6414
Training Epoch: 44 [11264/50176]	Loss: 4.6266
Training Epoch: 44 [12288/50176]	Loss: 4.6382
Training Epoch: 44 [13312/50176]	Loss: 4.6273
Training Epoch: 44 [14336/50176]	Loss: 4.6254
Training Epoch: 44 [15360/50176]	Loss: 4.6396
Training Epoch: 44 [16384/50176]	Loss: 4.6405
Training Epoch: 44 [17408/50176]	Loss: 4.6372
Training Epoch: 44 [18432/50176]	Loss: 4.6428
Training Epoch: 44 [19456/50176]	Loss: 4.6260
Training Epoch: 44 [20480/50176]	Loss: 4.6323
Training Epoch: 44 [21504/50176]	Loss: 4.6344
Training Epoch: 44 [22528/50176]	Loss: 4.6197
Training Epoch: 44 [23552/50176]	Loss: 4.6298
Training Epoch: 44 [24576/50176]	Loss: 4.6349
Training Epoch: 44 [25600/50176]	Loss: 4.6429
Training Epoch: 44 [26624/50176]	Loss: 4.6322
Training Epoch: 44 [27648/50176]	Loss: 4.6264
Training Epoch: 44 [28672/50176]	Loss: 4.6295
Training Epoch: 44 [29696/50176]	Loss: 4.6443
Training Epoch: 44 [30720/50176]	Loss: 4.6227
Training Epoch: 44 [31744/50176]	Loss: 4.6343
Training Epoch: 44 [32768/50176]	Loss: 4.6413
Training Epoch: 44 [33792/50176]	Loss: 4.6348
Training Epoch: 44 [34816/50176]	Loss: 4.6195
Training Epoch: 44 [35840/50176]	Loss: 4.6315
Training Epoch: 44 [36864/50176]	Loss: 4.6425
Training Epoch: 44 [37888/50176]	Loss: 4.6347
Training Epoch: 44 [38912/50176]	Loss: 4.6292
Training Epoch: 44 [39936/50176]	Loss: 4.6268
Training Epoch: 44 [40960/50176]	Loss: 4.6370
Training Epoch: 44 [41984/50176]	Loss: 4.6310
Training Epoch: 44 [43008/50176]	Loss: 4.6351
Training Epoch: 44 [44032/50176]	Loss: 4.6278
Training Epoch: 44 [45056/50176]	Loss: 4.6373
Training Epoch: 44 [46080/50176]	Loss: 4.6384
Training Epoch: 44 [47104/50176]	Loss: 4.6503
Training Epoch: 44 [48128/50176]	Loss: 4.6286
Training Epoch: 44 [49152/50176]	Loss: 4.6640
Training Epoch: 44 [50176/50176]	Loss: 4.6331
2022-12-06 20:07:55.758 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:07:55,815 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.81 energy=480.48
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Up to epoch 45: time=2155.89, energy=283562.55, cost=330421.37
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Expected next epoch: time=2202.49, energy=289928.85, cost=337682.60
2022-12-06 15:07:55,816 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 313.6202, Accuracy: 0.0098
2022-12-06 15:07:56,071 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:07:56,071 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:07:56.073 [ZeusMonitor] Monitor started.
2022-12-06 20:07:56.073 [ZeusMonitor] Running indefinitely. 2022-12-06 20:07:56.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:07:56.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 15:08:39,720 [ZeusDataLoader(train)] train epoch 46 done: time=43.90 energy=5833.35
2022-12-06 15:08:39,724 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 4.6390
Training Epoch: 45 [2048/50176]	Loss: 4.6320
Training Epoch: 45 [3072/50176]	Loss: 4.6242
Training Epoch: 45 [4096/50176]	Loss: 4.6595
Training Epoch: 45 [5120/50176]	Loss: 4.6302
Training Epoch: 45 [6144/50176]	Loss: 4.6495
Training Epoch: 45 [7168/50176]	Loss: 4.6370
Training Epoch: 45 [8192/50176]	Loss: 4.6371
Training Epoch: 45 [9216/50176]	Loss: 4.6468
Training Epoch: 45 [10240/50176]	Loss: 4.6310
Training Epoch: 45 [11264/50176]	Loss: 4.6430
Training Epoch: 45 [12288/50176]	Loss: 4.6347
Training Epoch: 45 [13312/50176]	Loss: 4.6406
Training Epoch: 45 [14336/50176]	Loss: 4.6350
Training Epoch: 45 [15360/50176]	Loss: 4.6304
Training Epoch: 45 [16384/50176]	Loss: 4.6473
Training Epoch: 45 [17408/50176]	Loss: 4.6346
Training Epoch: 45 [18432/50176]	Loss: 4.6329
Training Epoch: 45 [19456/50176]	Loss: 4.6380
Training Epoch: 45 [20480/50176]	Loss: 4.6360
Training Epoch: 45 [21504/50176]	Loss: 4.6424
Training Epoch: 45 [22528/50176]	Loss: 4.6477
Training Epoch: 45 [23552/50176]	Loss: 4.6232
Training Epoch: 45 [24576/50176]	Loss: 4.6336
Training Epoch: 45 [25600/50176]	Loss: 4.6441
Training Epoch: 45 [26624/50176]	Loss: 4.6308
Training Epoch: 45 [27648/50176]	Loss: 4.6370
Training Epoch: 45 [28672/50176]	Loss: 4.6383
Training Epoch: 45 [29696/50176]	Loss: 4.6488
Training Epoch: 45 [30720/50176]	Loss: 4.6434
Training Epoch: 45 [31744/50176]	Loss: 4.6382
Training Epoch: 45 [32768/50176]	Loss: 4.6290
Training Epoch: 45 [33792/50176]	Loss: 4.6497
Training Epoch: 45 [34816/50176]	Loss: 4.6498
Training Epoch: 45 [35840/50176]	Loss: 4.6359
Training Epoch: 45 [36864/50176]	Loss: 4.6372
Training Epoch: 45 [37888/50176]	Loss: 4.6308
Training Epoch: 45 [38912/50176]	Loss: 4.6488
Training Epoch: 45 [39936/50176]	Loss: 4.6506
Training Epoch: 45 [40960/50176]	Loss: 4.6344
Training Epoch: 45 [41984/50176]	Loss: 4.6363
Training Epoch: 45 [43008/50176]	Loss: 4.6399
Training Epoch: 45 [44032/50176]	Loss: 4.6348
Training Epoch: 45 [45056/50176]	Loss: 4.6517
Training Epoch: 45 [46080/50176]	Loss: 4.6375
Training Epoch: 45 [47104/50176]	Loss: 4.6428
Training Epoch: 45 [48128/50176]	Loss: 4.6470
Training Epoch: 45 [49152/50176]	Loss: 4.6463
Training Epoch: 45 [50176/50176]	Loss: 4.6325
2022-12-06 20:08:43.520 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:08:43,563 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.83 energy=475.26
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Up to epoch 46: time=2203.61, energy=289871.17, cost=337751.79
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Expected next epoch: time=2250.22, energy=296237.46, cost=345013.03
2022-12-06 15:08:43,564 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 15715.4555, Accuracy: 0.0098
2022-12-06 15:08:43,774 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:08:43,774 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:08:43.776 [ZeusMonitor] Monitor started.
2022-12-06 20:08:43.776 [ZeusMonitor] Running indefinitely. 2022-12-06 20:08:43.776 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:08:43.777 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 15:09:27,340 [ZeusDataLoader(train)] train epoch 47 done: time=43.77 energy=5832.95
2022-12-06 15:09:27,344 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 4.6333
Training Epoch: 46 [2048/50176]	Loss: 4.6488
Training Epoch: 46 [3072/50176]	Loss: 4.6532
Training Epoch: 46 [4096/50176]	Loss: 4.6295
Training Epoch: 46 [5120/50176]	Loss: 4.6417
Training Epoch: 46 [6144/50176]	Loss: 4.6413
Training Epoch: 46 [7168/50176]	Loss: 4.6436
Training Epoch: 46 [8192/50176]	Loss: 4.6355
Training Epoch: 46 [9216/50176]	Loss: 4.6420
Training Epoch: 46 [10240/50176]	Loss: 4.6407
Training Epoch: 46 [11264/50176]	Loss: 4.6259
Training Epoch: 46 [12288/50176]	Loss: 4.6301
Training Epoch: 46 [13312/50176]	Loss: 4.6331
Training Epoch: 46 [14336/50176]	Loss: 4.6378
Training Epoch: 46 [15360/50176]	Loss: 4.6183
Training Epoch: 46 [16384/50176]	Loss: 4.6351
Training Epoch: 46 [17408/50176]	Loss: 4.6310
Training Epoch: 46 [18432/50176]	Loss: 4.6295
Training Epoch: 46 [19456/50176]	Loss: 4.6227
Training Epoch: 46 [20480/50176]	Loss: 4.6378
Training Epoch: 46 [21504/50176]	Loss: 4.6352
Training Epoch: 46 [22528/50176]	Loss: 4.6342
Training Epoch: 46 [23552/50176]	Loss: 4.6421
Training Epoch: 46 [24576/50176]	Loss: 4.6426
Training Epoch: 46 [25600/50176]	Loss: 4.6359
Training Epoch: 46 [26624/50176]	Loss: 4.6345
Training Epoch: 46 [27648/50176]	Loss: 4.6417
Training Epoch: 46 [28672/50176]	Loss: 4.6350
Training Epoch: 46 [29696/50176]	Loss: 4.6361
Training Epoch: 46 [30720/50176]	Loss: 4.6485
Training Epoch: 46 [31744/50176]	Loss: 4.6377
Training Epoch: 46 [32768/50176]	Loss: 4.6325
Training Epoch: 46 [33792/50176]	Loss: 4.6244
Training Epoch: 46 [34816/50176]	Loss: 4.6259
Training Epoch: 46 [35840/50176]	Loss: 4.6332
Training Epoch: 46 [36864/50176]	Loss: 4.6477
Training Epoch: 46 [37888/50176]	Loss: 4.6415
Training Epoch: 46 [38912/50176]	Loss: 4.6374
Training Epoch: 46 [39936/50176]	Loss: 4.6175
Training Epoch: 46 [40960/50176]	Loss: 4.6460
Training Epoch: 46 [41984/50176]	Loss: 4.6339
Training Epoch: 46 [43008/50176]	Loss: 4.6448
Training Epoch: 46 [44032/50176]	Loss: 4.6331
Training Epoch: 46 [45056/50176]	Loss: 4.6418
Training Epoch: 46 [46080/50176]	Loss: 4.6465
Training Epoch: 46 [47104/50176]	Loss: 4.6320
Training Epoch: 46 [48128/50176]	Loss: 4.6262
Training Epoch: 46 [49152/50176]	Loss: 4.6345
Training Epoch: 46 [50176/50176]	Loss: 4.6416
2022-12-06 20:09:31.069 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:09:31,093 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.74 energy=467.13
2022-12-06 15:09:31,093 [ZeusDataLoader(train)] Up to epoch 47: time=2251.12, energy=296171.25, cost=345058.94
2022-12-06 15:09:31,094 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:09:31,094 [ZeusDataLoader(train)] Expected next epoch: time=2297.73, energy=302537.54, cost=352320.18
2022-12-06 15:09:31,095 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 13792.4378, Accuracy: 0.0098
2022-12-06 15:09:31,374 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:09:31,374 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:09:31.376 [ZeusMonitor] Monitor started.
2022-12-06 20:09:31.376 [ZeusMonitor] Running indefinitely. 2022-12-06 20:09:31.376 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:09:31.376 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 15:10:14,826 [ZeusDataLoader(train)] train epoch 48 done: time=43.72 energy=5822.93
2022-12-06 15:10:14,830 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 4.6379
Training Epoch: 47 [2048/50176]	Loss: 4.6394
Training Epoch: 47 [3072/50176]	Loss: 4.6521
Training Epoch: 47 [4096/50176]	Loss: 4.6394
Training Epoch: 47 [5120/50176]	Loss: 4.6435
Training Epoch: 47 [6144/50176]	Loss: 4.6373
Training Epoch: 47 [7168/50176]	Loss: 4.6156
Training Epoch: 47 [8192/50176]	Loss: 4.6553
Training Epoch: 47 [9216/50176]	Loss: 4.6386
Training Epoch: 47 [10240/50176]	Loss: 4.6582
Training Epoch: 47 [11264/50176]	Loss: 4.6449
Training Epoch: 47 [12288/50176]	Loss: 4.6409
Training Epoch: 47 [13312/50176]	Loss: 4.6398
Training Epoch: 47 [14336/50176]	Loss: 4.6322
Training Epoch: 47 [15360/50176]	Loss: 4.6228
Training Epoch: 47 [16384/50176]	Loss: 4.6348
Training Epoch: 47 [17408/50176]	Loss: 4.6406
Training Epoch: 47 [18432/50176]	Loss: 4.6330
Training Epoch: 47 [19456/50176]	Loss: 4.6635
Training Epoch: 47 [20480/50176]	Loss: 4.6384
Training Epoch: 47 [21504/50176]	Loss: 4.6449
Training Epoch: 47 [22528/50176]	Loss: 4.6233
Training Epoch: 47 [23552/50176]	Loss: 4.6411
Training Epoch: 47 [24576/50176]	Loss: 4.6259
Training Epoch: 47 [25600/50176]	Loss: 4.6448
Training Epoch: 47 [26624/50176]	Loss: 4.6388
Training Epoch: 47 [27648/50176]	Loss: 4.6324
Training Epoch: 47 [28672/50176]	Loss: 4.6394
Training Epoch: 47 [29696/50176]	Loss: 4.6320
Training Epoch: 47 [30720/50176]	Loss: 4.6426
Training Epoch: 47 [31744/50176]	Loss: 4.6376
Training Epoch: 47 [32768/50176]	Loss: 4.6388
Training Epoch: 47 [33792/50176]	Loss: 4.6401
Training Epoch: 47 [34816/50176]	Loss: 4.6341
Training Epoch: 47 [35840/50176]	Loss: 4.6413
Training Epoch: 47 [36864/50176]	Loss: 4.6284
Training Epoch: 47 [37888/50176]	Loss: 4.6421
Training Epoch: 47 [38912/50176]	Loss: 4.6462
Training Epoch: 47 [39936/50176]	Loss: 4.6361
Training Epoch: 47 [40960/50176]	Loss: 4.6450
Training Epoch: 47 [41984/50176]	Loss: 4.6472
Training Epoch: 47 [43008/50176]	Loss: 4.6279
Training Epoch: 47 [44032/50176]	Loss: 4.6407
Training Epoch: 47 [45056/50176]	Loss: 4.6225
Training Epoch: 47 [46080/50176]	Loss: 4.6276
Training Epoch: 47 [47104/50176]	Loss: 4.6347
Training Epoch: 47 [48128/50176]	Loss: 4.6295
Training Epoch: 47 [49152/50176]	Loss: 4.6360
Training Epoch: 47 [50176/50176]	Loss: 4.6229
2022-12-06 20:10:18.555 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:10:18,574 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.74 energy=464.47
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Up to epoch 48: time=2298.58, energy=302458.65, cost=352355.35
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Expected next epoch: time=2345.19, energy=308824.95, cost=359616.59
2022-12-06 15:10:18,575 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 19788.6666, Accuracy: 0.0098
2022-12-06 15:10:18,843 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:10:18,843 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:10:18.845 [ZeusMonitor] Monitor started.
2022-12-06 20:10:18.845 [ZeusMonitor] Running indefinitely. 2022-12-06 20:10:18.845 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:10:18.845 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 15:11:02,310 [ZeusDataLoader(train)] train epoch 49 done: time=43.73 energy=5830.79
2022-12-06 15:11:02,313 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 4.6278
Training Epoch: 48 [2048/50176]	Loss: 4.6316
Training Epoch: 48 [3072/50176]	Loss: 4.6328
Training Epoch: 48 [4096/50176]	Loss: 4.6277
Training Epoch: 48 [5120/50176]	Loss: 4.6294
Training Epoch: 48 [6144/50176]	Loss: 4.6434
Training Epoch: 48 [7168/50176]	Loss: 4.6339
Training Epoch: 48 [8192/50176]	Loss: 4.6370
Training Epoch: 48 [9216/50176]	Loss: 4.6384
Training Epoch: 48 [10240/50176]	Loss: 4.6373
Training Epoch: 48 [11264/50176]	Loss: 4.6384
Training Epoch: 48 [12288/50176]	Loss: 4.6268
Training Epoch: 48 [13312/50176]	Loss: 4.6366
Training Epoch: 48 [14336/50176]	Loss: 4.6339
Training Epoch: 48 [15360/50176]	Loss: 4.6245
Training Epoch: 48 [16384/50176]	Loss: 4.6337
Training Epoch: 48 [17408/50176]	Loss: 4.6315
Training Epoch: 48 [18432/50176]	Loss: 4.6347
Training Epoch: 48 [19456/50176]	Loss: 4.6334
Training Epoch: 48 [20480/50176]	Loss: 4.6543
Training Epoch: 48 [21504/50176]	Loss: 4.6361
Training Epoch: 48 [22528/50176]	Loss: 4.6411
Training Epoch: 48 [23552/50176]	Loss: 4.6258
Training Epoch: 48 [24576/50176]	Loss: 4.6358
Training Epoch: 48 [25600/50176]	Loss: 4.6371
Training Epoch: 48 [26624/50176]	Loss: 4.6303
Training Epoch: 48 [27648/50176]	Loss: 4.6364
Training Epoch: 48 [28672/50176]	Loss: 4.6319
Training Epoch: 48 [29696/50176]	Loss: 4.6486
Training Epoch: 48 [30720/50176]	Loss: 4.6353
Training Epoch: 48 [31744/50176]	Loss: 4.6350
Training Epoch: 48 [32768/50176]	Loss: 4.6374
Training Epoch: 48 [33792/50176]	Loss: 4.6303
Training Epoch: 48 [34816/50176]	Loss: 4.6285
Training Epoch: 48 [35840/50176]	Loss: 4.6325
Training Epoch: 48 [36864/50176]	Loss: 4.6422
Training Epoch: 48 [37888/50176]	Loss: 4.6237
Training Epoch: 48 [38912/50176]	Loss: 4.6226
Training Epoch: 48 [39936/50176]	Loss: 4.6362
Training Epoch: 48 [40960/50176]	Loss: 4.6325
Training Epoch: 48 [41984/50176]	Loss: 4.6496
Training Epoch: 48 [43008/50176]	Loss: 4.6219
Training Epoch: 48 [44032/50176]	Loss: 4.6370
Training Epoch: 48 [45056/50176]	Loss: 4.6305
Training Epoch: 48 [46080/50176]	Loss: 4.6499
Training Epoch: 48 [47104/50176]	Loss: 4.6407
Training Epoch: 48 [48128/50176]	Loss: 4.6405
Training Epoch: 48 [49152/50176]	Loss: 4.6313
Training Epoch: 48 [50176/50176]	Loss: 4.6315
2022-12-06 20:11:06.064 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:11:06,090 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.77 energy=463.07
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Up to epoch 49: time=2346.08, energy=308752.52, cost=359658.11
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Expected next epoch: time=2392.68, energy=315118.81, cost=366919.34
2022-12-06 15:11:06,091 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 66445.6536, Accuracy: 0.0098
2022-12-06 15:11:06,337 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:11:06,338 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:11:06.340 [ZeusMonitor] Monitor started.
2022-12-06 20:11:06.340 [ZeusMonitor] Running indefinitely. 2022-12-06 20:11:06.340 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:11:06.340 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 15:11:49,796 [ZeusDataLoader(train)] train epoch 50 done: time=43.70 energy=5817.93
2022-12-06 15:11:49,799 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 4.6253
Training Epoch: 49 [2048/50176]	Loss: 4.6395
Training Epoch: 49 [3072/50176]	Loss: 4.6325
Training Epoch: 49 [4096/50176]	Loss: 4.6319
Training Epoch: 49 [5120/50176]	Loss: 4.6545
Training Epoch: 49 [6144/50176]	Loss: 4.6487
Training Epoch: 49 [7168/50176]	Loss: 4.6334
Training Epoch: 49 [8192/50176]	Loss: 4.6380
Training Epoch: 49 [9216/50176]	Loss: 4.6375
Training Epoch: 49 [10240/50176]	Loss: 4.6347
Training Epoch: 49 [11264/50176]	Loss: 4.6456
Training Epoch: 49 [12288/50176]	Loss: 4.6378
Training Epoch: 49 [13312/50176]	Loss: 4.6421
Training Epoch: 49 [14336/50176]	Loss: 4.6333
Training Epoch: 49 [15360/50176]	Loss: 4.6497
Training Epoch: 49 [16384/50176]	Loss: 4.6390
Training Epoch: 49 [17408/50176]	Loss: 4.6454
Training Epoch: 49 [18432/50176]	Loss: 4.6383
Training Epoch: 49 [19456/50176]	Loss: 4.6299
Training Epoch: 49 [20480/50176]	Loss: 4.6305
Training Epoch: 49 [21504/50176]	Loss: 4.6461
Training Epoch: 49 [22528/50176]	Loss: 4.6417
Training Epoch: 49 [23552/50176]	Loss: 4.6268
Training Epoch: 49 [24576/50176]	Loss: 4.6333
Training Epoch: 49 [25600/50176]	Loss: 4.6386
Training Epoch: 49 [26624/50176]	Loss: 4.6263
Training Epoch: 49 [27648/50176]	Loss: 4.6273
Training Epoch: 49 [28672/50176]	Loss: 4.6309
Training Epoch: 49 [29696/50176]	Loss: 4.6375
Training Epoch: 49 [30720/50176]	Loss: 4.6348
Training Epoch: 49 [31744/50176]	Loss: 4.6398
Training Epoch: 49 [32768/50176]	Loss: 4.6341
Training Epoch: 49 [33792/50176]	Loss: 4.6403
Training Epoch: 49 [34816/50176]	Loss: 4.6245
Training Epoch: 49 [35840/50176]	Loss: 4.6280
Training Epoch: 49 [36864/50176]	Loss: 4.6458
Training Epoch: 49 [37888/50176]	Loss: 4.6316
Training Epoch: 49 [38912/50176]	Loss: 4.6362
Training Epoch: 49 [39936/50176]	Loss: 4.6374
Training Epoch: 49 [40960/50176]	Loss: 4.6362
Training Epoch: 49 [41984/50176]	Loss: 4.6344
Training Epoch: 49 [43008/50176]	Loss: 4.6264
Training Epoch: 49 [44032/50176]	Loss: 4.6340
Training Epoch: 49 [45056/50176]	Loss: 4.6393
Training Epoch: 49 [46080/50176]	Loss: 4.6256
Training Epoch: 49 [47104/50176]	Loss: 4.6279
Training Epoch: 49 [48128/50176]	Loss: 4.6417
Training Epoch: 49 [49152/50176]	Loss: 4.6292
Training Epoch: 49 [50176/50176]	Loss: 4.6271
2022-12-06 20:11:53.668 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:11:53,703 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.90 energy=487.94
2022-12-06 15:11:53,703 [ZeusDataLoader(train)] Up to epoch 50: time=2393.67, energy=315058.39, cost=366975.42
2022-12-06 15:11:53,703 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:11:53,704 [ZeusDataLoader(train)] Expected next epoch: time=2440.28, energy=321424.69, cost=374236.66
2022-12-06 15:11:53,704 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 22031.1692, Accuracy: 0.0098
2022-12-06 15:11:53,955 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:11:53,955 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:11:53.957 [ZeusMonitor] Monitor started.
2022-12-06 20:11:53.957 [ZeusMonitor] Running indefinitely. 2022-12-06 20:11:53.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:11:53.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 15:12:37,485 [ZeusDataLoader(train)] train epoch 51 done: time=43.77 energy=5828.01
2022-12-06 15:12:37,488 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 4.6415
Training Epoch: 50 [2048/50176]	Loss: 4.6209
Training Epoch: 50 [3072/50176]	Loss: 4.6386
Training Epoch: 50 [4096/50176]	Loss: 4.6514
Training Epoch: 50 [5120/50176]	Loss: 4.6418
Training Epoch: 50 [6144/50176]	Loss: 4.6410
Training Epoch: 50 [7168/50176]	Loss: 4.6337
Training Epoch: 50 [8192/50176]	Loss: 4.6357
Training Epoch: 50 [9216/50176]	Loss: 4.6486
Training Epoch: 50 [10240/50176]	Loss: 4.6369
Training Epoch: 50 [11264/50176]	Loss: 4.6671
Training Epoch: 50 [12288/50176]	Loss: 4.6316
Training Epoch: 50 [13312/50176]	Loss: 4.6350
Training Epoch: 50 [14336/50176]	Loss: 4.6327
Training Epoch: 50 [15360/50176]	Loss: 4.6329
Training Epoch: 50 [16384/50176]	Loss: 4.6343
Training Epoch: 50 [17408/50176]	Loss: 4.6423
Training Epoch: 50 [18432/50176]	Loss: 4.6408
Training Epoch: 50 [19456/50176]	Loss: 4.6356
Training Epoch: 50 [20480/50176]	Loss: 4.6330
Training Epoch: 50 [21504/50176]	Loss: 4.6254
Training Epoch: 50 [22528/50176]	Loss: 4.6541
Training Epoch: 50 [23552/50176]	Loss: 4.6418
Training Epoch: 50 [24576/50176]	Loss: 4.6318
Training Epoch: 50 [25600/50176]	Loss: 4.6324
Training Epoch: 50 [26624/50176]	Loss: 4.6319
Training Epoch: 50 [27648/50176]	Loss: 4.6399
Training Epoch: 50 [28672/50176]	Loss: 4.6373
Training Epoch: 50 [29696/50176]	Loss: 4.6402
Training Epoch: 50 [30720/50176]	Loss: 4.6367
Training Epoch: 50 [31744/50176]	Loss: 4.6378
Training Epoch: 50 [32768/50176]	Loss: 4.6354
Training Epoch: 50 [33792/50176]	Loss: 4.6434
Training Epoch: 50 [34816/50176]	Loss: 4.6234
Training Epoch: 50 [35840/50176]	Loss: 4.6327
Training Epoch: 50 [36864/50176]	Loss: 4.6475
Training Epoch: 50 [37888/50176]	Loss: 4.6328
Training Epoch: 50 [38912/50176]	Loss: 4.6403
Training Epoch: 50 [39936/50176]	Loss: 4.6312
Training Epoch: 50 [40960/50176]	Loss: 4.6374
Training Epoch: 50 [41984/50176]	Loss: 4.6511
Training Epoch: 50 [43008/50176]	Loss: 4.6497
Training Epoch: 50 [44032/50176]	Loss: 4.6488
Training Epoch: 50 [45056/50176]	Loss: 4.6489
Training Epoch: 50 [46080/50176]	Loss: 4.6281
Training Epoch: 50 [47104/50176]	Loss: 4.6376
Training Epoch: 50 [48128/50176]	Loss: 4.6513
Training Epoch: 50 [49152/50176]	Loss: 4.6361
Training Epoch: 50 [50176/50176]	Loss: 4.6463
2022-12-06 20:12:41.211 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:12:41,221 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.73 energy=464.73
2022-12-06 15:12:41,221 [ZeusDataLoader(train)] Up to epoch 51: time=2441.17, energy=321351.14, cost=374277.84
2022-12-06 15:12:41,222 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:12:41,222 [ZeusDataLoader(train)] Expected next epoch: time=2487.78, energy=327717.43, cost=381539.07
2022-12-06 15:12:41,223 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 1792.7416, Accuracy: 0.0097
2022-12-06 15:12:41,471 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:12:41,472 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:12:41.474 [ZeusMonitor] Monitor started.
2022-12-06 20:12:41.474 [ZeusMonitor] Running indefinitely. 2022-12-06 20:12:41.474 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:12:41.474 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 15:13:25,044 [ZeusDataLoader(train)] train epoch 52 done: time=43.81 energy=5837.99
2022-12-06 15:13:25,047 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 4.6253
Training Epoch: 51 [2048/50176]	Loss: 4.6296
Training Epoch: 51 [3072/50176]	Loss: 4.6260
Training Epoch: 51 [4096/50176]	Loss: 4.6587
Training Epoch: 51 [5120/50176]	Loss: 4.6377
Training Epoch: 51 [6144/50176]	Loss: 4.6466
Training Epoch: 51 [7168/50176]	Loss: 4.6355
Training Epoch: 51 [8192/50176]	Loss: 4.6283
Training Epoch: 51 [9216/50176]	Loss: 4.6425
Training Epoch: 51 [10240/50176]	Loss: 4.6314
Training Epoch: 51 [11264/50176]	Loss: 4.6406
Training Epoch: 51 [12288/50176]	Loss: 4.6328
Training Epoch: 51 [13312/50176]	Loss: 4.6441
Training Epoch: 51 [14336/50176]	Loss: 4.6454
Training Epoch: 51 [15360/50176]	Loss: 4.6399
Training Epoch: 51 [16384/50176]	Loss: 4.6412
Training Epoch: 51 [17408/50176]	Loss: 4.6404
Training Epoch: 51 [18432/50176]	Loss: 4.6420
Training Epoch: 51 [19456/50176]	Loss: 4.6452
Training Epoch: 51 [20480/50176]	Loss: 4.6211
Training Epoch: 51 [21504/50176]	Loss: 4.6307
Training Epoch: 51 [22528/50176]	Loss: 4.6197
Training Epoch: 51 [23552/50176]	Loss: 4.6356
Training Epoch: 51 [24576/50176]	Loss: 4.6604
Training Epoch: 51 [25600/50176]	Loss: 4.6263
Training Epoch: 51 [26624/50176]	Loss: 4.6339
Training Epoch: 51 [27648/50176]	Loss: 4.6410
Training Epoch: 51 [28672/50176]	Loss: 4.6395
Training Epoch: 51 [29696/50176]	Loss: 4.6484
Training Epoch: 51 [30720/50176]	Loss: 4.6396
Training Epoch: 51 [31744/50176]	Loss: 4.6412
Training Epoch: 51 [32768/50176]	Loss: 4.6504
Training Epoch: 51 [33792/50176]	Loss: 4.6309
Training Epoch: 51 [34816/50176]	Loss: 4.6420
Training Epoch: 51 [35840/50176]	Loss: 4.6384
Training Epoch: 51 [36864/50176]	Loss: 4.6400
Training Epoch: 51 [37888/50176]	Loss: 4.6631
Training Epoch: 51 [38912/50176]	Loss: 4.6319
Training Epoch: 51 [39936/50176]	Loss: 4.6297
Training Epoch: 51 [40960/50176]	Loss: 4.6259
Training Epoch: 51 [41984/50176]	Loss: 4.6421
Training Epoch: 51 [43008/50176]	Loss: 4.6475
Training Epoch: 51 [44032/50176]	Loss: 4.6377
Training Epoch: 51 [45056/50176]	Loss: 4.6318
Training Epoch: 51 [46080/50176]	Loss: 4.6468
Training Epoch: 51 [47104/50176]	Loss: 4.6481
Training Epoch: 51 [48128/50176]	Loss: 4.6332
Training Epoch: 51 [49152/50176]	Loss: 4.6390
Training Epoch: 51 [50176/50176]	Loss: 4.6382
2022-12-06 20:13:28.801 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:13:28,841 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.79 energy=482.31
2022-12-06 15:13:28,841 [ZeusDataLoader(train)] Up to epoch 52: time=2488.77, energy=327671.44, cost=381602.96
2022-12-06 15:13:28,841 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:13:28,842 [ZeusDataLoader(train)] Expected next epoch: time=2535.38, energy=334037.73, cost=388864.20
2022-12-06 15:13:28,842 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 1907.4217, Accuracy: 0.0098
2022-12-06 15:13:29,094 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:13:29,094 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:13:29.096 [ZeusMonitor] Monitor started.
2022-12-06 20:13:29.096 [ZeusMonitor] Running indefinitely. 2022-12-06 20:13:29.096 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:13:29.096 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 15:14:12,763 [ZeusDataLoader(train)] train epoch 53 done: time=43.91 energy=5843.53
2022-12-06 15:14:12,765 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 4.6317
Training Epoch: 52 [2048/50176]	Loss: 4.6376
Training Epoch: 52 [3072/50176]	Loss: 4.6524
Training Epoch: 52 [4096/50176]	Loss: 4.6348
Training Epoch: 52 [5120/50176]	Loss: 4.6321
Training Epoch: 52 [6144/50176]	Loss: 4.6579
Training Epoch: 52 [7168/50176]	Loss: 4.6462
Training Epoch: 52 [8192/50176]	Loss: 4.6316
Training Epoch: 52 [9216/50176]	Loss: 4.6394
Training Epoch: 52 [10240/50176]	Loss: 4.6367
Training Epoch: 52 [11264/50176]	Loss: 4.6412
Training Epoch: 52 [12288/50176]	Loss: 4.6432
Training Epoch: 52 [13312/50176]	Loss: 4.6455
Training Epoch: 52 [14336/50176]	Loss: 4.6321
Training Epoch: 52 [15360/50176]	Loss: 4.6434
Training Epoch: 52 [16384/50176]	Loss: 4.6419
Training Epoch: 52 [17408/50176]	Loss: 4.6317
Training Epoch: 52 [18432/50176]	Loss: 4.6405
Training Epoch: 52 [19456/50176]	Loss: 4.6304
Training Epoch: 52 [20480/50176]	Loss: 4.6342
Training Epoch: 52 [21504/50176]	Loss: 4.6318
Training Epoch: 52 [22528/50176]	Loss: 4.6578
Training Epoch: 52 [23552/50176]	Loss: 4.6464
Training Epoch: 52 [24576/50176]	Loss: 4.6515
Training Epoch: 52 [25600/50176]	Loss: 4.6369
Training Epoch: 52 [26624/50176]	Loss: 4.6492
Training Epoch: 52 [27648/50176]	Loss: 4.6546
Training Epoch: 52 [28672/50176]	Loss: 4.6477
Training Epoch: 52 [29696/50176]	Loss: 4.6531
Training Epoch: 52 [30720/50176]	Loss: 4.6409
Training Epoch: 52 [31744/50176]	Loss: 4.6443
Training Epoch: 52 [32768/50176]	Loss: 4.6402
Training Epoch: 52 [33792/50176]	Loss: 4.6149
Training Epoch: 52 [34816/50176]	Loss: 4.6458
Training Epoch: 52 [35840/50176]	Loss: 4.6523
Training Epoch: 52 [36864/50176]	Loss: 4.6349
Training Epoch: 52 [37888/50176]	Loss: 4.6380
Training Epoch: 52 [38912/50176]	Loss: 4.6366
Training Epoch: 52 [39936/50176]	Loss: 4.6367
Training Epoch: 52 [40960/50176]	Loss: 4.6337
Training Epoch: 52 [41984/50176]	Loss: 4.6304
Training Epoch: 52 [43008/50176]	Loss: 4.6513
Training Epoch: 52 [44032/50176]	Loss: 4.6203
Training Epoch: 52 [45056/50176]	Loss: 4.6410
Training Epoch: 52 [46080/50176]	Loss: 4.6352
Training Epoch: 52 [47104/50176]	Loss: 4.6370
Training Epoch: 52 [48128/50176]	Loss: 4.6441
Training Epoch: 52 [49152/50176]	Loss: 4.6333
Training Epoch: 52 [50176/50176]	Loss: 4.6479
2022-12-06 20:14:16.595 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:14:16,619 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.85 energy=474.56
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Up to epoch 53: time=2536.53, energy=333989.53, cost=388940.83
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Expected next epoch: time=2583.13, energy=340355.82, cost=396202.07
2022-12-06 15:14:16,620 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:14:16,871 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:14:16,871 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:14:16.873 [ZeusMonitor] Monitor started.
2022-12-06 20:14:16.873 [ZeusMonitor] Running indefinitely. 2022-12-06 20:14:16.873 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:14:16.873 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 15:15:00,311 [ZeusDataLoader(train)] train epoch 54 done: time=43.68 energy=5825.16
2022-12-06 15:15:00,314 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 4.6324
Training Epoch: 53 [2048/50176]	Loss: 4.6191
Training Epoch: 53 [3072/50176]	Loss: 4.6317
Training Epoch: 53 [4096/50176]	Loss: 4.6575
Training Epoch: 53 [5120/50176]	Loss: 4.6428
Training Epoch: 53 [6144/50176]	Loss: 4.6465
Training Epoch: 53 [7168/50176]	Loss: 4.6290
Training Epoch: 53 [8192/50176]	Loss: 4.6307
Training Epoch: 53 [9216/50176]	Loss: 4.6228
Training Epoch: 53 [10240/50176]	Loss: 4.6232
Training Epoch: 53 [11264/50176]	Loss: 4.6399
Training Epoch: 53 [12288/50176]	Loss: 4.6301
Training Epoch: 53 [13312/50176]	Loss: 4.6358
Training Epoch: 53 [14336/50176]	Loss: 4.6301
Training Epoch: 53 [15360/50176]	Loss: 4.6316
Training Epoch: 53 [16384/50176]	Loss: 4.6465
Training Epoch: 53 [17408/50176]	Loss: 4.6345
Training Epoch: 53 [18432/50176]	Loss: 4.6311
Training Epoch: 53 [19456/50176]	Loss: 4.6247
Training Epoch: 53 [20480/50176]	Loss: 4.6341
Training Epoch: 53 [21504/50176]	Loss: 4.6329
Training Epoch: 53 [22528/50176]	Loss: 4.6287
Training Epoch: 53 [23552/50176]	Loss: 4.6369
Training Epoch: 53 [24576/50176]	Loss: 4.6256
Training Epoch: 53 [25600/50176]	Loss: 4.6441
Training Epoch: 53 [26624/50176]	Loss: 4.6399
Training Epoch: 53 [27648/50176]	Loss: 4.6603
Training Epoch: 53 [28672/50176]	Loss: 4.6287
Training Epoch: 53 [29696/50176]	Loss: 4.6303
Training Epoch: 53 [30720/50176]	Loss: 4.6490
Training Epoch: 53 [31744/50176]	Loss: 4.6326
Training Epoch: 53 [32768/50176]	Loss: 4.6407
Training Epoch: 53 [33792/50176]	Loss: 4.6640
Training Epoch: 53 [34816/50176]	Loss: 4.6395
Training Epoch: 53 [35840/50176]	Loss: 4.6459
Training Epoch: 53 [36864/50176]	Loss: 4.6423
Training Epoch: 53 [37888/50176]	Loss: 4.6392
Training Epoch: 53 [38912/50176]	Loss: 4.6277
Training Epoch: 53 [39936/50176]	Loss: 4.6337
Training Epoch: 53 [40960/50176]	Loss: 4.6332
Training Epoch: 53 [41984/50176]	Loss: 4.6447
Training Epoch: 53 [43008/50176]	Loss: 4.6585
Training Epoch: 53 [44032/50176]	Loss: 4.6382
Training Epoch: 53 [45056/50176]	Loss: 4.6172
Training Epoch: 53 [46080/50176]	Loss: 4.6245
Training Epoch: 53 [47104/50176]	Loss: 4.6522
Training Epoch: 53 [48128/50176]	Loss: 4.6483
Training Epoch: 53 [49152/50176]	Loss: 4.6362
Training Epoch: 53 [50176/50176]	Loss: 4.6419
2022-12-06 20:15:04.028 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:15:04,043 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.72 energy=463.41
2022-12-06 15:15:04,043 [ZeusDataLoader(train)] Up to epoch 54: time=2583.93, energy=340278.09, cost=396232.95
2022-12-06 15:15:04,044 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:15:04,044 [ZeusDataLoader(train)] Expected next epoch: time=2630.54, energy=346644.39, cost=403494.19
2022-12-06 15:15:04,045 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 4018.8445, Accuracy: 0.0098
2022-12-06 15:15:04,265 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:15:04,266 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:15:04.268 [ZeusMonitor] Monitor started.
2022-12-06 20:15:04.268 [ZeusMonitor] Running indefinitely. 2022-12-06 20:15:04.268 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:15:04.268 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 15:15:48,023 [ZeusDataLoader(train)] train epoch 55 done: time=43.97 energy=5847.37
2022-12-06 15:15:48,027 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 4.6517
Training Epoch: 54 [2048/50176]	Loss: 4.6493
Training Epoch: 54 [3072/50176]	Loss: 4.6447
Training Epoch: 54 [4096/50176]	Loss: 4.6367
Training Epoch: 54 [5120/50176]	Loss: 4.6429
Training Epoch: 54 [6144/50176]	Loss: 4.6279
Training Epoch: 54 [7168/50176]	Loss: 4.6406
Training Epoch: 54 [8192/50176]	Loss: 4.6436
Training Epoch: 54 [9216/50176]	Loss: 4.6385
Training Epoch: 54 [10240/50176]	Loss: 4.6401
Training Epoch: 54 [11264/50176]	Loss: 4.6327
Training Epoch: 54 [12288/50176]	Loss: 4.6254
Training Epoch: 54 [13312/50176]	Loss: 4.6277
Training Epoch: 54 [14336/50176]	Loss: 4.6342
Training Epoch: 54 [15360/50176]	Loss: 4.6440
Training Epoch: 54 [16384/50176]	Loss: 4.6339
Training Epoch: 54 [17408/50176]	Loss: 4.6324
Training Epoch: 54 [18432/50176]	Loss: 4.6413
Training Epoch: 54 [19456/50176]	Loss: 4.6389
Training Epoch: 54 [20480/50176]	Loss: 4.6384
Training Epoch: 54 [21504/50176]	Loss: 4.6422
Training Epoch: 54 [22528/50176]	Loss: 4.6484
Training Epoch: 54 [23552/50176]	Loss: 4.6335
Training Epoch: 54 [24576/50176]	Loss: 4.6209
Training Epoch: 54 [25600/50176]	Loss: 4.6297
Training Epoch: 54 [26624/50176]	Loss: 4.6403
Training Epoch: 54 [27648/50176]	Loss: 4.6382
Training Epoch: 54 [28672/50176]	Loss: 4.6337
Training Epoch: 54 [29696/50176]	Loss: 4.6311
Training Epoch: 54 [30720/50176]	Loss: 4.6406
Training Epoch: 54 [31744/50176]	Loss: 4.6355
Training Epoch: 54 [32768/50176]	Loss: 4.6386
Training Epoch: 54 [33792/50176]	Loss: 4.6621
Training Epoch: 54 [34816/50176]	Loss: 4.6368
Training Epoch: 54 [35840/50176]	Loss: 4.6237
Training Epoch: 54 [36864/50176]	Loss: 4.6438
Training Epoch: 54 [37888/50176]	Loss: 4.6432
Training Epoch: 54 [38912/50176]	Loss: 4.6286
Training Epoch: 54 [39936/50176]	Loss: 4.6615
Training Epoch: 54 [40960/50176]	Loss: 4.6484
Training Epoch: 54 [41984/50176]	Loss: 4.6409
Training Epoch: 54 [43008/50176]	Loss: 4.6286
Training Epoch: 54 [44032/50176]	Loss: 4.6357
Training Epoch: 54 [45056/50176]	Loss: 4.6433
Training Epoch: 54 [46080/50176]	Loss: 4.6376
Training Epoch: 54 [47104/50176]	Loss: 4.6463
Training Epoch: 54 [48128/50176]	Loss: 4.6238
Training Epoch: 54 [49152/50176]	Loss: 4.6392
Training Epoch: 54 [50176/50176]	Loss: 4.6397
2022-12-06 20:15:51.755 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:15:51,777 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.74 energy=464.89
2022-12-06 15:15:51,777 [ZeusDataLoader(train)] Up to epoch 55: time=2631.64, energy=346590.35, cost=403564.02
2022-12-06 15:15:51,778 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:15:51,778 [ZeusDataLoader(train)] Expected next epoch: time=2678.25, energy=352956.65, cost=410825.26
2022-12-06 15:15:51,779 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 9533.3703, Accuracy: 0.0098
2022-12-06 15:15:52,021 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:15:52,022 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:15:52.023 [ZeusMonitor] Monitor started.
2022-12-06 20:15:52.024 [ZeusMonitor] Running indefinitely. 2022-12-06 20:15:52.024 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:15:52.024 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 15:16:35,727 [ZeusDataLoader(train)] train epoch 56 done: time=43.94 energy=5836.39
2022-12-06 15:16:35,730 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 4.6358
Training Epoch: 55 [2048/50176]	Loss: 4.6276
Training Epoch: 55 [3072/50176]	Loss: 4.6280
Training Epoch: 55 [4096/50176]	Loss: 4.6302
Training Epoch: 55 [5120/50176]	Loss: 4.6470
Training Epoch: 55 [6144/50176]	Loss: 4.6443
Training Epoch: 55 [7168/50176]	Loss: 4.6404
Training Epoch: 55 [8192/50176]	Loss: 4.6382
Training Epoch: 55 [9216/50176]	Loss: 4.6344
Training Epoch: 55 [10240/50176]	Loss: 4.6301
Training Epoch: 55 [11264/50176]	Loss: 4.6254
Training Epoch: 55 [12288/50176]	Loss: 4.6298
Training Epoch: 55 [13312/50176]	Loss: 4.6444
Training Epoch: 55 [14336/50176]	Loss: 4.6291
Training Epoch: 55 [15360/50176]	Loss: 4.6371
Training Epoch: 55 [16384/50176]	Loss: 4.6393
Training Epoch: 55 [17408/50176]	Loss: 4.6335
Training Epoch: 55 [18432/50176]	Loss: 4.6328
Training Epoch: 55 [19456/50176]	Loss: 4.6370
Training Epoch: 55 [20480/50176]	Loss: 4.6353
Training Epoch: 55 [21504/50176]	Loss: 4.6261
Training Epoch: 55 [22528/50176]	Loss: 4.6482
Training Epoch: 55 [23552/50176]	Loss: 4.6469
Training Epoch: 55 [24576/50176]	Loss: 4.6469
Training Epoch: 55 [25600/50176]	Loss: 4.6365
Training Epoch: 55 [26624/50176]	Loss: 4.6405
Training Epoch: 55 [27648/50176]	Loss: 4.6371
Training Epoch: 55 [28672/50176]	Loss: 4.6339
Training Epoch: 55 [29696/50176]	Loss: 4.6383
Training Epoch: 55 [30720/50176]	Loss: 4.6438
Training Epoch: 55 [31744/50176]	Loss: 4.6297
Training Epoch: 55 [32768/50176]	Loss: 4.6500
Training Epoch: 55 [33792/50176]	Loss: 4.6423
Training Epoch: 55 [34816/50176]	Loss: 4.6277
Training Epoch: 55 [35840/50176]	Loss: 4.6289
Training Epoch: 55 [36864/50176]	Loss: 4.6288
Training Epoch: 55 [37888/50176]	Loss: 4.6410
Training Epoch: 55 [38912/50176]	Loss: 4.6315
Training Epoch: 55 [39936/50176]	Loss: 4.6535
Training Epoch: 55 [40960/50176]	Loss: 4.6306
Training Epoch: 55 [41984/50176]	Loss: 4.6329
Training Epoch: 55 [43008/50176]	Loss: 4.6444
Training Epoch: 55 [44032/50176]	Loss: 4.6338
Training Epoch: 55 [45056/50176]	Loss: 4.6382
Training Epoch: 55 [46080/50176]	Loss: 4.6483
Training Epoch: 55 [47104/50176]	Loss: 4.6482
Training Epoch: 55 [48128/50176]	Loss: 4.6551
Training Epoch: 55 [49152/50176]	Loss: 4.6595
Training Epoch: 55 [50176/50176]	Loss: 4.6468
2022-12-06 20:16:39.411 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:16:39,420 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.68 energy=463.57
2022-12-06 15:16:39,420 [ZeusDataLoader(train)] Up to epoch 56: time=2679.27, energy=352890.32, cost=410881.00
2022-12-06 15:16:39,420 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:16:39,421 [ZeusDataLoader(train)] Expected next epoch: time=2725.87, energy=359256.61, cost=418142.24
2022-12-06 15:16:39,421 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:16:39,672 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:16:39,673 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:16:39.675 [ZeusMonitor] Monitor started.
2022-12-06 20:16:39.687 [ZeusMonitor] Running indefinitely. 2022-12-06 20:16:39.687 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:16:39.687 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 15:17:23,109 [ZeusDataLoader(train)] train epoch 57 done: time=43.68 energy=5825.55
2022-12-06 15:17:23,112 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 4.6395
Training Epoch: 56 [2048/50176]	Loss: 4.6461
Training Epoch: 56 [3072/50176]	Loss: 4.6352
Training Epoch: 56 [4096/50176]	Loss: 4.6422
Training Epoch: 56 [5120/50176]	Loss: 4.6496
Training Epoch: 56 [6144/50176]	Loss: 4.6429
Training Epoch: 56 [7168/50176]	Loss: 4.6411
Training Epoch: 56 [8192/50176]	Loss: 4.6306
Training Epoch: 56 [9216/50176]	Loss: 4.6390
Training Epoch: 56 [10240/50176]	Loss: 4.6412
Training Epoch: 56 [11264/50176]	Loss: 4.6323
Training Epoch: 56 [12288/50176]	Loss: 4.6312
Training Epoch: 56 [13312/50176]	Loss: 4.6330
Training Epoch: 56 [14336/50176]	Loss: 4.6234
Training Epoch: 56 [15360/50176]	Loss: 4.6308
Training Epoch: 56 [16384/50176]	Loss: 4.6348
Training Epoch: 56 [17408/50176]	Loss: 4.6452
Training Epoch: 56 [18432/50176]	Loss: 4.6370
Training Epoch: 56 [19456/50176]	Loss: 4.6414
Training Epoch: 56 [20480/50176]	Loss: 4.6392
Training Epoch: 56 [21504/50176]	Loss: 4.6346
Training Epoch: 56 [22528/50176]	Loss: 4.6353
Training Epoch: 56 [23552/50176]	Loss: 4.6292
Training Epoch: 56 [24576/50176]	Loss: 4.6465
Training Epoch: 56 [25600/50176]	Loss: 4.6541
Training Epoch: 56 [26624/50176]	Loss: 4.6441
Training Epoch: 56 [27648/50176]	Loss: 4.6368
Training Epoch: 56 [28672/50176]	Loss: 4.6532
Training Epoch: 56 [29696/50176]	Loss: 4.6360
Training Epoch: 56 [30720/50176]	Loss: 4.6262
Training Epoch: 56 [31744/50176]	Loss: 4.6288
Training Epoch: 56 [32768/50176]	Loss: 4.6362
Training Epoch: 56 [33792/50176]	Loss: 4.6361
Training Epoch: 56 [34816/50176]	Loss: 4.6329
Training Epoch: 56 [35840/50176]	Loss: 4.6469
Training Epoch: 56 [36864/50176]	Loss: 4.6361
Training Epoch: 56 [37888/50176]	Loss: 4.6342
Training Epoch: 56 [38912/50176]	Loss: 4.6225
Training Epoch: 56 [39936/50176]	Loss: 4.6153
Training Epoch: 56 [40960/50176]	Loss: 4.6334
Training Epoch: 56 [41984/50176]	Loss: 4.6438
Training Epoch: 56 [43008/50176]	Loss: 4.6366
Training Epoch: 56 [44032/50176]	Loss: 4.6223
Training Epoch: 56 [45056/50176]	Loss: 4.6385
Training Epoch: 56 [46080/50176]	Loss: 4.6381
Training Epoch: 56 [47104/50176]	Loss: 4.6477
Training Epoch: 56 [48128/50176]	Loss: 4.6247
Training Epoch: 56 [49152/50176]	Loss: 4.6339
Training Epoch: 56 [50176/50176]	Loss: 4.6364
2022-12-06 20:17:26.875 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:17:26,899 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.78 energy=485.48
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Up to epoch 57: time=2726.73, energy=359201.34, cost=418189.15
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Expected next epoch: time=2773.33, energy=365567.64, cost=425450.39
2022-12-06 15:17:26,900 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 2229.0759, Accuracy: 0.0098
2022-12-06 15:17:27,095 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:17:27,096 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:17:27.097 [ZeusMonitor] Monitor started.
2022-12-06 20:17:27.097 [ZeusMonitor] Running indefinitely. 2022-12-06 20:17:27.097 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:17:27.097 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 15:18:10,782 [ZeusDataLoader(train)] train epoch 58 done: time=43.87 energy=5847.04
2022-12-06 15:18:10,786 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 4.6408
Training Epoch: 57 [2048/50176]	Loss: 4.6418
Training Epoch: 57 [3072/50176]	Loss: 4.6294
Training Epoch: 57 [4096/50176]	Loss: 4.6408
Training Epoch: 57 [5120/50176]	Loss: 4.6359
Training Epoch: 57 [6144/50176]	Loss: 4.6457
Training Epoch: 57 [7168/50176]	Loss: 4.6340
Training Epoch: 57 [8192/50176]	Loss: 4.6579
Training Epoch: 57 [9216/50176]	Loss: 4.6469
Training Epoch: 57 [10240/50176]	Loss: 4.6494
Training Epoch: 57 [11264/50176]	Loss: 4.6263
Training Epoch: 57 [12288/50176]	Loss: 4.6347
Training Epoch: 57 [13312/50176]	Loss: 4.6228
Training Epoch: 57 [14336/50176]	Loss: 4.6597
Training Epoch: 57 [15360/50176]	Loss: 4.6472
Training Epoch: 57 [16384/50176]	Loss: 4.6406
Training Epoch: 57 [17408/50176]	Loss: 4.6396
Training Epoch: 57 [18432/50176]	Loss: 4.6416
Training Epoch: 57 [19456/50176]	Loss: 4.6305
Training Epoch: 57 [20480/50176]	Loss: 4.6453
Training Epoch: 57 [21504/50176]	Loss: 4.6407
Training Epoch: 57 [22528/50176]	Loss: 4.6374
Training Epoch: 57 [23552/50176]	Loss: 4.6357
Training Epoch: 57 [24576/50176]	Loss: 4.6487
Training Epoch: 57 [25600/50176]	Loss: 4.6287
Training Epoch: 57 [26624/50176]	Loss: 4.6467
Training Epoch: 57 [27648/50176]	Loss: 4.6666
Training Epoch: 57 [28672/50176]	Loss: 4.6446
Training Epoch: 57 [29696/50176]	Loss: 4.6239
Training Epoch: 57 [30720/50176]	Loss: 4.6422
Training Epoch: 57 [31744/50176]	Loss: 4.6483
Training Epoch: 57 [32768/50176]	Loss: 4.6318
Training Epoch: 57 [33792/50176]	Loss: 4.6363
Training Epoch: 57 [34816/50176]	Loss: 4.6299
Training Epoch: 57 [35840/50176]	Loss: 4.6387
Training Epoch: 57 [36864/50176]	Loss: 4.6384
Training Epoch: 57 [37888/50176]	Loss: 4.6473
Training Epoch: 57 [38912/50176]	Loss: 4.6442
Training Epoch: 57 [39936/50176]	Loss: 4.6279
Training Epoch: 57 [40960/50176]	Loss: 4.6497
Training Epoch: 57 [41984/50176]	Loss: 4.6335
Training Epoch: 57 [43008/50176]	Loss: 4.6250
Training Epoch: 57 [44032/50176]	Loss: 4.6294
Training Epoch: 57 [45056/50176]	Loss: 4.6286
Training Epoch: 57 [46080/50176]	Loss: 4.6311
Training Epoch: 57 [47104/50176]	Loss: 4.6496
Training Epoch: 57 [48128/50176]	Loss: 4.6283
Training Epoch: 57 [49152/50176]	Loss: 4.6364
Training Epoch: 57 [50176/50176]	Loss: 4.6313
2022-12-06 20:18:14.541 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:18:14,588 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.79 energy=476.68
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Up to epoch 58: time=2774.39, energy=365525.06, cost=425522.00
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Expected next epoch: time=2821.00, energy=371891.36, cost=432783.24
2022-12-06 15:18:14,589 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:18:14,769 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:18:14,770 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:18:14.773 [ZeusMonitor] Monitor started.
2022-12-06 20:18:14.774 [ZeusMonitor] Running indefinitely. 2022-12-06 20:18:14.774 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:18:14.774 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 15:18:58,467 [ZeusDataLoader(train)] train epoch 59 done: time=43.87 energy=5845.17
2022-12-06 15:18:58,471 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 4.6312
Training Epoch: 58 [2048/50176]	Loss: 4.6241
Training Epoch: 58 [3072/50176]	Loss: 4.6415
Training Epoch: 58 [4096/50176]	Loss: 4.6473
Training Epoch: 58 [5120/50176]	Loss: 4.6270
Training Epoch: 58 [6144/50176]	Loss: 4.6447
Training Epoch: 58 [7168/50176]	Loss: 4.6385
Training Epoch: 58 [8192/50176]	Loss: 4.6295
Training Epoch: 58 [9216/50176]	Loss: 4.6242
Training Epoch: 58 [10240/50176]	Loss: 4.6460
Training Epoch: 58 [11264/50176]	Loss: 4.6384
Training Epoch: 58 [12288/50176]	Loss: 4.6253
Training Epoch: 58 [13312/50176]	Loss: 4.6311
Training Epoch: 58 [14336/50176]	Loss: 4.6320
Training Epoch: 58 [15360/50176]	Loss: 4.6251
Training Epoch: 58 [16384/50176]	Loss: 4.6503
Training Epoch: 58 [17408/50176]	Loss: 4.6413
Training Epoch: 58 [18432/50176]	Loss: 4.6280
Training Epoch: 58 [19456/50176]	Loss: 4.6457
Training Epoch: 58 [20480/50176]	Loss: 4.6325
Training Epoch: 58 [21504/50176]	Loss: 4.6239
Training Epoch: 58 [22528/50176]	Loss: 4.6320
Training Epoch: 58 [23552/50176]	Loss: 4.6440
Training Epoch: 58 [24576/50176]	Loss: 4.6442
Training Epoch: 58 [25600/50176]	Loss: 4.6379
Training Epoch: 58 [26624/50176]	Loss: 4.6150
Training Epoch: 58 [27648/50176]	Loss: 4.6364
Training Epoch: 58 [28672/50176]	Loss: 4.6324
Training Epoch: 58 [29696/50176]	Loss: 4.6417
Training Epoch: 58 [30720/50176]	Loss: 4.6366
Training Epoch: 58 [31744/50176]	Loss: 4.6282
Training Epoch: 58 [32768/50176]	Loss: 4.6327
Training Epoch: 58 [33792/50176]	Loss: 4.6253
Training Epoch: 58 [34816/50176]	Loss: 4.6282
Training Epoch: 58 [35840/50176]	Loss: 4.6486
Training Epoch: 58 [36864/50176]	Loss: 4.6465
Training Epoch: 58 [37888/50176]	Loss: 4.6438
Training Epoch: 58 [38912/50176]	Loss: 4.6306
Training Epoch: 58 [39936/50176]	Loss: 4.6254
Training Epoch: 58 [40960/50176]	Loss: 4.6349
Training Epoch: 58 [41984/50176]	Loss: 4.6442
Training Epoch: 58 [43008/50176]	Loss: 4.6386
Training Epoch: 58 [44032/50176]	Loss: 4.6414
Training Epoch: 58 [45056/50176]	Loss: 4.6388
Training Epoch: 58 [46080/50176]	Loss: 4.6284
Training Epoch: 58 [47104/50176]	Loss: 4.6370
Training Epoch: 58 [48128/50176]	Loss: 4.6364
Training Epoch: 58 [49152/50176]	Loss: 4.6355
Training Epoch: 58 [50176/50176]	Loss: 4.6390
2022-12-06 20:19:02.228 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:19:02,258 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.78 energy=479.90
2022-12-06 15:19:02,258 [ZeusDataLoader(train)] Up to epoch 59: time=2822.04, energy=371850.13, cost=432853.84
2022-12-06 15:19:02,258 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:19:02,259 [ZeusDataLoader(train)] Expected next epoch: time=2868.65, energy=378216.43, cost=440115.08
2022-12-06 15:19:02,260 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 96.4861, Accuracy: 0.0098
2022-12-06 15:19:02,508 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:19:02,508 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:19:02.510 [ZeusMonitor] Monitor started.
2022-12-06 20:19:02.510 [ZeusMonitor] Running indefinitely. 2022-12-06 20:19:02.510 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:19:02.510 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 15:19:45,931 [ZeusDataLoader(train)] train epoch 60 done: time=43.66 energy=5821.24
2022-12-06 15:19:45,934 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 4.6252
Training Epoch: 59 [2048/50176]	Loss: 4.6430
Training Epoch: 59 [3072/50176]	Loss: 4.6383
Training Epoch: 59 [4096/50176]	Loss: 4.6363
Training Epoch: 59 [5120/50176]	Loss: 4.6296
Training Epoch: 59 [6144/50176]	Loss: 4.6294
Training Epoch: 59 [7168/50176]	Loss: 4.6362
Training Epoch: 59 [8192/50176]	Loss: 4.6375
Training Epoch: 59 [9216/50176]	Loss: 4.6366
Training Epoch: 59 [10240/50176]	Loss: 4.6441
Training Epoch: 59 [11264/50176]	Loss: 4.6314
Training Epoch: 59 [12288/50176]	Loss: 4.6417
Training Epoch: 59 [13312/50176]	Loss: 4.6329
Training Epoch: 59 [14336/50176]	Loss: 4.6427
Training Epoch: 59 [15360/50176]	Loss: 4.6538
Training Epoch: 59 [16384/50176]	Loss: 4.6325
Training Epoch: 59 [17408/50176]	Loss: 4.6309
Training Epoch: 59 [18432/50176]	Loss: 4.6453
Training Epoch: 59 [19456/50176]	Loss: 4.6564
Training Epoch: 59 [20480/50176]	Loss: 4.6408
Training Epoch: 59 [21504/50176]	Loss: 4.6237
Training Epoch: 59 [22528/50176]	Loss: 4.6387
Training Epoch: 59 [23552/50176]	Loss: 4.6389
Training Epoch: 59 [24576/50176]	Loss: 4.6370
Training Epoch: 59 [25600/50176]	Loss: 4.6350
Training Epoch: 59 [26624/50176]	Loss: 4.6394
Training Epoch: 59 [27648/50176]	Loss: 4.6381
Training Epoch: 59 [28672/50176]	Loss: 4.6227
Training Epoch: 59 [29696/50176]	Loss: 4.6461
Training Epoch: 59 [30720/50176]	Loss: 4.6514
Training Epoch: 59 [31744/50176]	Loss: 4.6465
Training Epoch: 59 [32768/50176]	Loss: 4.6279
Training Epoch: 59 [33792/50176]	Loss: 4.6376
Training Epoch: 59 [34816/50176]	Loss: 4.6557
Training Epoch: 59 [35840/50176]	Loss: 4.6577
Training Epoch: 59 [36864/50176]	Loss: 4.6401
Training Epoch: 59 [37888/50176]	Loss: 4.6485
Training Epoch: 59 [38912/50176]	Loss: 4.6411
Training Epoch: 59 [39936/50176]	Loss: 4.6450
Training Epoch: 59 [40960/50176]	Loss: 4.6587
Training Epoch: 59 [41984/50176]	Loss: 4.6531
Training Epoch: 59 [43008/50176]	Loss: 4.6617
Training Epoch: 59 [44032/50176]	Loss: 4.6536
Training Epoch: 59 [45056/50176]	Loss: 4.6443
Training Epoch: 59 [46080/50176]	Loss: 4.6273
Training Epoch: 59 [47104/50176]	Loss: 4.6447
Training Epoch: 59 [48128/50176]	Loss: 4.6404
Training Epoch: 59 [49152/50176]	Loss: 4.6519
Training Epoch: 59 [50176/50176]	Loss: 4.6362
2022-12-06 20:19:49.655 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:19:49,677 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.73 energy=461.63
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Up to epoch 60: time=2869.44, energy=378133.01, cost=440142.59
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Expected next epoch: time=2916.05, energy=384499.31, cost=447403.82
2022-12-06 15:19:49,678 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:19:49,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:19:49,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:19:49.912 [ZeusMonitor] Monitor started.
2022-12-06 20:19:49.912 [ZeusMonitor] Running indefinitely. 2022-12-06 20:19:49.912 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:19:49.912 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 15:20:33,542 [ZeusDataLoader(train)] train epoch 61 done: time=43.86 energy=5837.68
2022-12-06 15:20:33,546 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 4.6224
Training Epoch: 60 [2048/50176]	Loss: 4.6470
Training Epoch: 60 [3072/50176]	Loss: 4.6521
Training Epoch: 60 [4096/50176]	Loss: 4.6309
Training Epoch: 60 [5120/50176]	Loss: 4.6411
Training Epoch: 60 [6144/50176]	Loss: 4.6544
Training Epoch: 60 [7168/50176]	Loss: 4.6501
Training Epoch: 60 [8192/50176]	Loss: 4.6283
Training Epoch: 60 [9216/50176]	Loss: 4.6206
Training Epoch: 60 [10240/50176]	Loss: 4.6311
Training Epoch: 60 [11264/50176]	Loss: 4.6272
Training Epoch: 60 [12288/50176]	Loss: 4.6270
Training Epoch: 60 [13312/50176]	Loss: 4.6372
Training Epoch: 60 [14336/50176]	Loss: 4.6520
Training Epoch: 60 [15360/50176]	Loss: 4.6366
Training Epoch: 60 [16384/50176]	Loss: 4.6434
Training Epoch: 60 [17408/50176]	Loss: 4.6309
Training Epoch: 60 [18432/50176]	Loss: 4.6251
Training Epoch: 60 [19456/50176]	Loss: 4.6486
Training Epoch: 60 [20480/50176]	Loss: 4.6457
Training Epoch: 60 [21504/50176]	Loss: 4.6234
Training Epoch: 60 [22528/50176]	Loss: 4.6320
Training Epoch: 60 [23552/50176]	Loss: 4.6559
Training Epoch: 60 [24576/50176]	Loss: 4.6433
Training Epoch: 60 [25600/50176]	Loss: 4.6324
Training Epoch: 60 [26624/50176]	Loss: 4.6469
Training Epoch: 60 [27648/50176]	Loss: 4.6253
Training Epoch: 60 [28672/50176]	Loss: 4.6331
Training Epoch: 60 [29696/50176]	Loss: 4.6316
Training Epoch: 60 [30720/50176]	Loss: 4.6406
Training Epoch: 60 [31744/50176]	Loss: 4.6336
Training Epoch: 60 [32768/50176]	Loss: 4.6564
Training Epoch: 60 [33792/50176]	Loss: 4.6343
Training Epoch: 60 [34816/50176]	Loss: 4.6304
Training Epoch: 60 [35840/50176]	Loss: 4.6339
Training Epoch: 60 [36864/50176]	Loss: 4.6384
Training Epoch: 60 [37888/50176]	Loss: 4.6391
Training Epoch: 60 [38912/50176]	Loss: 4.6325
Training Epoch: 60 [39936/50176]	Loss: 4.6390
Training Epoch: 60 [40960/50176]	Loss: 4.6458
Training Epoch: 60 [41984/50176]	Loss: 4.6572
Training Epoch: 60 [43008/50176]	Loss: 4.6406
Training Epoch: 60 [44032/50176]	Loss: 4.6349
Training Epoch: 60 [45056/50176]	Loss: 4.6287
Training Epoch: 60 [46080/50176]	Loss: 4.6244
Training Epoch: 60 [47104/50176]	Loss: 4.6355
Training Epoch: 60 [48128/50176]	Loss: 4.6389
Training Epoch: 60 [49152/50176]	Loss: 4.6449
Training Epoch: 60 [50176/50176]	Loss: 4.6320
2022-12-06 20:20:37.283 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:20:37,307 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.75 energy=462.44
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Up to epoch 61: time=2917.05, energy=384433.13, cost=447458.41
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Expected next epoch: time=2963.66, energy=390799.42, cost=454719.65
2022-12-06 15:20:37,308 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0045, Accuracy: 0.0097
2022-12-06 15:20:37,550 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:20:37,551 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:20:37.565 [ZeusMonitor] Monitor started.
2022-12-06 20:20:37.565 [ZeusMonitor] Running indefinitely. 2022-12-06 20:20:37.565 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:20:37.565 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 15:21:21,118 [ZeusDataLoader(train)] train epoch 62 done: time=43.80 energy=5834.15
2022-12-06 15:21:21,121 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 4.6318
Training Epoch: 61 [2048/50176]	Loss: 4.6215
Training Epoch: 61 [3072/50176]	Loss: 4.6324
Training Epoch: 61 [4096/50176]	Loss: 4.6290
Training Epoch: 61 [5120/50176]	Loss: 4.6318
Training Epoch: 61 [6144/50176]	Loss: 4.6310
Training Epoch: 61 [7168/50176]	Loss: 4.6318
Training Epoch: 61 [8192/50176]	Loss: 4.6278
Training Epoch: 61 [9216/50176]	Loss: 4.6344
Training Epoch: 61 [10240/50176]	Loss: 4.6406
Training Epoch: 61 [11264/50176]	Loss: 4.6280
Training Epoch: 61 [12288/50176]	Loss: 4.6234
Training Epoch: 61 [13312/50176]	Loss: 4.6471
Training Epoch: 61 [14336/50176]	Loss: 4.6445
Training Epoch: 61 [15360/50176]	Loss: 4.6252
Training Epoch: 61 [16384/50176]	Loss: 4.6310
Training Epoch: 61 [17408/50176]	Loss: 4.6362
Training Epoch: 61 [18432/50176]	Loss: 4.6451
Training Epoch: 61 [19456/50176]	Loss: 4.6274
Training Epoch: 61 [20480/50176]	Loss: 4.6496
Training Epoch: 61 [21504/50176]	Loss: 4.6371
Training Epoch: 61 [22528/50176]	Loss: 4.6401
Training Epoch: 61 [23552/50176]	Loss: 4.6321
Training Epoch: 61 [24576/50176]	Loss: 4.6265
Training Epoch: 61 [25600/50176]	Loss: 4.6456
Training Epoch: 61 [26624/50176]	Loss: 4.6211
Training Epoch: 61 [27648/50176]	Loss: 4.6257
Training Epoch: 61 [28672/50176]	Loss: 4.6319
Training Epoch: 61 [29696/50176]	Loss: 4.6410
Training Epoch: 61 [30720/50176]	Loss: 4.6304
Training Epoch: 61 [31744/50176]	Loss: 4.6490
Training Epoch: 61 [32768/50176]	Loss: 4.6411
Training Epoch: 61 [33792/50176]	Loss: 4.6308
Training Epoch: 61 [34816/50176]	Loss: 4.6364
Training Epoch: 61 [35840/50176]	Loss: 4.6443
Training Epoch: 61 [36864/50176]	Loss: 4.6303
Training Epoch: 61 [37888/50176]	Loss: 4.6363
Training Epoch: 61 [38912/50176]	Loss: 4.6497
Training Epoch: 61 [39936/50176]	Loss: 4.6408
Training Epoch: 61 [40960/50176]	Loss: 4.6320
Training Epoch: 61 [41984/50176]	Loss: 4.6221
Training Epoch: 61 [43008/50176]	Loss: 4.6286
Training Epoch: 61 [44032/50176]	Loss: 4.6380
Training Epoch: 61 [45056/50176]	Loss: 4.6407
Training Epoch: 61 [46080/50176]	Loss: 4.6526
Training Epoch: 61 [47104/50176]	Loss: 4.6408
Training Epoch: 61 [48128/50176]	Loss: 4.6451
Training Epoch: 61 [49152/50176]	Loss: 4.6576
Training Epoch: 61 [50176/50176]	Loss: 4.6318
2022-12-06 20:21:24.998 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:21:25,036 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.91 energy=487.06
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Up to epoch 62: time=2964.76, energy=390754.33, cost=454793.44
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Expected next epoch: time=3011.36, energy=397120.63, cost=462054.67
2022-12-06 15:21:25,037 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 1057.8528, Accuracy: 0.0098
2022-12-06 15:21:25,299 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:21:25,299 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:21:25.301 [ZeusMonitor] Monitor started.
2022-12-06 20:21:25.301 [ZeusMonitor] Running indefinitely. 2022-12-06 20:21:25.301 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:21:25.301 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 15:22:08,865 [ZeusDataLoader(train)] train epoch 63 done: time=43.82 energy=5833.88
2022-12-06 15:22:08,868 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 4.6296
Training Epoch: 62 [2048/50176]	Loss: 4.6162
Training Epoch: 62 [3072/50176]	Loss: 4.6396
Training Epoch: 62 [4096/50176]	Loss: 4.6422
Training Epoch: 62 [5120/50176]	Loss: 4.6407
Training Epoch: 62 [6144/50176]	Loss: 4.6618
Training Epoch: 62 [7168/50176]	Loss: 4.6358
Training Epoch: 62 [8192/50176]	Loss: 4.6460
Training Epoch: 62 [9216/50176]	Loss: 4.6342
Training Epoch: 62 [10240/50176]	Loss: 4.6223
Training Epoch: 62 [11264/50176]	Loss: 4.6221
Training Epoch: 62 [12288/50176]	Loss: 4.6522
Training Epoch: 62 [13312/50176]	Loss: 4.6469
Training Epoch: 62 [14336/50176]	Loss: 4.6491
Training Epoch: 62 [15360/50176]	Loss: 4.6509
Training Epoch: 62 [16384/50176]	Loss: 4.6447
Training Epoch: 62 [17408/50176]	Loss: 4.6169
Training Epoch: 62 [18432/50176]	Loss: 4.6281
Training Epoch: 62 [19456/50176]	Loss: 4.6447
Training Epoch: 62 [20480/50176]	Loss: 4.6448
Training Epoch: 62 [21504/50176]	Loss: 4.6512
Training Epoch: 62 [22528/50176]	Loss: 4.6274
Training Epoch: 62 [23552/50176]	Loss: 4.6527
Training Epoch: 62 [24576/50176]	Loss: 4.6421
Training Epoch: 62 [25600/50176]	Loss: 4.6339
Training Epoch: 62 [26624/50176]	Loss: 4.6268
Training Epoch: 62 [27648/50176]	Loss: 4.6401
Training Epoch: 62 [28672/50176]	Loss: 4.6174
Training Epoch: 62 [29696/50176]	Loss: 4.6446
Training Epoch: 62 [30720/50176]	Loss: 4.6459
Training Epoch: 62 [31744/50176]	Loss: 4.6395
Training Epoch: 62 [32768/50176]	Loss: 4.6470
Training Epoch: 62 [33792/50176]	Loss: 4.6392
Training Epoch: 62 [34816/50176]	Loss: 4.6357
Training Epoch: 62 [35840/50176]	Loss: 4.6148
Training Epoch: 62 [36864/50176]	Loss: 4.6394
Training Epoch: 62 [37888/50176]	Loss: 4.6280
Training Epoch: 62 [38912/50176]	Loss: 4.6495
Training Epoch: 62 [39936/50176]	Loss: 4.6497
Training Epoch: 62 [40960/50176]	Loss: 4.6442
Training Epoch: 62 [41984/50176]	Loss: 4.6281
Training Epoch: 62 [43008/50176]	Loss: 4.6377
Training Epoch: 62 [44032/50176]	Loss: 4.6278
Training Epoch: 62 [45056/50176]	Loss: 4.6456
Training Epoch: 62 [46080/50176]	Loss: 4.6356
Training Epoch: 62 [47104/50176]	Loss: 4.6369
Training Epoch: 62 [48128/50176]	Loss: 4.6265
Training Epoch: 62 [49152/50176]	Loss: 4.6459
Training Epoch: 62 [50176/50176]	Loss: 4.6417
2022-12-06 20:22:12.734 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:22:12,790 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.91 energy=494.50
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Up to epoch 63: time=3012.49, energy=397082.71, cost=462134.31
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Expected next epoch: time=3059.10, energy=403449.00, cost=469395.54
2022-12-06 15:22:12,791 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 3924.0224, Accuracy: 0.0098
2022-12-06 15:22:13,034 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:22:13,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:22:13.036 [ZeusMonitor] Monitor started.
2022-12-06 20:22:13.036 [ZeusMonitor] Running indefinitely. 2022-12-06 20:22:13.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:22:13.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 15:22:56,694 [ZeusDataLoader(train)] train epoch 64 done: time=43.89 energy=5837.27
2022-12-06 15:22:56,697 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 4.6398
Training Epoch: 63 [2048/50176]	Loss: 4.6248
Training Epoch: 63 [3072/50176]	Loss: 4.6484
Training Epoch: 63 [4096/50176]	Loss: 4.6495
Training Epoch: 63 [5120/50176]	Loss: 4.6339
Training Epoch: 63 [6144/50176]	Loss: 4.6396
Training Epoch: 63 [7168/50176]	Loss: 4.6428
Training Epoch: 63 [8192/50176]	Loss: 4.6281
Training Epoch: 63 [9216/50176]	Loss: 4.6391
Training Epoch: 63 [10240/50176]	Loss: 4.6422
Training Epoch: 63 [11264/50176]	Loss: 4.6321
Training Epoch: 63 [12288/50176]	Loss: 4.6380
Training Epoch: 63 [13312/50176]	Loss: 4.6523
Training Epoch: 63 [14336/50176]	Loss: 4.6451
Training Epoch: 63 [15360/50176]	Loss: 4.6227
Training Epoch: 63 [16384/50176]	Loss: 4.6345
Training Epoch: 63 [17408/50176]	Loss: 4.6380
Training Epoch: 63 [18432/50176]	Loss: 4.6304
Training Epoch: 63 [19456/50176]	Loss: 4.6443
Training Epoch: 63 [20480/50176]	Loss: 4.6406
Training Epoch: 63 [21504/50176]	Loss: 4.6360
Training Epoch: 63 [22528/50176]	Loss: 4.6401
Training Epoch: 63 [23552/50176]	Loss: 4.6380
Training Epoch: 63 [24576/50176]	Loss: 4.6445
Training Epoch: 63 [25600/50176]	Loss: 4.6294
Training Epoch: 63 [26624/50176]	Loss: 4.6380
Training Epoch: 63 [27648/50176]	Loss: 4.6355
Training Epoch: 63 [28672/50176]	Loss: 4.6417
Training Epoch: 63 [29696/50176]	Loss: 4.6418
Training Epoch: 63 [30720/50176]	Loss: 4.6271
Training Epoch: 63 [31744/50176]	Loss: 4.6284
Training Epoch: 63 [32768/50176]	Loss: 4.6328
Training Epoch: 63 [33792/50176]	Loss: 4.6518
Training Epoch: 63 [34816/50176]	Loss: 4.6503
Training Epoch: 63 [35840/50176]	Loss: 4.6197
Training Epoch: 63 [36864/50176]	Loss: 4.6346
Training Epoch: 63 [37888/50176]	Loss: 4.6435
Training Epoch: 63 [38912/50176]	Loss: 4.6231
Training Epoch: 63 [39936/50176]	Loss: 4.6439
Training Epoch: 63 [40960/50176]	Loss: 4.6411
Training Epoch: 63 [41984/50176]	Loss: 4.6507
Training Epoch: 63 [43008/50176]	Loss: 4.6522
Training Epoch: 63 [44032/50176]	Loss: 4.6331
Training Epoch: 63 [45056/50176]	Loss: 4.6253
Training Epoch: 63 [46080/50176]	Loss: 4.6234
Training Epoch: 63 [47104/50176]	Loss: 4.6298
Training Epoch: 63 [48128/50176]	Loss: 4.6344
Training Epoch: 63 [49152/50176]	Loss: 4.6486
Training Epoch: 63 [50176/50176]	Loss: 4.6267
2022-12-06 20:23:00.403 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:23:00,413 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.71 energy=466.32
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Up to epoch 64: time=3060.09, energy=403386.30, cost=469451.35
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Expected next epoch: time=3106.70, energy=409752.59, cost=476712.58
2022-12-06 15:23:00,414 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 14420.2416, Accuracy: 0.0098
2022-12-06 15:23:00,615 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:23:00,616 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:23:00.619 [ZeusMonitor] Monitor started.
2022-12-06 20:23:00.619 [ZeusMonitor] Running indefinitely. 2022-12-06 20:23:00.619 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:23:00.619 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 15:23:44,183 [ZeusDataLoader(train)] train epoch 65 done: time=43.76 energy=5829.75
2022-12-06 15:23:44,186 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 4.6296
Training Epoch: 64 [2048/50176]	Loss: 4.6346
Training Epoch: 64 [3072/50176]	Loss: 4.6303
Training Epoch: 64 [4096/50176]	Loss: 4.6462
Training Epoch: 64 [5120/50176]	Loss: 4.6388
Training Epoch: 64 [6144/50176]	Loss: 4.6404
Training Epoch: 64 [7168/50176]	Loss: 4.6297
Training Epoch: 64 [8192/50176]	Loss: 4.6364
Training Epoch: 64 [9216/50176]	Loss: 4.6376
Training Epoch: 64 [10240/50176]	Loss: 4.6378
Training Epoch: 64 [11264/50176]	Loss: 4.6401
Training Epoch: 64 [12288/50176]	Loss: 4.6381
Training Epoch: 64 [13312/50176]	Loss: 4.6228
Training Epoch: 64 [14336/50176]	Loss: 4.6292
Training Epoch: 64 [15360/50176]	Loss: 4.6324
Training Epoch: 64 [16384/50176]	Loss: 4.6433
Training Epoch: 64 [17408/50176]	Loss: 4.6309
Training Epoch: 64 [18432/50176]	Loss: 4.6402
Training Epoch: 64 [19456/50176]	Loss: 4.6110
Training Epoch: 64 [20480/50176]	Loss: 4.6584
Training Epoch: 64 [21504/50176]	Loss: 4.6409
Training Epoch: 64 [22528/50176]	Loss: 4.6273
Training Epoch: 64 [23552/50176]	Loss: 4.6347
Training Epoch: 64 [24576/50176]	Loss: 4.6331
Training Epoch: 64 [25600/50176]	Loss: 4.6311
Training Epoch: 64 [26624/50176]	Loss: 4.6441
Training Epoch: 64 [27648/50176]	Loss: 4.6351
Training Epoch: 64 [28672/50176]	Loss: 4.6352
Training Epoch: 64 [29696/50176]	Loss: 4.6576
Training Epoch: 64 [30720/50176]	Loss: 4.6427
Training Epoch: 64 [31744/50176]	Loss: 4.6229
Training Epoch: 64 [32768/50176]	Loss: 4.6248
Training Epoch: 64 [33792/50176]	Loss: 4.6500
Training Epoch: 64 [34816/50176]	Loss: 4.6417
Training Epoch: 64 [35840/50176]	Loss: 4.6397
Training Epoch: 64 [36864/50176]	Loss: 4.6382
Training Epoch: 64 [37888/50176]	Loss: 4.6367
Training Epoch: 64 [38912/50176]	Loss: 4.6370
Training Epoch: 64 [39936/50176]	Loss: 4.6251
Training Epoch: 64 [40960/50176]	Loss: 4.6304
Training Epoch: 64 [41984/50176]	Loss: 4.6343
Training Epoch: 64 [43008/50176]	Loss: 4.6377
Training Epoch: 64 [44032/50176]	Loss: 4.6581
Training Epoch: 64 [45056/50176]	Loss: 4.6331
Training Epoch: 64 [46080/50176]	Loss: 4.6401
Training Epoch: 64 [47104/50176]	Loss: 4.6319
Training Epoch: 64 [48128/50176]	Loss: 4.6314
Training Epoch: 64 [49152/50176]	Loss: 4.6279
Training Epoch: 64 [50176/50176]	Loss: 4.6415
2022-12-06 20:23:47.889 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:23:47,924 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.73 energy=468.00
2022-12-06 15:23:47,924 [ZeusDataLoader(train)] Up to epoch 65: time=3107.59, energy=409684.05, cost=476755.74
2022-12-06 15:23:47,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:23:47,925 [ZeusDataLoader(train)] Expected next epoch: time=3154.19, energy=416050.34, cost=484016.98
2022-12-06 15:23:47,926 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 1409.7685, Accuracy: 0.0098
2022-12-06 15:23:48,176 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:23:48,177 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:23:48.178 [ZeusMonitor] Monitor started.
2022-12-06 20:23:48.178 [ZeusMonitor] Running indefinitely. 2022-12-06 20:23:48.178 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:23:48.178 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 15:24:31,681 [ZeusDataLoader(train)] train epoch 66 done: time=43.75 energy=5822.31
2022-12-06 15:24:31,684 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 4.6285
Training Epoch: 65 [2048/50176]	Loss: 4.6323
Training Epoch: 65 [3072/50176]	Loss: 4.6421
Training Epoch: 65 [4096/50176]	Loss: 4.6406
Training Epoch: 65 [5120/50176]	Loss: 4.6396
Training Epoch: 65 [6144/50176]	Loss: 4.6263
Training Epoch: 65 [7168/50176]	Loss: 4.6284
Training Epoch: 65 [8192/50176]	Loss: 4.6327
Training Epoch: 65 [9216/50176]	Loss: 4.6455
Training Epoch: 65 [10240/50176]	Loss: 4.6376
Training Epoch: 65 [11264/50176]	Loss: 4.6412
Training Epoch: 65 [12288/50176]	Loss: 4.6478
Training Epoch: 65 [13312/50176]	Loss: 4.6380
Training Epoch: 65 [14336/50176]	Loss: 4.6345
Training Epoch: 65 [15360/50176]	Loss: 4.6351
Training Epoch: 65 [16384/50176]	Loss: 4.6366
Training Epoch: 65 [17408/50176]	Loss: 4.6408
Training Epoch: 65 [18432/50176]	Loss: 4.6292
Training Epoch: 65 [19456/50176]	Loss: 4.6485
Training Epoch: 65 [20480/50176]	Loss: 4.6161
Training Epoch: 65 [21504/50176]	Loss: 4.6429
Training Epoch: 65 [22528/50176]	Loss: 4.6325
Training Epoch: 65 [23552/50176]	Loss: 4.6427
Training Epoch: 65 [24576/50176]	Loss: 4.6366
Training Epoch: 65 [25600/50176]	Loss: 4.6314
Training Epoch: 65 [26624/50176]	Loss: 4.6352
Training Epoch: 65 [27648/50176]	Loss: 4.6367
Training Epoch: 65 [28672/50176]	Loss: 4.6248
Training Epoch: 65 [29696/50176]	Loss: 4.6273
Training Epoch: 65 [30720/50176]	Loss: 4.6503
Training Epoch: 65 [31744/50176]	Loss: 4.6282
Training Epoch: 65 [32768/50176]	Loss: 4.6468
Training Epoch: 65 [33792/50176]	Loss: 4.6416
Training Epoch: 65 [34816/50176]	Loss: 4.6528
Training Epoch: 65 [35840/50176]	Loss: 4.6403
Training Epoch: 65 [36864/50176]	Loss: 4.6332
Training Epoch: 65 [37888/50176]	Loss: 4.6146
Training Epoch: 65 [38912/50176]	Loss: 4.6350
Training Epoch: 65 [39936/50176]	Loss: 4.6429
Training Epoch: 65 [40960/50176]	Loss: 4.6434
Training Epoch: 65 [41984/50176]	Loss: 4.6389
Training Epoch: 65 [43008/50176]	Loss: 4.6343
Training Epoch: 65 [44032/50176]	Loss: 4.6180
Training Epoch: 65 [45056/50176]	Loss: 4.6379
Training Epoch: 65 [46080/50176]	Loss: 4.6445
Training Epoch: 65 [47104/50176]	Loss: 4.6378
Training Epoch: 65 [48128/50176]	Loss: 4.6513
Training Epoch: 65 [49152/50176]	Loss: 4.6477
Training Epoch: 65 [50176/50176]	Loss: 4.6287
2022-12-06 20:24:35.395 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:24:35,411 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.72 energy=462.70
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Up to epoch 66: time=3155.05, energy=415969.06, cost=484051.57
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Expected next epoch: time=3201.66, energy=422335.35, cost=491312.80
2022-12-06 15:24:35,413 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 71545.0193, Accuracy: 0.0098
2022-12-06 15:24:35,607 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:24:35,608 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:24:35.611 [ZeusMonitor] Monitor started.
2022-12-06 20:24:35.611 [ZeusMonitor] Running indefinitely. 2022-12-06 20:24:35.611 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:24:35.611 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 15:25:19,393 [ZeusDataLoader(train)] train epoch 67 done: time=43.97 energy=5839.62
2022-12-06 15:25:19,396 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 4.6403
Training Epoch: 66 [2048/50176]	Loss: 4.6362
Training Epoch: 66 [3072/50176]	Loss: 4.6333
Training Epoch: 66 [4096/50176]	Loss: 4.6442
Training Epoch: 66 [5120/50176]	Loss: 4.6377
Training Epoch: 66 [6144/50176]	Loss: 4.6362
Training Epoch: 66 [7168/50176]	Loss: 4.6408
Training Epoch: 66 [8192/50176]	Loss: 4.6543
Training Epoch: 66 [9216/50176]	Loss: 4.6425
Training Epoch: 66 [10240/50176]	Loss: 4.6355
Training Epoch: 66 [11264/50176]	Loss: 4.6321
Training Epoch: 66 [12288/50176]	Loss: 4.6477
Training Epoch: 66 [13312/50176]	Loss: 4.6395
Training Epoch: 66 [14336/50176]	Loss: 4.6499
Training Epoch: 66 [15360/50176]	Loss: 4.6406
Training Epoch: 66 [16384/50176]	Loss: 4.6290
Training Epoch: 66 [17408/50176]	Loss: 4.6349
Training Epoch: 66 [18432/50176]	Loss: 4.6490
Training Epoch: 66 [19456/50176]	Loss: 4.6493
Training Epoch: 66 [20480/50176]	Loss: 4.6326
Training Epoch: 66 [21504/50176]	Loss: 4.6381
Training Epoch: 66 [22528/50176]	Loss: 4.6327
Training Epoch: 66 [23552/50176]	Loss: 4.6254
Training Epoch: 66 [24576/50176]	Loss: 4.6347
Training Epoch: 66 [25600/50176]	Loss: 4.6529
Training Epoch: 66 [26624/50176]	Loss: 4.6510
Training Epoch: 66 [27648/50176]	Loss: 4.6466
Training Epoch: 66 [28672/50176]	Loss: 4.6424
Training Epoch: 66 [29696/50176]	Loss: 4.6307
Training Epoch: 66 [30720/50176]	Loss: 4.6393
Training Epoch: 66 [31744/50176]	Loss: 4.6303
Training Epoch: 66 [32768/50176]	Loss: 4.6374
Training Epoch: 66 [33792/50176]	Loss: 4.6276
Training Epoch: 66 [34816/50176]	Loss: 4.6369
Training Epoch: 66 [35840/50176]	Loss: 4.6289
Training Epoch: 66 [36864/50176]	Loss: 4.6408
Training Epoch: 66 [37888/50176]	Loss: 4.6281
Training Epoch: 66 [38912/50176]	Loss: 4.6468
Training Epoch: 66 [39936/50176]	Loss: 4.6301
Training Epoch: 66 [40960/50176]	Loss: 4.6326
Training Epoch: 66 [41984/50176]	Loss: 4.6337
Training Epoch: 66 [43008/50176]	Loss: 4.6468
Training Epoch: 66 [44032/50176]	Loss: 4.6244
Training Epoch: 66 [45056/50176]	Loss: 4.6496
Training Epoch: 66 [46080/50176]	Loss: 4.6210
Training Epoch: 66 [47104/50176]	Loss: 4.6373
Training Epoch: 66 [48128/50176]	Loss: 4.6289
Training Epoch: 66 [49152/50176]	Loss: 4.6329
Training Epoch: 66 [50176/50176]	Loss: 4.6331
2022-12-06 20:25:23.190 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:25:23,221 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.82 energy=482.69
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Up to epoch 67: time=3202.84, energy=422291.37, cost=491394.34
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Expected next epoch: time=3249.45, energy=428657.67, cost=498655.58
2022-12-06 15:25:23,223 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 1680.4798, Accuracy: 0.0098
2022-12-06 15:25:23,477 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:25:23,478 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:25:23.479 [ZeusMonitor] Monitor started.
2022-12-06 20:25:23.480 [ZeusMonitor] Running indefinitely. 2022-12-06 20:25:23.480 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:25:23.480 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 15:26:06,999 [ZeusDataLoader(train)] train epoch 68 done: time=43.77 energy=5828.59
2022-12-06 15:26:07,002 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 4.6432
Training Epoch: 67 [2048/50176]	Loss: 4.6449
Training Epoch: 67 [3072/50176]	Loss: 4.6391
Training Epoch: 67 [4096/50176]	Loss: 4.6464
Training Epoch: 67 [5120/50176]	Loss: 4.6547
Training Epoch: 67 [6144/50176]	Loss: 4.6448
Training Epoch: 67 [7168/50176]	Loss: 4.6347
Training Epoch: 67 [8192/50176]	Loss: 4.6383
Training Epoch: 67 [9216/50176]	Loss: 4.6450
Training Epoch: 67 [10240/50176]	Loss: 4.6572
Training Epoch: 67 [11264/50176]	Loss: 4.6437
Training Epoch: 67 [12288/50176]	Loss: 4.6413
Training Epoch: 67 [13312/50176]	Loss: 4.6510
Training Epoch: 67 [14336/50176]	Loss: 4.6232
Training Epoch: 67 [15360/50176]	Loss: 4.6439
Training Epoch: 67 [16384/50176]	Loss: 4.6417
Training Epoch: 67 [17408/50176]	Loss: 4.6372
Training Epoch: 67 [18432/50176]	Loss: 4.6508
Training Epoch: 67 [19456/50176]	Loss: 4.6488
Training Epoch: 67 [20480/50176]	Loss: 4.6550
Training Epoch: 67 [21504/50176]	Loss: 4.6346
Training Epoch: 67 [22528/50176]	Loss: 4.6227
Training Epoch: 67 [23552/50176]	Loss: 4.6524
Training Epoch: 67 [24576/50176]	Loss: 4.6331
Training Epoch: 67 [25600/50176]	Loss: 4.6409
Training Epoch: 67 [26624/50176]	Loss: 4.6301
Training Epoch: 67 [27648/50176]	Loss: 4.6408
Training Epoch: 67 [28672/50176]	Loss: 4.6362
Training Epoch: 67 [29696/50176]	Loss: 4.6267
Training Epoch: 67 [30720/50176]	Loss: 4.6349
Training Epoch: 67 [31744/50176]	Loss: 4.6308
Training Epoch: 67 [32768/50176]	Loss: 4.6305
Training Epoch: 67 [33792/50176]	Loss: 4.6386
Training Epoch: 67 [34816/50176]	Loss: 4.6358
Training Epoch: 67 [35840/50176]	Loss: 4.6359
Training Epoch: 67 [36864/50176]	Loss: 4.6400
Training Epoch: 67 [37888/50176]	Loss: 4.6402
Training Epoch: 67 [38912/50176]	Loss: 4.6341
Training Epoch: 67 [39936/50176]	Loss: 4.6327
Training Epoch: 67 [40960/50176]	Loss: 4.6398
Training Epoch: 67 [41984/50176]	Loss: 4.6312
Training Epoch: 67 [43008/50176]	Loss: 4.6425
Training Epoch: 67 [44032/50176]	Loss: 4.6177
Training Epoch: 67 [45056/50176]	Loss: 4.6281
Training Epoch: 67 [46080/50176]	Loss: 4.6309
Training Epoch: 67 [47104/50176]	Loss: 4.6575
Training Epoch: 67 [48128/50176]	Loss: 4.6413
Training Epoch: 67 [49152/50176]	Loss: 4.6279
Training Epoch: 67 [50176/50176]	Loss: 4.6508
2022-12-06 20:26:10.782 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:26:10,827 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.82 energy=477.06
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Up to epoch 68: time=3250.43, energy=428597.03, cost=498710.88
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Expected next epoch: time=3297.03, energy=434963.32, cost=505972.11
2022-12-06 15:26:10,828 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 8505.2449, Accuracy: 0.0098
2022-12-06 15:26:11,065 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:26:11,065 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:26:11.074 [ZeusMonitor] Monitor started.
2022-12-06 20:26:11.074 [ZeusMonitor] Running indefinitely. 2022-12-06 20:26:11.074 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:26:11.074 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 15:26:54,679 [ZeusDataLoader(train)] train epoch 69 done: time=43.84 energy=5834.35
2022-12-06 15:26:54,682 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 4.6358
Training Epoch: 68 [2048/50176]	Loss: 4.6319
Training Epoch: 68 [3072/50176]	Loss: 4.6274
Training Epoch: 68 [4096/50176]	Loss: 4.6370
Training Epoch: 68 [5120/50176]	Loss: 4.6422
Training Epoch: 68 [6144/50176]	Loss: 4.6404
Training Epoch: 68 [7168/50176]	Loss: 4.6406
Training Epoch: 68 [8192/50176]	Loss: 4.6377
Training Epoch: 68 [9216/50176]	Loss: 4.6437
Training Epoch: 68 [10240/50176]	Loss: 4.6452
Training Epoch: 68 [11264/50176]	Loss: 4.6382
Training Epoch: 68 [12288/50176]	Loss: 4.6446
Training Epoch: 68 [13312/50176]	Loss: 4.6439
Training Epoch: 68 [14336/50176]	Loss: 4.6357
Training Epoch: 68 [15360/50176]	Loss: 4.6434
Training Epoch: 68 [16384/50176]	Loss: 4.6416
Training Epoch: 68 [17408/50176]	Loss: 4.6353
Training Epoch: 68 [18432/50176]	Loss: 4.6578
Training Epoch: 68 [19456/50176]	Loss: 4.6326
Training Epoch: 68 [20480/50176]	Loss: 4.6352
Training Epoch: 68 [21504/50176]	Loss: 4.6355
Training Epoch: 68 [22528/50176]	Loss: 4.6426
Training Epoch: 68 [23552/50176]	Loss: 4.6470
Training Epoch: 68 [24576/50176]	Loss: 4.6355
Training Epoch: 68 [25600/50176]	Loss: 4.6453
Training Epoch: 68 [26624/50176]	Loss: 4.6423
Training Epoch: 68 [27648/50176]	Loss: 4.6371
Training Epoch: 68 [28672/50176]	Loss: 4.6292
Training Epoch: 68 [29696/50176]	Loss: 4.6429
Training Epoch: 68 [30720/50176]	Loss: 4.6403
Training Epoch: 68 [31744/50176]	Loss: 4.6237
Training Epoch: 68 [32768/50176]	Loss: 4.6347
Training Epoch: 68 [33792/50176]	Loss: 4.6444
Training Epoch: 68 [34816/50176]	Loss: 4.6277
Training Epoch: 68 [35840/50176]	Loss: 4.6229
Training Epoch: 68 [36864/50176]	Loss: 4.6301
Training Epoch: 68 [37888/50176]	Loss: 4.6343
Training Epoch: 68 [38912/50176]	Loss: 4.6335
Training Epoch: 68 [39936/50176]	Loss: 4.6355
Training Epoch: 68 [40960/50176]	Loss: 4.6409
Training Epoch: 68 [41984/50176]	Loss: 4.6377
Training Epoch: 68 [43008/50176]	Loss: 4.6376
Training Epoch: 68 [44032/50176]	Loss: 4.6386
Training Epoch: 68 [45056/50176]	Loss: 4.6264
Training Epoch: 68 [46080/50176]	Loss: 4.6313
Training Epoch: 68 [47104/50176]	Loss: 4.6388
Training Epoch: 68 [48128/50176]	Loss: 4.6395
Training Epoch: 68 [49152/50176]	Loss: 4.6311
Training Epoch: 68 [50176/50176]	Loss: 4.6565
2022-12-06 20:26:58.437 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:26:58,494 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.80 energy=480.65
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Up to epoch 69: time=3298.07, energy=434912.03, cost=506037.46
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Expected next epoch: time=3344.68, energy=441278.33, cost=513298.70
2022-12-06 15:26:58,495 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 5371.4322, Accuracy: 0.0098
2022-12-06 15:26:58,693 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:26:58,694 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:26:58.695 [ZeusMonitor] Monitor started.
2022-12-06 20:26:58.696 [ZeusMonitor] Running indefinitely. 2022-12-06 20:26:58.696 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:26:58.696 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 15:27:42,139 [ZeusDataLoader(train)] train epoch 70 done: time=43.64 energy=5820.54
2022-12-06 15:27:42,142 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 4.6576
Training Epoch: 69 [2048/50176]	Loss: 4.6319
Training Epoch: 69 [3072/50176]	Loss: 4.6404
Training Epoch: 69 [4096/50176]	Loss: 4.6369
Training Epoch: 69 [5120/50176]	Loss: 4.6331
Training Epoch: 69 [6144/50176]	Loss: 4.6406
Training Epoch: 69 [7168/50176]	Loss: 4.6520
Training Epoch: 69 [8192/50176]	Loss: 4.6366
Training Epoch: 69 [9216/50176]	Loss: 4.6420
Training Epoch: 69 [10240/50176]	Loss: 4.6421
Training Epoch: 69 [11264/50176]	Loss: 4.6474
Training Epoch: 69 [12288/50176]	Loss: 4.6386
Training Epoch: 69 [13312/50176]	Loss: 4.6362
Training Epoch: 69 [14336/50176]	Loss: 4.6403
Training Epoch: 69 [15360/50176]	Loss: 4.6513
Training Epoch: 69 [16384/50176]	Loss: 4.6375
Training Epoch: 69 [17408/50176]	Loss: 4.6417
Training Epoch: 69 [18432/50176]	Loss: 4.6418
Training Epoch: 69 [19456/50176]	Loss: 4.6350
Training Epoch: 69 [20480/50176]	Loss: 4.6357
Training Epoch: 69 [21504/50176]	Loss: 4.6432
Training Epoch: 69 [22528/50176]	Loss: 4.6437
Training Epoch: 69 [23552/50176]	Loss: 4.6518
Training Epoch: 69 [24576/50176]	Loss: 4.6404
Training Epoch: 69 [25600/50176]	Loss: 4.6392
Training Epoch: 69 [26624/50176]	Loss: 4.6285
Training Epoch: 69 [27648/50176]	Loss: 4.6302
Training Epoch: 69 [28672/50176]	Loss: 4.6425
Training Epoch: 69 [29696/50176]	Loss: 4.6498
Training Epoch: 69 [30720/50176]	Loss: 4.6361
Training Epoch: 69 [31744/50176]	Loss: 4.6470
Training Epoch: 69 [32768/50176]	Loss: 4.6479
Training Epoch: 69 [33792/50176]	Loss: 4.6355
Training Epoch: 69 [34816/50176]	Loss: 4.6360
Training Epoch: 69 [35840/50176]	Loss: 4.6238
Training Epoch: 69 [36864/50176]	Loss: 4.6404
Training Epoch: 69 [37888/50176]	Loss: 4.6682
Training Epoch: 69 [38912/50176]	Loss: 4.6506
Training Epoch: 69 [39936/50176]	Loss: 4.6477
Training Epoch: 69 [40960/50176]	Loss: 4.6293
Training Epoch: 69 [41984/50176]	Loss: 4.6358
Training Epoch: 69 [43008/50176]	Loss: 4.6382
Training Epoch: 69 [44032/50176]	Loss: 4.6483
Training Epoch: 69 [45056/50176]	Loss: 4.6382
Training Epoch: 69 [46080/50176]	Loss: 4.6428
Training Epoch: 69 [47104/50176]	Loss: 4.6377
Training Epoch: 69 [48128/50176]	Loss: 4.6439
Training Epoch: 69 [49152/50176]	Loss: 4.6463
Training Epoch: 69 [50176/50176]	Loss: 4.6310
2022-12-06 20:27:45.855 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:27:45,870 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.72 energy=465.43
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Up to epoch 70: time=3345.43, energy=441198.00, cost=513324.05
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Expected next epoch: time=3392.04, energy=447564.30, cost=520585.29
2022-12-06 15:27:45,871 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:27:46,121 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:27:46,122 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:27:46.138 [ZeusMonitor] Monitor started.
2022-12-06 20:27:46.138 [ZeusMonitor] Running indefinitely. 2022-12-06 20:27:46.138 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:27:46.138 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 15:28:29,521 [ZeusDataLoader(train)] train epoch 71 done: time=43.64 energy=5817.17
2022-12-06 15:28:29,524 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 4.6424
Training Epoch: 70 [2048/50176]	Loss: 4.6431
Training Epoch: 70 [3072/50176]	Loss: 4.6481
Training Epoch: 70 [4096/50176]	Loss: 4.6345
Training Epoch: 70 [5120/50176]	Loss: 4.6426
Training Epoch: 70 [6144/50176]	Loss: 4.6339
Training Epoch: 70 [7168/50176]	Loss: 4.6278
Training Epoch: 70 [8192/50176]	Loss: 4.6372
Training Epoch: 70 [9216/50176]	Loss: 4.6367
Training Epoch: 70 [10240/50176]	Loss: 4.6384
Training Epoch: 70 [11264/50176]	Loss: 4.6442
Training Epoch: 70 [12288/50176]	Loss: 4.6340
Training Epoch: 70 [13312/50176]	Loss: 4.6475
Training Epoch: 70 [14336/50176]	Loss: 4.6452
Training Epoch: 70 [15360/50176]	Loss: 4.6297
Training Epoch: 70 [16384/50176]	Loss: 4.6313
Training Epoch: 70 [17408/50176]	Loss: 4.6195
Training Epoch: 70 [18432/50176]	Loss: 4.6283
Training Epoch: 70 [19456/50176]	Loss: 4.6345
Training Epoch: 70 [20480/50176]	Loss: 4.6264
Training Epoch: 70 [21504/50176]	Loss: 4.6476
Training Epoch: 70 [22528/50176]	Loss: 4.6283
Training Epoch: 70 [23552/50176]	Loss: 4.6349
Training Epoch: 70 [24576/50176]	Loss: 4.6354
Training Epoch: 70 [25600/50176]	Loss: 4.6277
Training Epoch: 70 [26624/50176]	Loss: 4.6502
Training Epoch: 70 [27648/50176]	Loss: 4.6401
Training Epoch: 70 [28672/50176]	Loss: 4.6304
Training Epoch: 70 [29696/50176]	Loss: 4.6249
Training Epoch: 70 [30720/50176]	Loss: 4.6201
Training Epoch: 70 [31744/50176]	Loss: 4.6403
Training Epoch: 70 [32768/50176]	Loss: 4.6400
Training Epoch: 70 [33792/50176]	Loss: 4.6434
Training Epoch: 70 [34816/50176]	Loss: 4.6577
Training Epoch: 70 [35840/50176]	Loss: 4.6421
Training Epoch: 70 [36864/50176]	Loss: 4.6270
Training Epoch: 70 [37888/50176]	Loss: 4.6277
Training Epoch: 70 [38912/50176]	Loss: 4.6275
Training Epoch: 70 [39936/50176]	Loss: 4.6450
Training Epoch: 70 [40960/50176]	Loss: 4.6452
Training Epoch: 70 [41984/50176]	Loss: 4.6489
Training Epoch: 70 [43008/50176]	Loss: 4.6600
Training Epoch: 70 [44032/50176]	Loss: 4.6319
Training Epoch: 70 [45056/50176]	Loss: 4.6383
Training Epoch: 70 [46080/50176]	Loss: 4.6309
Training Epoch: 70 [47104/50176]	Loss: 4.6345
Training Epoch: 70 [48128/50176]	Loss: 4.6434
Training Epoch: 70 [49152/50176]	Loss: 4.6231
Training Epoch: 70 [50176/50176]	Loss: 4.6357
2022-12-06 20:28:33.328 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:28:33,351 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.82 energy=471.44
2022-12-06 15:28:33,351 [ZeusDataLoader(train)] Up to epoch 71: time=3392.89, energy=447486.62, cost=520621.21
2022-12-06 15:28:33,352 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:28:33,352 [ZeusDataLoader(train)] Expected next epoch: time=3439.50, energy=453852.91, cost=527882.45
2022-12-06 15:28:33,353 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 6921.8770, Accuracy: 0.0098
2022-12-06 15:28:33,598 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:28:33,598 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:28:33.600 [ZeusMonitor] Monitor started.
2022-12-06 20:28:33.600 [ZeusMonitor] Running indefinitely. 2022-12-06 20:28:33.600 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:28:33.600 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 15:29:17,134 [ZeusDataLoader(train)] train epoch 72 done: time=43.77 energy=5825.79
2022-12-06 15:29:17,137 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 4.6448
Training Epoch: 71 [2048/50176]	Loss: 4.6444
Training Epoch: 71 [3072/50176]	Loss: 4.6563
Training Epoch: 71 [4096/50176]	Loss: 4.6293
Training Epoch: 71 [5120/50176]	Loss: 4.6389
Training Epoch: 71 [6144/50176]	Loss: 4.6375
Training Epoch: 71 [7168/50176]	Loss: 4.6276
Training Epoch: 71 [8192/50176]	Loss: 4.6410
Training Epoch: 71 [9216/50176]	Loss: 4.6392
Training Epoch: 71 [10240/50176]	Loss: 4.6447
Training Epoch: 71 [11264/50176]	Loss: 4.6446
Training Epoch: 71 [12288/50176]	Loss: 4.6413
Training Epoch: 71 [13312/50176]	Loss: 4.6374
Training Epoch: 71 [14336/50176]	Loss: 4.6252
Training Epoch: 71 [15360/50176]	Loss: 4.6359
Training Epoch: 71 [16384/50176]	Loss: 4.6315
Training Epoch: 71 [17408/50176]	Loss: 4.6411
Training Epoch: 71 [18432/50176]	Loss: 4.6363
Training Epoch: 71 [19456/50176]	Loss: 4.6553
Training Epoch: 71 [20480/50176]	Loss: 4.6483
Training Epoch: 71 [21504/50176]	Loss: 4.6375
Training Epoch: 71 [22528/50176]	Loss: 4.6307
Training Epoch: 71 [23552/50176]	Loss: 4.6208
Training Epoch: 71 [24576/50176]	Loss: 4.6323
Training Epoch: 71 [25600/50176]	Loss: 4.6313
Training Epoch: 71 [26624/50176]	Loss: 4.6415
Training Epoch: 71 [27648/50176]	Loss: 4.6389
Training Epoch: 71 [28672/50176]	Loss: 4.6358
Training Epoch: 71 [29696/50176]	Loss: 4.6393
Training Epoch: 71 [30720/50176]	Loss: 4.6419
Training Epoch: 71 [31744/50176]	Loss: 4.6383
Training Epoch: 71 [32768/50176]	Loss: 4.6512
Training Epoch: 71 [33792/50176]	Loss: 4.6422
Training Epoch: 71 [34816/50176]	Loss: 4.6382
Training Epoch: 71 [35840/50176]	Loss: 4.6468
Training Epoch: 71 [36864/50176]	Loss: 4.6372
Training Epoch: 71 [37888/50176]	Loss: 4.6337
Training Epoch: 71 [38912/50176]	Loss: 4.6414
Training Epoch: 71 [39936/50176]	Loss: 4.6316
Training Epoch: 71 [40960/50176]	Loss: 4.6270
Training Epoch: 71 [41984/50176]	Loss: 4.6227
Training Epoch: 71 [43008/50176]	Loss: 4.6518
Training Epoch: 71 [44032/50176]	Loss: 4.6549
Training Epoch: 71 [45056/50176]	Loss: 4.6408
Training Epoch: 71 [46080/50176]	Loss: 4.6250
Training Epoch: 71 [47104/50176]	Loss: 4.6196
Training Epoch: 71 [48128/50176]	Loss: 4.6387
Training Epoch: 71 [49152/50176]	Loss: 4.6191
Training Epoch: 71 [50176/50176]	Loss: 4.6458
2022-12-06 20:29:21.025 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:29:21,058 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.91 energy=484.44
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Up to epoch 72: time=3440.58, energy=453796.85, cost=527948.91
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Expected next epoch: time=3487.18, energy=460163.15, cost=535210.15
2022-12-06 15:29:21,059 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 557.8394, Accuracy: 0.0098
2022-12-06 15:29:21,314 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:29:21,315 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:29:21.316 [ZeusMonitor] Monitor started.
2022-12-06 20:29:21.316 [ZeusMonitor] Running indefinitely. 2022-12-06 20:29:21.316 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:29:21.317 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 15:30:04,827 [ZeusDataLoader(train)] train epoch 73 done: time=43.76 energy=5819.67
2022-12-06 15:30:04,830 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 4.6476
Training Epoch: 72 [2048/50176]	Loss: 4.6268
Training Epoch: 72 [3072/50176]	Loss: 4.6231
Training Epoch: 72 [4096/50176]	Loss: 4.6358
Training Epoch: 72 [5120/50176]	Loss: 4.6528
Training Epoch: 72 [6144/50176]	Loss: 4.6476
Training Epoch: 72 [7168/50176]	Loss: 4.6186
Training Epoch: 72 [8192/50176]	Loss: 4.6441
Training Epoch: 72 [9216/50176]	Loss: 4.6372
Training Epoch: 72 [10240/50176]	Loss: 4.6482
Training Epoch: 72 [11264/50176]	Loss: 4.6323
Training Epoch: 72 [12288/50176]	Loss: 4.6401
Training Epoch: 72 [13312/50176]	Loss: 4.6389
Training Epoch: 72 [14336/50176]	Loss: 4.6249
Training Epoch: 72 [15360/50176]	Loss: 4.6356
Training Epoch: 72 [16384/50176]	Loss: 4.6566
Training Epoch: 72 [17408/50176]	Loss: 4.6505
Training Epoch: 72 [18432/50176]	Loss: 4.6288
Training Epoch: 72 [19456/50176]	Loss: 4.6506
Training Epoch: 72 [20480/50176]	Loss: 4.6425
Training Epoch: 72 [21504/50176]	Loss: 4.6317
Training Epoch: 72 [22528/50176]	Loss: 4.6327
Training Epoch: 72 [23552/50176]	Loss: 4.6411
Training Epoch: 72 [24576/50176]	Loss: 4.6553
Training Epoch: 72 [25600/50176]	Loss: 4.6409
Training Epoch: 72 [26624/50176]	Loss: 4.6620
Training Epoch: 72 [27648/50176]	Loss: 4.6426
Training Epoch: 72 [28672/50176]	Loss: 4.6397
Training Epoch: 72 [29696/50176]	Loss: 4.6323
Training Epoch: 72 [30720/50176]	Loss: 4.6428
Training Epoch: 72 [31744/50176]	Loss: 4.6483
Training Epoch: 72 [32768/50176]	Loss: 4.6355
Training Epoch: 72 [33792/50176]	Loss: 4.6445
Training Epoch: 72 [34816/50176]	Loss: 4.6356
Training Epoch: 72 [35840/50176]	Loss: 4.6218
Training Epoch: 72 [36864/50176]	Loss: 4.6232
Training Epoch: 72 [37888/50176]	Loss: 4.6380
Training Epoch: 72 [38912/50176]	Loss: 4.6523
Training Epoch: 72 [39936/50176]	Loss: 4.6444
Training Epoch: 72 [40960/50176]	Loss: 4.6431
Training Epoch: 72 [41984/50176]	Loss: 4.6267
Training Epoch: 72 [43008/50176]	Loss: 4.6341
Training Epoch: 72 [44032/50176]	Loss: 4.6335
Training Epoch: 72 [45056/50176]	Loss: 4.6379
Training Epoch: 72 [46080/50176]	Loss: 4.6357
Training Epoch: 72 [47104/50176]	Loss: 4.6257
Training Epoch: 72 [48128/50176]	Loss: 4.6442
Training Epoch: 72 [49152/50176]	Loss: 4.6326
Training Epoch: 72 [50176/50176]	Loss: 4.6392
2022-12-06 20:30:08.594 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:30:08,642 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.80 energy=482.72
2022-12-06 15:30:08,642 [ZeusDataLoader(train)] Up to epoch 73: time=3488.14, energy=460099.25, cost=535261.88
2022-12-06 15:30:08,642 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:30:08,643 [ZeusDataLoader(train)] Expected next epoch: time=3534.75, energy=466465.54, cost=542523.12
2022-12-06 15:30:08,644 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 4357.5853, Accuracy: 0.0098
2022-12-06 15:30:08,837 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:30:08,838 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:30:08.841 [ZeusMonitor] Monitor started.
2022-12-06 20:30:08.842 [ZeusMonitor] Running indefinitely. 2022-12-06 20:30:08.842 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:30:08.842 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 15:30:52,420 [ZeusDataLoader(train)] train epoch 74 done: time=43.77 energy=5824.41
2022-12-06 15:30:52,423 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 4.6439
Training Epoch: 73 [2048/50176]	Loss: 4.6278
Training Epoch: 73 [3072/50176]	Loss: 4.6256
Training Epoch: 73 [4096/50176]	Loss: 4.6428
Training Epoch: 73 [5120/50176]	Loss: 4.6504
Training Epoch: 73 [6144/50176]	Loss: 4.6420
Training Epoch: 73 [7168/50176]	Loss: 4.6322
Training Epoch: 73 [8192/50176]	Loss: 4.6371
Training Epoch: 73 [9216/50176]	Loss: 4.6224
Training Epoch: 73 [10240/50176]	Loss: 4.6496
Training Epoch: 73 [11264/50176]	Loss: 4.6299
Training Epoch: 73 [12288/50176]	Loss: 4.6316
Training Epoch: 73 [13312/50176]	Loss: 4.6484
Training Epoch: 73 [14336/50176]	Loss: 4.6378
Training Epoch: 73 [15360/50176]	Loss: 4.6344
Training Epoch: 73 [16384/50176]	Loss: 4.6338
Training Epoch: 73 [17408/50176]	Loss: 4.6188
Training Epoch: 73 [18432/50176]	Loss: 4.6260
Training Epoch: 73 [19456/50176]	Loss: 4.6390
Training Epoch: 73 [20480/50176]	Loss: 4.6330
Training Epoch: 73 [21504/50176]	Loss: 4.6345
Training Epoch: 73 [22528/50176]	Loss: 4.6373
Training Epoch: 73 [23552/50176]	Loss: 4.6285
Training Epoch: 73 [24576/50176]	Loss: 4.6471
Training Epoch: 73 [25600/50176]	Loss: 4.6449
Training Epoch: 73 [26624/50176]	Loss: 4.6407
Training Epoch: 73 [27648/50176]	Loss: 4.6455
Training Epoch: 73 [28672/50176]	Loss: 4.6351
Training Epoch: 73 [29696/50176]	Loss: 4.6334
Training Epoch: 73 [30720/50176]	Loss: 4.6321
Training Epoch: 73 [31744/50176]	Loss: 4.6457
Training Epoch: 73 [32768/50176]	Loss: 4.6384
Training Epoch: 73 [33792/50176]	Loss: 4.6373
Training Epoch: 73 [34816/50176]	Loss: 4.6183
Training Epoch: 73 [35840/50176]	Loss: 4.6238
Training Epoch: 73 [36864/50176]	Loss: 4.6492
Training Epoch: 73 [37888/50176]	Loss: 4.6431
Training Epoch: 73 [38912/50176]	Loss: 4.6496
Training Epoch: 73 [39936/50176]	Loss: 4.6460
Training Epoch: 73 [40960/50176]	Loss: 4.6267
Training Epoch: 73 [41984/50176]	Loss: 4.6282
Training Epoch: 73 [43008/50176]	Loss: 4.6427
Training Epoch: 73 [44032/50176]	Loss: 4.6392
Training Epoch: 73 [45056/50176]	Loss: 4.6314
Training Epoch: 73 [46080/50176]	Loss: 4.6401
Training Epoch: 73 [47104/50176]	Loss: 4.6418
Training Epoch: 73 [48128/50176]	Loss: 4.6507
Training Epoch: 73 [49152/50176]	Loss: 4.6470
Training Epoch: 73 [50176/50176]	Loss: 4.6471
2022-12-06 20:30:56.114 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:30:56,124 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.69 energy=452.52
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Up to epoch 74: time=3535.60, energy=466376.18, cost=542553.22
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Expected next epoch: time=3582.21, energy=472742.47, cost=549814.46
2022-12-06 15:30:56,126 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 35791.9193, Accuracy: 0.0098
2022-12-06 15:30:56,361 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:30:56,362 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:30:56.364 [ZeusMonitor] Monitor started.
2022-12-06 20:30:56.364 [ZeusMonitor] Running indefinitely. 2022-12-06 20:30:56.364 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:30:56.364 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 15:31:39,958 [ZeusDataLoader(train)] train epoch 75 done: time=43.82 energy=5834.95
2022-12-06 15:31:39,961 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 4.6305
Training Epoch: 74 [2048/50176]	Loss: 4.6319
Training Epoch: 74 [3072/50176]	Loss: 4.6390
Training Epoch: 74 [4096/50176]	Loss: 4.6169
Training Epoch: 74 [5120/50176]	Loss: 4.6351
Training Epoch: 74 [6144/50176]	Loss: 4.6402
Training Epoch: 74 [7168/50176]	Loss: 4.6315
Training Epoch: 74 [8192/50176]	Loss: 4.6288
Training Epoch: 74 [9216/50176]	Loss: 4.6396
Training Epoch: 74 [10240/50176]	Loss: 4.6381
Training Epoch: 74 [11264/50176]	Loss: 4.6280
Training Epoch: 74 [12288/50176]	Loss: 4.6174
Training Epoch: 74 [13312/50176]	Loss: 4.6240
Training Epoch: 74 [14336/50176]	Loss: 4.6323
Training Epoch: 74 [15360/50176]	Loss: 4.6366
Training Epoch: 74 [16384/50176]	Loss: 4.6368
Training Epoch: 74 [17408/50176]	Loss: 4.6336
Training Epoch: 74 [18432/50176]	Loss: 4.6255
Training Epoch: 74 [19456/50176]	Loss: 4.6291
Training Epoch: 74 [20480/50176]	Loss: 4.6332
Training Epoch: 74 [21504/50176]	Loss: 4.6318
Training Epoch: 74 [22528/50176]	Loss: 4.6382
Training Epoch: 74 [23552/50176]	Loss: 4.6300
Training Epoch: 74 [24576/50176]	Loss: 4.6311
Training Epoch: 74 [25600/50176]	Loss: 4.6404
Training Epoch: 74 [26624/50176]	Loss: 4.6313
Training Epoch: 74 [27648/50176]	Loss: 4.6322
Training Epoch: 74 [28672/50176]	Loss: 4.6324
Training Epoch: 74 [29696/50176]	Loss: 4.6351
Training Epoch: 74 [30720/50176]	Loss: 4.6495
Training Epoch: 74 [31744/50176]	Loss: 4.6402
Training Epoch: 74 [32768/50176]	Loss: 4.6439
Training Epoch: 74 [33792/50176]	Loss: 4.6275
Training Epoch: 74 [34816/50176]	Loss: 4.6384
Training Epoch: 74 [35840/50176]	Loss: 4.6491
Training Epoch: 74 [36864/50176]	Loss: 4.6366
Training Epoch: 74 [37888/50176]	Loss: 4.6220
Training Epoch: 74 [38912/50176]	Loss: 4.6444
Training Epoch: 74 [39936/50176]	Loss: 4.6184
Training Epoch: 74 [40960/50176]	Loss: 4.6593
Training Epoch: 74 [41984/50176]	Loss: 4.6414
Training Epoch: 74 [43008/50176]	Loss: 4.6505
Training Epoch: 74 [44032/50176]	Loss: 4.6432
Training Epoch: 74 [45056/50176]	Loss: 4.6324
Training Epoch: 74 [46080/50176]	Loss: 4.6324
Training Epoch: 74 [47104/50176]	Loss: 4.6456
Training Epoch: 74 [48128/50176]	Loss: 4.6571
Training Epoch: 74 [49152/50176]	Loss: 4.6379
Training Epoch: 74 [50176/50176]	Loss: 4.6427
2022-12-06 20:31:43.774 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:31:43,794 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.82 energy=471.39
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Up to epoch 75: time=3583.25, energy=472682.52, cost=549875.62
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Expected next epoch: time=3629.86, energy=479048.82, cost=557136.86
2022-12-06 15:31:43,795 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 1961.2634, Accuracy: 0.0098
2022-12-06 15:31:44,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:31:44,043 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:31:44.045 [ZeusMonitor] Monitor started.
2022-12-06 20:31:44.045 [ZeusMonitor] Running indefinitely. 2022-12-06 20:31:44.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:31:44.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e76+gpu0.power.log
2022-12-06 15:32:27,567 [ZeusDataLoader(train)] train epoch 76 done: time=43.76 energy=5823.39
2022-12-06 15:32:27,570 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 4.6443
Training Epoch: 75 [2048/50176]	Loss: 4.6416
Training Epoch: 75 [3072/50176]	Loss: 4.6335
Training Epoch: 75 [4096/50176]	Loss: 4.6358
Training Epoch: 75 [5120/50176]	Loss: 4.6390
Training Epoch: 75 [6144/50176]	Loss: 4.6540
Training Epoch: 75 [7168/50176]	Loss: 4.6331
Training Epoch: 75 [8192/50176]	Loss: 4.6462
Training Epoch: 75 [9216/50176]	Loss: 4.6487
Training Epoch: 75 [10240/50176]	Loss: 4.6374
Training Epoch: 75 [11264/50176]	Loss: 4.6450
Training Epoch: 75 [12288/50176]	Loss: 4.6504
Training Epoch: 75 [13312/50176]	Loss: 4.6420
Training Epoch: 75 [14336/50176]	Loss: 4.6404
Training Epoch: 75 [15360/50176]	Loss: 4.6314
Training Epoch: 75 [16384/50176]	Loss: 4.6493
Training Epoch: 75 [17408/50176]	Loss: 4.6304
Training Epoch: 75 [18432/50176]	Loss: 4.6267
Training Epoch: 75 [19456/50176]	Loss: 4.6260
Training Epoch: 75 [20480/50176]	Loss: 4.6340
Training Epoch: 75 [21504/50176]	Loss: 4.6421
Training Epoch: 75 [22528/50176]	Loss: 4.6343
Training Epoch: 75 [23552/50176]	Loss: 4.6280
Training Epoch: 75 [24576/50176]	Loss: 4.6301
Training Epoch: 75 [25600/50176]	Loss: 4.6264
Training Epoch: 75 [26624/50176]	Loss: 4.6345
Training Epoch: 75 [27648/50176]	Loss: 4.6404
Training Epoch: 75 [28672/50176]	Loss: 4.6421
Training Epoch: 75 [29696/50176]	Loss: 4.6493
Training Epoch: 75 [30720/50176]	Loss: 4.6465
Training Epoch: 75 [31744/50176]	Loss: 4.6301
Training Epoch: 75 [32768/50176]	Loss: 4.6532
Training Epoch: 75 [33792/50176]	Loss: 4.6343
Training Epoch: 75 [34816/50176]	Loss: 4.6287
Training Epoch: 75 [35840/50176]	Loss: 4.6408
Training Epoch: 75 [36864/50176]	Loss: 4.6436
Training Epoch: 75 [37888/50176]	Loss: 4.6412
Training Epoch: 75 [38912/50176]	Loss: 4.6396
Training Epoch: 75 [39936/50176]	Loss: 4.6385
Training Epoch: 75 [40960/50176]	Loss: 4.6360
Training Epoch: 75 [41984/50176]	Loss: 4.6229
Training Epoch: 75 [43008/50176]	Loss: 4.6273
Training Epoch: 75 [44032/50176]	Loss: 4.6382
Training Epoch: 75 [45056/50176]	Loss: 4.6222
Training Epoch: 75 [46080/50176]	Loss: 4.6316
Training Epoch: 75 [47104/50176]	Loss: 4.6477
Training Epoch: 75 [48128/50176]	Loss: 4.6412
Training Epoch: 75 [49152/50176]	Loss: 4.6382
Training Epoch: 75 [50176/50176]	Loss: 4.6320
2022-12-06 20:32:31.291 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:32:31,309 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.73 energy=462.47
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Up to epoch 76: time=3630.74, energy=478968.39, cost=557174.36
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Expected next epoch: time=3677.35, energy=485334.68, cost=564435.60
2022-12-06 15:32:31,310 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 212.9936, Accuracy: 0.0098
2022-12-06 15:32:31,558 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:32:31,559 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:32:31.572 [ZeusMonitor] Monitor started.
2022-12-06 20:32:31.573 [ZeusMonitor] Running indefinitely. 2022-12-06 20:32:31.573 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:32:31.573 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e77+gpu0.power.log
2022-12-06 15:33:15,169 [ZeusDataLoader(train)] train epoch 77 done: time=43.85 energy=5829.62
2022-12-06 15:33:15,172 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 4.6457
Training Epoch: 76 [2048/50176]	Loss: 4.6299
Training Epoch: 76 [3072/50176]	Loss: 4.6370
Training Epoch: 76 [4096/50176]	Loss: 4.6375
Training Epoch: 76 [5120/50176]	Loss: 4.6423
Training Epoch: 76 [6144/50176]	Loss: 4.6475
Training Epoch: 76 [7168/50176]	Loss: 4.6489
Training Epoch: 76 [8192/50176]	Loss: 4.6431
Training Epoch: 76 [9216/50176]	Loss: 4.6298
Training Epoch: 76 [10240/50176]	Loss: 4.6307
Training Epoch: 76 [11264/50176]	Loss: 4.6302
Training Epoch: 76 [12288/50176]	Loss: 4.6245
Training Epoch: 76 [13312/50176]	Loss: 4.6399
Training Epoch: 76 [14336/50176]	Loss: 4.6363
Training Epoch: 76 [15360/50176]	Loss: 4.6261
Training Epoch: 76 [16384/50176]	Loss: 4.6425
Training Epoch: 76 [17408/50176]	Loss: 4.6332
Training Epoch: 76 [18432/50176]	Loss: 4.6401
Training Epoch: 76 [19456/50176]	Loss: 4.6352
Training Epoch: 76 [20480/50176]	Loss: 4.6361
Training Epoch: 76 [21504/50176]	Loss: 4.6299
Training Epoch: 76 [22528/50176]	Loss: 4.6316
Training Epoch: 76 [23552/50176]	Loss: 4.6326
Training Epoch: 76 [24576/50176]	Loss: 4.6399
Training Epoch: 76 [25600/50176]	Loss: 4.6249
Training Epoch: 76 [26624/50176]	Loss: 4.6221
Training Epoch: 76 [27648/50176]	Loss: 4.6539
Training Epoch: 76 [28672/50176]	Loss: 4.6611
Training Epoch: 76 [29696/50176]	Loss: 4.6236
Training Epoch: 76 [30720/50176]	Loss: 4.6321
Training Epoch: 76 [31744/50176]	Loss: 4.6478
Training Epoch: 76 [32768/50176]	Loss: 4.6417
Training Epoch: 76 [33792/50176]	Loss: 4.6534
Training Epoch: 76 [34816/50176]	Loss: 4.6409
Training Epoch: 76 [35840/50176]	Loss: 4.6449
Training Epoch: 76 [36864/50176]	Loss: 4.6430
Training Epoch: 76 [37888/50176]	Loss: 4.6284
Training Epoch: 76 [38912/50176]	Loss: 4.6406
Training Epoch: 76 [39936/50176]	Loss: 4.6447
Training Epoch: 76 [40960/50176]	Loss: 4.6421
Training Epoch: 76 [41984/50176]	Loss: 4.6450
Training Epoch: 76 [43008/50176]	Loss: 4.6311
Training Epoch: 76 [44032/50176]	Loss: 4.6422
Training Epoch: 76 [45056/50176]	Loss: 4.6339
Training Epoch: 76 [46080/50176]	Loss: 4.6420
Training Epoch: 76 [47104/50176]	Loss: 4.6230
Training Epoch: 76 [48128/50176]	Loss: 4.6386
Training Epoch: 76 [49152/50176]	Loss: 4.6242
Training Epoch: 76 [50176/50176]	Loss: 4.6424
2022-12-06 20:33:18.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:33:18,997 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.82 energy=478.81
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Up to epoch 77: time=3678.41, energy=485276.81, cost=564499.51
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Expected next epoch: time=3725.02, energy=491643.11, cost=571760.74
2022-12-06 15:33:18,999 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:33:19,302 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:33:19,303 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:33:19.304 [ZeusMonitor] Monitor started.
2022-12-06 20:33:19.304 [ZeusMonitor] Running indefinitely. 2022-12-06 20:33:19.304 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:33:19.304 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e78+gpu0.power.log
2022-12-06 15:34:02,888 [ZeusDataLoader(train)] train epoch 78 done: time=43.88 energy=5827.67
2022-12-06 15:34:02,892 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 4.6367
Training Epoch: 77 [2048/50176]	Loss: 4.6321
Training Epoch: 77 [3072/50176]	Loss: 4.6470
Training Epoch: 77 [4096/50176]	Loss: 4.6310
Training Epoch: 77 [5120/50176]	Loss: 4.6254
Training Epoch: 77 [6144/50176]	Loss: 4.6189
Training Epoch: 77 [7168/50176]	Loss: 4.6377
Training Epoch: 77 [8192/50176]	Loss: 4.6361
Training Epoch: 77 [9216/50176]	Loss: 4.6479
Training Epoch: 77 [10240/50176]	Loss: 4.6421
Training Epoch: 77 [11264/50176]	Loss: 4.6554
Training Epoch: 77 [12288/50176]	Loss: 4.6424
Training Epoch: 77 [13312/50176]	Loss: 4.6311
Training Epoch: 77 [14336/50176]	Loss: 4.6352
Training Epoch: 77 [15360/50176]	Loss: 4.6328
Training Epoch: 77 [16384/50176]	Loss: 4.6240
Training Epoch: 77 [17408/50176]	Loss: 4.6409
Training Epoch: 77 [18432/50176]	Loss: 4.6383
Training Epoch: 77 [19456/50176]	Loss: 4.6473
Training Epoch: 77 [20480/50176]	Loss: 4.6436
Training Epoch: 77 [21504/50176]	Loss: 4.6527
Training Epoch: 77 [22528/50176]	Loss: 4.6252
Training Epoch: 77 [23552/50176]	Loss: 4.6373
Training Epoch: 77 [24576/50176]	Loss: 4.6248
Training Epoch: 77 [25600/50176]	Loss: 4.6304
Training Epoch: 77 [26624/50176]	Loss: 4.6234
Training Epoch: 77 [27648/50176]	Loss: 4.6391
Training Epoch: 77 [28672/50176]	Loss: 4.6513
Training Epoch: 77 [29696/50176]	Loss: 4.6329
Training Epoch: 77 [30720/50176]	Loss: 4.6621
Training Epoch: 77 [31744/50176]	Loss: 4.6305
Training Epoch: 77 [32768/50176]	Loss: 4.6302
Training Epoch: 77 [33792/50176]	Loss: 4.6240
Training Epoch: 77 [34816/50176]	Loss: 4.6350
Training Epoch: 77 [35840/50176]	Loss: 4.6381
Training Epoch: 77 [36864/50176]	Loss: 4.6425
Training Epoch: 77 [37888/50176]	Loss: 4.6506
Training Epoch: 77 [38912/50176]	Loss: 4.6624
Training Epoch: 77 [39936/50176]	Loss: 4.6376
Training Epoch: 77 [40960/50176]	Loss: 4.6294
Training Epoch: 77 [41984/50176]	Loss: 4.6255
Training Epoch: 77 [43008/50176]	Loss: 4.6314
Training Epoch: 77 [44032/50176]	Loss: 4.6323
Training Epoch: 77 [45056/50176]	Loss: 4.6553
Training Epoch: 77 [46080/50176]	Loss: 4.6425
Training Epoch: 77 [47104/50176]	Loss: 4.6464
Training Epoch: 77 [48128/50176]	Loss: 4.6574
Training Epoch: 77 [49152/50176]	Loss: 4.6436
Training Epoch: 77 [50176/50176]	Loss: 4.6369
2022-12-06 20:34:06.705 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:34:06,745 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.85 energy=471.26
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Up to epoch 78: time=3726.14, energy=491575.75, cost=571825.11
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Expected next epoch: time=3772.75, energy=497942.04, cost=579086.35
2022-12-06 15:34:06,746 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:34:06,995 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:34:06,996 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:34:06.998 [ZeusMonitor] Monitor started.
2022-12-06 20:34:06.998 [ZeusMonitor] Running indefinitely. 2022-12-06 20:34:06.998 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:34:06.998 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e79+gpu0.power.log
2022-12-06 15:34:50,651 [ZeusDataLoader(train)] train epoch 79 done: time=43.90 energy=5832.68
2022-12-06 15:34:50,655 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 4.6430
Training Epoch: 78 [2048/50176]	Loss: 4.6214
Training Epoch: 78 [3072/50176]	Loss: 4.6488
Training Epoch: 78 [4096/50176]	Loss: 4.6336
Training Epoch: 78 [5120/50176]	Loss: 4.6577
Training Epoch: 78 [6144/50176]	Loss: 4.6402
Training Epoch: 78 [7168/50176]	Loss: 4.6530
Training Epoch: 78 [8192/50176]	Loss: 4.6316
Training Epoch: 78 [9216/50176]	Loss: 4.6382
Training Epoch: 78 [10240/50176]	Loss: 4.6479
Training Epoch: 78 [11264/50176]	Loss: 4.6369
Training Epoch: 78 [12288/50176]	Loss: 4.6275
Training Epoch: 78 [13312/50176]	Loss: 4.6365
Training Epoch: 78 [14336/50176]	Loss: 4.6393
Training Epoch: 78 [15360/50176]	Loss: 4.6456
Training Epoch: 78 [16384/50176]	Loss: 4.6431
Training Epoch: 78 [17408/50176]	Loss: 4.6457
Training Epoch: 78 [18432/50176]	Loss: 4.6298
Training Epoch: 78 [19456/50176]	Loss: 4.6421
Training Epoch: 78 [20480/50176]	Loss: 4.6440
Training Epoch: 78 [21504/50176]	Loss: 4.6489
Training Epoch: 78 [22528/50176]	Loss: 4.6368
Training Epoch: 78 [23552/50176]	Loss: 4.6584
Training Epoch: 78 [24576/50176]	Loss: 4.6409
Training Epoch: 78 [25600/50176]	Loss: 4.6329
Training Epoch: 78 [26624/50176]	Loss: 4.6427
Training Epoch: 78 [27648/50176]	Loss: 4.6377
Training Epoch: 78 [28672/50176]	Loss: 4.6440
Training Epoch: 78 [29696/50176]	Loss: 4.6404
Training Epoch: 78 [30720/50176]	Loss: 4.6406
Training Epoch: 78 [31744/50176]	Loss: 4.6301
Training Epoch: 78 [32768/50176]	Loss: 4.6308
Training Epoch: 78 [33792/50176]	Loss: 4.6305
Training Epoch: 78 [34816/50176]	Loss: 4.6289
Training Epoch: 78 [35840/50176]	Loss: 4.6351
Training Epoch: 78 [36864/50176]	Loss: 4.6504
Training Epoch: 78 [37888/50176]	Loss: 4.6429
Training Epoch: 78 [38912/50176]	Loss: 4.6511
Training Epoch: 78 [39936/50176]	Loss: 4.6352
Training Epoch: 78 [40960/50176]	Loss: 4.6398
Training Epoch: 78 [41984/50176]	Loss: 4.6259
Training Epoch: 78 [43008/50176]	Loss: 4.6360
Training Epoch: 78 [44032/50176]	Loss: 4.6596
Training Epoch: 78 [45056/50176]	Loss: 4.6532
Training Epoch: 78 [46080/50176]	Loss: 4.6475
Training Epoch: 78 [47104/50176]	Loss: 4.6351
Training Epoch: 78 [48128/50176]	Loss: 4.6351
Training Epoch: 78 [49152/50176]	Loss: 4.6333
Training Epoch: 78 [50176/50176]	Loss: 4.6553
2022-12-06 20:34:54.369 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:34:54,405 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.74 energy=463.87
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Up to epoch 79: time=3773.78, energy=497872.29, cost=579141.81
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Expected next epoch: time=3820.39, energy=504238.59, cost=586403.04
2022-12-06 15:34:54,406 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 15.0071, Accuracy: 0.0098
2022-12-06 15:34:54,599 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:34:54,600 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:34:54.603 [ZeusMonitor] Monitor started.
2022-12-06 20:34:54.603 [ZeusMonitor] Running indefinitely. 2022-12-06 20:34:54.603 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:34:54.603 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e80+gpu0.power.log
2022-12-06 15:35:38,148 [ZeusDataLoader(train)] train epoch 80 done: time=43.73 energy=5824.17
2022-12-06 15:35:38,152 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 4.6450
Training Epoch: 79 [2048/50176]	Loss: 4.6475
Training Epoch: 79 [3072/50176]	Loss: 4.6442
Training Epoch: 79 [4096/50176]	Loss: 4.6411
Training Epoch: 79 [5120/50176]	Loss: 4.6319
Training Epoch: 79 [6144/50176]	Loss: 4.6284
Training Epoch: 79 [7168/50176]	Loss: 4.6372
Training Epoch: 79 [8192/50176]	Loss: 4.6415
Training Epoch: 79 [9216/50176]	Loss: 4.6464
Training Epoch: 79 [10240/50176]	Loss: 4.6444
Training Epoch: 79 [11264/50176]	Loss: 4.6419
Training Epoch: 79 [12288/50176]	Loss: 4.6568
Training Epoch: 79 [13312/50176]	Loss: 4.6342
Training Epoch: 79 [14336/50176]	Loss: 4.6321
Training Epoch: 79 [15360/50176]	Loss: 4.6430
Training Epoch: 79 [16384/50176]	Loss: 4.6412
Training Epoch: 79 [17408/50176]	Loss: 4.6359
Training Epoch: 79 [18432/50176]	Loss: 4.6441
Training Epoch: 79 [19456/50176]	Loss: 4.6479
Training Epoch: 79 [20480/50176]	Loss: 4.6454
Training Epoch: 79 [21504/50176]	Loss: 4.6384
Training Epoch: 79 [22528/50176]	Loss: 4.6462
Training Epoch: 79 [23552/50176]	Loss: 4.6379
Training Epoch: 79 [24576/50176]	Loss: 4.6375
Training Epoch: 79 [25600/50176]	Loss: 4.6415
Training Epoch: 79 [26624/50176]	Loss: 4.6372
Training Epoch: 79 [27648/50176]	Loss: 4.6446
Training Epoch: 79 [28672/50176]	Loss: 4.6266
Training Epoch: 79 [29696/50176]	Loss: 4.6331
Training Epoch: 79 [30720/50176]	Loss: 4.6365
Training Epoch: 79 [31744/50176]	Loss: 4.6491
Training Epoch: 79 [32768/50176]	Loss: 4.6345
Training Epoch: 79 [33792/50176]	Loss: 4.6291
Training Epoch: 79 [34816/50176]	Loss: 4.6388
Training Epoch: 79 [35840/50176]	Loss: 4.6358
Training Epoch: 79 [36864/50176]	Loss: 4.6300
Training Epoch: 79 [37888/50176]	Loss: 4.6445
Training Epoch: 79 [38912/50176]	Loss: 4.6261
Training Epoch: 79 [39936/50176]	Loss: 4.6496
Training Epoch: 79 [40960/50176]	Loss: 4.6279
Training Epoch: 79 [41984/50176]	Loss: 4.6347
Training Epoch: 79 [43008/50176]	Loss: 4.6429
Training Epoch: 79 [44032/50176]	Loss: 4.6450
Training Epoch: 79 [45056/50176]	Loss: 4.6306
Training Epoch: 79 [46080/50176]	Loss: 4.6322
Training Epoch: 79 [47104/50176]	Loss: 4.6369
Training Epoch: 79 [48128/50176]	Loss: 4.6413
Training Epoch: 79 [49152/50176]	Loss: 4.6255
Training Epoch: 79 [50176/50176]	Loss: 4.6397
2022-12-06 20:35:41.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:35:41,999 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.84 energy=472.50
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Up to epoch 80: time=3821.35, energy=504168.97, cost=586452.91
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Expected next epoch: time=3867.96, energy=510535.26, cost=593714.14
2022-12-06 15:35:42,000 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 7978.9542, Accuracy: 0.0098
2022-12-06 15:35:42,233 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:35:42,233 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:35:42.235 [ZeusMonitor] Monitor started.
2022-12-06 20:35:42.235 [ZeusMonitor] Running indefinitely. 2022-12-06 20:35:42.235 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:35:42.235 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e81+gpu0.power.log
2022-12-06 15:36:25,657 [ZeusDataLoader(train)] train epoch 81 done: time=43.65 energy=5817.52
2022-12-06 15:36:25,660 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 4.6400
Training Epoch: 80 [2048/50176]	Loss: 4.6257
Training Epoch: 80 [3072/50176]	Loss: 4.6336
Training Epoch: 80 [4096/50176]	Loss: 4.6451
Training Epoch: 80 [5120/50176]	Loss: 4.6332
Training Epoch: 80 [6144/50176]	Loss: 4.6450
Training Epoch: 80 [7168/50176]	Loss: 4.6351
Training Epoch: 80 [8192/50176]	Loss: 4.6402
Training Epoch: 80 [9216/50176]	Loss: 4.6459
Training Epoch: 80 [10240/50176]	Loss: 4.6251
Training Epoch: 80 [11264/50176]	Loss: 4.6341
Training Epoch: 80 [12288/50176]	Loss: 4.6428
Training Epoch: 80 [13312/50176]	Loss: 4.6473
Training Epoch: 80 [14336/50176]	Loss: 4.6341
Training Epoch: 80 [15360/50176]	Loss: 4.6359
Training Epoch: 80 [16384/50176]	Loss: 4.6254
Training Epoch: 80 [17408/50176]	Loss: 4.6303
Training Epoch: 80 [18432/50176]	Loss: 4.6500
Training Epoch: 80 [19456/50176]	Loss: 4.6298
Training Epoch: 80 [20480/50176]	Loss: 4.6498
Training Epoch: 80 [21504/50176]	Loss: 4.6350
Training Epoch: 80 [22528/50176]	Loss: 4.6263
Training Epoch: 80 [23552/50176]	Loss: 4.6409
Training Epoch: 80 [24576/50176]	Loss: 4.6368
Training Epoch: 80 [25600/50176]	Loss: 4.6384
Training Epoch: 80 [26624/50176]	Loss: 4.6464
Training Epoch: 80 [27648/50176]	Loss: 4.6472
Training Epoch: 80 [28672/50176]	Loss: 4.6463
Training Epoch: 80 [29696/50176]	Loss: 4.6370
Training Epoch: 80 [30720/50176]	Loss: 4.6246
Training Epoch: 80 [31744/50176]	Loss: 4.6361
Training Epoch: 80 [32768/50176]	Loss: 4.6392
Training Epoch: 80 [33792/50176]	Loss: 4.6436
Training Epoch: 80 [34816/50176]	Loss: 4.6419
Training Epoch: 80 [35840/50176]	Loss: 4.6164
Training Epoch: 80 [36864/50176]	Loss: 4.6330
Training Epoch: 80 [37888/50176]	Loss: 4.6365
Training Epoch: 80 [38912/50176]	Loss: 4.6313
Training Epoch: 80 [39936/50176]	Loss: 4.6290
Training Epoch: 80 [40960/50176]	Loss: 4.6256
Training Epoch: 80 [41984/50176]	Loss: 4.6334
Training Epoch: 80 [43008/50176]	Loss: 4.6324
Training Epoch: 80 [44032/50176]	Loss: 4.6334
Training Epoch: 80 [45056/50176]	Loss: 4.6258
Training Epoch: 80 [46080/50176]	Loss: 4.6309
Training Epoch: 80 [47104/50176]	Loss: 4.6319
Training Epoch: 80 [48128/50176]	Loss: 4.6335
Training Epoch: 80 [49152/50176]	Loss: 4.6384
Training Epoch: 80 [50176/50176]	Loss: 4.6473
2022-12-06 20:36:29.398 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:36:29,452 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.78 energy=484.58
2022-12-06 15:36:29,452 [ZeusDataLoader(train)] Up to epoch 81: time=3868.79, energy=510471.06, cost=593754.34
2022-12-06 15:36:29,452 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:36:29,453 [ZeusDataLoader(train)] Expected next epoch: time=3915.39, energy=516837.36, cost=601015.58
2022-12-06 15:36:29,453 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:36:29,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:36:29,702 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:36:29.704 [ZeusMonitor] Monitor started.
2022-12-06 20:36:29.704 [ZeusMonitor] Running indefinitely. 2022-12-06 20:36:29.704 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:36:29.704 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e82+gpu0.power.log
2022-12-06 15:37:13,296 [ZeusDataLoader(train)] train epoch 82 done: time=43.84 energy=5832.14
2022-12-06 15:37:13,300 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 4.6379
Training Epoch: 81 [2048/50176]	Loss: 4.6294
Training Epoch: 81 [3072/50176]	Loss: 4.6229
Training Epoch: 81 [4096/50176]	Loss: 4.6288
Training Epoch: 81 [5120/50176]	Loss: 4.6340
Training Epoch: 81 [6144/50176]	Loss: 4.6439
Training Epoch: 81 [7168/50176]	Loss: 4.6299
Training Epoch: 81 [8192/50176]	Loss: 4.6309
Training Epoch: 81 [9216/50176]	Loss: 4.6347
Training Epoch: 81 [10240/50176]	Loss: 4.6519
Training Epoch: 81 [11264/50176]	Loss: 4.6430
Training Epoch: 81 [12288/50176]	Loss: 4.6358
Training Epoch: 81 [13312/50176]	Loss: 4.6249
Training Epoch: 81 [14336/50176]	Loss: 4.6456
Training Epoch: 81 [15360/50176]	Loss: 4.6384
Training Epoch: 81 [16384/50176]	Loss: 4.6532
Training Epoch: 81 [17408/50176]	Loss: 4.6586
Training Epoch: 81 [18432/50176]	Loss: 4.6359
Training Epoch: 81 [19456/50176]	Loss: 4.6471
Training Epoch: 81 [20480/50176]	Loss: 4.6406
Training Epoch: 81 [21504/50176]	Loss: 4.6266
Training Epoch: 81 [22528/50176]	Loss: 4.6433
Training Epoch: 81 [23552/50176]	Loss: 4.6203
Training Epoch: 81 [24576/50176]	Loss: 4.6380
Training Epoch: 81 [25600/50176]	Loss: 4.6445
Training Epoch: 81 [26624/50176]	Loss: 4.6281
Training Epoch: 81 [27648/50176]	Loss: 4.6395
Training Epoch: 81 [28672/50176]	Loss: 4.6511
Training Epoch: 81 [29696/50176]	Loss: 4.6316
Training Epoch: 81 [30720/50176]	Loss: 4.6312
Training Epoch: 81 [31744/50176]	Loss: 4.6437
Training Epoch: 81 [32768/50176]	Loss: 4.6504
Training Epoch: 81 [33792/50176]	Loss: 4.6321
Training Epoch: 81 [34816/50176]	Loss: 4.6340
Training Epoch: 81 [35840/50176]	Loss: 4.6303
Training Epoch: 81 [36864/50176]	Loss: 4.6341
Training Epoch: 81 [37888/50176]	Loss: 4.6319
Training Epoch: 81 [38912/50176]	Loss: 4.6400
Training Epoch: 81 [39936/50176]	Loss: 4.6455
Training Epoch: 81 [40960/50176]	Loss: 4.6421
Training Epoch: 81 [41984/50176]	Loss: 4.6271
Training Epoch: 81 [43008/50176]	Loss: 4.6222
Training Epoch: 81 [44032/50176]	Loss: 4.6403
Training Epoch: 81 [45056/50176]	Loss: 4.6459
Training Epoch: 81 [46080/50176]	Loss: 4.6401
Training Epoch: 81 [47104/50176]	Loss: 4.6443
Training Epoch: 81 [48128/50176]	Loss: 4.6482
Training Epoch: 81 [49152/50176]	Loss: 4.6255
Training Epoch: 81 [50176/50176]	Loss: 4.6427
2022-12-06 20:37:17.058 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:37:17,114 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.81 energy=487.61
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Up to epoch 82: time=3916.43, energy=516790.81, cost=601082.86
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Expected next epoch: time=3963.03, energy=523157.11, cost=608344.09
2022-12-06 15:37:17,116 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 60.3389, Accuracy: 0.0098
2022-12-06 15:37:17,354 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:37:17,355 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:37:17.357 [ZeusMonitor] Monitor started.
2022-12-06 20:37:17.357 [ZeusMonitor] Running indefinitely. 2022-12-06 20:37:17.357 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:37:17.357 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e83+gpu0.power.log
2022-12-06 15:38:00,842 [ZeusDataLoader(train)] train epoch 83 done: time=43.72 energy=5826.18
2022-12-06 15:38:00,845 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 4.6476
Training Epoch: 82 [2048/50176]	Loss: 4.6488
Training Epoch: 82 [3072/50176]	Loss: 4.6366
Training Epoch: 82 [4096/50176]	Loss: 4.6509
Training Epoch: 82 [5120/50176]	Loss: 4.6473
Training Epoch: 82 [6144/50176]	Loss: 4.6430
Training Epoch: 82 [7168/50176]	Loss: 4.6396
Training Epoch: 82 [8192/50176]	Loss: 4.6324
Training Epoch: 82 [9216/50176]	Loss: 4.6379
Training Epoch: 82 [10240/50176]	Loss: 4.6371
Training Epoch: 82 [11264/50176]	Loss: 4.6336
Training Epoch: 82 [12288/50176]	Loss: 4.6399
Training Epoch: 82 [13312/50176]	Loss: 4.6407
Training Epoch: 82 [14336/50176]	Loss: 4.6467
Training Epoch: 82 [15360/50176]	Loss: 4.6486
Training Epoch: 82 [16384/50176]	Loss: 4.6409
Training Epoch: 82 [17408/50176]	Loss: 4.6493
Training Epoch: 82 [18432/50176]	Loss: 4.6503
Training Epoch: 82 [19456/50176]	Loss: 4.6479
Training Epoch: 82 [20480/50176]	Loss: 4.6434
Training Epoch: 82 [21504/50176]	Loss: 4.6375
Training Epoch: 82 [22528/50176]	Loss: 4.6514
Training Epoch: 82 [23552/50176]	Loss: 4.6350
Training Epoch: 82 [24576/50176]	Loss: 4.6328
Training Epoch: 82 [25600/50176]	Loss: 4.6545
Training Epoch: 82 [26624/50176]	Loss: 4.6304
Training Epoch: 82 [27648/50176]	Loss: 4.6466
Training Epoch: 82 [28672/50176]	Loss: 4.6350
Training Epoch: 82 [29696/50176]	Loss: 4.6630
Training Epoch: 82 [30720/50176]	Loss: 4.6383
Training Epoch: 82 [31744/50176]	Loss: 4.6268
Training Epoch: 82 [32768/50176]	Loss: 4.6371
Training Epoch: 82 [33792/50176]	Loss: 4.6252
Training Epoch: 82 [34816/50176]	Loss: 4.6453
Training Epoch: 82 [35840/50176]	Loss: 4.6362
Training Epoch: 82 [36864/50176]	Loss: 4.6460
Training Epoch: 82 [37888/50176]	Loss: 4.6317
Training Epoch: 82 [38912/50176]	Loss: 4.6258
Training Epoch: 82 [39936/50176]	Loss: 4.6420
Training Epoch: 82 [40960/50176]	Loss: 4.6403
Training Epoch: 82 [41984/50176]	Loss: 4.6372
Training Epoch: 82 [43008/50176]	Loss: 4.6307
Training Epoch: 82 [44032/50176]	Loss: 4.6461
Training Epoch: 82 [45056/50176]	Loss: 4.6421
Training Epoch: 82 [46080/50176]	Loss: 4.6274
Training Epoch: 82 [47104/50176]	Loss: 4.6307
Training Epoch: 82 [48128/50176]	Loss: 4.6303
Training Epoch: 82 [49152/50176]	Loss: 4.6240
Training Epoch: 82 [50176/50176]	Loss: 4.6312
2022-12-06 20:38:04.597 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:38:04,610 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.76 energy=462.14
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Up to epoch 83: time=3963.90, energy=523079.12, cost=608381.07
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Expected next epoch: time=4010.51, energy=529445.42, cost=615642.30
2022-12-06 15:38:04,611 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 22964.5239, Accuracy: 0.0098
2022-12-06 15:38:04,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:38:04,836 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:38:04.850 [ZeusMonitor] Monitor started.
2022-12-06 20:38:04.850 [ZeusMonitor] Running indefinitely. 2022-12-06 20:38:04.850 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:38:04.850 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e84+gpu0.power.log
2022-12-06 15:38:48,532 [ZeusDataLoader(train)] train epoch 84 done: time=43.91 energy=5828.40
2022-12-06 15:38:48,535 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 4.6303
Training Epoch: 83 [2048/50176]	Loss: 4.6276
Training Epoch: 83 [3072/50176]	Loss: 4.6303
Training Epoch: 83 [4096/50176]	Loss: 4.6228
Training Epoch: 83 [5120/50176]	Loss: 4.6405
Training Epoch: 83 [6144/50176]	Loss: 4.6544
Training Epoch: 83 [7168/50176]	Loss: 4.6405
Training Epoch: 83 [8192/50176]	Loss: 4.6415
Training Epoch: 83 [9216/50176]	Loss: 4.6410
Training Epoch: 83 [10240/50176]	Loss: 4.6299
Training Epoch: 83 [11264/50176]	Loss: 4.6259
Training Epoch: 83 [12288/50176]	Loss: 4.6340
Training Epoch: 83 [13312/50176]	Loss: 4.6500
Training Epoch: 83 [14336/50176]	Loss: 4.6417
Training Epoch: 83 [15360/50176]	Loss: 4.6347
Training Epoch: 83 [16384/50176]	Loss: 4.6451
Training Epoch: 83 [17408/50176]	Loss: 4.6264
Training Epoch: 83 [18432/50176]	Loss: 4.6343
Training Epoch: 83 [19456/50176]	Loss: 4.6252
Training Epoch: 83 [20480/50176]	Loss: 4.6354
Training Epoch: 83 [21504/50176]	Loss: 4.6422
Training Epoch: 83 [22528/50176]	Loss: 4.6374
Training Epoch: 83 [23552/50176]	Loss: 4.6352
Training Epoch: 83 [24576/50176]	Loss: 4.6367
Training Epoch: 83 [25600/50176]	Loss: 4.6169
Training Epoch: 83 [26624/50176]	Loss: 4.6355
Training Epoch: 83 [27648/50176]	Loss: 4.6332
Training Epoch: 83 [28672/50176]	Loss: 4.6148
Training Epoch: 83 [29696/50176]	Loss: 4.6270
Training Epoch: 83 [30720/50176]	Loss: 4.6311
Training Epoch: 83 [31744/50176]	Loss: 4.6477
Training Epoch: 83 [32768/50176]	Loss: 4.6462
Training Epoch: 83 [33792/50176]	Loss: 4.6367
Training Epoch: 83 [34816/50176]	Loss: 4.6463
Training Epoch: 83 [35840/50176]	Loss: 4.6474
Training Epoch: 83 [36864/50176]	Loss: 4.6391
Training Epoch: 83 [37888/50176]	Loss: 4.6371
Training Epoch: 83 [38912/50176]	Loss: 4.6422
Training Epoch: 83 [39936/50176]	Loss: 4.6559
Training Epoch: 83 [40960/50176]	Loss: 4.6193
Training Epoch: 83 [41984/50176]	Loss: 4.6431
Training Epoch: 83 [43008/50176]	Loss: 4.6267
Training Epoch: 83 [44032/50176]	Loss: 4.6441
Training Epoch: 83 [45056/50176]	Loss: 4.6461
Training Epoch: 83 [46080/50176]	Loss: 4.6348
Training Epoch: 83 [47104/50176]	Loss: 4.6410
Training Epoch: 83 [48128/50176]	Loss: 4.6333
Training Epoch: 83 [49152/50176]	Loss: 4.6451
Training Epoch: 83 [50176/50176]	Loss: 4.6425
2022-12-06 20:38:52.323 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:38:52,367 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.82 energy=474.51
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Up to epoch 84: time=4011.64, energy=529382.03, cost=615709.45
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Expected next epoch: time=4058.25, energy=535748.32, cost=622970.69
2022-12-06 15:38:52,368 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 18148.9215, Accuracy: 0.0098
2022-12-06 15:38:52,619 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:38:52,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:38:52.621 [ZeusMonitor] Monitor started.
2022-12-06 20:38:52.621 [ZeusMonitor] Running indefinitely. 2022-12-06 20:38:52.621 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:38:52.621 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e85+gpu0.power.log
2022-12-06 15:39:36,215 [ZeusDataLoader(train)] train epoch 85 done: time=43.84 energy=5836.19
2022-12-06 15:39:36,218 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 4.6403
Training Epoch: 84 [2048/50176]	Loss: 4.6621
Training Epoch: 84 [3072/50176]	Loss: 4.6352
Training Epoch: 84 [4096/50176]	Loss: 4.6605
Training Epoch: 84 [5120/50176]	Loss: 4.6568
Training Epoch: 84 [6144/50176]	Loss: 4.6435
Training Epoch: 84 [7168/50176]	Loss: 4.6489
Training Epoch: 84 [8192/50176]	Loss: 4.6314
Training Epoch: 84 [9216/50176]	Loss: 4.6336
Training Epoch: 84 [10240/50176]	Loss: 4.6581
Training Epoch: 84 [11264/50176]	Loss: 4.6397
Training Epoch: 84 [12288/50176]	Loss: 4.6428
Training Epoch: 84 [13312/50176]	Loss: 4.6518
Training Epoch: 84 [14336/50176]	Loss: 4.6396
Training Epoch: 84 [15360/50176]	Loss: 4.6395
Training Epoch: 84 [16384/50176]	Loss: 4.6295
Training Epoch: 84 [17408/50176]	Loss: 4.6344
Training Epoch: 84 [18432/50176]	Loss: 4.6443
Training Epoch: 84 [19456/50176]	Loss: 4.6338
Training Epoch: 84 [20480/50176]	Loss: 4.6395
Training Epoch: 84 [21504/50176]	Loss: 4.6383
Training Epoch: 84 [22528/50176]	Loss: 4.6310
Training Epoch: 84 [23552/50176]	Loss: 4.6277
Training Epoch: 84 [24576/50176]	Loss: 4.6406
Training Epoch: 84 [25600/50176]	Loss: 4.6423
Training Epoch: 84 [26624/50176]	Loss: 4.6288
Training Epoch: 84 [27648/50176]	Loss: 4.6336
Training Epoch: 84 [28672/50176]	Loss: 4.6307
Training Epoch: 84 [29696/50176]	Loss: 4.6306
Training Epoch: 84 [30720/50176]	Loss: 4.6269
Training Epoch: 84 [31744/50176]	Loss: 4.6323
Training Epoch: 84 [32768/50176]	Loss: 4.6331
Training Epoch: 84 [33792/50176]	Loss: 4.6387
Training Epoch: 84 [34816/50176]	Loss: 4.6383
Training Epoch: 84 [35840/50176]	Loss: 4.6353
Training Epoch: 84 [36864/50176]	Loss: 4.6291
Training Epoch: 84 [37888/50176]	Loss: 4.6404
Training Epoch: 84 [38912/50176]	Loss: 4.6366
Training Epoch: 84 [39936/50176]	Loss: 4.6265
Training Epoch: 84 [40960/50176]	Loss: 4.6266
Training Epoch: 84 [41984/50176]	Loss: 4.6285
Training Epoch: 84 [43008/50176]	Loss: 4.6371
Training Epoch: 84 [44032/50176]	Loss: 4.6419
Training Epoch: 84 [45056/50176]	Loss: 4.6603
Training Epoch: 84 [46080/50176]	Loss: 4.6489
Training Epoch: 84 [47104/50176]	Loss: 4.6329
Training Epoch: 84 [48128/50176]	Loss: 4.6351
Training Epoch: 84 [49152/50176]	Loss: 4.6221
Training Epoch: 84 [50176/50176]	Loss: 4.6410
2022-12-06 20:39:39.970 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:39:40,026 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.80 energy=476.90
2022-12-06 15:39:40,026 [ZeusDataLoader(train)] Up to epoch 85: time=4059.28, energy=535695.12, cost=623034.42
2022-12-06 15:39:40,027 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:39:40,027 [ZeusDataLoader(train)] Expected next epoch: time=4105.89, energy=542061.41, cost=630295.65
2022-12-06 15:39:40,028 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 3550.1572, Accuracy: 0.0098
2022-12-06 15:39:40,284 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:39:40,285 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:39:40.287 [ZeusMonitor] Monitor started.
2022-12-06 20:39:40.287 [ZeusMonitor] Running indefinitely. 2022-12-06 20:39:40.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:39:40.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e86+gpu0.power.log
2022-12-06 15:40:23,969 [ZeusDataLoader(train)] train epoch 86 done: time=43.93 energy=5839.47
2022-12-06 15:40:23,972 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 4.6509
Training Epoch: 85 [2048/50176]	Loss: 4.6556
Training Epoch: 85 [3072/50176]	Loss: 4.6643
Training Epoch: 85 [4096/50176]	Loss: 4.6609
Training Epoch: 85 [5120/50176]	Loss: 4.6331
Training Epoch: 85 [6144/50176]	Loss: 4.6349
Training Epoch: 85 [7168/50176]	Loss: 4.6321
Training Epoch: 85 [8192/50176]	Loss: 4.6387
Training Epoch: 85 [9216/50176]	Loss: 4.6388
Training Epoch: 85 [10240/50176]	Loss: 4.6471
Training Epoch: 85 [11264/50176]	Loss: 4.6434
Training Epoch: 85 [12288/50176]	Loss: 4.6415
Training Epoch: 85 [13312/50176]	Loss: 4.6304
Training Epoch: 85 [14336/50176]	Loss: 4.6323
Training Epoch: 85 [15360/50176]	Loss: 4.6515
Training Epoch: 85 [16384/50176]	Loss: 4.6389
Training Epoch: 85 [17408/50176]	Loss: 4.6418
Training Epoch: 85 [18432/50176]	Loss: 4.6313
Training Epoch: 85 [19456/50176]	Loss: 4.6392
Training Epoch: 85 [20480/50176]	Loss: 4.6305
Training Epoch: 85 [21504/50176]	Loss: 4.6358
Training Epoch: 85 [22528/50176]	Loss: 4.6424
Training Epoch: 85 [23552/50176]	Loss: 4.6388
Training Epoch: 85 [24576/50176]	Loss: 4.6369
Training Epoch: 85 [25600/50176]	Loss: 4.6401
Training Epoch: 85 [26624/50176]	Loss: 4.6507
Training Epoch: 85 [27648/50176]	Loss: 4.6407
Training Epoch: 85 [28672/50176]	Loss: 4.6217
Training Epoch: 85 [29696/50176]	Loss: 4.6388
Training Epoch: 85 [30720/50176]	Loss: 4.6491
Training Epoch: 85 [31744/50176]	Loss: 4.6347
Training Epoch: 85 [32768/50176]	Loss: 4.6447
Training Epoch: 85 [33792/50176]	Loss: 4.6309
Training Epoch: 85 [34816/50176]	Loss: 4.6394
Training Epoch: 85 [35840/50176]	Loss: 4.6235
Training Epoch: 85 [36864/50176]	Loss: 4.6353
Training Epoch: 85 [37888/50176]	Loss: 4.6412
Training Epoch: 85 [38912/50176]	Loss: 4.6558
Training Epoch: 85 [39936/50176]	Loss: 4.6478
Training Epoch: 85 [40960/50176]	Loss: 4.6543
Training Epoch: 85 [41984/50176]	Loss: 4.6443
Training Epoch: 85 [43008/50176]	Loss: 4.6265
Training Epoch: 85 [44032/50176]	Loss: 4.6450
Training Epoch: 85 [45056/50176]	Loss: 4.6258
Training Epoch: 85 [46080/50176]	Loss: 4.6465
Training Epoch: 85 [47104/50176]	Loss: 4.6385
Training Epoch: 85 [48128/50176]	Loss: 4.6495
Training Epoch: 85 [49152/50176]	Loss: 4.6454
Training Epoch: 85 [50176/50176]	Loss: 4.6434
2022-12-06 20:40:27.689 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:40:27,708 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.73 energy=465.39
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Up to epoch 86: time=4106.94, energy=541999.97, cost=630357.20
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Expected next epoch: time=4153.55, energy=548366.27, cost=637618.43
2022-12-06 15:40:27,709 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 11342.6416, Accuracy: 0.0098
2022-12-06 15:40:27,954 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:40:27,955 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:40:27.957 [ZeusMonitor] Monitor started.
2022-12-06 20:40:27.957 [ZeusMonitor] Running indefinitely. 2022-12-06 20:40:27.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:40:27.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e87+gpu0.power.log
2022-12-06 15:41:11,577 [ZeusDataLoader(train)] train epoch 87 done: time=43.86 energy=5829.46
2022-12-06 15:41:11,581 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 4.6341
Training Epoch: 86 [2048/50176]	Loss: 4.6204
Training Epoch: 86 [3072/50176]	Loss: 4.6428
Training Epoch: 86 [4096/50176]	Loss: 4.6418
Training Epoch: 86 [5120/50176]	Loss: 4.6481
Training Epoch: 86 [6144/50176]	Loss: 4.6380
Training Epoch: 86 [7168/50176]	Loss: 4.6455
Training Epoch: 86 [8192/50176]	Loss: 4.6355
Training Epoch: 86 [9216/50176]	Loss: 4.6480
Training Epoch: 86 [10240/50176]	Loss: 4.6411
Training Epoch: 86 [11264/50176]	Loss: 4.6263
Training Epoch: 86 [12288/50176]	Loss: 4.6265
Training Epoch: 86 [13312/50176]	Loss: 4.6343
Training Epoch: 86 [14336/50176]	Loss: 4.6345
Training Epoch: 86 [15360/50176]	Loss: 4.6473
Training Epoch: 86 [16384/50176]	Loss: 4.6371
Training Epoch: 86 [17408/50176]	Loss: 4.6533
Training Epoch: 86 [18432/50176]	Loss: 4.6469
Training Epoch: 86 [19456/50176]	Loss: 4.6361
Training Epoch: 86 [20480/50176]	Loss: 4.6326
Training Epoch: 86 [21504/50176]	Loss: 4.6478
Training Epoch: 86 [22528/50176]	Loss: 4.6514
Training Epoch: 86 [23552/50176]	Loss: 4.6398
Training Epoch: 86 [24576/50176]	Loss: 4.6529
Training Epoch: 86 [25600/50176]	Loss: 4.6480
Training Epoch: 86 [26624/50176]	Loss: 4.6531
Training Epoch: 86 [27648/50176]	Loss: 4.6476
Training Epoch: 86 [28672/50176]	Loss: 4.6194
Training Epoch: 86 [29696/50176]	Loss: 4.6354
Training Epoch: 86 [30720/50176]	Loss: 4.6421
Training Epoch: 86 [31744/50176]	Loss: 4.6405
Training Epoch: 86 [32768/50176]	Loss: 4.6272
Training Epoch: 86 [33792/50176]	Loss: 4.6367
Training Epoch: 86 [34816/50176]	Loss: 4.6552
Training Epoch: 86 [35840/50176]	Loss: 4.6457
Training Epoch: 86 [36864/50176]	Loss: 4.6419
Training Epoch: 86 [37888/50176]	Loss: 4.6345
Training Epoch: 86 [38912/50176]	Loss: 4.6374
Training Epoch: 86 [39936/50176]	Loss: 4.6290
Training Epoch: 86 [40960/50176]	Loss: 4.6561
Training Epoch: 86 [41984/50176]	Loss: 4.6473
Training Epoch: 86 [43008/50176]	Loss: 4.6552
Training Epoch: 86 [44032/50176]	Loss: 4.6380
Training Epoch: 86 [45056/50176]	Loss: 4.6373
Training Epoch: 86 [46080/50176]	Loss: 4.6404
Training Epoch: 86 [47104/50176]	Loss: 4.6467
Training Epoch: 86 [48128/50176]	Loss: 4.6216
Training Epoch: 86 [49152/50176]	Loss: 4.6301
Training Epoch: 86 [50176/50176]	Loss: 4.6388
2022-12-06 20:41:15.375 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:41:15,398 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.81 energy=479.72
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Up to epoch 87: time=4154.61, energy=548309.15, cost=637682.81
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Expected next epoch: time=4201.22, energy=554675.44, cost=644944.05
2022-12-06 15:41:15,399 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 1051.6934, Accuracy: 0.0098
2022-12-06 15:41:15,585 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:41:15,586 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:41:15.589 [ZeusMonitor] Monitor started.
2022-12-06 20:41:15.590 [ZeusMonitor] Running indefinitely. 2022-12-06 20:41:15.590 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:41:15.590 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e88+gpu0.power.log
2022-12-06 15:41:59,232 [ZeusDataLoader(train)] train epoch 88 done: time=43.83 energy=5836.74
2022-12-06 15:41:59,236 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 4.6589
Training Epoch: 87 [2048/50176]	Loss: 4.6500
Training Epoch: 87 [3072/50176]	Loss: 4.6394
Training Epoch: 87 [4096/50176]	Loss: 4.6331
Training Epoch: 87 [5120/50176]	Loss: 4.6292
Training Epoch: 87 [6144/50176]	Loss: 4.6508
Training Epoch: 87 [7168/50176]	Loss: 4.6425
Training Epoch: 87 [8192/50176]	Loss: 4.6402
Training Epoch: 87 [9216/50176]	Loss: 4.6672
Training Epoch: 87 [10240/50176]	Loss: 4.6455
Training Epoch: 87 [11264/50176]	Loss: 4.6623
Training Epoch: 87 [12288/50176]	Loss: 4.6270
Training Epoch: 87 [13312/50176]	Loss: 4.6530
Training Epoch: 87 [14336/50176]	Loss: 4.6342
Training Epoch: 87 [15360/50176]	Loss: 4.6314
Training Epoch: 87 [16384/50176]	Loss: 4.6425
Training Epoch: 87 [17408/50176]	Loss: 4.6485
Training Epoch: 87 [18432/50176]	Loss: 4.6406
Training Epoch: 87 [19456/50176]	Loss: 4.6381
Training Epoch: 87 [20480/50176]	Loss: 4.6377
Training Epoch: 87 [21504/50176]	Loss: 4.6407
Training Epoch: 87 [22528/50176]	Loss: 4.6329
Training Epoch: 87 [23552/50176]	Loss: 4.6478
Training Epoch: 87 [24576/50176]	Loss: 4.6287
Training Epoch: 87 [25600/50176]	Loss: 4.6321
Training Epoch: 87 [26624/50176]	Loss: 4.6434
Training Epoch: 87 [27648/50176]	Loss: 4.6245
Training Epoch: 87 [28672/50176]	Loss: 4.6314
Training Epoch: 87 [29696/50176]	Loss: 4.6207
Training Epoch: 87 [30720/50176]	Loss: 4.6455
Training Epoch: 87 [31744/50176]	Loss: 4.6393
Training Epoch: 87 [32768/50176]	Loss: 4.6377
Training Epoch: 87 [33792/50176]	Loss: 4.6336
Training Epoch: 87 [34816/50176]	Loss: 4.6144
Training Epoch: 87 [35840/50176]	Loss: 4.6187
Training Epoch: 87 [36864/50176]	Loss: 4.6293
Training Epoch: 87 [37888/50176]	Loss: 4.6406
Training Epoch: 87 [38912/50176]	Loss: 4.6338
Training Epoch: 87 [39936/50176]	Loss: 4.6345
Training Epoch: 87 [40960/50176]	Loss: 4.6378
Training Epoch: 87 [41984/50176]	Loss: 4.6398
Training Epoch: 87 [43008/50176]	Loss: 4.6344
Training Epoch: 87 [44032/50176]	Loss: 4.6472
Training Epoch: 87 [45056/50176]	Loss: 4.6447
Training Epoch: 87 [46080/50176]	Loss: 4.6269
Training Epoch: 87 [47104/50176]	Loss: 4.6294
Training Epoch: 87 [48128/50176]	Loss: 4.6385
Training Epoch: 87 [49152/50176]	Loss: 4.6375
Training Epoch: 87 [50176/50176]	Loss: 4.6320
2022-12-06 20:42:02.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:42:03,010 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.77 energy=463.21
2022-12-06 15:42:03,010 [ZeusDataLoader(train)] Up to epoch 88: time=4202.20, energy=554609.09, cost=644997.08
2022-12-06 15:42:03,011 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:42:03,011 [ZeusDataLoader(train)] Expected next epoch: time=4248.81, energy=560975.39, cost=652258.31
2022-12-06 15:42:03,012 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:42:03,281 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:42:03,282 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:42:03.296 [ZeusMonitor] Monitor started.
2022-12-06 20:42:03.296 [ZeusMonitor] Running indefinitely. 2022-12-06 20:42:03.296 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:42:03.296 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e89+gpu0.power.log
2022-12-06 15:42:47,451 [ZeusDataLoader(train)] train epoch 89 done: time=44.43 energy=5877.23
2022-12-06 15:42:47,454 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 4.6489
Training Epoch: 88 [2048/50176]	Loss: 4.6363
Training Epoch: 88 [3072/50176]	Loss: 4.6530
Training Epoch: 88 [4096/50176]	Loss: 4.6353
Training Epoch: 88 [5120/50176]	Loss: 4.6312
Training Epoch: 88 [6144/50176]	Loss: 4.6349
Training Epoch: 88 [7168/50176]	Loss: 4.6428
Training Epoch: 88 [8192/50176]	Loss: 4.6436
Training Epoch: 88 [9216/50176]	Loss: 4.6374
Training Epoch: 88 [10240/50176]	Loss: 4.6455
Training Epoch: 88 [11264/50176]	Loss: 4.6332
Training Epoch: 88 [12288/50176]	Loss: 4.6416
Training Epoch: 88 [13312/50176]	Loss: 4.6475
Training Epoch: 88 [14336/50176]	Loss: 4.6490
Training Epoch: 88 [15360/50176]	Loss: 4.6421
Training Epoch: 88 [16384/50176]	Loss: 4.6398
Training Epoch: 88 [17408/50176]	Loss: 4.6370
Training Epoch: 88 [18432/50176]	Loss: 4.6529
Training Epoch: 88 [19456/50176]	Loss: 4.6350
Training Epoch: 88 [20480/50176]	Loss: 4.6321
Training Epoch: 88 [21504/50176]	Loss: 4.6395
Training Epoch: 88 [22528/50176]	Loss: 4.6315
Training Epoch: 88 [23552/50176]	Loss: 4.6340
Training Epoch: 88 [24576/50176]	Loss: 4.6294
Training Epoch: 88 [25600/50176]	Loss: 4.6388
Training Epoch: 88 [26624/50176]	Loss: 4.6279
Training Epoch: 88 [27648/50176]	Loss: 4.6363
Training Epoch: 88 [28672/50176]	Loss: 4.6400
Training Epoch: 88 [29696/50176]	Loss: 4.6484
Training Epoch: 88 [30720/50176]	Loss: 4.6467
Training Epoch: 88 [31744/50176]	Loss: 4.6433
Training Epoch: 88 [32768/50176]	Loss: 4.6239
Training Epoch: 88 [33792/50176]	Loss: 4.6556
Training Epoch: 88 [34816/50176]	Loss: 4.6387
Training Epoch: 88 [35840/50176]	Loss: 4.6480
Training Epoch: 88 [36864/50176]	Loss: 4.6283
Training Epoch: 88 [37888/50176]	Loss: 4.6276
Training Epoch: 88 [38912/50176]	Loss: 4.6182
Training Epoch: 88 [39936/50176]	Loss: 4.6297
Training Epoch: 88 [40960/50176]	Loss: 4.6545
Training Epoch: 88 [41984/50176]	Loss: 4.6512
Training Epoch: 88 [43008/50176]	Loss: 4.6372
Training Epoch: 88 [44032/50176]	Loss: 4.6398
Training Epoch: 88 [45056/50176]	Loss: 4.6312
Training Epoch: 88 [46080/50176]	Loss: 4.6382
Training Epoch: 88 [47104/50176]	Loss: 4.6350
Training Epoch: 88 [48128/50176]	Loss: 4.6290
Training Epoch: 88 [49152/50176]	Loss: 4.6353
Training Epoch: 88 [50176/50176]	Loss: 4.6476
2022-12-06 20:42:51.292 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:42:51,333 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.87 energy=476.94
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Up to epoch 89: time=4250.50, energy=560963.26, cost=652400.56
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Expected next epoch: time=4297.11, energy=567329.55, cost=659661.80
2022-12-06 15:42:51,334 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 14242.4237, Accuracy: 0.0098
2022-12-06 15:42:51,586 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:42:51,586 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:42:51.588 [ZeusMonitor] Monitor started.
2022-12-06 20:42:51.588 [ZeusMonitor] Running indefinitely. 2022-12-06 20:42:51.588 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:42:51.588 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e90+gpu0.power.log
2022-12-06 15:43:36,016 [ZeusDataLoader(train)] train epoch 90 done: time=44.67 energy=5898.26
2022-12-06 15:43:36,019 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 4.6310
Training Epoch: 89 [2048/50176]	Loss: 4.6510
Training Epoch: 89 [3072/50176]	Loss: 4.6328
Training Epoch: 89 [4096/50176]	Loss: 4.6407
Training Epoch: 89 [5120/50176]	Loss: 4.6461
Training Epoch: 89 [6144/50176]	Loss: 4.6516
Training Epoch: 89 [7168/50176]	Loss: 4.6362
Training Epoch: 89 [8192/50176]	Loss: 4.6327
Training Epoch: 89 [9216/50176]	Loss: 4.6417
Training Epoch: 89 [10240/50176]	Loss: 4.6455
Training Epoch: 89 [11264/50176]	Loss: 4.6442
Training Epoch: 89 [12288/50176]	Loss: 4.6398
Training Epoch: 89 [13312/50176]	Loss: 4.6313
Training Epoch: 89 [14336/50176]	Loss: 4.6261
Training Epoch: 89 [15360/50176]	Loss: 4.6502
Training Epoch: 89 [16384/50176]	Loss: 4.6280
Training Epoch: 89 [17408/50176]	Loss: 4.6575
Training Epoch: 89 [18432/50176]	Loss: 4.6283
Training Epoch: 89 [19456/50176]	Loss: 4.6356
Training Epoch: 89 [20480/50176]	Loss: 4.6209
Training Epoch: 89 [21504/50176]	Loss: 4.6357
Training Epoch: 89 [22528/50176]	Loss: 4.6341
Training Epoch: 89 [23552/50176]	Loss: 4.6461
Training Epoch: 89 [24576/50176]	Loss: 4.6360
Training Epoch: 89 [25600/50176]	Loss: 4.6444
Training Epoch: 89 [26624/50176]	Loss: 4.6414
Training Epoch: 89 [27648/50176]	Loss: 4.6315
Training Epoch: 89 [28672/50176]	Loss: 4.6533
Training Epoch: 89 [29696/50176]	Loss: 4.6338
Training Epoch: 89 [30720/50176]	Loss: 4.6471
Training Epoch: 89 [31744/50176]	Loss: 4.6300
Training Epoch: 89 [32768/50176]	Loss: 4.6354
Training Epoch: 89 [33792/50176]	Loss: 4.6214
Training Epoch: 89 [34816/50176]	Loss: 4.6157
Training Epoch: 89 [35840/50176]	Loss: 4.6379
Training Epoch: 89 [36864/50176]	Loss: 4.6356
Training Epoch: 89 [37888/50176]	Loss: 4.6297
Training Epoch: 89 [38912/50176]	Loss: 4.6373
Training Epoch: 89 [39936/50176]	Loss: 4.6284
Training Epoch: 89 [40960/50176]	Loss: 4.6422
Training Epoch: 89 [41984/50176]	Loss: 4.6292
Training Epoch: 89 [43008/50176]	Loss: 4.6198
Training Epoch: 89 [44032/50176]	Loss: 4.6253
Training Epoch: 89 [45056/50176]	Loss: 4.6369
Training Epoch: 89 [46080/50176]	Loss: 4.6247
Training Epoch: 89 [47104/50176]	Loss: 4.6261
Training Epoch: 89 [48128/50176]	Loss: 4.6244
Training Epoch: 89 [49152/50176]	Loss: 4.6412
Training Epoch: 89 [50176/50176]	Loss: 4.6388
2022-12-06 20:43:39.776 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:43:39,789 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.76 energy=459.91
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Up to epoch 90: time=4298.94, energy=567321.44, cost=659817.72
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Expected next epoch: time=4345.54, energy=573687.73, cost=667078.96
2022-12-06 15:43:39,791 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:43:40,032 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:43:40,032 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:43:40.044 [ZeusMonitor] Monitor started.
2022-12-06 20:43:40.044 [ZeusMonitor] Running indefinitely. 2022-12-06 20:43:40.044 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:43:40.044 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e91+gpu0.power.log
2022-12-06 15:44:24,261 [ZeusDataLoader(train)] train epoch 91 done: time=44.46 energy=5873.22
2022-12-06 15:44:24,265 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 4.6429
Training Epoch: 90 [2048/50176]	Loss: 4.6325
Training Epoch: 90 [3072/50176]	Loss: 4.6235
Training Epoch: 90 [4096/50176]	Loss: 4.6224
Training Epoch: 90 [5120/50176]	Loss: 4.6429
Training Epoch: 90 [6144/50176]	Loss: 4.6361
Training Epoch: 90 [7168/50176]	Loss: 4.6234
Training Epoch: 90 [8192/50176]	Loss: 4.6462
Training Epoch: 90 [9216/50176]	Loss: 4.6315
Training Epoch: 90 [10240/50176]	Loss: 4.6342
Training Epoch: 90 [11264/50176]	Loss: 4.6238
Training Epoch: 90 [12288/50176]	Loss: 4.6466
Training Epoch: 90 [13312/50176]	Loss: 4.6494
Training Epoch: 90 [14336/50176]	Loss: 4.6354
Training Epoch: 90 [15360/50176]	Loss: 4.6242
Training Epoch: 90 [16384/50176]	Loss: 4.6369
Training Epoch: 90 [17408/50176]	Loss: 4.6333
Training Epoch: 90 [18432/50176]	Loss: 4.6471
Training Epoch: 90 [19456/50176]	Loss: 4.6292
Training Epoch: 90 [20480/50176]	Loss: 4.6393
Training Epoch: 90 [21504/50176]	Loss: 4.6418
Training Epoch: 90 [22528/50176]	Loss: 4.6343
Training Epoch: 90 [23552/50176]	Loss: 4.6376
Training Epoch: 90 [24576/50176]	Loss: 4.6363
Training Epoch: 90 [25600/50176]	Loss: 4.6308
Training Epoch: 90 [26624/50176]	Loss: 4.6371
Training Epoch: 90 [27648/50176]	Loss: 4.6433
Training Epoch: 90 [28672/50176]	Loss: 4.6607
Training Epoch: 90 [29696/50176]	Loss: 4.6454
Training Epoch: 90 [30720/50176]	Loss: 4.6356
Training Epoch: 90 [31744/50176]	Loss: 4.6274
Training Epoch: 90 [32768/50176]	Loss: 4.6431
Training Epoch: 90 [33792/50176]	Loss: 4.6453
Training Epoch: 90 [34816/50176]	Loss: 4.6392
Training Epoch: 90 [35840/50176]	Loss: 4.6304
Training Epoch: 90 [36864/50176]	Loss: 4.6427
Training Epoch: 90 [37888/50176]	Loss: 4.6369
Training Epoch: 90 [38912/50176]	Loss: 4.6367
Training Epoch: 90 [39936/50176]	Loss: 4.6309
Training Epoch: 90 [40960/50176]	Loss: 4.6383
Training Epoch: 90 [41984/50176]	Loss: 4.6420
Training Epoch: 90 [43008/50176]	Loss: 4.6311
Training Epoch: 90 [44032/50176]	Loss: 4.6341
Training Epoch: 90 [45056/50176]	Loss: 4.6249
Training Epoch: 90 [46080/50176]	Loss: 4.6420
Training Epoch: 90 [47104/50176]	Loss: 4.6322
Training Epoch: 90 [48128/50176]	Loss: 4.6406
Training Epoch: 90 [49152/50176]	Loss: 4.6459
Training Epoch: 90 [50176/50176]	Loss: 4.6267
2022-12-06 20:44:28.026 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:44:28,075 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.80 energy=476.46
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Up to epoch 91: time=4347.20, energy=573671.12, cost=667215.76
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Expected next epoch: time=4393.81, energy=580037.41, cost=674477.00
2022-12-06 15:44:28,077 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 17559.5884, Accuracy: 0.0098
2022-12-06 15:44:28,326 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:44:28,327 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:44:28.341 [ZeusMonitor] Monitor started.
2022-12-06 20:44:28.341 [ZeusMonitor] Running indefinitely. 2022-12-06 20:44:28.341 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:44:28.341 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e92+gpu0.power.log
2022-12-06 15:45:11,887 [ZeusDataLoader(train)] train epoch 92 done: time=43.80 energy=5832.56
2022-12-06 15:45:11,891 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 4.6347
Training Epoch: 91 [2048/50176]	Loss: 4.6244
Training Epoch: 91 [3072/50176]	Loss: 4.6290
Training Epoch: 91 [4096/50176]	Loss: 4.6244
Training Epoch: 91 [5120/50176]	Loss: 4.6469
Training Epoch: 91 [6144/50176]	Loss: 4.6475
Training Epoch: 91 [7168/50176]	Loss: 4.6320
Training Epoch: 91 [8192/50176]	Loss: 4.6417
Training Epoch: 91 [9216/50176]	Loss: 4.6355
Training Epoch: 91 [10240/50176]	Loss: 4.6428
Training Epoch: 91 [11264/50176]	Loss: 4.6380
Training Epoch: 91 [12288/50176]	Loss: 4.6392
Training Epoch: 91 [13312/50176]	Loss: 4.6290
Training Epoch: 91 [14336/50176]	Loss: 4.6275
Training Epoch: 91 [15360/50176]	Loss: 4.6552
Training Epoch: 91 [16384/50176]	Loss: 4.6432
Training Epoch: 91 [17408/50176]	Loss: 4.6398
Training Epoch: 91 [18432/50176]	Loss: 4.6365
Training Epoch: 91 [19456/50176]	Loss: 4.6224
Training Epoch: 91 [20480/50176]	Loss: 4.6323
Training Epoch: 91 [21504/50176]	Loss: 4.6410
Training Epoch: 91 [22528/50176]	Loss: 4.6326
Training Epoch: 91 [23552/50176]	Loss: 4.6458
Training Epoch: 91 [24576/50176]	Loss: 4.6399
Training Epoch: 91 [25600/50176]	Loss: 4.6317
Training Epoch: 91 [26624/50176]	Loss: 4.6322
Training Epoch: 91 [27648/50176]	Loss: 4.6351
Training Epoch: 91 [28672/50176]	Loss: 4.6296
Training Epoch: 91 [29696/50176]	Loss: 4.6210
Training Epoch: 91 [30720/50176]	Loss: 4.6392
Training Epoch: 91 [31744/50176]	Loss: 4.6320
Training Epoch: 91 [32768/50176]	Loss: 4.6338
Training Epoch: 91 [33792/50176]	Loss: 4.6328
Training Epoch: 91 [34816/50176]	Loss: 4.6385
Training Epoch: 91 [35840/50176]	Loss: 4.6457
Training Epoch: 91 [36864/50176]	Loss: 4.6252
Training Epoch: 91 [37888/50176]	Loss: 4.6282
Training Epoch: 91 [38912/50176]	Loss: 4.6277
Training Epoch: 91 [39936/50176]	Loss: 4.6407
Training Epoch: 91 [40960/50176]	Loss: 4.6396
Training Epoch: 91 [41984/50176]	Loss: 4.6342
Training Epoch: 91 [43008/50176]	Loss: 4.6340
Training Epoch: 91 [44032/50176]	Loss: 4.6453
Training Epoch: 91 [45056/50176]	Loss: 4.6456
Training Epoch: 91 [46080/50176]	Loss: 4.6347
Training Epoch: 91 [47104/50176]	Loss: 4.6424
Training Epoch: 91 [48128/50176]	Loss: 4.6419
Training Epoch: 91 [49152/50176]	Loss: 4.6423
Training Epoch: 91 [50176/50176]	Loss: 4.6432
2022-12-06 20:45:15.725 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:45:15,735 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.84 energy=473.44
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Up to epoch 92: time=4394.84, energy=579977.12, cost=674537.21
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Expected next epoch: time=4441.45, energy=586343.41, cost=681798.45
2022-12-06 15:45:15,736 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 9744.3790, Accuracy: 0.0098
2022-12-06 15:45:15,956 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:45:15,957 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:45:15.959 [ZeusMonitor] Monitor started.
2022-12-06 20:45:15.959 [ZeusMonitor] Running indefinitely. 2022-12-06 20:45:15.959 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:45:15.959 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e93+gpu0.power.log
2022-12-06 15:45:59,590 [ZeusDataLoader(train)] train epoch 93 done: time=43.85 energy=5837.45
2022-12-06 15:45:59,593 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 4.6322
Training Epoch: 92 [2048/50176]	Loss: 4.6397
Training Epoch: 92 [3072/50176]	Loss: 4.6340
Training Epoch: 92 [4096/50176]	Loss: 4.6115
Training Epoch: 92 [5120/50176]	Loss: 4.6373
Training Epoch: 92 [6144/50176]	Loss: 4.6476
Training Epoch: 92 [7168/50176]	Loss: 4.6327
Training Epoch: 92 [8192/50176]	Loss: 4.6362
Training Epoch: 92 [9216/50176]	Loss: 4.6293
Training Epoch: 92 [10240/50176]	Loss: 4.6200
Training Epoch: 92 [11264/50176]	Loss: 4.6340
Training Epoch: 92 [12288/50176]	Loss: 4.6264
Training Epoch: 92 [13312/50176]	Loss: 4.6378
Training Epoch: 92 [14336/50176]	Loss: 4.6259
Training Epoch: 92 [15360/50176]	Loss: 4.6475
Training Epoch: 92 [16384/50176]	Loss: 4.6417
Training Epoch: 92 [17408/50176]	Loss: 4.6432
Training Epoch: 92 [18432/50176]	Loss: 4.6354
Training Epoch: 92 [19456/50176]	Loss: 4.6336
Training Epoch: 92 [20480/50176]	Loss: 4.6312
Training Epoch: 92 [21504/50176]	Loss: 4.6368
Training Epoch: 92 [22528/50176]	Loss: 4.6585
Training Epoch: 92 [23552/50176]	Loss: 4.6419
Training Epoch: 92 [24576/50176]	Loss: 4.6361
Training Epoch: 92 [25600/50176]	Loss: 4.6343
Training Epoch: 92 [26624/50176]	Loss: 4.6336
Training Epoch: 92 [27648/50176]	Loss: 4.6364
Training Epoch: 92 [28672/50176]	Loss: 4.6298
Training Epoch: 92 [29696/50176]	Loss: 4.6372
Training Epoch: 92 [30720/50176]	Loss: 4.6419
Training Epoch: 92 [31744/50176]	Loss: 4.6292
Training Epoch: 92 [32768/50176]	Loss: 4.6394
Training Epoch: 92 [33792/50176]	Loss: 4.6281
Training Epoch: 92 [34816/50176]	Loss: 4.6335
Training Epoch: 92 [35840/50176]	Loss: 4.6242
Training Epoch: 92 [36864/50176]	Loss: 4.6447
Training Epoch: 92 [37888/50176]	Loss: 4.6250
Training Epoch: 92 [38912/50176]	Loss: 4.6316
Training Epoch: 92 [39936/50176]	Loss: 4.6353
Training Epoch: 92 [40960/50176]	Loss: 4.6247
Training Epoch: 92 [41984/50176]	Loss: 4.6394
Training Epoch: 92 [43008/50176]	Loss: 4.6224
Training Epoch: 92 [44032/50176]	Loss: 4.6314
Training Epoch: 92 [45056/50176]	Loss: 4.6330
Training Epoch: 92 [46080/50176]	Loss: 4.6277
Training Epoch: 92 [47104/50176]	Loss: 4.6362
Training Epoch: 92 [48128/50176]	Loss: 4.6395
Training Epoch: 92 [49152/50176]	Loss: 4.6271
Training Epoch: 92 [50176/50176]	Loss: 4.6304
2022-12-06 20:46:03.262 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:46:03,272 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.67 energy=453.85
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Up to epoch 93: time=4442.36, energy=586268.42, cost=681840.54
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Expected next epoch: time=4488.96, energy=592634.71, cost=689101.77
2022-12-06 15:46:03,273 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:46:03,563 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:46:03,563 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:46:03.565 [ZeusMonitor] Monitor started.
2022-12-06 20:46:03.565 [ZeusMonitor] Running indefinitely. 2022-12-06 20:46:03.565 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:46:03.565 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e94+gpu0.power.log
2022-12-06 15:46:47,150 [ZeusDataLoader(train)] train epoch 94 done: time=43.87 energy=5833.46
2022-12-06 15:46:47,154 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 4.6331
Training Epoch: 93 [2048/50176]	Loss: 4.6334
Training Epoch: 93 [3072/50176]	Loss: 4.6411
Training Epoch: 93 [4096/50176]	Loss: 4.6419
Training Epoch: 93 [5120/50176]	Loss: 4.6237
Training Epoch: 93 [6144/50176]	Loss: 4.6344
Training Epoch: 93 [7168/50176]	Loss: 4.6249
Training Epoch: 93 [8192/50176]	Loss: 4.6425
Training Epoch: 93 [9216/50176]	Loss: 4.6341
Training Epoch: 93 [10240/50176]	Loss: 4.6331
Training Epoch: 93 [11264/50176]	Loss: 4.6368
Training Epoch: 93 [12288/50176]	Loss: 4.6388
Training Epoch: 93 [13312/50176]	Loss: 4.6394
Training Epoch: 93 [14336/50176]	Loss: 4.6301
Training Epoch: 93 [15360/50176]	Loss: 4.6288
Training Epoch: 93 [16384/50176]	Loss: 4.6252
Training Epoch: 93 [17408/50176]	Loss: 4.6328
Training Epoch: 93 [18432/50176]	Loss: 4.6166
Training Epoch: 93 [19456/50176]	Loss: 4.6380
Training Epoch: 93 [20480/50176]	Loss: 4.6219
Training Epoch: 93 [21504/50176]	Loss: 4.6312
Training Epoch: 93 [22528/50176]	Loss: 4.6367
Training Epoch: 93 [23552/50176]	Loss: 4.6469
Training Epoch: 93 [24576/50176]	Loss: 4.6353
Training Epoch: 93 [25600/50176]	Loss: 4.6308
Training Epoch: 93 [26624/50176]	Loss: 4.6431
Training Epoch: 93 [27648/50176]	Loss: 4.6277
Training Epoch: 93 [28672/50176]	Loss: 4.6548
Training Epoch: 93 [29696/50176]	Loss: 4.6320
Training Epoch: 93 [30720/50176]	Loss: 4.6213
Training Epoch: 93 [31744/50176]	Loss: 4.6274
Training Epoch: 93 [32768/50176]	Loss: 4.6380
Training Epoch: 93 [33792/50176]	Loss: 4.6396
Training Epoch: 93 [34816/50176]	Loss: 4.6323
Training Epoch: 93 [35840/50176]	Loss: 4.6391
Training Epoch: 93 [36864/50176]	Loss: 4.6314
Training Epoch: 93 [37888/50176]	Loss: 4.6338
Training Epoch: 93 [38912/50176]	Loss: 4.6555
Training Epoch: 93 [39936/50176]	Loss: 4.6290
Training Epoch: 93 [40960/50176]	Loss: 4.6419
Training Epoch: 93 [41984/50176]	Loss: 4.6379
Training Epoch: 93 [43008/50176]	Loss: 4.6188
Training Epoch: 93 [44032/50176]	Loss: 4.6212
Training Epoch: 93 [45056/50176]	Loss: 4.6442
Training Epoch: 93 [46080/50176]	Loss: 4.6481
Training Epoch: 93 [47104/50176]	Loss: 4.6484
Training Epoch: 93 [48128/50176]	Loss: 4.6446
Training Epoch: 93 [49152/50176]	Loss: 4.6486
Training Epoch: 93 [50176/50176]	Loss: 4.6527
2022-12-06 20:46:50.910 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:46:50,961 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.80 energy=480.53
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Up to epoch 94: time=4490.03, energy=592582.41, cost=689168.57
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Expected next epoch: time=4536.63, energy=598948.71, cost=696429.81
2022-12-06 15:46:50,962 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 12261.9728, Accuracy: 0.0098
2022-12-06 15:46:51,186 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:46:51,187 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:46:51.201 [ZeusMonitor] Monitor started.
2022-12-06 20:46:51.201 [ZeusMonitor] Running indefinitely. 2022-12-06 20:46:51.201 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:46:51.201 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e95+gpu0.power.log
2022-12-06 15:47:34,736 [ZeusDataLoader(train)] train epoch 95 done: time=43.77 energy=5822.16
2022-12-06 15:47:34,740 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 4.6130
Training Epoch: 94 [2048/50176]	Loss: 4.6408
Training Epoch: 94 [3072/50176]	Loss: 4.6343
Training Epoch: 94 [4096/50176]	Loss: 4.6339
Training Epoch: 94 [5120/50176]	Loss: 4.6366
Training Epoch: 94 [6144/50176]	Loss: 4.6338
Training Epoch: 94 [7168/50176]	Loss: 4.6188
Training Epoch: 94 [8192/50176]	Loss: 4.6468
Training Epoch: 94 [9216/50176]	Loss: 4.6282
Training Epoch: 94 [10240/50176]	Loss: 4.6365
Training Epoch: 94 [11264/50176]	Loss: 4.6285
Training Epoch: 94 [12288/50176]	Loss: 4.6467
Training Epoch: 94 [13312/50176]	Loss: 4.6401
Training Epoch: 94 [14336/50176]	Loss: 4.6374
Training Epoch: 94 [15360/50176]	Loss: 4.6386
Training Epoch: 94 [16384/50176]	Loss: 4.6245
Training Epoch: 94 [17408/50176]	Loss: 4.6558
Training Epoch: 94 [18432/50176]	Loss: 4.6409
Training Epoch: 94 [19456/50176]	Loss: 4.6352
Training Epoch: 94 [20480/50176]	Loss: 4.6429
Training Epoch: 94 [21504/50176]	Loss: 4.6401
Training Epoch: 94 [22528/50176]	Loss: 4.6457
Training Epoch: 94 [23552/50176]	Loss: 4.6333
Training Epoch: 94 [24576/50176]	Loss: 4.6599
Training Epoch: 94 [25600/50176]	Loss: 4.6385
Training Epoch: 94 [26624/50176]	Loss: 4.6365
Training Epoch: 94 [27648/50176]	Loss: 4.6485
Training Epoch: 94 [28672/50176]	Loss: 4.6531
Training Epoch: 94 [29696/50176]	Loss: 4.6435
Training Epoch: 94 [30720/50176]	Loss: 4.6350
Training Epoch: 94 [31744/50176]	Loss: 4.6413
Training Epoch: 94 [32768/50176]	Loss: 4.6326
Training Epoch: 94 [33792/50176]	Loss: 4.6412
Training Epoch: 94 [34816/50176]	Loss: 4.6399
Training Epoch: 94 [35840/50176]	Loss: 4.6303
Training Epoch: 94 [36864/50176]	Loss: 4.6507
Training Epoch: 94 [37888/50176]	Loss: 4.6273
Training Epoch: 94 [38912/50176]	Loss: 4.6327
Training Epoch: 94 [39936/50176]	Loss: 4.6399
Training Epoch: 94 [40960/50176]	Loss: 4.6324
Training Epoch: 94 [41984/50176]	Loss: 4.6452
Training Epoch: 94 [43008/50176]	Loss: 4.6413
Training Epoch: 94 [44032/50176]	Loss: 4.6384
Training Epoch: 94 [45056/50176]	Loss: 4.6366
Training Epoch: 94 [46080/50176]	Loss: 4.6313
Training Epoch: 94 [47104/50176]	Loss: 4.6340
Training Epoch: 94 [48128/50176]	Loss: 4.6361
Training Epoch: 94 [49152/50176]	Loss: 4.6324
Training Epoch: 94 [50176/50176]	Loss: 4.6380
2022-12-06 20:47:38.446 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:47:38,456 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.71 energy=466.74
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Up to epoch 95: time=4537.50, energy=598871.31, cost=696467.04
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Expected next epoch: time=4584.11, energy=605237.61, cost=703728.28
2022-12-06 15:47:38,458 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 138.5148, Accuracy: 0.0098
2022-12-06 15:47:38,712 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:47:38,713 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:47:38.726 [ZeusMonitor] Monitor started.
2022-12-06 20:47:38.726 [ZeusMonitor] Running indefinitely. 2022-12-06 20:47:38.726 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:47:38.726 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e96+gpu0.power.log
2022-12-06 15:48:22,312 [ZeusDataLoader(train)] train epoch 96 done: time=43.85 energy=5831.84
2022-12-06 15:48:22,315 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 4.6446
Training Epoch: 95 [2048/50176]	Loss: 4.6342
Training Epoch: 95 [3072/50176]	Loss: 4.6157
Training Epoch: 95 [4096/50176]	Loss: 4.6489
Training Epoch: 95 [5120/50176]	Loss: 4.6424
Training Epoch: 95 [6144/50176]	Loss: 4.6430
Training Epoch: 95 [7168/50176]	Loss: 4.6466
Training Epoch: 95 [8192/50176]	Loss: 4.6371
Training Epoch: 95 [9216/50176]	Loss: 4.6326
Training Epoch: 95 [10240/50176]	Loss: 4.6292
Training Epoch: 95 [11264/50176]	Loss: 4.6344
Training Epoch: 95 [12288/50176]	Loss: 4.6398
Training Epoch: 95 [13312/50176]	Loss: 4.6410
Training Epoch: 95 [14336/50176]	Loss: 4.6300
Training Epoch: 95 [15360/50176]	Loss: 4.6364
Training Epoch: 95 [16384/50176]	Loss: 4.6311
Training Epoch: 95 [17408/50176]	Loss: 4.6608
Training Epoch: 95 [18432/50176]	Loss: 4.6316
Training Epoch: 95 [19456/50176]	Loss: 4.6298
Training Epoch: 95 [20480/50176]	Loss: 4.6250
Training Epoch: 95 [21504/50176]	Loss: 4.6269
Training Epoch: 95 [22528/50176]	Loss: 4.6451
Training Epoch: 95 [23552/50176]	Loss: 4.6385
Training Epoch: 95 [24576/50176]	Loss: 4.6531
Training Epoch: 95 [25600/50176]	Loss: 4.6347
Training Epoch: 95 [26624/50176]	Loss: 4.6321
Training Epoch: 95 [27648/50176]	Loss: 4.6268
Training Epoch: 95 [28672/50176]	Loss: 4.6448
Training Epoch: 95 [29696/50176]	Loss: 4.6264
Training Epoch: 95 [30720/50176]	Loss: 4.6461
Training Epoch: 95 [31744/50176]	Loss: 4.6555
Training Epoch: 95 [32768/50176]	Loss: 4.6354
Training Epoch: 95 [33792/50176]	Loss: 4.6394
Training Epoch: 95 [34816/50176]	Loss: 4.6314
Training Epoch: 95 [35840/50176]	Loss: 4.6437
Training Epoch: 95 [36864/50176]	Loss: 4.6448
Training Epoch: 95 [37888/50176]	Loss: 4.6418
Training Epoch: 95 [38912/50176]	Loss: 4.6494
Training Epoch: 95 [39936/50176]	Loss: 4.6284
Training Epoch: 95 [40960/50176]	Loss: 4.6471
Training Epoch: 95 [41984/50176]	Loss: 4.6476
Training Epoch: 95 [43008/50176]	Loss: 4.6274
Training Epoch: 95 [44032/50176]	Loss: 4.6349
Training Epoch: 95 [45056/50176]	Loss: 4.6237
Training Epoch: 95 [46080/50176]	Loss: 4.6259
Training Epoch: 95 [47104/50176]	Loss: 4.6503
Training Epoch: 95 [48128/50176]	Loss: 4.6453
Training Epoch: 95 [49152/50176]	Loss: 4.6328
Training Epoch: 95 [50176/50176]	Loss: 4.6545
2022-12-06 20:48:26.050 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:48:26,102 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.78 energy=468.42
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Up to epoch 96: time=4585.13, energy=605171.57, cost=703784.37
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Expected next epoch: time=4631.73, energy=611537.87, cost=711045.60
2022-12-06 15:48:26,103 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 2393.0713, Accuracy: 0.0098
2022-12-06 15:48:26,352 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:48:26,352 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:48:26.354 [ZeusMonitor] Monitor started.
2022-12-06 20:48:26.354 [ZeusMonitor] Running indefinitely. 2022-12-06 20:48:26.354 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:48:26.354 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e97+gpu0.power.log
2022-12-06 15:49:09,975 [ZeusDataLoader(train)] train epoch 97 done: time=43.86 energy=5837.78
2022-12-06 15:49:09,978 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 4.6290
Training Epoch: 96 [2048/50176]	Loss: 4.6382
Training Epoch: 96 [3072/50176]	Loss: 4.6161
Training Epoch: 96 [4096/50176]	Loss: 4.6483
Training Epoch: 96 [5120/50176]	Loss: 4.6376
Training Epoch: 96 [6144/50176]	Loss: 4.6377
Training Epoch: 96 [7168/50176]	Loss: 4.6484
Training Epoch: 96 [8192/50176]	Loss: 4.6340
Training Epoch: 96 [9216/50176]	Loss: 4.6366
Training Epoch: 96 [10240/50176]	Loss: 4.6242
Training Epoch: 96 [11264/50176]	Loss: 4.6455
Training Epoch: 96 [12288/50176]	Loss: 4.6428
Training Epoch: 96 [13312/50176]	Loss: 4.6347
Training Epoch: 96 [14336/50176]	Loss: 4.6339
Training Epoch: 96 [15360/50176]	Loss: 4.6388
Training Epoch: 96 [16384/50176]	Loss: 4.6364
Training Epoch: 96 [17408/50176]	Loss: 4.6395
Training Epoch: 96 [18432/50176]	Loss: 4.6192
Training Epoch: 96 [19456/50176]	Loss: 4.6282
Training Epoch: 96 [20480/50176]	Loss: 4.6342
Training Epoch: 96 [21504/50176]	Loss: 4.6501
Training Epoch: 96 [22528/50176]	Loss: 4.6384
Training Epoch: 96 [23552/50176]	Loss: 4.6372
Training Epoch: 96 [24576/50176]	Loss: 4.6461
Training Epoch: 96 [25600/50176]	Loss: 4.6468
Training Epoch: 96 [26624/50176]	Loss: 4.6344
Training Epoch: 96 [27648/50176]	Loss: 4.6359
Training Epoch: 96 [28672/50176]	Loss: 4.6447
Training Epoch: 96 [29696/50176]	Loss: 4.6371
Training Epoch: 96 [30720/50176]	Loss: 4.6319
Training Epoch: 96 [31744/50176]	Loss: 4.6392
Training Epoch: 96 [32768/50176]	Loss: 4.6432
Training Epoch: 96 [33792/50176]	Loss: 4.6322
Training Epoch: 96 [34816/50176]	Loss: 4.6381
Training Epoch: 96 [35840/50176]	Loss: 4.6437
Training Epoch: 96 [36864/50176]	Loss: 4.6432
Training Epoch: 96 [37888/50176]	Loss: 4.6304
Training Epoch: 96 [38912/50176]	Loss: 4.6427
Training Epoch: 96 [39936/50176]	Loss: 4.6299
Training Epoch: 96 [40960/50176]	Loss: 4.6383
Training Epoch: 96 [41984/50176]	Loss: 4.6342
Training Epoch: 96 [43008/50176]	Loss: 4.6362
Training Epoch: 96 [44032/50176]	Loss: 4.6362
Training Epoch: 96 [45056/50176]	Loss: 4.6381
Training Epoch: 96 [46080/50176]	Loss: 4.6516
Training Epoch: 96 [47104/50176]	Loss: 4.6343
Training Epoch: 96 [48128/50176]	Loss: 4.6437
Training Epoch: 96 [49152/50176]	Loss: 4.6298
Training Epoch: 96 [50176/50176]	Loss: 4.6282
2022-12-06 20:49:13.735 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:49:13,771 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.78 energy=473.89
2022-12-06 15:49:13,771 [ZeusDataLoader(train)] Up to epoch 97: time=4632.78, energy=611483.24, cost=711109.50
2022-12-06 15:49:13,772 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:49:13,772 [ZeusDataLoader(train)] Expected next epoch: time=4679.38, energy=617849.53, cost=718370.74
2022-12-06 15:49:13,773 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 15863.4256, Accuracy: 0.0098
2022-12-06 15:49:13,969 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:49:13,970 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:49:13.973 [ZeusMonitor] Monitor started.
2022-12-06 20:49:13.973 [ZeusMonitor] Running indefinitely. 2022-12-06 20:49:13.973 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:49:13.973 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e98+gpu0.power.log
2022-12-06 15:49:57,580 [ZeusDataLoader(train)] train epoch 98 done: time=43.80 energy=5832.38
2022-12-06 15:49:57,583 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 4.6478
Training Epoch: 97 [2048/50176]	Loss: 4.6233
Training Epoch: 97 [3072/50176]	Loss: 4.6377
Training Epoch: 97 [4096/50176]	Loss: 4.6454
Training Epoch: 97 [5120/50176]	Loss: 4.6356
Training Epoch: 97 [6144/50176]	Loss: 4.6320
Training Epoch: 97 [7168/50176]	Loss: 4.6402
Training Epoch: 97 [8192/50176]	Loss: 4.6293
Training Epoch: 97 [9216/50176]	Loss: 4.6305
Training Epoch: 97 [10240/50176]	Loss: 4.6428
Training Epoch: 97 [11264/50176]	Loss: 4.6351
Training Epoch: 97 [12288/50176]	Loss: 4.6346
Training Epoch: 97 [13312/50176]	Loss: 4.6613
Training Epoch: 97 [14336/50176]	Loss: 4.6431
Training Epoch: 97 [15360/50176]	Loss: 4.6525
Training Epoch: 97 [16384/50176]	Loss: 4.6319
Training Epoch: 97 [17408/50176]	Loss: 4.6260
Training Epoch: 97 [18432/50176]	Loss: 4.6304
Training Epoch: 97 [19456/50176]	Loss: 4.6409
Training Epoch: 97 [20480/50176]	Loss: 4.6448
Training Epoch: 97 [21504/50176]	Loss: 4.6335
Training Epoch: 97 [22528/50176]	Loss: 4.6468
Training Epoch: 97 [23552/50176]	Loss: 4.6393
Training Epoch: 97 [24576/50176]	Loss: 4.6430
Training Epoch: 97 [25600/50176]	Loss: 4.6321
Training Epoch: 97 [26624/50176]	Loss: 4.6399
Training Epoch: 97 [27648/50176]	Loss: 4.6274
Training Epoch: 97 [28672/50176]	Loss: 4.6256
Training Epoch: 97 [29696/50176]	Loss: 4.6488
Training Epoch: 97 [30720/50176]	Loss: 4.6390
Training Epoch: 97 [31744/50176]	Loss: 4.6454
Training Epoch: 97 [32768/50176]	Loss: 4.6486
Training Epoch: 97 [33792/50176]	Loss: 4.6411
Training Epoch: 97 [34816/50176]	Loss: 4.6524
Training Epoch: 97 [35840/50176]	Loss: 4.6227
Training Epoch: 97 [36864/50176]	Loss: 4.6344
Training Epoch: 97 [37888/50176]	Loss: 4.6423
Training Epoch: 97 [38912/50176]	Loss: 4.6338
Training Epoch: 97 [39936/50176]	Loss: 4.6344
Training Epoch: 97 [40960/50176]	Loss: 4.6331
Training Epoch: 97 [41984/50176]	Loss: 4.6439
Training Epoch: 97 [43008/50176]	Loss: 4.6429
Training Epoch: 97 [44032/50176]	Loss: 4.6418
Training Epoch: 97 [45056/50176]	Loss: 4.6411
Training Epoch: 97 [46080/50176]	Loss: 4.6338
Training Epoch: 97 [47104/50176]	Loss: 4.6562
Training Epoch: 97 [48128/50176]	Loss: 4.6447
Training Epoch: 97 [49152/50176]	Loss: 4.6319
Training Epoch: 97 [50176/50176]	Loss: 4.6293
2022-12-06 20:50:01.382 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:50:01,393 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.80 energy=469.49
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Up to epoch 98: time=4680.38, energy=617785.10, cost=718425.55
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Expected next epoch: time=4726.98, energy=624151.40, cost=725686.78
2022-12-06 15:50:01,394 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:50:01,638 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:50:01,638 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:50:01.640 [ZeusMonitor] Monitor started.
2022-12-06 20:50:01.640 [ZeusMonitor] Running indefinitely. 2022-12-06 20:50:01.640 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:50:01.640 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e99+gpu0.power.log
2022-12-06 15:50:45,117 [ZeusDataLoader(train)] train epoch 99 done: time=43.71 energy=5818.57
2022-12-06 15:50:45,121 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 4.6287
Training Epoch: 98 [2048/50176]	Loss: 4.6371
Training Epoch: 98 [3072/50176]	Loss: 4.6355
Training Epoch: 98 [4096/50176]	Loss: 4.6353
Training Epoch: 98 [5120/50176]	Loss: 4.6511
Training Epoch: 98 [6144/50176]	Loss: 4.6309
Training Epoch: 98 [7168/50176]	Loss: 4.6285
Training Epoch: 98 [8192/50176]	Loss: 4.6260
Training Epoch: 98 [9216/50176]	Loss: 4.6269
Training Epoch: 98 [10240/50176]	Loss: 4.6403
Training Epoch: 98 [11264/50176]	Loss: 4.6368
Training Epoch: 98 [12288/50176]	Loss: 4.6330
Training Epoch: 98 [13312/50176]	Loss: 4.6451
Training Epoch: 98 [14336/50176]	Loss: 4.6285
Training Epoch: 98 [15360/50176]	Loss: 4.6443
Training Epoch: 98 [16384/50176]	Loss: 4.6498
Training Epoch: 98 [17408/50176]	Loss: 4.6368
Training Epoch: 98 [18432/50176]	Loss: 4.6393
Training Epoch: 98 [19456/50176]	Loss: 4.6420
Training Epoch: 98 [20480/50176]	Loss: 4.6395
Training Epoch: 98 [21504/50176]	Loss: 4.6418
Training Epoch: 98 [22528/50176]	Loss: 4.6459
Training Epoch: 98 [23552/50176]	Loss: 4.6413
Training Epoch: 98 [24576/50176]	Loss: 4.6439
Training Epoch: 98 [25600/50176]	Loss: 4.6389
Training Epoch: 98 [26624/50176]	Loss: 4.6324
Training Epoch: 98 [27648/50176]	Loss: 4.6521
Training Epoch: 98 [28672/50176]	Loss: 4.6353
Training Epoch: 98 [29696/50176]	Loss: 4.6548
Training Epoch: 98 [30720/50176]	Loss: 4.6444
Training Epoch: 98 [31744/50176]	Loss: 4.6536
Training Epoch: 98 [32768/50176]	Loss: 4.6450
Training Epoch: 98 [33792/50176]	Loss: 4.6423
Training Epoch: 98 [34816/50176]	Loss: 4.6377
Training Epoch: 98 [35840/50176]	Loss: 4.6336
Training Epoch: 98 [36864/50176]	Loss: 4.6341
Training Epoch: 98 [37888/50176]	Loss: 4.6444
Training Epoch: 98 [38912/50176]	Loss: 4.6331
Training Epoch: 98 [39936/50176]	Loss: 4.6318
Training Epoch: 98 [40960/50176]	Loss: 4.6245
Training Epoch: 98 [41984/50176]	Loss: 4.6314
Training Epoch: 98 [43008/50176]	Loss: 4.6472
Training Epoch: 98 [44032/50176]	Loss: 4.6265
Training Epoch: 98 [45056/50176]	Loss: 4.6385
Training Epoch: 98 [46080/50176]	Loss: 4.6558
Training Epoch: 98 [47104/50176]	Loss: 4.6384
Training Epoch: 98 [48128/50176]	Loss: 4.6329
Training Epoch: 98 [49152/50176]	Loss: 4.6292
Training Epoch: 98 [50176/50176]	Loss: 4.6116
2022-12-06 20:50:48.795 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:50:48,804 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.68 energy=468.98
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Up to epoch 99: time=4727.77, energy=624072.65, cost=725715.97
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Expected next epoch: time=4774.37, energy=630438.94, cost=732977.21
2022-12-06 15:50:48,806 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:50:49,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:50:49,042 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:50:49.044 [ZeusMonitor] Monitor started.
2022-12-06 20:50:49.044 [ZeusMonitor] Running indefinitely. 2022-12-06 20:50:49.044 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:50:49.044 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e100+gpu0.power.log
2022-12-06 15:51:32,596 [ZeusDataLoader(train)] train epoch 100 done: time=43.78 energy=5830.92
2022-12-06 15:51:32,600 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 4.6584
Training Epoch: 99 [2048/50176]	Loss: 4.6383
Training Epoch: 99 [3072/50176]	Loss: 4.6524
Training Epoch: 99 [4096/50176]	Loss: 4.6410
Training Epoch: 99 [5120/50176]	Loss: 4.6289
Training Epoch: 99 [6144/50176]	Loss: 4.6328
Training Epoch: 99 [7168/50176]	Loss: 4.6287
Training Epoch: 99 [8192/50176]	Loss: 4.6335
Training Epoch: 99 [9216/50176]	Loss: 4.6389
Training Epoch: 99 [10240/50176]	Loss: 4.6576
Training Epoch: 99 [11264/50176]	Loss: 4.6371
Training Epoch: 99 [12288/50176]	Loss: 4.6473
Training Epoch: 99 [13312/50176]	Loss: 4.6520
Training Epoch: 99 [14336/50176]	Loss: 4.6380
Training Epoch: 99 [15360/50176]	Loss: 4.6181
Training Epoch: 99 [16384/50176]	Loss: 4.6487
Training Epoch: 99 [17408/50176]	Loss: 4.6233
Training Epoch: 99 [18432/50176]	Loss: 4.6419
Training Epoch: 99 [19456/50176]	Loss: 4.6257
Training Epoch: 99 [20480/50176]	Loss: 4.6467
Training Epoch: 99 [21504/50176]	Loss: 4.6311
Training Epoch: 99 [22528/50176]	Loss: 4.6416
Training Epoch: 99 [23552/50176]	Loss: 4.6357
Training Epoch: 99 [24576/50176]	Loss: 4.6274
Training Epoch: 99 [25600/50176]	Loss: 4.6394
Training Epoch: 99 [26624/50176]	Loss: 4.6500
Training Epoch: 99 [27648/50176]	Loss: 4.6582
Training Epoch: 99 [28672/50176]	Loss: 4.6492
Training Epoch: 99 [29696/50176]	Loss: 4.6393
Training Epoch: 99 [30720/50176]	Loss: 4.6464
Training Epoch: 99 [31744/50176]	Loss: 4.6498
Training Epoch: 99 [32768/50176]	Loss: 4.6219
Training Epoch: 99 [33792/50176]	Loss: 4.6340
Training Epoch: 99 [34816/50176]	Loss: 4.6352
Training Epoch: 99 [35840/50176]	Loss: 4.6555
Training Epoch: 99 [36864/50176]	Loss: 4.6452
Training Epoch: 99 [37888/50176]	Loss: 4.6488
Training Epoch: 99 [38912/50176]	Loss: 4.6447
Training Epoch: 99 [39936/50176]	Loss: 4.6285
Training Epoch: 99 [40960/50176]	Loss: 4.6280
Training Epoch: 99 [41984/50176]	Loss: 4.6462
Training Epoch: 99 [43008/50176]	Loss: 4.6290
Training Epoch: 99 [44032/50176]	Loss: 4.6418
Training Epoch: 99 [45056/50176]	Loss: 4.6313
Training Epoch: 99 [46080/50176]	Loss: 4.6294
Training Epoch: 99 [47104/50176]	Loss: 4.6250
Training Epoch: 99 [48128/50176]	Loss: 4.6491
Training Epoch: 99 [49152/50176]	Loss: 4.6251
Training Epoch: 99 [50176/50176]	Loss: 4.6362
2022-12-06 20:51:36.353 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:51:36,371 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.76 energy=471.77
2022-12-06 15:51:36,371 [ZeusDataLoader(train)] Up to epoch 100: time=4775.31, energy=630375.34, cost=733027.61
2022-12-06 15:51:36,371 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-06 15:51:36,372 [ZeusDataLoader(train)] Training done.
2022-12-06 15:51:36,372 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec03+try01+bs1024+lr0.5000000.train.json: {"energy": 630375.3421898179, "time": 4775.313635210998, "cost": 733027.6141758712, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 1926.2423, Accuracy: 0.0098

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 630375.3421898179, 'time': 4775.313635210998, 'cost': 733027.6141758712, 'num_epochs': 100, 'reached': False}
[run job; power] power_stats={'job_id': 'rec03+try01', 'train_power': {'175000': 141.93837297518056, '150000': 137.5711933424961, '125000': 122.45263058940533, '100000': 98.39104404902801}, 'train_throughput': {'175000': 1.1131630264555321, '150000': 1.1449147533158621, '125000': 1.086906289817731, '100000': 0.8999782655864567}, 'eval_power': {'175000': 125.66587303669519, '150000': 125.63847713019706, '125000': 111.94785245414742}, 'eval_throughput': {'175000': 2.662326664559453, '150000': 2.6255096010426673, '125000': 2.5308668007617996}, 'optimal_pl': 150000}
[Zeus Master] cost=733027.6141758712

[Zeus Master] Job did not reach the target metric!
[Zeus Master]
[HistoryEntry(bs=1024, pl=175.0, lr=0.005, energy=240343.41170650077, reached=True, time=1745.0100623509989), HistoryEntry(bs=1024, pl=175.0, lr=0.01, energy=512864.726165234, reached=True, time=3675.9740900210018), HistoryEntry(bs=1024, pl=150.0, lr=0.05, energy=673308.1082976655, reached=False, time=4862.071877154984), HistoryEntry(bs=1024, pl=150.0, lr=0.5, energy=630375.3421898179, reached=False, time=4775.313635210998)]
