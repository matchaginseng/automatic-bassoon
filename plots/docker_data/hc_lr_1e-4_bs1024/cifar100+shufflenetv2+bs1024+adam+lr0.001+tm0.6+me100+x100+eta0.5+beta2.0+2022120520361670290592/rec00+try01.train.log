2022-12-05 20:36:36,961 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-05 20:36:36,961 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-05 20:36:36,961 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-05 20:36:37,008 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-05 20:36:37,008 [ZeusDataLoader(train)] Power profiling: ON
2022-12-05 20:36:44,696 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-05 20:36:44,697 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-05 20:36:44,823 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 01:36:44.835 [ZeusMonitor] Monitor started.
2022-12-06 01:36:44.835 [ZeusMonitor] Running indefinitely. 2022-12-06 01:36:44.835 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:36:44.835 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e1+gpu0.power.log
2022-12-05 20:36:45,634 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-05 20:36:45,634 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-05 20:36:55,984 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-05 20:37:29,385 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-05 20:37:31,039 [ZeusDataLoader(train)] train epoch 1 done: time=46.34 energy=6826.45
2022-12-05 20:37:31,042 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 4.6407
Training Epoch: 0 [3072/50176]	Loss: 4.6157
Training Epoch: 0 [4096/50176]	Loss: 4.6122
Training Epoch: 0 [5120/50176]	Loss: 4.6138
Training Epoch: 0 [6144/50176]	Loss: 4.6054
Training Epoch: 0 [7168/50176]	Loss: 4.6140
Training Epoch: 0 [8192/50176]	Loss: 4.6132
Training Epoch: 0 [9216/50176]	Loss: 4.6016
Training Epoch: 0 [10240/50176]	Loss: 4.5973
Training Epoch: 0 [11264/50176]	Loss: 4.5825
Training Epoch: 0 [12288/50176]	Loss: 4.5860
Training Epoch: 0 [13312/50176]	Loss: 4.5846
Training Epoch: 0 [14336/50176]	Loss: 4.5902
Training Epoch: 0 [15360/50176]	Loss: 4.5814
Training Epoch: 0 [16384/50176]	Loss: 4.5751
Training Epoch: 0 [17408/50176]	Loss: 4.5703
Training Epoch: 0 [18432/50176]	Loss: 4.5713
Training Epoch: 0 [19456/50176]	Loss: 4.5556
Training Epoch: 0 [20480/50176]	Loss: 4.5698
Training Epoch: 0 [21504/50176]	Loss: 4.5673
Training Epoch: 0 [22528/50176]	Loss: 4.5639
Training Epoch: 0 [23552/50176]	Loss: 4.5513
Training Epoch: 0 [24576/50176]	Loss: 4.5623
Training Epoch: 0 [25600/50176]	Loss: 4.5438
Training Epoch: 0 [26624/50176]	Loss: 4.5455
Training Epoch: 0 [27648/50176]	Loss: 4.5539
Training Epoch: 0 [28672/50176]	Loss: 4.5417
Training Epoch: 0 [29696/50176]	Loss: 4.5494
Training Epoch: 0 [30720/50176]	Loss: 4.5574
Training Epoch: 0 [31744/50176]	Loss: 4.5412
Training Epoch: 0 [32768/50176]	Loss: 4.5456
Training Epoch: 0 [33792/50176]	Loss: 4.5496
Training Epoch: 0 [34816/50176]	Loss: 4.5346
Training Epoch: 0 [35840/50176]	Loss: 4.5414
Training Epoch: 0 [36864/50176]	Loss: 4.5282
Training Epoch: 0 [37888/50176]	Loss: 4.5044
Training Epoch: 0 [38912/50176]	Loss: 4.5180
Training Epoch: 0 [39936/50176]	Loss: 4.5298
Training Epoch: 0 [40960/50176]	Loss: 4.5043
Training Epoch: 0 [41984/50176]	Loss: 4.5183
Training Epoch: 0 [43008/50176]	Loss: 4.5232
Training Epoch: 0 [44032/50176]	Loss: 4.4948
Training Epoch: 0 [45056/50176]	Loss: 4.5173
Training Epoch: 0 [46080/50176]	Loss: 4.5043
Training Epoch: 0 [47104/50176]	Loss: 4.5009
Training Epoch: 0 [48128/50176]	Loss: 4.5117
Training Epoch: 0 [49152/50176]	Loss: 4.5021
Training Epoch: 0 [50176/50176]	Loss: 4.5102
2022-12-06 01:37:34.691 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:37:34,707 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.66 energy=500.29
2022-12-05 20:37:34,708 [ZeusDataLoader(train)] Up to epoch 1: time=49.99, energy=7326.74, cost=8037.69
2022-12-05 20:37:34,709 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0045, Accuracy: 0.0115
2022-12-05 20:37:34,849 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 01:37:34.854 [ZeusMonitor] Monitor started.
2022-12-06 01:37:34.854 [ZeusMonitor] Running indefinitely. 2022-12-06 01:37:34.854 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:37:34.854 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e2+gpu0.power.log
2022-12-05 20:37:35,612 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-05 20:37:35,612 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-05 20:37:43,898 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-05 20:38:18,414 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-05 20:38:20,121 [ZeusDataLoader(train)] train epoch 2 done: time=45.41 energy=6532.60
2022-12-05 20:38:20,124 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.4777
Training Epoch: 1 [2048/50176]	Loss: 4.4935
Training Epoch: 1 [3072/50176]	Loss: 4.4987
Training Epoch: 1 [4096/50176]	Loss: 4.5153
Training Epoch: 1 [5120/50176]	Loss: 4.4906
Training Epoch: 1 [6144/50176]	Loss: 4.4989
Training Epoch: 1 [7168/50176]	Loss: 4.4838
Training Epoch: 1 [8192/50176]	Loss: 4.4742
Training Epoch: 1 [9216/50176]	Loss: 4.4924
Training Epoch: 1 [10240/50176]	Loss: 4.4838
Training Epoch: 1 [11264/50176]	Loss: 4.4769
Training Epoch: 1 [12288/50176]	Loss: 4.4676
Training Epoch: 1 [13312/50176]	Loss: 4.4826
Training Epoch: 1 [14336/50176]	Loss: 4.4789
Training Epoch: 1 [15360/50176]	Loss: 4.4898
Training Epoch: 1 [16384/50176]	Loss: 4.4833
Training Epoch: 1 [17408/50176]	Loss: 4.4830
Training Epoch: 1 [18432/50176]	Loss: 4.4471
Training Epoch: 1 [19456/50176]	Loss: 4.4915
Training Epoch: 1 [20480/50176]	Loss: 4.4566
Training Epoch: 1 [21504/50176]	Loss: 4.4741
Training Epoch: 1 [22528/50176]	Loss: 4.4548
Training Epoch: 1 [23552/50176]	Loss: 4.4494
Training Epoch: 1 [24576/50176]	Loss: 4.4482
Training Epoch: 1 [25600/50176]	Loss: 4.4638
Training Epoch: 1 [26624/50176]	Loss: 4.4681
Training Epoch: 1 [27648/50176]	Loss: 4.4639
Training Epoch: 1 [28672/50176]	Loss: 4.4395
Training Epoch: 1 [29696/50176]	Loss: 4.4589
Training Epoch: 1 [30720/50176]	Loss: 4.4146
Training Epoch: 1 [31744/50176]	Loss: 4.4591
Training Epoch: 1 [32768/50176]	Loss: 4.4151
Training Epoch: 1 [33792/50176]	Loss: 4.4544
Training Epoch: 1 [34816/50176]	Loss: 4.4310
Training Epoch: 1 [35840/50176]	Loss: 4.4665
Training Epoch: 1 [36864/50176]	Loss: 4.4356
Training Epoch: 1 [37888/50176]	Loss: 4.4168
Training Epoch: 1 [38912/50176]	Loss: 4.4333
Training Epoch: 1 [39936/50176]	Loss: 4.4421
Training Epoch: 1 [40960/50176]	Loss: 4.4289
Training Epoch: 1 [41984/50176]	Loss: 4.4169
Training Epoch: 1 [43008/50176]	Loss: 4.4238
Training Epoch: 1 [44032/50176]	Loss: 4.4176
Training Epoch: 1 [45056/50176]	Loss: 4.4404
Training Epoch: 1 [46080/50176]	Loss: 4.4005
Training Epoch: 1 [47104/50176]	Loss: 4.4213
Training Epoch: 1 [48128/50176]	Loss: 4.4314
Training Epoch: 1 [49152/50176]	Loss: 4.4271
Training Epoch: 1 [50176/50176]	Loss: 4.4119
2022-12-06 01:38:23.942 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:38:23,973 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.84 energy=507.63
2022-12-05 20:38:23,973 [ZeusDataLoader(train)] Up to epoch 2: time=99.24, energy=14366.98, cost=15866.87
2022-12-05 20:38:23,974 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0043, Accuracy: 0.0354
2022-12-05 20:38:24,159 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 01:38:24.161 [ZeusMonitor] Monitor started.
2022-12-06 01:38:24.162 [ZeusMonitor] Running indefinitely. 2022-12-06 01:38:24.162 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:38:24.162 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e3+gpu0.power.log
2022-12-05 20:38:24,926 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-05 20:38:24,926 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-05 20:38:34,404 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-05 20:39:13,768 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-05 20:39:15,692 [ZeusDataLoader(train)] train epoch 3 done: time=51.71 energy=6254.37
2022-12-05 20:39:15,695 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 4.3796
Training Epoch: 2 [2048/50176]	Loss: 4.4241
Training Epoch: 2 [3072/50176]	Loss: 4.4102
Training Epoch: 2 [4096/50176]	Loss: 4.3882
Training Epoch: 2 [5120/50176]	Loss: 4.4118
Training Epoch: 2 [6144/50176]	Loss: 4.4100
Training Epoch: 2 [7168/50176]	Loss: 4.4121
Training Epoch: 2 [8192/50176]	Loss: 4.4125
Training Epoch: 2 [9216/50176]	Loss: 4.4025
Training Epoch: 2 [10240/50176]	Loss: 4.3595
Training Epoch: 2 [11264/50176]	Loss: 4.3646
Training Epoch: 2 [12288/50176]	Loss: 4.3644
Training Epoch: 2 [13312/50176]	Loss: 4.3596
Training Epoch: 2 [14336/50176]	Loss: 4.3996
Training Epoch: 2 [15360/50176]	Loss: 4.3901
Training Epoch: 2 [16384/50176]	Loss: 4.3815
Training Epoch: 2 [17408/50176]	Loss: 4.3524
Training Epoch: 2 [18432/50176]	Loss: 4.3504
Training Epoch: 2 [19456/50176]	Loss: 4.3880
Training Epoch: 2 [20480/50176]	Loss: 4.3402
Training Epoch: 2 [21504/50176]	Loss: 4.3478
Training Epoch: 2 [22528/50176]	Loss: 4.3391
Training Epoch: 2 [23552/50176]	Loss: 4.3385
Training Epoch: 2 [24576/50176]	Loss: 4.3534
Training Epoch: 2 [25600/50176]	Loss: 4.3413
Training Epoch: 2 [26624/50176]	Loss: 4.3476
Training Epoch: 2 [27648/50176]	Loss: 4.3709
Training Epoch: 2 [28672/50176]	Loss: 4.3292
Training Epoch: 2 [29696/50176]	Loss: 4.3087
Training Epoch: 2 [30720/50176]	Loss: 4.3611
Training Epoch: 2 [31744/50176]	Loss: 4.3258
Training Epoch: 2 [32768/50176]	Loss: 4.3356
Training Epoch: 2 [33792/50176]	Loss: 4.3222
Training Epoch: 2 [34816/50176]	Loss: 4.3380
Training Epoch: 2 [35840/50176]	Loss: 4.3065
Training Epoch: 2 [36864/50176]	Loss: 4.3069
Training Epoch: 2 [37888/50176]	Loss: 4.3528
Training Epoch: 2 [38912/50176]	Loss: 4.2962
Training Epoch: 2 [39936/50176]	Loss: 4.2701
Training Epoch: 2 [40960/50176]	Loss: 4.2834
Training Epoch: 2 [41984/50176]	Loss: 4.3235
Training Epoch: 2 [43008/50176]	Loss: 4.2724
Training Epoch: 2 [44032/50176]	Loss: 4.2649
Training Epoch: 2 [45056/50176]	Loss: 4.2979
Training Epoch: 2 [46080/50176]	Loss: 4.2901
Training Epoch: 2 [47104/50176]	Loss: 4.2951
Training Epoch: 2 [48128/50176]	Loss: 4.2469
Training Epoch: 2 [49152/50176]	Loss: 4.2412
Training Epoch: 2 [50176/50176]	Loss: 4.2576
2022-12-06 01:39:19.829 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:39:19,847 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.14 energy=473.06
2022-12-05 20:39:19,847 [ZeusDataLoader(train)] Up to epoch 3: time=155.09, energy=21094.40, cost=24117.70
2022-12-05 20:39:19,848 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0042, Accuracy: 0.0458
2022-12-05 20:39:20,020 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 01:39:20.023 [ZeusMonitor] Monitor started.
2022-12-06 01:39:20.023 [ZeusMonitor] Running indefinitely. 2022-12-06 01:39:20.023 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:39:20.023 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e4+gpu0.power.log
2022-12-05 20:39:20,792 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-05 20:39:20,792 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-05 20:39:45,681 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-05 20:41:29,102 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-05 20:41:29,102 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-05 20:41:29,102 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-05 20:41:29,105 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-05 20:41:31,256 [ZeusDataLoader(train)] train epoch 4 done: time=131.35 energy=13396.73
2022-12-05 20:41:31,272 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 4.2221
Training Epoch: 3 [2048/50176]	Loss: 4.2438
Training Epoch: 3 [3072/50176]	Loss: 4.2288
Training Epoch: 3 [4096/50176]	Loss: 4.2185
Training Epoch: 3 [5120/50176]	Loss: 4.2288
Training Epoch: 3 [6144/50176]	Loss: 4.2538
Training Epoch: 3 [7168/50176]	Loss: 4.2341
Training Epoch: 3 [8192/50176]	Loss: 4.2385
Training Epoch: 3 [9216/50176]	Loss: 4.2624
Training Epoch: 3 [10240/50176]	Loss: 4.2094
Training Epoch: 3 [11264/50176]	Loss: 4.2310
Training Epoch: 3 [12288/50176]	Loss: 4.1943
Training Epoch: 3 [13312/50176]	Loss: 4.2224
Training Epoch: 3 [14336/50176]	Loss: 4.1767
Training Epoch: 3 [15360/50176]	Loss: 4.1864
Training Epoch: 3 [16384/50176]	Loss: 4.2228
Training Epoch: 3 [17408/50176]	Loss: 4.1716
Training Epoch: 3 [18432/50176]	Loss: 4.1931
Training Epoch: 3 [19456/50176]	Loss: 4.2168
Training Epoch: 3 [20480/50176]	Loss: 4.1541
Training Epoch: 3 [21504/50176]	Loss: 4.1968
Training Epoch: 3 [22528/50176]	Loss: 4.1706
Training Epoch: 3 [23552/50176]	Loss: 4.1497
Training Epoch: 3 [24576/50176]	Loss: 4.1588
Training Epoch: 3 [25600/50176]	Loss: 4.1559
Training Epoch: 3 [26624/50176]	Loss: 4.2212
Training Epoch: 3 [27648/50176]	Loss: 4.1940
Training Epoch: 3 [28672/50176]	Loss: 4.1477
Training Epoch: 3 [29696/50176]	Loss: 4.1527
Training Epoch: 3 [30720/50176]	Loss: 4.1478
Training Epoch: 3 [31744/50176]	Loss: 4.1309
Training Epoch: 3 [32768/50176]	Loss: 4.1921
Training Epoch: 3 [33792/50176]	Loss: 4.1097
Training Epoch: 3 [34816/50176]	Loss: 4.1320
Training Epoch: 3 [35840/50176]	Loss: 4.1342
Training Epoch: 3 [36864/50176]	Loss: 4.1133
Training Epoch: 3 [37888/50176]	Loss: 4.1201
Training Epoch: 3 [38912/50176]	Loss: 4.1279
Training Epoch: 3 [39936/50176]	Loss: 4.1247
Training Epoch: 3 [40960/50176]	Loss: 4.1298
Training Epoch: 3 [41984/50176]	Loss: 4.1193
Training Epoch: 3 [43008/50176]	Loss: 4.0982
Training Epoch: 3 [44032/50176]	Loss: 4.0862
Training Epoch: 3 [45056/50176]	Loss: 4.0793
Training Epoch: 3 [46080/50176]	Loss: 4.0911
Training Epoch: 3 [47104/50176]	Loss: 4.1036
Training Epoch: 3 [48128/50176]	Loss: 4.1773
Training Epoch: 3 [49152/50176]	Loss: 4.1106
Training Epoch: 3 [50176/50176]	Loss: 4.1214
2022-12-06 01:41:36.569 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:41:36,590 [ZeusDataLoader(eval)] Power profiling done.
2022-12-05 20:41:36,591 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+lr0.0001000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 155.109488296236, "150000": 146.68469254029122, "125000": 122.90733697450204, "100000": 102.00850118980948}, "train_throughput": {"175000": 1.1384988454287117, "150000": 1.1013028901502382, "125000": 0.9656124206810447, "100000": 0.3674840455212511}, "eval_power": {"175000": 115.43706053525592, "150000": 132.18577011313258, "125000": 114.18485435171795}, "eval_throughput": {"175000": 1.8847332441398674, "150000": 2.6039722835263004, "125000": 2.4137410386379115}, "optimal_pl": 175000}
2022-12-05 20:41:36,591 [ZeusDataLoader(eval)] eval epoch 4 done: time=5.31 energy=612.48
2022-12-05 20:41:36,591 [ZeusDataLoader(train)] Up to epoch 4: time=291.75, energy=35103.62, cost=43079.58
2022-12-05 20:41:36,591 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:41:36,591 [ZeusDataLoader(train)] Expected next epoch: time=340.09, energy=42391.88, cost=50953.89
2022-12-05 20:41:36,592 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0040, Accuracy: 0.0648
2022-12-05 20:41:36,792 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:41:36,792 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:41:36.794 [ZeusMonitor] Monitor started.
2022-12-06 01:41:36.794 [ZeusMonitor] Running indefinitely. 2022-12-06 01:41:36.794 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:41:36.794 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e5+gpu0.power.log
2022-12-05 20:42:21,348 [ZeusDataLoader(train)] train epoch 5 done: time=44.74 energy=6741.19
2022-12-05 20:42:21,353 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 4.1172
Training Epoch: 4 [2048/50176]	Loss: 4.0416
Training Epoch: 4 [3072/50176]	Loss: 4.0565
Training Epoch: 4 [4096/50176]	Loss: 4.0669
Training Epoch: 4 [5120/50176]	Loss: 4.0732
Training Epoch: 4 [6144/50176]	Loss: 4.0787
Training Epoch: 4 [7168/50176]	Loss: 4.0745
Training Epoch: 4 [8192/50176]	Loss: 4.0767
Training Epoch: 4 [9216/50176]	Loss: 4.1009
Training Epoch: 4 [10240/50176]	Loss: 4.0617
Training Epoch: 4 [11264/50176]	Loss: 4.0571
Training Epoch: 4 [12288/50176]	Loss: 4.0558
Training Epoch: 4 [13312/50176]	Loss: 4.0584
Training Epoch: 4 [14336/50176]	Loss: 4.0497
Training Epoch: 4 [15360/50176]	Loss: 4.0587
Training Epoch: 4 [16384/50176]	Loss: 3.9766
Training Epoch: 4 [17408/50176]	Loss: 4.0440
Training Epoch: 4 [18432/50176]	Loss: 4.0537
Training Epoch: 4 [19456/50176]	Loss: 4.0324
Training Epoch: 4 [20480/50176]	Loss: 4.0246
Training Epoch: 4 [21504/50176]	Loss: 4.0430
Training Epoch: 4 [22528/50176]	Loss: 4.0382
Training Epoch: 4 [23552/50176]	Loss: 4.0156
Training Epoch: 4 [24576/50176]	Loss: 4.0418
Training Epoch: 4 [25600/50176]	Loss: 4.0288
Training Epoch: 4 [26624/50176]	Loss: 4.0023
Training Epoch: 4 [27648/50176]	Loss: 4.0507
Training Epoch: 4 [28672/50176]	Loss: 3.9745
Training Epoch: 4 [29696/50176]	Loss: 4.0231
Training Epoch: 4 [30720/50176]	Loss: 3.9781
Training Epoch: 4 [31744/50176]	Loss: 3.9484
Training Epoch: 4 [32768/50176]	Loss: 4.0226
Training Epoch: 4 [33792/50176]	Loss: 3.9934
Training Epoch: 4 [34816/50176]	Loss: 3.9768
Training Epoch: 4 [35840/50176]	Loss: 4.0025
Training Epoch: 4 [36864/50176]	Loss: 3.9691
Training Epoch: 4 [37888/50176]	Loss: 4.0532
Training Epoch: 4 [38912/50176]	Loss: 3.9781
Training Epoch: 4 [39936/50176]	Loss: 4.0483
Training Epoch: 4 [40960/50176]	Loss: 3.9533
Training Epoch: 4 [41984/50176]	Loss: 3.9472
Training Epoch: 4 [43008/50176]	Loss: 3.9924
Training Epoch: 4 [44032/50176]	Loss: 3.9100
Training Epoch: 4 [45056/50176]	Loss: 4.0104
Training Epoch: 4 [46080/50176]	Loss: 3.9875
Training Epoch: 4 [47104/50176]	Loss: 3.9384
Training Epoch: 4 [48128/50176]	Loss: 3.9910
Training Epoch: 4 [49152/50176]	Loss: 4.0011
Training Epoch: 4 [50176/50176]	Loss: 3.9941
2022-12-06 01:42:25.631 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:42:25,657 [ZeusDataLoader(eval)] eval epoch 5 done: time=4.29 energy=563.13
2022-12-05 20:42:25,658 [ZeusDataLoader(train)] Up to epoch 5: time=340.78, energy=42407.94, cost=51022.09
2022-12-05 20:42:25,658 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:42:25,658 [ZeusDataLoader(train)] Expected next epoch: time=389.12, energy=49696.20, cost=58896.40
2022-12-05 20:42:25,660 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0039, Accuracy: 0.0766
2022-12-05 20:42:26,023 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:42:26,024 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:42:26.042 [ZeusMonitor] Monitor started.
2022-12-06 01:42:26.042 [ZeusMonitor] Running indefinitely. 2022-12-06 01:42:26.042 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:42:26.042 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e6+gpu0.power.log
2022-12-05 20:43:11,628 [ZeusDataLoader(train)] train epoch 6 done: time=45.95 energy=6842.07
2022-12-05 20:43:11,633 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 3.9803
Training Epoch: 5 [2048/50176]	Loss: 3.9377
Training Epoch: 5 [3072/50176]	Loss: 3.9458
Training Epoch: 5 [4096/50176]	Loss: 3.9389
Training Epoch: 5 [5120/50176]	Loss: 3.9530
Training Epoch: 5 [6144/50176]	Loss: 3.9705
Training Epoch: 5 [7168/50176]	Loss: 3.9408
Training Epoch: 5 [8192/50176]	Loss: 3.9812
Training Epoch: 5 [9216/50176]	Loss: 3.9597
Training Epoch: 5 [10240/50176]	Loss: 3.9392
Training Epoch: 5 [11264/50176]	Loss: 3.9592
Training Epoch: 5 [12288/50176]	Loss: 3.9487
Training Epoch: 5 [13312/50176]	Loss: 3.9206
Training Epoch: 5 [14336/50176]	Loss: 3.8884
Training Epoch: 5 [15360/50176]	Loss: 3.9527
Training Epoch: 5 [16384/50176]	Loss: 3.9203
Training Epoch: 5 [17408/50176]	Loss: 3.9365
Training Epoch: 5 [18432/50176]	Loss: 3.9094
Training Epoch: 5 [19456/50176]	Loss: 3.9325
Training Epoch: 5 [20480/50176]	Loss: 3.9387
Training Epoch: 5 [21504/50176]	Loss: 3.8979
Training Epoch: 5 [22528/50176]	Loss: 3.9445
Training Epoch: 5 [23552/50176]	Loss: 3.9058
Training Epoch: 5 [24576/50176]	Loss: 3.9277
Training Epoch: 5 [25600/50176]	Loss: 3.9285
Training Epoch: 5 [26624/50176]	Loss: 3.8970
Training Epoch: 5 [27648/50176]	Loss: 3.9048
Training Epoch: 5 [28672/50176]	Loss: 3.9141
Training Epoch: 5 [29696/50176]	Loss: 3.8477
Training Epoch: 5 [30720/50176]	Loss: 3.8588
Training Epoch: 5 [31744/50176]	Loss: 3.9186
Training Epoch: 5 [32768/50176]	Loss: 3.8821
Training Epoch: 5 [33792/50176]	Loss: 3.8466
Training Epoch: 5 [34816/50176]	Loss: 3.8876
Training Epoch: 5 [35840/50176]	Loss: 3.9256
Training Epoch: 5 [36864/50176]	Loss: 3.8595
Training Epoch: 5 [37888/50176]	Loss: 3.9078
Training Epoch: 5 [38912/50176]	Loss: 3.8538
Training Epoch: 5 [39936/50176]	Loss: 3.8971
Training Epoch: 5 [40960/50176]	Loss: 3.8653
Training Epoch: 5 [41984/50176]	Loss: 3.8799
Training Epoch: 5 [43008/50176]	Loss: 3.8648
Training Epoch: 5 [44032/50176]	Loss: 3.9080
Training Epoch: 5 [45056/50176]	Loss: 3.9194
Training Epoch: 5 [46080/50176]	Loss: 3.8660
Training Epoch: 5 [47104/50176]	Loss: 3.8722
Training Epoch: 5 [48128/50176]	Loss: 3.8793
Training Epoch: 5 [49152/50176]	Loss: 3.8513
Training Epoch: 5 [50176/50176]	Loss: 3.8440
2022-12-06 01:43:16.202 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:43:16,228 [ZeusDataLoader(eval)] eval epoch 6 done: time=4.58 energy=581.77
2022-12-05 20:43:16,229 [ZeusDataLoader(train)] Up to epoch 6: time=391.31, energy=49831.78, cost=59155.41
2022-12-05 20:43:16,229 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:43:16,229 [ZeusDataLoader(train)] Expected next epoch: time=439.65, energy=57120.04, cost=67029.72
2022-12-05 20:43:16,231 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0038, Accuracy: 0.0940
2022-12-05 20:43:16,564 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:43:16,565 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:43:16.578 [ZeusMonitor] Monitor started.
2022-12-06 01:43:16.578 [ZeusMonitor] Running indefinitely. 2022-12-06 01:43:16.578 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:43:16.578 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e7+gpu0.power.log
2022-12-05 20:44:02,274 [ZeusDataLoader(train)] train epoch 7 done: time=46.03 energy=6854.74
2022-12-05 20:44:02,280 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 3.8831
Training Epoch: 6 [2048/50176]	Loss: 3.9086
Training Epoch: 6 [3072/50176]	Loss: 3.8624
Training Epoch: 6 [4096/50176]	Loss: 3.8328
Training Epoch: 6 [5120/50176]	Loss: 3.7862
Training Epoch: 6 [6144/50176]	Loss: 3.8187
Training Epoch: 6 [7168/50176]	Loss: 3.8061
Training Epoch: 6 [8192/50176]	Loss: 3.8529
Training Epoch: 6 [9216/50176]	Loss: 3.9462
Training Epoch: 6 [10240/50176]	Loss: 3.8016
Training Epoch: 6 [11264/50176]	Loss: 3.8498
Training Epoch: 6 [12288/50176]	Loss: 3.8161
Training Epoch: 6 [13312/50176]	Loss: 3.8318
Training Epoch: 6 [14336/50176]	Loss: 3.8177
Training Epoch: 6 [15360/50176]	Loss: 3.7786
Training Epoch: 6 [16384/50176]	Loss: 3.7958
Training Epoch: 6 [17408/50176]	Loss: 3.7458
Training Epoch: 6 [18432/50176]	Loss: 3.8623
Training Epoch: 6 [19456/50176]	Loss: 3.7966
Training Epoch: 6 [20480/50176]	Loss: 3.8128
Training Epoch: 6 [21504/50176]	Loss: 3.8213
Training Epoch: 6 [22528/50176]	Loss: 3.8081
Training Epoch: 6 [23552/50176]	Loss: 3.7979
Training Epoch: 6 [24576/50176]	Loss: 3.7988
Training Epoch: 6 [25600/50176]	Loss: 3.7696
Training Epoch: 6 [26624/50176]	Loss: 3.7916
Training Epoch: 6 [27648/50176]	Loss: 3.8110
Training Epoch: 6 [28672/50176]	Loss: 3.7543
Training Epoch: 6 [29696/50176]	Loss: 3.8344
Training Epoch: 6 [30720/50176]	Loss: 3.7543
Training Epoch: 6 [31744/50176]	Loss: 3.8458
Training Epoch: 6 [32768/50176]	Loss: 3.7566
Training Epoch: 6 [33792/50176]	Loss: 3.7864
Training Epoch: 6 [34816/50176]	Loss: 3.7742
Training Epoch: 6 [35840/50176]	Loss: 3.7706
Training Epoch: 6 [36864/50176]	Loss: 3.7760
Training Epoch: 6 [37888/50176]	Loss: 3.8357
Training Epoch: 6 [38912/50176]	Loss: 3.7849
Training Epoch: 6 [39936/50176]	Loss: 3.7897
Training Epoch: 6 [40960/50176]	Loss: 3.7925
Training Epoch: 6 [41984/50176]	Loss: 3.7636
Training Epoch: 6 [43008/50176]	Loss: 3.7288
Training Epoch: 6 [44032/50176]	Loss: 3.7487
Training Epoch: 6 [45056/50176]	Loss: 3.7802
Training Epoch: 6 [46080/50176]	Loss: 3.8296
Training Epoch: 6 [47104/50176]	Loss: 3.7277
Training Epoch: 6 [48128/50176]	Loss: 3.8052
Training Epoch: 6 [49152/50176]	Loss: 3.7278
Training Epoch: 6 [50176/50176]	Loss: 3.7936
2022-12-06 01:44:06.830 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:44:06,860 [ZeusDataLoader(eval)] eval epoch 7 done: time=4.57 energy=577.99
2022-12-05 20:44:06,860 [ZeusDataLoader(train)] Up to epoch 7: time=441.91, energy=57264.51, cost=67299.09
2022-12-05 20:44:06,860 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:44:06,860 [ZeusDataLoader(train)] Expected next epoch: time=490.25, energy=64552.78, cost=75173.40
2022-12-05 20:44:06,862 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0037, Accuracy: 0.1108
2022-12-05 20:44:07,184 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:44:07,185 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:44:07.196 [ZeusMonitor] Monitor started.
2022-12-06 01:44:07.196 [ZeusMonitor] Running indefinitely. 2022-12-06 01:44:07.196 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:44:07.196 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e8+gpu0.power.log
2022-12-05 20:44:53,044 [ZeusDataLoader(train)] train epoch 8 done: time=46.17 energy=6867.58
2022-12-05 20:44:53,048 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 3.8114
Training Epoch: 7 [2048/50176]	Loss: 3.7398
Training Epoch: 7 [3072/50176]	Loss: 3.7210
Training Epoch: 7 [4096/50176]	Loss: 3.7523
Training Epoch: 7 [5120/50176]	Loss: 3.8252
Training Epoch: 7 [6144/50176]	Loss: 3.7121
Training Epoch: 7 [7168/50176]	Loss: 3.7295
Training Epoch: 7 [8192/50176]	Loss: 3.7137
Training Epoch: 7 [9216/50176]	Loss: 3.6563
Training Epoch: 7 [10240/50176]	Loss: 3.6803
Training Epoch: 7 [11264/50176]	Loss: 3.7717
Training Epoch: 7 [12288/50176]	Loss: 3.7348
Training Epoch: 7 [13312/50176]	Loss: 3.7066
Training Epoch: 7 [14336/50176]	Loss: 3.8181
Training Epoch: 7 [15360/50176]	Loss: 3.7747
Training Epoch: 7 [16384/50176]	Loss: 3.6821
Training Epoch: 7 [17408/50176]	Loss: 3.7022
Training Epoch: 7 [18432/50176]	Loss: 3.7684
Training Epoch: 7 [19456/50176]	Loss: 3.7208
Training Epoch: 7 [20480/50176]	Loss: 3.7916
Training Epoch: 7 [21504/50176]	Loss: 3.7831
Training Epoch: 7 [22528/50176]	Loss: 3.7620
Training Epoch: 7 [23552/50176]	Loss: 3.7289
Training Epoch: 7 [24576/50176]	Loss: 3.7073
Training Epoch: 7 [25600/50176]	Loss: 3.6737
Training Epoch: 7 [26624/50176]	Loss: 3.7623
Training Epoch: 7 [27648/50176]	Loss: 3.7732
Training Epoch: 7 [28672/50176]	Loss: 3.6989
Training Epoch: 7 [29696/50176]	Loss: 3.7667
Training Epoch: 7 [30720/50176]	Loss: 3.7363
Training Epoch: 7 [31744/50176]	Loss: 3.7211
Training Epoch: 7 [32768/50176]	Loss: 3.7338
Training Epoch: 7 [33792/50176]	Loss: 3.7356
Training Epoch: 7 [34816/50176]	Loss: 3.7218
Training Epoch: 7 [35840/50176]	Loss: 3.6968
Training Epoch: 7 [36864/50176]	Loss: 3.7177
Training Epoch: 7 [37888/50176]	Loss: 3.6414
Training Epoch: 7 [38912/50176]	Loss: 3.7445
Training Epoch: 7 [39936/50176]	Loss: 3.7260
Training Epoch: 7 [40960/50176]	Loss: 3.7524
Training Epoch: 7 [41984/50176]	Loss: 3.6832
Training Epoch: 7 [43008/50176]	Loss: 3.7182
Training Epoch: 7 [44032/50176]	Loss: 3.6366
Training Epoch: 7 [45056/50176]	Loss: 3.7034
Training Epoch: 7 [46080/50176]	Loss: 3.7198
Training Epoch: 7 [47104/50176]	Loss: 3.6913
Training Epoch: 7 [48128/50176]	Loss: 3.7323
Training Epoch: 7 [49152/50176]	Loss: 3.7517
Training Epoch: 7 [50176/50176]	Loss: 3.6620
2022-12-06 01:44:56.834 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:44:56,868 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.81 energy=528.01
2022-12-05 20:44:56,868 [ZeusDataLoader(train)] Up to epoch 8: time=491.89, energy=64660.10, cost=75370.56
2022-12-05 20:44:56,868 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:44:56,868 [ZeusDataLoader(train)] Expected next epoch: time=540.24, energy=71948.37, cost=83244.88
2022-12-05 20:44:56,869 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0036, Accuracy: 0.1242
2022-12-05 20:44:57,048 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:44:57,049 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:44:57.052 [ZeusMonitor] Monitor started.
2022-12-06 01:44:57.052 [ZeusMonitor] Running indefinitely. 2022-12-06 01:44:57.052 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:44:57.052 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e9+gpu0.power.log
2022-12-05 20:45:41,568 [ZeusDataLoader(train)] train epoch 9 done: time=44.69 energy=6758.92
2022-12-05 20:45:41,571 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 3.7368
Training Epoch: 8 [2048/50176]	Loss: 3.7801
Training Epoch: 8 [3072/50176]	Loss: 3.7335
Training Epoch: 8 [4096/50176]	Loss: 3.6589
Training Epoch: 8 [5120/50176]	Loss: 3.6382
Training Epoch: 8 [6144/50176]	Loss: 3.7078
Training Epoch: 8 [7168/50176]	Loss: 3.6221
Training Epoch: 8 [8192/50176]	Loss: 3.7167
Training Epoch: 8 [9216/50176]	Loss: 3.6874
Training Epoch: 8 [10240/50176]	Loss: 3.6719
Training Epoch: 8 [11264/50176]	Loss: 3.6549
Training Epoch: 8 [12288/50176]	Loss: 3.6473
Training Epoch: 8 [13312/50176]	Loss: 3.6554
Training Epoch: 8 [14336/50176]	Loss: 3.6499
Training Epoch: 8 [15360/50176]	Loss: 3.6767
Training Epoch: 8 [16384/50176]	Loss: 3.6254
Training Epoch: 8 [17408/50176]	Loss: 3.6839
Training Epoch: 8 [18432/50176]	Loss: 3.6468
Training Epoch: 8 [19456/50176]	Loss: 3.6664
Training Epoch: 8 [20480/50176]	Loss: 3.6119
Training Epoch: 8 [21504/50176]	Loss: 3.6432
Training Epoch: 8 [22528/50176]	Loss: 3.6376
Training Epoch: 8 [23552/50176]	Loss: 3.7056
Training Epoch: 8 [24576/50176]	Loss: 3.7065
Training Epoch: 8 [25600/50176]	Loss: 3.6856
Training Epoch: 8 [26624/50176]	Loss: 3.6949
Training Epoch: 8 [27648/50176]	Loss: 3.6781
Training Epoch: 8 [28672/50176]	Loss: 3.6539
Training Epoch: 8 [29696/50176]	Loss: 3.6196
Training Epoch: 8 [30720/50176]	Loss: 3.6831
Training Epoch: 8 [31744/50176]	Loss: 3.6558
Training Epoch: 8 [32768/50176]	Loss: 3.6573
Training Epoch: 8 [33792/50176]	Loss: 3.7099
Training Epoch: 8 [34816/50176]	Loss: 3.6546
Training Epoch: 8 [35840/50176]	Loss: 3.6750
Training Epoch: 8 [36864/50176]	Loss: 3.6359
Training Epoch: 8 [37888/50176]	Loss: 3.6711
Training Epoch: 8 [38912/50176]	Loss: 3.7122
Training Epoch: 8 [39936/50176]	Loss: 3.6748
Training Epoch: 8 [40960/50176]	Loss: 3.6543
Training Epoch: 8 [41984/50176]	Loss: 3.5985
Training Epoch: 8 [43008/50176]	Loss: 3.6424
Training Epoch: 8 [44032/50176]	Loss: 3.6898
Training Epoch: 8 [45056/50176]	Loss: 3.7155
Training Epoch: 8 [46080/50176]	Loss: 3.6746
Training Epoch: 8 [47104/50176]	Loss: 3.6925
Training Epoch: 8 [48128/50176]	Loss: 3.6308
Training Epoch: 8 [49152/50176]	Loss: 3.7240
Training Epoch: 8 [50176/50176]	Loss: 3.6718
2022-12-06 01:45:45.443 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:45:45,456 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.87 energy=523.71
2022-12-05 20:45:45,457 [ZeusDataLoader(train)] Up to epoch 9: time=540.45, energy=71942.74, cost=83261.15
2022-12-05 20:45:45,457 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:45:45,457 [ZeusDataLoader(train)] Expected next epoch: time=588.80, energy=79231.00, cost=91135.46
2022-12-05 20:45:45,458 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0036, Accuracy: 0.1323
2022-12-05 20:45:45,717 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:45:45,718 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:45:45.730 [ZeusMonitor] Monitor started.
2022-12-06 01:45:45.730 [ZeusMonitor] Running indefinitely. 2022-12-06 01:45:45.730 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:45:45.730 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e10+gpu0.power.log
2022-12-05 20:46:30,788 [ZeusDataLoader(train)] train epoch 10 done: time=45.32 energy=6784.97
2022-12-05 20:46:30,793 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 3.6515
Training Epoch: 9 [2048/50176]	Loss: 3.6489
Training Epoch: 9 [3072/50176]	Loss: 3.6019
Training Epoch: 9 [4096/50176]	Loss: 3.6695
Training Epoch: 9 [5120/50176]	Loss: 3.6555
Training Epoch: 9 [6144/50176]	Loss: 3.6782
Training Epoch: 9 [7168/50176]	Loss: 3.6542
Training Epoch: 9 [8192/50176]	Loss: 3.6396
Training Epoch: 9 [9216/50176]	Loss: 3.6191
Training Epoch: 9 [10240/50176]	Loss: 3.6268
Training Epoch: 9 [11264/50176]	Loss: 3.5723
Training Epoch: 9 [12288/50176]	Loss: 3.6216
Training Epoch: 9 [13312/50176]	Loss: 3.5997
Training Epoch: 9 [14336/50176]	Loss: 3.6467
Training Epoch: 9 [15360/50176]	Loss: 3.6530
Training Epoch: 9 [16384/50176]	Loss: 3.6923
Training Epoch: 9 [17408/50176]	Loss: 3.6033
Training Epoch: 9 [18432/50176]	Loss: 3.6336
Training Epoch: 9 [19456/50176]	Loss: 3.6440
Training Epoch: 9 [20480/50176]	Loss: 3.6467
Training Epoch: 9 [21504/50176]	Loss: 3.5848
Training Epoch: 9 [22528/50176]	Loss: 3.5496
Training Epoch: 9 [23552/50176]	Loss: 3.5279
Training Epoch: 9 [24576/50176]	Loss: 3.6110
Training Epoch: 9 [25600/50176]	Loss: 3.6149
Training Epoch: 9 [26624/50176]	Loss: 3.6299
Training Epoch: 9 [27648/50176]	Loss: 3.6089
Training Epoch: 9 [28672/50176]	Loss: 3.6229
Training Epoch: 9 [29696/50176]	Loss: 3.5476
Training Epoch: 9 [30720/50176]	Loss: 3.6068
Training Epoch: 9 [31744/50176]	Loss: 3.6213
Training Epoch: 9 [32768/50176]	Loss: 3.5872
Training Epoch: 9 [33792/50176]	Loss: 3.5830
Training Epoch: 9 [34816/50176]	Loss: 3.6144
Training Epoch: 9 [35840/50176]	Loss: 3.6026
Training Epoch: 9 [36864/50176]	Loss: 3.6293
Training Epoch: 9 [37888/50176]	Loss: 3.6172
Training Epoch: 9 [38912/50176]	Loss: 3.6474
Training Epoch: 9 [39936/50176]	Loss: 3.6338
Training Epoch: 9 [40960/50176]	Loss: 3.6607
Training Epoch: 9 [41984/50176]	Loss: 3.6396
Training Epoch: 9 [43008/50176]	Loss: 3.6672
Training Epoch: 9 [44032/50176]	Loss: 3.5930
Training Epoch: 9 [45056/50176]	Loss: 3.5212
Training Epoch: 9 [46080/50176]	Loss: 3.6198
Training Epoch: 9 [47104/50176]	Loss: 3.6247
Training Epoch: 9 [48128/50176]	Loss: 3.6421
Training Epoch: 9 [49152/50176]	Loss: 3.6033
Training Epoch: 9 [50176/50176]	Loss: 3.5589
2022-12-06 01:46:35.091 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:46:35,145 [ZeusDataLoader(eval)] eval epoch 10 done: time=4.34 energy=570.01
2022-12-05 20:46:35,145 [ZeusDataLoader(train)] Up to epoch 10: time=590.11, energy=79297.71, cost=91283.38
2022-12-05 20:46:35,145 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:46:35,146 [ZeusDataLoader(train)] Expected next epoch: time=638.45, energy=86585.98, cost=99157.70
2022-12-05 20:46:35,151 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0035, Accuracy: 0.1373
2022-12-06 01:46:35.526 [ZeusMonitor] Monitor started.
2022-12-06 01:46:35.527 [ZeusMonitor] Running indefinitely. 2022-12-06 01:46:35.527 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:46:35.527 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e11+gpu0.power.log
2022-12-05 20:46:35,527 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:46:35,528 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-05 20:47:21,669 [ZeusDataLoader(train)] train epoch 11 done: time=46.50 energy=6909.26
2022-12-05 20:47:21,675 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 3.6283
Training Epoch: 10 [2048/50176]	Loss: 3.5833
Training Epoch: 10 [3072/50176]	Loss: 3.5746
Training Epoch: 10 [4096/50176]	Loss: 3.5948
Training Epoch: 10 [5120/50176]	Loss: 3.5975
Training Epoch: 10 [6144/50176]	Loss: 3.5705
Training Epoch: 10 [7168/50176]	Loss: 3.6087
Training Epoch: 10 [8192/50176]	Loss: 3.5363
Training Epoch: 10 [9216/50176]	Loss: 3.5251
Training Epoch: 10 [10240/50176]	Loss: 3.5303
Training Epoch: 10 [11264/50176]	Loss: 3.6011
Training Epoch: 10 [12288/50176]	Loss: 3.5647
Training Epoch: 10 [13312/50176]	Loss: 3.6193
Training Epoch: 10 [14336/50176]	Loss: 3.6509
Training Epoch: 10 [15360/50176]	Loss: 3.5452
Training Epoch: 10 [16384/50176]	Loss: 3.6535
Training Epoch: 10 [17408/50176]	Loss: 3.5969
Training Epoch: 10 [18432/50176]	Loss: 3.5150
Training Epoch: 10 [19456/50176]	Loss: 3.5890
Training Epoch: 10 [20480/50176]	Loss: 3.5707
Training Epoch: 10 [21504/50176]	Loss: 3.6167
Training Epoch: 10 [22528/50176]	Loss: 3.5538
Training Epoch: 10 [23552/50176]	Loss: 3.5305
Training Epoch: 10 [24576/50176]	Loss: 3.5836
Training Epoch: 10 [25600/50176]	Loss: 3.5531
Training Epoch: 10 [26624/50176]	Loss: 3.5834
Training Epoch: 10 [27648/50176]	Loss: 3.5578
Training Epoch: 10 [28672/50176]	Loss: 3.5792
Training Epoch: 10 [29696/50176]	Loss: 3.6028
Training Epoch: 10 [30720/50176]	Loss: 3.5935
Training Epoch: 10 [31744/50176]	Loss: 3.6296
Training Epoch: 10 [32768/50176]	Loss: 3.5640
Training Epoch: 10 [33792/50176]	Loss: 3.5528
Training Epoch: 10 [34816/50176]	Loss: 3.5318
Training Epoch: 10 [35840/50176]	Loss: 3.6072
Training Epoch: 10 [36864/50176]	Loss: 3.5482
Training Epoch: 10 [37888/50176]	Loss: 3.5038
Training Epoch: 10 [38912/50176]	Loss: 3.5127
Training Epoch: 10 [39936/50176]	Loss: 3.6209
Training Epoch: 10 [40960/50176]	Loss: 3.4977
Training Epoch: 10 [41984/50176]	Loss: 3.5137
Training Epoch: 10 [43008/50176]	Loss: 3.6210
Training Epoch: 10 [44032/50176]	Loss: 3.5413
Training Epoch: 10 [45056/50176]	Loss: 3.5882
Training Epoch: 10 [46080/50176]	Loss: 3.5028
Training Epoch: 10 [47104/50176]	Loss: 3.5356
Training Epoch: 10 [48128/50176]	Loss: 3.5982
Training Epoch: 10 [49152/50176]	Loss: 3.5823
Training Epoch: 10 [50176/50176]	Loss: 3.5522
2022-12-06 01:47:26.179 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:47:26,203 [ZeusDataLoader(eval)] eval epoch 11 done: time=4.52 energy=564.89
2022-12-05 20:47:26,203 [ZeusDataLoader(train)] Up to epoch 11: time=641.12, energy=86771.86, cost=99484.28
2022-12-05 20:47:26,204 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:47:26,204 [ZeusDataLoader(train)] Expected next epoch: time=689.47, energy=94060.12, cost=107358.60
2022-12-05 20:47:26,205 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0035, Accuracy: 0.1463
2022-12-05 20:47:26,626 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:47:26,631 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:47:26.641 [ZeusMonitor] Monitor started.
2022-12-06 01:47:26.641 [ZeusMonitor] Running indefinitely. 2022-12-06 01:47:26.641 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:47:26.641 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e12+gpu0.power.log
2022-12-05 20:48:13,166 [ZeusDataLoader(train)] train epoch 12 done: time=46.94 energy=6984.10
2022-12-05 20:48:13,171 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 3.5458
Training Epoch: 11 [2048/50176]	Loss: 3.5113
Training Epoch: 11 [3072/50176]	Loss: 3.5604
Training Epoch: 11 [4096/50176]	Loss: 3.5526
Training Epoch: 11 [5120/50176]	Loss: 3.6029
Training Epoch: 11 [6144/50176]	Loss: 3.4916
Training Epoch: 11 [7168/50176]	Loss: 3.5292
Training Epoch: 11 [8192/50176]	Loss: 3.4901
Training Epoch: 11 [9216/50176]	Loss: 3.5417
Training Epoch: 11 [10240/50176]	Loss: 3.5894
Training Epoch: 11 [11264/50176]	Loss: 3.4994
Training Epoch: 11 [12288/50176]	Loss: 3.5101
Training Epoch: 11 [13312/50176]	Loss: 3.6242
Training Epoch: 11 [14336/50176]	Loss: 3.5384
Training Epoch: 11 [15360/50176]	Loss: 3.5624
Training Epoch: 11 [16384/50176]	Loss: 3.5342
Training Epoch: 11 [17408/50176]	Loss: 3.5863
Training Epoch: 11 [18432/50176]	Loss: 3.5280
Training Epoch: 11 [19456/50176]	Loss: 3.5267
Training Epoch: 11 [20480/50176]	Loss: 3.6233
Training Epoch: 11 [21504/50176]	Loss: 3.5417
Training Epoch: 11 [22528/50176]	Loss: 3.5542
Training Epoch: 11 [23552/50176]	Loss: 3.5781
Training Epoch: 11 [24576/50176]	Loss: 3.5041
Training Epoch: 11 [25600/50176]	Loss: 3.5638
Training Epoch: 11 [26624/50176]	Loss: 3.4566
Training Epoch: 11 [27648/50176]	Loss: 3.5656
Training Epoch: 11 [28672/50176]	Loss: 3.5521
Training Epoch: 11 [29696/50176]	Loss: 3.4901
Training Epoch: 11 [30720/50176]	Loss: 3.4761
Training Epoch: 11 [31744/50176]	Loss: 3.5303
Training Epoch: 11 [32768/50176]	Loss: 3.4577
Training Epoch: 11 [33792/50176]	Loss: 3.4854
Training Epoch: 11 [34816/50176]	Loss: 3.5940
Training Epoch: 11 [35840/50176]	Loss: 3.5556
Training Epoch: 11 [36864/50176]	Loss: 3.5556
Training Epoch: 11 [37888/50176]	Loss: 3.4848
Training Epoch: 11 [38912/50176]	Loss: 3.5160
Training Epoch: 11 [39936/50176]	Loss: 3.5227
Training Epoch: 11 [40960/50176]	Loss: 3.4695
Training Epoch: 11 [41984/50176]	Loss: 3.4955
Training Epoch: 11 [43008/50176]	Loss: 3.5842
Training Epoch: 11 [44032/50176]	Loss: 3.4436
Training Epoch: 11 [45056/50176]	Loss: 3.5447
Training Epoch: 11 [46080/50176]	Loss: 3.4581
Training Epoch: 11 [47104/50176]	Loss: 3.5503
Training Epoch: 11 [48128/50176]	Loss: 3.5015
Training Epoch: 11 [49152/50176]	Loss: 3.4424
Training Epoch: 11 [50176/50176]	Loss: 3.5125
2022-12-06 01:48:17.842 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:48:17,884 [ZeusDataLoader(eval)] eval epoch 12 done: time=4.70 energy=594.68
2022-12-05 20:48:17,884 [ZeusDataLoader(train)] Up to epoch 12: time=692.77, energy=94350.64, cost=107792.43
2022-12-05 20:48:17,885 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:48:17,885 [ZeusDataLoader(train)] Expected next epoch: time=741.11, energy=101638.90, cost=115666.75
2022-12-05 20:48:17,886 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0034, Accuracy: 0.1557
2022-12-06 01:48:18.259 [ZeusMonitor] Monitor started.
2022-12-06 01:48:18.259 [ZeusMonitor] Running indefinitely. 2022-12-06 01:48:18.259 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:48:18.259 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e13+gpu0.power.log
2022-12-05 20:48:18,264 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:48:18,264 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-05 20:49:03,975 [ZeusDataLoader(train)] train epoch 13 done: time=46.08 energy=6909.70
2022-12-05 20:49:03,978 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 3.5322
Training Epoch: 12 [2048/50176]	Loss: 3.4962
Training Epoch: 12 [3072/50176]	Loss: 3.4837
Training Epoch: 12 [4096/50176]	Loss: 3.4734
Training Epoch: 12 [5120/50176]	Loss: 3.3598
Training Epoch: 12 [6144/50176]	Loss: 3.5154
Training Epoch: 12 [7168/50176]	Loss: 3.5508
Training Epoch: 12 [8192/50176]	Loss: 3.4563
Training Epoch: 12 [9216/50176]	Loss: 3.5327
Training Epoch: 12 [10240/50176]	Loss: 3.4541
Training Epoch: 12 [11264/50176]	Loss: 3.5687
Training Epoch: 12 [12288/50176]	Loss: 3.5019
Training Epoch: 12 [13312/50176]	Loss: 3.4820
Training Epoch: 12 [14336/50176]	Loss: 3.5455
Training Epoch: 12 [15360/50176]	Loss: 3.4182
Training Epoch: 12 [16384/50176]	Loss: 3.4991
Training Epoch: 12 [17408/50176]	Loss: 3.4543
Training Epoch: 12 [18432/50176]	Loss: 3.4725
Training Epoch: 12 [19456/50176]	Loss: 3.4510
Training Epoch: 12 [20480/50176]	Loss: 3.5235
Training Epoch: 12 [21504/50176]	Loss: 3.5063
Training Epoch: 12 [22528/50176]	Loss: 3.4772
Training Epoch: 12 [23552/50176]	Loss: 3.5143
Training Epoch: 12 [24576/50176]	Loss: 3.4373
Training Epoch: 12 [25600/50176]	Loss: 3.5634
Training Epoch: 12 [26624/50176]	Loss: 3.5161
Training Epoch: 12 [27648/50176]	Loss: 3.4624
Training Epoch: 12 [28672/50176]	Loss: 3.5339
Training Epoch: 12 [29696/50176]	Loss: 3.4955
Training Epoch: 12 [30720/50176]	Loss: 3.5277
Training Epoch: 12 [31744/50176]	Loss: 3.4404
Training Epoch: 12 [32768/50176]	Loss: 3.5543
Training Epoch: 12 [33792/50176]	Loss: 3.4484
Training Epoch: 12 [34816/50176]	Loss: 3.5430
Training Epoch: 12 [35840/50176]	Loss: 3.4728
Training Epoch: 12 [36864/50176]	Loss: 3.5485
Training Epoch: 12 [37888/50176]	Loss: 3.4806
Training Epoch: 12 [38912/50176]	Loss: 3.4597
Training Epoch: 12 [39936/50176]	Loss: 3.5405
Training Epoch: 12 [40960/50176]	Loss: 3.4585
Training Epoch: 12 [41984/50176]	Loss: 3.4659
Training Epoch: 12 [43008/50176]	Loss: 3.5024
Training Epoch: 12 [44032/50176]	Loss: 3.5453
Training Epoch: 12 [45056/50176]	Loss: 3.4163
Training Epoch: 12 [46080/50176]	Loss: 3.4825
Training Epoch: 12 [47104/50176]	Loss: 3.4083
Training Epoch: 12 [48128/50176]	Loss: 3.4191
Training Epoch: 12 [49152/50176]	Loss: 3.4755
Training Epoch: 12 [50176/50176]	Loss: 3.3926
2022-12-06 01:49:07.808 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:49:07,853 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.87 energy=530.37
2022-12-05 20:49:07,853 [ZeusDataLoader(train)] Up to epoch 13: time=742.71, energy=101790.71, cost=115882.68
2022-12-05 20:49:07,854 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:49:07,854 [ZeusDataLoader(train)] Expected next epoch: time=791.06, energy=109078.97, cost=123756.99
2022-12-05 20:49:07,855 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0034, Accuracy: 0.1640
2022-12-05 20:49:08,087 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:49:08,088 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:49:08.093 [ZeusMonitor] Monitor started.
2022-12-06 01:49:08.093 [ZeusMonitor] Running indefinitely. 2022-12-06 01:49:08.093 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:49:08.093 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e14+gpu0.power.log
2022-12-05 20:49:52,225 [ZeusDataLoader(train)] train epoch 14 done: time=44.36 energy=6737.39
2022-12-05 20:49:52,229 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 3.4477
Training Epoch: 13 [2048/50176]	Loss: 3.4578
Training Epoch: 13 [3072/50176]	Loss: 3.4709
Training Epoch: 13 [4096/50176]	Loss: 3.4564
Training Epoch: 13 [5120/50176]	Loss: 3.4534
Training Epoch: 13 [6144/50176]	Loss: 3.4751
Training Epoch: 13 [7168/50176]	Loss: 3.4046
Training Epoch: 13 [8192/50176]	Loss: 3.4480
Training Epoch: 13 [9216/50176]	Loss: 3.4612
Training Epoch: 13 [10240/50176]	Loss: 3.4964
Training Epoch: 13 [11264/50176]	Loss: 3.5207
Training Epoch: 13 [12288/50176]	Loss: 3.4059
Training Epoch: 13 [13312/50176]	Loss: 3.4650
Training Epoch: 13 [14336/50176]	Loss: 3.5001
Training Epoch: 13 [15360/50176]	Loss: 3.4873
Training Epoch: 13 [16384/50176]	Loss: 3.4912
Training Epoch: 13 [17408/50176]	Loss: 3.4785
Training Epoch: 13 [18432/50176]	Loss: 3.4496
Training Epoch: 13 [19456/50176]	Loss: 3.4250
Training Epoch: 13 [20480/50176]	Loss: 3.3731
Training Epoch: 13 [21504/50176]	Loss: 3.4670
Training Epoch: 13 [22528/50176]	Loss: 3.4809
Training Epoch: 13 [23552/50176]	Loss: 3.3986
Training Epoch: 13 [24576/50176]	Loss: 3.4529
Training Epoch: 13 [25600/50176]	Loss: 3.4407
Training Epoch: 13 [26624/50176]	Loss: 3.4775
Training Epoch: 13 [27648/50176]	Loss: 3.4505
Training Epoch: 13 [28672/50176]	Loss: 3.3839
Training Epoch: 13 [29696/50176]	Loss: 3.5190
Training Epoch: 13 [30720/50176]	Loss: 3.4826
Training Epoch: 13 [31744/50176]	Loss: 3.4953
Training Epoch: 13 [32768/50176]	Loss: 3.4404
Training Epoch: 13 [33792/50176]	Loss: 3.4651
Training Epoch: 13 [34816/50176]	Loss: 3.4806
Training Epoch: 13 [35840/50176]	Loss: 3.5452
Training Epoch: 13 [36864/50176]	Loss: 3.5021
Training Epoch: 13 [37888/50176]	Loss: 3.4638
Training Epoch: 13 [38912/50176]	Loss: 3.4053
Training Epoch: 13 [39936/50176]	Loss: 3.3955
Training Epoch: 13 [40960/50176]	Loss: 3.4303
Training Epoch: 13 [41984/50176]	Loss: 3.5337
Training Epoch: 13 [43008/50176]	Loss: 3.3894
Training Epoch: 13 [44032/50176]	Loss: 3.4252
Training Epoch: 13 [45056/50176]	Loss: 3.4651
Training Epoch: 13 [46080/50176]	Loss: 3.4642
Training Epoch: 13 [47104/50176]	Loss: 3.4189
Training Epoch: 13 [48128/50176]	Loss: 3.4008
Training Epoch: 13 [49152/50176]	Loss: 3.3910
Training Epoch: 13 [50176/50176]	Loss: 3.4184
2022-12-06 01:49:55.962 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:49:55,986 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.75 energy=519.21
2022-12-05 20:49:55,987 [ZeusDataLoader(train)] Up to epoch 14: time=790.82, energy=109047.32, cost=123720.72
2022-12-05 20:49:55,987 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:49:55,987 [ZeusDataLoader(train)] Expected next epoch: time=839.17, energy=116335.58, cost=131595.03
2022-12-05 20:49:55,988 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0034, Accuracy: 0.1696
2022-12-05 20:49:56,214 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:49:56,215 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:49:56.226 [ZeusMonitor] Monitor started.
2022-12-06 01:49:56.226 [ZeusMonitor] Running indefinitely. 2022-12-06 01:49:56.226 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:49:56.226 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e15+gpu0.power.log
2022-12-05 20:50:40,357 [ZeusDataLoader(train)] train epoch 15 done: time=44.36 energy=6755.14
2022-12-05 20:50:40,361 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 3.4832
Training Epoch: 14 [2048/50176]	Loss: 3.4461
Training Epoch: 14 [3072/50176]	Loss: 3.5109
Training Epoch: 14 [4096/50176]	Loss: 3.4973
Training Epoch: 14 [5120/50176]	Loss: 3.4041
Training Epoch: 14 [6144/50176]	Loss: 3.3858
Training Epoch: 14 [7168/50176]	Loss: 3.4045
Training Epoch: 14 [8192/50176]	Loss: 3.4539
Training Epoch: 14 [9216/50176]	Loss: 3.4203
Training Epoch: 14 [10240/50176]	Loss: 3.4169
Training Epoch: 14 [11264/50176]	Loss: 3.4562
Training Epoch: 14 [12288/50176]	Loss: 3.4724
Training Epoch: 14 [13312/50176]	Loss: 3.3966
Training Epoch: 14 [14336/50176]	Loss: 3.3843
Training Epoch: 14 [15360/50176]	Loss: 3.3960
Training Epoch: 14 [16384/50176]	Loss: 3.3451
Training Epoch: 14 [17408/50176]	Loss: 3.4399
Training Epoch: 14 [18432/50176]	Loss: 3.4728
Training Epoch: 14 [19456/50176]	Loss: 3.4295
Training Epoch: 14 [20480/50176]	Loss: 3.4077
Training Epoch: 14 [21504/50176]	Loss: 3.3814
Training Epoch: 14 [22528/50176]	Loss: 3.3820
Training Epoch: 14 [23552/50176]	Loss: 3.4062
Training Epoch: 14 [24576/50176]	Loss: 3.3792
Training Epoch: 14 [25600/50176]	Loss: 3.4577
Training Epoch: 14 [26624/50176]	Loss: 3.3896
Training Epoch: 14 [27648/50176]	Loss: 3.3887
Training Epoch: 14 [28672/50176]	Loss: 3.4789
Training Epoch: 14 [29696/50176]	Loss: 3.4352
Training Epoch: 14 [30720/50176]	Loss: 3.4166
Training Epoch: 14 [31744/50176]	Loss: 3.4076
Training Epoch: 14 [32768/50176]	Loss: 3.4533
Training Epoch: 14 [33792/50176]	Loss: 3.4361
Training Epoch: 14 [34816/50176]	Loss: 3.4997
Training Epoch: 14 [35840/50176]	Loss: 3.3962
Training Epoch: 14 [36864/50176]	Loss: 3.4942
Training Epoch: 14 [37888/50176]	Loss: 3.3705
Training Epoch: 14 [38912/50176]	Loss: 3.4110
Training Epoch: 14 [39936/50176]	Loss: 3.3151
Training Epoch: 14 [40960/50176]	Loss: 3.3820
Training Epoch: 14 [41984/50176]	Loss: 3.4582
Training Epoch: 14 [43008/50176]	Loss: 3.4046
Training Epoch: 14 [44032/50176]	Loss: 3.3594
Training Epoch: 14 [45056/50176]	Loss: 3.3944
Training Epoch: 14 [46080/50176]	Loss: 3.4067
Training Epoch: 14 [47104/50176]	Loss: 3.3783
Training Epoch: 14 [48128/50176]	Loss: 3.4487
Training Epoch: 14 [49152/50176]	Loss: 3.4198
Training Epoch: 14 [50176/50176]	Loss: 3.4031
2022-12-06 01:50:44.140 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:50:44,166 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.80 energy=520.53
2022-12-05 20:50:44,166 [ZeusDataLoader(train)] Up to epoch 15: time=838.98, energy=116322.98, cost=131572.38
2022-12-05 20:50:44,166 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:50:44,166 [ZeusDataLoader(train)] Expected next epoch: time=887.33, energy=123611.24, cost=139446.70
2022-12-05 20:50:44,167 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0033, Accuracy: 0.1764
2022-12-05 20:50:44,359 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:50:44,360 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:50:44.362 [ZeusMonitor] Monitor started.
2022-12-06 01:50:44.362 [ZeusMonitor] Running indefinitely. 2022-12-06 01:50:44.362 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:50:44.362 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e16+gpu0.power.log
2022-12-05 20:51:28,419 [ZeusDataLoader(train)] train epoch 16 done: time=44.24 energy=6732.50
2022-12-05 20:51:28,423 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 3.4390
Training Epoch: 15 [2048/50176]	Loss: 3.3726
Training Epoch: 15 [3072/50176]	Loss: 3.3652
Training Epoch: 15 [4096/50176]	Loss: 3.3885
Training Epoch: 15 [5120/50176]	Loss: 3.3925
Training Epoch: 15 [6144/50176]	Loss: 3.4230
Training Epoch: 15 [7168/50176]	Loss: 3.3221
Training Epoch: 15 [8192/50176]	Loss: 3.4512
Training Epoch: 15 [9216/50176]	Loss: 3.3658
Training Epoch: 15 [10240/50176]	Loss: 3.3763
Training Epoch: 15 [11264/50176]	Loss: 3.3598
Training Epoch: 15 [12288/50176]	Loss: 3.3974
Training Epoch: 15 [13312/50176]	Loss: 3.4122
Training Epoch: 15 [14336/50176]	Loss: 3.3670
Training Epoch: 15 [15360/50176]	Loss: 3.4179
Training Epoch: 15 [16384/50176]	Loss: 3.4199
Training Epoch: 15 [17408/50176]	Loss: 3.3797
Training Epoch: 15 [18432/50176]	Loss: 3.4248
Training Epoch: 15 [19456/50176]	Loss: 3.3407
Training Epoch: 15 [20480/50176]	Loss: 3.3507
Training Epoch: 15 [21504/50176]	Loss: 3.3432
Training Epoch: 15 [22528/50176]	Loss: 3.4753
Training Epoch: 15 [23552/50176]	Loss: 3.3829
Training Epoch: 15 [24576/50176]	Loss: 3.3174
Training Epoch: 15 [25600/50176]	Loss: 3.4616
Training Epoch: 15 [26624/50176]	Loss: 3.4064
Training Epoch: 15 [27648/50176]	Loss: 3.3719
Training Epoch: 15 [28672/50176]	Loss: 3.3302
Training Epoch: 15 [29696/50176]	Loss: 3.3129
Training Epoch: 15 [30720/50176]	Loss: 3.4132
Training Epoch: 15 [31744/50176]	Loss: 3.4255
Training Epoch: 15 [32768/50176]	Loss: 3.3824
Training Epoch: 15 [33792/50176]	Loss: 3.3980
Training Epoch: 15 [34816/50176]	Loss: 3.3335
Training Epoch: 15 [35840/50176]	Loss: 3.3850
Training Epoch: 15 [36864/50176]	Loss: 3.3376
Training Epoch: 15 [37888/50176]	Loss: 3.4130
Training Epoch: 15 [38912/50176]	Loss: 3.3570
Training Epoch: 15 [39936/50176]	Loss: 3.3214
Training Epoch: 15 [40960/50176]	Loss: 3.4241
Training Epoch: 15 [41984/50176]	Loss: 3.3645
Training Epoch: 15 [43008/50176]	Loss: 3.4059
Training Epoch: 15 [44032/50176]	Loss: 3.3678
Training Epoch: 15 [45056/50176]	Loss: 3.3739
Training Epoch: 15 [46080/50176]	Loss: 3.4119
Training Epoch: 15 [47104/50176]	Loss: 3.3199
Training Epoch: 15 [48128/50176]	Loss: 3.3279
Training Epoch: 15 [49152/50176]	Loss: 3.3749
Training Epoch: 15 [50176/50176]	Loss: 3.2915
2022-12-06 01:51:32.139 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:51:32,150 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.72 energy=524.05
2022-12-05 20:51:32,151 [ZeusDataLoader(train)] Up to epoch 16: time=886.94, energy=123579.53, cost=139397.44
2022-12-05 20:51:32,151 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:51:32,151 [ZeusDataLoader(train)] Expected next epoch: time=935.29, energy=130867.79, cost=147271.75
2022-12-05 20:51:32,152 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0033, Accuracy: 0.1851
2022-12-05 20:51:32,337 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:51:32,338 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:51:32.352 [ZeusMonitor] Monitor started.
2022-12-06 01:51:32.352 [ZeusMonitor] Running indefinitely. 2022-12-06 01:51:32.352 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:51:32.352 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e17+gpu0.power.log
2022-12-05 20:52:16,546 [ZeusDataLoader(train)] train epoch 17 done: time=44.39 energy=6753.61
2022-12-05 20:52:16,550 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 3.3416
Training Epoch: 16 [2048/50176]	Loss: 3.3934
Training Epoch: 16 [3072/50176]	Loss: 3.2760
Training Epoch: 16 [4096/50176]	Loss: 3.2911
Training Epoch: 16 [5120/50176]	Loss: 3.3726
Training Epoch: 16 [6144/50176]	Loss: 3.3453
Training Epoch: 16 [7168/50176]	Loss: 3.3206
Training Epoch: 16 [8192/50176]	Loss: 3.3447
Training Epoch: 16 [9216/50176]	Loss: 3.3326
Training Epoch: 16 [10240/50176]	Loss: 3.3415
Training Epoch: 16 [11264/50176]	Loss: 3.3850
Training Epoch: 16 [12288/50176]	Loss: 3.3448
Training Epoch: 16 [13312/50176]	Loss: 3.3897
Training Epoch: 16 [14336/50176]	Loss: 3.3370
Training Epoch: 16 [15360/50176]	Loss: 3.3740
Training Epoch: 16 [16384/50176]	Loss: 3.4336
Training Epoch: 16 [17408/50176]	Loss: 3.3447
Training Epoch: 16 [18432/50176]	Loss: 3.3792
Training Epoch: 16 [19456/50176]	Loss: 3.4185
Training Epoch: 16 [20480/50176]	Loss: 3.3295
Training Epoch: 16 [21504/50176]	Loss: 3.3865
Training Epoch: 16 [22528/50176]	Loss: 3.3674
Training Epoch: 16 [23552/50176]	Loss: 3.3690
Training Epoch: 16 [24576/50176]	Loss: 3.3203
Training Epoch: 16 [25600/50176]	Loss: 3.3307
Training Epoch: 16 [26624/50176]	Loss: 3.3850
Training Epoch: 16 [27648/50176]	Loss: 3.4072
Training Epoch: 16 [28672/50176]	Loss: 3.3213
Training Epoch: 16 [29696/50176]	Loss: 3.3068
Training Epoch: 16 [30720/50176]	Loss: 3.3345
Training Epoch: 16 [31744/50176]	Loss: 3.2755
Training Epoch: 16 [32768/50176]	Loss: 3.2839
Training Epoch: 16 [33792/50176]	Loss: 3.3434
Training Epoch: 16 [34816/50176]	Loss: 3.4498
Training Epoch: 16 [35840/50176]	Loss: 3.4723
Training Epoch: 16 [36864/50176]	Loss: 3.3398
Training Epoch: 16 [37888/50176]	Loss: 3.3272
Training Epoch: 16 [38912/50176]	Loss: 3.2796
Training Epoch: 16 [39936/50176]	Loss: 3.3731
Training Epoch: 16 [40960/50176]	Loss: 3.2796
Training Epoch: 16 [41984/50176]	Loss: 3.2979
Training Epoch: 16 [43008/50176]	Loss: 3.3512
Training Epoch: 16 [44032/50176]	Loss: 3.3230
Training Epoch: 16 [45056/50176]	Loss: 3.3096
Training Epoch: 16 [46080/50176]	Loss: 3.3437
Training Epoch: 16 [47104/50176]	Loss: 3.3581
Training Epoch: 16 [48128/50176]	Loss: 3.3660
Training Epoch: 16 [49152/50176]	Loss: 3.2903
Training Epoch: 16 [50176/50176]	Loss: 3.3520
2022-12-06 01:52:20.299 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:52:20,336 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.78 energy=530.92
2022-12-05 20:52:20,336 [ZeusDataLoader(train)] Up to epoch 17: time=935.11, energy=130864.06, cost=147254.04
2022-12-05 20:52:20,336 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:52:20,336 [ZeusDataLoader(train)] Expected next epoch: time=983.45, energy=138152.32, cost=155128.35
2022-12-05 20:52:20,337 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0033, Accuracy: 0.1909
2022-12-05 20:52:20,516 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:52:20,517 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:52:20.518 [ZeusMonitor] Monitor started.
2022-12-06 01:52:20.519 [ZeusMonitor] Running indefinitely. 2022-12-06 01:52:20.519 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:52:20.519 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e18+gpu0.power.log
2022-12-05 20:53:04,659 [ZeusDataLoader(train)] train epoch 18 done: time=44.31 energy=6752.83
2022-12-05 20:53:04,663 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 3.3402
Training Epoch: 17 [2048/50176]	Loss: 3.2594
Training Epoch: 17 [3072/50176]	Loss: 3.3033
Training Epoch: 17 [4096/50176]	Loss: 3.3471
Training Epoch: 17 [5120/50176]	Loss: 3.4163
Training Epoch: 17 [6144/50176]	Loss: 3.2954
Training Epoch: 17 [7168/50176]	Loss: 3.2921
Training Epoch: 17 [8192/50176]	Loss: 3.2937
Training Epoch: 17 [9216/50176]	Loss: 3.3100
Training Epoch: 17 [10240/50176]	Loss: 3.3083
Training Epoch: 17 [11264/50176]	Loss: 3.2843
Training Epoch: 17 [12288/50176]	Loss: 3.3341
Training Epoch: 17 [13312/50176]	Loss: 3.3500
Training Epoch: 17 [14336/50176]	Loss: 3.3287
Training Epoch: 17 [15360/50176]	Loss: 3.3283
Training Epoch: 17 [16384/50176]	Loss: 3.2590
Training Epoch: 17 [17408/50176]	Loss: 3.3402
Training Epoch: 17 [18432/50176]	Loss: 3.3308
Training Epoch: 17 [19456/50176]	Loss: 3.2950
Training Epoch: 17 [20480/50176]	Loss: 3.3013
Training Epoch: 17 [21504/50176]	Loss: 3.3059
Training Epoch: 17 [22528/50176]	Loss: 3.3344
Training Epoch: 17 [23552/50176]	Loss: 3.3131
Training Epoch: 17 [24576/50176]	Loss: 3.3614
Training Epoch: 17 [25600/50176]	Loss: 3.3174
Training Epoch: 17 [26624/50176]	Loss: 3.2657
Training Epoch: 17 [27648/50176]	Loss: 3.2661
Training Epoch: 17 [28672/50176]	Loss: 3.3034
Training Epoch: 17 [29696/50176]	Loss: 3.3234
Training Epoch: 17 [30720/50176]	Loss: 3.3160
Training Epoch: 17 [31744/50176]	Loss: 3.2545
Training Epoch: 17 [32768/50176]	Loss: 3.3042
Training Epoch: 17 [33792/50176]	Loss: 3.3203
Training Epoch: 17 [34816/50176]	Loss: 3.2815
Training Epoch: 17 [35840/50176]	Loss: 3.3096
Training Epoch: 17 [36864/50176]	Loss: 3.3841
Training Epoch: 17 [37888/50176]	Loss: 3.3659
Training Epoch: 17 [38912/50176]	Loss: 3.3203
Training Epoch: 17 [39936/50176]	Loss: 3.3652
Training Epoch: 17 [40960/50176]	Loss: 3.3581
Training Epoch: 17 [41984/50176]	Loss: 3.2880
Training Epoch: 17 [43008/50176]	Loss: 3.2431
Training Epoch: 17 [44032/50176]	Loss: 3.2876
Training Epoch: 17 [45056/50176]	Loss: 3.3108
Training Epoch: 17 [46080/50176]	Loss: 3.1644
Training Epoch: 17 [47104/50176]	Loss: 3.2492
Training Epoch: 17 [48128/50176]	Loss: 3.3223
Training Epoch: 17 [49152/50176]	Loss: 3.2993
Training Epoch: 17 [50176/50176]	Loss: 3.3035
2022-12-06 01:53:08.379 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:53:08,409 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.74 energy=522.42
2022-12-05 20:53:08,410 [ZeusDataLoader(train)] Up to epoch 18: time=983.16, energy=138139.31, cost=155096.26
2022-12-05 20:53:08,410 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:53:08,410 [ZeusDataLoader(train)] Expected next epoch: time=1031.51, energy=145427.57, cost=162970.57
2022-12-05 20:53:08,411 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0032, Accuracy: 0.1977
2022-12-05 20:53:08,589 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:53:08,590 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:53:08.603 [ZeusMonitor] Monitor started.
2022-12-06 01:53:08.604 [ZeusMonitor] Running indefinitely. 2022-12-06 01:53:08.604 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:53:08.604 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e19+gpu0.power.log
2022-12-05 20:53:52,667 [ZeusDataLoader(train)] train epoch 19 done: time=44.25 energy=6735.92
2022-12-05 20:53:52,671 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 3.2220
Training Epoch: 18 [2048/50176]	Loss: 3.2681
Training Epoch: 18 [3072/50176]	Loss: 3.2746
Training Epoch: 18 [4096/50176]	Loss: 3.2445
Training Epoch: 18 [5120/50176]	Loss: 3.2613
Training Epoch: 18 [6144/50176]	Loss: 3.3228
Training Epoch: 18 [7168/50176]	Loss: 3.2217
Training Epoch: 18 [8192/50176]	Loss: 3.2786
Training Epoch: 18 [9216/50176]	Loss: 3.2830
Training Epoch: 18 [10240/50176]	Loss: 3.3369
Training Epoch: 18 [11264/50176]	Loss: 3.3435
Training Epoch: 18 [12288/50176]	Loss: 3.2871
Training Epoch: 18 [13312/50176]	Loss: 3.2949
Training Epoch: 18 [14336/50176]	Loss: 3.2755
Training Epoch: 18 [15360/50176]	Loss: 3.2877
Training Epoch: 18 [16384/50176]	Loss: 3.2808
Training Epoch: 18 [17408/50176]	Loss: 3.2650
Training Epoch: 18 [18432/50176]	Loss: 3.3400
Training Epoch: 18 [19456/50176]	Loss: 3.3125
Training Epoch: 18 [20480/50176]	Loss: 3.2478
Training Epoch: 18 [21504/50176]	Loss: 3.3051
Training Epoch: 18 [22528/50176]	Loss: 3.2995
Training Epoch: 18 [23552/50176]	Loss: 3.2652
Training Epoch: 18 [24576/50176]	Loss: 3.2446
Training Epoch: 18 [25600/50176]	Loss: 3.1808
Training Epoch: 18 [26624/50176]	Loss: 3.1514
Training Epoch: 18 [27648/50176]	Loss: 3.3273
Training Epoch: 18 [28672/50176]	Loss: 3.3032
Training Epoch: 18 [29696/50176]	Loss: 3.3361
Training Epoch: 18 [30720/50176]	Loss: 3.2436
Training Epoch: 18 [31744/50176]	Loss: 3.3228
Training Epoch: 18 [32768/50176]	Loss: 3.2259
Training Epoch: 18 [33792/50176]	Loss: 3.2682
Training Epoch: 18 [34816/50176]	Loss: 3.2649
Training Epoch: 18 [35840/50176]	Loss: 3.3390
Training Epoch: 18 [36864/50176]	Loss: 3.2765
Training Epoch: 18 [37888/50176]	Loss: 3.2910
Training Epoch: 18 [38912/50176]	Loss: 3.2322
Training Epoch: 18 [39936/50176]	Loss: 3.2736
Training Epoch: 18 [40960/50176]	Loss: 3.2767
Training Epoch: 18 [41984/50176]	Loss: 3.3146
Training Epoch: 18 [43008/50176]	Loss: 3.2872
Training Epoch: 18 [44032/50176]	Loss: 3.2897
Training Epoch: 18 [45056/50176]	Loss: 3.2969
Training Epoch: 18 [46080/50176]	Loss: 3.2103
Training Epoch: 18 [47104/50176]	Loss: 3.2256
Training Epoch: 18 [48128/50176]	Loss: 3.3556
Training Epoch: 18 [49152/50176]	Loss: 3.2570
Training Epoch: 18 [50176/50176]	Loss: 3.3176
2022-12-06 01:53:56.370 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:53:56,391 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.71 energy=529.01
2022-12-05 20:53:56,391 [ZeusDataLoader(train)] Up to epoch 19: time=1031.12, energy=145404.24, cost=162925.14
2022-12-05 20:53:56,391 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:53:56,391 [ZeusDataLoader(train)] Expected next epoch: time=1079.47, energy=152692.50, cost=170799.45
2022-12-05 20:53:56,392 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0032, Accuracy: 0.2104
2022-12-05 20:53:56,537 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:53:56,538 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:53:56.541 [ZeusMonitor] Monitor started.
2022-12-06 01:53:56.541 [ZeusMonitor] Running indefinitely. 2022-12-06 01:53:56.542 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:53:56.542 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e20+gpu0.power.log
2022-12-05 20:54:40,665 [ZeusDataLoader(train)] train epoch 20 done: time=44.26 energy=6748.43
2022-12-05 20:54:40,668 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 3.1668
Training Epoch: 19 [2048/50176]	Loss: 3.2933
Training Epoch: 19 [3072/50176]	Loss: 3.2967
Training Epoch: 19 [4096/50176]	Loss: 3.2724
Training Epoch: 19 [5120/50176]	Loss: 3.1839
Training Epoch: 19 [6144/50176]	Loss: 3.1825
Training Epoch: 19 [7168/50176]	Loss: 3.1820
Training Epoch: 19 [8192/50176]	Loss: 3.2179
Training Epoch: 19 [9216/50176]	Loss: 3.2753
Training Epoch: 19 [10240/50176]	Loss: 3.3573
Training Epoch: 19 [11264/50176]	Loss: 3.2696
Training Epoch: 19 [12288/50176]	Loss: 3.2807
Training Epoch: 19 [13312/50176]	Loss: 3.1967
Training Epoch: 19 [14336/50176]	Loss: 3.2341
Training Epoch: 19 [15360/50176]	Loss: 3.3139
Training Epoch: 19 [16384/50176]	Loss: 3.2756
Training Epoch: 19 [17408/50176]	Loss: 3.2377
Training Epoch: 19 [18432/50176]	Loss: 3.2724
Training Epoch: 19 [19456/50176]	Loss: 3.2131
Training Epoch: 19 [20480/50176]	Loss: 3.2323
Training Epoch: 19 [21504/50176]	Loss: 3.2183
Training Epoch: 19 [22528/50176]	Loss: 3.2657
Training Epoch: 19 [23552/50176]	Loss: 3.3283
Training Epoch: 19 [24576/50176]	Loss: 3.2236
Training Epoch: 19 [25600/50176]	Loss: 3.2110
Training Epoch: 19 [26624/50176]	Loss: 3.2701
Training Epoch: 19 [27648/50176]	Loss: 3.2489
Training Epoch: 19 [28672/50176]	Loss: 3.2560
Training Epoch: 19 [29696/50176]	Loss: 3.2237
Training Epoch: 19 [30720/50176]	Loss: 3.2593
Training Epoch: 19 [31744/50176]	Loss: 3.2725
Training Epoch: 19 [32768/50176]	Loss: 3.2733
Training Epoch: 19 [33792/50176]	Loss: 3.2105
Training Epoch: 19 [34816/50176]	Loss: 3.2180
Training Epoch: 19 [35840/50176]	Loss: 3.2026
Training Epoch: 19 [36864/50176]	Loss: 3.1925
Training Epoch: 19 [37888/50176]	Loss: 3.1899
Training Epoch: 19 [38912/50176]	Loss: 3.2526
Training Epoch: 19 [39936/50176]	Loss: 3.2328
Training Epoch: 19 [40960/50176]	Loss: 3.1540
Training Epoch: 19 [41984/50176]	Loss: 3.1990
Training Epoch: 19 [43008/50176]	Loss: 3.2659
Training Epoch: 19 [44032/50176]	Loss: 3.2018
Training Epoch: 19 [45056/50176]	Loss: 3.2751
Training Epoch: 19 [46080/50176]	Loss: 3.1775
Training Epoch: 19 [47104/50176]	Loss: 3.1829
Training Epoch: 19 [48128/50176]	Loss: 3.1733
Training Epoch: 19 [49152/50176]	Loss: 3.2835
Training Epoch: 19 [50176/50176]	Loss: 3.1665
2022-12-06 01:54:44.376 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:54:44,393 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.72 energy=521.13
2022-12-05 20:54:44,393 [ZeusDataLoader(train)] Up to epoch 20: time=1079.10, energy=152673.80, cost=170758.23
2022-12-05 20:54:44,393 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:54:44,393 [ZeusDataLoader(train)] Expected next epoch: time=1127.45, energy=159962.06, cost=178632.54
2022-12-05 20:54:44,394 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0032, Accuracy: 0.2068
2022-12-05 20:54:44,536 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:54:44,537 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:54:44.541 [ZeusMonitor] Monitor started.
2022-12-06 01:54:44.541 [ZeusMonitor] Running indefinitely. 2022-12-06 01:54:44.541 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:54:44.541 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e21+gpu0.power.log
2022-12-05 20:55:28,669 [ZeusDataLoader(train)] train epoch 21 done: time=44.27 energy=6745.35
2022-12-05 20:55:28,673 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 3.1981
Training Epoch: 20 [2048/50176]	Loss: 3.1364
Training Epoch: 20 [3072/50176]	Loss: 3.2309
Training Epoch: 20 [4096/50176]	Loss: 3.1881
Training Epoch: 20 [5120/50176]	Loss: 3.1030
Training Epoch: 20 [6144/50176]	Loss: 3.2396
Training Epoch: 20 [7168/50176]	Loss: 3.1512
Training Epoch: 20 [8192/50176]	Loss: 3.2367
Training Epoch: 20 [9216/50176]	Loss: 3.2911
Training Epoch: 20 [10240/50176]	Loss: 3.1585
Training Epoch: 20 [11264/50176]	Loss: 3.2520
Training Epoch: 20 [12288/50176]	Loss: 3.2024
Training Epoch: 20 [13312/50176]	Loss: 3.1159
Training Epoch: 20 [14336/50176]	Loss: 3.2446
Training Epoch: 20 [15360/50176]	Loss: 3.2159
Training Epoch: 20 [16384/50176]	Loss: 3.2241
Training Epoch: 20 [17408/50176]	Loss: 3.1830
Training Epoch: 20 [18432/50176]	Loss: 3.2019
Training Epoch: 20 [19456/50176]	Loss: 3.2057
Training Epoch: 20 [20480/50176]	Loss: 3.1835
Training Epoch: 20 [21504/50176]	Loss: 3.2318
Training Epoch: 20 [22528/50176]	Loss: 3.1889
Training Epoch: 20 [23552/50176]	Loss: 3.1653
Training Epoch: 20 [24576/50176]	Loss: 3.2578
Training Epoch: 20 [25600/50176]	Loss: 3.2666
Training Epoch: 20 [26624/50176]	Loss: 3.2346
Training Epoch: 20 [27648/50176]	Loss: 3.2587
Training Epoch: 20 [28672/50176]	Loss: 3.2288
Training Epoch: 20 [29696/50176]	Loss: 3.2135
Training Epoch: 20 [30720/50176]	Loss: 3.1757
Training Epoch: 20 [31744/50176]	Loss: 3.1912
Training Epoch: 20 [32768/50176]	Loss: 3.1902
Training Epoch: 20 [33792/50176]	Loss: 3.1449
Training Epoch: 20 [34816/50176]	Loss: 3.2364
Training Epoch: 20 [35840/50176]	Loss: 3.1412
Training Epoch: 20 [36864/50176]	Loss: 3.2544
Training Epoch: 20 [37888/50176]	Loss: 3.1192
Training Epoch: 20 [38912/50176]	Loss: 3.2170
Training Epoch: 20 [39936/50176]	Loss: 3.1831
Training Epoch: 20 [40960/50176]	Loss: 3.2467
Training Epoch: 20 [41984/50176]	Loss: 3.1955
Training Epoch: 20 [43008/50176]	Loss: 3.1817
Training Epoch: 20 [44032/50176]	Loss: 3.1877
Training Epoch: 20 [45056/50176]	Loss: 3.2792
Training Epoch: 20 [46080/50176]	Loss: 3.2121
Training Epoch: 20 [47104/50176]	Loss: 3.2100
Training Epoch: 20 [48128/50176]	Loss: 3.1998
Training Epoch: 20 [49152/50176]	Loss: 3.2012
Training Epoch: 20 [50176/50176]	Loss: 3.1565
2022-12-06 01:55:32.406 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:55:32,426 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.74 energy=519.42
2022-12-05 20:55:32,426 [ZeusDataLoader(train)] Up to epoch 21: time=1127.11, energy=159938.57, cost=178591.64
2022-12-05 20:55:32,426 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:55:32,426 [ZeusDataLoader(train)] Expected next epoch: time=1175.46, energy=167226.84, cost=186465.96
2022-12-05 20:55:32,427 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0031, Accuracy: 0.2156
2022-12-05 20:55:32,632 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:55:32,633 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:55:32.635 [ZeusMonitor] Monitor started.
2022-12-06 01:55:32.635 [ZeusMonitor] Running indefinitely. 2022-12-06 01:55:32.635 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:55:32.635 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e22+gpu0.power.log
2022-12-05 20:56:16,700 [ZeusDataLoader(train)] train epoch 22 done: time=44.26 energy=6747.17
2022-12-05 20:56:16,704 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 3.1499
Training Epoch: 21 [2048/50176]	Loss: 3.1427
Training Epoch: 21 [3072/50176]	Loss: 3.2140
Training Epoch: 21 [4096/50176]	Loss: 3.1307
Training Epoch: 21 [5120/50176]	Loss: 3.2248
Training Epoch: 21 [6144/50176]	Loss: 3.1705
Training Epoch: 21 [7168/50176]	Loss: 3.1166
Training Epoch: 21 [8192/50176]	Loss: 3.1465
Training Epoch: 21 [9216/50176]	Loss: 3.1737
Training Epoch: 21 [10240/50176]	Loss: 3.1278
Training Epoch: 21 [11264/50176]	Loss: 3.1590
Training Epoch: 21 [12288/50176]	Loss: 3.2056
Training Epoch: 21 [13312/50176]	Loss: 3.1664
Training Epoch: 21 [14336/50176]	Loss: 3.1665
Training Epoch: 21 [15360/50176]	Loss: 3.1712
Training Epoch: 21 [16384/50176]	Loss: 3.1926
Training Epoch: 21 [17408/50176]	Loss: 3.1021
Training Epoch: 21 [18432/50176]	Loss: 3.1429
Training Epoch: 21 [19456/50176]	Loss: 3.2182
Training Epoch: 21 [20480/50176]	Loss: 3.1630
Training Epoch: 21 [21504/50176]	Loss: 3.1855
Training Epoch: 21 [22528/50176]	Loss: 3.1441
Training Epoch: 21 [23552/50176]	Loss: 3.2055
Training Epoch: 21 [24576/50176]	Loss: 3.1016
Training Epoch: 21 [25600/50176]	Loss: 3.1273
Training Epoch: 21 [26624/50176]	Loss: 3.1674
Training Epoch: 21 [27648/50176]	Loss: 3.1247
Training Epoch: 21 [28672/50176]	Loss: 3.1302
Training Epoch: 21 [29696/50176]	Loss: 3.1998
Training Epoch: 21 [30720/50176]	Loss: 3.0683
Training Epoch: 21 [31744/50176]	Loss: 3.1472
Training Epoch: 21 [32768/50176]	Loss: 3.2092
Training Epoch: 21 [33792/50176]	Loss: 3.2075
Training Epoch: 21 [34816/50176]	Loss: 3.1876
Training Epoch: 21 [35840/50176]	Loss: 3.2104
Training Epoch: 21 [36864/50176]	Loss: 3.1380
Training Epoch: 21 [37888/50176]	Loss: 3.1628
Training Epoch: 21 [38912/50176]	Loss: 3.1612
Training Epoch: 21 [39936/50176]	Loss: 3.1483
Training Epoch: 21 [40960/50176]	Loss: 3.1966
Training Epoch: 21 [41984/50176]	Loss: 3.1810
Training Epoch: 21 [43008/50176]	Loss: 3.1743
Training Epoch: 21 [44032/50176]	Loss: 3.1817
Training Epoch: 21 [45056/50176]	Loss: 3.2143
Training Epoch: 21 [46080/50176]	Loss: 3.1984
Training Epoch: 21 [47104/50176]	Loss: 3.1826
Training Epoch: 21 [48128/50176]	Loss: 3.1261
Training Epoch: 21 [49152/50176]	Loss: 3.1700
Training Epoch: 21 [50176/50176]	Loss: 3.2486
2022-12-06 01:56:20.446 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:56:20,469 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.76 energy=518.76
2022-12-05 20:56:20,470 [ZeusDataLoader(train)] Up to epoch 22: time=1175.13, energy=167204.51, cost=186426.47
2022-12-05 20:56:20,470 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:56:20,470 [ZeusDataLoader(train)] Expected next epoch: time=1223.48, energy=174492.77, cost=194300.78
2022-12-05 20:56:20,471 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0031, Accuracy: 0.2261
2022-12-05 20:56:20,657 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:56:20,658 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:56:20.668 [ZeusMonitor] Monitor started.
2022-12-06 01:56:20.668 [ZeusMonitor] Running indefinitely. 2022-12-06 01:56:20.668 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:56:20.668 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e23+gpu0.power.log
2022-12-05 20:57:04,763 [ZeusDataLoader(train)] train epoch 23 done: time=44.28 energy=6738.30
2022-12-05 20:57:04,767 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 3.1878
Training Epoch: 22 [2048/50176]	Loss: 3.1379
Training Epoch: 22 [3072/50176]	Loss: 3.2030
Training Epoch: 22 [4096/50176]	Loss: 3.1199
Training Epoch: 22 [5120/50176]	Loss: 3.1297
Training Epoch: 22 [6144/50176]	Loss: 3.1516
Training Epoch: 22 [7168/50176]	Loss: 3.1222
Training Epoch: 22 [8192/50176]	Loss: 3.1560
Training Epoch: 22 [9216/50176]	Loss: 3.1576
Training Epoch: 22 [10240/50176]	Loss: 3.0912
Training Epoch: 22 [11264/50176]	Loss: 3.2112
Training Epoch: 22 [12288/50176]	Loss: 3.1889
Training Epoch: 22 [13312/50176]	Loss: 3.1201
Training Epoch: 22 [14336/50176]	Loss: 3.1275
Training Epoch: 22 [15360/50176]	Loss: 3.0562
Training Epoch: 22 [16384/50176]	Loss: 3.1398
Training Epoch: 22 [17408/50176]	Loss: 3.0757
Training Epoch: 22 [18432/50176]	Loss: 3.1167
Training Epoch: 22 [19456/50176]	Loss: 3.1424
Training Epoch: 22 [20480/50176]	Loss: 3.1924
Training Epoch: 22 [21504/50176]	Loss: 3.1610
Training Epoch: 22 [22528/50176]	Loss: 3.1533
Training Epoch: 22 [23552/50176]	Loss: 3.0651
Training Epoch: 22 [24576/50176]	Loss: 3.1354
Training Epoch: 22 [25600/50176]	Loss: 3.2031
Training Epoch: 22 [26624/50176]	Loss: 3.0946
Training Epoch: 22 [27648/50176]	Loss: 3.1506
Training Epoch: 22 [28672/50176]	Loss: 3.1666
Training Epoch: 22 [29696/50176]	Loss: 3.0741
Training Epoch: 22 [30720/50176]	Loss: 3.0836
Training Epoch: 22 [31744/50176]	Loss: 3.2407
Training Epoch: 22 [32768/50176]	Loss: 3.0514
Training Epoch: 22 [33792/50176]	Loss: 3.0908
Training Epoch: 22 [34816/50176]	Loss: 3.1537
Training Epoch: 22 [35840/50176]	Loss: 3.1291
Training Epoch: 22 [36864/50176]	Loss: 3.1059
Training Epoch: 22 [37888/50176]	Loss: 3.1519
Training Epoch: 22 [38912/50176]	Loss: 3.0928
Training Epoch: 22 [39936/50176]	Loss: 3.1205
Training Epoch: 22 [40960/50176]	Loss: 3.1689
Training Epoch: 22 [41984/50176]	Loss: 3.1619
Training Epoch: 22 [43008/50176]	Loss: 3.1090
Training Epoch: 22 [44032/50176]	Loss: 3.0705
Training Epoch: 22 [45056/50176]	Loss: 3.1666
Training Epoch: 22 [46080/50176]	Loss: 3.1130
Training Epoch: 22 [47104/50176]	Loss: 3.1070
Training Epoch: 22 [48128/50176]	Loss: 3.2412
Training Epoch: 22 [49152/50176]	Loss: 3.1218
Training Epoch: 22 [50176/50176]	Loss: 3.0545
2022-12-06 01:57:08.476 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:57:08,493 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.72 energy=519.05
2022-12-05 20:57:08,493 [ZeusDataLoader(train)] Up to epoch 23: time=1223.13, energy=174461.85, cost=194255.22
2022-12-05 20:57:08,493 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:57:08,493 [ZeusDataLoader(train)] Expected next epoch: time=1271.48, energy=181750.11, cost=202129.53
2022-12-05 20:57:08,494 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0030, Accuracy: 0.2315
2022-12-05 20:57:08,639 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:57:08,640 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:57:08.643 [ZeusMonitor] Monitor started.
2022-12-06 01:57:08.643 [ZeusMonitor] Running indefinitely. 2022-12-06 01:57:08.643 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:57:08.643 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e24+gpu0.power.log
2022-12-05 20:57:52,806 [ZeusDataLoader(train)] train epoch 24 done: time=44.30 energy=6754.36
2022-12-05 20:57:52,810 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 3.1112
Training Epoch: 23 [2048/50176]	Loss: 3.0745
Training Epoch: 23 [3072/50176]	Loss: 3.0951
Training Epoch: 23 [4096/50176]	Loss: 3.1363
Training Epoch: 23 [5120/50176]	Loss: 3.0544
Training Epoch: 23 [6144/50176]	Loss: 3.1524
Training Epoch: 23 [7168/50176]	Loss: 3.0880
Training Epoch: 23 [8192/50176]	Loss: 3.0653
Training Epoch: 23 [9216/50176]	Loss: 3.0592
Training Epoch: 23 [10240/50176]	Loss: 3.0925
Training Epoch: 23 [11264/50176]	Loss: 3.1271
Training Epoch: 23 [12288/50176]	Loss: 3.0546
Training Epoch: 23 [13312/50176]	Loss: 3.1134
Training Epoch: 23 [14336/50176]	Loss: 3.0997
Training Epoch: 23 [15360/50176]	Loss: 3.0829
Training Epoch: 23 [16384/50176]	Loss: 3.0866
Training Epoch: 23 [17408/50176]	Loss: 3.1882
Training Epoch: 23 [18432/50176]	Loss: 3.1491
Training Epoch: 23 [19456/50176]	Loss: 3.0710
Training Epoch: 23 [20480/50176]	Loss: 3.0576
Training Epoch: 23 [21504/50176]	Loss: 3.1143
Training Epoch: 23 [22528/50176]	Loss: 3.0871
Training Epoch: 23 [23552/50176]	Loss: 3.0422
Training Epoch: 23 [24576/50176]	Loss: 3.0243
Training Epoch: 23 [25600/50176]	Loss: 3.1358
Training Epoch: 23 [26624/50176]	Loss: 3.1549
Training Epoch: 23 [27648/50176]	Loss: 3.0786
Training Epoch: 23 [28672/50176]	Loss: 3.0363
Training Epoch: 23 [29696/50176]	Loss: 3.0285
Training Epoch: 23 [30720/50176]	Loss: 3.1690
Training Epoch: 23 [31744/50176]	Loss: 3.0836
Training Epoch: 23 [32768/50176]	Loss: 3.1567
Training Epoch: 23 [33792/50176]	Loss: 3.1097
Training Epoch: 23 [34816/50176]	Loss: 3.0905
Training Epoch: 23 [35840/50176]	Loss: 3.1595
Training Epoch: 23 [36864/50176]	Loss: 3.0680
Training Epoch: 23 [37888/50176]	Loss: 3.1330
Training Epoch: 23 [38912/50176]	Loss: 3.0303
Training Epoch: 23 [39936/50176]	Loss: 3.0632
Training Epoch: 23 [40960/50176]	Loss: 3.1148
Training Epoch: 23 [41984/50176]	Loss: 3.1506
Training Epoch: 23 [43008/50176]	Loss: 3.0816
Training Epoch: 23 [44032/50176]	Loss: 3.0811
Training Epoch: 23 [45056/50176]	Loss: 3.0957
Training Epoch: 23 [46080/50176]	Loss: 3.1829
Training Epoch: 23 [47104/50176]	Loss: 3.1111
Training Epoch: 23 [48128/50176]	Loss: 3.0081
Training Epoch: 23 [49152/50176]	Loss: 3.0542
Training Epoch: 23 [50176/50176]	Loss: 3.0545
2022-12-06 01:57:56.499 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:57:56,516 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.70 energy=518.92
2022-12-05 20:57:56,517 [ZeusDataLoader(train)] Up to epoch 24: time=1271.14, energy=181735.14, cost=202092.04
2022-12-05 20:57:56,517 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:57:56,517 [ZeusDataLoader(train)] Expected next epoch: time=1319.48, energy=189023.40, cost=209966.35
2022-12-05 20:57:56,518 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0030, Accuracy: 0.2356
2022-12-05 20:57:56,704 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:57:56,705 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:57:56.707 [ZeusMonitor] Monitor started.
2022-12-06 01:57:56.707 [ZeusMonitor] Running indefinitely. 2022-12-06 01:57:56.707 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:57:56.707 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e25+gpu0.power.log
2022-12-05 20:58:40,873 [ZeusDataLoader(train)] train epoch 25 done: time=44.35 energy=6745.16
2022-12-05 20:58:40,877 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 3.0507
Training Epoch: 24 [2048/50176]	Loss: 3.0219
Training Epoch: 24 [3072/50176]	Loss: 3.0416
Training Epoch: 24 [4096/50176]	Loss: 3.0157
Training Epoch: 24 [5120/50176]	Loss: 3.0419
Training Epoch: 24 [6144/50176]	Loss: 3.0189
Training Epoch: 24 [7168/50176]	Loss: 3.1038
Training Epoch: 24 [8192/50176]	Loss: 3.0951
Training Epoch: 24 [9216/50176]	Loss: 3.1729
Training Epoch: 24 [10240/50176]	Loss: 3.1280
Training Epoch: 24 [11264/50176]	Loss: 3.0427
Training Epoch: 24 [12288/50176]	Loss: 3.0288
Training Epoch: 24 [13312/50176]	Loss: 3.0858
Training Epoch: 24 [14336/50176]	Loss: 3.0298
Training Epoch: 24 [15360/50176]	Loss: 3.0310
Training Epoch: 24 [16384/50176]	Loss: 2.9915
Training Epoch: 24 [17408/50176]	Loss: 3.0655
Training Epoch: 24 [18432/50176]	Loss: 3.0618
Training Epoch: 24 [19456/50176]	Loss: 3.0875
Training Epoch: 24 [20480/50176]	Loss: 3.0466
Training Epoch: 24 [21504/50176]	Loss: 3.0178
Training Epoch: 24 [22528/50176]	Loss: 3.0564
Training Epoch: 24 [23552/50176]	Loss: 3.0870
Training Epoch: 24 [24576/50176]	Loss: 2.9779
Training Epoch: 24 [25600/50176]	Loss: 3.1126
Training Epoch: 24 [26624/50176]	Loss: 3.0395
Training Epoch: 24 [27648/50176]	Loss: 3.2281
Training Epoch: 24 [28672/50176]	Loss: 3.0628
Training Epoch: 24 [29696/50176]	Loss: 3.0217
Training Epoch: 24 [30720/50176]	Loss: 3.0334
Training Epoch: 24 [31744/50176]	Loss: 3.1158
Training Epoch: 24 [32768/50176]	Loss: 3.0926
Training Epoch: 24 [33792/50176]	Loss: 3.0428
Training Epoch: 24 [34816/50176]	Loss: 3.0669
Training Epoch: 24 [35840/50176]	Loss: 3.0804
Training Epoch: 24 [36864/50176]	Loss: 3.0488
Training Epoch: 24 [37888/50176]	Loss: 3.0255
Training Epoch: 24 [38912/50176]	Loss: 3.0548
Training Epoch: 24 [39936/50176]	Loss: 3.0836
Training Epoch: 24 [40960/50176]	Loss: 3.0106
Training Epoch: 24 [41984/50176]	Loss: 3.0618
Training Epoch: 24 [43008/50176]	Loss: 3.0717
Training Epoch: 24 [44032/50176]	Loss: 3.0383
Training Epoch: 24 [45056/50176]	Loss: 3.0297
Training Epoch: 24 [46080/50176]	Loss: 3.0787
Training Epoch: 24 [47104/50176]	Loss: 3.0870
Training Epoch: 24 [48128/50176]	Loss: 3.0864
Training Epoch: 24 [49152/50176]	Loss: 3.0374
Training Epoch: 24 [50176/50176]	Loss: 3.0584
2022-12-06 01:58:44.575 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:58:44,584 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.70 energy=519.82
2022-12-05 20:58:44,584 [ZeusDataLoader(train)] Up to epoch 25: time=1319.18, energy=189000.13, cost=209928.52
2022-12-05 20:58:44,585 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:58:44,585 [ZeusDataLoader(train)] Expected next epoch: time=1367.53, energy=196288.39, cost=217802.83
2022-12-05 20:58:44,586 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0030, Accuracy: 0.2436
2022-12-05 20:58:44,769 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:58:44,770 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:58:44.784 [ZeusMonitor] Monitor started.
2022-12-06 01:58:44.784 [ZeusMonitor] Running indefinitely. 2022-12-06 01:58:44.784 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:58:44.784 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e26+gpu0.power.log
2022-12-05 20:59:28,980 [ZeusDataLoader(train)] train epoch 26 done: time=44.39 energy=6763.40
2022-12-05 20:59:28,984 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 2.9583
Training Epoch: 25 [2048/50176]	Loss: 3.0367
Training Epoch: 25 [3072/50176]	Loss: 3.0912
Training Epoch: 25 [4096/50176]	Loss: 3.1097
Training Epoch: 25 [5120/50176]	Loss: 3.0231
Training Epoch: 25 [6144/50176]	Loss: 3.0760
Training Epoch: 25 [7168/50176]	Loss: 2.9919
Training Epoch: 25 [8192/50176]	Loss: 3.0498
Training Epoch: 25 [9216/50176]	Loss: 3.0816
Training Epoch: 25 [10240/50176]	Loss: 2.9566
Training Epoch: 25 [11264/50176]	Loss: 3.0068
Training Epoch: 25 [12288/50176]	Loss: 3.0699
Training Epoch: 25 [13312/50176]	Loss: 3.0332
Training Epoch: 25 [14336/50176]	Loss: 2.9676
Training Epoch: 25 [15360/50176]	Loss: 3.0117
Training Epoch: 25 [16384/50176]	Loss: 3.0759
Training Epoch: 25 [17408/50176]	Loss: 3.0219
Training Epoch: 25 [18432/50176]	Loss: 3.0315
Training Epoch: 25 [19456/50176]	Loss: 2.9465
Training Epoch: 25 [20480/50176]	Loss: 3.0466
Training Epoch: 25 [21504/50176]	Loss: 2.9307
Training Epoch: 25 [22528/50176]	Loss: 3.0542
Training Epoch: 25 [23552/50176]	Loss: 2.9975
Training Epoch: 25 [24576/50176]	Loss: 2.9368
Training Epoch: 25 [25600/50176]	Loss: 2.9551
Training Epoch: 25 [26624/50176]	Loss: 3.1151
Training Epoch: 25 [27648/50176]	Loss: 3.0574
Training Epoch: 25 [28672/50176]	Loss: 3.0607
Training Epoch: 25 [29696/50176]	Loss: 3.1153
Training Epoch: 25 [30720/50176]	Loss: 3.0000
Training Epoch: 25 [31744/50176]	Loss: 3.0375
Training Epoch: 25 [32768/50176]	Loss: 3.0345
Training Epoch: 25 [33792/50176]	Loss: 3.0956
Training Epoch: 25 [34816/50176]	Loss: 3.0495
Training Epoch: 25 [35840/50176]	Loss: 3.0079
Training Epoch: 25 [36864/50176]	Loss: 3.0022
Training Epoch: 25 [37888/50176]	Loss: 3.0657
Training Epoch: 25 [38912/50176]	Loss: 3.0632
Training Epoch: 25 [39936/50176]	Loss: 2.9570
Training Epoch: 25 [40960/50176]	Loss: 2.9945
Training Epoch: 25 [41984/50176]	Loss: 2.9971
Training Epoch: 25 [43008/50176]	Loss: 3.0466
Training Epoch: 25 [44032/50176]	Loss: 2.9796
Training Epoch: 25 [45056/50176]	Loss: 3.0634
Training Epoch: 25 [46080/50176]	Loss: 2.9482
Training Epoch: 25 [47104/50176]	Loss: 3.0280
Training Epoch: 25 [48128/50176]	Loss: 3.0093
Training Epoch: 25 [49152/50176]	Loss: 3.0456
Training Epoch: 25 [50176/50176]	Loss: 3.0213
2022-12-06 01:59:32.705 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 20:59:32,716 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.72 energy=519.91
2022-12-05 20:59:32,716 [ZeusDataLoader(train)] Up to epoch 26: time=1367.29, energy=196283.44, cost=217779.82
2022-12-05 20:59:32,717 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 20:59:32,717 [ZeusDataLoader(train)] Expected next epoch: time=1415.64, energy=203571.70, cost=225654.14
2022-12-05 20:59:32,718 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0030, Accuracy: 0.2504
2022-12-05 20:59:32,904 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 20:59:32,905 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 01:59:32.907 [ZeusMonitor] Monitor started.
2022-12-06 01:59:32.907 [ZeusMonitor] Running indefinitely. 2022-12-06 01:59:32.907 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 01:59:32.907 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e27+gpu0.power.log
2022-12-05 21:00:17,003 [ZeusDataLoader(train)] train epoch 27 done: time=44.28 energy=6726.89
2022-12-05 21:00:17,006 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 3.0667
Training Epoch: 26 [2048/50176]	Loss: 3.0396
Training Epoch: 26 [3072/50176]	Loss: 3.0194
Training Epoch: 26 [4096/50176]	Loss: 3.0312
Training Epoch: 26 [5120/50176]	Loss: 2.9901
Training Epoch: 26 [6144/50176]	Loss: 3.0140
Training Epoch: 26 [7168/50176]	Loss: 3.0173
Training Epoch: 26 [8192/50176]	Loss: 2.9408
Training Epoch: 26 [9216/50176]	Loss: 2.9328
Training Epoch: 26 [10240/50176]	Loss: 3.0517
Training Epoch: 26 [11264/50176]	Loss: 2.9299
Training Epoch: 26 [12288/50176]	Loss: 3.0176
Training Epoch: 26 [13312/50176]	Loss: 2.9107
Training Epoch: 26 [14336/50176]	Loss: 2.9842
Training Epoch: 26 [15360/50176]	Loss: 2.9812
Training Epoch: 26 [16384/50176]	Loss: 2.9086
Training Epoch: 26 [17408/50176]	Loss: 3.0398
Training Epoch: 26 [18432/50176]	Loss: 3.0190
Training Epoch: 26 [19456/50176]	Loss: 2.9796
Training Epoch: 26 [20480/50176]	Loss: 2.9167
Training Epoch: 26 [21504/50176]	Loss: 2.9153
Training Epoch: 26 [22528/50176]	Loss: 2.9776
Training Epoch: 26 [23552/50176]	Loss: 3.0110
Training Epoch: 26 [24576/50176]	Loss: 3.0581
Training Epoch: 26 [25600/50176]	Loss: 3.0219
Training Epoch: 26 [26624/50176]	Loss: 3.0286
Training Epoch: 26 [27648/50176]	Loss: 3.0208
Training Epoch: 26 [28672/50176]	Loss: 2.9956
Training Epoch: 26 [29696/50176]	Loss: 3.0047
Training Epoch: 26 [30720/50176]	Loss: 2.9868
Training Epoch: 26 [31744/50176]	Loss: 3.0359
Training Epoch: 26 [32768/50176]	Loss: 2.9865
Training Epoch: 26 [33792/50176]	Loss: 3.0329
Training Epoch: 26 [34816/50176]	Loss: 2.9813
Training Epoch: 26 [35840/50176]	Loss: 3.0251
Training Epoch: 26 [36864/50176]	Loss: 2.9655
Training Epoch: 26 [37888/50176]	Loss: 3.0004
Training Epoch: 26 [38912/50176]	Loss: 2.9226
Training Epoch: 26 [39936/50176]	Loss: 3.0258
Training Epoch: 26 [40960/50176]	Loss: 2.9613
Training Epoch: 26 [41984/50176]	Loss: 2.9953
Training Epoch: 26 [43008/50176]	Loss: 3.0589
Training Epoch: 26 [44032/50176]	Loss: 2.9637
Training Epoch: 26 [45056/50176]	Loss: 2.9936
Training Epoch: 26 [46080/50176]	Loss: 2.9775
Training Epoch: 26 [47104/50176]	Loss: 3.0090
Training Epoch: 26 [48128/50176]	Loss: 3.0689
Training Epoch: 26 [49152/50176]	Loss: 2.9557
Training Epoch: 26 [50176/50176]	Loss: 2.9381
2022-12-06 02:00:20.791 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:00:20,820 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.81 energy=535.60
2022-12-05 21:00:20,820 [ZeusDataLoader(train)] Up to epoch 27: time=1415.37, energy=203545.92, cost=225618.24
2022-12-05 21:00:20,820 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:00:20,820 [ZeusDataLoader(train)] Expected next epoch: time=1463.72, energy=210834.18, cost=233492.56
2022-12-05 21:00:20,821 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0029, Accuracy: 0.2573
2022-12-05 21:00:21,004 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:00:21,005 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:00:21.020 [ZeusMonitor] Monitor started.
2022-12-06 02:00:21.020 [ZeusMonitor] Running indefinitely. 2022-12-06 02:00:21.020 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:00:21.020 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e28+gpu0.power.log
2022-12-05 21:01:05,097 [ZeusDataLoader(train)] train epoch 28 done: time=44.27 energy=6739.71
2022-12-05 21:01:05,101 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 2.9846
Training Epoch: 27 [2048/50176]	Loss: 2.8999
Training Epoch: 27 [3072/50176]	Loss: 2.9289
Training Epoch: 27 [4096/50176]	Loss: 2.9426
Training Epoch: 27 [5120/50176]	Loss: 2.9744
Training Epoch: 27 [6144/50176]	Loss: 2.9185
Training Epoch: 27 [7168/50176]	Loss: 2.8386
Training Epoch: 27 [8192/50176]	Loss: 3.0020
Training Epoch: 27 [9216/50176]	Loss: 2.8950
Training Epoch: 27 [10240/50176]	Loss: 3.0849
Training Epoch: 27 [11264/50176]	Loss: 2.9441
Training Epoch: 27 [12288/50176]	Loss: 2.8469
Training Epoch: 27 [13312/50176]	Loss: 3.0344
Training Epoch: 27 [14336/50176]	Loss: 2.9763
Training Epoch: 27 [15360/50176]	Loss: 2.9360
Training Epoch: 27 [16384/50176]	Loss: 2.9746
Training Epoch: 27 [17408/50176]	Loss: 2.9349
Training Epoch: 27 [18432/50176]	Loss: 3.0081
Training Epoch: 27 [19456/50176]	Loss: 2.9776
Training Epoch: 27 [20480/50176]	Loss: 2.9340
Training Epoch: 27 [21504/50176]	Loss: 3.0076
Training Epoch: 27 [22528/50176]	Loss: 2.9549
Training Epoch: 27 [23552/50176]	Loss: 2.9593
Training Epoch: 27 [24576/50176]	Loss: 2.9654
Training Epoch: 27 [25600/50176]	Loss: 2.9299
Training Epoch: 27 [26624/50176]	Loss: 3.0092
Training Epoch: 27 [27648/50176]	Loss: 3.0331
Training Epoch: 27 [28672/50176]	Loss: 2.9254
Training Epoch: 27 [29696/50176]	Loss: 2.9785
Training Epoch: 27 [30720/50176]	Loss: 2.8896
Training Epoch: 27 [31744/50176]	Loss: 2.9875
Training Epoch: 27 [32768/50176]	Loss: 3.0403
Training Epoch: 27 [33792/50176]	Loss: 2.8940
Training Epoch: 27 [34816/50176]	Loss: 3.0051
Training Epoch: 27 [35840/50176]	Loss: 3.0409
Training Epoch: 27 [36864/50176]	Loss: 2.9920
Training Epoch: 27 [37888/50176]	Loss: 2.8922
Training Epoch: 27 [38912/50176]	Loss: 2.9656
Training Epoch: 27 [39936/50176]	Loss: 3.0032
Training Epoch: 27 [40960/50176]	Loss: 2.9509
Training Epoch: 27 [41984/50176]	Loss: 2.9637
Training Epoch: 27 [43008/50176]	Loss: 2.9523
Training Epoch: 27 [44032/50176]	Loss: 3.0147
Training Epoch: 27 [45056/50176]	Loss: 2.9079
Training Epoch: 27 [46080/50176]	Loss: 2.9732
Training Epoch: 27 [47104/50176]	Loss: 3.0477
Training Epoch: 27 [48128/50176]	Loss: 2.9468
Training Epoch: 27 [49152/50176]	Loss: 3.0086
Training Epoch: 27 [50176/50176]	Loss: 2.9429
2022-12-06 02:01:08.825 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:01:08,848 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=526.31
2022-12-05 21:01:08,848 [ZeusDataLoader(train)] Up to epoch 28: time=1463.38, energy=210811.94, cost=233451.75
2022-12-05 21:01:08,849 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:01:08,849 [ZeusDataLoader(train)] Expected next epoch: time=1511.73, energy=218100.20, cost=241326.07
2022-12-05 21:01:08,850 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0029, Accuracy: 0.2652
2022-12-05 21:01:09,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:01:09,033 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:01:09.048 [ZeusMonitor] Monitor started.
2022-12-06 02:01:09.049 [ZeusMonitor] Running indefinitely. 2022-12-06 02:01:09.049 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:01:09.049 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e29+gpu0.power.log
2022-12-05 21:01:53,168 [ZeusDataLoader(train)] train epoch 29 done: time=44.31 energy=6744.32
2022-12-05 21:01:53,172 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 2.9064
Training Epoch: 28 [2048/50176]	Loss: 2.9915
Training Epoch: 28 [3072/50176]	Loss: 2.9309
Training Epoch: 28 [4096/50176]	Loss: 2.9441
Training Epoch: 28 [5120/50176]	Loss: 2.8669
Training Epoch: 28 [6144/50176]	Loss: 2.9613
Training Epoch: 28 [7168/50176]	Loss: 2.9491
Training Epoch: 28 [8192/50176]	Loss: 2.9262
Training Epoch: 28 [9216/50176]	Loss: 2.9352
Training Epoch: 28 [10240/50176]	Loss: 2.9288
Training Epoch: 28 [11264/50176]	Loss: 2.9278
Training Epoch: 28 [12288/50176]	Loss: 2.9512
Training Epoch: 28 [13312/50176]	Loss: 2.9194
Training Epoch: 28 [14336/50176]	Loss: 2.9496
Training Epoch: 28 [15360/50176]	Loss: 2.9152
Training Epoch: 28 [16384/50176]	Loss: 2.8757
Training Epoch: 28 [17408/50176]	Loss: 2.9413
Training Epoch: 28 [18432/50176]	Loss: 2.9510
Training Epoch: 28 [19456/50176]	Loss: 2.9796
Training Epoch: 28 [20480/50176]	Loss: 2.8734
Training Epoch: 28 [21504/50176]	Loss: 2.9128
Training Epoch: 28 [22528/50176]	Loss: 2.9626
Training Epoch: 28 [23552/50176]	Loss: 2.9129
Training Epoch: 28 [24576/50176]	Loss: 2.8663
Training Epoch: 28 [25600/50176]	Loss: 2.9180
Training Epoch: 28 [26624/50176]	Loss: 2.8857
Training Epoch: 28 [27648/50176]	Loss: 2.9737
Training Epoch: 28 [28672/50176]	Loss: 2.8867
Training Epoch: 28 [29696/50176]	Loss: 2.9130
Training Epoch: 28 [30720/50176]	Loss: 2.9047
Training Epoch: 28 [31744/50176]	Loss: 2.9925
Training Epoch: 28 [32768/50176]	Loss: 2.9036
Training Epoch: 28 [33792/50176]	Loss: 2.9133
Training Epoch: 28 [34816/50176]	Loss: 2.9421
Training Epoch: 28 [35840/50176]	Loss: 2.9160
Training Epoch: 28 [36864/50176]	Loss: 2.9875
Training Epoch: 28 [37888/50176]	Loss: 2.9157
Training Epoch: 28 [38912/50176]	Loss: 2.9535
Training Epoch: 28 [39936/50176]	Loss: 2.9383
Training Epoch: 28 [40960/50176]	Loss: 2.9500
Training Epoch: 28 [41984/50176]	Loss: 2.9263
Training Epoch: 28 [43008/50176]	Loss: 2.9005
Training Epoch: 28 [44032/50176]	Loss: 2.9294
Training Epoch: 28 [45056/50176]	Loss: 2.9684
Training Epoch: 28 [46080/50176]	Loss: 2.9581
Training Epoch: 28 [47104/50176]	Loss: 2.9157
Training Epoch: 28 [48128/50176]	Loss: 2.9604
Training Epoch: 28 [49152/50176]	Loss: 2.9182
Training Epoch: 28 [50176/50176]	Loss: 2.9488
2022-12-06 02:01:56.888 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:01:56,925 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.74 energy=519.66
2022-12-05 21:01:56,925 [ZeusDataLoader(train)] Up to epoch 29: time=1511.44, energy=218075.93, cost=241288.53
2022-12-05 21:01:56,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:01:56,925 [ZeusDataLoader(train)] Expected next epoch: time=1559.78, energy=225364.19, cost=249162.85
2022-12-05 21:01:56,926 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0029, Accuracy: 0.2674
2022-12-05 21:01:57,076 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:01:57,077 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:01:57.081 [ZeusMonitor] Monitor started.
2022-12-06 02:01:57.081 [ZeusMonitor] Running indefinitely. 2022-12-06 02:01:57.081 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:01:57.081 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e30+gpu0.power.log
2022-12-05 21:02:41,191 [ZeusDataLoader(train)] train epoch 30 done: time=44.26 energy=6749.13
2022-12-05 21:02:41,195 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 2.9293
Training Epoch: 29 [2048/50176]	Loss: 2.8868
Training Epoch: 29 [3072/50176]	Loss: 2.8628
Training Epoch: 29 [4096/50176]	Loss: 2.9545
Training Epoch: 29 [5120/50176]	Loss: 2.9360
Training Epoch: 29 [6144/50176]	Loss: 2.9641
Training Epoch: 29 [7168/50176]	Loss: 2.9146
Training Epoch: 29 [8192/50176]	Loss: 2.8119
Training Epoch: 29 [9216/50176]	Loss: 2.9650
Training Epoch: 29 [10240/50176]	Loss: 2.8762
Training Epoch: 29 [11264/50176]	Loss: 2.9035
Training Epoch: 29 [12288/50176]	Loss: 2.9679
Training Epoch: 29 [13312/50176]	Loss: 2.8017
Training Epoch: 29 [14336/50176]	Loss: 2.8721
Training Epoch: 29 [15360/50176]	Loss: 2.9415
Training Epoch: 29 [16384/50176]	Loss: 2.8766
Training Epoch: 29 [17408/50176]	Loss: 2.8235
Training Epoch: 29 [18432/50176]	Loss: 2.9374
Training Epoch: 29 [19456/50176]	Loss: 2.8998
Training Epoch: 29 [20480/50176]	Loss: 2.8351
Training Epoch: 29 [21504/50176]	Loss: 2.8996
Training Epoch: 29 [22528/50176]	Loss: 2.8313
Training Epoch: 29 [23552/50176]	Loss: 2.8255
Training Epoch: 29 [24576/50176]	Loss: 2.9467
Training Epoch: 29 [25600/50176]	Loss: 2.9179
Training Epoch: 29 [26624/50176]	Loss: 2.8773
Training Epoch: 29 [27648/50176]	Loss: 2.9319
Training Epoch: 29 [28672/50176]	Loss: 2.8732
Training Epoch: 29 [29696/50176]	Loss: 2.8021
Training Epoch: 29 [30720/50176]	Loss: 2.9583
Training Epoch: 29 [31744/50176]	Loss: 2.8915
Training Epoch: 29 [32768/50176]	Loss: 2.9409
Training Epoch: 29 [33792/50176]	Loss: 2.9479
Training Epoch: 29 [34816/50176]	Loss: 2.8809
Training Epoch: 29 [35840/50176]	Loss: 2.8642
Training Epoch: 29 [36864/50176]	Loss: 2.8618
Training Epoch: 29 [37888/50176]	Loss: 2.8616
Training Epoch: 29 [38912/50176]	Loss: 2.8600
Training Epoch: 29 [39936/50176]	Loss: 2.9306
Training Epoch: 29 [40960/50176]	Loss: 2.9091
Training Epoch: 29 [41984/50176]	Loss: 2.8853
Training Epoch: 29 [43008/50176]	Loss: 2.9076
Training Epoch: 29 [44032/50176]	Loss: 2.8500
Training Epoch: 29 [45056/50176]	Loss: 2.9072
Training Epoch: 29 [46080/50176]	Loss: 2.9670
Training Epoch: 29 [47104/50176]	Loss: 2.8916
Training Epoch: 29 [48128/50176]	Loss: 2.9536
Training Epoch: 29 [49152/50176]	Loss: 2.9464
Training Epoch: 29 [50176/50176]	Loss: 2.9734
2022-12-06 02:02:44.946 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:02:44,993 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.79 energy=520.42
2022-12-05 21:02:44,993 [ZeusDataLoader(train)] Up to epoch 30: time=1559.48, energy=225345.47, cost=249127.36
2022-12-05 21:02:44,993 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:02:44,993 [ZeusDataLoader(train)] Expected next epoch: time=1607.83, energy=232633.73, cost=257001.67
2022-12-05 21:02:44,994 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0029, Accuracy: 0.2701
2022-12-05 21:02:45,177 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:02:45,178 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:02:45.180 [ZeusMonitor] Monitor started.
2022-12-06 02:02:45.180 [ZeusMonitor] Running indefinitely. 2022-12-06 02:02:45.180 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:02:45.180 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e31+gpu0.power.log
2022-12-05 21:03:29,284 [ZeusDataLoader(train)] train epoch 31 done: time=44.28 energy=6743.87
2022-12-05 21:03:29,288 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 2.9645
Training Epoch: 30 [2048/50176]	Loss: 2.9036
Training Epoch: 30 [3072/50176]	Loss: 2.9812
Training Epoch: 30 [4096/50176]	Loss: 2.9513
Training Epoch: 30 [5120/50176]	Loss: 2.8918
Training Epoch: 30 [6144/50176]	Loss: 2.8628
Training Epoch: 30 [7168/50176]	Loss: 2.9069
Training Epoch: 30 [8192/50176]	Loss: 2.9037
Training Epoch: 30 [9216/50176]	Loss: 2.8029
Training Epoch: 30 [10240/50176]	Loss: 2.8572
Training Epoch: 30 [11264/50176]	Loss: 2.8436
Training Epoch: 30 [12288/50176]	Loss: 2.9109
Training Epoch: 30 [13312/50176]	Loss: 2.9124
Training Epoch: 30 [14336/50176]	Loss: 2.8981
Training Epoch: 30 [15360/50176]	Loss: 2.9200
Training Epoch: 30 [16384/50176]	Loss: 2.9349
Training Epoch: 30 [17408/50176]	Loss: 2.9070
Training Epoch: 30 [18432/50176]	Loss: 2.8332
Training Epoch: 30 [19456/50176]	Loss: 2.8688
Training Epoch: 30 [20480/50176]	Loss: 2.8565
Training Epoch: 30 [21504/50176]	Loss: 2.8836
Training Epoch: 30 [22528/50176]	Loss: 2.8243
Training Epoch: 30 [23552/50176]	Loss: 2.8210
Training Epoch: 30 [24576/50176]	Loss: 2.9021
Training Epoch: 30 [25600/50176]	Loss: 2.8674
Training Epoch: 30 [26624/50176]	Loss: 2.8349
Training Epoch: 30 [27648/50176]	Loss: 2.8467
Training Epoch: 30 [28672/50176]	Loss: 2.9337
Training Epoch: 30 [29696/50176]	Loss: 2.8030
Training Epoch: 30 [30720/50176]	Loss: 2.8294
Training Epoch: 30 [31744/50176]	Loss: 2.8243
Training Epoch: 30 [32768/50176]	Loss: 2.8711
Training Epoch: 30 [33792/50176]	Loss: 2.8831
Training Epoch: 30 [34816/50176]	Loss: 2.9329
Training Epoch: 30 [35840/50176]	Loss: 2.8546
Training Epoch: 30 [36864/50176]	Loss: 2.8751
Training Epoch: 30 [37888/50176]	Loss: 2.8460
Training Epoch: 30 [38912/50176]	Loss: 2.9226
Training Epoch: 30 [39936/50176]	Loss: 2.8273
Training Epoch: 30 [40960/50176]	Loss: 2.8654
Training Epoch: 30 [41984/50176]	Loss: 2.8866
Training Epoch: 30 [43008/50176]	Loss: 2.8813
Training Epoch: 30 [44032/50176]	Loss: 2.7939
Training Epoch: 30 [45056/50176]	Loss: 2.8071
Training Epoch: 30 [46080/50176]	Loss: 2.8120
Training Epoch: 30 [47104/50176]	Loss: 2.7940
Training Epoch: 30 [48128/50176]	Loss: 2.8491
Training Epoch: 30 [49152/50176]	Loss: 2.9189
Training Epoch: 30 [50176/50176]	Loss: 2.8811
2022-12-06 02:03:33.074 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:03:33,106 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.81 energy=532.41
2022-12-05 21:03:33,106 [ZeusDataLoader(train)] Up to epoch 31: time=1607.57, energy=232621.74, cost=256973.46
2022-12-05 21:03:33,106 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:03:33,106 [ZeusDataLoader(train)] Expected next epoch: time=1655.92, energy=239910.01, cost=264847.77
2022-12-05 21:03:33,107 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0028, Accuracy: 0.2778
2022-12-05 21:03:33,256 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:03:33,257 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:03:33.261 [ZeusMonitor] Monitor started.
2022-12-06 02:03:33.261 [ZeusMonitor] Running indefinitely. 2022-12-06 02:03:33.261 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:03:33.261 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e32+gpu0.power.log
2022-12-05 21:04:17,425 [ZeusDataLoader(train)] train epoch 32 done: time=44.31 energy=6751.84
2022-12-05 21:04:17,428 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 2.8161
Training Epoch: 31 [2048/50176]	Loss: 2.8701
Training Epoch: 31 [3072/50176]	Loss: 2.8690
Training Epoch: 31 [4096/50176]	Loss: 2.8893
Training Epoch: 31 [5120/50176]	Loss: 2.8331
Training Epoch: 31 [6144/50176]	Loss: 2.8430
Training Epoch: 31 [7168/50176]	Loss: 2.8697
Training Epoch: 31 [8192/50176]	Loss: 2.8386
Training Epoch: 31 [9216/50176]	Loss: 2.7943
Training Epoch: 31 [10240/50176]	Loss: 2.8321
Training Epoch: 31 [11264/50176]	Loss: 2.8075
Training Epoch: 31 [12288/50176]	Loss: 2.9162
Training Epoch: 31 [13312/50176]	Loss: 2.8836
Training Epoch: 31 [14336/50176]	Loss: 2.8024
Training Epoch: 31 [15360/50176]	Loss: 2.8017
Training Epoch: 31 [16384/50176]	Loss: 2.8434
Training Epoch: 31 [17408/50176]	Loss: 2.9008
Training Epoch: 31 [18432/50176]	Loss: 2.8808
Training Epoch: 31 [19456/50176]	Loss: 2.8543
Training Epoch: 31 [20480/50176]	Loss: 2.8904
Training Epoch: 31 [21504/50176]	Loss: 2.8896
Training Epoch: 31 [22528/50176]	Loss: 2.8552
Training Epoch: 31 [23552/50176]	Loss: 2.7697
Training Epoch: 31 [24576/50176]	Loss: 2.8317
Training Epoch: 31 [25600/50176]	Loss: 2.7985
Training Epoch: 31 [26624/50176]	Loss: 2.8290
Training Epoch: 31 [27648/50176]	Loss: 2.7910
Training Epoch: 31 [28672/50176]	Loss: 2.7882
Training Epoch: 31 [29696/50176]	Loss: 2.7635
Training Epoch: 31 [30720/50176]	Loss: 2.8507
Training Epoch: 31 [31744/50176]	Loss: 2.8936
Training Epoch: 31 [32768/50176]	Loss: 2.8454
Training Epoch: 31 [33792/50176]	Loss: 2.8162
Training Epoch: 31 [34816/50176]	Loss: 2.8126
Training Epoch: 31 [35840/50176]	Loss: 2.8800
Training Epoch: 31 [36864/50176]	Loss: 2.9009
Training Epoch: 31 [37888/50176]	Loss: 2.8887
Training Epoch: 31 [38912/50176]	Loss: 2.9152
Training Epoch: 31 [39936/50176]	Loss: 2.8175
Training Epoch: 31 [40960/50176]	Loss: 2.8599
Training Epoch: 31 [41984/50176]	Loss: 2.7782
Training Epoch: 31 [43008/50176]	Loss: 2.8080
Training Epoch: 31 [44032/50176]	Loss: 2.9128
Training Epoch: 31 [45056/50176]	Loss: 2.8761
Training Epoch: 31 [46080/50176]	Loss: 2.8895
Training Epoch: 31 [47104/50176]	Loss: 2.7925
Training Epoch: 31 [48128/50176]	Loss: 2.8864
Training Epoch: 31 [49152/50176]	Loss: 2.8518
Training Epoch: 31 [50176/50176]	Loss: 2.8540
2022-12-06 02:04:21.119 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:04:21,141 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.70 energy=517.54
2022-12-05 21:04:21,142 [ZeusDataLoader(train)] Up to epoch 32: time=1655.59, energy=239891.12, cost=264809.34
2022-12-05 21:04:21,142 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:04:21,142 [ZeusDataLoader(train)] Expected next epoch: time=1703.93, energy=247179.38, cost=272683.65
2022-12-05 21:04:21,143 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0028, Accuracy: 0.2847
2022-12-05 21:04:21,323 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:04:21,324 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:04:21.326 [ZeusMonitor] Monitor started.
2022-12-06 02:04:21.326 [ZeusMonitor] Running indefinitely. 2022-12-06 02:04:21.326 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:04:21.326 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e33+gpu0.power.log
2022-12-05 21:05:05,464 [ZeusDataLoader(train)] train epoch 33 done: time=44.31 energy=6750.10
2022-12-05 21:05:05,467 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 2.7578
Training Epoch: 32 [2048/50176]	Loss: 2.7645
Training Epoch: 32 [3072/50176]	Loss: 2.7987
Training Epoch: 32 [4096/50176]	Loss: 2.8561
Training Epoch: 32 [5120/50176]	Loss: 2.8181
Training Epoch: 32 [6144/50176]	Loss: 2.8774
Training Epoch: 32 [7168/50176]	Loss: 2.8478
Training Epoch: 32 [8192/50176]	Loss: 2.8058
Training Epoch: 32 [9216/50176]	Loss: 2.7887
Training Epoch: 32 [10240/50176]	Loss: 2.8169
Training Epoch: 32 [11264/50176]	Loss: 2.8638
Training Epoch: 32 [12288/50176]	Loss: 2.8188
Training Epoch: 32 [13312/50176]	Loss: 2.7424
Training Epoch: 32 [14336/50176]	Loss: 2.9134
Training Epoch: 32 [15360/50176]	Loss: 2.7754
Training Epoch: 32 [16384/50176]	Loss: 2.8012
Training Epoch: 32 [17408/50176]	Loss: 2.8440
Training Epoch: 32 [18432/50176]	Loss: 2.8032
Training Epoch: 32 [19456/50176]	Loss: 2.8127
Training Epoch: 32 [20480/50176]	Loss: 2.8509
Training Epoch: 32 [21504/50176]	Loss: 2.8730
Training Epoch: 32 [22528/50176]	Loss: 2.9006
Training Epoch: 32 [23552/50176]	Loss: 2.8945
Training Epoch: 32 [24576/50176]	Loss: 2.7730
Training Epoch: 32 [25600/50176]	Loss: 2.8641
Training Epoch: 32 [26624/50176]	Loss: 2.8038
Training Epoch: 32 [27648/50176]	Loss: 2.7671
Training Epoch: 32 [28672/50176]	Loss: 2.7815
Training Epoch: 32 [29696/50176]	Loss: 2.7308
Training Epoch: 32 [30720/50176]	Loss: 2.8173
Training Epoch: 32 [31744/50176]	Loss: 2.7418
Training Epoch: 32 [32768/50176]	Loss: 2.7444
Training Epoch: 32 [33792/50176]	Loss: 2.8547
Training Epoch: 32 [34816/50176]	Loss: 2.6629
Training Epoch: 32 [35840/50176]	Loss: 2.8035
Training Epoch: 32 [36864/50176]	Loss: 2.8331
Training Epoch: 32 [37888/50176]	Loss: 2.9130
Training Epoch: 32 [38912/50176]	Loss: 2.8168
Training Epoch: 32 [39936/50176]	Loss: 2.8657
Training Epoch: 32 [40960/50176]	Loss: 2.7432
Training Epoch: 32 [41984/50176]	Loss: 2.7915
Training Epoch: 32 [43008/50176]	Loss: 2.8189
Training Epoch: 32 [44032/50176]	Loss: 2.9026
Training Epoch: 32 [45056/50176]	Loss: 2.7691
Training Epoch: 32 [46080/50176]	Loss: 2.8709
Training Epoch: 32 [47104/50176]	Loss: 2.7563
Training Epoch: 32 [48128/50176]	Loss: 2.8329
Training Epoch: 32 [49152/50176]	Loss: 2.8051
Training Epoch: 32 [50176/50176]	Loss: 2.8387
2022-12-06 02:05:09.259 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:05:09,280 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.80 energy=527.11
2022-12-05 21:05:09,281 [ZeusDataLoader(train)] Up to epoch 33: time=1703.70, energy=247168.33, cost=272658.23
2022-12-05 21:05:09,281 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:05:09,281 [ZeusDataLoader(train)] Expected next epoch: time=1752.05, energy=254456.60, cost=280532.54
2022-12-05 21:05:09,282 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0028, Accuracy: 0.2863
2022-12-05 21:05:09,428 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:05:09,429 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:05:09.433 [ZeusMonitor] Monitor started.
2022-12-06 02:05:09.433 [ZeusMonitor] Running indefinitely. 2022-12-06 02:05:09.433 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:05:09.433 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e34+gpu0.power.log
2022-12-05 21:05:53,583 [ZeusDataLoader(train)] train epoch 34 done: time=44.29 energy=6752.23
2022-12-05 21:05:53,586 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 2.7332
Training Epoch: 33 [2048/50176]	Loss: 2.7338
Training Epoch: 33 [3072/50176]	Loss: 2.8879
Training Epoch: 33 [4096/50176]	Loss: 2.7175
Training Epoch: 33 [5120/50176]	Loss: 2.8454
Training Epoch: 33 [6144/50176]	Loss: 2.7806
Training Epoch: 33 [7168/50176]	Loss: 2.8688
Training Epoch: 33 [8192/50176]	Loss: 2.8288
Training Epoch: 33 [9216/50176]	Loss: 2.8320
Training Epoch: 33 [10240/50176]	Loss: 2.8502
Training Epoch: 33 [11264/50176]	Loss: 2.8447
Training Epoch: 33 [12288/50176]	Loss: 2.8007
Training Epoch: 33 [13312/50176]	Loss: 2.7812
Training Epoch: 33 [14336/50176]	Loss: 2.7841
Training Epoch: 33 [15360/50176]	Loss: 2.8201
Training Epoch: 33 [16384/50176]	Loss: 2.7457
Training Epoch: 33 [17408/50176]	Loss: 2.7769
Training Epoch: 33 [18432/50176]	Loss: 2.8500
Training Epoch: 33 [19456/50176]	Loss: 2.8137
Training Epoch: 33 [20480/50176]	Loss: 2.7160
Training Epoch: 33 [21504/50176]	Loss: 2.8555
Training Epoch: 33 [22528/50176]	Loss: 2.8050
Training Epoch: 33 [23552/50176]	Loss: 2.8462
Training Epoch: 33 [24576/50176]	Loss: 2.7952
Training Epoch: 33 [25600/50176]	Loss: 2.8119
Training Epoch: 33 [26624/50176]	Loss: 2.7360
Training Epoch: 33 [27648/50176]	Loss: 2.7138
Training Epoch: 33 [28672/50176]	Loss: 2.8580
Training Epoch: 33 [29696/50176]	Loss: 2.8014
Training Epoch: 33 [30720/50176]	Loss: 2.7262
Training Epoch: 33 [31744/50176]	Loss: 2.7867
Training Epoch: 33 [32768/50176]	Loss: 2.7800
Training Epoch: 33 [33792/50176]	Loss: 2.8771
Training Epoch: 33 [34816/50176]	Loss: 2.7357
Training Epoch: 33 [35840/50176]	Loss: 2.7728
Training Epoch: 33 [36864/50176]	Loss: 2.7810
Training Epoch: 33 [37888/50176]	Loss: 2.7541
Training Epoch: 33 [38912/50176]	Loss: 2.8460
Training Epoch: 33 [39936/50176]	Loss: 2.8022
Training Epoch: 33 [40960/50176]	Loss: 2.7674
Training Epoch: 33 [41984/50176]	Loss: 2.7827
Training Epoch: 33 [43008/50176]	Loss: 2.8200
Training Epoch: 33 [44032/50176]	Loss: 2.7196
Training Epoch: 33 [45056/50176]	Loss: 2.7752
Training Epoch: 33 [46080/50176]	Loss: 2.7202
Training Epoch: 33 [47104/50176]	Loss: 2.7666
Training Epoch: 33 [48128/50176]	Loss: 2.8328
Training Epoch: 33 [49152/50176]	Loss: 2.7978
Training Epoch: 33 [50176/50176]	Loss: 2.7687
2022-12-06 02:05:57.272 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:05:57,282 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.69 energy=516.65
2022-12-05 21:05:57,282 [ZeusDataLoader(train)] Up to epoch 34: time=1751.68, energy=254437.22, cost=280490.87
2022-12-05 21:05:57,282 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:05:57,282 [ZeusDataLoader(train)] Expected next epoch: time=1800.03, energy=261725.48, cost=288365.18
2022-12-05 21:05:57,283 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0028, Accuracy: 0.2873
2022-12-05 21:05:57,467 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:05:57,468 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:05:57.470 [ZeusMonitor] Monitor started.
2022-12-06 02:05:57.470 [ZeusMonitor] Running indefinitely. 2022-12-06 02:05:57.470 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:05:57.470 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e35+gpu0.power.log
2022-12-05 21:06:41,533 [ZeusDataLoader(train)] train epoch 35 done: time=44.24 energy=6750.69
2022-12-05 21:06:41,537 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 2.7814
Training Epoch: 34 [2048/50176]	Loss: 2.7525
Training Epoch: 34 [3072/50176]	Loss: 2.7863
Training Epoch: 34 [4096/50176]	Loss: 2.7880
Training Epoch: 34 [5120/50176]	Loss: 2.8090
Training Epoch: 34 [6144/50176]	Loss: 2.7623
Training Epoch: 34 [7168/50176]	Loss: 2.6904
Training Epoch: 34 [8192/50176]	Loss: 2.7865
Training Epoch: 34 [9216/50176]	Loss: 2.7285
Training Epoch: 34 [10240/50176]	Loss: 2.7850
Training Epoch: 34 [11264/50176]	Loss: 2.7621
Training Epoch: 34 [12288/50176]	Loss: 2.8136
Training Epoch: 34 [13312/50176]	Loss: 2.7686
Training Epoch: 34 [14336/50176]	Loss: 2.6785
Training Epoch: 34 [15360/50176]	Loss: 2.7525
Training Epoch: 34 [16384/50176]	Loss: 2.8351
Training Epoch: 34 [17408/50176]	Loss: 2.7661
Training Epoch: 34 [18432/50176]	Loss: 2.7382
Training Epoch: 34 [19456/50176]	Loss: 2.6833
Training Epoch: 34 [20480/50176]	Loss: 2.7850
Training Epoch: 34 [21504/50176]	Loss: 2.7863
Training Epoch: 34 [22528/50176]	Loss: 2.7566
Training Epoch: 34 [23552/50176]	Loss: 2.7884
Training Epoch: 34 [24576/50176]	Loss: 2.6838
Training Epoch: 34 [25600/50176]	Loss: 2.7335
Training Epoch: 34 [26624/50176]	Loss: 2.7763
Training Epoch: 34 [27648/50176]	Loss: 2.8132
Training Epoch: 34 [28672/50176]	Loss: 2.8284
Training Epoch: 34 [29696/50176]	Loss: 2.7995
Training Epoch: 34 [30720/50176]	Loss: 2.7295
Training Epoch: 34 [31744/50176]	Loss: 2.7539
Training Epoch: 34 [32768/50176]	Loss: 2.8375
Training Epoch: 34 [33792/50176]	Loss: 2.7418
Training Epoch: 34 [34816/50176]	Loss: 2.7066
Training Epoch: 34 [35840/50176]	Loss: 2.8035
Training Epoch: 34 [36864/50176]	Loss: 2.8212
Training Epoch: 34 [37888/50176]	Loss: 2.7601
Training Epoch: 34 [38912/50176]	Loss: 2.6958
Training Epoch: 34 [39936/50176]	Loss: 2.7071
Training Epoch: 34 [40960/50176]	Loss: 2.8087
Training Epoch: 34 [41984/50176]	Loss: 2.7062
Training Epoch: 34 [43008/50176]	Loss: 2.7362
Training Epoch: 34 [44032/50176]	Loss: 2.8084
Training Epoch: 34 [45056/50176]	Loss: 2.7973
Training Epoch: 34 [46080/50176]	Loss: 2.7763
Training Epoch: 34 [47104/50176]	Loss: 2.7782
Training Epoch: 34 [48128/50176]	Loss: 2.7501
Training Epoch: 34 [49152/50176]	Loss: 2.8045
Training Epoch: 34 [50176/50176]	Loss: 2.7763
2022-12-06 02:06:45.277 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:06:45,315 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.77 energy=523.24
2022-12-05 21:06:45,316 [ZeusDataLoader(train)] Up to epoch 35: time=1799.69, energy=261711.15, cost=288328.83
2022-12-05 21:06:45,316 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:06:45,316 [ZeusDataLoader(train)] Expected next epoch: time=1848.04, energy=268999.41, cost=296203.14
2022-12-05 21:06:45,317 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0027, Accuracy: 0.2977
2022-12-05 21:06:45,495 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:06:45,496 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:06:45.498 [ZeusMonitor] Monitor started.
2022-12-06 02:06:45.498 [ZeusMonitor] Running indefinitely. 2022-12-06 02:06:45.498 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:06:45.498 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e36+gpu0.power.log
2022-12-05 21:07:29,607 [ZeusDataLoader(train)] train epoch 36 done: time=44.28 energy=6744.65
2022-12-05 21:07:29,610 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 2.7764
Training Epoch: 35 [2048/50176]	Loss: 2.7680
Training Epoch: 35 [3072/50176]	Loss: 2.7749
Training Epoch: 35 [4096/50176]	Loss: 2.7538
Training Epoch: 35 [5120/50176]	Loss: 2.7484
Training Epoch: 35 [6144/50176]	Loss: 2.6750
Training Epoch: 35 [7168/50176]	Loss: 2.7755
Training Epoch: 35 [8192/50176]	Loss: 2.6931
Training Epoch: 35 [9216/50176]	Loss: 2.6892
Training Epoch: 35 [10240/50176]	Loss: 2.7696
Training Epoch: 35 [11264/50176]	Loss: 2.8205
Training Epoch: 35 [12288/50176]	Loss: 2.7721
Training Epoch: 35 [13312/50176]	Loss: 2.7411
Training Epoch: 35 [14336/50176]	Loss: 2.7518
Training Epoch: 35 [15360/50176]	Loss: 2.7716
Training Epoch: 35 [16384/50176]	Loss: 2.8282
Training Epoch: 35 [17408/50176]	Loss: 2.7226
Training Epoch: 35 [18432/50176]	Loss: 2.7530
Training Epoch: 35 [19456/50176]	Loss: 2.7394
Training Epoch: 35 [20480/50176]	Loss: 2.6646
Training Epoch: 35 [21504/50176]	Loss: 2.7118
Training Epoch: 35 [22528/50176]	Loss: 2.7672
Training Epoch: 35 [23552/50176]	Loss: 2.5779
Training Epoch: 35 [24576/50176]	Loss: 2.7969
Training Epoch: 35 [25600/50176]	Loss: 2.7321
Training Epoch: 35 [26624/50176]	Loss: 2.7756
Training Epoch: 35 [27648/50176]	Loss: 2.7320
Training Epoch: 35 [28672/50176]	Loss: 2.7747
Training Epoch: 35 [29696/50176]	Loss: 2.7204
Training Epoch: 35 [30720/50176]	Loss: 2.7908
Training Epoch: 35 [31744/50176]	Loss: 2.7065
Training Epoch: 35 [32768/50176]	Loss: 2.6541
Training Epoch: 35 [33792/50176]	Loss: 2.6918
Training Epoch: 35 [34816/50176]	Loss: 2.6924
Training Epoch: 35 [35840/50176]	Loss: 2.6621
Training Epoch: 35 [36864/50176]	Loss: 2.7674
Training Epoch: 35 [37888/50176]	Loss: 2.7632
Training Epoch: 35 [38912/50176]	Loss: 2.6555
Training Epoch: 35 [39936/50176]	Loss: 2.7598
Training Epoch: 35 [40960/50176]	Loss: 2.7660
Training Epoch: 35 [41984/50176]	Loss: 2.7759
Training Epoch: 35 [43008/50176]	Loss: 2.7259
Training Epoch: 35 [44032/50176]	Loss: 2.7753
Training Epoch: 35 [45056/50176]	Loss: 2.8302
Training Epoch: 35 [46080/50176]	Loss: 2.6848
Training Epoch: 35 [47104/50176]	Loss: 2.7663
Training Epoch: 35 [48128/50176]	Loss: 2.8031
Training Epoch: 35 [49152/50176]	Loss: 2.7569
Training Epoch: 35 [50176/50176]	Loss: 2.7312
2022-12-06 02:07:33.329 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:07:33,351 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.73 energy=526.34
2022-12-05 21:07:33,351 [ZeusDataLoader(train)] Up to epoch 36: time=1847.71, energy=268982.14, cost=296165.53
2022-12-05 21:07:33,351 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:07:33,351 [ZeusDataLoader(train)] Expected next epoch: time=1896.05, energy=276270.41, cost=304039.84
2022-12-05 21:07:33,352 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0027, Accuracy: 0.2992
2022-12-05 21:07:33,541 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:07:33,541 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:07:33.543 [ZeusMonitor] Monitor started.
2022-12-06 02:07:33.543 [ZeusMonitor] Running indefinitely. 2022-12-06 02:07:33.543 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:07:33.543 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e37+gpu0.power.log
2022-12-05 21:08:17,656 [ZeusDataLoader(train)] train epoch 37 done: time=44.30 energy=6756.46
2022-12-05 21:08:17,660 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 2.7015
Training Epoch: 36 [2048/50176]	Loss: 2.6956
Training Epoch: 36 [3072/50176]	Loss: 2.7101
Training Epoch: 36 [4096/50176]	Loss: 2.6666
Training Epoch: 36 [5120/50176]	Loss: 2.6579
Training Epoch: 36 [6144/50176]	Loss: 2.7114
Training Epoch: 36 [7168/50176]	Loss: 2.6857
Training Epoch: 36 [8192/50176]	Loss: 2.6752
Training Epoch: 36 [9216/50176]	Loss: 2.6211
Training Epoch: 36 [10240/50176]	Loss: 2.8615
Training Epoch: 36 [11264/50176]	Loss: 2.7605
Training Epoch: 36 [12288/50176]	Loss: 2.7138
Training Epoch: 36 [13312/50176]	Loss: 2.7350
Training Epoch: 36 [14336/50176]	Loss: 2.6359
Training Epoch: 36 [15360/50176]	Loss: 2.6652
Training Epoch: 36 [16384/50176]	Loss: 2.6867
Training Epoch: 36 [17408/50176]	Loss: 2.7369
Training Epoch: 36 [18432/50176]	Loss: 2.7291
Training Epoch: 36 [19456/50176]	Loss: 2.7677
Training Epoch: 36 [20480/50176]	Loss: 2.7421
Training Epoch: 36 [21504/50176]	Loss: 2.7306
Training Epoch: 36 [22528/50176]	Loss: 2.8000
Training Epoch: 36 [23552/50176]	Loss: 2.6522
Training Epoch: 36 [24576/50176]	Loss: 2.6642
Training Epoch: 36 [25600/50176]	Loss: 2.7497
Training Epoch: 36 [26624/50176]	Loss: 2.7311
Training Epoch: 36 [27648/50176]	Loss: 2.6626
Training Epoch: 36 [28672/50176]	Loss: 2.6619
Training Epoch: 36 [29696/50176]	Loss: 2.7707
Training Epoch: 36 [30720/50176]	Loss: 2.6972
Training Epoch: 36 [31744/50176]	Loss: 2.6194
Training Epoch: 36 [32768/50176]	Loss: 2.7265
Training Epoch: 36 [33792/50176]	Loss: 2.7932
Training Epoch: 36 [34816/50176]	Loss: 2.7377
Training Epoch: 36 [35840/50176]	Loss: 2.7102
Training Epoch: 36 [36864/50176]	Loss: 2.7035
Training Epoch: 36 [37888/50176]	Loss: 2.7669
Training Epoch: 36 [38912/50176]	Loss: 2.6188
Training Epoch: 36 [39936/50176]	Loss: 2.7539
Training Epoch: 36 [40960/50176]	Loss: 2.7441
Training Epoch: 36 [41984/50176]	Loss: 2.7544
Training Epoch: 36 [43008/50176]	Loss: 2.7698
Training Epoch: 36 [44032/50176]	Loss: 2.7532
Training Epoch: 36 [45056/50176]	Loss: 2.7559
Training Epoch: 36 [46080/50176]	Loss: 2.7241
Training Epoch: 36 [47104/50176]	Loss: 2.7253
Training Epoch: 36 [48128/50176]	Loss: 2.6128
Training Epoch: 36 [49152/50176]	Loss: 2.6913
Training Epoch: 36 [50176/50176]	Loss: 2.6684
2022-12-06 02:08:21.441 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:08:21,485 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.82 energy=536.16
2022-12-05 21:08:21,485 [ZeusDataLoader(train)] Up to epoch 37: time=1895.82, energy=276274.76, cost=304021.68
2022-12-05 21:08:21,485 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:08:21,485 [ZeusDataLoader(train)] Expected next epoch: time=1944.17, energy=283563.03, cost=311895.99
2022-12-05 21:08:21,486 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0027, Accuracy: 0.3025
2022-12-05 21:08:21,677 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:08:21,678 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:08:21.680 [ZeusMonitor] Monitor started.
2022-12-06 02:08:21.680 [ZeusMonitor] Running indefinitely. 2022-12-06 02:08:21.680 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:08:21.680 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e38+gpu0.power.log
2022-12-05 21:09:05,788 [ZeusDataLoader(train)] train epoch 38 done: time=44.29 energy=6757.49
2022-12-05 21:09:05,792 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 2.7322
Training Epoch: 37 [2048/50176]	Loss: 2.6143
Training Epoch: 37 [3072/50176]	Loss: 2.6055
Training Epoch: 37 [4096/50176]	Loss: 2.7240
Training Epoch: 37 [5120/50176]	Loss: 2.5805
Training Epoch: 37 [6144/50176]	Loss: 2.7284
Training Epoch: 37 [7168/50176]	Loss: 2.6104
Training Epoch: 37 [8192/50176]	Loss: 2.6891
Training Epoch: 37 [9216/50176]	Loss: 2.6885
Training Epoch: 37 [10240/50176]	Loss: 2.7145
Training Epoch: 37 [11264/50176]	Loss: 2.6848
Training Epoch: 37 [12288/50176]	Loss: 2.6949
Training Epoch: 37 [13312/50176]	Loss: 2.6267
Training Epoch: 37 [14336/50176]	Loss: 2.6690
Training Epoch: 37 [15360/50176]	Loss: 2.7217
Training Epoch: 37 [16384/50176]	Loss: 2.6933
Training Epoch: 37 [17408/50176]	Loss: 2.7099
Training Epoch: 37 [18432/50176]	Loss: 2.6566
Training Epoch: 37 [19456/50176]	Loss: 2.6544
Training Epoch: 37 [20480/50176]	Loss: 2.6285
Training Epoch: 37 [21504/50176]	Loss: 2.7195
Training Epoch: 37 [22528/50176]	Loss: 2.7047
Training Epoch: 37 [23552/50176]	Loss: 2.6160
Training Epoch: 37 [24576/50176]	Loss: 2.6571
Training Epoch: 37 [25600/50176]	Loss: 2.6494
Training Epoch: 37 [26624/50176]	Loss: 2.6840
Training Epoch: 37 [27648/50176]	Loss: 2.7648
Training Epoch: 37 [28672/50176]	Loss: 2.7051
Training Epoch: 37 [29696/50176]	Loss: 2.7634
Training Epoch: 37 [30720/50176]	Loss: 2.7498
Training Epoch: 37 [31744/50176]	Loss: 2.6571
Training Epoch: 37 [32768/50176]	Loss: 2.6794
Training Epoch: 37 [33792/50176]	Loss: 2.6666
Training Epoch: 37 [34816/50176]	Loss: 2.7904
Training Epoch: 37 [35840/50176]	Loss: 2.7084
Training Epoch: 37 [36864/50176]	Loss: 2.6723
Training Epoch: 37 [37888/50176]	Loss: 2.8263
Training Epoch: 37 [38912/50176]	Loss: 2.7308
Training Epoch: 37 [39936/50176]	Loss: 2.6908
Training Epoch: 37 [40960/50176]	Loss: 2.6127
Training Epoch: 37 [41984/50176]	Loss: 2.6394
Training Epoch: 37 [43008/50176]	Loss: 2.7684
Training Epoch: 37 [44032/50176]	Loss: 2.7643
Training Epoch: 37 [45056/50176]	Loss: 2.7516
Training Epoch: 37 [46080/50176]	Loss: 2.7034
Training Epoch: 37 [47104/50176]	Loss: 2.7614
Training Epoch: 37 [48128/50176]	Loss: 2.7258
Training Epoch: 37 [49152/50176]	Loss: 2.6544
Training Epoch: 37 [50176/50176]	Loss: 2.6655
2022-12-06 02:09:09.558 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:09:09,594 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.79 energy=535.58
2022-12-05 21:09:09,594 [ZeusDataLoader(train)] Up to epoch 38: time=1943.91, energy=283567.83, cost=311875.88
2022-12-05 21:09:09,594 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:09:09,594 [ZeusDataLoader(train)] Expected next epoch: time=1992.25, energy=290856.10, cost=319750.19
2022-12-05 21:09:09,595 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0027, Accuracy: 0.3034
2022-12-05 21:09:09,740 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:09:09,740 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:09:09.742 [ZeusMonitor] Monitor started.
2022-12-06 02:09:09.742 [ZeusMonitor] Running indefinitely. 2022-12-06 02:09:09.742 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:09:09.742 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e39+gpu0.power.log
2022-12-05 21:09:53,893 [ZeusDataLoader(train)] train epoch 39 done: time=44.29 energy=6741.46
2022-12-05 21:09:53,897 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 2.6137
Training Epoch: 38 [2048/50176]	Loss: 2.7561
Training Epoch: 38 [3072/50176]	Loss: 2.6917
Training Epoch: 38 [4096/50176]	Loss: 2.6368
Training Epoch: 38 [5120/50176]	Loss: 2.7060
Training Epoch: 38 [6144/50176]	Loss: 2.6663
Training Epoch: 38 [7168/50176]	Loss: 2.6688
Training Epoch: 38 [8192/50176]	Loss: 2.7083
Training Epoch: 38 [9216/50176]	Loss: 2.6077
Training Epoch: 38 [10240/50176]	Loss: 2.7362
Training Epoch: 38 [11264/50176]	Loss: 2.7296
Training Epoch: 38 [12288/50176]	Loss: 2.6201
Training Epoch: 38 [13312/50176]	Loss: 2.6313
Training Epoch: 38 [14336/50176]	Loss: 2.6379
Training Epoch: 38 [15360/50176]	Loss: 2.7049
Training Epoch: 38 [16384/50176]	Loss: 2.6742
Training Epoch: 38 [17408/50176]	Loss: 2.7314
Training Epoch: 38 [18432/50176]	Loss: 2.7274
Training Epoch: 38 [19456/50176]	Loss: 2.7222
Training Epoch: 38 [20480/50176]	Loss: 2.6509
Training Epoch: 38 [21504/50176]	Loss: 2.6507
Training Epoch: 38 [22528/50176]	Loss: 2.6881
Training Epoch: 38 [23552/50176]	Loss: 2.7588
Training Epoch: 38 [24576/50176]	Loss: 2.7307
Training Epoch: 38 [25600/50176]	Loss: 2.6254
Training Epoch: 38 [26624/50176]	Loss: 2.6065
Training Epoch: 38 [27648/50176]	Loss: 2.7039
Training Epoch: 38 [28672/50176]	Loss: 2.7032
Training Epoch: 38 [29696/50176]	Loss: 2.5960
Training Epoch: 38 [30720/50176]	Loss: 2.6966
Training Epoch: 38 [31744/50176]	Loss: 2.6495
Training Epoch: 38 [32768/50176]	Loss: 2.6750
Training Epoch: 38 [33792/50176]	Loss: 2.6299
Training Epoch: 38 [34816/50176]	Loss: 2.6836
Training Epoch: 38 [35840/50176]	Loss: 2.6594
Training Epoch: 38 [36864/50176]	Loss: 2.6441
Training Epoch: 38 [37888/50176]	Loss: 2.6871
Training Epoch: 38 [38912/50176]	Loss: 2.5994
Training Epoch: 38 [39936/50176]	Loss: 2.6686
Training Epoch: 38 [40960/50176]	Loss: 2.7166
Training Epoch: 38 [41984/50176]	Loss: 2.6427
Training Epoch: 38 [43008/50176]	Loss: 2.6910
Training Epoch: 38 [44032/50176]	Loss: 2.6138
Training Epoch: 38 [45056/50176]	Loss: 2.6019
Training Epoch: 38 [46080/50176]	Loss: 2.6069
Training Epoch: 38 [47104/50176]	Loss: 2.6562
Training Epoch: 38 [48128/50176]	Loss: 2.6382
Training Epoch: 38 [49152/50176]	Loss: 2.6893
Training Epoch: 38 [50176/50176]	Loss: 2.6389
2022-12-06 02:09:57.691 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:09:57,722 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.82 energy=537.53
2022-12-05 21:09:57,722 [ZeusDataLoader(train)] Up to epoch 39: time=1992.01, energy=290846.82, cost=319724.64
2022-12-05 21:09:57,722 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:09:57,722 [ZeusDataLoader(train)] Expected next epoch: time=2040.36, energy=298135.08, cost=327598.96
2022-12-05 21:09:57,723 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0027, Accuracy: 0.3099
2022-12-05 21:09:57,873 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:09:57,874 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:09:57.876 [ZeusMonitor] Monitor started.
2022-12-06 02:09:57.876 [ZeusMonitor] Running indefinitely. 2022-12-06 02:09:57.876 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:09:57.876 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e40+gpu0.power.log
2022-12-05 21:10:42,033 [ZeusDataLoader(train)] train epoch 40 done: time=44.30 energy=6736.03
2022-12-05 21:10:42,038 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 2.5231
Training Epoch: 39 [2048/50176]	Loss: 2.6586
Training Epoch: 39 [3072/50176]	Loss: 2.6986
Training Epoch: 39 [4096/50176]	Loss: 2.6747
Training Epoch: 39 [5120/50176]	Loss: 2.7469
Training Epoch: 39 [6144/50176]	Loss: 2.6287
Training Epoch: 39 [7168/50176]	Loss: 2.5551
Training Epoch: 39 [8192/50176]	Loss: 2.6476
Training Epoch: 39 [9216/50176]	Loss: 2.6740
Training Epoch: 39 [10240/50176]	Loss: 2.6622
Training Epoch: 39 [11264/50176]	Loss: 2.6520
Training Epoch: 39 [12288/50176]	Loss: 2.6470
Training Epoch: 39 [13312/50176]	Loss: 2.6638
Training Epoch: 39 [14336/50176]	Loss: 2.5484
Training Epoch: 39 [15360/50176]	Loss: 2.6563
Training Epoch: 39 [16384/50176]	Loss: 2.5829
Training Epoch: 39 [17408/50176]	Loss: 2.7164
Training Epoch: 39 [18432/50176]	Loss: 2.6533
Training Epoch: 39 [19456/50176]	Loss: 2.6002
Training Epoch: 39 [20480/50176]	Loss: 2.6174
Training Epoch: 39 [21504/50176]	Loss: 2.6655
Training Epoch: 39 [22528/50176]	Loss: 2.6254
Training Epoch: 39 [23552/50176]	Loss: 2.6233
Training Epoch: 39 [24576/50176]	Loss: 2.6300
Training Epoch: 39 [25600/50176]	Loss: 2.6698
Training Epoch: 39 [26624/50176]	Loss: 2.6824
Training Epoch: 39 [27648/50176]	Loss: 2.7135
Training Epoch: 39 [28672/50176]	Loss: 2.5965
Training Epoch: 39 [29696/50176]	Loss: 2.7215
Training Epoch: 39 [30720/50176]	Loss: 2.6629
Training Epoch: 39 [31744/50176]	Loss: 2.7250
Training Epoch: 39 [32768/50176]	Loss: 2.6286
Training Epoch: 39 [33792/50176]	Loss: 2.6627
Training Epoch: 39 [34816/50176]	Loss: 2.6396
Training Epoch: 39 [35840/50176]	Loss: 2.5903
Training Epoch: 39 [36864/50176]	Loss: 2.6393
Training Epoch: 39 [37888/50176]	Loss: 2.5889
Training Epoch: 39 [38912/50176]	Loss: 2.6245
Training Epoch: 39 [39936/50176]	Loss: 2.6614
Training Epoch: 39 [40960/50176]	Loss: 2.6242
Training Epoch: 39 [41984/50176]	Loss: 2.6715
Training Epoch: 39 [43008/50176]	Loss: 2.6002
Training Epoch: 39 [44032/50176]	Loss: 2.6338
Training Epoch: 39 [45056/50176]	Loss: 2.6593
Training Epoch: 39 [46080/50176]	Loss: 2.6537
Training Epoch: 39 [47104/50176]	Loss: 2.6461
Training Epoch: 39 [48128/50176]	Loss: 2.6044
Training Epoch: 39 [49152/50176]	Loss: 2.6517
Training Epoch: 39 [50176/50176]	Loss: 2.7036
2022-12-06 02:10:45.725 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:10:45,738 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.69 energy=520.83
2022-12-05 21:10:45,738 [ZeusDataLoader(train)] Up to epoch 40: time=2040.01, energy=298103.67, cost=327552.49
2022-12-05 21:10:45,738 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:10:45,738 [ZeusDataLoader(train)] Expected next epoch: time=2088.35, energy=305391.93, cost=335426.80
2022-12-05 21:10:45,739 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0027, Accuracy: 0.3146
2022-12-05 21:10:45,925 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:10:45,926 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:10:45.928 [ZeusMonitor] Monitor started.
2022-12-06 02:10:45.928 [ZeusMonitor] Running indefinitely. 2022-12-06 02:10:45.928 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:10:45.928 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e41+gpu0.power.log
2022-12-05 21:11:30,060 [ZeusDataLoader(train)] train epoch 41 done: time=44.31 energy=6749.02
2022-12-05 21:11:30,063 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 2.6119
Training Epoch: 40 [2048/50176]	Loss: 2.5760
Training Epoch: 40 [3072/50176]	Loss: 2.5844
Training Epoch: 40 [4096/50176]	Loss: 2.6081
Training Epoch: 40 [5120/50176]	Loss: 2.5967
Training Epoch: 40 [6144/50176]	Loss: 2.6470
Training Epoch: 40 [7168/50176]	Loss: 2.5966
Training Epoch: 40 [8192/50176]	Loss: 2.6399
Training Epoch: 40 [9216/50176]	Loss: 2.5734
Training Epoch: 40 [10240/50176]	Loss: 2.6451
Training Epoch: 40 [11264/50176]	Loss: 2.6128
Training Epoch: 40 [12288/50176]	Loss: 2.6451
Training Epoch: 40 [13312/50176]	Loss: 2.5568
Training Epoch: 40 [14336/50176]	Loss: 2.6600
Training Epoch: 40 [15360/50176]	Loss: 2.5929
Training Epoch: 40 [16384/50176]	Loss: 2.5502
Training Epoch: 40 [17408/50176]	Loss: 2.5840
Training Epoch: 40 [18432/50176]	Loss: 2.6819
Training Epoch: 40 [19456/50176]	Loss: 2.5609
Training Epoch: 40 [20480/50176]	Loss: 2.5865
Training Epoch: 40 [21504/50176]	Loss: 2.6190
Training Epoch: 40 [22528/50176]	Loss: 2.5941
Training Epoch: 40 [23552/50176]	Loss: 2.6307
Training Epoch: 40 [24576/50176]	Loss: 2.6541
Training Epoch: 40 [25600/50176]	Loss: 2.5760
Training Epoch: 40 [26624/50176]	Loss: 2.6461
Training Epoch: 40 [27648/50176]	Loss: 2.6046
Training Epoch: 40 [28672/50176]	Loss: 2.6152
Training Epoch: 40 [29696/50176]	Loss: 2.5720
Training Epoch: 40 [30720/50176]	Loss: 2.5598
Training Epoch: 40 [31744/50176]	Loss: 2.6590
Training Epoch: 40 [32768/50176]	Loss: 2.7932
Training Epoch: 40 [33792/50176]	Loss: 2.7373
Training Epoch: 40 [34816/50176]	Loss: 2.6125
Training Epoch: 40 [35840/50176]	Loss: 2.6039
Training Epoch: 40 [36864/50176]	Loss: 2.5953
Training Epoch: 40 [37888/50176]	Loss: 2.6096
Training Epoch: 40 [38912/50176]	Loss: 2.5909
Training Epoch: 40 [39936/50176]	Loss: 2.5880
Training Epoch: 40 [40960/50176]	Loss: 2.5901
Training Epoch: 40 [41984/50176]	Loss: 2.5558
Training Epoch: 40 [43008/50176]	Loss: 2.7167
Training Epoch: 40 [44032/50176]	Loss: 2.6064
Training Epoch: 40 [45056/50176]	Loss: 2.6484
Training Epoch: 40 [46080/50176]	Loss: 2.6616
Training Epoch: 40 [47104/50176]	Loss: 2.6622
Training Epoch: 40 [48128/50176]	Loss: 2.5787
Training Epoch: 40 [49152/50176]	Loss: 2.6446
Training Epoch: 40 [50176/50176]	Loss: 2.6627
2022-12-06 02:11:33.773 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:11:33,795 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.72 energy=516.29
2022-12-05 21:11:33,795 [ZeusDataLoader(train)] Up to epoch 41: time=2088.04, energy=305368.98, cost=335388.31
2022-12-05 21:11:33,795 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:11:33,795 [ZeusDataLoader(train)] Expected next epoch: time=2136.39, energy=312657.24, cost=343262.62
2022-12-05 21:11:33,796 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0026, Accuracy: 0.3164
2022-12-05 21:11:33,973 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:11:33,974 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:11:33.987 [ZeusMonitor] Monitor started.
2022-12-06 02:11:33.988 [ZeusMonitor] Running indefinitely. 2022-12-06 02:11:33.988 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:11:33.988 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e42+gpu0.power.log
2022-12-05 21:12:18,078 [ZeusDataLoader(train)] train epoch 42 done: time=44.27 energy=6756.69
2022-12-05 21:12:18,082 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 2.5524
Training Epoch: 41 [2048/50176]	Loss: 2.6300
Training Epoch: 41 [3072/50176]	Loss: 2.6805
Training Epoch: 41 [4096/50176]	Loss: 2.6217
Training Epoch: 41 [5120/50176]	Loss: 2.5875
Training Epoch: 41 [6144/50176]	Loss: 2.6286
Training Epoch: 41 [7168/50176]	Loss: 2.6584
Training Epoch: 41 [8192/50176]	Loss: 2.6002
Training Epoch: 41 [9216/50176]	Loss: 2.6439
Training Epoch: 41 [10240/50176]	Loss: 2.6800
Training Epoch: 41 [11264/50176]	Loss: 2.6275
Training Epoch: 41 [12288/50176]	Loss: 2.5876
Training Epoch: 41 [13312/50176]	Loss: 2.6109
Training Epoch: 41 [14336/50176]	Loss: 2.5874
Training Epoch: 41 [15360/50176]	Loss: 2.6553
Training Epoch: 41 [16384/50176]	Loss: 2.6571
Training Epoch: 41 [17408/50176]	Loss: 2.6733
Training Epoch: 41 [18432/50176]	Loss: 2.5404
Training Epoch: 41 [19456/50176]	Loss: 2.6348
Training Epoch: 41 [20480/50176]	Loss: 2.6163
Training Epoch: 41 [21504/50176]	Loss: 2.5399
Training Epoch: 41 [22528/50176]	Loss: 2.6177
Training Epoch: 41 [23552/50176]	Loss: 2.6499
Training Epoch: 41 [24576/50176]	Loss: 2.6208
Training Epoch: 41 [25600/50176]	Loss: 2.5612
Training Epoch: 41 [26624/50176]	Loss: 2.5722
Training Epoch: 41 [27648/50176]	Loss: 2.5363
Training Epoch: 41 [28672/50176]	Loss: 2.6541
Training Epoch: 41 [29696/50176]	Loss: 2.6078
Training Epoch: 41 [30720/50176]	Loss: 2.5550
Training Epoch: 41 [31744/50176]	Loss: 2.5789
Training Epoch: 41 [32768/50176]	Loss: 2.5640
Training Epoch: 41 [33792/50176]	Loss: 2.5883
Training Epoch: 41 [34816/50176]	Loss: 2.5877
Training Epoch: 41 [35840/50176]	Loss: 2.5706
Training Epoch: 41 [36864/50176]	Loss: 2.5853
Training Epoch: 41 [37888/50176]	Loss: 2.5943
Training Epoch: 41 [38912/50176]	Loss: 2.5852
Training Epoch: 41 [39936/50176]	Loss: 2.6047
Training Epoch: 41 [40960/50176]	Loss: 2.5677
Training Epoch: 41 [41984/50176]	Loss: 2.4910
Training Epoch: 41 [43008/50176]	Loss: 2.5622
Training Epoch: 41 [44032/50176]	Loss: 2.6447
Training Epoch: 41 [45056/50176]	Loss: 2.6623
Training Epoch: 41 [46080/50176]	Loss: 2.5521
Training Epoch: 41 [47104/50176]	Loss: 2.5379
Training Epoch: 41 [48128/50176]	Loss: 2.6403
Training Epoch: 41 [49152/50176]	Loss: 2.5318
Training Epoch: 41 [50176/50176]	Loss: 2.6024
2022-12-06 02:12:21.822 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:12:21,850 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.76 energy=518.38
2022-12-05 21:12:21,851 [ZeusDataLoader(train)] Up to epoch 42: time=2136.08, energy=312644.05, cost=343228.85
2022-12-05 21:12:21,851 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:12:21,851 [ZeusDataLoader(train)] Expected next epoch: time=2184.42, energy=319932.31, cost=351103.16
2022-12-05 21:12:21,852 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0026, Accuracy: 0.3179
2022-12-05 21:12:22,022 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:12:22,022 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:12:22.038 [ZeusMonitor] Monitor started.
2022-12-06 02:12:22.038 [ZeusMonitor] Running indefinitely. 2022-12-06 02:12:22.038 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:12:22.038 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e43+gpu0.power.log
2022-12-05 21:13:06,274 [ZeusDataLoader(train)] train epoch 43 done: time=44.41 energy=6764.61
2022-12-05 21:13:06,277 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 2.5764
Training Epoch: 42 [2048/50176]	Loss: 2.5047
Training Epoch: 42 [3072/50176]	Loss: 2.5628
Training Epoch: 42 [4096/50176]	Loss: 2.5070
Training Epoch: 42 [5120/50176]	Loss: 2.5412
Training Epoch: 42 [6144/50176]	Loss: 2.5561
Training Epoch: 42 [7168/50176]	Loss: 2.4960
Training Epoch: 42 [8192/50176]	Loss: 2.5538
Training Epoch: 42 [9216/50176]	Loss: 2.5813
Training Epoch: 42 [10240/50176]	Loss: 2.6065
Training Epoch: 42 [11264/50176]	Loss: 2.5434
Training Epoch: 42 [12288/50176]	Loss: 2.6240
Training Epoch: 42 [13312/50176]	Loss: 2.5240
Training Epoch: 42 [14336/50176]	Loss: 2.5534
Training Epoch: 42 [15360/50176]	Loss: 2.5302
Training Epoch: 42 [16384/50176]	Loss: 2.5183
Training Epoch: 42 [17408/50176]	Loss: 2.5182
Training Epoch: 42 [18432/50176]	Loss: 2.5468
Training Epoch: 42 [19456/50176]	Loss: 2.5757
Training Epoch: 42 [20480/50176]	Loss: 2.5630
Training Epoch: 42 [21504/50176]	Loss: 2.5862
Training Epoch: 42 [22528/50176]	Loss: 2.6388
Training Epoch: 42 [23552/50176]	Loss: 2.4990
Training Epoch: 42 [24576/50176]	Loss: 2.5261
Training Epoch: 42 [25600/50176]	Loss: 2.6512
Training Epoch: 42 [26624/50176]	Loss: 2.5477
Training Epoch: 42 [27648/50176]	Loss: 2.5428
Training Epoch: 42 [28672/50176]	Loss: 2.4899
Training Epoch: 42 [29696/50176]	Loss: 2.6209
Training Epoch: 42 [30720/50176]	Loss: 2.5774
Training Epoch: 42 [31744/50176]	Loss: 2.5556
Training Epoch: 42 [32768/50176]	Loss: 2.7016
Training Epoch: 42 [33792/50176]	Loss: 2.5968
Training Epoch: 42 [34816/50176]	Loss: 2.5009
Training Epoch: 42 [35840/50176]	Loss: 2.6217
Training Epoch: 42 [36864/50176]	Loss: 2.6961
Training Epoch: 42 [37888/50176]	Loss: 2.6321
Training Epoch: 42 [38912/50176]	Loss: 2.6406
Training Epoch: 42 [39936/50176]	Loss: 2.5453
Training Epoch: 42 [40960/50176]	Loss: 2.6405
Training Epoch: 42 [41984/50176]	Loss: 2.5105
Training Epoch: 42 [43008/50176]	Loss: 2.6391
Training Epoch: 42 [44032/50176]	Loss: 2.5762
Training Epoch: 42 [45056/50176]	Loss: 2.6442
Training Epoch: 42 [46080/50176]	Loss: 2.5876
Training Epoch: 42 [47104/50176]	Loss: 2.5689
Training Epoch: 42 [48128/50176]	Loss: 2.5791
Training Epoch: 42 [49152/50176]	Loss: 2.6284
Training Epoch: 42 [50176/50176]	Loss: 2.6612
2022-12-06 02:13:10.016 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:13:10,071 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.79 energy=528.42
2022-12-05 21:13:10,072 [ZeusDataLoader(train)] Up to epoch 43: time=2184.28, energy=319937.08, cost=351092.81
2022-12-05 21:13:10,072 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:13:10,072 [ZeusDataLoader(train)] Expected next epoch: time=2232.62, energy=327225.35, cost=358967.12
2022-12-05 21:13:10,073 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0026, Accuracy: 0.3175
2022-12-05 21:13:10,257 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:13:10,258 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:13:10.267 [ZeusMonitor] Monitor started.
2022-12-06 02:13:10.268 [ZeusMonitor] Running indefinitely. 2022-12-06 02:13:10.268 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:13:10.268 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e44+gpu0.power.log
2022-12-05 21:13:54,400 [ZeusDataLoader(train)] train epoch 44 done: time=44.32 energy=6756.03
2022-12-05 21:13:54,404 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 2.4679
Training Epoch: 43 [2048/50176]	Loss: 2.4738
Training Epoch: 43 [3072/50176]	Loss: 2.5521
Training Epoch: 43 [4096/50176]	Loss: 2.5602
Training Epoch: 43 [5120/50176]	Loss: 2.5297
Training Epoch: 43 [6144/50176]	Loss: 2.5458
Training Epoch: 43 [7168/50176]	Loss: 2.4779
Training Epoch: 43 [8192/50176]	Loss: 2.5029
Training Epoch: 43 [9216/50176]	Loss: 2.5689
Training Epoch: 43 [10240/50176]	Loss: 2.5719
Training Epoch: 43 [11264/50176]	Loss: 2.4925
Training Epoch: 43 [12288/50176]	Loss: 2.5076
Training Epoch: 43 [13312/50176]	Loss: 2.5984
Training Epoch: 43 [14336/50176]	Loss: 2.5861
Training Epoch: 43 [15360/50176]	Loss: 2.5139
Training Epoch: 43 [16384/50176]	Loss: 2.5790
Training Epoch: 43 [17408/50176]	Loss: 2.5492
Training Epoch: 43 [18432/50176]	Loss: 2.5570
Training Epoch: 43 [19456/50176]	Loss: 2.6789
Training Epoch: 43 [20480/50176]	Loss: 2.5054
Training Epoch: 43 [21504/50176]	Loss: 2.6406
Training Epoch: 43 [22528/50176]	Loss: 2.6493
Training Epoch: 43 [23552/50176]	Loss: 2.5482
Training Epoch: 43 [24576/50176]	Loss: 2.5326
Training Epoch: 43 [25600/50176]	Loss: 2.6436
Training Epoch: 43 [26624/50176]	Loss: 2.5160
Training Epoch: 43 [27648/50176]	Loss: 2.5770
Training Epoch: 43 [28672/50176]	Loss: 2.5869
Training Epoch: 43 [29696/50176]	Loss: 2.4949
Training Epoch: 43 [30720/50176]	Loss: 2.5116
Training Epoch: 43 [31744/50176]	Loss: 2.5528
Training Epoch: 43 [32768/50176]	Loss: 2.5879
Training Epoch: 43 [33792/50176]	Loss: 2.5059
Training Epoch: 43 [34816/50176]	Loss: 2.4925
Training Epoch: 43 [35840/50176]	Loss: 2.5519
Training Epoch: 43 [36864/50176]	Loss: 2.5932
Training Epoch: 43 [37888/50176]	Loss: 2.4898
Training Epoch: 43 [38912/50176]	Loss: 2.5119
Training Epoch: 43 [39936/50176]	Loss: 2.5318
Training Epoch: 43 [40960/50176]	Loss: 2.4654
Training Epoch: 43 [41984/50176]	Loss: 2.5399
Training Epoch: 43 [43008/50176]	Loss: 2.5547
Training Epoch: 43 [44032/50176]	Loss: 2.6012
Training Epoch: 43 [45056/50176]	Loss: 2.5717
Training Epoch: 43 [46080/50176]	Loss: 2.5207
Training Epoch: 43 [47104/50176]	Loss: 2.5559
Training Epoch: 43 [48128/50176]	Loss: 2.5803
Training Epoch: 43 [49152/50176]	Loss: 2.5116
Training Epoch: 43 [50176/50176]	Loss: 2.5490
2022-12-06 02:13:58.140 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:13:58,175 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.76 energy=527.13
2022-12-05 21:13:58,175 [ZeusDataLoader(train)] Up to epoch 44: time=2232.36, energy=327220.25, cost=358941.46
2022-12-05 21:13:58,175 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:13:58,175 [ZeusDataLoader(train)] Expected next epoch: time=2280.70, energy=334508.51, cost=366815.77
2022-12-05 21:13:58,176 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0026, Accuracy: 0.3252
2022-12-05 21:13:58,373 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:13:58,373 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:13:58.375 [ZeusMonitor] Monitor started.
2022-12-06 02:13:58.375 [ZeusMonitor] Running indefinitely. 2022-12-06 02:13:58.375 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:13:58.375 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e45+gpu0.power.log
2022-12-05 21:14:42,505 [ZeusDataLoader(train)] train epoch 45 done: time=44.32 energy=6746.96
2022-12-05 21:14:42,508 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 2.5096
Training Epoch: 44 [2048/50176]	Loss: 2.5027
Training Epoch: 44 [3072/50176]	Loss: 2.4783
Training Epoch: 44 [4096/50176]	Loss: 2.5837
Training Epoch: 44 [5120/50176]	Loss: 2.5065
Training Epoch: 44 [6144/50176]	Loss: 2.5832
Training Epoch: 44 [7168/50176]	Loss: 2.5161
Training Epoch: 44 [8192/50176]	Loss: 2.4975
Training Epoch: 44 [9216/50176]	Loss: 2.4987
Training Epoch: 44 [10240/50176]	Loss: 2.4725
Training Epoch: 44 [11264/50176]	Loss: 2.6005
Training Epoch: 44 [12288/50176]	Loss: 2.5139
Training Epoch: 44 [13312/50176]	Loss: 2.5983
Training Epoch: 44 [14336/50176]	Loss: 2.5244
Training Epoch: 44 [15360/50176]	Loss: 2.6177
Training Epoch: 44 [16384/50176]	Loss: 2.5055
Training Epoch: 44 [17408/50176]	Loss: 2.5014
Training Epoch: 44 [18432/50176]	Loss: 2.5255
Training Epoch: 44 [19456/50176]	Loss: 2.5424
Training Epoch: 44 [20480/50176]	Loss: 2.5069
Training Epoch: 44 [21504/50176]	Loss: 2.5267
Training Epoch: 44 [22528/50176]	Loss: 2.5847
Training Epoch: 44 [23552/50176]	Loss: 2.4595
Training Epoch: 44 [24576/50176]	Loss: 2.5855
Training Epoch: 44 [25600/50176]	Loss: 2.5303
Training Epoch: 44 [26624/50176]	Loss: 2.6101
Training Epoch: 44 [27648/50176]	Loss: 2.5196
Training Epoch: 44 [28672/50176]	Loss: 2.5329
Training Epoch: 44 [29696/50176]	Loss: 2.5218
Training Epoch: 44 [30720/50176]	Loss: 2.4640
Training Epoch: 44 [31744/50176]	Loss: 2.5762
Training Epoch: 44 [32768/50176]	Loss: 2.5755
Training Epoch: 44 [33792/50176]	Loss: 2.5068
Training Epoch: 44 [34816/50176]	Loss: 2.4967
Training Epoch: 44 [35840/50176]	Loss: 2.4693
Training Epoch: 44 [36864/50176]	Loss: 2.5170
Training Epoch: 44 [37888/50176]	Loss: 2.5195
Training Epoch: 44 [38912/50176]	Loss: 2.5469
Training Epoch: 44 [39936/50176]	Loss: 2.5509
Training Epoch: 44 [40960/50176]	Loss: 2.5249
Training Epoch: 44 [41984/50176]	Loss: 2.4305
Training Epoch: 44 [43008/50176]	Loss: 2.4536
Training Epoch: 44 [44032/50176]	Loss: 2.5434
Training Epoch: 44 [45056/50176]	Loss: 2.4977
Training Epoch: 44 [46080/50176]	Loss: 2.5375
Training Epoch: 44 [47104/50176]	Loss: 2.5953
Training Epoch: 44 [48128/50176]	Loss: 2.5368
Training Epoch: 44 [49152/50176]	Loss: 2.5854
Training Epoch: 44 [50176/50176]	Loss: 2.5013
2022-12-06 02:14:46.220 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:14:46,229 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.71 energy=520.24
2022-12-05 21:14:46,230 [ZeusDataLoader(train)] Up to epoch 45: time=2280.39, energy=334487.44, cost=366777.97
2022-12-05 21:14:46,230 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:14:46,230 [ZeusDataLoader(train)] Expected next epoch: time=2328.74, energy=341775.70, cost=374652.28
2022-12-05 21:14:46,231 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0026, Accuracy: 0.3303
2022-12-05 21:14:46,413 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:14:46,413 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:14:46.415 [ZeusMonitor] Monitor started.
2022-12-06 02:14:46.415 [ZeusMonitor] Running indefinitely. 2022-12-06 02:14:46.415 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:14:46.415 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e46+gpu0.power.log
2022-12-05 21:15:30,532 [ZeusDataLoader(train)] train epoch 46 done: time=44.29 energy=6742.34
2022-12-05 21:15:30,536 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 2.5678
Training Epoch: 45 [2048/50176]	Loss: 2.5389
Training Epoch: 45 [3072/50176]	Loss: 2.4393
Training Epoch: 45 [4096/50176]	Loss: 2.5509
Training Epoch: 45 [5120/50176]	Loss: 2.4609
Training Epoch: 45 [6144/50176]	Loss: 2.4943
Training Epoch: 45 [7168/50176]	Loss: 2.5103
Training Epoch: 45 [8192/50176]	Loss: 2.5432
Training Epoch: 45 [9216/50176]	Loss: 2.4708
Training Epoch: 45 [10240/50176]	Loss: 2.5357
Training Epoch: 45 [11264/50176]	Loss: 2.5736
Training Epoch: 45 [12288/50176]	Loss: 2.5266
Training Epoch: 45 [13312/50176]	Loss: 2.4501
Training Epoch: 45 [14336/50176]	Loss: 2.5608
Training Epoch: 45 [15360/50176]	Loss: 2.5015
Training Epoch: 45 [16384/50176]	Loss: 2.5130
Training Epoch: 45 [17408/50176]	Loss: 2.5366
Training Epoch: 45 [18432/50176]	Loss: 2.5026
Training Epoch: 45 [19456/50176]	Loss: 2.5415
Training Epoch: 45 [20480/50176]	Loss: 2.4817
Training Epoch: 45 [21504/50176]	Loss: 2.4955
Training Epoch: 45 [22528/50176]	Loss: 2.5031
Training Epoch: 45 [23552/50176]	Loss: 2.5496
Training Epoch: 45 [24576/50176]	Loss: 2.4855
Training Epoch: 45 [25600/50176]	Loss: 2.5230
Training Epoch: 45 [26624/50176]	Loss: 2.4987
Training Epoch: 45 [27648/50176]	Loss: 2.4844
Training Epoch: 45 [28672/50176]	Loss: 2.5070
Training Epoch: 45 [29696/50176]	Loss: 2.5217
Training Epoch: 45 [30720/50176]	Loss: 2.5927
Training Epoch: 45 [31744/50176]	Loss: 2.5076
Training Epoch: 45 [32768/50176]	Loss: 2.4995
Training Epoch: 45 [33792/50176]	Loss: 2.5014
Training Epoch: 45 [34816/50176]	Loss: 2.5479
Training Epoch: 45 [35840/50176]	Loss: 2.5420
Training Epoch: 45 [36864/50176]	Loss: 2.4134
Training Epoch: 45 [37888/50176]	Loss: 2.5211
Training Epoch: 45 [38912/50176]	Loss: 2.4019
Training Epoch: 45 [39936/50176]	Loss: 2.5371
Training Epoch: 45 [40960/50176]	Loss: 2.4673
Training Epoch: 45 [41984/50176]	Loss: 2.4692
Training Epoch: 45 [43008/50176]	Loss: 2.4947
Training Epoch: 45 [44032/50176]	Loss: 2.5416
Training Epoch: 45 [45056/50176]	Loss: 2.5695
Training Epoch: 45 [46080/50176]	Loss: 2.4875
Training Epoch: 45 [47104/50176]	Loss: 2.4660
Training Epoch: 45 [48128/50176]	Loss: 2.5092
Training Epoch: 45 [49152/50176]	Loss: 2.4965
Training Epoch: 45 [50176/50176]	Loss: 2.5325
2022-12-06 02:15:34.259 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:15:34,279 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.74 energy=522.49
2022-12-05 21:15:34,280 [ZeusDataLoader(train)] Up to epoch 46: time=2328.42, energy=341752.27, cost=374612.81
2022-12-05 21:15:34,280 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:15:34,280 [ZeusDataLoader(train)] Expected next epoch: time=2376.76, energy=349040.53, cost=382487.12
2022-12-05 21:15:34,281 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0026, Accuracy: 0.3307
2022-12-05 21:15:34,431 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:15:34,432 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:15:34.435 [ZeusMonitor] Monitor started.
2022-12-06 02:15:34.436 [ZeusMonitor] Running indefinitely. 2022-12-06 02:15:34.436 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:15:34.436 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e47+gpu0.power.log
2022-12-05 21:16:18,575 [ZeusDataLoader(train)] train epoch 47 done: time=44.29 energy=6749.08
2022-12-05 21:16:18,579 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 2.4681
Training Epoch: 46 [2048/50176]	Loss: 2.5942
Training Epoch: 46 [3072/50176]	Loss: 2.5037
Training Epoch: 46 [4096/50176]	Loss: 2.4859
Training Epoch: 46 [5120/50176]	Loss: 2.5004
Training Epoch: 46 [6144/50176]	Loss: 2.5287
Training Epoch: 46 [7168/50176]	Loss: 2.4561
Training Epoch: 46 [8192/50176]	Loss: 2.4457
Training Epoch: 46 [9216/50176]	Loss: 2.4011
Training Epoch: 46 [10240/50176]	Loss: 2.4582
Training Epoch: 46 [11264/50176]	Loss: 2.4659
Training Epoch: 46 [12288/50176]	Loss: 2.4783
Training Epoch: 46 [13312/50176]	Loss: 2.4383
Training Epoch: 46 [14336/50176]	Loss: 2.5036
Training Epoch: 46 [15360/50176]	Loss: 2.4853
Training Epoch: 46 [16384/50176]	Loss: 2.5301
Training Epoch: 46 [17408/50176]	Loss: 2.4344
Training Epoch: 46 [18432/50176]	Loss: 2.5239
Training Epoch: 46 [19456/50176]	Loss: 2.5170
Training Epoch: 46 [20480/50176]	Loss: 2.4199
Training Epoch: 46 [21504/50176]	Loss: 2.5158
Training Epoch: 46 [22528/50176]	Loss: 2.5265
Training Epoch: 46 [23552/50176]	Loss: 2.5358
Training Epoch: 46 [24576/50176]	Loss: 2.5651
Training Epoch: 46 [25600/50176]	Loss: 2.4048
Training Epoch: 46 [26624/50176]	Loss: 2.4937
Training Epoch: 46 [27648/50176]	Loss: 2.4480
Training Epoch: 46 [28672/50176]	Loss: 2.4340
Training Epoch: 46 [29696/50176]	Loss: 2.4977
Training Epoch: 46 [30720/50176]	Loss: 2.5241
Training Epoch: 46 [31744/50176]	Loss: 2.5324
Training Epoch: 46 [32768/50176]	Loss: 2.4428
Training Epoch: 46 [33792/50176]	Loss: 2.4973
Training Epoch: 46 [34816/50176]	Loss: 2.5110
Training Epoch: 46 [35840/50176]	Loss: 2.4733
Training Epoch: 46 [36864/50176]	Loss: 2.5052
Training Epoch: 46 [37888/50176]	Loss: 2.4689
Training Epoch: 46 [38912/50176]	Loss: 2.5147
Training Epoch: 46 [39936/50176]	Loss: 2.4978
Training Epoch: 46 [40960/50176]	Loss: 2.5298
Training Epoch: 46 [41984/50176]	Loss: 2.4486
Training Epoch: 46 [43008/50176]	Loss: 2.3893
Training Epoch: 46 [44032/50176]	Loss: 2.5134
Training Epoch: 46 [45056/50176]	Loss: 2.4675
Training Epoch: 46 [46080/50176]	Loss: 2.4412
Training Epoch: 46 [47104/50176]	Loss: 2.5344
Training Epoch: 46 [48128/50176]	Loss: 2.5274
Training Epoch: 46 [49152/50176]	Loss: 2.4831
Training Epoch: 46 [50176/50176]	Loss: 2.5034
2022-12-06 02:16:22.318 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:16:22,364 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.78 energy=522.53
2022-12-05 21:16:22,364 [ZeusDataLoader(train)] Up to epoch 47: time=2376.48, energy=349023.88, cost=382454.08
2022-12-05 21:16:22,364 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:16:22,364 [ZeusDataLoader(train)] Expected next epoch: time=2424.83, energy=356312.15, cost=390328.40
2022-12-05 21:16:22,365 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0026, Accuracy: 0.3375
2022-12-05 21:16:22,520 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:16:22,521 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:16:22.523 [ZeusMonitor] Monitor started.
2022-12-06 02:16:22.523 [ZeusMonitor] Running indefinitely. 2022-12-06 02:16:22.523 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:16:22.523 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e48+gpu0.power.log
2022-12-05 21:17:06,641 [ZeusDataLoader(train)] train epoch 48 done: time=44.27 energy=6762.06
2022-12-05 21:17:06,644 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 2.5389
Training Epoch: 47 [2048/50176]	Loss: 2.4137
Training Epoch: 47 [3072/50176]	Loss: 2.4670
Training Epoch: 47 [4096/50176]	Loss: 2.5265
Training Epoch: 47 [5120/50176]	Loss: 2.4428
Training Epoch: 47 [6144/50176]	Loss: 2.4884
Training Epoch: 47 [7168/50176]	Loss: 2.4907
Training Epoch: 47 [8192/50176]	Loss: 2.4995
Training Epoch: 47 [9216/50176]	Loss: 2.4443
Training Epoch: 47 [10240/50176]	Loss: 2.4573
Training Epoch: 47 [11264/50176]	Loss: 2.5953
Training Epoch: 47 [12288/50176]	Loss: 2.5119
Training Epoch: 47 [13312/50176]	Loss: 2.4182
Training Epoch: 47 [14336/50176]	Loss: 2.5421
Training Epoch: 47 [15360/50176]	Loss: 2.5294
Training Epoch: 47 [16384/50176]	Loss: 2.4767
Training Epoch: 47 [17408/50176]	Loss: 2.3827
Training Epoch: 47 [18432/50176]	Loss: 2.5354
Training Epoch: 47 [19456/50176]	Loss: 2.4358
Training Epoch: 47 [20480/50176]	Loss: 2.4748
Training Epoch: 47 [21504/50176]	Loss: 2.4911
Training Epoch: 47 [22528/50176]	Loss: 2.4911
Training Epoch: 47 [23552/50176]	Loss: 2.4418
Training Epoch: 47 [24576/50176]	Loss: 2.4773
Training Epoch: 47 [25600/50176]	Loss: 2.5606
Training Epoch: 47 [26624/50176]	Loss: 2.3451
Training Epoch: 47 [27648/50176]	Loss: 2.4111
Training Epoch: 47 [28672/50176]	Loss: 2.4738
Training Epoch: 47 [29696/50176]	Loss: 2.4261
Training Epoch: 47 [30720/50176]	Loss: 2.5159
Training Epoch: 47 [31744/50176]	Loss: 2.4797
Training Epoch: 47 [32768/50176]	Loss: 2.4645
Training Epoch: 47 [33792/50176]	Loss: 2.4398
Training Epoch: 47 [34816/50176]	Loss: 2.4453
Training Epoch: 47 [35840/50176]	Loss: 2.4564
Training Epoch: 47 [36864/50176]	Loss: 2.3973
Training Epoch: 47 [37888/50176]	Loss: 2.4434
Training Epoch: 47 [38912/50176]	Loss: 2.4561
Training Epoch: 47 [39936/50176]	Loss: 2.4618
Training Epoch: 47 [40960/50176]	Loss: 2.4887
Training Epoch: 47 [41984/50176]	Loss: 2.4665
Training Epoch: 47 [43008/50176]	Loss: 2.4694
Training Epoch: 47 [44032/50176]	Loss: 2.4872
Training Epoch: 47 [45056/50176]	Loss: 2.4114
Training Epoch: 47 [46080/50176]	Loss: 2.4628
Training Epoch: 47 [47104/50176]	Loss: 2.4069
Training Epoch: 47 [48128/50176]	Loss: 2.4691
Training Epoch: 47 [49152/50176]	Loss: 2.4426
Training Epoch: 47 [50176/50176]	Loss: 2.4685
2022-12-06 02:17:10.430 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:17:10,450 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.80 energy=521.95
2022-12-05 21:17:10,451 [ZeusDataLoader(train)] Up to epoch 48: time=2424.55, energy=356307.90, cost=390301.84
2022-12-05 21:17:10,451 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:17:10,451 [ZeusDataLoader(train)] Expected next epoch: time=2472.89, energy=363596.16, cost=398176.15
2022-12-05 21:17:10,452 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0025, Accuracy: 0.3413
2022-12-05 21:17:10,678 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:17:10,679 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:17:10.689 [ZeusMonitor] Monitor started.
2022-12-06 02:17:10.689 [ZeusMonitor] Running indefinitely. 2022-12-06 02:17:10.689 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:17:10.689 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e49+gpu0.power.log
2022-12-05 21:17:54,758 [ZeusDataLoader(train)] train epoch 49 done: time=44.30 energy=6747.82
2022-12-05 21:17:54,762 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 2.3894
Training Epoch: 48 [2048/50176]	Loss: 2.4538
Training Epoch: 48 [3072/50176]	Loss: 2.3511
Training Epoch: 48 [4096/50176]	Loss: 2.4651
Training Epoch: 48 [5120/50176]	Loss: 2.4009
Training Epoch: 48 [6144/50176]	Loss: 2.3885
Training Epoch: 48 [7168/50176]	Loss: 2.3891
Training Epoch: 48 [8192/50176]	Loss: 2.4034
Training Epoch: 48 [9216/50176]	Loss: 2.4852
Training Epoch: 48 [10240/50176]	Loss: 2.4683
Training Epoch: 48 [11264/50176]	Loss: 2.4459
Training Epoch: 48 [12288/50176]	Loss: 2.4834
Training Epoch: 48 [13312/50176]	Loss: 2.4087
Training Epoch: 48 [14336/50176]	Loss: 2.4113
Training Epoch: 48 [15360/50176]	Loss: 2.4899
Training Epoch: 48 [16384/50176]	Loss: 2.4407
Training Epoch: 48 [17408/50176]	Loss: 2.4227
Training Epoch: 48 [18432/50176]	Loss: 2.5347
Training Epoch: 48 [19456/50176]	Loss: 2.4114
Training Epoch: 48 [20480/50176]	Loss: 2.4571
Training Epoch: 48 [21504/50176]	Loss: 2.4935
Training Epoch: 48 [22528/50176]	Loss: 2.4226
Training Epoch: 48 [23552/50176]	Loss: 2.4690
Training Epoch: 48 [24576/50176]	Loss: 2.4721
Training Epoch: 48 [25600/50176]	Loss: 2.4375
Training Epoch: 48 [26624/50176]	Loss: 2.3532
Training Epoch: 48 [27648/50176]	Loss: 2.5214
Training Epoch: 48 [28672/50176]	Loss: 2.4793
Training Epoch: 48 [29696/50176]	Loss: 2.4374
Training Epoch: 48 [30720/50176]	Loss: 2.4158
Training Epoch: 48 [31744/50176]	Loss: 2.4433
Training Epoch: 48 [32768/50176]	Loss: 2.4398
Training Epoch: 48 [33792/50176]	Loss: 2.4617
Training Epoch: 48 [34816/50176]	Loss: 2.4350
Training Epoch: 48 [35840/50176]	Loss: 2.4417
Training Epoch: 48 [36864/50176]	Loss: 2.4533
Training Epoch: 48 [37888/50176]	Loss: 2.4301
Training Epoch: 48 [38912/50176]	Loss: 2.4244
Training Epoch: 48 [39936/50176]	Loss: 2.4451
Training Epoch: 48 [40960/50176]	Loss: 2.4819
Training Epoch: 48 [41984/50176]	Loss: 2.5042
Training Epoch: 48 [43008/50176]	Loss: 2.4320
Training Epoch: 48 [44032/50176]	Loss: 2.4422
Training Epoch: 48 [45056/50176]	Loss: 2.4458
Training Epoch: 48 [46080/50176]	Loss: 2.4736
Training Epoch: 48 [47104/50176]	Loss: 2.4151
Training Epoch: 48 [48128/50176]	Loss: 2.4090
Training Epoch: 48 [49152/50176]	Loss: 2.4572
Training Epoch: 48 [50176/50176]	Loss: 2.3576
2022-12-06 02:17:58.543 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:17:58,577 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.81 energy=533.52
2022-12-05 21:17:58,577 [ZeusDataLoader(train)] Up to epoch 49: time=2472.65, energy=363589.24, cost=398151.65
2022-12-05 21:17:58,577 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:17:58,577 [ZeusDataLoader(train)] Expected next epoch: time=2521.00, energy=370877.50, cost=406025.96
2022-12-05 21:17:58,578 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0025, Accuracy: 0.3411
2022-12-05 21:17:58,759 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:17:58,760 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:17:58.771 [ZeusMonitor] Monitor started.
2022-12-06 02:17:58.771 [ZeusMonitor] Running indefinitely. 2022-12-06 02:17:58.771 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:17:58.771 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e50+gpu0.power.log
2022-12-05 21:18:42,962 [ZeusDataLoader(train)] train epoch 50 done: time=44.38 energy=6766.04
2022-12-05 21:18:42,966 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 2.4002
Training Epoch: 49 [2048/50176]	Loss: 2.4575
Training Epoch: 49 [3072/50176]	Loss: 2.4700
Training Epoch: 49 [4096/50176]	Loss: 2.4329
Training Epoch: 49 [5120/50176]	Loss: 2.4056
Training Epoch: 49 [6144/50176]	Loss: 2.4013
Training Epoch: 49 [7168/50176]	Loss: 2.4620
Training Epoch: 49 [8192/50176]	Loss: 2.3934
Training Epoch: 49 [9216/50176]	Loss: 2.4982
Training Epoch: 49 [10240/50176]	Loss: 2.3697
Training Epoch: 49 [11264/50176]	Loss: 2.4288
Training Epoch: 49 [12288/50176]	Loss: 2.4550
Training Epoch: 49 [13312/50176]	Loss: 2.3884
Training Epoch: 49 [14336/50176]	Loss: 2.4555
Training Epoch: 49 [15360/50176]	Loss: 2.4445
Training Epoch: 49 [16384/50176]	Loss: 2.5002
Training Epoch: 49 [17408/50176]	Loss: 2.4098
Training Epoch: 49 [18432/50176]	Loss: 2.4514
Training Epoch: 49 [19456/50176]	Loss: 2.4063
Training Epoch: 49 [20480/50176]	Loss: 2.2828
Training Epoch: 49 [21504/50176]	Loss: 2.3965
Training Epoch: 49 [22528/50176]	Loss: 2.4103
Training Epoch: 49 [23552/50176]	Loss: 2.4081
Training Epoch: 49 [24576/50176]	Loss: 2.3784
Training Epoch: 49 [25600/50176]	Loss: 2.4786
Training Epoch: 49 [26624/50176]	Loss: 2.4846
Training Epoch: 49 [27648/50176]	Loss: 2.4488
Training Epoch: 49 [28672/50176]	Loss: 2.3205
Training Epoch: 49 [29696/50176]	Loss: 2.4021
Training Epoch: 49 [30720/50176]	Loss: 2.5151
Training Epoch: 49 [31744/50176]	Loss: 2.4692
Training Epoch: 49 [32768/50176]	Loss: 2.3607
Training Epoch: 49 [33792/50176]	Loss: 2.4368
Training Epoch: 49 [34816/50176]	Loss: 2.4935
Training Epoch: 49 [35840/50176]	Loss: 2.4549
Training Epoch: 49 [36864/50176]	Loss: 2.4651
Training Epoch: 49 [37888/50176]	Loss: 2.4089
Training Epoch: 49 [38912/50176]	Loss: 2.3970
Training Epoch: 49 [39936/50176]	Loss: 2.4480
Training Epoch: 49 [40960/50176]	Loss: 2.3616
Training Epoch: 49 [41984/50176]	Loss: 2.5281
Training Epoch: 49 [43008/50176]	Loss: 2.3978
Training Epoch: 49 [44032/50176]	Loss: 2.3491
Training Epoch: 49 [45056/50176]	Loss: 2.3485
Training Epoch: 49 [46080/50176]	Loss: 2.4613
Training Epoch: 49 [47104/50176]	Loss: 2.4386
Training Epoch: 49 [48128/50176]	Loss: 2.4318
Training Epoch: 49 [49152/50176]	Loss: 2.4798
Training Epoch: 49 [50176/50176]	Loss: 2.4084
2022-12-06 02:18:46.732 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:18:46,764 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.79 energy=522.32
2022-12-05 21:18:46,764 [ZeusDataLoader(train)] Up to epoch 50: time=2520.82, energy=370877.60, cost=406010.33
2022-12-05 21:18:46,765 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:18:46,765 [ZeusDataLoader(train)] Expected next epoch: time=2569.16, energy=378165.86, cost=413884.64
2022-12-05 21:18:46,766 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0025, Accuracy: 0.3372
2022-12-05 21:18:46,981 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:18:46,981 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:18:46.995 [ZeusMonitor] Monitor started.
2022-12-06 02:18:46.996 [ZeusMonitor] Running indefinitely. 2022-12-06 02:18:46.996 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:18:46.996 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e51+gpu0.power.log
2022-12-05 21:19:31,044 [ZeusDataLoader(train)] train epoch 51 done: time=44.27 energy=6746.31
2022-12-05 21:19:31,047 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 2.4148
Training Epoch: 50 [2048/50176]	Loss: 2.4144
Training Epoch: 50 [3072/50176]	Loss: 2.5335
Training Epoch: 50 [4096/50176]	Loss: 2.4247
Training Epoch: 50 [5120/50176]	Loss: 2.4024
Training Epoch: 50 [6144/50176]	Loss: 2.4221
Training Epoch: 50 [7168/50176]	Loss: 2.4161
Training Epoch: 50 [8192/50176]	Loss: 2.4387
Training Epoch: 50 [9216/50176]	Loss: 2.3950
Training Epoch: 50 [10240/50176]	Loss: 2.4343
Training Epoch: 50 [11264/50176]	Loss: 2.3040
Training Epoch: 50 [12288/50176]	Loss: 2.4325
Training Epoch: 50 [13312/50176]	Loss: 2.3821
Training Epoch: 50 [14336/50176]	Loss: 2.3922
Training Epoch: 50 [15360/50176]	Loss: 2.4053
Training Epoch: 50 [16384/50176]	Loss: 2.4206
Training Epoch: 50 [17408/50176]	Loss: 2.3455
Training Epoch: 50 [18432/50176]	Loss: 2.4562
Training Epoch: 50 [19456/50176]	Loss: 2.3978
Training Epoch: 50 [20480/50176]	Loss: 2.4144
Training Epoch: 50 [21504/50176]	Loss: 2.4535
Training Epoch: 50 [22528/50176]	Loss: 2.3532
Training Epoch: 50 [23552/50176]	Loss: 2.3786
Training Epoch: 50 [24576/50176]	Loss: 2.4048
Training Epoch: 50 [25600/50176]	Loss: 2.3760
Training Epoch: 50 [26624/50176]	Loss: 2.3592
Training Epoch: 50 [27648/50176]	Loss: 2.3770
Training Epoch: 50 [28672/50176]	Loss: 2.4432
Training Epoch: 50 [29696/50176]	Loss: 2.3848
Training Epoch: 50 [30720/50176]	Loss: 2.3324
Training Epoch: 50 [31744/50176]	Loss: 2.3768
Training Epoch: 50 [32768/50176]	Loss: 2.4012
Training Epoch: 50 [33792/50176]	Loss: 2.3453
Training Epoch: 50 [34816/50176]	Loss: 2.4319
Training Epoch: 50 [35840/50176]	Loss: 2.3278
Training Epoch: 50 [36864/50176]	Loss: 2.5251
Training Epoch: 50 [37888/50176]	Loss: 2.4366
Training Epoch: 50 [38912/50176]	Loss: 2.4556
Training Epoch: 50 [39936/50176]	Loss: 2.3664
Training Epoch: 50 [40960/50176]	Loss: 2.3929
Training Epoch: 50 [41984/50176]	Loss: 2.3058
Training Epoch: 50 [43008/50176]	Loss: 2.4222
Training Epoch: 50 [44032/50176]	Loss: 2.3766
Training Epoch: 50 [45056/50176]	Loss: 2.4295
Training Epoch: 50 [46080/50176]	Loss: 2.4726
Training Epoch: 50 [47104/50176]	Loss: 2.4364
Training Epoch: 50 [48128/50176]	Loss: 2.3953
Training Epoch: 50 [49152/50176]	Loss: 2.4118
Training Epoch: 50 [50176/50176]	Loss: 2.4661
2022-12-06 02:19:34.815 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:19:34,841 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.79 energy=530.57
2022-12-05 21:19:34,841 [ZeusDataLoader(train)] Up to epoch 51: time=2568.87, energy=378154.48, cost=413853.58
2022-12-05 21:19:34,841 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:19:34,841 [ZeusDataLoader(train)] Expected next epoch: time=2617.22, energy=385442.74, cost=421727.89
2022-12-05 21:19:34,842 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0025, Accuracy: 0.3444
2022-12-05 21:19:35,037 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:19:35,038 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:19:35.048 [ZeusMonitor] Monitor started.
2022-12-06 02:19:35.048 [ZeusMonitor] Running indefinitely. 2022-12-06 02:19:35.048 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:19:35.048 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e52+gpu0.power.log
2022-12-05 21:20:19,277 [ZeusDataLoader(train)] train epoch 52 done: time=44.43 energy=6755.70
2022-12-05 21:20:19,281 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 2.2953
Training Epoch: 51 [2048/50176]	Loss: 2.4501
Training Epoch: 51 [3072/50176]	Loss: 2.3989
Training Epoch: 51 [4096/50176]	Loss: 2.3717
Training Epoch: 51 [5120/50176]	Loss: 2.3625
Training Epoch: 51 [6144/50176]	Loss: 2.3924
Training Epoch: 51 [7168/50176]	Loss: 2.4100
Training Epoch: 51 [8192/50176]	Loss: 2.4619
Training Epoch: 51 [9216/50176]	Loss: 2.3478
Training Epoch: 51 [10240/50176]	Loss: 2.3125
Training Epoch: 51 [11264/50176]	Loss: 2.3903
Training Epoch: 51 [12288/50176]	Loss: 2.5417
Training Epoch: 51 [13312/50176]	Loss: 2.3778
Training Epoch: 51 [14336/50176]	Loss: 2.3476
Training Epoch: 51 [15360/50176]	Loss: 2.3589
Training Epoch: 51 [16384/50176]	Loss: 2.4064
Training Epoch: 51 [17408/50176]	Loss: 2.4056
Training Epoch: 51 [18432/50176]	Loss: 2.3789
Training Epoch: 51 [19456/50176]	Loss: 2.4224
Training Epoch: 51 [20480/50176]	Loss: 2.3304
Training Epoch: 51 [21504/50176]	Loss: 2.3642
Training Epoch: 51 [22528/50176]	Loss: 2.4285
Training Epoch: 51 [23552/50176]	Loss: 2.3491
Training Epoch: 51 [24576/50176]	Loss: 2.3108
Training Epoch: 51 [25600/50176]	Loss: 2.4003
Training Epoch: 51 [26624/50176]	Loss: 2.3771
Training Epoch: 51 [27648/50176]	Loss: 2.3975
Training Epoch: 51 [28672/50176]	Loss: 2.3543
Training Epoch: 51 [29696/50176]	Loss: 2.3930
Training Epoch: 51 [30720/50176]	Loss: 2.4296
Training Epoch: 51 [31744/50176]	Loss: 2.4422
Training Epoch: 51 [32768/50176]	Loss: 2.4747
Training Epoch: 51 [33792/50176]	Loss: 2.4693
Training Epoch: 51 [34816/50176]	Loss: 2.3617
Training Epoch: 51 [35840/50176]	Loss: 2.3269
Training Epoch: 51 [36864/50176]	Loss: 2.3681
Training Epoch: 51 [37888/50176]	Loss: 2.4079
Training Epoch: 51 [38912/50176]	Loss: 2.3432
Training Epoch: 51 [39936/50176]	Loss: 2.3434
Training Epoch: 51 [40960/50176]	Loss: 2.3402
Training Epoch: 51 [41984/50176]	Loss: 2.4239
Training Epoch: 51 [43008/50176]	Loss: 2.3424
Training Epoch: 51 [44032/50176]	Loss: 2.3668
Training Epoch: 51 [45056/50176]	Loss: 2.4817
Training Epoch: 51 [46080/50176]	Loss: 2.4767
Training Epoch: 51 [47104/50176]	Loss: 2.4555
Training Epoch: 51 [48128/50176]	Loss: 2.2691
Training Epoch: 51 [49152/50176]	Loss: 2.3691
Training Epoch: 51 [50176/50176]	Loss: 2.3549
2022-12-06 02:20:22.986 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:20:23,006 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.72 energy=518.28
2022-12-05 21:20:23,006 [ZeusDataLoader(train)] Up to epoch 52: time=2617.02, energy=385428.47, cost=421703.05
2022-12-05 21:20:23,006 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:20:23,006 [ZeusDataLoader(train)] Expected next epoch: time=2665.36, energy=392716.73, cost=429577.37
2022-12-05 21:20:23,007 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0025, Accuracy: 0.3459
2022-12-05 21:20:23,155 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:20:23,156 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:20:23.158 [ZeusMonitor] Monitor started.
2022-12-06 02:20:23.158 [ZeusMonitor] Running indefinitely. 2022-12-06 02:20:23.158 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:20:23.158 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e53+gpu0.power.log
2022-12-05 21:21:07,271 [ZeusDataLoader(train)] train epoch 53 done: time=44.25 energy=6754.25
2022-12-05 21:21:07,274 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 2.3331
Training Epoch: 52 [2048/50176]	Loss: 2.3460
Training Epoch: 52 [3072/50176]	Loss: 2.3107
Training Epoch: 52 [4096/50176]	Loss: 2.3246
Training Epoch: 52 [5120/50176]	Loss: 2.3360
Training Epoch: 52 [6144/50176]	Loss: 2.3197
Training Epoch: 52 [7168/50176]	Loss: 2.4389
Training Epoch: 52 [8192/50176]	Loss: 2.4063
Training Epoch: 52 [9216/50176]	Loss: 2.3530
Training Epoch: 52 [10240/50176]	Loss: 2.3052
Training Epoch: 52 [11264/50176]	Loss: 2.4095
Training Epoch: 52 [12288/50176]	Loss: 2.2465
Training Epoch: 52 [13312/50176]	Loss: 2.3116
Training Epoch: 52 [14336/50176]	Loss: 2.3403
Training Epoch: 52 [15360/50176]	Loss: 2.3457
Training Epoch: 52 [16384/50176]	Loss: 2.3358
Training Epoch: 52 [17408/50176]	Loss: 2.3499
Training Epoch: 52 [18432/50176]	Loss: 2.4228
Training Epoch: 52 [19456/50176]	Loss: 2.3767
Training Epoch: 52 [20480/50176]	Loss: 2.4321
Training Epoch: 52 [21504/50176]	Loss: 2.4260
Training Epoch: 52 [22528/50176]	Loss: 2.2877
Training Epoch: 52 [23552/50176]	Loss: 2.3999
Training Epoch: 52 [24576/50176]	Loss: 2.3214
Training Epoch: 52 [25600/50176]	Loss: 2.3299
Training Epoch: 52 [26624/50176]	Loss: 2.2668
Training Epoch: 52 [27648/50176]	Loss: 2.4051
Training Epoch: 52 [28672/50176]	Loss: 2.3336
Training Epoch: 52 [29696/50176]	Loss: 2.3364
Training Epoch: 52 [30720/50176]	Loss: 2.3805
Training Epoch: 52 [31744/50176]	Loss: 2.3310
Training Epoch: 52 [32768/50176]	Loss: 2.4242
Training Epoch: 52 [33792/50176]	Loss: 2.4100
Training Epoch: 52 [34816/50176]	Loss: 2.3754
Training Epoch: 52 [35840/50176]	Loss: 2.3755
Training Epoch: 52 [36864/50176]	Loss: 2.4917
Training Epoch: 52 [37888/50176]	Loss: 2.4189
Training Epoch: 52 [38912/50176]	Loss: 2.3633
Training Epoch: 52 [39936/50176]	Loss: 2.3466
Training Epoch: 52 [40960/50176]	Loss: 2.3376
Training Epoch: 52 [41984/50176]	Loss: 2.3358
Training Epoch: 52 [43008/50176]	Loss: 2.2622
Training Epoch: 52 [44032/50176]	Loss: 2.3619
Training Epoch: 52 [45056/50176]	Loss: 2.3769
Training Epoch: 52 [46080/50176]	Loss: 2.4659
Training Epoch: 52 [47104/50176]	Loss: 2.2843
Training Epoch: 52 [48128/50176]	Loss: 2.4225
Training Epoch: 52 [49152/50176]	Loss: 2.3762
Training Epoch: 52 [50176/50176]	Loss: 2.4296
2022-12-06 02:21:10.996 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:21:11,009 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.73 energy=528.65
2022-12-05 21:21:11,009 [ZeusDataLoader(train)] Up to epoch 53: time=2665.00, energy=392711.38, cost=429542.81
2022-12-05 21:21:11,009 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:21:11,009 [ZeusDataLoader(train)] Expected next epoch: time=2713.34, energy=399999.64, cost=437417.12
2022-12-05 21:21:11,010 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0025, Accuracy: 0.3487
2022-12-05 21:21:11,199 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:21:11,200 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:21:11.210 [ZeusMonitor] Monitor started.
2022-12-06 02:21:11.210 [ZeusMonitor] Running indefinitely. 2022-12-06 02:21:11.210 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:21:11.210 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e54+gpu0.power.log
2022-12-05 21:21:55,252 [ZeusDataLoader(train)] train epoch 54 done: time=44.23 energy=6745.79
2022-12-05 21:21:55,256 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 2.3415
Training Epoch: 53 [2048/50176]	Loss: 2.2329
Training Epoch: 53 [3072/50176]	Loss: 2.3345
Training Epoch: 53 [4096/50176]	Loss: 2.3679
Training Epoch: 53 [5120/50176]	Loss: 2.2847
Training Epoch: 53 [6144/50176]	Loss: 2.3381
Training Epoch: 53 [7168/50176]	Loss: 2.3054
Training Epoch: 53 [8192/50176]	Loss: 2.2989
Training Epoch: 53 [9216/50176]	Loss: 2.3500
Training Epoch: 53 [10240/50176]	Loss: 2.3704
Training Epoch: 53 [11264/50176]	Loss: 2.3221
Training Epoch: 53 [12288/50176]	Loss: 2.3184
Training Epoch: 53 [13312/50176]	Loss: 2.2914
Training Epoch: 53 [14336/50176]	Loss: 2.4059
Training Epoch: 53 [15360/50176]	Loss: 2.3858
Training Epoch: 53 [16384/50176]	Loss: 2.3573
Training Epoch: 53 [17408/50176]	Loss: 2.3321
Training Epoch: 53 [18432/50176]	Loss: 2.2956
Training Epoch: 53 [19456/50176]	Loss: 2.4441
Training Epoch: 53 [20480/50176]	Loss: 2.3333
Training Epoch: 53 [21504/50176]	Loss: 2.3123
Training Epoch: 53 [22528/50176]	Loss: 2.3445
Training Epoch: 53 [23552/50176]	Loss: 2.2632
Training Epoch: 53 [24576/50176]	Loss: 2.3183
Training Epoch: 53 [25600/50176]	Loss: 2.3494
Training Epoch: 53 [26624/50176]	Loss: 2.3316
Training Epoch: 53 [27648/50176]	Loss: 2.3505
Training Epoch: 53 [28672/50176]	Loss: 2.3142
Training Epoch: 53 [29696/50176]	Loss: 2.3532
Training Epoch: 53 [30720/50176]	Loss: 2.3602
Training Epoch: 53 [31744/50176]	Loss: 2.3569
Training Epoch: 53 [32768/50176]	Loss: 2.4169
Training Epoch: 53 [33792/50176]	Loss: 2.3463
Training Epoch: 53 [34816/50176]	Loss: 2.3343
Training Epoch: 53 [35840/50176]	Loss: 2.3434
Training Epoch: 53 [36864/50176]	Loss: 2.3229
Training Epoch: 53 [37888/50176]	Loss: 2.4063
Training Epoch: 53 [38912/50176]	Loss: 2.4022
Training Epoch: 53 [39936/50176]	Loss: 2.3540
Training Epoch: 53 [40960/50176]	Loss: 2.2948
Training Epoch: 53 [41984/50176]	Loss: 2.3697
Training Epoch: 53 [43008/50176]	Loss: 2.3782
Training Epoch: 53 [44032/50176]	Loss: 2.4023
Training Epoch: 53 [45056/50176]	Loss: 2.4265
Training Epoch: 53 [46080/50176]	Loss: 2.4341
Training Epoch: 53 [47104/50176]	Loss: 2.2986
Training Epoch: 53 [48128/50176]	Loss: 2.3800
Training Epoch: 53 [49152/50176]	Loss: 2.3038
Training Epoch: 53 [50176/50176]	Loss: 2.3336
2022-12-06 02:21:58.936 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:21:58,953 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.69 energy=518.65
2022-12-05 21:21:58,953 [ZeusDataLoader(train)] Up to epoch 54: time=2712.92, energy=399975.81, cost=437368.22
2022-12-05 21:21:58,954 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:21:58,954 [ZeusDataLoader(train)] Expected next epoch: time=2761.26, energy=407264.07, cost=445242.53
2022-12-05 21:21:58,955 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0025, Accuracy: 0.3525
2022-12-05 21:21:59,164 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:21:59,164 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:21:59.166 [ZeusMonitor] Monitor started.
2022-12-06 02:21:59.166 [ZeusMonitor] Running indefinitely. 2022-12-06 02:21:59.166 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:21:59.166 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e55+gpu0.power.log
2022-12-05 21:22:43,281 [ZeusDataLoader(train)] train epoch 55 done: time=44.32 energy=6743.57
2022-12-05 21:22:43,285 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 2.3331
Training Epoch: 54 [2048/50176]	Loss: 2.4574
Training Epoch: 54 [3072/50176]	Loss: 2.2694
Training Epoch: 54 [4096/50176]	Loss: 2.3111
Training Epoch: 54 [5120/50176]	Loss: 2.2546
Training Epoch: 54 [6144/50176]	Loss: 2.2656
Training Epoch: 54 [7168/50176]	Loss: 2.3219
Training Epoch: 54 [8192/50176]	Loss: 2.3206
Training Epoch: 54 [9216/50176]	Loss: 2.3182
Training Epoch: 54 [10240/50176]	Loss: 2.2984
Training Epoch: 54 [11264/50176]	Loss: 2.2835
Training Epoch: 54 [12288/50176]	Loss: 2.2758
Training Epoch: 54 [13312/50176]	Loss: 2.4012
Training Epoch: 54 [14336/50176]	Loss: 2.2264
Training Epoch: 54 [15360/50176]	Loss: 2.4433
Training Epoch: 54 [16384/50176]	Loss: 2.3534
Training Epoch: 54 [17408/50176]	Loss: 2.3775
Training Epoch: 54 [18432/50176]	Loss: 2.2383
Training Epoch: 54 [19456/50176]	Loss: 2.3867
Training Epoch: 54 [20480/50176]	Loss: 2.2932
Training Epoch: 54 [21504/50176]	Loss: 2.3269
Training Epoch: 54 [22528/50176]	Loss: 2.3006
Training Epoch: 54 [23552/50176]	Loss: 2.2935
Training Epoch: 54 [24576/50176]	Loss: 2.3413
Training Epoch: 54 [25600/50176]	Loss: 2.3373
Training Epoch: 54 [26624/50176]	Loss: 2.3109
Training Epoch: 54 [27648/50176]	Loss: 2.4338
Training Epoch: 54 [28672/50176]	Loss: 2.4029
Training Epoch: 54 [29696/50176]	Loss: 2.2526
Training Epoch: 54 [30720/50176]	Loss: 2.3365
Training Epoch: 54 [31744/50176]	Loss: 2.2868
Training Epoch: 54 [32768/50176]	Loss: 2.2491
Training Epoch: 54 [33792/50176]	Loss: 2.3300
Training Epoch: 54 [34816/50176]	Loss: 2.3685
Training Epoch: 54 [35840/50176]	Loss: 2.3825
Training Epoch: 54 [36864/50176]	Loss: 2.3326
Training Epoch: 54 [37888/50176]	Loss: 2.3885
Training Epoch: 54 [38912/50176]	Loss: 2.3977
Training Epoch: 54 [39936/50176]	Loss: 2.3583
Training Epoch: 54 [40960/50176]	Loss: 2.2970
Training Epoch: 54 [41984/50176]	Loss: 2.3124
Training Epoch: 54 [43008/50176]	Loss: 2.3070
Training Epoch: 54 [44032/50176]	Loss: 2.2553
Training Epoch: 54 [45056/50176]	Loss: 2.3435
Training Epoch: 54 [46080/50176]	Loss: 2.2654
Training Epoch: 54 [47104/50176]	Loss: 2.3039
Training Epoch: 54 [48128/50176]	Loss: 2.2922
Training Epoch: 54 [49152/50176]	Loss: 2.3021
Training Epoch: 54 [50176/50176]	Loss: 2.3681
2022-12-06 02:22:46.997 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:22:47,007 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.71 energy=519.36
2022-12-05 21:22:47,007 [ZeusDataLoader(train)] Up to epoch 55: time=2760.95, energy=407238.74, cost=445202.48
2022-12-05 21:22:47,007 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:22:47,007 [ZeusDataLoader(train)] Expected next epoch: time=2809.29, energy=414527.00, cost=453076.79
2022-12-05 21:22:47,008 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0025, Accuracy: 0.3546
2022-12-05 21:22:47,159 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:22:47,160 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:22:47.163 [ZeusMonitor] Monitor started.
2022-12-06 02:22:47.163 [ZeusMonitor] Running indefinitely. 2022-12-06 02:22:47.163 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:22:47.163 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e56+gpu0.power.log
2022-12-05 21:23:31,260 [ZeusDataLoader(train)] train epoch 56 done: time=44.24 energy=6753.05
2022-12-05 21:23:31,264 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 2.3435
Training Epoch: 55 [2048/50176]	Loss: 2.3359
Training Epoch: 55 [3072/50176]	Loss: 2.2542
Training Epoch: 55 [4096/50176]	Loss: 2.2523
Training Epoch: 55 [5120/50176]	Loss: 2.3147
Training Epoch: 55 [6144/50176]	Loss: 2.2748
Training Epoch: 55 [7168/50176]	Loss: 2.3318
Training Epoch: 55 [8192/50176]	Loss: 2.4012
Training Epoch: 55 [9216/50176]	Loss: 2.2801
Training Epoch: 55 [10240/50176]	Loss: 2.3095
Training Epoch: 55 [11264/50176]	Loss: 2.2824
Training Epoch: 55 [12288/50176]	Loss: 2.2087
Training Epoch: 55 [13312/50176]	Loss: 2.2993
Training Epoch: 55 [14336/50176]	Loss: 2.2681
Training Epoch: 55 [15360/50176]	Loss: 2.2468
Training Epoch: 55 [16384/50176]	Loss: 2.2235
Training Epoch: 55 [17408/50176]	Loss: 2.2942
Training Epoch: 55 [18432/50176]	Loss: 2.3148
Training Epoch: 55 [19456/50176]	Loss: 2.3086
Training Epoch: 55 [20480/50176]	Loss: 2.3815
Training Epoch: 55 [21504/50176]	Loss: 2.2997
Training Epoch: 55 [22528/50176]	Loss: 2.2940
Training Epoch: 55 [23552/50176]	Loss: 2.2906
Training Epoch: 55 [24576/50176]	Loss: 2.3286
Training Epoch: 55 [25600/50176]	Loss: 2.2693
Training Epoch: 55 [26624/50176]	Loss: 2.2763
Training Epoch: 55 [27648/50176]	Loss: 2.3115
Training Epoch: 55 [28672/50176]	Loss: 2.3302
Training Epoch: 55 [29696/50176]	Loss: 2.2638
Training Epoch: 55 [30720/50176]	Loss: 2.3227
Training Epoch: 55 [31744/50176]	Loss: 2.3109
Training Epoch: 55 [32768/50176]	Loss: 2.3843
Training Epoch: 55 [33792/50176]	Loss: 2.3415
Training Epoch: 55 [34816/50176]	Loss: 2.3186
Training Epoch: 55 [35840/50176]	Loss: 2.2409
Training Epoch: 55 [36864/50176]	Loss: 2.3241
Training Epoch: 55 [37888/50176]	Loss: 2.4023
Training Epoch: 55 [38912/50176]	Loss: 2.2842
Training Epoch: 55 [39936/50176]	Loss: 2.3220
Training Epoch: 55 [40960/50176]	Loss: 2.2888
Training Epoch: 55 [41984/50176]	Loss: 2.3058
Training Epoch: 55 [43008/50176]	Loss: 2.3300
Training Epoch: 55 [44032/50176]	Loss: 2.2882
Training Epoch: 55 [45056/50176]	Loss: 2.3675
Training Epoch: 55 [46080/50176]	Loss: 2.2976
Training Epoch: 55 [47104/50176]	Loss: 2.3718
Training Epoch: 55 [48128/50176]	Loss: 2.3945
Training Epoch: 55 [49152/50176]	Loss: 2.2894
Training Epoch: 55 [50176/50176]	Loss: 2.2742
2022-12-06 02:23:34.971 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:23:34,981 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.71 energy=518.90
2022-12-05 21:23:34,982 [ZeusDataLoader(train)] Up to epoch 56: time=2808.90, energy=414510.69, cost=453034.29
2022-12-05 21:23:34,982 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:23:34,982 [ZeusDataLoader(train)] Expected next epoch: time=2857.25, energy=421798.95, cost=460908.60
2022-12-05 21:23:34,983 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0025, Accuracy: 0.3560
2022-12-05 21:23:35,181 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:23:35,181 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:23:35.183 [ZeusMonitor] Monitor started.
2022-12-06 02:23:35.183 [ZeusMonitor] Running indefinitely. 2022-12-06 02:23:35.183 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:23:35.183 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e57+gpu0.power.log
2022-12-05 21:24:19,226 [ZeusDataLoader(train)] train epoch 57 done: time=44.23 energy=6735.94
2022-12-05 21:24:19,229 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 2.2754
Training Epoch: 56 [2048/50176]	Loss: 2.3057
Training Epoch: 56 [3072/50176]	Loss: 2.2413
Training Epoch: 56 [4096/50176]	Loss: 2.1996
Training Epoch: 56 [5120/50176]	Loss: 2.4000
Training Epoch: 56 [6144/50176]	Loss: 2.2608
Training Epoch: 56 [7168/50176]	Loss: 2.2897
Training Epoch: 56 [8192/50176]	Loss: 2.2788
Training Epoch: 56 [9216/50176]	Loss: 2.3158
Training Epoch: 56 [10240/50176]	Loss: 2.2469
Training Epoch: 56 [11264/50176]	Loss: 2.2187
Training Epoch: 56 [12288/50176]	Loss: 2.2188
Training Epoch: 56 [13312/50176]	Loss: 2.2812
Training Epoch: 56 [14336/50176]	Loss: 2.3309
Training Epoch: 56 [15360/50176]	Loss: 2.2653
Training Epoch: 56 [16384/50176]	Loss: 2.3300
Training Epoch: 56 [17408/50176]	Loss: 2.2733
Training Epoch: 56 [18432/50176]	Loss: 2.2929
Training Epoch: 56 [19456/50176]	Loss: 2.2759
Training Epoch: 56 [20480/50176]	Loss: 2.3007
Training Epoch: 56 [21504/50176]	Loss: 2.3149
Training Epoch: 56 [22528/50176]	Loss: 2.3062
Training Epoch: 56 [23552/50176]	Loss: 2.2880
Training Epoch: 56 [24576/50176]	Loss: 2.2735
Training Epoch: 56 [25600/50176]	Loss: 2.1660
Training Epoch: 56 [26624/50176]	Loss: 2.3413
Training Epoch: 56 [27648/50176]	Loss: 2.2273
Training Epoch: 56 [28672/50176]	Loss: 2.2524
Training Epoch: 56 [29696/50176]	Loss: 2.2058
Training Epoch: 56 [30720/50176]	Loss: 2.2785
Training Epoch: 56 [31744/50176]	Loss: 2.3080
Training Epoch: 56 [32768/50176]	Loss: 2.3204
Training Epoch: 56 [33792/50176]	Loss: 2.2763
Training Epoch: 56 [34816/50176]	Loss: 2.2452
Training Epoch: 56 [35840/50176]	Loss: 2.3533
Training Epoch: 56 [36864/50176]	Loss: 2.2128
Training Epoch: 56 [37888/50176]	Loss: 2.3208
Training Epoch: 56 [38912/50176]	Loss: 2.3704
Training Epoch: 56 [39936/50176]	Loss: 2.2366
Training Epoch: 56 [40960/50176]	Loss: 2.2417
Training Epoch: 56 [41984/50176]	Loss: 2.2941
Training Epoch: 56 [43008/50176]	Loss: 2.2931
Training Epoch: 56 [44032/50176]	Loss: 2.3234
Training Epoch: 56 [45056/50176]	Loss: 2.3794
Training Epoch: 56 [46080/50176]	Loss: 2.2361
Training Epoch: 56 [47104/50176]	Loss: 2.3399
Training Epoch: 56 [48128/50176]	Loss: 2.3596
Training Epoch: 56 [49152/50176]	Loss: 2.3719
Training Epoch: 56 [50176/50176]	Loss: 2.2484
2022-12-06 02:24:22.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:24:22,976 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.74 energy=519.27
2022-12-05 21:24:22,977 [ZeusDataLoader(train)] Up to epoch 57: time=2856.88, energy=421765.90, cost=460859.60
2022-12-05 21:24:22,977 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:24:22,977 [ZeusDataLoader(train)] Expected next epoch: time=2905.22, energy=429054.17, cost=468733.91
2022-12-05 21:24:22,978 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0024, Accuracy: 0.3591
2022-12-05 21:24:23,158 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:24:23,159 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:24:23.174 [ZeusMonitor] Monitor started.
2022-12-06 02:24:23.174 [ZeusMonitor] Running indefinitely. 2022-12-06 02:24:23.174 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:24:23.174 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e58+gpu0.power.log
2022-12-05 21:25:07,320 [ZeusDataLoader(train)] train epoch 58 done: time=44.33 energy=6760.64
2022-12-05 21:25:07,323 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 2.3789
Training Epoch: 57 [2048/50176]	Loss: 2.2663
Training Epoch: 57 [3072/50176]	Loss: 2.2725
Training Epoch: 57 [4096/50176]	Loss: 2.2772
Training Epoch: 57 [5120/50176]	Loss: 2.3470
Training Epoch: 57 [6144/50176]	Loss: 2.3488
Training Epoch: 57 [7168/50176]	Loss: 2.2096
Training Epoch: 57 [8192/50176]	Loss: 2.3165
Training Epoch: 57 [9216/50176]	Loss: 2.2399
Training Epoch: 57 [10240/50176]	Loss: 2.2487
Training Epoch: 57 [11264/50176]	Loss: 2.2595
Training Epoch: 57 [12288/50176]	Loss: 2.2537
Training Epoch: 57 [13312/50176]	Loss: 2.1377
Training Epoch: 57 [14336/50176]	Loss: 2.2588
Training Epoch: 57 [15360/50176]	Loss: 2.1870
Training Epoch: 57 [16384/50176]	Loss: 2.2703
Training Epoch: 57 [17408/50176]	Loss: 2.2509
Training Epoch: 57 [18432/50176]	Loss: 2.3204
Training Epoch: 57 [19456/50176]	Loss: 2.2251
Training Epoch: 57 [20480/50176]	Loss: 2.2419
Training Epoch: 57 [21504/50176]	Loss: 2.2744
Training Epoch: 57 [22528/50176]	Loss: 2.1891
Training Epoch: 57 [23552/50176]	Loss: 2.2828
Training Epoch: 57 [24576/50176]	Loss: 2.1872
Training Epoch: 57 [25600/50176]	Loss: 2.2626
Training Epoch: 57 [26624/50176]	Loss: 2.2149
Training Epoch: 57 [27648/50176]	Loss: 2.2557
Training Epoch: 57 [28672/50176]	Loss: 2.2833
Training Epoch: 57 [29696/50176]	Loss: 2.3406
Training Epoch: 57 [30720/50176]	Loss: 2.1659
Training Epoch: 57 [31744/50176]	Loss: 2.2690
Training Epoch: 57 [32768/50176]	Loss: 2.2479
Training Epoch: 57 [33792/50176]	Loss: 2.3798
Training Epoch: 57 [34816/50176]	Loss: 2.2862
Training Epoch: 57 [35840/50176]	Loss: 2.2784
Training Epoch: 57 [36864/50176]	Loss: 2.2901
Training Epoch: 57 [37888/50176]	Loss: 2.2247
Training Epoch: 57 [38912/50176]	Loss: 2.2598
Training Epoch: 57 [39936/50176]	Loss: 2.2413
Training Epoch: 57 [40960/50176]	Loss: 2.3284
Training Epoch: 57 [41984/50176]	Loss: 2.3125
Training Epoch: 57 [43008/50176]	Loss: 2.2101
Training Epoch: 57 [44032/50176]	Loss: 2.2220
Training Epoch: 57 [45056/50176]	Loss: 2.3315
Training Epoch: 57 [46080/50176]	Loss: 2.2704
Training Epoch: 57 [47104/50176]	Loss: 2.2901
Training Epoch: 57 [48128/50176]	Loss: 2.2608
Training Epoch: 57 [49152/50176]	Loss: 2.3262
Training Epoch: 57 [50176/50176]	Loss: 2.2445
2022-12-06 02:25:11.019 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:25:11,027 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.70 energy=518.14
2022-12-05 21:25:11,028 [ZeusDataLoader(train)] Up to epoch 58: time=2904.91, energy=429044.68, cost=468701.63
2022-12-05 21:25:11,028 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:25:11,028 [ZeusDataLoader(train)] Expected next epoch: time=2953.25, energy=436332.95, cost=476575.94
2022-12-05 21:25:11,029 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0024, Accuracy: 0.3645
2022-12-05 21:25:11,216 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:25:11,217 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:25:11.219 [ZeusMonitor] Monitor started.
2022-12-06 02:25:11.219 [ZeusMonitor] Running indefinitely. 2022-12-06 02:25:11.219 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:25:11.219 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e59+gpu0.power.log
2022-12-05 21:25:55,421 [ZeusDataLoader(train)] train epoch 59 done: time=44.38 energy=6768.99
2022-12-05 21:25:55,425 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 2.2240
Training Epoch: 58 [2048/50176]	Loss: 2.2489
Training Epoch: 58 [3072/50176]	Loss: 2.2407
Training Epoch: 58 [4096/50176]	Loss: 2.2038
Training Epoch: 58 [5120/50176]	Loss: 2.1349
Training Epoch: 58 [6144/50176]	Loss: 2.2445
Training Epoch: 58 [7168/50176]	Loss: 2.2053
Training Epoch: 58 [8192/50176]	Loss: 2.2996
Training Epoch: 58 [9216/50176]	Loss: 2.3414
Training Epoch: 58 [10240/50176]	Loss: 2.2107
Training Epoch: 58 [11264/50176]	Loss: 2.2354
Training Epoch: 58 [12288/50176]	Loss: 2.3085
Training Epoch: 58 [13312/50176]	Loss: 2.2250
Training Epoch: 58 [14336/50176]	Loss: 2.1735
Training Epoch: 58 [15360/50176]	Loss: 2.1917
Training Epoch: 58 [16384/50176]	Loss: 2.2355
Training Epoch: 58 [17408/50176]	Loss: 2.3091
Training Epoch: 58 [18432/50176]	Loss: 2.2958
Training Epoch: 58 [19456/50176]	Loss: 2.2019
Training Epoch: 58 [20480/50176]	Loss: 2.1337
Training Epoch: 58 [21504/50176]	Loss: 2.2111
Training Epoch: 58 [22528/50176]	Loss: 2.2505
Training Epoch: 58 [23552/50176]	Loss: 2.2850
Training Epoch: 58 [24576/50176]	Loss: 2.2022
Training Epoch: 58 [25600/50176]	Loss: 2.3077
Training Epoch: 58 [26624/50176]	Loss: 2.2775
Training Epoch: 58 [27648/50176]	Loss: 2.2988
Training Epoch: 58 [28672/50176]	Loss: 2.2564
Training Epoch: 58 [29696/50176]	Loss: 2.2119
Training Epoch: 58 [30720/50176]	Loss: 2.1446
Training Epoch: 58 [31744/50176]	Loss: 2.3337
Training Epoch: 58 [32768/50176]	Loss: 2.2570
Training Epoch: 58 [33792/50176]	Loss: 2.2671
Training Epoch: 58 [34816/50176]	Loss: 2.2337
Training Epoch: 58 [35840/50176]	Loss: 2.2529
Training Epoch: 58 [36864/50176]	Loss: 2.2087
Training Epoch: 58 [37888/50176]	Loss: 2.2499
Training Epoch: 58 [38912/50176]	Loss: 2.2726
Training Epoch: 58 [39936/50176]	Loss: 2.2032
Training Epoch: 58 [40960/50176]	Loss: 2.2620
Training Epoch: 58 [41984/50176]	Loss: 2.2266
Training Epoch: 58 [43008/50176]	Loss: 2.2975
Training Epoch: 58 [44032/50176]	Loss: 2.2467
Training Epoch: 58 [45056/50176]	Loss: 2.3097
Training Epoch: 58 [46080/50176]	Loss: 2.2968
Training Epoch: 58 [47104/50176]	Loss: 2.2848
Training Epoch: 58 [48128/50176]	Loss: 2.2429
Training Epoch: 58 [49152/50176]	Loss: 2.2974
Training Epoch: 58 [50176/50176]	Loss: 2.1593
2022-12-06 02:25:59.188 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:25:59,238 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.80 energy=533.32
2022-12-05 21:25:59,238 [ZeusDataLoader(train)] Up to epoch 59: time=2953.09, energy=436347.00, cost=476569.20
2022-12-05 21:25:59,238 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:25:59,238 [ZeusDataLoader(train)] Expected next epoch: time=3001.44, energy=443635.26, cost=484443.52
2022-12-05 21:25:59,239 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0024, Accuracy: 0.3629
2022-12-05 21:25:59,414 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:25:59,415 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:25:59.429 [ZeusMonitor] Monitor started.
2022-12-06 02:25:59.429 [ZeusMonitor] Running indefinitely. 2022-12-06 02:25:59.429 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:25:59.429 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e60+gpu0.power.log
2022-12-05 21:26:43,589 [ZeusDataLoader(train)] train epoch 60 done: time=44.34 energy=6758.75
2022-12-05 21:26:43,593 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 2.2279
Training Epoch: 59 [2048/50176]	Loss: 2.2710
Training Epoch: 59 [3072/50176]	Loss: 2.2043
Training Epoch: 59 [4096/50176]	Loss: 2.2736
Training Epoch: 59 [5120/50176]	Loss: 2.1507
Training Epoch: 59 [6144/50176]	Loss: 2.3473
Training Epoch: 59 [7168/50176]	Loss: 2.1945
Training Epoch: 59 [8192/50176]	Loss: 2.2950
Training Epoch: 59 [9216/50176]	Loss: 2.2087
Training Epoch: 59 [10240/50176]	Loss: 2.1866
Training Epoch: 59 [11264/50176]	Loss: 2.2167
Training Epoch: 59 [12288/50176]	Loss: 2.2666
Training Epoch: 59 [13312/50176]	Loss: 2.2327
Training Epoch: 59 [14336/50176]	Loss: 2.2067
Training Epoch: 59 [15360/50176]	Loss: 2.2062
Training Epoch: 59 [16384/50176]	Loss: 2.1359
Training Epoch: 59 [17408/50176]	Loss: 2.3084
Training Epoch: 59 [18432/50176]	Loss: 2.2439
Training Epoch: 59 [19456/50176]	Loss: 2.2195
Training Epoch: 59 [20480/50176]	Loss: 2.2422
Training Epoch: 59 [21504/50176]	Loss: 2.2546
Training Epoch: 59 [22528/50176]	Loss: 2.2164
Training Epoch: 59 [23552/50176]	Loss: 2.2860
Training Epoch: 59 [24576/50176]	Loss: 2.2184
Training Epoch: 59 [25600/50176]	Loss: 2.1955
Training Epoch: 59 [26624/50176]	Loss: 2.1943
Training Epoch: 59 [27648/50176]	Loss: 2.2196
Training Epoch: 59 [28672/50176]	Loss: 2.1972
Training Epoch: 59 [29696/50176]	Loss: 2.2183
Training Epoch: 59 [30720/50176]	Loss: 2.2354
Training Epoch: 59 [31744/50176]	Loss: 2.2017
Training Epoch: 59 [32768/50176]	Loss: 2.0775
Training Epoch: 59 [33792/50176]	Loss: 2.1126
Training Epoch: 59 [34816/50176]	Loss: 2.2262
Training Epoch: 59 [35840/50176]	Loss: 2.1768
Training Epoch: 59 [36864/50176]	Loss: 2.3870
Training Epoch: 59 [37888/50176]	Loss: 2.2690
Training Epoch: 59 [38912/50176]	Loss: 2.2114
Training Epoch: 59 [39936/50176]	Loss: 2.3197
Training Epoch: 59 [40960/50176]	Loss: 2.2758
Training Epoch: 59 [41984/50176]	Loss: 2.2617
Training Epoch: 59 [43008/50176]	Loss: 2.2775
Training Epoch: 59 [44032/50176]	Loss: 2.2432
Training Epoch: 59 [45056/50176]	Loss: 2.2019
Training Epoch: 59 [46080/50176]	Loss: 2.2399
Training Epoch: 59 [47104/50176]	Loss: 2.2701
Training Epoch: 59 [48128/50176]	Loss: 2.2369
Training Epoch: 59 [49152/50176]	Loss: 2.2224
Training Epoch: 59 [50176/50176]	Loss: 2.2021
2022-12-06 02:26:47.336 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:26:47,353 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.75 energy=519.98
2022-12-05 21:26:47,353 [ZeusDataLoader(train)] Up to epoch 60: time=3001.19, energy=443625.73, cost=484416.68
2022-12-05 21:26:47,353 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:26:47,353 [ZeusDataLoader(train)] Expected next epoch: time=3049.53, energy=450914.00, cost=492290.99
2022-12-05 21:26:47,354 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0024, Accuracy: 0.3656
2022-12-05 21:26:47,533 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:26:47,534 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:26:47.550 [ZeusMonitor] Monitor started.
2022-12-06 02:26:47.550 [ZeusMonitor] Running indefinitely. 2022-12-06 02:26:47.550 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:26:47.550 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e61+gpu0.power.log
2022-12-05 21:27:31,691 [ZeusDataLoader(train)] train epoch 61 done: time=44.33 energy=6761.51
2022-12-05 21:27:31,694 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 2.1522
Training Epoch: 60 [2048/50176]	Loss: 2.2084
Training Epoch: 60 [3072/50176]	Loss: 2.2472
Training Epoch: 60 [4096/50176]	Loss: 2.1343
Training Epoch: 60 [5120/50176]	Loss: 2.2597
Training Epoch: 60 [6144/50176]	Loss: 2.1772
Training Epoch: 60 [7168/50176]	Loss: 2.1305
Training Epoch: 60 [8192/50176]	Loss: 2.2333
Training Epoch: 60 [9216/50176]	Loss: 2.2285
Training Epoch: 60 [10240/50176]	Loss: 2.2402
Training Epoch: 60 [11264/50176]	Loss: 2.2407
Training Epoch: 60 [12288/50176]	Loss: 2.2836
Training Epoch: 60 [13312/50176]	Loss: 2.1688
Training Epoch: 60 [14336/50176]	Loss: 2.2293
Training Epoch: 60 [15360/50176]	Loss: 2.2111
Training Epoch: 60 [16384/50176]	Loss: 2.2110
Training Epoch: 60 [17408/50176]	Loss: 2.1729
Training Epoch: 60 [18432/50176]	Loss: 2.2369
Training Epoch: 60 [19456/50176]	Loss: 2.1822
Training Epoch: 60 [20480/50176]	Loss: 2.1947
Training Epoch: 60 [21504/50176]	Loss: 2.1942
Training Epoch: 60 [22528/50176]	Loss: 2.2571
Training Epoch: 60 [23552/50176]	Loss: 2.1836
Training Epoch: 60 [24576/50176]	Loss: 2.2217
Training Epoch: 60 [25600/50176]	Loss: 2.2257
Training Epoch: 60 [26624/50176]	Loss: 2.1595
Training Epoch: 60 [27648/50176]	Loss: 2.1690
Training Epoch: 60 [28672/50176]	Loss: 2.1278
Training Epoch: 60 [29696/50176]	Loss: 2.1364
Training Epoch: 60 [30720/50176]	Loss: 2.2066
Training Epoch: 60 [31744/50176]	Loss: 2.2737
Training Epoch: 60 [32768/50176]	Loss: 2.2318
Training Epoch: 60 [33792/50176]	Loss: 2.2249
Training Epoch: 60 [34816/50176]	Loss: 2.2337
Training Epoch: 60 [35840/50176]	Loss: 2.1967
Training Epoch: 60 [36864/50176]	Loss: 2.2217
Training Epoch: 60 [37888/50176]	Loss: 2.2378
Training Epoch: 60 [38912/50176]	Loss: 2.2308
Training Epoch: 60 [39936/50176]	Loss: 2.2104
Training Epoch: 60 [40960/50176]	Loss: 2.2138
Training Epoch: 60 [41984/50176]	Loss: 2.1970
Training Epoch: 60 [43008/50176]	Loss: 2.2360
Training Epoch: 60 [44032/50176]	Loss: 2.1906
Training Epoch: 60 [45056/50176]	Loss: 2.1228
Training Epoch: 60 [46080/50176]	Loss: 2.1980
Training Epoch: 60 [47104/50176]	Loss: 2.2412
Training Epoch: 60 [48128/50176]	Loss: 2.2509
Training Epoch: 60 [49152/50176]	Loss: 2.1769
Training Epoch: 60 [50176/50176]	Loss: 2.2883
2022-12-06 02:27:35.372 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:27:35,388 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.69 energy=507.29
2022-12-05 21:27:35,388 [ZeusDataLoader(train)] Up to epoch 61: time=3049.20, energy=450894.53, cost=492252.25
2022-12-05 21:27:35,388 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:27:35,388 [ZeusDataLoader(train)] Expected next epoch: time=3097.54, energy=458182.79, cost=500126.56
2022-12-05 21:27:35,389 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0024, Accuracy: 0.3646
2022-12-05 21:27:35,581 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:27:35,582 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:27:35.584 [ZeusMonitor] Monitor started.
2022-12-06 02:27:35.584 [ZeusMonitor] Running indefinitely. 2022-12-06 02:27:35.584 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:27:35.584 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e62+gpu0.power.log
2022-12-05 21:28:19,722 [ZeusDataLoader(train)] train epoch 62 done: time=44.32 energy=6761.91
2022-12-05 21:28:19,726 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 2.2131
Training Epoch: 61 [2048/50176]	Loss: 2.1913
Training Epoch: 61 [3072/50176]	Loss: 2.0829
Training Epoch: 61 [4096/50176]	Loss: 2.2769
Training Epoch: 61 [5120/50176]	Loss: 2.2726
Training Epoch: 61 [6144/50176]	Loss: 2.2423
Training Epoch: 61 [7168/50176]	Loss: 2.2093
Training Epoch: 61 [8192/50176]	Loss: 2.1122
Training Epoch: 61 [9216/50176]	Loss: 2.1851
Training Epoch: 61 [10240/50176]	Loss: 2.0668
Training Epoch: 61 [11264/50176]	Loss: 2.1666
Training Epoch: 61 [12288/50176]	Loss: 2.1504
Training Epoch: 61 [13312/50176]	Loss: 2.2538
Training Epoch: 61 [14336/50176]	Loss: 2.2650
Training Epoch: 61 [15360/50176]	Loss: 2.1104
Training Epoch: 61 [16384/50176]	Loss: 2.1570
Training Epoch: 61 [17408/50176]	Loss: 2.1655
Training Epoch: 61 [18432/50176]	Loss: 2.1751
Training Epoch: 61 [19456/50176]	Loss: 2.1380
Training Epoch: 61 [20480/50176]	Loss: 2.1629
Training Epoch: 61 [21504/50176]	Loss: 2.3082
Training Epoch: 61 [22528/50176]	Loss: 2.2179
Training Epoch: 61 [23552/50176]	Loss: 2.0308
Training Epoch: 61 [24576/50176]	Loss: 2.1794
Training Epoch: 61 [25600/50176]	Loss: 2.1645
Training Epoch: 61 [26624/50176]	Loss: 2.2647
Training Epoch: 61 [27648/50176]	Loss: 2.2308
Training Epoch: 61 [28672/50176]	Loss: 2.2226
Training Epoch: 61 [29696/50176]	Loss: 2.1488
Training Epoch: 61 [30720/50176]	Loss: 2.1617
Training Epoch: 61 [31744/50176]	Loss: 2.1347
Training Epoch: 61 [32768/50176]	Loss: 2.1834
Training Epoch: 61 [33792/50176]	Loss: 2.2639
Training Epoch: 61 [34816/50176]	Loss: 2.1408
Training Epoch: 61 [35840/50176]	Loss: 2.1861
Training Epoch: 61 [36864/50176]	Loss: 2.1619
Training Epoch: 61 [37888/50176]	Loss: 2.1835
Training Epoch: 61 [38912/50176]	Loss: 2.1394
Training Epoch: 61 [39936/50176]	Loss: 2.1803
Training Epoch: 61 [40960/50176]	Loss: 2.2652
Training Epoch: 61 [41984/50176]	Loss: 2.2071
Training Epoch: 61 [43008/50176]	Loss: 2.1934
Training Epoch: 61 [44032/50176]	Loss: 2.2586
Training Epoch: 61 [45056/50176]	Loss: 2.2543
Training Epoch: 61 [46080/50176]	Loss: 2.2671
Training Epoch: 61 [47104/50176]	Loss: 2.2329
Training Epoch: 61 [48128/50176]	Loss: 2.1973
Training Epoch: 61 [49152/50176]	Loss: 2.2268
Training Epoch: 61 [50176/50176]	Loss: 2.2638
2022-12-06 02:28:23.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:28:23,458 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.72 energy=518.33
2022-12-05 21:28:23,458 [ZeusDataLoader(train)] Up to epoch 62: time=3097.25, energy=458174.78, cost=500096.60
2022-12-05 21:28:23,458 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:28:23,458 [ZeusDataLoader(train)] Expected next epoch: time=3145.59, energy=465463.04, cost=507970.91
2022-12-05 21:28:23,459 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0024, Accuracy: 0.3703
2022-12-05 21:28:23,648 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:28:23,649 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:28:23.651 [ZeusMonitor] Monitor started.
2022-12-06 02:28:23.651 [ZeusMonitor] Running indefinitely. 2022-12-06 02:28:23.651 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:28:23.651 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e63+gpu0.power.log
2022-12-05 21:29:07,711 [ZeusDataLoader(train)] train epoch 63 done: time=44.24 energy=6739.36
2022-12-05 21:29:07,714 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 2.2065
Training Epoch: 62 [2048/50176]	Loss: 2.1073
Training Epoch: 62 [3072/50176]	Loss: 2.1261
Training Epoch: 62 [4096/50176]	Loss: 2.1949
Training Epoch: 62 [5120/50176]	Loss: 2.1904
Training Epoch: 62 [6144/50176]	Loss: 2.1127
Training Epoch: 62 [7168/50176]	Loss: 2.1474
Training Epoch: 62 [8192/50176]	Loss: 2.2538
Training Epoch: 62 [9216/50176]	Loss: 2.1314
Training Epoch: 62 [10240/50176]	Loss: 2.1114
Training Epoch: 62 [11264/50176]	Loss: 2.1673
Training Epoch: 62 [12288/50176]	Loss: 2.1909
Training Epoch: 62 [13312/50176]	Loss: 2.1213
Training Epoch: 62 [14336/50176]	Loss: 2.1632
Training Epoch: 62 [15360/50176]	Loss: 2.2064
Training Epoch: 62 [16384/50176]	Loss: 2.1814
Training Epoch: 62 [17408/50176]	Loss: 2.1790
Training Epoch: 62 [18432/50176]	Loss: 2.1262
Training Epoch: 62 [19456/50176]	Loss: 2.1573
Training Epoch: 62 [20480/50176]	Loss: 2.2287
Training Epoch: 62 [21504/50176]	Loss: 2.1634
Training Epoch: 62 [22528/50176]	Loss: 2.2439
Training Epoch: 62 [23552/50176]	Loss: 2.0535
Training Epoch: 62 [24576/50176]	Loss: 2.2446
Training Epoch: 62 [25600/50176]	Loss: 2.1467
Training Epoch: 62 [26624/50176]	Loss: 2.1777
Training Epoch: 62 [27648/50176]	Loss: 2.1221
Training Epoch: 62 [28672/50176]	Loss: 2.1749
Training Epoch: 62 [29696/50176]	Loss: 2.1127
Training Epoch: 62 [30720/50176]	Loss: 2.2169
Training Epoch: 62 [31744/50176]	Loss: 2.2650
Training Epoch: 62 [32768/50176]	Loss: 2.2392
Training Epoch: 62 [33792/50176]	Loss: 2.1532
Training Epoch: 62 [34816/50176]	Loss: 2.1702
Training Epoch: 62 [35840/50176]	Loss: 2.1596
Training Epoch: 62 [36864/50176]	Loss: 2.2102
Training Epoch: 62 [37888/50176]	Loss: 2.0986
Training Epoch: 62 [38912/50176]	Loss: 2.1203
Training Epoch: 62 [39936/50176]	Loss: 2.1818
Training Epoch: 62 [40960/50176]	Loss: 2.2133
Training Epoch: 62 [41984/50176]	Loss: 2.1889
Training Epoch: 62 [43008/50176]	Loss: 2.2047
Training Epoch: 62 [44032/50176]	Loss: 2.1206
Training Epoch: 62 [45056/50176]	Loss: 2.1331
Training Epoch: 62 [46080/50176]	Loss: 2.1628
Training Epoch: 62 [47104/50176]	Loss: 2.2212
Training Epoch: 62 [48128/50176]	Loss: 2.2502
Training Epoch: 62 [49152/50176]	Loss: 2.2993
Training Epoch: 62 [50176/50176]	Loss: 2.1294
2022-12-06 02:29:11.408 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:29:11,427 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.70 energy=519.39
2022-12-05 21:29:11,427 [ZeusDataLoader(train)] Up to epoch 63: time=3145.20, energy=465433.53, cost=507921.42
2022-12-05 21:29:11,428 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:29:11,428 [ZeusDataLoader(train)] Expected next epoch: time=3193.54, energy=472721.79, cost=515795.73
2022-12-05 21:29:11,429 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0024, Accuracy: 0.3722
2022-12-05 21:29:11,642 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:29:11,643 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:29:11.645 [ZeusMonitor] Monitor started.
2022-12-06 02:29:11.645 [ZeusMonitor] Running indefinitely. 2022-12-06 02:29:11.645 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:29:11.645 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e64+gpu0.power.log
2022-12-05 21:29:55,775 [ZeusDataLoader(train)] train epoch 64 done: time=44.34 energy=6755.19
2022-12-05 21:29:55,779 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 2.2095
Training Epoch: 63 [2048/50176]	Loss: 2.1950
Training Epoch: 63 [3072/50176]	Loss: 2.1692
Training Epoch: 63 [4096/50176]	Loss: 2.1884
Training Epoch: 63 [5120/50176]	Loss: 2.2088
Training Epoch: 63 [6144/50176]	Loss: 2.1670
Training Epoch: 63 [7168/50176]	Loss: 2.2044
Training Epoch: 63 [8192/50176]	Loss: 2.2233
Training Epoch: 63 [9216/50176]	Loss: 2.0997
Training Epoch: 63 [10240/50176]	Loss: 2.1199
Training Epoch: 63 [11264/50176]	Loss: 2.1732
Training Epoch: 63 [12288/50176]	Loss: 2.1252
Training Epoch: 63 [13312/50176]	Loss: 2.0864
Training Epoch: 63 [14336/50176]	Loss: 2.1803
Training Epoch: 63 [15360/50176]	Loss: 2.2018
Training Epoch: 63 [16384/50176]	Loss: 2.2113
Training Epoch: 63 [17408/50176]	Loss: 2.1997
Training Epoch: 63 [18432/50176]	Loss: 2.1642
Training Epoch: 63 [19456/50176]	Loss: 2.1355
Training Epoch: 63 [20480/50176]	Loss: 2.1986
Training Epoch: 63 [21504/50176]	Loss: 2.2400
Training Epoch: 63 [22528/50176]	Loss: 2.1458
Training Epoch: 63 [23552/50176]	Loss: 2.1447
Training Epoch: 63 [24576/50176]	Loss: 2.0625
Training Epoch: 63 [25600/50176]	Loss: 2.1614
Training Epoch: 63 [26624/50176]	Loss: 2.1313
Training Epoch: 63 [27648/50176]	Loss: 2.1016
Training Epoch: 63 [28672/50176]	Loss: 2.1788
Training Epoch: 63 [29696/50176]	Loss: 2.1351
Training Epoch: 63 [30720/50176]	Loss: 2.2177
Training Epoch: 63 [31744/50176]	Loss: 2.1824
Training Epoch: 63 [32768/50176]	Loss: 2.2543
Training Epoch: 63 [33792/50176]	Loss: 2.1596
Training Epoch: 63 [34816/50176]	Loss: 2.1304
Training Epoch: 63 [35840/50176]	Loss: 2.1070
Training Epoch: 63 [36864/50176]	Loss: 2.1882
Training Epoch: 63 [37888/50176]	Loss: 2.1347
Training Epoch: 63 [38912/50176]	Loss: 2.2176
Training Epoch: 63 [39936/50176]	Loss: 2.1310
Training Epoch: 63 [40960/50176]	Loss: 2.1354
Training Epoch: 63 [41984/50176]	Loss: 2.1073
Training Epoch: 63 [43008/50176]	Loss: 2.1474
Training Epoch: 63 [44032/50176]	Loss: 2.1831
Training Epoch: 63 [45056/50176]	Loss: 2.1280
Training Epoch: 63 [46080/50176]	Loss: 2.1737
Training Epoch: 63 [47104/50176]	Loss: 2.1950
Training Epoch: 63 [48128/50176]	Loss: 2.0991
Training Epoch: 63 [49152/50176]	Loss: 2.1401
Training Epoch: 63 [50176/50176]	Loss: 2.1624
2022-12-06 02:29:59.499 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:29:59,540 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.75 energy=526.23
2022-12-05 21:29:59,541 [ZeusDataLoader(train)] Up to epoch 64: time=3193.29, energy=472714.95, cost=515770.14
2022-12-05 21:29:59,541 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:29:59,541 [ZeusDataLoader(train)] Expected next epoch: time=3241.63, energy=480003.21, cost=523644.45
2022-12-05 21:29:59,542 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0024, Accuracy: 0.3771
2022-12-05 21:29:59,729 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:29:59,730 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:29:59.731 [ZeusMonitor] Monitor started.
2022-12-06 02:29:59.732 [ZeusMonitor] Running indefinitely. 2022-12-06 02:29:59.732 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:29:59.732 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e65+gpu0.power.log
2022-12-05 21:30:43,945 [ZeusDataLoader(train)] train epoch 65 done: time=44.40 energy=6760.99
2022-12-05 21:30:43,949 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 2.1554
Training Epoch: 64 [2048/50176]	Loss: 2.1381
Training Epoch: 64 [3072/50176]	Loss: 2.1605
Training Epoch: 64 [4096/50176]	Loss: 2.1268
Training Epoch: 64 [5120/50176]	Loss: 2.1187
Training Epoch: 64 [6144/50176]	Loss: 2.1629
Training Epoch: 64 [7168/50176]	Loss: 2.1371
Training Epoch: 64 [8192/50176]	Loss: 2.0572
Training Epoch: 64 [9216/50176]	Loss: 2.1975
Training Epoch: 64 [10240/50176]	Loss: 2.1463
Training Epoch: 64 [11264/50176]	Loss: 2.1037
Training Epoch: 64 [12288/50176]	Loss: 2.1332
Training Epoch: 64 [13312/50176]	Loss: 2.2544
Training Epoch: 64 [14336/50176]	Loss: 2.1859
Training Epoch: 64 [15360/50176]	Loss: 2.1722
Training Epoch: 64 [16384/50176]	Loss: 2.1062
Training Epoch: 64 [17408/50176]	Loss: 2.0430
Training Epoch: 64 [18432/50176]	Loss: 2.0433
Training Epoch: 64 [19456/50176]	Loss: 2.1509
Training Epoch: 64 [20480/50176]	Loss: 2.1743
Training Epoch: 64 [21504/50176]	Loss: 2.1427
Training Epoch: 64 [22528/50176]	Loss: 2.0831
Training Epoch: 64 [23552/50176]	Loss: 2.1806
Training Epoch: 64 [24576/50176]	Loss: 2.1111
Training Epoch: 64 [25600/50176]	Loss: 2.1280
Training Epoch: 64 [26624/50176]	Loss: 2.0985
Training Epoch: 64 [27648/50176]	Loss: 2.0989
Training Epoch: 64 [28672/50176]	Loss: 2.1360
Training Epoch: 64 [29696/50176]	Loss: 2.1429
Training Epoch: 64 [30720/50176]	Loss: 2.1397
Training Epoch: 64 [31744/50176]	Loss: 2.0969
Training Epoch: 64 [32768/50176]	Loss: 2.1945
Training Epoch: 64 [33792/50176]	Loss: 2.1868
Training Epoch: 64 [34816/50176]	Loss: 2.1148
Training Epoch: 64 [35840/50176]	Loss: 2.0645
Training Epoch: 64 [36864/50176]	Loss: 2.2211
Training Epoch: 64 [37888/50176]	Loss: 2.2090
Training Epoch: 64 [38912/50176]	Loss: 2.1175
Training Epoch: 64 [39936/50176]	Loss: 2.0975
Training Epoch: 64 [40960/50176]	Loss: 2.0751
Training Epoch: 64 [41984/50176]	Loss: 2.1912
Training Epoch: 64 [43008/50176]	Loss: 2.1322
Training Epoch: 64 [44032/50176]	Loss: 2.1164
Training Epoch: 64 [45056/50176]	Loss: 2.2315
Training Epoch: 64 [46080/50176]	Loss: 2.1217
Training Epoch: 64 [47104/50176]	Loss: 2.1159
Training Epoch: 64 [48128/50176]	Loss: 2.1147
Training Epoch: 64 [49152/50176]	Loss: 2.2080
Training Epoch: 64 [50176/50176]	Loss: 2.1680
2022-12-06 02:30:47.668 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:30:47,678 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.72 energy=518.13
2022-12-05 21:30:47,678 [ZeusDataLoader(train)] Up to epoch 65: time=3241.40, energy=479994.07, cost=523619.85
2022-12-05 21:30:47,678 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:30:47,678 [ZeusDataLoader(train)] Expected next epoch: time=3289.75, energy=487282.34, cost=531494.16
2022-12-05 21:30:47,679 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0024, Accuracy: 0.3745
2022-12-05 21:30:47,823 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:30:47,824 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:30:47.828 [ZeusMonitor] Monitor started.
2022-12-06 02:30:47.828 [ZeusMonitor] Running indefinitely. 2022-12-06 02:30:47.828 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:30:47.828 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e66+gpu0.power.log
2022-12-05 21:31:32,014 [ZeusDataLoader(train)] train epoch 66 done: time=44.33 energy=6771.80
2022-12-05 21:31:32,018 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 2.1447
Training Epoch: 65 [2048/50176]	Loss: 2.0246
Training Epoch: 65 [3072/50176]	Loss: 2.1738
Training Epoch: 65 [4096/50176]	Loss: 2.0506
Training Epoch: 65 [5120/50176]	Loss: 2.1184
Training Epoch: 65 [6144/50176]	Loss: 2.1589
Training Epoch: 65 [7168/50176]	Loss: 1.9943
Training Epoch: 65 [8192/50176]	Loss: 2.0427
Training Epoch: 65 [9216/50176]	Loss: 2.2091
Training Epoch: 65 [10240/50176]	Loss: 2.1653
Training Epoch: 65 [11264/50176]	Loss: 2.1081
Training Epoch: 65 [12288/50176]	Loss: 2.0144
Training Epoch: 65 [13312/50176]	Loss: 2.1694
Training Epoch: 65 [14336/50176]	Loss: 2.1367
Training Epoch: 65 [15360/50176]	Loss: 2.0579
Training Epoch: 65 [16384/50176]	Loss: 2.1885
Training Epoch: 65 [17408/50176]	Loss: 1.9676
Training Epoch: 65 [18432/50176]	Loss: 2.1499
Training Epoch: 65 [19456/50176]	Loss: 2.1217
Training Epoch: 65 [20480/50176]	Loss: 2.1576
Training Epoch: 65 [21504/50176]	Loss: 2.1473
Training Epoch: 65 [22528/50176]	Loss: 2.1046
Training Epoch: 65 [23552/50176]	Loss: 2.2355
Training Epoch: 65 [24576/50176]	Loss: 2.1363
Training Epoch: 65 [25600/50176]	Loss: 2.0995
Training Epoch: 65 [26624/50176]	Loss: 2.1138
Training Epoch: 65 [27648/50176]	Loss: 2.1271
Training Epoch: 65 [28672/50176]	Loss: 2.0267
Training Epoch: 65 [29696/50176]	Loss: 2.1868
Training Epoch: 65 [30720/50176]	Loss: 2.1047
Training Epoch: 65 [31744/50176]	Loss: 2.2255
Training Epoch: 65 [32768/50176]	Loss: 2.1375
Training Epoch: 65 [33792/50176]	Loss: 2.1449
Training Epoch: 65 [34816/50176]	Loss: 2.1105
Training Epoch: 65 [35840/50176]	Loss: 2.2054
Training Epoch: 65 [36864/50176]	Loss: 2.1900
Training Epoch: 65 [37888/50176]	Loss: 2.1127
Training Epoch: 65 [38912/50176]	Loss: 2.1035
Training Epoch: 65 [39936/50176]	Loss: 2.0900
Training Epoch: 65 [40960/50176]	Loss: 2.1438
Training Epoch: 65 [41984/50176]	Loss: 2.0914
Training Epoch: 65 [43008/50176]	Loss: 2.1047
Training Epoch: 65 [44032/50176]	Loss: 2.0959
Training Epoch: 65 [45056/50176]	Loss: 2.1554
Training Epoch: 65 [46080/50176]	Loss: 2.1494
Training Epoch: 65 [47104/50176]	Loss: 2.0833
Training Epoch: 65 [48128/50176]	Loss: 2.1777
Training Epoch: 65 [49152/50176]	Loss: 2.1827
Training Epoch: 65 [50176/50176]	Loss: 2.1045
2022-12-06 02:31:35.784 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:31:35,833 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.81 energy=521.21
2022-12-05 21:31:35,834 [ZeusDataLoader(train)] Up to epoch 66: time=3289.54, energy=487287.09, cost=531477.99
2022-12-05 21:31:35,834 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:31:35,834 [ZeusDataLoader(train)] Expected next epoch: time=3337.88, energy=494575.35, cost=539352.30
2022-12-05 21:31:35,835 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0024, Accuracy: 0.3801
2022-12-05 21:31:35,983 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:31:35,984 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:31:35.987 [ZeusMonitor] Monitor started.
2022-12-06 02:31:35.987 [ZeusMonitor] Running indefinitely. 2022-12-06 02:31:35.987 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:31:35.987 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e67+gpu0.power.log
2022-12-05 21:32:20,259 [ZeusDataLoader(train)] train epoch 67 done: time=44.42 energy=6777.01
2022-12-05 21:32:20,262 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 2.1500
Training Epoch: 66 [2048/50176]	Loss: 2.1433
Training Epoch: 66 [3072/50176]	Loss: 2.0969
Training Epoch: 66 [4096/50176]	Loss: 2.0924
Training Epoch: 66 [5120/50176]	Loss: 2.1354
Training Epoch: 66 [6144/50176]	Loss: 2.0062
Training Epoch: 66 [7168/50176]	Loss: 2.1576
Training Epoch: 66 [8192/50176]	Loss: 2.2050
Training Epoch: 66 [9216/50176]	Loss: 2.0252
Training Epoch: 66 [10240/50176]	Loss: 2.1594
Training Epoch: 66 [11264/50176]	Loss: 2.0891
Training Epoch: 66 [12288/50176]	Loss: 2.1479
Training Epoch: 66 [13312/50176]	Loss: 2.0960
Training Epoch: 66 [14336/50176]	Loss: 2.0688
Training Epoch: 66 [15360/50176]	Loss: 2.0244
Training Epoch: 66 [16384/50176]	Loss: 2.1020
Training Epoch: 66 [17408/50176]	Loss: 2.0905
Training Epoch: 66 [18432/50176]	Loss: 2.0257
Training Epoch: 66 [19456/50176]	Loss: 2.0633
Training Epoch: 66 [20480/50176]	Loss: 2.1288
Training Epoch: 66 [21504/50176]	Loss: 2.0490
Training Epoch: 66 [22528/50176]	Loss: 1.9742
Training Epoch: 66 [23552/50176]	Loss: 2.0292
Training Epoch: 66 [24576/50176]	Loss: 2.0557
Training Epoch: 66 [25600/50176]	Loss: 2.1664
Training Epoch: 66 [26624/50176]	Loss: 2.0943
Training Epoch: 66 [27648/50176]	Loss: 2.1864
Training Epoch: 66 [28672/50176]	Loss: 2.2399
Training Epoch: 66 [29696/50176]	Loss: 2.1780
Training Epoch: 66 [30720/50176]	Loss: 2.1809
Training Epoch: 66 [31744/50176]	Loss: 2.0210
Training Epoch: 66 [32768/50176]	Loss: 2.0659
Training Epoch: 66 [33792/50176]	Loss: 2.0496
Training Epoch: 66 [34816/50176]	Loss: 2.1615
Training Epoch: 66 [35840/50176]	Loss: 2.1838
Training Epoch: 66 [36864/50176]	Loss: 2.1128
Training Epoch: 66 [37888/50176]	Loss: 2.0945
Training Epoch: 66 [38912/50176]	Loss: 2.1231
Training Epoch: 66 [39936/50176]	Loss: 2.1032
Training Epoch: 66 [40960/50176]	Loss: 2.1221
Training Epoch: 66 [41984/50176]	Loss: 2.0339
Training Epoch: 66 [43008/50176]	Loss: 2.1477
Training Epoch: 66 [44032/50176]	Loss: 2.0756
Training Epoch: 66 [45056/50176]	Loss: 2.0483
Training Epoch: 66 [46080/50176]	Loss: 2.0377
Training Epoch: 66 [47104/50176]	Loss: 2.1560
Training Epoch: 66 [48128/50176]	Loss: 2.0091
Training Epoch: 66 [49152/50176]	Loss: 2.0716
Training Epoch: 66 [50176/50176]	Loss: 2.1828
2022-12-06 02:32:24.014 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:32:24,070 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.80 energy=542.76
2022-12-05 21:32:24,071 [ZeusDataLoader(train)] Up to epoch 67: time=3337.75, energy=494606.87, cost=539356.74
2022-12-05 21:32:24,071 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:32:24,071 [ZeusDataLoader(train)] Expected next epoch: time=3386.10, energy=501895.13, cost=547231.05
2022-12-05 21:32:24,072 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0024, Accuracy: 0.3826
2022-12-05 21:32:24,268 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:32:24,269 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:32:24.271 [ZeusMonitor] Monitor started.
2022-12-06 02:32:24.271 [ZeusMonitor] Running indefinitely. 2022-12-06 02:32:24.271 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:32:24.271 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e68+gpu0.power.log
2022-12-05 21:33:08,532 [ZeusDataLoader(train)] train epoch 68 done: time=44.45 energy=6775.95
2022-12-05 21:33:08,536 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 2.0201
Training Epoch: 67 [2048/50176]	Loss: 2.1057
Training Epoch: 67 [3072/50176]	Loss: 2.1287
Training Epoch: 67 [4096/50176]	Loss: 2.1557
Training Epoch: 67 [5120/50176]	Loss: 2.0673
Training Epoch: 67 [6144/50176]	Loss: 2.0621
Training Epoch: 67 [7168/50176]	Loss: 2.0675
Training Epoch: 67 [8192/50176]	Loss: 2.0638
Training Epoch: 67 [9216/50176]	Loss: 2.1285
Training Epoch: 67 [10240/50176]	Loss: 2.1419
Training Epoch: 67 [11264/50176]	Loss: 2.1131
Training Epoch: 67 [12288/50176]	Loss: 2.0408
Training Epoch: 67 [13312/50176]	Loss: 2.0764
Training Epoch: 67 [14336/50176]	Loss: 2.0124
Training Epoch: 67 [15360/50176]	Loss: 2.0851
Training Epoch: 67 [16384/50176]	Loss: 2.0564
Training Epoch: 67 [17408/50176]	Loss: 2.0223
Training Epoch: 67 [18432/50176]	Loss: 2.1399
Training Epoch: 67 [19456/50176]	Loss: 2.1241
Training Epoch: 67 [20480/50176]	Loss: 2.0426
Training Epoch: 67 [21504/50176]	Loss: 2.0785
Training Epoch: 67 [22528/50176]	Loss: 2.0847
Training Epoch: 67 [23552/50176]	Loss: 2.0566
Training Epoch: 67 [24576/50176]	Loss: 2.0977
Training Epoch: 67 [25600/50176]	Loss: 2.1338
Training Epoch: 67 [26624/50176]	Loss: 2.1183
Training Epoch: 67 [27648/50176]	Loss: 2.0928
Training Epoch: 67 [28672/50176]	Loss: 2.1106
Training Epoch: 67 [29696/50176]	Loss: 2.0782
Training Epoch: 67 [30720/50176]	Loss: 2.0298
Training Epoch: 67 [31744/50176]	Loss: 2.0329
Training Epoch: 67 [32768/50176]	Loss: 2.0520
Training Epoch: 67 [33792/50176]	Loss: 2.0772
Training Epoch: 67 [34816/50176]	Loss: 2.0576
Training Epoch: 67 [35840/50176]	Loss: 2.0480
Training Epoch: 67 [36864/50176]	Loss: 2.0367
Training Epoch: 67 [37888/50176]	Loss: 2.0968
Training Epoch: 67 [38912/50176]	Loss: 2.0344
Training Epoch: 67 [39936/50176]	Loss: 2.1847
Training Epoch: 67 [40960/50176]	Loss: 2.0776
Training Epoch: 67 [41984/50176]	Loss: 2.0320
Training Epoch: 67 [43008/50176]	Loss: 2.0337
Training Epoch: 67 [44032/50176]	Loss: 2.1545
Training Epoch: 67 [45056/50176]	Loss: 2.1838
Training Epoch: 67 [46080/50176]	Loss: 2.1561
Training Epoch: 67 [47104/50176]	Loss: 2.0898
Training Epoch: 67 [48128/50176]	Loss: 2.0762
Training Epoch: 67 [49152/50176]	Loss: 2.1144
Training Epoch: 67 [50176/50176]	Loss: 2.1614
2022-12-06 02:33:12.291 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:33:12,321 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.78 energy=519.21
2022-12-05 21:33:12,322 [ZeusDataLoader(train)] Up to epoch 68: time=3385.98, energy=501902.03, cost=547224.39
2022-12-05 21:33:12,322 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:33:12,322 [ZeusDataLoader(train)] Expected next epoch: time=3434.33, energy=509190.29, cost=555098.70
2022-12-05 21:33:12,323 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0024, Accuracy: 0.3857
2022-12-05 21:33:12,512 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:33:12,513 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:33:12.515 [ZeusMonitor] Monitor started.
2022-12-06 02:33:12.515 [ZeusMonitor] Running indefinitely. 2022-12-06 02:33:12.515 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:33:12.515 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e69+gpu0.power.log
2022-12-05 21:33:56,994 [ZeusDataLoader(train)] train epoch 69 done: time=44.66 energy=6797.45
2022-12-05 21:33:56,998 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 1.9941
Training Epoch: 68 [2048/50176]	Loss: 2.0186
Training Epoch: 68 [3072/50176]	Loss: 2.0509
Training Epoch: 68 [4096/50176]	Loss: 2.0560
Training Epoch: 68 [5120/50176]	Loss: 2.0486
Training Epoch: 68 [6144/50176]	Loss: 2.0628
Training Epoch: 68 [7168/50176]	Loss: 2.1480
Training Epoch: 68 [8192/50176]	Loss: 2.0689
Training Epoch: 68 [9216/50176]	Loss: 2.0937
Training Epoch: 68 [10240/50176]	Loss: 2.0315
Training Epoch: 68 [11264/50176]	Loss: 2.0729
Training Epoch: 68 [12288/50176]	Loss: 2.1029
Training Epoch: 68 [13312/50176]	Loss: 2.1149
Training Epoch: 68 [14336/50176]	Loss: 2.0015
Training Epoch: 68 [15360/50176]	Loss: 2.0463
Training Epoch: 68 [16384/50176]	Loss: 2.1896
Training Epoch: 68 [17408/50176]	Loss: 2.0257
Training Epoch: 68 [18432/50176]	Loss: 2.0658
Training Epoch: 68 [19456/50176]	Loss: 1.9926
Training Epoch: 68 [20480/50176]	Loss: 2.0396
Training Epoch: 68 [21504/50176]	Loss: 2.1006
Training Epoch: 68 [22528/50176]	Loss: 2.1671
Training Epoch: 68 [23552/50176]	Loss: 1.9360
Training Epoch: 68 [24576/50176]	Loss: 2.1075
Training Epoch: 68 [25600/50176]	Loss: 2.1194
Training Epoch: 68 [26624/50176]	Loss: 2.1276
Training Epoch: 68 [27648/50176]	Loss: 2.0646
Training Epoch: 68 [28672/50176]	Loss: 2.1249
Training Epoch: 68 [29696/50176]	Loss: 2.1302
Training Epoch: 68 [30720/50176]	Loss: 2.0846
Training Epoch: 68 [31744/50176]	Loss: 2.0438
Training Epoch: 68 [32768/50176]	Loss: 2.0816
Training Epoch: 68 [33792/50176]	Loss: 2.1571
Training Epoch: 68 [34816/50176]	Loss: 2.1104
Training Epoch: 68 [35840/50176]	Loss: 2.1648
Training Epoch: 68 [36864/50176]	Loss: 2.0443
Training Epoch: 68 [37888/50176]	Loss: 2.0752
Training Epoch: 68 [38912/50176]	Loss: 1.9776
Training Epoch: 68 [39936/50176]	Loss: 2.1191
Training Epoch: 68 [40960/50176]	Loss: 2.0246
Training Epoch: 68 [41984/50176]	Loss: 2.1275
Training Epoch: 68 [43008/50176]	Loss: 2.0779
Training Epoch: 68 [44032/50176]	Loss: 2.1381
Training Epoch: 68 [45056/50176]	Loss: 2.0799
Training Epoch: 68 [46080/50176]	Loss: 1.9901
Training Epoch: 68 [47104/50176]	Loss: 2.0759
Training Epoch: 68 [48128/50176]	Loss: 2.0814
Training Epoch: 68 [49152/50176]	Loss: 2.1584
Training Epoch: 68 [50176/50176]	Loss: 2.1016
2022-12-06 02:34:00.727 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:34:00,753 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.75 energy=521.72
2022-12-05 21:34:00,754 [ZeusDataLoader(train)] Up to epoch 69: time=3434.39, energy=509221.20, cost=555119.86
2022-12-05 21:34:00,754 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:34:00,754 [ZeusDataLoader(train)] Expected next epoch: time=3482.74, energy=516509.46, cost=562994.17
2022-12-05 21:34:00,755 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0024, Accuracy: 0.3827
2022-12-05 21:34:00,946 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:34:00,947 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:34:00.957 [ZeusMonitor] Monitor started.
2022-12-06 02:34:00.957 [ZeusMonitor] Running indefinitely. 2022-12-06 02:34:00.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:34:00.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e70+gpu0.power.log
2022-12-05 21:34:45,060 [ZeusDataLoader(train)] train epoch 70 done: time=44.30 energy=6744.15
2022-12-05 21:34:45,064 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 2.0201
Training Epoch: 69 [2048/50176]	Loss: 2.1318
Training Epoch: 69 [3072/50176]	Loss: 2.0418
Training Epoch: 69 [4096/50176]	Loss: 2.0479
Training Epoch: 69 [5120/50176]	Loss: 1.9996
Training Epoch: 69 [6144/50176]	Loss: 2.0356
Training Epoch: 69 [7168/50176]	Loss: 2.0807
Training Epoch: 69 [8192/50176]	Loss: 2.0107
Training Epoch: 69 [9216/50176]	Loss: 2.0687
Training Epoch: 69 [10240/50176]	Loss: 2.0470
Training Epoch: 69 [11264/50176]	Loss: 2.0376
Training Epoch: 69 [12288/50176]	Loss: 1.9691
Training Epoch: 69 [13312/50176]	Loss: 2.0095
Training Epoch: 69 [14336/50176]	Loss: 2.0164
Training Epoch: 69 [15360/50176]	Loss: 2.0757
Training Epoch: 69 [16384/50176]	Loss: 1.9956
Training Epoch: 69 [17408/50176]	Loss: 2.1290
Training Epoch: 69 [18432/50176]	Loss: 2.0581
Training Epoch: 69 [19456/50176]	Loss: 2.0900
Training Epoch: 69 [20480/50176]	Loss: 2.0599
Training Epoch: 69 [21504/50176]	Loss: 2.0250
Training Epoch: 69 [22528/50176]	Loss: 2.0751
Training Epoch: 69 [23552/50176]	Loss: 2.0086
Training Epoch: 69 [24576/50176]	Loss: 2.0271
Training Epoch: 69 [25600/50176]	Loss: 2.0397
Training Epoch: 69 [26624/50176]	Loss: 2.0131
Training Epoch: 69 [27648/50176]	Loss: 2.0848
Training Epoch: 69 [28672/50176]	Loss: 1.9758
Training Epoch: 69 [29696/50176]	Loss: 2.0147
Training Epoch: 69 [30720/50176]	Loss: 2.0574
Training Epoch: 69 [31744/50176]	Loss: 2.1574
Training Epoch: 69 [32768/50176]	Loss: 2.0239
Training Epoch: 69 [33792/50176]	Loss: 2.2175
Training Epoch: 69 [34816/50176]	Loss: 2.0266
Training Epoch: 69 [35840/50176]	Loss: 2.0305
Training Epoch: 69 [36864/50176]	Loss: 2.0509
Training Epoch: 69 [37888/50176]	Loss: 2.0091
Training Epoch: 69 [38912/50176]	Loss: 2.0522
Training Epoch: 69 [39936/50176]	Loss: 2.1303
Training Epoch: 69 [40960/50176]	Loss: 2.0366
Training Epoch: 69 [41984/50176]	Loss: 2.0463
Training Epoch: 69 [43008/50176]	Loss: 2.0502
Training Epoch: 69 [44032/50176]	Loss: 2.0620
Training Epoch: 69 [45056/50176]	Loss: 2.1833
Training Epoch: 69 [46080/50176]	Loss: 2.0965
Training Epoch: 69 [47104/50176]	Loss: 2.0895
Training Epoch: 69 [48128/50176]	Loss: 2.0637
Training Epoch: 69 [49152/50176]	Loss: 2.0413
Training Epoch: 69 [50176/50176]	Loss: 2.1347
2022-12-06 02:34:48.796 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:34:48,815 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.74 energy=519.64
2022-12-05 21:34:48,815 [ZeusDataLoader(train)] Up to epoch 70: time=3482.43, energy=516484.98, cost=562955.20
2022-12-05 21:34:48,815 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:34:48,815 [ZeusDataLoader(train)] Expected next epoch: time=3530.78, energy=523773.25, cost=570829.51
2022-12-05 21:34:48,816 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0024, Accuracy: 0.3842
2022-12-05 21:34:48,991 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:34:48,992 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:34:49.006 [ZeusMonitor] Monitor started.
2022-12-06 02:34:49.006 [ZeusMonitor] Running indefinitely. 2022-12-06 02:34:49.006 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:34:49.006 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e71+gpu0.power.log
2022-12-05 21:35:33,655 [ZeusDataLoader(train)] train epoch 71 done: time=44.83 energy=6816.78
2022-12-05 21:35:33,658 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 2.0232
Training Epoch: 70 [2048/50176]	Loss: 2.0155
Training Epoch: 70 [3072/50176]	Loss: 1.9970
Training Epoch: 70 [4096/50176]	Loss: 1.9471
Training Epoch: 70 [5120/50176]	Loss: 2.0438
Training Epoch: 70 [6144/50176]	Loss: 2.0492
Training Epoch: 70 [7168/50176]	Loss: 2.0985
Training Epoch: 70 [8192/50176]	Loss: 1.9564
Training Epoch: 70 [9216/50176]	Loss: 2.0026
Training Epoch: 70 [10240/50176]	Loss: 2.0586
Training Epoch: 70 [11264/50176]	Loss: 1.9629
Training Epoch: 70 [12288/50176]	Loss: 2.0384
Training Epoch: 70 [13312/50176]	Loss: 2.0811
Training Epoch: 70 [14336/50176]	Loss: 2.0426
Training Epoch: 70 [15360/50176]	Loss: 1.9646
Training Epoch: 70 [16384/50176]	Loss: 2.0096
Training Epoch: 70 [17408/50176]	Loss: 1.9363
Training Epoch: 70 [18432/50176]	Loss: 2.0218
Training Epoch: 70 [19456/50176]	Loss: 2.0885
Training Epoch: 70 [20480/50176]	Loss: 2.0550
Training Epoch: 70 [21504/50176]	Loss: 2.0127
Training Epoch: 70 [22528/50176]	Loss: 2.1145
Training Epoch: 70 [23552/50176]	Loss: 2.0603
Training Epoch: 70 [24576/50176]	Loss: 2.0352
Training Epoch: 70 [25600/50176]	Loss: 2.0136
Training Epoch: 70 [26624/50176]	Loss: 2.0886
Training Epoch: 70 [27648/50176]	Loss: 2.1399
Training Epoch: 70 [28672/50176]	Loss: 2.0287
Training Epoch: 70 [29696/50176]	Loss: 1.9669
Training Epoch: 70 [30720/50176]	Loss: 2.0627
Training Epoch: 70 [31744/50176]	Loss: 1.9384
Training Epoch: 70 [32768/50176]	Loss: 2.0275
Training Epoch: 70 [33792/50176]	Loss: 2.0515
Training Epoch: 70 [34816/50176]	Loss: 1.9717
Training Epoch: 70 [35840/50176]	Loss: 2.0866
Training Epoch: 70 [36864/50176]	Loss: 2.1517
Training Epoch: 70 [37888/50176]	Loss: 1.9802
Training Epoch: 70 [38912/50176]	Loss: 2.1659
Training Epoch: 70 [39936/50176]	Loss: 2.1328
Training Epoch: 70 [40960/50176]	Loss: 2.0956
Training Epoch: 70 [41984/50176]	Loss: 2.0342
Training Epoch: 70 [43008/50176]	Loss: 2.0916
Training Epoch: 70 [44032/50176]	Loss: 2.0585
Training Epoch: 70 [45056/50176]	Loss: 2.1311
Training Epoch: 70 [46080/50176]	Loss: 1.9816
Training Epoch: 70 [47104/50176]	Loss: 2.0490
Training Epoch: 70 [48128/50176]	Loss: 2.0204
Training Epoch: 70 [49152/50176]	Loss: 2.0082
Training Epoch: 70 [50176/50176]	Loss: 2.0061
2022-12-06 02:35:37.457 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:35:37,468 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.80 energy=529.45
2022-12-05 21:35:37,468 [ZeusDataLoader(train)] Up to epoch 71: time=3531.06, energy=523831.21, cost=570883.50
2022-12-05 21:35:37,468 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:35:37,468 [ZeusDataLoader(train)] Expected next epoch: time=3579.41, energy=531119.47, cost=578757.81
2022-12-05 21:35:37,469 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0023, Accuracy: 0.3806
2022-12-05 21:35:37,622 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:35:37,623 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:35:37.626 [ZeusMonitor] Monitor started.
2022-12-06 02:35:37.627 [ZeusMonitor] Running indefinitely. 2022-12-06 02:35:37.627 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:35:37.627 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e72+gpu0.power.log
2022-12-05 21:36:22,760 [ZeusDataLoader(train)] train epoch 72 done: time=45.28 energy=6877.43
2022-12-05 21:36:22,763 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 2.0578
Training Epoch: 71 [2048/50176]	Loss: 2.0100
Training Epoch: 71 [3072/50176]	Loss: 2.0386
Training Epoch: 71 [4096/50176]	Loss: 2.0192
Training Epoch: 71 [5120/50176]	Loss: 2.0508
Training Epoch: 71 [6144/50176]	Loss: 1.9542
Training Epoch: 71 [7168/50176]	Loss: 1.9502
Training Epoch: 71 [8192/50176]	Loss: 1.9484
Training Epoch: 71 [9216/50176]	Loss: 1.9827
Training Epoch: 71 [10240/50176]	Loss: 2.0090
Training Epoch: 71 [11264/50176]	Loss: 2.0607
Training Epoch: 71 [12288/50176]	Loss: 2.0331
Training Epoch: 71 [13312/50176]	Loss: 2.0459
Training Epoch: 71 [14336/50176]	Loss: 2.0658
Training Epoch: 71 [15360/50176]	Loss: 1.9903
Training Epoch: 71 [16384/50176]	Loss: 2.0474
Training Epoch: 71 [17408/50176]	Loss: 2.0326
Training Epoch: 71 [18432/50176]	Loss: 1.9957
Training Epoch: 71 [19456/50176]	Loss: 1.9781
Training Epoch: 71 [20480/50176]	Loss: 2.0066
Training Epoch: 71 [21504/50176]	Loss: 2.0784
Training Epoch: 71 [22528/50176]	Loss: 1.9525
Training Epoch: 71 [23552/50176]	Loss: 1.9787
Training Epoch: 71 [24576/50176]	Loss: 1.9735
Training Epoch: 71 [25600/50176]	Loss: 2.0393
Training Epoch: 71 [26624/50176]	Loss: 2.0622
Training Epoch: 71 [27648/50176]	Loss: 2.0156
Training Epoch: 71 [28672/50176]	Loss: 2.0269
Training Epoch: 71 [29696/50176]	Loss: 2.0411
Training Epoch: 71 [30720/50176]	Loss: 1.9666
Training Epoch: 71 [31744/50176]	Loss: 1.9464
Training Epoch: 71 [32768/50176]	Loss: 2.0774
Training Epoch: 71 [33792/50176]	Loss: 2.0823
Training Epoch: 71 [34816/50176]	Loss: 2.0389
Training Epoch: 71 [35840/50176]	Loss: 2.0859
Training Epoch: 71 [36864/50176]	Loss: 2.0703
Training Epoch: 71 [37888/50176]	Loss: 1.9352
Training Epoch: 71 [38912/50176]	Loss: 1.9775
Training Epoch: 71 [39936/50176]	Loss: 2.0401
Training Epoch: 71 [40960/50176]	Loss: 1.9070
Training Epoch: 71 [41984/50176]	Loss: 2.0422
Training Epoch: 71 [43008/50176]	Loss: 2.0539
Training Epoch: 71 [44032/50176]	Loss: 2.0385
Training Epoch: 71 [45056/50176]	Loss: 1.9588
Training Epoch: 71 [46080/50176]	Loss: 1.9785
Training Epoch: 71 [47104/50176]	Loss: 2.0024
Training Epoch: 71 [48128/50176]	Loss: 2.0725
Training Epoch: 71 [49152/50176]	Loss: 2.1070
Training Epoch: 71 [50176/50176]	Loss: 1.9995
2022-12-06 02:36:26.567 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:36:26,585 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.81 energy=534.15
2022-12-05 21:36:26,586 [ZeusDataLoader(train)] Up to epoch 72: time=3580.16, energy=531242.80, cost=578885.22
2022-12-05 21:36:26,586 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:36:26,586 [ZeusDataLoader(train)] Expected next epoch: time=3628.50, energy=538531.06, cost=586759.53
2022-12-05 21:36:26,587 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0023, Accuracy: 0.3815
2022-12-05 21:36:26,768 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:36:26,769 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:36:26.771 [ZeusMonitor] Monitor started.
2022-12-06 02:36:26.783 [ZeusMonitor] Running indefinitely. 2022-12-06 02:36:26.783 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:36:26.783 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e73+gpu0.power.log
2022-12-05 21:37:11,715 [ZeusDataLoader(train)] train epoch 73 done: time=45.12 energy=6858.74
2022-12-05 21:37:11,718 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 2.0019
Training Epoch: 72 [2048/50176]	Loss: 2.0080
Training Epoch: 72 [3072/50176]	Loss: 1.9936
Training Epoch: 72 [4096/50176]	Loss: 1.8828
Training Epoch: 72 [5120/50176]	Loss: 2.0069
Training Epoch: 72 [6144/50176]	Loss: 1.8998
Training Epoch: 72 [7168/50176]	Loss: 1.9618
Training Epoch: 72 [8192/50176]	Loss: 1.8998
Training Epoch: 72 [9216/50176]	Loss: 1.9012
Training Epoch: 72 [10240/50176]	Loss: 2.0064
Training Epoch: 72 [11264/50176]	Loss: 2.0478
Training Epoch: 72 [12288/50176]	Loss: 1.9467
Training Epoch: 72 [13312/50176]	Loss: 2.0580
Training Epoch: 72 [14336/50176]	Loss: 1.9161
Training Epoch: 72 [15360/50176]	Loss: 1.9907
Training Epoch: 72 [16384/50176]	Loss: 2.0460
Training Epoch: 72 [17408/50176]	Loss: 2.0616
Training Epoch: 72 [18432/50176]	Loss: 2.0509
Training Epoch: 72 [19456/50176]	Loss: 2.0383
Training Epoch: 72 [20480/50176]	Loss: 2.0025
Training Epoch: 72 [21504/50176]	Loss: 2.0882
Training Epoch: 72 [22528/50176]	Loss: 2.0796
Training Epoch: 72 [23552/50176]	Loss: 1.9739
Training Epoch: 72 [24576/50176]	Loss: 1.9835
Training Epoch: 72 [25600/50176]	Loss: 1.9930
Training Epoch: 72 [26624/50176]	Loss: 1.9951
Training Epoch: 72 [27648/50176]	Loss: 2.0509
Training Epoch: 72 [28672/50176]	Loss: 2.0132
Training Epoch: 72 [29696/50176]	Loss: 1.9005
Training Epoch: 72 [30720/50176]	Loss: 2.0389
Training Epoch: 72 [31744/50176]	Loss: 1.9382
Training Epoch: 72 [32768/50176]	Loss: 1.9504
Training Epoch: 72 [33792/50176]	Loss: 1.9258
Training Epoch: 72 [34816/50176]	Loss: 1.9566
Training Epoch: 72 [35840/50176]	Loss: 2.0293
Training Epoch: 72 [36864/50176]	Loss: 2.0557
Training Epoch: 72 [37888/50176]	Loss: 2.1099
Training Epoch: 72 [38912/50176]	Loss: 2.0438
Training Epoch: 72 [39936/50176]	Loss: 1.9459
Training Epoch: 72 [40960/50176]	Loss: 2.1123
Training Epoch: 72 [41984/50176]	Loss: 1.9782
Training Epoch: 72 [43008/50176]	Loss: 2.0426
Training Epoch: 72 [44032/50176]	Loss: 2.1044
Training Epoch: 72 [45056/50176]	Loss: 2.0185
Training Epoch: 72 [46080/50176]	Loss: 2.0321
Training Epoch: 72 [47104/50176]	Loss: 2.0124
Training Epoch: 72 [48128/50176]	Loss: 2.0380
Training Epoch: 72 [49152/50176]	Loss: 1.9559
Training Epoch: 72 [50176/50176]	Loss: 2.0900
2022-12-06 02:37:15.437 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:37:15,467 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.74 energy=518.18
2022-12-05 21:37:15,467 [ZeusDataLoader(train)] Up to epoch 73: time=3629.02, energy=538619.72, cost=586848.91
2022-12-05 21:37:15,467 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:37:15,467 [ZeusDataLoader(train)] Expected next epoch: time=3677.36, energy=545907.98, cost=594723.22
2022-12-05 21:37:15,468 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0023, Accuracy: 0.3894
2022-12-05 21:37:15,661 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:37:15,662 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:37:15.663 [ZeusMonitor] Monitor started.
2022-12-06 02:37:15.663 [ZeusMonitor] Running indefinitely. 2022-12-06 02:37:15.664 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:37:15.664 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e74+gpu0.power.log
2022-12-05 21:37:59,790 [ZeusDataLoader(train)] train epoch 74 done: time=44.31 energy=6766.06
2022-12-05 21:37:59,793 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 1.9622
Training Epoch: 73 [2048/50176]	Loss: 1.9639
Training Epoch: 73 [3072/50176]	Loss: 1.9548
Training Epoch: 73 [4096/50176]	Loss: 1.9822
Training Epoch: 73 [5120/50176]	Loss: 1.9140
Training Epoch: 73 [6144/50176]	Loss: 1.8937
Training Epoch: 73 [7168/50176]	Loss: 2.0028
Training Epoch: 73 [8192/50176]	Loss: 1.9719
Training Epoch: 73 [9216/50176]	Loss: 1.9282
Training Epoch: 73 [10240/50176]	Loss: 1.9594
Training Epoch: 73 [11264/50176]	Loss: 1.9562
Training Epoch: 73 [12288/50176]	Loss: 2.0260
Training Epoch: 73 [13312/50176]	Loss: 1.9436
Training Epoch: 73 [14336/50176]	Loss: 1.9992
Training Epoch: 73 [15360/50176]	Loss: 1.9968
Training Epoch: 73 [16384/50176]	Loss: 2.0308
Training Epoch: 73 [17408/50176]	Loss: 1.9485
Training Epoch: 73 [18432/50176]	Loss: 1.9372
Training Epoch: 73 [19456/50176]	Loss: 2.0052
Training Epoch: 73 [20480/50176]	Loss: 1.9555
Training Epoch: 73 [21504/50176]	Loss: 1.9387
Training Epoch: 73 [22528/50176]	Loss: 2.0086
Training Epoch: 73 [23552/50176]	Loss: 1.9421
Training Epoch: 73 [24576/50176]	Loss: 1.8858
Training Epoch: 73 [25600/50176]	Loss: 1.9507
Training Epoch: 73 [26624/50176]	Loss: 2.0754
Training Epoch: 73 [27648/50176]	Loss: 2.0123
Training Epoch: 73 [28672/50176]	Loss: 2.0682
Training Epoch: 73 [29696/50176]	Loss: 2.0977
Training Epoch: 73 [30720/50176]	Loss: 1.9391
Training Epoch: 73 [31744/50176]	Loss: 2.0017
Training Epoch: 73 [32768/50176]	Loss: 2.0337
Training Epoch: 73 [33792/50176]	Loss: 1.9949
Training Epoch: 73 [34816/50176]	Loss: 2.0176
Training Epoch: 73 [35840/50176]	Loss: 2.0592
Training Epoch: 73 [36864/50176]	Loss: 1.9961
Training Epoch: 73 [37888/50176]	Loss: 1.9665
Training Epoch: 73 [38912/50176]	Loss: 1.9999
Training Epoch: 73 [39936/50176]	Loss: 2.0410
Training Epoch: 73 [40960/50176]	Loss: 2.0109
Training Epoch: 73 [41984/50176]	Loss: 1.9726
Training Epoch: 73 [43008/50176]	Loss: 2.0021
Training Epoch: 73 [44032/50176]	Loss: 2.0324
Training Epoch: 73 [45056/50176]	Loss: 1.9473
Training Epoch: 73 [46080/50176]	Loss: 2.0222
Training Epoch: 73 [47104/50176]	Loss: 2.0125
Training Epoch: 73 [48128/50176]	Loss: 1.9701
Training Epoch: 73 [49152/50176]	Loss: 1.9542
Training Epoch: 73 [50176/50176]	Loss: 2.0532
2022-12-06 02:38:03.571 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:38:03,610 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.81 energy=536.90
2022-12-05 21:38:03,610 [ZeusDataLoader(train)] Up to epoch 74: time=3677.14, energy=545922.68, cost=594711.10
2022-12-05 21:38:03,611 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:38:03,611 [ZeusDataLoader(train)] Expected next epoch: time=3725.49, energy=553210.94, cost=602585.41
2022-12-05 21:38:03,612 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0023, Accuracy: 0.3914
2022-12-05 21:38:03,800 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:38:03,801 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:38:03.803 [ZeusMonitor] Monitor started.
2022-12-06 02:38:03.803 [ZeusMonitor] Running indefinitely. 2022-12-06 02:38:03.803 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:38:03.803 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e75+gpu0.power.log
2022-12-05 21:38:47,965 [ZeusDataLoader(train)] train epoch 75 done: time=44.34 energy=6749.78
2022-12-05 21:38:47,969 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 2.0042
Training Epoch: 74 [2048/50176]	Loss: 1.8741
Training Epoch: 74 [3072/50176]	Loss: 1.9185
Training Epoch: 74 [4096/50176]	Loss: 1.9618
Training Epoch: 74 [5120/50176]	Loss: 1.9366
Training Epoch: 74 [6144/50176]	Loss: 1.9081
Training Epoch: 74 [7168/50176]	Loss: 1.9356
Training Epoch: 74 [8192/50176]	Loss: 1.9120
Training Epoch: 74 [9216/50176]	Loss: 2.0534
Training Epoch: 74 [10240/50176]	Loss: 1.9930
Training Epoch: 74 [11264/50176]	Loss: 1.9596
Training Epoch: 74 [12288/50176]	Loss: 1.9602
Training Epoch: 74 [13312/50176]	Loss: 1.9640
Training Epoch: 74 [14336/50176]	Loss: 1.9439
Training Epoch: 74 [15360/50176]	Loss: 1.9534
Training Epoch: 74 [16384/50176]	Loss: 1.9728
Training Epoch: 74 [17408/50176]	Loss: 1.9545
Training Epoch: 74 [18432/50176]	Loss: 1.9752
Training Epoch: 74 [19456/50176]	Loss: 1.9270
Training Epoch: 74 [20480/50176]	Loss: 2.0659
Training Epoch: 74 [21504/50176]	Loss: 1.9059
Training Epoch: 74 [22528/50176]	Loss: 1.9228
Training Epoch: 74 [23552/50176]	Loss: 1.9572
Training Epoch: 74 [24576/50176]	Loss: 1.8973
Training Epoch: 74 [25600/50176]	Loss: 1.8510
Training Epoch: 74 [26624/50176]	Loss: 1.9890
Training Epoch: 74 [27648/50176]	Loss: 2.0296
Training Epoch: 74 [28672/50176]	Loss: 1.9366
Training Epoch: 74 [29696/50176]	Loss: 1.9541
Training Epoch: 74 [30720/50176]	Loss: 1.9036
Training Epoch: 74 [31744/50176]	Loss: 2.0261
Training Epoch: 74 [32768/50176]	Loss: 1.9930
Training Epoch: 74 [33792/50176]	Loss: 2.0515
Training Epoch: 74 [34816/50176]	Loss: 2.0155
Training Epoch: 74 [35840/50176]	Loss: 2.0063
Training Epoch: 74 [36864/50176]	Loss: 2.0059
Training Epoch: 74 [37888/50176]	Loss: 2.0381
Training Epoch: 74 [38912/50176]	Loss: 2.0016
Training Epoch: 74 [39936/50176]	Loss: 2.0716
Training Epoch: 74 [40960/50176]	Loss: 1.9319
Training Epoch: 74 [41984/50176]	Loss: 1.9938
Training Epoch: 74 [43008/50176]	Loss: 1.9602
Training Epoch: 74 [44032/50176]	Loss: 2.0043
Training Epoch: 74 [45056/50176]	Loss: 2.0021
Training Epoch: 74 [46080/50176]	Loss: 1.9520
Training Epoch: 74 [47104/50176]	Loss: 1.9468
Training Epoch: 74 [48128/50176]	Loss: 1.9980
Training Epoch: 74 [49152/50176]	Loss: 1.9956
Training Epoch: 74 [50176/50176]	Loss: 2.0645
2022-12-06 02:38:51.659 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:38:51,668 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.69 energy=513.31
2022-12-05 21:38:51,668 [ZeusDataLoader(train)] Up to epoch 75: time=3725.18, energy=553185.77, cost=602545.71
2022-12-05 21:38:51,668 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:38:51,668 [ZeusDataLoader(train)] Expected next epoch: time=3773.52, energy=560474.03, cost=610420.03
2022-12-05 21:38:51,669 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 0.0023, Accuracy: 0.3947
2022-12-05 21:38:51,860 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:38:51,861 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:38:51.863 [ZeusMonitor] Monitor started.
2022-12-06 02:38:51.863 [ZeusMonitor] Running indefinitely. 2022-12-06 02:38:51.863 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:38:51.863 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e76+gpu0.power.log
2022-12-05 21:39:35,944 [ZeusDataLoader(train)] train epoch 76 done: time=44.27 energy=6750.62
2022-12-05 21:39:35,948 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 1.9054
Training Epoch: 75 [2048/50176]	Loss: 1.9768
Training Epoch: 75 [3072/50176]	Loss: 1.8637
Training Epoch: 75 [4096/50176]	Loss: 1.9056
Training Epoch: 75 [5120/50176]	Loss: 1.9592
Training Epoch: 75 [6144/50176]	Loss: 2.0030
Training Epoch: 75 [7168/50176]	Loss: 1.9392
Training Epoch: 75 [8192/50176]	Loss: 1.9222
Training Epoch: 75 [9216/50176]	Loss: 1.8824
Training Epoch: 75 [10240/50176]	Loss: 1.9337
Training Epoch: 75 [11264/50176]	Loss: 1.9010
Training Epoch: 75 [12288/50176]	Loss: 1.8641
Training Epoch: 75 [13312/50176]	Loss: 1.9078
Training Epoch: 75 [14336/50176]	Loss: 1.9791
Training Epoch: 75 [15360/50176]	Loss: 1.9722
Training Epoch: 75 [16384/50176]	Loss: 1.9362
Training Epoch: 75 [17408/50176]	Loss: 1.9018
Training Epoch: 75 [18432/50176]	Loss: 1.9142
Training Epoch: 75 [19456/50176]	Loss: 1.9345
Training Epoch: 75 [20480/50176]	Loss: 1.9654
Training Epoch: 75 [21504/50176]	Loss: 1.9138
Training Epoch: 75 [22528/50176]	Loss: 1.9313
Training Epoch: 75 [23552/50176]	Loss: 1.9882
Training Epoch: 75 [24576/50176]	Loss: 1.9332
Training Epoch: 75 [25600/50176]	Loss: 1.9468
Training Epoch: 75 [26624/50176]	Loss: 2.0046
Training Epoch: 75 [27648/50176]	Loss: 1.9123
Training Epoch: 75 [28672/50176]	Loss: 1.9897
Training Epoch: 75 [29696/50176]	Loss: 2.1097
Training Epoch: 75 [30720/50176]	Loss: 2.0222
Training Epoch: 75 [31744/50176]	Loss: 2.0033
Training Epoch: 75 [32768/50176]	Loss: 1.9708
Training Epoch: 75 [33792/50176]	Loss: 1.9010
Training Epoch: 75 [34816/50176]	Loss: 2.1290
Training Epoch: 75 [35840/50176]	Loss: 1.9395
Training Epoch: 75 [36864/50176]	Loss: 1.9362
Training Epoch: 75 [37888/50176]	Loss: 1.9172
Training Epoch: 75 [38912/50176]	Loss: 2.0298
Training Epoch: 75 [39936/50176]	Loss: 1.9823
Training Epoch: 75 [40960/50176]	Loss: 1.9265
Training Epoch: 75 [41984/50176]	Loss: 1.9669
Training Epoch: 75 [43008/50176]	Loss: 2.0330
Training Epoch: 75 [44032/50176]	Loss: 2.0189
Training Epoch: 75 [45056/50176]	Loss: 1.9156
Training Epoch: 75 [46080/50176]	Loss: 2.0043
Training Epoch: 75 [47104/50176]	Loss: 1.8857
Training Epoch: 75 [48128/50176]	Loss: 2.0007
Training Epoch: 75 [49152/50176]	Loss: 1.9901
Training Epoch: 75 [50176/50176]	Loss: 1.9527
2022-12-06 02:39:39.635 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:39:39,645 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.69 energy=505.49
2022-12-05 21:39:39,646 [ZeusDataLoader(train)] Up to epoch 76: time=3773.13, energy=560441.88, cost=610369.84
2022-12-05 21:39:39,646 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:39:39,646 [ZeusDataLoader(train)] Expected next epoch: time=3821.48, energy=567730.15, cost=618244.16
2022-12-05 21:39:39,647 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 0.0023, Accuracy: 0.3887
2022-12-05 21:39:39,837 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:39:39,838 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:39:39.852 [ZeusMonitor] Monitor started.
2022-12-06 02:39:39.852 [ZeusMonitor] Running indefinitely. 2022-12-06 02:39:39.853 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:39:39.853 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e77+gpu0.power.log
2022-12-05 21:40:23,954 [ZeusDataLoader(train)] train epoch 77 done: time=44.30 energy=6746.28
2022-12-05 21:40:23,958 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 1.8561
Training Epoch: 76 [2048/50176]	Loss: 1.9766
Training Epoch: 76 [3072/50176]	Loss: 1.8807
Training Epoch: 76 [4096/50176]	Loss: 1.8633
Training Epoch: 76 [5120/50176]	Loss: 1.9181
Training Epoch: 76 [6144/50176]	Loss: 1.9613
Training Epoch: 76 [7168/50176]	Loss: 1.9439
Training Epoch: 76 [8192/50176]	Loss: 1.8460
Training Epoch: 76 [9216/50176]	Loss: 1.8991
Training Epoch: 76 [10240/50176]	Loss: 1.9449
Training Epoch: 76 [11264/50176]	Loss: 1.9032
Training Epoch: 76 [12288/50176]	Loss: 1.9787
Training Epoch: 76 [13312/50176]	Loss: 1.8976
Training Epoch: 76 [14336/50176]	Loss: 1.9692
Training Epoch: 76 [15360/50176]	Loss: 1.9763
Training Epoch: 76 [16384/50176]	Loss: 1.8743
Training Epoch: 76 [17408/50176]	Loss: 1.9751
Training Epoch: 76 [18432/50176]	Loss: 1.8823
Training Epoch: 76 [19456/50176]	Loss: 1.8667
Training Epoch: 76 [20480/50176]	Loss: 2.0116
Training Epoch: 76 [21504/50176]	Loss: 1.9327
Training Epoch: 76 [22528/50176]	Loss: 1.9862
Training Epoch: 76 [23552/50176]	Loss: 1.9377
Training Epoch: 76 [24576/50176]	Loss: 1.8897
Training Epoch: 76 [25600/50176]	Loss: 1.9974
Training Epoch: 76 [26624/50176]	Loss: 1.9375
Training Epoch: 76 [27648/50176]	Loss: 1.9817
Training Epoch: 76 [28672/50176]	Loss: 1.9240
Training Epoch: 76 [29696/50176]	Loss: 1.9568
Training Epoch: 76 [30720/50176]	Loss: 1.9945
Training Epoch: 76 [31744/50176]	Loss: 1.9821
Training Epoch: 76 [32768/50176]	Loss: 1.9820
Training Epoch: 76 [33792/50176]	Loss: 2.0075
Training Epoch: 76 [34816/50176]	Loss: 1.9559
Training Epoch: 76 [35840/50176]	Loss: 1.9579
Training Epoch: 76 [36864/50176]	Loss: 1.8292
Training Epoch: 76 [37888/50176]	Loss: 1.9145
Training Epoch: 76 [38912/50176]	Loss: 1.9743
Training Epoch: 76 [39936/50176]	Loss: 1.9491
Training Epoch: 76 [40960/50176]	Loss: 2.0005
Training Epoch: 76 [41984/50176]	Loss: 1.9800
Training Epoch: 76 [43008/50176]	Loss: 1.9534
Training Epoch: 76 [44032/50176]	Loss: 1.9918
Training Epoch: 76 [45056/50176]	Loss: 1.9715
Training Epoch: 76 [46080/50176]	Loss: 1.9068
Training Epoch: 76 [47104/50176]	Loss: 1.9312
Training Epoch: 76 [48128/50176]	Loss: 1.9226
Training Epoch: 76 [49152/50176]	Loss: 1.9368
Training Epoch: 76 [50176/50176]	Loss: 1.9832
2022-12-06 02:40:27.706 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:40:27,762 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.80 energy=521.23
2022-12-05 21:40:27,763 [ZeusDataLoader(train)] Up to epoch 77: time=3821.23, energy=567709.39, cost=618211.95
2022-12-05 21:40:27,763 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:40:27,763 [ZeusDataLoader(train)] Expected next epoch: time=3869.57, energy=574997.66, cost=626086.26
2022-12-05 21:40:27,764 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0023, Accuracy: 0.3925
2022-12-05 21:40:27,976 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:40:27,977 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:40:27.979 [ZeusMonitor] Monitor started.
2022-12-06 02:40:27.979 [ZeusMonitor] Running indefinitely. 2022-12-06 02:40:27.979 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:40:27.979 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e78+gpu0.power.log
2022-12-05 21:41:12,082 [ZeusDataLoader(train)] train epoch 78 done: time=44.31 energy=6757.26
2022-12-05 21:41:12,085 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 1.8585
Training Epoch: 77 [2048/50176]	Loss: 1.9921
Training Epoch: 77 [3072/50176]	Loss: 1.8578
Training Epoch: 77 [4096/50176]	Loss: 1.9090
Training Epoch: 77 [5120/50176]	Loss: 1.9193
Training Epoch: 77 [6144/50176]	Loss: 1.8179
Training Epoch: 77 [7168/50176]	Loss: 1.8756
Training Epoch: 77 [8192/50176]	Loss: 1.8508
Training Epoch: 77 [9216/50176]	Loss: 1.9467
Training Epoch: 77 [10240/50176]	Loss: 1.9999
Training Epoch: 77 [11264/50176]	Loss: 1.8093
Training Epoch: 77 [12288/50176]	Loss: 1.8692
Training Epoch: 77 [13312/50176]	Loss: 1.9347
Training Epoch: 77 [14336/50176]	Loss: 1.9187
Training Epoch: 77 [15360/50176]	Loss: 1.9229
Training Epoch: 77 [16384/50176]	Loss: 1.9963
Training Epoch: 77 [17408/50176]	Loss: 1.9674
Training Epoch: 77 [18432/50176]	Loss: 1.9151
Training Epoch: 77 [19456/50176]	Loss: 1.9617
Training Epoch: 77 [20480/50176]	Loss: 1.8339
Training Epoch: 77 [21504/50176]	Loss: 1.8297
Training Epoch: 77 [22528/50176]	Loss: 1.8578
Training Epoch: 77 [23552/50176]	Loss: 1.9085
Training Epoch: 77 [24576/50176]	Loss: 1.9026
Training Epoch: 77 [25600/50176]	Loss: 1.9502
Training Epoch: 77 [26624/50176]	Loss: 1.8398
Training Epoch: 77 [27648/50176]	Loss: 1.8972
Training Epoch: 77 [28672/50176]	Loss: 1.9562
Training Epoch: 77 [29696/50176]	Loss: 1.9027
Training Epoch: 77 [30720/50176]	Loss: 1.9689
Training Epoch: 77 [31744/50176]	Loss: 1.9840
Training Epoch: 77 [32768/50176]	Loss: 1.9510
Training Epoch: 77 [33792/50176]	Loss: 1.9157
Training Epoch: 77 [34816/50176]	Loss: 1.9942
Training Epoch: 77 [35840/50176]	Loss: 1.9810
Training Epoch: 77 [36864/50176]	Loss: 1.9565
Training Epoch: 77 [37888/50176]	Loss: 1.9870
Training Epoch: 77 [38912/50176]	Loss: 1.9029
Training Epoch: 77 [39936/50176]	Loss: 1.9506
Training Epoch: 77 [40960/50176]	Loss: 1.9040
Training Epoch: 77 [41984/50176]	Loss: 2.0130
Training Epoch: 77 [43008/50176]	Loss: 1.9390
Training Epoch: 77 [44032/50176]	Loss: 1.9935
Training Epoch: 77 [45056/50176]	Loss: 1.8782
Training Epoch: 77 [46080/50176]	Loss: 1.9231
Training Epoch: 77 [47104/50176]	Loss: 1.8889
Training Epoch: 77 [48128/50176]	Loss: 1.9811
Training Epoch: 77 [49152/50176]	Loss: 1.9437
Training Epoch: 77 [50176/50176]	Loss: 2.0251
2022-12-06 02:41:15.839 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:41:15,850 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.76 energy=521.37
2022-12-05 21:41:15,851 [ZeusDataLoader(train)] Up to epoch 78: time=3869.29, energy=574988.02, cost=626057.08
2022-12-05 21:41:15,851 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:41:15,851 [ZeusDataLoader(train)] Expected next epoch: time=3917.64, energy=582276.29, cost=633931.39
2022-12-05 21:41:15,852 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0023, Accuracy: 0.3936
2022-12-05 21:41:15,995 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:41:15,995 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:41:15.997 [ZeusMonitor] Monitor started.
2022-12-06 02:41:15.997 [ZeusMonitor] Running indefinitely. 2022-12-06 02:41:15.997 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:41:15.997 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e79+gpu0.power.log
2022-12-05 21:42:00,254 [ZeusDataLoader(train)] train epoch 79 done: time=44.39 energy=6769.46
2022-12-05 21:42:00,258 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 1.8626
Training Epoch: 78 [2048/50176]	Loss: 1.8581
Training Epoch: 78 [3072/50176]	Loss: 1.9142
Training Epoch: 78 [4096/50176]	Loss: 1.9371
Training Epoch: 78 [5120/50176]	Loss: 1.8686
Training Epoch: 78 [6144/50176]	Loss: 1.8895
Training Epoch: 78 [7168/50176]	Loss: 1.9343
Training Epoch: 78 [8192/50176]	Loss: 1.9502
Training Epoch: 78 [9216/50176]	Loss: 1.8910
Training Epoch: 78 [10240/50176]	Loss: 1.9543
Training Epoch: 78 [11264/50176]	Loss: 1.8587
Training Epoch: 78 [12288/50176]	Loss: 1.8334
Training Epoch: 78 [13312/50176]	Loss: 1.9423
Training Epoch: 78 [14336/50176]	Loss: 1.9046
Training Epoch: 78 [15360/50176]	Loss: 1.8664
Training Epoch: 78 [16384/50176]	Loss: 1.9212
Training Epoch: 78 [17408/50176]	Loss: 1.9672
Training Epoch: 78 [18432/50176]	Loss: 1.9421
Training Epoch: 78 [19456/50176]	Loss: 1.8443
Training Epoch: 78 [20480/50176]	Loss: 1.9012
Training Epoch: 78 [21504/50176]	Loss: 1.9780
Training Epoch: 78 [22528/50176]	Loss: 1.9385
Training Epoch: 78 [23552/50176]	Loss: 1.9187
Training Epoch: 78 [24576/50176]	Loss: 1.9970
Training Epoch: 78 [25600/50176]	Loss: 1.9769
Training Epoch: 78 [26624/50176]	Loss: 1.9335
Training Epoch: 78 [27648/50176]	Loss: 1.9124
Training Epoch: 78 [28672/50176]	Loss: 1.7996
Training Epoch: 78 [29696/50176]	Loss: 1.9624
Training Epoch: 78 [30720/50176]	Loss: 1.9251
Training Epoch: 78 [31744/50176]	Loss: 1.8867
Training Epoch: 78 [32768/50176]	Loss: 1.9357
Training Epoch: 78 [33792/50176]	Loss: 1.9789
Training Epoch: 78 [34816/50176]	Loss: 1.9427
Training Epoch: 78 [35840/50176]	Loss: 1.8158
Training Epoch: 78 [36864/50176]	Loss: 1.9662
Training Epoch: 78 [37888/50176]	Loss: 1.9609
Training Epoch: 78 [38912/50176]	Loss: 1.9157
Training Epoch: 78 [39936/50176]	Loss: 1.9176
Training Epoch: 78 [40960/50176]	Loss: 1.9132
Training Epoch: 78 [41984/50176]	Loss: 1.7733
Training Epoch: 78 [43008/50176]	Loss: 1.8945
Training Epoch: 78 [44032/50176]	Loss: 1.8074
Training Epoch: 78 [45056/50176]	Loss: 1.9595
Training Epoch: 78 [46080/50176]	Loss: 1.8029
Training Epoch: 78 [47104/50176]	Loss: 1.9390
Training Epoch: 78 [48128/50176]	Loss: 1.8896
Training Epoch: 78 [49152/50176]	Loss: 1.9486
Training Epoch: 78 [50176/50176]	Loss: 1.8940
2022-12-06 02:42:03.975 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:42:03,987 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.72 energy=520.27
2022-12-05 21:42:03,987 [ZeusDataLoader(train)] Up to epoch 79: time=3917.41, energy=582277.75, cost=633911.91
2022-12-05 21:42:03,987 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:42:03,987 [ZeusDataLoader(train)] Expected next epoch: time=3965.75, energy=589566.01, cost=641786.22
2022-12-05 21:42:03,988 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 0.0023, Accuracy: 0.3973
2022-12-05 21:42:04,158 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:42:04,159 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:42:04.160 [ZeusMonitor] Monitor started.
2022-12-06 02:42:04.160 [ZeusMonitor] Running indefinitely. 2022-12-06 02:42:04.160 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:42:04.161 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e80+gpu0.power.log
2022-12-05 21:42:48,399 [ZeusDataLoader(train)] train epoch 80 done: time=44.40 energy=6753.72
2022-12-05 21:42:48,403 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 1.8132
Training Epoch: 79 [2048/50176]	Loss: 1.8843
Training Epoch: 79 [3072/50176]	Loss: 1.9389
Training Epoch: 79 [4096/50176]	Loss: 1.8372
Training Epoch: 79 [5120/50176]	Loss: 1.8882
Training Epoch: 79 [6144/50176]	Loss: 1.8280
Training Epoch: 79 [7168/50176]	Loss: 1.8796
Training Epoch: 79 [8192/50176]	Loss: 1.9314
Training Epoch: 79 [9216/50176]	Loss: 1.8861
Training Epoch: 79 [10240/50176]	Loss: 1.8366
Training Epoch: 79 [11264/50176]	Loss: 1.9655
Training Epoch: 79 [12288/50176]	Loss: 1.9145
Training Epoch: 79 [13312/50176]	Loss: 1.8977
Training Epoch: 79 [14336/50176]	Loss: 1.8652
Training Epoch: 79 [15360/50176]	Loss: 1.7528
Training Epoch: 79 [16384/50176]	Loss: 1.9537
Training Epoch: 79 [17408/50176]	Loss: 1.9030
Training Epoch: 79 [18432/50176]	Loss: 1.8354
Training Epoch: 79 [19456/50176]	Loss: 1.9336
Training Epoch: 79 [20480/50176]	Loss: 1.8678
Training Epoch: 79 [21504/50176]	Loss: 1.9532
Training Epoch: 79 [22528/50176]	Loss: 1.8513
Training Epoch: 79 [23552/50176]	Loss: 1.8868
Training Epoch: 79 [24576/50176]	Loss: 1.8672
Training Epoch: 79 [25600/50176]	Loss: 1.8262
Training Epoch: 79 [26624/50176]	Loss: 1.9799
Training Epoch: 79 [27648/50176]	Loss: 1.8827
Training Epoch: 79 [28672/50176]	Loss: 1.8866
Training Epoch: 79 [29696/50176]	Loss: 1.8998
Training Epoch: 79 [30720/50176]	Loss: 1.8558
Training Epoch: 79 [31744/50176]	Loss: 1.9135
Training Epoch: 79 [32768/50176]	Loss: 1.9131
Training Epoch: 79 [33792/50176]	Loss: 1.8483
Training Epoch: 79 [34816/50176]	Loss: 1.8763
Training Epoch: 79 [35840/50176]	Loss: 1.9375
Training Epoch: 79 [36864/50176]	Loss: 1.9246
Training Epoch: 79 [37888/50176]	Loss: 1.9064
Training Epoch: 79 [38912/50176]	Loss: 1.9677
Training Epoch: 79 [39936/50176]	Loss: 1.8406
Training Epoch: 79 [40960/50176]	Loss: 1.9135
Training Epoch: 79 [41984/50176]	Loss: 1.9029
Training Epoch: 79 [43008/50176]	Loss: 2.0081
Training Epoch: 79 [44032/50176]	Loss: 1.8970
Training Epoch: 79 [45056/50176]	Loss: 1.7565
Training Epoch: 79 [46080/50176]	Loss: 1.9273
Training Epoch: 79 [47104/50176]	Loss: 1.9009
Training Epoch: 79 [48128/50176]	Loss: 1.9121
Training Epoch: 79 [49152/50176]	Loss: 1.8393
Training Epoch: 79 [50176/50176]	Loss: 1.9360
2022-12-06 02:42:52.207 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:42:52,229 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.82 energy=538.45
2022-12-05 21:42:52,229 [ZeusDataLoader(train)] Up to epoch 80: time=3965.63, energy=589569.92, cost=641777.21
2022-12-05 21:42:52,229 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:42:52,229 [ZeusDataLoader(train)] Expected next epoch: time=4013.97, energy=596858.18, cost=649651.52
2022-12-05 21:42:52,230 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 0.0023, Accuracy: 0.3992
2022-12-05 21:42:52,415 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:42:52,416 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:42:52.420 [ZeusMonitor] Monitor started.
2022-12-06 02:42:52.420 [ZeusMonitor] Running indefinitely. 2022-12-06 02:42:52.420 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:42:52.420 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e81+gpu0.power.log
2022-12-05 21:43:36,531 [ZeusDataLoader(train)] train epoch 81 done: time=44.29 energy=6747.91
2022-12-05 21:43:36,534 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 1.8497
Training Epoch: 80 [2048/50176]	Loss: 1.9302
Training Epoch: 80 [3072/50176]	Loss: 1.8437
Training Epoch: 80 [4096/50176]	Loss: 1.8815
Training Epoch: 80 [5120/50176]	Loss: 1.9396
Training Epoch: 80 [6144/50176]	Loss: 1.8123
Training Epoch: 80 [7168/50176]	Loss: 1.8493
Training Epoch: 80 [8192/50176]	Loss: 1.8336
Training Epoch: 80 [9216/50176]	Loss: 1.9468
Training Epoch: 80 [10240/50176]	Loss: 1.8511
Training Epoch: 80 [11264/50176]	Loss: 1.8653
Training Epoch: 80 [12288/50176]	Loss: 1.8462
Training Epoch: 80 [13312/50176]	Loss: 1.8248
Training Epoch: 80 [14336/50176]	Loss: 1.8145
Training Epoch: 80 [15360/50176]	Loss: 1.8744
Training Epoch: 80 [16384/50176]	Loss: 1.9467
Training Epoch: 80 [17408/50176]	Loss: 1.9129
Training Epoch: 80 [18432/50176]	Loss: 1.8266
Training Epoch: 80 [19456/50176]	Loss: 1.8707
Training Epoch: 80 [20480/50176]	Loss: 1.9292
Training Epoch: 80 [21504/50176]	Loss: 1.8504
Training Epoch: 80 [22528/50176]	Loss: 1.8893
Training Epoch: 80 [23552/50176]	Loss: 1.8665
Training Epoch: 80 [24576/50176]	Loss: 1.8926
Training Epoch: 80 [25600/50176]	Loss: 1.8790
Training Epoch: 80 [26624/50176]	Loss: 1.8410
Training Epoch: 80 [27648/50176]	Loss: 1.9035
Training Epoch: 80 [28672/50176]	Loss: 1.8721
Training Epoch: 80 [29696/50176]	Loss: 1.8419
Training Epoch: 80 [30720/50176]	Loss: 1.8827
Training Epoch: 80 [31744/50176]	Loss: 1.8836
Training Epoch: 80 [32768/50176]	Loss: 1.8383
Training Epoch: 80 [33792/50176]	Loss: 1.8683
Training Epoch: 80 [34816/50176]	Loss: 1.7970
Training Epoch: 80 [35840/50176]	Loss: 1.8037
Training Epoch: 80 [36864/50176]	Loss: 1.9375
Training Epoch: 80 [37888/50176]	Loss: 1.8440
Training Epoch: 80 [38912/50176]	Loss: 1.8701
Training Epoch: 80 [39936/50176]	Loss: 1.9248
Training Epoch: 80 [40960/50176]	Loss: 1.8630
Training Epoch: 80 [41984/50176]	Loss: 1.9882
Training Epoch: 80 [43008/50176]	Loss: 1.8984
Training Epoch: 80 [44032/50176]	Loss: 1.9730
Training Epoch: 80 [45056/50176]	Loss: 1.8794
Training Epoch: 80 [46080/50176]	Loss: 1.9496
Training Epoch: 80 [47104/50176]	Loss: 1.8739
Training Epoch: 80 [48128/50176]	Loss: 1.8910
Training Epoch: 80 [49152/50176]	Loss: 1.8757
Training Epoch: 80 [50176/50176]	Loss: 1.9847
2022-12-06 02:43:40.282 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:43:40,293 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.75 energy=524.70
2022-12-05 21:43:40,294 [ZeusDataLoader(train)] Up to epoch 81: time=4013.67, energy=596842.53, cost=649617.28
2022-12-05 21:43:40,294 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:43:40,294 [ZeusDataLoader(train)] Expected next epoch: time=4062.01, energy=604130.79, cost=657491.59
2022-12-05 21:43:40,295 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0023, Accuracy: 0.3987
2022-12-05 21:43:40,482 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:43:40,483 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:43:40.484 [ZeusMonitor] Monitor started.
2022-12-06 02:43:40.485 [ZeusMonitor] Running indefinitely. 2022-12-06 02:43:40.485 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:43:40.485 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e82+gpu0.power.log
2022-12-05 21:44:24,624 [ZeusDataLoader(train)] train epoch 82 done: time=44.32 energy=6752.14
2022-12-05 21:44:24,627 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 1.8207
Training Epoch: 81 [2048/50176]	Loss: 1.8348
Training Epoch: 81 [3072/50176]	Loss: 1.8410
Training Epoch: 81 [4096/50176]	Loss: 1.8648
Training Epoch: 81 [5120/50176]	Loss: 1.9638
Training Epoch: 81 [6144/50176]	Loss: 1.8603
Training Epoch: 81 [7168/50176]	Loss: 1.9255
Training Epoch: 81 [8192/50176]	Loss: 1.8310
Training Epoch: 81 [9216/50176]	Loss: 1.8297
Training Epoch: 81 [10240/50176]	Loss: 1.8534
Training Epoch: 81 [11264/50176]	Loss: 1.8551
Training Epoch: 81 [12288/50176]	Loss: 1.8089
Training Epoch: 81 [13312/50176]	Loss: 1.8399
Training Epoch: 81 [14336/50176]	Loss: 1.7878
Training Epoch: 81 [15360/50176]	Loss: 1.8310
Training Epoch: 81 [16384/50176]	Loss: 1.7987
Training Epoch: 81 [17408/50176]	Loss: 1.9084
Training Epoch: 81 [18432/50176]	Loss: 1.8290
Training Epoch: 81 [19456/50176]	Loss: 1.8587
Training Epoch: 81 [20480/50176]	Loss: 1.8635
Training Epoch: 81 [21504/50176]	Loss: 1.7612
Training Epoch: 81 [22528/50176]	Loss: 1.9072
Training Epoch: 81 [23552/50176]	Loss: 1.7745
Training Epoch: 81 [24576/50176]	Loss: 1.7997
Training Epoch: 81 [25600/50176]	Loss: 1.8873
Training Epoch: 81 [26624/50176]	Loss: 1.9123
Training Epoch: 81 [27648/50176]	Loss: 1.8279
Training Epoch: 81 [28672/50176]	Loss: 1.8428
Training Epoch: 81 [29696/50176]	Loss: 1.9131
Training Epoch: 81 [30720/50176]	Loss: 1.8422
Training Epoch: 81 [31744/50176]	Loss: 1.8532
Training Epoch: 81 [32768/50176]	Loss: 1.8621
Training Epoch: 81 [33792/50176]	Loss: 1.8925
Training Epoch: 81 [34816/50176]	Loss: 1.7558
Training Epoch: 81 [35840/50176]	Loss: 1.9677
Training Epoch: 81 [36864/50176]	Loss: 1.8795
Training Epoch: 81 [37888/50176]	Loss: 1.9430
Training Epoch: 81 [38912/50176]	Loss: 1.8814
Training Epoch: 81 [39936/50176]	Loss: 1.8666
Training Epoch: 81 [40960/50176]	Loss: 1.9050
Training Epoch: 81 [41984/50176]	Loss: 1.7913
Training Epoch: 81 [43008/50176]	Loss: 1.8715
Training Epoch: 81 [44032/50176]	Loss: 1.9046
Training Epoch: 81 [45056/50176]	Loss: 1.8819
Training Epoch: 81 [46080/50176]	Loss: 1.9198
Training Epoch: 81 [47104/50176]	Loss: 1.9239
Training Epoch: 81 [48128/50176]	Loss: 1.9326
Training Epoch: 81 [49152/50176]	Loss: 1.8719
Training Epoch: 81 [50176/50176]	Loss: 1.8325
2022-12-06 02:44:28.389 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:44:28,410 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.77 energy=525.13
2022-12-05 21:44:28,410 [ZeusDataLoader(train)] Up to epoch 82: time=4061.76, energy=604119.79, cost=657464.14
2022-12-05 21:44:28,410 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:44:28,410 [ZeusDataLoader(train)] Expected next epoch: time=4110.11, energy=611408.05, cost=665338.45
2022-12-05 21:44:28,411 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 0.0023, Accuracy: 0.3993
2022-12-05 21:44:28,592 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:44:28,593 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:44:28.595 [ZeusMonitor] Monitor started.
2022-12-06 02:44:28.595 [ZeusMonitor] Running indefinitely. 2022-12-06 02:44:28.595 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:44:28.595 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e83+gpu0.power.log
2022-12-05 21:45:12,679 [ZeusDataLoader(train)] train epoch 83 done: time=44.26 energy=6746.53
2022-12-05 21:45:12,682 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 1.7956
Training Epoch: 82 [2048/50176]	Loss: 1.8662
Training Epoch: 82 [3072/50176]	Loss: 1.8560
Training Epoch: 82 [4096/50176]	Loss: 1.7804
Training Epoch: 82 [5120/50176]	Loss: 1.7977
Training Epoch: 82 [6144/50176]	Loss: 1.8380
Training Epoch: 82 [7168/50176]	Loss: 1.8314
Training Epoch: 82 [8192/50176]	Loss: 1.8580
Training Epoch: 82 [9216/50176]	Loss: 1.8474
Training Epoch: 82 [10240/50176]	Loss: 1.8481
Training Epoch: 82 [11264/50176]	Loss: 1.8259
Training Epoch: 82 [12288/50176]	Loss: 1.7587
Training Epoch: 82 [13312/50176]	Loss: 1.8198
Training Epoch: 82 [14336/50176]	Loss: 1.8068
Training Epoch: 82 [15360/50176]	Loss: 1.8746
Training Epoch: 82 [16384/50176]	Loss: 1.8875
Training Epoch: 82 [17408/50176]	Loss: 1.7979
Training Epoch: 82 [18432/50176]	Loss: 1.8542
Training Epoch: 82 [19456/50176]	Loss: 1.8238
Training Epoch: 82 [20480/50176]	Loss: 1.9616
Training Epoch: 82 [21504/50176]	Loss: 1.8006
Training Epoch: 82 [22528/50176]	Loss: 1.7483
Training Epoch: 82 [23552/50176]	Loss: 1.8587
Training Epoch: 82 [24576/50176]	Loss: 1.8662
Training Epoch: 82 [25600/50176]	Loss: 1.8473
Training Epoch: 82 [26624/50176]	Loss: 1.9147
Training Epoch: 82 [27648/50176]	Loss: 1.8596
Training Epoch: 82 [28672/50176]	Loss: 1.8176
Training Epoch: 82 [29696/50176]	Loss: 1.7381
Training Epoch: 82 [30720/50176]	Loss: 1.8589
Training Epoch: 82 [31744/50176]	Loss: 1.8398
Training Epoch: 82 [32768/50176]	Loss: 1.8450
Training Epoch: 82 [33792/50176]	Loss: 1.8492
Training Epoch: 82 [34816/50176]	Loss: 1.8120
Training Epoch: 82 [35840/50176]	Loss: 1.8383
Training Epoch: 82 [36864/50176]	Loss: 1.9107
Training Epoch: 82 [37888/50176]	Loss: 1.8653
Training Epoch: 82 [38912/50176]	Loss: 1.8541
Training Epoch: 82 [39936/50176]	Loss: 1.8547
Training Epoch: 82 [40960/50176]	Loss: 1.9548
Training Epoch: 82 [41984/50176]	Loss: 1.8261
Training Epoch: 82 [43008/50176]	Loss: 1.9268
Training Epoch: 82 [44032/50176]	Loss: 1.8338
Training Epoch: 82 [45056/50176]	Loss: 1.8483
Training Epoch: 82 [46080/50176]	Loss: 1.8867
Training Epoch: 82 [47104/50176]	Loss: 1.7672
Training Epoch: 82 [48128/50176]	Loss: 1.8856
Training Epoch: 82 [49152/50176]	Loss: 1.9135
Training Epoch: 82 [50176/50176]	Loss: 1.8060
2022-12-06 02:45:16.440 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:45:16,473 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.78 energy=536.38
2022-12-05 21:45:16,473 [ZeusDataLoader(train)] Up to epoch 83: time=4109.81, energy=611402.70, cost=665309.31
2022-12-05 21:45:16,473 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:45:16,473 [ZeusDataLoader(train)] Expected next epoch: time=4158.15, energy=618690.96, cost=673183.62
2022-12-05 21:45:16,474 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 0.0023, Accuracy: 0.4023
2022-12-05 21:45:16,653 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:45:16,654 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:45:16.668 [ZeusMonitor] Monitor started.
2022-12-06 02:45:16.668 [ZeusMonitor] Running indefinitely. 2022-12-06 02:45:16.668 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:45:16.668 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e84+gpu0.power.log
2022-12-05 21:46:00,791 [ZeusDataLoader(train)] train epoch 84 done: time=44.31 energy=6746.08
2022-12-05 21:46:00,794 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 1.7864
Training Epoch: 83 [2048/50176]	Loss: 1.7945
Training Epoch: 83 [3072/50176]	Loss: 1.8075
Training Epoch: 83 [4096/50176]	Loss: 1.9156
Training Epoch: 83 [5120/50176]	Loss: 1.8379
Training Epoch: 83 [6144/50176]	Loss: 1.7647
Training Epoch: 83 [7168/50176]	Loss: 1.8592
Training Epoch: 83 [8192/50176]	Loss: 1.8038
Training Epoch: 83 [9216/50176]	Loss: 1.8429
Training Epoch: 83 [10240/50176]	Loss: 1.8411
Training Epoch: 83 [11264/50176]	Loss: 1.7999
Training Epoch: 83 [12288/50176]	Loss: 1.8892
Training Epoch: 83 [13312/50176]	Loss: 1.8140
Training Epoch: 83 [14336/50176]	Loss: 1.8383
Training Epoch: 83 [15360/50176]	Loss: 1.7836
Training Epoch: 83 [16384/50176]	Loss: 1.8015
Training Epoch: 83 [17408/50176]	Loss: 1.8549
Training Epoch: 83 [18432/50176]	Loss: 1.8494
Training Epoch: 83 [19456/50176]	Loss: 1.8423
Training Epoch: 83 [20480/50176]	Loss: 1.9380
Training Epoch: 83 [21504/50176]	Loss: 1.8395
Training Epoch: 83 [22528/50176]	Loss: 1.7669
Training Epoch: 83 [23552/50176]	Loss: 1.7801
Training Epoch: 83 [24576/50176]	Loss: 1.7637
Training Epoch: 83 [25600/50176]	Loss: 1.8636
Training Epoch: 83 [26624/50176]	Loss: 1.8693
Training Epoch: 83 [27648/50176]	Loss: 1.8803
Training Epoch: 83 [28672/50176]	Loss: 1.7969
Training Epoch: 83 [29696/50176]	Loss: 1.8249
Training Epoch: 83 [30720/50176]	Loss: 1.8387
Training Epoch: 83 [31744/50176]	Loss: 1.8931
Training Epoch: 83 [32768/50176]	Loss: 1.8129
Training Epoch: 83 [33792/50176]	Loss: 1.8563
Training Epoch: 83 [34816/50176]	Loss: 1.7509
Training Epoch: 83 [35840/50176]	Loss: 1.8308
Training Epoch: 83 [36864/50176]	Loss: 1.7950
Training Epoch: 83 [37888/50176]	Loss: 1.7841
Training Epoch: 83 [38912/50176]	Loss: 1.7778
Training Epoch: 83 [39936/50176]	Loss: 1.8981
Training Epoch: 83 [40960/50176]	Loss: 1.8371
Training Epoch: 83 [41984/50176]	Loss: 1.8417
Training Epoch: 83 [43008/50176]	Loss: 1.8152
Training Epoch: 83 [44032/50176]	Loss: 1.7698
Training Epoch: 83 [45056/50176]	Loss: 1.8655
Training Epoch: 83 [46080/50176]	Loss: 1.7917
Training Epoch: 83 [47104/50176]	Loss: 1.8484
Training Epoch: 83 [48128/50176]	Loss: 1.8587
Training Epoch: 83 [49152/50176]	Loss: 1.8274
Training Epoch: 83 [50176/50176]	Loss: 1.8386
2022-12-06 02:46:04.582 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:46:04,618 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.82 energy=536.13
2022-12-05 21:46:04,618 [ZeusDataLoader(train)] Up to epoch 84: time=4157.93, energy=618684.92, cost=673161.28
2022-12-05 21:46:04,619 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:46:04,619 [ZeusDataLoader(train)] Expected next epoch: time=4206.27, energy=625973.18, cost=681035.60
2022-12-05 21:46:04,620 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 0.0023, Accuracy: 0.4022
2022-12-05 21:46:04,807 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:46:04,808 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:46:04.821 [ZeusMonitor] Monitor started.
2022-12-06 02:46:04.822 [ZeusMonitor] Running indefinitely. 2022-12-06 02:46:04.822 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:46:04.822 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e85+gpu0.power.log
2022-12-05 21:46:49,022 [ZeusDataLoader(train)] train epoch 85 done: time=44.39 energy=6749.40
2022-12-05 21:46:49,025 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 1.6974
Training Epoch: 84 [2048/50176]	Loss: 1.8257
Training Epoch: 84 [3072/50176]	Loss: 1.8749
Training Epoch: 84 [4096/50176]	Loss: 1.7766
Training Epoch: 84 [5120/50176]	Loss: 1.9151
Training Epoch: 84 [6144/50176]	Loss: 1.8237
Training Epoch: 84 [7168/50176]	Loss: 1.7958
Training Epoch: 84 [8192/50176]	Loss: 1.8172
Training Epoch: 84 [9216/50176]	Loss: 1.8182
Training Epoch: 84 [10240/50176]	Loss: 1.7987
Training Epoch: 84 [11264/50176]	Loss: 1.8056
Training Epoch: 84 [12288/50176]	Loss: 1.8709
Training Epoch: 84 [13312/50176]	Loss: 1.7733
Training Epoch: 84 [14336/50176]	Loss: 1.9585
Training Epoch: 84 [15360/50176]	Loss: 1.7101
Training Epoch: 84 [16384/50176]	Loss: 1.7900
Training Epoch: 84 [17408/50176]	Loss: 1.8029
Training Epoch: 84 [18432/50176]	Loss: 1.7974
Training Epoch: 84 [19456/50176]	Loss: 1.8177
Training Epoch: 84 [20480/50176]	Loss: 1.8437
Training Epoch: 84 [21504/50176]	Loss: 1.7668
Training Epoch: 84 [22528/50176]	Loss: 1.8390
Training Epoch: 84 [23552/50176]	Loss: 1.7681
Training Epoch: 84 [24576/50176]	Loss: 1.7726
Training Epoch: 84 [25600/50176]	Loss: 1.7942
Training Epoch: 84 [26624/50176]	Loss: 1.8720
Training Epoch: 84 [27648/50176]	Loss: 1.8197
Training Epoch: 84 [28672/50176]	Loss: 1.8597
Training Epoch: 84 [29696/50176]	Loss: 1.8806
Training Epoch: 84 [30720/50176]	Loss: 1.8040
Training Epoch: 84 [31744/50176]	Loss: 1.6767
Training Epoch: 84 [32768/50176]	Loss: 1.8200
Training Epoch: 84 [33792/50176]	Loss: 1.8713
Training Epoch: 84 [34816/50176]	Loss: 1.8245
Training Epoch: 84 [35840/50176]	Loss: 1.8093
Training Epoch: 84 [36864/50176]	Loss: 1.8630
Training Epoch: 84 [37888/50176]	Loss: 1.7770
Training Epoch: 84 [38912/50176]	Loss: 1.8126
Training Epoch: 84 [39936/50176]	Loss: 1.7387
Training Epoch: 84 [40960/50176]	Loss: 1.7784
Training Epoch: 84 [41984/50176]	Loss: 1.8618
Training Epoch: 84 [43008/50176]	Loss: 1.8082
Training Epoch: 84 [44032/50176]	Loss: 1.8366
Training Epoch: 84 [45056/50176]	Loss: 1.8105
Training Epoch: 84 [46080/50176]	Loss: 1.8000
Training Epoch: 84 [47104/50176]	Loss: 1.8418
Training Epoch: 84 [48128/50176]	Loss: 1.8511
Training Epoch: 84 [49152/50176]	Loss: 1.8653
Training Epoch: 84 [50176/50176]	Loss: 1.7623
2022-12-06 02:46:52.796 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:46:52,809 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.77 energy=518.23
2022-12-05 21:46:52,809 [ZeusDataLoader(train)] Up to epoch 85: time=4206.10, energy=625952.56, cost=681009.89
2022-12-05 21:46:52,809 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:46:52,809 [ZeusDataLoader(train)] Expected next epoch: time=4254.44, energy=633240.82, cost=688884.21
2022-12-05 21:46:52,810 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 0.0023, Accuracy: 0.4075
2022-12-05 21:46:52,958 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:46:52,958 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:46:52.962 [ZeusMonitor] Monitor started.
2022-12-06 02:46:52.962 [ZeusMonitor] Running indefinitely. 2022-12-06 02:46:52.962 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:46:52.962 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e86+gpu0.power.log
2022-12-05 21:47:37,110 [ZeusDataLoader(train)] train epoch 86 done: time=44.29 energy=6756.73
2022-12-05 21:47:37,114 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 1.7838
Training Epoch: 85 [2048/50176]	Loss: 1.7661
Training Epoch: 85 [3072/50176]	Loss: 1.8048
Training Epoch: 85 [4096/50176]	Loss: 1.7078
Training Epoch: 85 [5120/50176]	Loss: 1.7755
Training Epoch: 85 [6144/50176]	Loss: 1.7285
Training Epoch: 85 [7168/50176]	Loss: 1.8204
Training Epoch: 85 [8192/50176]	Loss: 1.8127
Training Epoch: 85 [9216/50176]	Loss: 1.8685
Training Epoch: 85 [10240/50176]	Loss: 1.8274
Training Epoch: 85 [11264/50176]	Loss: 1.8477
Training Epoch: 85 [12288/50176]	Loss: 1.8694
Training Epoch: 85 [13312/50176]	Loss: 1.7604
Training Epoch: 85 [14336/50176]	Loss: 1.7453
Training Epoch: 85 [15360/50176]	Loss: 1.7685
Training Epoch: 85 [16384/50176]	Loss: 1.7217
Training Epoch: 85 [17408/50176]	Loss: 1.7813
Training Epoch: 85 [18432/50176]	Loss: 1.7479
Training Epoch: 85 [19456/50176]	Loss: 1.7474
Training Epoch: 85 [20480/50176]	Loss: 1.8447
Training Epoch: 85 [21504/50176]	Loss: 1.7812
Training Epoch: 85 [22528/50176]	Loss: 1.7778
Training Epoch: 85 [23552/50176]	Loss: 1.7700
Training Epoch: 85 [24576/50176]	Loss: 1.8436
Training Epoch: 85 [25600/50176]	Loss: 1.7231
Training Epoch: 85 [26624/50176]	Loss: 1.8152
Training Epoch: 85 [27648/50176]	Loss: 1.7709
Training Epoch: 85 [28672/50176]	Loss: 1.7948
Training Epoch: 85 [29696/50176]	Loss: 1.8053
Training Epoch: 85 [30720/50176]	Loss: 1.7981
Training Epoch: 85 [31744/50176]	Loss: 1.7821
Training Epoch: 85 [32768/50176]	Loss: 1.7431
Training Epoch: 85 [33792/50176]	Loss: 1.8437
Training Epoch: 85 [34816/50176]	Loss: 1.7785
Training Epoch: 85 [35840/50176]	Loss: 1.8375
Training Epoch: 85 [36864/50176]	Loss: 1.7170
Training Epoch: 85 [37888/50176]	Loss: 1.7535
Training Epoch: 85 [38912/50176]	Loss: 1.8945
Training Epoch: 85 [39936/50176]	Loss: 1.9537
Training Epoch: 85 [40960/50176]	Loss: 1.7848
Training Epoch: 85 [41984/50176]	Loss: 1.7541
Training Epoch: 85 [43008/50176]	Loss: 1.8643
Training Epoch: 85 [44032/50176]	Loss: 1.8757
Training Epoch: 85 [45056/50176]	Loss: 1.7421
Training Epoch: 85 [46080/50176]	Loss: 1.8479
Training Epoch: 85 [47104/50176]	Loss: 1.7621
Training Epoch: 85 [48128/50176]	Loss: 1.7550
Training Epoch: 85 [49152/50176]	Loss: 1.9038
Training Epoch: 85 [50176/50176]	Loss: 1.8289
2022-12-06 02:47:40.806 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:47:40,822 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.70 energy=518.33
2022-12-05 21:47:40,822 [ZeusDataLoader(train)] Up to epoch 86: time=4254.09, energy=633227.62, cost=688846.69
2022-12-05 21:47:40,822 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:47:40,822 [ZeusDataLoader(train)] Expected next epoch: time=4302.43, energy=640515.88, cost=696721.00
2022-12-05 21:47:40,823 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 0.0023, Accuracy: 0.4044
2022-12-05 21:47:41,005 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:47:41,006 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:47:41.020 [ZeusMonitor] Monitor started.
2022-12-06 02:47:41.020 [ZeusMonitor] Running indefinitely. 2022-12-06 02:47:41.020 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:47:41.020 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e87+gpu0.power.log
2022-12-05 21:48:25,106 [ZeusDataLoader(train)] train epoch 87 done: time=44.27 energy=6753.22
2022-12-05 21:48:25,110 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 1.7685
Training Epoch: 86 [2048/50176]	Loss: 1.7348
Training Epoch: 86 [3072/50176]	Loss: 1.8507
Training Epoch: 86 [4096/50176]	Loss: 1.8129
Training Epoch: 86 [5120/50176]	Loss: 1.8057
Training Epoch: 86 [6144/50176]	Loss: 1.8182
Training Epoch: 86 [7168/50176]	Loss: 1.7500
Training Epoch: 86 [8192/50176]	Loss: 1.7889
Training Epoch: 86 [9216/50176]	Loss: 1.7679
Training Epoch: 86 [10240/50176]	Loss: 1.7266
Training Epoch: 86 [11264/50176]	Loss: 1.7285
Training Epoch: 86 [12288/50176]	Loss: 1.6938
Training Epoch: 86 [13312/50176]	Loss: 1.7162
Training Epoch: 86 [14336/50176]	Loss: 1.7205
Training Epoch: 86 [15360/50176]	Loss: 1.8789
Training Epoch: 86 [16384/50176]	Loss: 1.6967
Training Epoch: 86 [17408/50176]	Loss: 1.8516
Training Epoch: 86 [18432/50176]	Loss: 1.7354
Training Epoch: 86 [19456/50176]	Loss: 1.8026
Training Epoch: 86 [20480/50176]	Loss: 1.7839
Training Epoch: 86 [21504/50176]	Loss: 1.8154
Training Epoch: 86 [22528/50176]	Loss: 1.8223
Training Epoch: 86 [23552/50176]	Loss: 1.7962
Training Epoch: 86 [24576/50176]	Loss: 1.8171
Training Epoch: 86 [25600/50176]	Loss: 1.8350
Training Epoch: 86 [26624/50176]	Loss: 1.8911
Training Epoch: 86 [27648/50176]	Loss: 1.8232
Training Epoch: 86 [28672/50176]	Loss: 1.8672
Training Epoch: 86 [29696/50176]	Loss: 1.7936
Training Epoch: 86 [30720/50176]	Loss: 1.8060
Training Epoch: 86 [31744/50176]	Loss: 1.8035
Training Epoch: 86 [32768/50176]	Loss: 1.7800
Training Epoch: 86 [33792/50176]	Loss: 1.7775
Training Epoch: 86 [34816/50176]	Loss: 1.6720
Training Epoch: 86 [35840/50176]	Loss: 1.8244
Training Epoch: 86 [36864/50176]	Loss: 1.7821
Training Epoch: 86 [37888/50176]	Loss: 1.7946
Training Epoch: 86 [38912/50176]	Loss: 1.7699
Training Epoch: 86 [39936/50176]	Loss: 1.7676
Training Epoch: 86 [40960/50176]	Loss: 1.7709
Training Epoch: 86 [41984/50176]	Loss: 1.7534
Training Epoch: 86 [43008/50176]	Loss: 1.8059
Training Epoch: 86 [44032/50176]	Loss: 1.7672
Training Epoch: 86 [45056/50176]	Loss: 1.7766
Training Epoch: 86 [46080/50176]	Loss: 1.7765
Training Epoch: 86 [47104/50176]	Loss: 1.8018
Training Epoch: 86 [48128/50176]	Loss: 1.6954
Training Epoch: 86 [49152/50176]	Loss: 1.8365
Training Epoch: 86 [50176/50176]	Loss: 1.8602
2022-12-06 02:48:28.868 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:48:28,913 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.79 energy=534.48
2022-12-05 21:48:28,913 [ZeusDataLoader(train)] Up to epoch 87: time=4302.16, energy=640515.32, cost=696696.55
2022-12-05 21:48:28,913 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:48:28,913 [ZeusDataLoader(train)] Expected next epoch: time=4350.50, energy=647803.58, cost=704570.86
2022-12-05 21:48:28,914 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 0.0023, Accuracy: 0.4089
2022-12-05 21:48:29,061 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:48:29,062 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:48:29.065 [ZeusMonitor] Monitor started.
2022-12-06 02:48:29.066 [ZeusMonitor] Running indefinitely. 2022-12-06 02:48:29.066 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:48:29.066 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e88+gpu0.power.log
2022-12-05 21:49:13,211 [ZeusDataLoader(train)] train epoch 88 done: time=44.29 energy=6745.30
2022-12-05 21:49:13,214 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 1.7384
Training Epoch: 87 [2048/50176]	Loss: 1.6997
Training Epoch: 87 [3072/50176]	Loss: 1.7465
Training Epoch: 87 [4096/50176]	Loss: 1.7924
Training Epoch: 87 [5120/50176]	Loss: 1.7977
Training Epoch: 87 [6144/50176]	Loss: 1.7943
Training Epoch: 87 [7168/50176]	Loss: 1.6435
Training Epoch: 87 [8192/50176]	Loss: 1.7150
Training Epoch: 87 [9216/50176]	Loss: 1.7314
Training Epoch: 87 [10240/50176]	Loss: 1.8252
Training Epoch: 87 [11264/50176]	Loss: 1.7957
Training Epoch: 87 [12288/50176]	Loss: 1.7195
Training Epoch: 87 [13312/50176]	Loss: 1.7534
Training Epoch: 87 [14336/50176]	Loss: 1.7037
Training Epoch: 87 [15360/50176]	Loss: 1.7716
Training Epoch: 87 [16384/50176]	Loss: 1.8098
Training Epoch: 87 [17408/50176]	Loss: 1.8225
Training Epoch: 87 [18432/50176]	Loss: 1.7862
Training Epoch: 87 [19456/50176]	Loss: 1.7534
Training Epoch: 87 [20480/50176]	Loss: 1.7058
Training Epoch: 87 [21504/50176]	Loss: 1.7961
Training Epoch: 87 [22528/50176]	Loss: 1.7353
Training Epoch: 87 [23552/50176]	Loss: 1.8015
Training Epoch: 87 [24576/50176]	Loss: 1.8367
Training Epoch: 87 [25600/50176]	Loss: 1.8433
Training Epoch: 87 [26624/50176]	Loss: 1.6670
Training Epoch: 87 [27648/50176]	Loss: 1.6680
Training Epoch: 87 [28672/50176]	Loss: 1.7442
Training Epoch: 87 [29696/50176]	Loss: 1.8347
Training Epoch: 87 [30720/50176]	Loss: 1.7557
Training Epoch: 87 [31744/50176]	Loss: 1.7447
Training Epoch: 87 [32768/50176]	Loss: 1.7730
Training Epoch: 87 [33792/50176]	Loss: 1.7748
Training Epoch: 87 [34816/50176]	Loss: 1.7938
Training Epoch: 87 [35840/50176]	Loss: 1.8861
Training Epoch: 87 [36864/50176]	Loss: 1.7173
Training Epoch: 87 [37888/50176]	Loss: 1.7677
Training Epoch: 87 [38912/50176]	Loss: 1.7158
Training Epoch: 87 [39936/50176]	Loss: 1.7882
Training Epoch: 87 [40960/50176]	Loss: 1.8132
Training Epoch: 87 [41984/50176]	Loss: 1.7300
Training Epoch: 87 [43008/50176]	Loss: 1.8214
Training Epoch: 87 [44032/50176]	Loss: 1.7322
Training Epoch: 87 [45056/50176]	Loss: 1.7398
Training Epoch: 87 [46080/50176]	Loss: 1.8063
Training Epoch: 87 [47104/50176]	Loss: 1.8438
Training Epoch: 87 [48128/50176]	Loss: 1.8119
Training Epoch: 87 [49152/50176]	Loss: 1.7496
Training Epoch: 87 [50176/50176]	Loss: 1.7623
2022-12-06 02:49:17.025 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:49:17,047 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.82 energy=531.37
2022-12-05 21:49:17,047 [ZeusDataLoader(train)] Up to epoch 88: time=4350.27, energy=647791.98, cost=704544.83
2022-12-05 21:49:17,048 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:49:17,048 [ZeusDataLoader(train)] Expected next epoch: time=4398.62, energy=655080.25, cost=712419.14
2022-12-05 21:49:17,049 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0023, Accuracy: 0.4072
2022-12-05 21:49:17,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:49:17,238 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:49:17.240 [ZeusMonitor] Monitor started.
2022-12-06 02:49:17.240 [ZeusMonitor] Running indefinitely. 2022-12-06 02:49:17.240 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:49:17.240 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e89+gpu0.power.log
2022-12-05 21:50:01,329 [ZeusDataLoader(train)] train epoch 89 done: time=44.27 energy=6747.81
2022-12-05 21:50:01,333 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 1.7682
Training Epoch: 88 [2048/50176]	Loss: 1.6948
Training Epoch: 88 [3072/50176]	Loss: 1.6613
Training Epoch: 88 [4096/50176]	Loss: 1.7293
Training Epoch: 88 [5120/50176]	Loss: 1.7083
Training Epoch: 88 [6144/50176]	Loss: 1.7636
Training Epoch: 88 [7168/50176]	Loss: 1.6717
Training Epoch: 88 [8192/50176]	Loss: 1.6959
Training Epoch: 88 [9216/50176]	Loss: 1.7613
Training Epoch: 88 [10240/50176]	Loss: 1.6960
Training Epoch: 88 [11264/50176]	Loss: 1.7329
Training Epoch: 88 [12288/50176]	Loss: 1.7918
Training Epoch: 88 [13312/50176]	Loss: 1.7137
Training Epoch: 88 [14336/50176]	Loss: 1.7361
Training Epoch: 88 [15360/50176]	Loss: 1.7736
Training Epoch: 88 [16384/50176]	Loss: 1.7120
Training Epoch: 88 [17408/50176]	Loss: 1.7341
Training Epoch: 88 [18432/50176]	Loss: 1.7792
Training Epoch: 88 [19456/50176]	Loss: 1.6765
Training Epoch: 88 [20480/50176]	Loss: 1.7420
Training Epoch: 88 [21504/50176]	Loss: 1.6618
Training Epoch: 88 [22528/50176]	Loss: 1.7467
Training Epoch: 88 [23552/50176]	Loss: 1.7931
Training Epoch: 88 [24576/50176]	Loss: 1.7106
Training Epoch: 88 [25600/50176]	Loss: 1.6764
Training Epoch: 88 [26624/50176]	Loss: 1.7764
Training Epoch: 88 [27648/50176]	Loss: 1.7891
Training Epoch: 88 [28672/50176]	Loss: 1.7950
Training Epoch: 88 [29696/50176]	Loss: 1.6417
Training Epoch: 88 [30720/50176]	Loss: 1.7772
Training Epoch: 88 [31744/50176]	Loss: 1.8077
Training Epoch: 88 [32768/50176]	Loss: 1.8068
Training Epoch: 88 [33792/50176]	Loss: 1.8485
Training Epoch: 88 [34816/50176]	Loss: 1.6865
Training Epoch: 88 [35840/50176]	Loss: 1.7565
Training Epoch: 88 [36864/50176]	Loss: 1.7891
Training Epoch: 88 [37888/50176]	Loss: 1.7491
Training Epoch: 88 [38912/50176]	Loss: 1.7654
Training Epoch: 88 [39936/50176]	Loss: 1.7785
Training Epoch: 88 [40960/50176]	Loss: 1.7339
Training Epoch: 88 [41984/50176]	Loss: 1.7772
Training Epoch: 88 [43008/50176]	Loss: 1.7974
Training Epoch: 88 [44032/50176]	Loss: 1.7565
Training Epoch: 88 [45056/50176]	Loss: 1.8047
Training Epoch: 88 [46080/50176]	Loss: 1.7935
Training Epoch: 88 [47104/50176]	Loss: 1.7683
Training Epoch: 88 [48128/50176]	Loss: 1.7394
Training Epoch: 88 [49152/50176]	Loss: 1.7739
Training Epoch: 88 [50176/50176]	Loss: 1.8453
2022-12-06 02:50:05.070 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:50:05,095 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.75 energy=516.90
2022-12-05 21:50:05,095 [ZeusDataLoader(train)] Up to epoch 89: time=4398.30, energy=655056.69, cost=712379.44
2022-12-05 21:50:05,096 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:50:05,096 [ZeusDataLoader(train)] Expected next epoch: time=4446.64, energy=662344.96, cost=720253.75
2022-12-05 21:50:05,097 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 0.0023, Accuracy: 0.4078
2022-12-05 21:50:05,249 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:50:05,250 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:50:05.254 [ZeusMonitor] Monitor started.
2022-12-06 02:50:05.254 [ZeusMonitor] Running indefinitely. 2022-12-06 02:50:05.254 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:50:05.254 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e90+gpu0.power.log
2022-12-05 21:50:49,506 [ZeusDataLoader(train)] train epoch 90 done: time=44.40 energy=6763.99
2022-12-05 21:50:49,510 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 1.7133
Training Epoch: 89 [2048/50176]	Loss: 1.6892
Training Epoch: 89 [3072/50176]	Loss: 1.6898
Training Epoch: 89 [4096/50176]	Loss: 1.7199
Training Epoch: 89 [5120/50176]	Loss: 1.7124
Training Epoch: 89 [6144/50176]	Loss: 1.7307
Training Epoch: 89 [7168/50176]	Loss: 1.6708
Training Epoch: 89 [8192/50176]	Loss: 1.7881
Training Epoch: 89 [9216/50176]	Loss: 1.7531
Training Epoch: 89 [10240/50176]	Loss: 1.7745
Training Epoch: 89 [11264/50176]	Loss: 1.6764
Training Epoch: 89 [12288/50176]	Loss: 1.7358
Training Epoch: 89 [13312/50176]	Loss: 1.8213
Training Epoch: 89 [14336/50176]	Loss: 1.7812
Training Epoch: 89 [15360/50176]	Loss: 1.7247
Training Epoch: 89 [16384/50176]	Loss: 1.7645
Training Epoch: 89 [17408/50176]	Loss: 1.7343
Training Epoch: 89 [18432/50176]	Loss: 1.6710
Training Epoch: 89 [19456/50176]	Loss: 1.7000
Training Epoch: 89 [20480/50176]	Loss: 1.6608
Training Epoch: 89 [21504/50176]	Loss: 1.7370
Training Epoch: 89 [22528/50176]	Loss: 1.6770
Training Epoch: 89 [23552/50176]	Loss: 1.8381
Training Epoch: 89 [24576/50176]	Loss: 1.8251
Training Epoch: 89 [25600/50176]	Loss: 1.6965
Training Epoch: 89 [26624/50176]	Loss: 1.7995
Training Epoch: 89 [27648/50176]	Loss: 1.6687
Training Epoch: 89 [28672/50176]	Loss: 1.6867
Training Epoch: 89 [29696/50176]	Loss: 1.6898
Training Epoch: 89 [30720/50176]	Loss: 1.7052
Training Epoch: 89 [31744/50176]	Loss: 1.7647
Training Epoch: 89 [32768/50176]	Loss: 1.7781
Training Epoch: 89 [33792/50176]	Loss: 1.6766
Training Epoch: 89 [34816/50176]	Loss: 1.7587
Training Epoch: 89 [35840/50176]	Loss: 1.7191
Training Epoch: 89 [36864/50176]	Loss: 1.6528
Training Epoch: 89 [37888/50176]	Loss: 1.7839
Training Epoch: 89 [38912/50176]	Loss: 1.8305
Training Epoch: 89 [39936/50176]	Loss: 1.7455
Training Epoch: 89 [40960/50176]	Loss: 1.7354
Training Epoch: 89 [41984/50176]	Loss: 1.7673
Training Epoch: 89 [43008/50176]	Loss: 1.7353
Training Epoch: 89 [44032/50176]	Loss: 1.7584
Training Epoch: 89 [45056/50176]	Loss: 1.6813
Training Epoch: 89 [46080/50176]	Loss: 1.7806
Training Epoch: 89 [47104/50176]	Loss: 1.7634
Training Epoch: 89 [48128/50176]	Loss: 1.7916
Training Epoch: 89 [49152/50176]	Loss: 1.7485
Training Epoch: 89 [50176/50176]	Loss: 1.7924
2022-12-06 02:50:53.273 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:50:53,330 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.81 energy=537.80
2022-12-05 21:50:53,330 [ZeusDataLoader(train)] Up to epoch 90: time=4446.51, energy=662358.49, cost=720248.96
2022-12-05 21:50:53,330 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:50:53,330 [ZeusDataLoader(train)] Expected next epoch: time=4494.86, energy=669646.75, cost=728123.27
2022-12-05 21:50:53,331 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0023, Accuracy: 0.4089
2022-12-05 21:50:53,519 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:50:53,520 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:50:53.522 [ZeusMonitor] Monitor started.
2022-12-06 02:50:53.522 [ZeusMonitor] Running indefinitely. 2022-12-06 02:50:53.522 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:50:53.522 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e91+gpu0.power.log
2022-12-05 21:51:37,601 [ZeusDataLoader(train)] train epoch 91 done: time=44.26 energy=6745.20
2022-12-05 21:51:37,605 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 1.7510
Training Epoch: 90 [2048/50176]	Loss: 1.6720
Training Epoch: 90 [3072/50176]	Loss: 1.7211
Training Epoch: 90 [4096/50176]	Loss: 1.6446
Training Epoch: 90 [5120/50176]	Loss: 1.6194
Training Epoch: 90 [6144/50176]	Loss: 1.6554
Training Epoch: 90 [7168/50176]	Loss: 1.6848
Training Epoch: 90 [8192/50176]	Loss: 1.7865
Training Epoch: 90 [9216/50176]	Loss: 1.6988
Training Epoch: 90 [10240/50176]	Loss: 1.7990
Training Epoch: 90 [11264/50176]	Loss: 1.6277
Training Epoch: 90 [12288/50176]	Loss: 1.7536
Training Epoch: 90 [13312/50176]	Loss: 1.6823
Training Epoch: 90 [14336/50176]	Loss: 1.7951
Training Epoch: 90 [15360/50176]	Loss: 1.6147
Training Epoch: 90 [16384/50176]	Loss: 1.6943
Training Epoch: 90 [17408/50176]	Loss: 1.7532
Training Epoch: 90 [18432/50176]	Loss: 1.7389
Training Epoch: 90 [19456/50176]	Loss: 1.6919
Training Epoch: 90 [20480/50176]	Loss: 1.6968
Training Epoch: 90 [21504/50176]	Loss: 1.7710
Training Epoch: 90 [22528/50176]	Loss: 1.7297
Training Epoch: 90 [23552/50176]	Loss: 1.7138
Training Epoch: 90 [24576/50176]	Loss: 1.7333
Training Epoch: 90 [25600/50176]	Loss: 1.7596
Training Epoch: 90 [26624/50176]	Loss: 1.7610
Training Epoch: 90 [27648/50176]	Loss: 1.7396
Training Epoch: 90 [28672/50176]	Loss: 1.7666
Training Epoch: 90 [29696/50176]	Loss: 1.7412
Training Epoch: 90 [30720/50176]	Loss: 1.7099
Training Epoch: 90 [31744/50176]	Loss: 1.7602
Training Epoch: 90 [32768/50176]	Loss: 1.7057
Training Epoch: 90 [33792/50176]	Loss: 1.7736
Training Epoch: 90 [34816/50176]	Loss: 1.8109
Training Epoch: 90 [35840/50176]	Loss: 1.7852
Training Epoch: 90 [36864/50176]	Loss: 1.6746
Training Epoch: 90 [37888/50176]	Loss: 1.7297
Training Epoch: 90 [38912/50176]	Loss: 1.7870
Training Epoch: 90 [39936/50176]	Loss: 1.8098
Training Epoch: 90 [40960/50176]	Loss: 1.7430
Training Epoch: 90 [41984/50176]	Loss: 1.7176
Training Epoch: 90 [43008/50176]	Loss: 1.6524
Training Epoch: 90 [44032/50176]	Loss: 1.8002
Training Epoch: 90 [45056/50176]	Loss: 1.6887
Training Epoch: 90 [46080/50176]	Loss: 1.6897
Training Epoch: 90 [47104/50176]	Loss: 1.7827
Training Epoch: 90 [48128/50176]	Loss: 1.7514
Training Epoch: 90 [49152/50176]	Loss: 1.7215
Training Epoch: 90 [50176/50176]	Loss: 1.6638
2022-12-06 02:51:41.294 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:51:41,306 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.69 energy=503.61
2022-12-05 21:51:41,307 [ZeusDataLoader(train)] Up to epoch 91: time=4494.46, energy=669607.30, cost=728069.26
2022-12-05 21:51:41,307 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:51:41,307 [ZeusDataLoader(train)] Expected next epoch: time=4542.81, energy=676895.56, cost=735943.58
2022-12-05 21:51:41,308 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 0.0023, Accuracy: 0.4108
2022-12-05 21:51:41,470 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:51:41,471 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:51:41.473 [ZeusMonitor] Monitor started.
2022-12-06 02:51:41.473 [ZeusMonitor] Running indefinitely. 2022-12-06 02:51:41.473 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:51:41.473 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e92+gpu0.power.log
2022-12-05 21:52:25,710 [ZeusDataLoader(train)] train epoch 92 done: time=44.39 energy=6775.48
2022-12-05 21:52:25,714 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 1.6349
Training Epoch: 91 [2048/50176]	Loss: 1.7084
Training Epoch: 91 [3072/50176]	Loss: 1.7648
Training Epoch: 91 [4096/50176]	Loss: 1.6384
Training Epoch: 91 [5120/50176]	Loss: 1.7359
Training Epoch: 91 [6144/50176]	Loss: 1.7131
Training Epoch: 91 [7168/50176]	Loss: 1.6877
Training Epoch: 91 [8192/50176]	Loss: 1.7949
Training Epoch: 91 [9216/50176]	Loss: 1.6761
Training Epoch: 91 [10240/50176]	Loss: 1.6666
Training Epoch: 91 [11264/50176]	Loss: 1.6885
Training Epoch: 91 [12288/50176]	Loss: 1.6503
Training Epoch: 91 [13312/50176]	Loss: 1.6560
Training Epoch: 91 [14336/50176]	Loss: 1.6861
Training Epoch: 91 [15360/50176]	Loss: 1.7071
Training Epoch: 91 [16384/50176]	Loss: 1.8103
Training Epoch: 91 [17408/50176]	Loss: 1.6884
Training Epoch: 91 [18432/50176]	Loss: 1.6596
Training Epoch: 91 [19456/50176]	Loss: 1.6825
Training Epoch: 91 [20480/50176]	Loss: 1.7531
Training Epoch: 91 [21504/50176]	Loss: 1.6625
Training Epoch: 91 [22528/50176]	Loss: 1.7090
Training Epoch: 91 [23552/50176]	Loss: 1.7758
Training Epoch: 91 [24576/50176]	Loss: 1.6864
Training Epoch: 91 [25600/50176]	Loss: 1.7092
Training Epoch: 91 [26624/50176]	Loss: 1.6982
Training Epoch: 91 [27648/50176]	Loss: 1.6622
Training Epoch: 91 [28672/50176]	Loss: 1.6590
Training Epoch: 91 [29696/50176]	Loss: 1.7189
Training Epoch: 91 [30720/50176]	Loss: 1.8428
Training Epoch: 91 [31744/50176]	Loss: 1.6693
Training Epoch: 91 [32768/50176]	Loss: 1.7163
Training Epoch: 91 [33792/50176]	Loss: 1.6762
Training Epoch: 91 [34816/50176]	Loss: 1.7333
Training Epoch: 91 [35840/50176]	Loss: 1.6849
Training Epoch: 91 [36864/50176]	Loss: 1.7081
Training Epoch: 91 [37888/50176]	Loss: 1.7932
Training Epoch: 91 [38912/50176]	Loss: 1.7223
Training Epoch: 91 [39936/50176]	Loss: 1.7541
Training Epoch: 91 [40960/50176]	Loss: 1.7282
Training Epoch: 91 [41984/50176]	Loss: 1.7402
Training Epoch: 91 [43008/50176]	Loss: 1.7357
Training Epoch: 91 [44032/50176]	Loss: 1.6840
Training Epoch: 91 [45056/50176]	Loss: 1.7565
Training Epoch: 91 [46080/50176]	Loss: 1.6954
Training Epoch: 91 [47104/50176]	Loss: 1.7001
Training Epoch: 91 [48128/50176]	Loss: 1.7478
Training Epoch: 91 [49152/50176]	Loss: 1.6628
Training Epoch: 91 [50176/50176]	Loss: 1.7099
2022-12-06 02:52:29.597 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:52:29,676 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.94 energy=549.00
2022-12-05 21:52:29,676 [ZeusDataLoader(train)] Up to epoch 92: time=4542.79, energy=676931.78, cost=735960.43
2022-12-05 21:52:29,680 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:52:29,681 [ZeusDataLoader(train)] Expected next epoch: time=4591.14, energy=684220.04, cost=743834.74
2022-12-05 21:52:29,681 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 0.0023, Accuracy: 0.4140
2022-12-05 21:52:30,140 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:52:30,145 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:52:30.170 [ZeusMonitor] Monitor started.
2022-12-06 02:52:30.170 [ZeusMonitor] Running indefinitely. 2022-12-06 02:52:30.170 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:52:30.170 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e93+gpu0.power.log
2022-12-05 21:53:14,862 [ZeusDataLoader(train)] train epoch 93 done: time=45.17 energy=6800.66
2022-12-05 21:53:14,865 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 1.7607
Training Epoch: 92 [2048/50176]	Loss: 1.7321
Training Epoch: 92 [3072/50176]	Loss: 1.6130
Training Epoch: 92 [4096/50176]	Loss: 1.6475
Training Epoch: 92 [5120/50176]	Loss: 1.6846
Training Epoch: 92 [6144/50176]	Loss: 1.5984
Training Epoch: 92 [7168/50176]	Loss: 1.6927
Training Epoch: 92 [8192/50176]	Loss: 1.6447
Training Epoch: 92 [9216/50176]	Loss: 1.6825
Training Epoch: 92 [10240/50176]	Loss: 1.6949
Training Epoch: 92 [11264/50176]	Loss: 1.7288
Training Epoch: 92 [12288/50176]	Loss: 1.7278
Training Epoch: 92 [13312/50176]	Loss: 1.7186
Training Epoch: 92 [14336/50176]	Loss: 1.7020
Training Epoch: 92 [15360/50176]	Loss: 1.7175
Training Epoch: 92 [16384/50176]	Loss: 1.6317
Training Epoch: 92 [17408/50176]	Loss: 1.6441
Training Epoch: 92 [18432/50176]	Loss: 1.6922
Training Epoch: 92 [19456/50176]	Loss: 1.6975
Training Epoch: 92 [20480/50176]	Loss: 1.7295
Training Epoch: 92 [21504/50176]	Loss: 1.6460
Training Epoch: 92 [22528/50176]	Loss: 1.6692
Training Epoch: 92 [23552/50176]	Loss: 1.7326
Training Epoch: 92 [24576/50176]	Loss: 1.6792
Training Epoch: 92 [25600/50176]	Loss: 1.6860
Training Epoch: 92 [26624/50176]	Loss: 1.7962
Training Epoch: 92 [27648/50176]	Loss: 1.6609
Training Epoch: 92 [28672/50176]	Loss: 1.7269
Training Epoch: 92 [29696/50176]	Loss: 1.6964
Training Epoch: 92 [30720/50176]	Loss: 1.6845
Training Epoch: 92 [31744/50176]	Loss: 1.6887
Training Epoch: 92 [32768/50176]	Loss: 1.7196
Training Epoch: 92 [33792/50176]	Loss: 1.6485
Training Epoch: 92 [34816/50176]	Loss: 1.6867
Training Epoch: 92 [35840/50176]	Loss: 1.7157
Training Epoch: 92 [36864/50176]	Loss: 1.7172
Training Epoch: 92 [37888/50176]	Loss: 1.6732
Training Epoch: 92 [38912/50176]	Loss: 1.7625
Training Epoch: 92 [39936/50176]	Loss: 1.7180
Training Epoch: 92 [40960/50176]	Loss: 1.7882
Training Epoch: 92 [41984/50176]	Loss: 1.7407
Training Epoch: 92 [43008/50176]	Loss: 1.7171
Training Epoch: 92 [44032/50176]	Loss: 1.6990
Training Epoch: 92 [45056/50176]	Loss: 1.7451
Training Epoch: 92 [46080/50176]	Loss: 1.8053
Training Epoch: 92 [47104/50176]	Loss: 1.7710
Training Epoch: 92 [48128/50176]	Loss: 1.7051
Training Epoch: 92 [49152/50176]	Loss: 1.7618
Training Epoch: 92 [50176/50176]	Loss: 1.7172
2022-12-06 02:53:18.610 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:53:18,638 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.76 energy=517.02
2022-12-05 21:53:18,638 [ZeusDataLoader(train)] Up to epoch 93: time=4591.73, energy=684249.47, cost=743901.19
2022-12-05 21:53:18,638 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:53:18,638 [ZeusDataLoader(train)] Expected next epoch: time=4640.08, energy=691537.73, cost=751775.50
2022-12-05 21:53:18,639 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0023, Accuracy: 0.4136
2022-12-05 21:53:18,816 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:53:18,817 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:53:18.818 [ZeusMonitor] Monitor started.
2022-12-06 02:53:18.818 [ZeusMonitor] Running indefinitely. 2022-12-06 02:53:18.818 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:53:18.818 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e94+gpu0.power.log
2022-12-05 21:54:02,949 [ZeusDataLoader(train)] train epoch 94 done: time=44.30 energy=6740.92
2022-12-05 21:54:02,952 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 1.6343
Training Epoch: 93 [2048/50176]	Loss: 1.6789
Training Epoch: 93 [3072/50176]	Loss: 1.7217
Training Epoch: 93 [4096/50176]	Loss: 1.6487
Training Epoch: 93 [5120/50176]	Loss: 1.7310
Training Epoch: 93 [6144/50176]	Loss: 1.6853
Training Epoch: 93 [7168/50176]	Loss: 1.6661
Training Epoch: 93 [8192/50176]	Loss: 1.6309
Training Epoch: 93 [9216/50176]	Loss: 1.6977
Training Epoch: 93 [10240/50176]	Loss: 1.5853
Training Epoch: 93 [11264/50176]	Loss: 1.6601
Training Epoch: 93 [12288/50176]	Loss: 1.6903
Training Epoch: 93 [13312/50176]	Loss: 1.6371
Training Epoch: 93 [14336/50176]	Loss: 1.7499
Training Epoch: 93 [15360/50176]	Loss: 1.7108
Training Epoch: 93 [16384/50176]	Loss: 1.6613
Training Epoch: 93 [17408/50176]	Loss: 1.6899
Training Epoch: 93 [18432/50176]	Loss: 1.6886
Training Epoch: 93 [19456/50176]	Loss: 1.6767
Training Epoch: 93 [20480/50176]	Loss: 1.6407
Training Epoch: 93 [21504/50176]	Loss: 1.6897
Training Epoch: 93 [22528/50176]	Loss: 1.6090
Training Epoch: 93 [23552/50176]	Loss: 1.6364
Training Epoch: 93 [24576/50176]	Loss: 1.6800
Training Epoch: 93 [25600/50176]	Loss: 1.6985
Training Epoch: 93 [26624/50176]	Loss: 1.6320
Training Epoch: 93 [27648/50176]	Loss: 1.6882
Training Epoch: 93 [28672/50176]	Loss: 1.6923
Training Epoch: 93 [29696/50176]	Loss: 1.7298
Training Epoch: 93 [30720/50176]	Loss: 1.7071
Training Epoch: 93 [31744/50176]	Loss: 1.6537
Training Epoch: 93 [32768/50176]	Loss: 1.6448
Training Epoch: 93 [33792/50176]	Loss: 1.7242
Training Epoch: 93 [34816/50176]	Loss: 1.7254
Training Epoch: 93 [35840/50176]	Loss: 1.6681
Training Epoch: 93 [36864/50176]	Loss: 1.6753
Training Epoch: 93 [37888/50176]	Loss: 1.6661
Training Epoch: 93 [38912/50176]	Loss: 1.6727
Training Epoch: 93 [39936/50176]	Loss: 1.6350
Training Epoch: 93 [40960/50176]	Loss: 1.7139
Training Epoch: 93 [41984/50176]	Loss: 1.7230
Training Epoch: 93 [43008/50176]	Loss: 1.8117
Training Epoch: 93 [44032/50176]	Loss: 1.6664
Training Epoch: 93 [45056/50176]	Loss: 1.6944
Training Epoch: 93 [46080/50176]	Loss: 1.6773
Training Epoch: 93 [47104/50176]	Loss: 1.7206
Training Epoch: 93 [48128/50176]	Loss: 1.5905
Training Epoch: 93 [49152/50176]	Loss: 1.7673
Training Epoch: 93 [50176/50176]	Loss: 1.6951
2022-12-06 02:54:06.663 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:54:06,672 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.71 energy=523.51
2022-12-05 21:54:06,672 [ZeusDataLoader(train)] Up to epoch 94: time=4639.74, energy=691513.90, cost=751734.52
2022-12-05 21:54:06,673 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:54:06,673 [ZeusDataLoader(train)] Expected next epoch: time=4688.09, energy=698802.16, cost=759608.84
2022-12-05 21:54:06,674 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 0.0023, Accuracy: 0.4146
2022-12-05 21:54:06,859 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:54:06,860 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:54:06.862 [ZeusMonitor] Monitor started.
2022-12-06 02:54:06.862 [ZeusMonitor] Running indefinitely. 2022-12-06 02:54:06.862 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:54:06.862 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e95+gpu0.power.log
2022-12-05 21:54:51,080 [ZeusDataLoader(train)] train epoch 95 done: time=44.40 energy=6769.01
2022-12-05 21:54:51,083 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 1.5868
Training Epoch: 94 [2048/50176]	Loss: 1.7080
Training Epoch: 94 [3072/50176]	Loss: 1.5380
Training Epoch: 94 [4096/50176]	Loss: 1.5912
Training Epoch: 94 [5120/50176]	Loss: 1.6199
Training Epoch: 94 [6144/50176]	Loss: 1.5774
Training Epoch: 94 [7168/50176]	Loss: 1.6389
Training Epoch: 94 [8192/50176]	Loss: 1.6356
Training Epoch: 94 [9216/50176]	Loss: 1.6789
Training Epoch: 94 [10240/50176]	Loss: 1.7712
Training Epoch: 94 [11264/50176]	Loss: 1.5978
Training Epoch: 94 [12288/50176]	Loss: 1.5912
Training Epoch: 94 [13312/50176]	Loss: 1.6768
Training Epoch: 94 [14336/50176]	Loss: 1.6815
Training Epoch: 94 [15360/50176]	Loss: 1.6752
Training Epoch: 94 [16384/50176]	Loss: 1.6708
Training Epoch: 94 [17408/50176]	Loss: 1.7072
Training Epoch: 94 [18432/50176]	Loss: 1.7608
Training Epoch: 94 [19456/50176]	Loss: 1.5968
Training Epoch: 94 [20480/50176]	Loss: 1.6820
Training Epoch: 94 [21504/50176]	Loss: 1.6401
Training Epoch: 94 [22528/50176]	Loss: 1.7497
Training Epoch: 94 [23552/50176]	Loss: 1.7024
Training Epoch: 94 [24576/50176]	Loss: 1.6450
Training Epoch: 94 [25600/50176]	Loss: 1.6070
Training Epoch: 94 [26624/50176]	Loss: 1.6997
Training Epoch: 94 [27648/50176]	Loss: 1.6516
Training Epoch: 94 [28672/50176]	Loss: 1.6891
Training Epoch: 94 [29696/50176]	Loss: 1.6964
Training Epoch: 94 [30720/50176]	Loss: 1.6633
Training Epoch: 94 [31744/50176]	Loss: 1.6567
Training Epoch: 94 [32768/50176]	Loss: 1.6341
Training Epoch: 94 [33792/50176]	Loss: 1.6032
Training Epoch: 94 [34816/50176]	Loss: 1.6527
Training Epoch: 94 [35840/50176]	Loss: 1.6844
Training Epoch: 94 [36864/50176]	Loss: 1.7759
Training Epoch: 94 [37888/50176]	Loss: 1.6241
Training Epoch: 94 [38912/50176]	Loss: 1.7543
Training Epoch: 94 [39936/50176]	Loss: 1.6711
Training Epoch: 94 [40960/50176]	Loss: 1.7687
Training Epoch: 94 [41984/50176]	Loss: 1.6918
Training Epoch: 94 [43008/50176]	Loss: 1.6037
Training Epoch: 94 [44032/50176]	Loss: 1.6770
Training Epoch: 94 [45056/50176]	Loss: 1.7566
Training Epoch: 94 [46080/50176]	Loss: 1.6879
Training Epoch: 94 [47104/50176]	Loss: 1.6464
Training Epoch: 94 [48128/50176]	Loss: 1.7099
Training Epoch: 94 [49152/50176]	Loss: 1.6148
Training Epoch: 94 [50176/50176]	Loss: 1.7798
2022-12-06 02:54:54.848 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:54:54,859 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.77 energy=517.62
2022-12-05 21:54:54,859 [ZeusDataLoader(train)] Up to epoch 95: time=4687.91, energy=698800.53, cost=759592.28
2022-12-05 21:54:54,859 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:54:54,859 [ZeusDataLoader(train)] Expected next epoch: time=4736.25, energy=706088.79, cost=767466.59
2022-12-05 21:54:54,860 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 0.0023, Accuracy: 0.4132
2022-12-05 21:54:55,009 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:54:55,010 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:54:55.014 [ZeusMonitor] Monitor started.
2022-12-06 02:54:55.014 [ZeusMonitor] Running indefinitely. 2022-12-06 02:54:55.014 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:54:55.014 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e96+gpu0.power.log
2022-12-05 21:55:39,197 [ZeusDataLoader(train)] train epoch 96 done: time=44.33 energy=6747.55
2022-12-05 21:55:39,200 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 1.6046
Training Epoch: 95 [2048/50176]	Loss: 1.5727
Training Epoch: 95 [3072/50176]	Loss: 1.6777
Training Epoch: 95 [4096/50176]	Loss: 1.6762
Training Epoch: 95 [5120/50176]	Loss: 1.6826
Training Epoch: 95 [6144/50176]	Loss: 1.5891
Training Epoch: 95 [7168/50176]	Loss: 1.6394
Training Epoch: 95 [8192/50176]	Loss: 1.6331
Training Epoch: 95 [9216/50176]	Loss: 1.6940
Training Epoch: 95 [10240/50176]	Loss: 1.6594
Training Epoch: 95 [11264/50176]	Loss: 1.5977
Training Epoch: 95 [12288/50176]	Loss: 1.5804
Training Epoch: 95 [13312/50176]	Loss: 1.6788
Training Epoch: 95 [14336/50176]	Loss: 1.7047
Training Epoch: 95 [15360/50176]	Loss: 1.6910
Training Epoch: 95 [16384/50176]	Loss: 1.6472
Training Epoch: 95 [17408/50176]	Loss: 1.6319
Training Epoch: 95 [18432/50176]	Loss: 1.6648
Training Epoch: 95 [19456/50176]	Loss: 1.6917
Training Epoch: 95 [20480/50176]	Loss: 1.6616
Training Epoch: 95 [21504/50176]	Loss: 1.5753
Training Epoch: 95 [22528/50176]	Loss: 1.6777
Training Epoch: 95 [23552/50176]	Loss: 1.5614
Training Epoch: 95 [24576/50176]	Loss: 1.6881
Training Epoch: 95 [25600/50176]	Loss: 1.6818
Training Epoch: 95 [26624/50176]	Loss: 1.6920
Training Epoch: 95 [27648/50176]	Loss: 1.5651
Training Epoch: 95 [28672/50176]	Loss: 1.6774
Training Epoch: 95 [29696/50176]	Loss: 1.6845
Training Epoch: 95 [30720/50176]	Loss: 1.6645
Training Epoch: 95 [31744/50176]	Loss: 1.7193
Training Epoch: 95 [32768/50176]	Loss: 1.6433
Training Epoch: 95 [33792/50176]	Loss: 1.6525
Training Epoch: 95 [34816/50176]	Loss: 1.6190
Training Epoch: 95 [35840/50176]	Loss: 1.6539
Training Epoch: 95 [36864/50176]	Loss: 1.5857
Training Epoch: 95 [37888/50176]	Loss: 1.6194
Training Epoch: 95 [38912/50176]	Loss: 1.6797
Training Epoch: 95 [39936/50176]	Loss: 1.7052
Training Epoch: 95 [40960/50176]	Loss: 1.6516
Training Epoch: 95 [41984/50176]	Loss: 1.7140
Training Epoch: 95 [43008/50176]	Loss: 1.6606
Training Epoch: 95 [44032/50176]	Loss: 1.5978
Training Epoch: 95 [45056/50176]	Loss: 1.7290
Training Epoch: 95 [46080/50176]	Loss: 1.6103
Training Epoch: 95 [47104/50176]	Loss: 1.6437
Training Epoch: 95 [48128/50176]	Loss: 1.6808
Training Epoch: 95 [49152/50176]	Loss: 1.6240
Training Epoch: 95 [50176/50176]	Loss: 1.6933
2022-12-06 02:55:42.967 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:55:43,012 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.80 energy=532.36
2022-12-05 21:55:43,012 [ZeusDataLoader(train)] Up to epoch 96: time=4736.04, energy=706080.43, cost=767443.64
2022-12-05 21:55:43,012 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:55:43,012 [ZeusDataLoader(train)] Expected next epoch: time=4784.38, energy=713368.70, cost=775317.95
2022-12-05 21:55:43,013 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 0.0023, Accuracy: 0.4130
2022-12-05 21:55:43,163 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:55:43,164 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:55:43.168 [ZeusMonitor] Monitor started.
2022-12-06 02:55:43.168 [ZeusMonitor] Running indefinitely. 2022-12-06 02:55:43.168 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:55:43.168 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e97+gpu0.power.log
2022-12-05 21:56:27,407 [ZeusDataLoader(train)] train epoch 97 done: time=44.38 energy=6762.54
2022-12-05 21:56:27,411 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 1.6580
Training Epoch: 96 [2048/50176]	Loss: 1.6302
Training Epoch: 96 [3072/50176]	Loss: 1.6163
Training Epoch: 96 [4096/50176]	Loss: 1.6112
Training Epoch: 96 [5120/50176]	Loss: 1.5917
Training Epoch: 96 [6144/50176]	Loss: 1.6448
Training Epoch: 96 [7168/50176]	Loss: 1.6630
Training Epoch: 96 [8192/50176]	Loss: 1.6084
Training Epoch: 96 [9216/50176]	Loss: 1.6948
Training Epoch: 96 [10240/50176]	Loss: 1.6398
Training Epoch: 96 [11264/50176]	Loss: 1.6554
Training Epoch: 96 [12288/50176]	Loss: 1.6757
Training Epoch: 96 [13312/50176]	Loss: 1.6619
Training Epoch: 96 [14336/50176]	Loss: 1.6927
Training Epoch: 96 [15360/50176]	Loss: 1.5535
Training Epoch: 96 [16384/50176]	Loss: 1.7204
Training Epoch: 96 [17408/50176]	Loss: 1.5861
Training Epoch: 96 [18432/50176]	Loss: 1.6627
Training Epoch: 96 [19456/50176]	Loss: 1.6254
Training Epoch: 96 [20480/50176]	Loss: 1.6299
Training Epoch: 96 [21504/50176]	Loss: 1.6753
Training Epoch: 96 [22528/50176]	Loss: 1.5424
Training Epoch: 96 [23552/50176]	Loss: 1.6559
Training Epoch: 96 [24576/50176]	Loss: 1.6086
Training Epoch: 96 [25600/50176]	Loss: 1.7032
Training Epoch: 96 [26624/50176]	Loss: 1.5065
Training Epoch: 96 [27648/50176]	Loss: 1.5703
Training Epoch: 96 [28672/50176]	Loss: 1.6247
Training Epoch: 96 [29696/50176]	Loss: 1.6363
Training Epoch: 96 [30720/50176]	Loss: 1.6535
Training Epoch: 96 [31744/50176]	Loss: 1.5176
Training Epoch: 96 [32768/50176]	Loss: 1.6364
Training Epoch: 96 [33792/50176]	Loss: 1.6227
Training Epoch: 96 [34816/50176]	Loss: 1.5817
Training Epoch: 96 [35840/50176]	Loss: 1.5967
Training Epoch: 96 [36864/50176]	Loss: 1.6122
Training Epoch: 96 [37888/50176]	Loss: 1.6654
Training Epoch: 96 [38912/50176]	Loss: 1.6710
Training Epoch: 96 [39936/50176]	Loss: 1.6775
Training Epoch: 96 [40960/50176]	Loss: 1.5699
Training Epoch: 96 [41984/50176]	Loss: 1.5705
Training Epoch: 96 [43008/50176]	Loss: 1.6857
Training Epoch: 96 [44032/50176]	Loss: 1.6398
Training Epoch: 96 [45056/50176]	Loss: 1.7341
Training Epoch: 96 [46080/50176]	Loss: 1.5965
Training Epoch: 96 [47104/50176]	Loss: 1.6599
Training Epoch: 96 [48128/50176]	Loss: 1.5828
Training Epoch: 96 [49152/50176]	Loss: 1.5817
Training Epoch: 96 [50176/50176]	Loss: 1.6836
2022-12-06 02:56:31.100 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:56:31,123 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.70 energy=522.80
2022-12-05 21:56:31,124 [ZeusDataLoader(train)] Up to epoch 97: time=4784.13, energy=713365.77, cost=775294.06
2022-12-05 21:56:31,124 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:56:31,124 [ZeusDataLoader(train)] Expected next epoch: time=4832.47, energy=720654.03, cost=783168.37
2022-12-05 21:56:31,125 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 0.0023, Accuracy: 0.4135
2022-12-05 21:56:31,277 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:56:31,278 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:56:31.282 [ZeusMonitor] Monitor started.
2022-12-06 02:56:31.282 [ZeusMonitor] Running indefinitely. 2022-12-06 02:56:31.282 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:56:31.282 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e98+gpu0.power.log
2022-12-05 21:57:15,472 [ZeusDataLoader(train)] train epoch 98 done: time=44.34 energy=6757.43
2022-12-05 21:57:15,475 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 1.5817
Training Epoch: 97 [2048/50176]	Loss: 1.5524
Training Epoch: 97 [3072/50176]	Loss: 1.6119
Training Epoch: 97 [4096/50176]	Loss: 1.5903
Training Epoch: 97 [5120/50176]	Loss: 1.5935
Training Epoch: 97 [6144/50176]	Loss: 1.5746
Training Epoch: 97 [7168/50176]	Loss: 1.6609
Training Epoch: 97 [8192/50176]	Loss: 1.6332
Training Epoch: 97 [9216/50176]	Loss: 1.6716
Training Epoch: 97 [10240/50176]	Loss: 1.5424
Training Epoch: 97 [11264/50176]	Loss: 1.5478
Training Epoch: 97 [12288/50176]	Loss: 1.5321
Training Epoch: 97 [13312/50176]	Loss: 1.6117
Training Epoch: 97 [14336/50176]	Loss: 1.6041
Training Epoch: 97 [15360/50176]	Loss: 1.5725
Training Epoch: 97 [16384/50176]	Loss: 1.6475
Training Epoch: 97 [17408/50176]	Loss: 1.6181
Training Epoch: 97 [18432/50176]	Loss: 1.5646
Training Epoch: 97 [19456/50176]	Loss: 1.6514
Training Epoch: 97 [20480/50176]	Loss: 1.6479
Training Epoch: 97 [21504/50176]	Loss: 1.6129
Training Epoch: 97 [22528/50176]	Loss: 1.6397
Training Epoch: 97 [23552/50176]	Loss: 1.5966
Training Epoch: 97 [24576/50176]	Loss: 1.6647
Training Epoch: 97 [25600/50176]	Loss: 1.6549
Training Epoch: 97 [26624/50176]	Loss: 1.5251
Training Epoch: 97 [27648/50176]	Loss: 1.7080
Training Epoch: 97 [28672/50176]	Loss: 1.5651
Training Epoch: 97 [29696/50176]	Loss: 1.6213
Training Epoch: 97 [30720/50176]	Loss: 1.7045
Training Epoch: 97 [31744/50176]	Loss: 1.6511
Training Epoch: 97 [32768/50176]	Loss: 1.6714
Training Epoch: 97 [33792/50176]	Loss: 1.6817
Training Epoch: 97 [34816/50176]	Loss: 1.6697
Training Epoch: 97 [35840/50176]	Loss: 1.7487
Training Epoch: 97 [36864/50176]	Loss: 1.7040
Training Epoch: 97 [37888/50176]	Loss: 1.6079
Training Epoch: 97 [38912/50176]	Loss: 1.6752
Training Epoch: 97 [39936/50176]	Loss: 1.6358
Training Epoch: 97 [40960/50176]	Loss: 1.6651
Training Epoch: 97 [41984/50176]	Loss: 1.5555
Training Epoch: 97 [43008/50176]	Loss: 1.5519
Training Epoch: 97 [44032/50176]	Loss: 1.6872
Training Epoch: 97 [45056/50176]	Loss: 1.6069
Training Epoch: 97 [46080/50176]	Loss: 1.6586
Training Epoch: 97 [47104/50176]	Loss: 1.6805
Training Epoch: 97 [48128/50176]	Loss: 1.6179
Training Epoch: 97 [49152/50176]	Loss: 1.6222
Training Epoch: 97 [50176/50176]	Loss: 1.7350
2022-12-06 02:57:19.239 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:57:19,273 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.79 energy=524.12
2022-12-05 21:57:19,273 [ZeusDataLoader(train)] Up to epoch 98: time=4832.26, energy=720647.32, cost=783146.05
2022-12-05 21:57:19,273 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:57:19,273 [ZeusDataLoader(train)] Expected next epoch: time=4880.60, energy=727935.58, cost=791020.36
2022-12-05 21:57:19,274 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0023, Accuracy: 0.4132
2022-12-05 21:57:19,472 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:57:19,473 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:57:19.475 [ZeusMonitor] Monitor started.
2022-12-06 02:57:19.475 [ZeusMonitor] Running indefinitely. 2022-12-06 02:57:19.475 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:57:19.475 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e99+gpu0.power.log
2022-12-05 21:58:03,557 [ZeusDataLoader(train)] train epoch 99 done: time=44.27 energy=6749.20
2022-12-05 21:58:03,561 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 1.5458
Training Epoch: 98 [2048/50176]	Loss: 1.5347
Training Epoch: 98 [3072/50176]	Loss: 1.5207
Training Epoch: 98 [4096/50176]	Loss: 1.5632
Training Epoch: 98 [5120/50176]	Loss: 1.5764
Training Epoch: 98 [6144/50176]	Loss: 1.6304
Training Epoch: 98 [7168/50176]	Loss: 1.4894
Training Epoch: 98 [8192/50176]	Loss: 1.6539
Training Epoch: 98 [9216/50176]	Loss: 1.5919
Training Epoch: 98 [10240/50176]	Loss: 1.6340
Training Epoch: 98 [11264/50176]	Loss: 1.5780
Training Epoch: 98 [12288/50176]	Loss: 1.5992
Training Epoch: 98 [13312/50176]	Loss: 1.6331
Training Epoch: 98 [14336/50176]	Loss: 1.5907
Training Epoch: 98 [15360/50176]	Loss: 1.5605
Training Epoch: 98 [16384/50176]	Loss: 1.5807
Training Epoch: 98 [17408/50176]	Loss: 1.6492
Training Epoch: 98 [18432/50176]	Loss: 1.5958
Training Epoch: 98 [19456/50176]	Loss: 1.6317
Training Epoch: 98 [20480/50176]	Loss: 1.6120
Training Epoch: 98 [21504/50176]	Loss: 1.5933
Training Epoch: 98 [22528/50176]	Loss: 1.6378
Training Epoch: 98 [23552/50176]	Loss: 1.6377
Training Epoch: 98 [24576/50176]	Loss: 1.6517
Training Epoch: 98 [25600/50176]	Loss: 1.6791
Training Epoch: 98 [26624/50176]	Loss: 1.5723
Training Epoch: 98 [27648/50176]	Loss: 1.6325
Training Epoch: 98 [28672/50176]	Loss: 1.7024
Training Epoch: 98 [29696/50176]	Loss: 1.6083
Training Epoch: 98 [30720/50176]	Loss: 1.7377
Training Epoch: 98 [31744/50176]	Loss: 1.6584
Training Epoch: 98 [32768/50176]	Loss: 1.5384
Training Epoch: 98 [33792/50176]	Loss: 1.6495
Training Epoch: 98 [34816/50176]	Loss: 1.6443
Training Epoch: 98 [35840/50176]	Loss: 1.6873
Training Epoch: 98 [36864/50176]	Loss: 1.6861
Training Epoch: 98 [37888/50176]	Loss: 1.6924
Training Epoch: 98 [38912/50176]	Loss: 1.6779
Training Epoch: 98 [39936/50176]	Loss: 1.5800
Training Epoch: 98 [40960/50176]	Loss: 1.5647
Training Epoch: 98 [41984/50176]	Loss: 1.6989
Training Epoch: 98 [43008/50176]	Loss: 1.5420
Training Epoch: 98 [44032/50176]	Loss: 1.6020
Training Epoch: 98 [45056/50176]	Loss: 1.5934
Training Epoch: 98 [46080/50176]	Loss: 1.6577
Training Epoch: 98 [47104/50176]	Loss: 1.6428
Training Epoch: 98 [48128/50176]	Loss: 1.7270
Training Epoch: 98 [49152/50176]	Loss: 1.6098
Training Epoch: 98 [50176/50176]	Loss: 1.6208
2022-12-06 02:58:07.270 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:58:07,285 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.72 energy=521.95
2022-12-05 21:58:07,285 [ZeusDataLoader(train)] Up to epoch 99: time=4880.25, energy=727918.47, cost=790980.83
2022-12-05 21:58:07,286 [ZeusDataLoader(train)] Optimal PL train & eval expected time=48.34 energy=7288.26
2022-12-05 21:58:07,286 [ZeusDataLoader(train)] Expected next epoch: time=4928.59, energy=735206.73, cost=798855.14
2022-12-05 21:58:07,287 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0023, Accuracy: 0.4177
2022-12-05 21:58:07,470 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-05 21:58:07,471 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 02:58:07.473 [ZeusMonitor] Monitor started.
2022-12-06 02:58:07.473 [ZeusMonitor] Running indefinitely. 2022-12-06 02:58:07.473 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 02:58:07.473 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/bs1024+e100+gpu0.power.log
2022-12-05 21:58:51,597 [ZeusDataLoader(train)] train epoch 100 done: time=44.30 energy=6757.84
2022-12-05 21:58:51,601 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 1.5637
Training Epoch: 99 [2048/50176]	Loss: 1.5381
Training Epoch: 99 [3072/50176]	Loss: 1.5947
Training Epoch: 99 [4096/50176]	Loss: 1.5852
Training Epoch: 99 [5120/50176]	Loss: 1.6170
Training Epoch: 99 [6144/50176]	Loss: 1.5391
Training Epoch: 99 [7168/50176]	Loss: 1.5901
Training Epoch: 99 [8192/50176]	Loss: 1.5006
Training Epoch: 99 [9216/50176]	Loss: 1.5689
Training Epoch: 99 [10240/50176]	Loss: 1.6009
Training Epoch: 99 [11264/50176]	Loss: 1.5196
Training Epoch: 99 [12288/50176]	Loss: 1.6259
Training Epoch: 99 [13312/50176]	Loss: 1.5329
Training Epoch: 99 [14336/50176]	Loss: 1.5552
Training Epoch: 99 [15360/50176]	Loss: 1.5349
Training Epoch: 99 [16384/50176]	Loss: 1.6487
Training Epoch: 99 [17408/50176]	Loss: 1.6228
Training Epoch: 99 [18432/50176]	Loss: 1.5664
Training Epoch: 99 [19456/50176]	Loss: 1.6271
Training Epoch: 99 [20480/50176]	Loss: 1.6547
Training Epoch: 99 [21504/50176]	Loss: 1.6452
Training Epoch: 99 [22528/50176]	Loss: 1.5584
Training Epoch: 99 [23552/50176]	Loss: 1.6022
Training Epoch: 99 [24576/50176]	Loss: 1.6416
Training Epoch: 99 [25600/50176]	Loss: 1.6011
Training Epoch: 99 [26624/50176]	Loss: 1.6264
Training Epoch: 99 [27648/50176]	Loss: 1.6232
Training Epoch: 99 [28672/50176]	Loss: 1.6306
Training Epoch: 99 [29696/50176]	Loss: 1.5337
Training Epoch: 99 [30720/50176]	Loss: 1.6050
Training Epoch: 99 [31744/50176]	Loss: 1.5618
Training Epoch: 99 [32768/50176]	Loss: 1.5423
Training Epoch: 99 [33792/50176]	Loss: 1.6419
Training Epoch: 99 [34816/50176]	Loss: 1.6236
Training Epoch: 99 [35840/50176]	Loss: 1.6645
Training Epoch: 99 [36864/50176]	Loss: 1.5988
Training Epoch: 99 [37888/50176]	Loss: 1.5868
Training Epoch: 99 [38912/50176]	Loss: 1.6510
Training Epoch: 99 [39936/50176]	Loss: 1.5705
Training Epoch: 99 [40960/50176]	Loss: 1.5093
Training Epoch: 99 [41984/50176]	Loss: 1.6984
Training Epoch: 99 [43008/50176]	Loss: 1.6304
Training Epoch: 99 [44032/50176]	Loss: 1.6417
Training Epoch: 99 [45056/50176]	Loss: 1.5667
Training Epoch: 99 [46080/50176]	Loss: 1.5615
Training Epoch: 99 [47104/50176]	Loss: 1.5708
Training Epoch: 99 [48128/50176]	Loss: 1.6997
Training Epoch: 99 [49152/50176]	Loss: 1.5504
Training Epoch: 99 [50176/50176]	Loss: 1.5988
2022-12-06 02:58:55.280 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-05 21:58:55,289 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.68 energy=505.14
2022-12-05 21:58:55,290 [ZeusDataLoader(train)] Up to epoch 100: time=4928.23, energy=735181.45, cost=798810.80
2022-12-05 21:58:55,290 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-05 21:58:55,290 [ZeusDataLoader(train)] Training done.
2022-12-05 21:58:55,290 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120520361670290592/rec00+try01+bs1024+lr0.0001000.train.json: {"energy": 735181.4526552451, "time": 4928.229457993996, "cost": 798810.8039020973, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 0.0023, Accuracy: 0.4178
