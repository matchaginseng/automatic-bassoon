[Power Profiler] Batch sizes: [8, 16, 32, 64, 128, 256, 512]
[Power Profiler] Learning rates: [0.8, 1.0, 1.2]

[Power Profiler] with batch size 8 and learning rate 0.0008
[run job] Launching job with BS 8: and LR: 0.0008 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00080+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0008', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00080+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0008
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8076
Training Epoch: 0 [24/50000]	Loss: 4.7134
Training Epoch: 0 [32/50000]	Loss: 4.7907
Training Epoch: 0 [40/50000]	Loss: 4.7478
Training Epoch: 0 [48/50000]	Loss: 5.5602
Training Epoch: 0 [56/50000]	Loss: 5.4040
Training Epoch: 0 [64/50000]	Loss: 4.9808
Training Epoch: 0 [72/50000]	Loss: 5.2343
Training Epoch: 0 [80/50000]	Loss: 5.1693
Training Epoch: 0 [88/50000]	Loss: 4.8736
Training Epoch: 0 [96/50000]	Loss: 5.9523
Training Epoch: 0 [104/50000]	Loss: 5.8109
Training Epoch: 0 [112/50000]	Loss: 5.0146
Training Epoch: 0 [120/50000]	Loss: 5.6381
Training Epoch: 0 [128/50000]	Loss: 5.8619
Training Epoch: 0 [136/50000]	Loss: 5.6248
Training Epoch: 0 [144/50000]	Loss: 5.0949
Training Epoch: 0 [152/50000]	Loss: 5.1237
Training Epoch: 0 [160/50000]	Loss: 5.9764
Training Epoch: 0 [168/50000]	Loss: 5.5238
Training Epoch: 0 [176/50000]	Loss: 5.0121
Training Epoch: 0 [184/50000]	Loss: 5.3585
Training Epoch: 0 [192/50000]	Loss: 4.5214
Training Epoch: 0 [200/50000]	Loss: 5.6263
Training Epoch: 0 [208/50000]	Loss: 5.2484
Training Epoch: 0 [216/50000]	Loss: 4.8383
Training Epoch: 0 [224/50000]	Loss: 5.2070
Training Epoch: 0 [232/50000]	Loss: 4.8633
Training Epoch: 0 [240/50000]	Loss: 5.1761
Training Epoch: 0 [248/50000]	Loss: 5.1170
Training Epoch: 0 [256/50000]	Loss: 5.2862
Training Epoch: 0 [264/50000]	Loss: 4.6640
Training Epoch: 0 [272/50000]	Loss: 5.4626
Training Epoch: 0 [280/50000]	Loss: 5.1262
Training Epoch: 0 [288/50000]	Loss: 5.3783
Training Epoch: 0 [296/50000]	Loss: 5.5007
Training Epoch: 0 [304/50000]	Loss: 5.1730
Training Epoch: 0 [312/50000]	Loss: 4.6852
Training Epoch: 0 [320/50000]	Loss: 5.0292
Training Epoch: 0 [328/50000]	Loss: 5.3785
Training Epoch: 0 [336/50000]	Loss: 5.0083
Training Epoch: 0 [344/50000]	Loss: 4.4321
Training Epoch: 0 [352/50000]	Loss: 4.8620
Training Epoch: 0 [360/50000]	Loss: 5.5725
Training Epoch: 0 [368/50000]	Loss: 4.9629
Training Epoch: 0 [376/50000]	Loss: 4.9307
Training Epoch: 0 [384/50000]	Loss: 4.5944
Training Epoch: 0 [392/50000]	Loss: 4.8040
Training Epoch: 0 [400/50000]	Loss: 4.6017
Profile done with power limit 175W
epoch 1 train time consumed: 3.39s
Validation Epoch: 0, Average loss: 0.6201, Accuracy: 0.0118
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 175000, 'lr': 0.0008, 'energy': 97.75108605305954, 'time': 2.214743546999671, 'accuracy': 0.0118, 'total_cost': 3317.713255653092}
[run job] Launching job with BS 8: and LR: 0.0008 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00080+pl150', 'ZEUS_COST_THRESH': '6635.426511306184', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0008', '--power_limit', '150']
[run job] cost_ub=6635.426511306184
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00080+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0008
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8076
Training Epoch: 0 [24/50000]	Loss: 4.7133
Training Epoch: 0 [32/50000]	Loss: 4.7880
Training Epoch: 0 [40/50000]	Loss: 4.7560
Training Epoch: 0 [48/50000]	Loss: 5.6045
Training Epoch: 0 [56/50000]	Loss: 5.4212
Training Epoch: 0 [64/50000]	Loss: 4.9677
Training Epoch: 0 [72/50000]	Loss: 5.2249
Training Epoch: 0 [80/50000]	Loss: 5.0965
Training Epoch: 0 [88/50000]	Loss: 4.8600
Training Epoch: 0 [96/50000]	Loss: 5.9037
Training Epoch: 0 [104/50000]	Loss: 5.7849
Training Epoch: 0 [112/50000]	Loss: 4.9619
Training Epoch: 0 [120/50000]	Loss: 5.5974
Training Epoch: 0 [128/50000]	Loss: 5.8118
Training Epoch: 0 [136/50000]	Loss: 5.5905
Training Epoch: 0 [144/50000]	Loss: 5.1283
Training Epoch: 0 [152/50000]	Loss: 5.1169
Training Epoch: 0 [160/50000]	Loss: 6.0296
Training Epoch: 0 [168/50000]	Loss: 5.4524
Training Epoch: 0 [176/50000]	Loss: 5.0563
Training Epoch: 0 [184/50000]	Loss: 5.4405
Training Epoch: 0 [192/50000]	Loss: 4.4569
Training Epoch: 0 [200/50000]	Loss: 5.7896
Training Epoch: 0 [208/50000]	Loss: 5.3651
Training Epoch: 0 [216/50000]	Loss: 4.8999
Training Epoch: 0 [224/50000]	Loss: 5.1780
Training Epoch: 0 [232/50000]	Loss: 4.7885
Training Epoch: 0 [240/50000]	Loss: 5.2331
Training Epoch: 0 [248/50000]	Loss: 5.1290
Training Epoch: 0 [256/50000]	Loss: 5.3825
Training Epoch: 0 [264/50000]	Loss: 4.7143
Training Epoch: 0 [272/50000]	Loss: 5.4913
Training Epoch: 0 [280/50000]	Loss: 5.1008
Training Epoch: 0 [288/50000]	Loss: 5.3258
Training Epoch: 0 [296/50000]	Loss: 5.4414
Training Epoch: 0 [304/50000]	Loss: 5.2260
Training Epoch: 0 [312/50000]	Loss: 4.6711
Training Epoch: 0 [320/50000]	Loss: 5.0759
Training Epoch: 0 [328/50000]	Loss: 5.3277
Training Epoch: 0 [336/50000]	Loss: 5.0793
Training Epoch: 0 [344/50000]	Loss: 4.4686
Training Epoch: 0 [352/50000]	Loss: 4.8355
Training Epoch: 0 [360/50000]	Loss: 5.5514
Training Epoch: 0 [368/50000]	Loss: 5.0333
Training Epoch: 0 [376/50000]	Loss: 4.8129
Training Epoch: 0 [384/50000]	Loss: 4.6966
Training Epoch: 0 [392/50000]	Loss: 4.7637
Training Epoch: 0 [400/50000]	Loss: 4.5749
Profile done with power limit 150W
epoch 1 train time consumed: 3.13s
Validation Epoch: 0, Average loss: 0.6244, Accuracy: 0.0131
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 150000, 'lr': 0.0008, 'energy': 99.9819681527312, 'time': 2.1725833950004017, 'accuracy': 0.0131, 'total_cost': 2932.8349072609126}
[run job] Launching job with BS 8: and LR: 0.0008 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00080+pl125', 'ZEUS_COST_THRESH': '5865.669814521825', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0008', '--power_limit', '125']
[run job] cost_ub=5865.669814521825
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00080+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0008
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8076
Training Epoch: 0 [24/50000]	Loss: 4.7133
Training Epoch: 0 [32/50000]	Loss: 4.7881
Training Epoch: 0 [40/50000]	Loss: 4.7584
Training Epoch: 0 [48/50000]	Loss: 5.6091
Training Epoch: 0 [56/50000]	Loss: 5.3997
Training Epoch: 0 [64/50000]	Loss: 4.9717
Training Epoch: 0 [72/50000]	Loss: 5.1602
Training Epoch: 0 [80/50000]	Loss: 5.1355
Training Epoch: 0 [88/50000]	Loss: 4.8661
Training Epoch: 0 [96/50000]	Loss: 5.9125
Training Epoch: 0 [104/50000]	Loss: 5.8190
Training Epoch: 0 [112/50000]	Loss: 4.9986
Training Epoch: 0 [120/50000]	Loss: 5.6412
Training Epoch: 0 [128/50000]	Loss: 5.8426
Training Epoch: 0 [136/50000]	Loss: 5.5945
Training Epoch: 0 [144/50000]	Loss: 5.0908
Training Epoch: 0 [152/50000]	Loss: 5.1302
Training Epoch: 0 [160/50000]	Loss: 6.0874
Training Epoch: 0 [168/50000]	Loss: 5.4269
Training Epoch: 0 [176/50000]	Loss: 5.0988
Training Epoch: 0 [184/50000]	Loss: 5.4351
Training Epoch: 0 [192/50000]	Loss: 4.5608
Training Epoch: 0 [200/50000]	Loss: 5.7417
Training Epoch: 0 [208/50000]	Loss: 5.3529
Training Epoch: 0 [216/50000]	Loss: 4.9022
Training Epoch: 0 [224/50000]	Loss: 5.2489
Training Epoch: 0 [232/50000]	Loss: 4.7804
Training Epoch: 0 [240/50000]	Loss: 5.2291
Training Epoch: 0 [248/50000]	Loss: 5.1598
Training Epoch: 0 [256/50000]	Loss: 5.3046
Training Epoch: 0 [264/50000]	Loss: 4.7486
Training Epoch: 0 [272/50000]	Loss: 5.5528
Training Epoch: 0 [280/50000]	Loss: 5.0250
Training Epoch: 0 [288/50000]	Loss: 5.3525
Training Epoch: 0 [296/50000]	Loss: 5.4996
Training Epoch: 0 [304/50000]	Loss: 5.1931
Training Epoch: 0 [312/50000]	Loss: 4.7003
Training Epoch: 0 [320/50000]	Loss: 5.0306
Training Epoch: 0 [328/50000]	Loss: 5.3842
Training Epoch: 0 [336/50000]	Loss: 5.0171
Training Epoch: 0 [344/50000]	Loss: 4.4289
Training Epoch: 0 [352/50000]	Loss: 4.8161
Training Epoch: 0 [360/50000]	Loss: 5.5248
Training Epoch: 0 [368/50000]	Loss: 4.9997
Training Epoch: 0 [376/50000]	Loss: 4.8273
Training Epoch: 0 [384/50000]	Loss: 4.6761
Training Epoch: 0 [392/50000]	Loss: 4.8032
Training Epoch: 0 [400/50000]	Loss: 4.5573
Profile done with power limit 125W
epoch 1 train time consumed: 3.18s
Validation Epoch: 0, Average loss: 0.6220, Accuracy: 0.0103
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 125000, 'lr': 0.0008, 'energy': 100.77161556104932, 'time': 2.2163420710003265, 'accuracy': 0.0103, 'total_cost': 3804.7643402669814}
[run job] Launching job with BS 8: and LR: 0.0008 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00080+pl100', 'ZEUS_COST_THRESH': '5865.669814521825', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0008', '--power_limit', '100']
[run job] cost_ub=5865.669814521825
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00080+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0008
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8076
Training Epoch: 0 [24/50000]	Loss: 4.7132
Training Epoch: 0 [32/50000]	Loss: 4.7931
Training Epoch: 0 [40/50000]	Loss: 4.7621
Training Epoch: 0 [48/50000]	Loss: 5.5748
Training Epoch: 0 [56/50000]	Loss: 5.4098
Training Epoch: 0 [64/50000]	Loss: 4.9739
Training Epoch: 0 [72/50000]	Loss: 5.1928
Training Epoch: 0 [80/50000]	Loss: 5.1211
Training Epoch: 0 [88/50000]	Loss: 4.8752
Training Epoch: 0 [96/50000]	Loss: 5.9645
Training Epoch: 0 [104/50000]	Loss: 5.7422
Training Epoch: 0 [112/50000]	Loss: 4.9974
Training Epoch: 0 [120/50000]	Loss: 5.5752
Training Epoch: 0 [128/50000]	Loss: 5.8054
Training Epoch: 0 [136/50000]	Loss: 5.5480
Training Epoch: 0 [144/50000]	Loss: 5.0992
Training Epoch: 0 [152/50000]	Loss: 5.1350
Training Epoch: 0 [160/50000]	Loss: 5.9534
Training Epoch: 0 [168/50000]	Loss: 5.4713
Training Epoch: 0 [176/50000]	Loss: 5.0579
Training Epoch: 0 [184/50000]	Loss: 5.4523
Training Epoch: 0 [192/50000]	Loss: 4.4759
Training Epoch: 0 [200/50000]	Loss: 5.8048
Training Epoch: 0 [208/50000]	Loss: 5.2953
Training Epoch: 0 [216/50000]	Loss: 4.8460
Training Epoch: 0 [224/50000]	Loss: 5.2161
Training Epoch: 0 [232/50000]	Loss: 4.8223
Training Epoch: 0 [240/50000]	Loss: 5.2328
Training Epoch: 0 [248/50000]	Loss: 5.1245
Training Epoch: 0 [256/50000]	Loss: 5.3190
Training Epoch: 0 [264/50000]	Loss: 4.7532
Training Epoch: 0 [272/50000]	Loss: 5.5436
Training Epoch: 0 [280/50000]	Loss: 5.0230
Training Epoch: 0 [288/50000]	Loss: 5.3320
Training Epoch: 0 [296/50000]	Loss: 5.4805
Training Epoch: 0 [304/50000]	Loss: 5.2058
Training Epoch: 0 [312/50000]	Loss: 4.6746
Training Epoch: 0 [320/50000]	Loss: 5.0890
Training Epoch: 0 [328/50000]	Loss: 5.3042
Training Epoch: 0 [336/50000]	Loss: 5.0229
Training Epoch: 0 [344/50000]	Loss: 4.4970
Training Epoch: 0 [352/50000]	Loss: 4.8563
Training Epoch: 0 [360/50000]	Loss: 5.4795
Training Epoch: 0 [368/50000]	Loss: 5.0661
Training Epoch: 0 [376/50000]	Loss: 4.8669
Training Epoch: 0 [384/50000]	Loss: 4.6464
Training Epoch: 0 [392/50000]	Loss: 4.8038
Training Epoch: 0 [400/50000]	Loss: 4.5375
Profile done with power limit 100W
epoch 1 train time consumed: 3.19s
Validation Epoch: 0, Average loss: 0.6258, Accuracy: 0.0111
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 100000, 'lr': 0.0008, 'energy': 97.99115913009724, 'time': 2.2401014269998996, 'accuracy': 0.0111, 'total_cost': 3567.0035683800565}

[Power Profiler] with batch size 8 and learning rate 0.001
[run job] Launching job with BS 8: and LR: 0.001 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00100+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.001', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.001', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00100+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.001
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8286
Training Epoch: 0 [24/50000]	Loss: 4.7004
Training Epoch: 0 [32/50000]	Loss: 4.8897
Training Epoch: 0 [40/50000]	Loss: 4.8653
Training Epoch: 0 [48/50000]	Loss: 5.8933
Training Epoch: 0 [56/50000]	Loss: 5.6952
Training Epoch: 0 [64/50000]	Loss: 5.0958
Training Epoch: 0 [72/50000]	Loss: 5.4228
Training Epoch: 0 [80/50000]	Loss: 5.3325
Training Epoch: 0 [88/50000]	Loss: 5.1573
Training Epoch: 0 [96/50000]	Loss: 6.2635
Training Epoch: 0 [104/50000]	Loss: 6.1311
Training Epoch: 0 [112/50000]	Loss: 5.2142
Training Epoch: 0 [120/50000]	Loss: 5.8437
Training Epoch: 0 [128/50000]	Loss: 6.1181
Training Epoch: 0 [136/50000]	Loss: 5.8173
Training Epoch: 0 [144/50000]	Loss: 5.1705
Training Epoch: 0 [152/50000]	Loss: 5.2944
Training Epoch: 0 [160/50000]	Loss: 6.2770
Training Epoch: 0 [168/50000]	Loss: 5.5082
Training Epoch: 0 [176/50000]	Loss: 5.0456
Training Epoch: 0 [184/50000]	Loss: 5.5021
Training Epoch: 0 [192/50000]	Loss: 4.6038
Training Epoch: 0 [200/50000]	Loss: 5.8957
Training Epoch: 0 [208/50000]	Loss: 5.4810
Training Epoch: 0 [216/50000]	Loss: 4.8942
Training Epoch: 0 [224/50000]	Loss: 5.3246
Training Epoch: 0 [232/50000]	Loss: 4.8065
Training Epoch: 0 [240/50000]	Loss: 5.2879
Training Epoch: 0 [248/50000]	Loss: 5.0069
Training Epoch: 0 [256/50000]	Loss: 5.3281
Training Epoch: 0 [264/50000]	Loss: 4.8557
Training Epoch: 0 [272/50000]	Loss: 5.8009
Training Epoch: 0 [280/50000]	Loss: 5.1368
Training Epoch: 0 [288/50000]	Loss: 5.5348
Training Epoch: 0 [296/50000]	Loss: 5.5437
Training Epoch: 0 [304/50000]	Loss: 5.2426
Training Epoch: 0 [312/50000]	Loss: 4.6851
Training Epoch: 0 [320/50000]	Loss: 5.1737
Training Epoch: 0 [328/50000]	Loss: 5.3183
Training Epoch: 0 [336/50000]	Loss: 5.0759
Training Epoch: 0 [344/50000]	Loss: 4.5620
Training Epoch: 0 [352/50000]	Loss: 4.7003
Training Epoch: 0 [360/50000]	Loss: 5.4963
Training Epoch: 0 [368/50000]	Loss: 5.0190
Training Epoch: 0 [376/50000]	Loss: 4.9190
Training Epoch: 0 [384/50000]	Loss: 4.6458
Training Epoch: 0 [392/50000]	Loss: 4.8000
Training Epoch: 0 [400/50000]	Loss: 4.5494
Profile done with power limit 175W
epoch 1 train time consumed: 3.10s
Validation Epoch: 0, Average loss: 0.6345, Accuracy: 0.0131
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 175000, 'lr': 0.001, 'energy': 103.5316350735005, 'time': 2.1396361090000937, 'accuracy': 0.0131, 'total_cost': 2889.9052250225686}
[run job] Launching job with BS 8: and LR: 0.001 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00100+pl150', 'ZEUS_COST_THRESH': '5779.810450045137', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.001', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.001', '--power_limit', '150']
[run job] cost_ub=5779.810450045137
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00100+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.001
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8286
Training Epoch: 0 [24/50000]	Loss: 4.7004
Training Epoch: 0 [32/50000]	Loss: 4.8893
Training Epoch: 0 [40/50000]	Loss: 4.8611
Training Epoch: 0 [48/50000]	Loss: 5.8935
Training Epoch: 0 [56/50000]	Loss: 5.7119
Training Epoch: 0 [64/50000]	Loss: 5.1445
Training Epoch: 0 [72/50000]	Loss: 5.3487
Training Epoch: 0 [80/50000]	Loss: 5.3935
Training Epoch: 0 [88/50000]	Loss: 5.2007
Training Epoch: 0 [96/50000]	Loss: 6.2641
Training Epoch: 0 [104/50000]	Loss: 6.1096
Training Epoch: 0 [112/50000]	Loss: 5.2584
Training Epoch: 0 [120/50000]	Loss: 5.8639
Training Epoch: 0 [128/50000]	Loss: 6.0773
Training Epoch: 0 [136/50000]	Loss: 5.8299
Training Epoch: 0 [144/50000]	Loss: 5.1895
Training Epoch: 0 [152/50000]	Loss: 5.2646
Training Epoch: 0 [160/50000]	Loss: 6.2196
Training Epoch: 0 [168/50000]	Loss: 5.5090
Training Epoch: 0 [176/50000]	Loss: 5.1016
Training Epoch: 0 [184/50000]	Loss: 5.5406
Training Epoch: 0 [192/50000]	Loss: 4.5831
Training Epoch: 0 [200/50000]	Loss: 6.0059
Training Epoch: 0 [208/50000]	Loss: 5.5268
Training Epoch: 0 [216/50000]	Loss: 4.8971
Training Epoch: 0 [224/50000]	Loss: 5.2463
Training Epoch: 0 [232/50000]	Loss: 4.7833
Training Epoch: 0 [240/50000]	Loss: 5.2436
Training Epoch: 0 [248/50000]	Loss: 5.0154
Training Epoch: 0 [256/50000]	Loss: 5.3770
Training Epoch: 0 [264/50000]	Loss: 4.8179
Training Epoch: 0 [272/50000]	Loss: 5.7663
Training Epoch: 0 [280/50000]	Loss: 5.1538
Training Epoch: 0 [288/50000]	Loss: 5.5922
Training Epoch: 0 [296/50000]	Loss: 5.6543
Training Epoch: 0 [304/50000]	Loss: 5.2666
Training Epoch: 0 [312/50000]	Loss: 4.7442
Training Epoch: 0 [320/50000]	Loss: 5.0533
Training Epoch: 0 [328/50000]	Loss: 5.2851
Training Epoch: 0 [336/50000]	Loss: 5.0820
Training Epoch: 0 [344/50000]	Loss: 4.6274
Training Epoch: 0 [352/50000]	Loss: 4.8296
Training Epoch: 0 [360/50000]	Loss: 5.5710
Training Epoch: 0 [368/50000]	Loss: 4.9230
Training Epoch: 0 [376/50000]	Loss: 4.9790
Training Epoch: 0 [384/50000]	Loss: 4.5800
Training Epoch: 0 [392/50000]	Loss: 4.7341
Training Epoch: 0 [400/50000]	Loss: 4.5040
Profile done with power limit 150W
epoch 1 train time consumed: 3.02s
Validation Epoch: 0, Average loss: 0.6285, Accuracy: 0.0117
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 150000, 'lr': 0.001, 'energy': 105.71358638633863, 'time': 2.077709589000733, 'accuracy': 0.0117, 'total_cost': 3143.8266797485626}
[run job] Launching job with BS 8: and LR: 0.001 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00100+pl125', 'ZEUS_COST_THRESH': '5779.810450045137', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.001', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.001', '--power_limit', '125']
[run job] cost_ub=5779.810450045137
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00100+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.001
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8286
Training Epoch: 0 [24/50000]	Loss: 4.7004
Training Epoch: 0 [32/50000]	Loss: 4.8893
Training Epoch: 0 [40/50000]	Loss: 4.8638
Training Epoch: 0 [48/50000]	Loss: 5.9013
Training Epoch: 0 [56/50000]	Loss: 5.6981
Training Epoch: 0 [64/50000]	Loss: 5.1516
Training Epoch: 0 [72/50000]	Loss: 5.4068
Training Epoch: 0 [80/50000]	Loss: 5.3588
Training Epoch: 0 [88/50000]	Loss: 5.1997
Training Epoch: 0 [96/50000]	Loss: 6.2923
Training Epoch: 0 [104/50000]	Loss: 6.1087
Training Epoch: 0 [112/50000]	Loss: 5.2342
Training Epoch: 0 [120/50000]	Loss: 5.8790
Training Epoch: 0 [128/50000]	Loss: 6.0958
Training Epoch: 0 [136/50000]	Loss: 5.7957
Training Epoch: 0 [144/50000]	Loss: 5.1229
Training Epoch: 0 [152/50000]	Loss: 5.3141
Training Epoch: 0 [160/50000]	Loss: 6.1397
Training Epoch: 0 [168/50000]	Loss: 5.5783
Training Epoch: 0 [176/50000]	Loss: 5.0992
Training Epoch: 0 [184/50000]	Loss: 5.5310
Training Epoch: 0 [192/50000]	Loss: 4.5457
Training Epoch: 0 [200/50000]	Loss: 5.8871
Training Epoch: 0 [208/50000]	Loss: 5.4567
Training Epoch: 0 [216/50000]	Loss: 4.9161
Training Epoch: 0 [224/50000]	Loss: 5.3280
Training Epoch: 0 [232/50000]	Loss: 4.8070
Training Epoch: 0 [240/50000]	Loss: 5.2057
Training Epoch: 0 [248/50000]	Loss: 5.0132
Training Epoch: 0 [256/50000]	Loss: 5.4322
Training Epoch: 0 [264/50000]	Loss: 4.8788
Training Epoch: 0 [272/50000]	Loss: 5.6979
Training Epoch: 0 [280/50000]	Loss: 5.1129
Training Epoch: 0 [288/50000]	Loss: 5.4624
Training Epoch: 0 [296/50000]	Loss: 5.6284
Training Epoch: 0 [304/50000]	Loss: 5.2341
Training Epoch: 0 [312/50000]	Loss: 4.7894
Training Epoch: 0 [320/50000]	Loss: 5.0911
Training Epoch: 0 [328/50000]	Loss: 5.4199
Training Epoch: 0 [336/50000]	Loss: 5.0223
Training Epoch: 0 [344/50000]	Loss: 4.5815
Training Epoch: 0 [352/50000]	Loss: 4.8100
Training Epoch: 0 [360/50000]	Loss: 5.5085
Training Epoch: 0 [368/50000]	Loss: 5.0382
Training Epoch: 0 [376/50000]	Loss: 4.8959
Training Epoch: 0 [384/50000]	Loss: 4.6425
Training Epoch: 0 [392/50000]	Loss: 4.7456
Training Epoch: 0 [400/50000]	Loss: 4.5625
Profile done with power limit 125W
epoch 1 train time consumed: 3.09s
Validation Epoch: 0, Average loss: 0.6328, Accuracy: 0.0117
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 125000, 'lr': 0.001, 'energy': 103.66378236774052, 'time': 2.140584773000228, 'accuracy': 0.0117, 'total_cost': 3237.16997068162}
[run job] Launching job with BS 8: and LR: 0.001 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00100+pl100', 'ZEUS_COST_THRESH': '5779.810450045137', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.001', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.001', '--power_limit', '100']
[run job] cost_ub=5779.810450045137
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00100+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.001
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8286
Training Epoch: 0 [24/50000]	Loss: 4.7004
Training Epoch: 0 [32/50000]	Loss: 4.8896
Training Epoch: 0 [40/50000]	Loss: 4.8655
Training Epoch: 0 [48/50000]	Loss: 5.9013
Training Epoch: 0 [56/50000]	Loss: 5.6823
Training Epoch: 0 [64/50000]	Loss: 5.0933
Training Epoch: 0 [72/50000]	Loss: 5.4390
Training Epoch: 0 [80/50000]	Loss: 5.3511
Training Epoch: 0 [88/50000]	Loss: 5.1807
Training Epoch: 0 [96/50000]	Loss: 6.2552
Training Epoch: 0 [104/50000]	Loss: 6.1096
Training Epoch: 0 [112/50000]	Loss: 5.1746
Training Epoch: 0 [120/50000]	Loss: 5.8668
Training Epoch: 0 [128/50000]	Loss: 6.0859
Training Epoch: 0 [136/50000]	Loss: 5.7893
Training Epoch: 0 [144/50000]	Loss: 5.1879
Training Epoch: 0 [152/50000]	Loss: 5.3036
Training Epoch: 0 [160/50000]	Loss: 6.1621
Training Epoch: 0 [168/50000]	Loss: 5.5380
Training Epoch: 0 [176/50000]	Loss: 5.1579
Training Epoch: 0 [184/50000]	Loss: 5.6196
Training Epoch: 0 [192/50000]	Loss: 4.5997
Training Epoch: 0 [200/50000]	Loss: 5.8822
Training Epoch: 0 [208/50000]	Loss: 5.4959
Training Epoch: 0 [216/50000]	Loss: 4.9312
Training Epoch: 0 [224/50000]	Loss: 5.2648
Training Epoch: 0 [232/50000]	Loss: 4.8076
Training Epoch: 0 [240/50000]	Loss: 5.2305
Training Epoch: 0 [248/50000]	Loss: 5.0975
Training Epoch: 0 [256/50000]	Loss: 5.4057
Training Epoch: 0 [264/50000]	Loss: 4.8096
Training Epoch: 0 [272/50000]	Loss: 5.7529
Training Epoch: 0 [280/50000]	Loss: 5.2159
Training Epoch: 0 [288/50000]	Loss: 5.5263
Training Epoch: 0 [296/50000]	Loss: 5.5750
Training Epoch: 0 [304/50000]	Loss: 5.2295
Training Epoch: 0 [312/50000]	Loss: 4.8079
Training Epoch: 0 [320/50000]	Loss: 5.0846
Training Epoch: 0 [328/50000]	Loss: 5.2850
Training Epoch: 0 [336/50000]	Loss: 4.9715
Training Epoch: 0 [344/50000]	Loss: 4.6126
Training Epoch: 0 [352/50000]	Loss: 4.8818
Training Epoch: 0 [360/50000]	Loss: 5.5394
Training Epoch: 0 [368/50000]	Loss: 4.9922
Training Epoch: 0 [376/50000]	Loss: 4.9597
Training Epoch: 0 [384/50000]	Loss: 4.5896
Training Epoch: 0 [392/50000]	Loss: 4.7114
Training Epoch: 0 [400/50000]	Loss: 4.5297
Profile done with power limit 100W
epoch 1 train time consumed: 3.25s
Validation Epoch: 0, Average loss: 0.6260, Accuracy: 0.0113
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 100000, 'lr': 0.001, 'energy': 96.84755958985113, 'time': 2.2785308219999933, 'accuracy': 0.0113, 'total_cost': 3562.9804976424157}

[Power Profiler] with batch size 8 and learning rate 0.0012
[run job] Launching job with BS 8: and LR: 0.0012 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00120+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0012', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0012', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00120+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0012
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8424
Training Epoch: 0 [24/50000]	Loss: 4.7710
Training Epoch: 0 [32/50000]	Loss: 4.9678
Training Epoch: 0 [40/50000]	Loss: 4.9733
Training Epoch: 0 [48/50000]	Loss: 6.2088
Training Epoch: 0 [56/50000]	Loss: 5.9435
Training Epoch: 0 [64/50000]	Loss: 5.2986
Training Epoch: 0 [72/50000]	Loss: 5.6066
Training Epoch: 0 [80/50000]	Loss: 5.5112
Training Epoch: 0 [88/50000]	Loss: 5.2568
Training Epoch: 0 [96/50000]	Loss: 6.5144
Training Epoch: 0 [104/50000]	Loss: 6.3537
Training Epoch: 0 [112/50000]	Loss: 5.3121
Training Epoch: 0 [120/50000]	Loss: 6.0998
Training Epoch: 0 [128/50000]	Loss: 6.2957
Training Epoch: 0 [136/50000]	Loss: 5.8553
Training Epoch: 0 [144/50000]	Loss: 5.2204
Training Epoch: 0 [152/50000]	Loss: 5.3069
Training Epoch: 0 [160/50000]	Loss: 6.3321
Training Epoch: 0 [168/50000]	Loss: 5.7315
Training Epoch: 0 [176/50000]	Loss: 5.0905
Training Epoch: 0 [184/50000]	Loss: 5.5221
Training Epoch: 0 [192/50000]	Loss: 4.6276
Training Epoch: 0 [200/50000]	Loss: 6.1912
Training Epoch: 0 [208/50000]	Loss: 5.6689
Training Epoch: 0 [216/50000]	Loss: 4.8911
Training Epoch: 0 [224/50000]	Loss: 5.4646
Training Epoch: 0 [232/50000]	Loss: 4.8720
Training Epoch: 0 [240/50000]	Loss: 5.3883
Training Epoch: 0 [248/50000]	Loss: 5.1190
Training Epoch: 0 [256/50000]	Loss: 5.5835
Training Epoch: 0 [264/50000]	Loss: 4.9685
Training Epoch: 0 [272/50000]	Loss: 5.8775
Training Epoch: 0 [280/50000]	Loss: 5.3221
Training Epoch: 0 [288/50000]	Loss: 5.4926
Training Epoch: 0 [296/50000]	Loss: 5.7844
Training Epoch: 0 [304/50000]	Loss: 5.2765
Training Epoch: 0 [312/50000]	Loss: 4.7322
Training Epoch: 0 [320/50000]	Loss: 5.2923
Training Epoch: 0 [328/50000]	Loss: 5.3807
Training Epoch: 0 [336/50000]	Loss: 5.0322
Training Epoch: 0 [344/50000]	Loss: 4.6209
Training Epoch: 0 [352/50000]	Loss: 4.6714
Training Epoch: 0 [360/50000]	Loss: 5.4886
Training Epoch: 0 [368/50000]	Loss: 4.8478
Training Epoch: 0 [376/50000]	Loss: 4.8244
Training Epoch: 0 [384/50000]	Loss: 4.6309
Training Epoch: 0 [392/50000]	Loss: 4.7715
Training Epoch: 0 [400/50000]	Loss: 4.5523
Profile done with power limit 175W
epoch 1 train time consumed: 3.06s
Validation Epoch: 0, Average loss: 0.6504, Accuracy: 0.0108
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 175000, 'lr': 0.0012, 'energy': 103.61932284042622, 'time': 2.11055593600031, 'accuracy': 0.0108, 'total_cost': 3458.2598306821415}
[run job] Launching job with BS 8: and LR: 0.0012 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00120+pl150', 'ZEUS_COST_THRESH': '6916.519661364283', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0012', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0012', '--power_limit', '150']
[run job] cost_ub=6916.519661364283
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00120+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0012
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8424
Training Epoch: 0 [24/50000]	Loss: 4.7710
Training Epoch: 0 [32/50000]	Loss: 4.9679
Training Epoch: 0 [40/50000]	Loss: 4.9693
Training Epoch: 0 [48/50000]	Loss: 6.1969
Training Epoch: 0 [56/50000]	Loss: 6.0014
Training Epoch: 0 [64/50000]	Loss: 5.2290
Training Epoch: 0 [72/50000]	Loss: 5.6558
Training Epoch: 0 [80/50000]	Loss: 5.6135
Training Epoch: 0 [88/50000]	Loss: 5.3169
Training Epoch: 0 [96/50000]	Loss: 6.4881
Training Epoch: 0 [104/50000]	Loss: 6.4088
Training Epoch: 0 [112/50000]	Loss: 5.3517
Training Epoch: 0 [120/50000]	Loss: 6.0923
Training Epoch: 0 [128/50000]	Loss: 6.3034
Training Epoch: 0 [136/50000]	Loss: 5.8802
Training Epoch: 0 [144/50000]	Loss: 5.2272
Training Epoch: 0 [152/50000]	Loss: 5.4276
Training Epoch: 0 [160/50000]	Loss: 6.3313
Training Epoch: 0 [168/50000]	Loss: 5.6720
Training Epoch: 0 [176/50000]	Loss: 5.1361
Training Epoch: 0 [184/50000]	Loss: 5.7096
Training Epoch: 0 [192/50000]	Loss: 4.6950
Training Epoch: 0 [200/50000]	Loss: 6.0597
Training Epoch: 0 [208/50000]	Loss: 5.6138
Training Epoch: 0 [216/50000]	Loss: 4.8556
Training Epoch: 0 [224/50000]	Loss: 5.4524
Training Epoch: 0 [232/50000]	Loss: 4.8695
Training Epoch: 0 [240/50000]	Loss: 5.3532
Training Epoch: 0 [248/50000]	Loss: 5.0061
Training Epoch: 0 [256/50000]	Loss: 5.3976
Training Epoch: 0 [264/50000]	Loss: 5.0111
Training Epoch: 0 [272/50000]	Loss: 5.9835
Training Epoch: 0 [280/50000]	Loss: 5.2970
Training Epoch: 0 [288/50000]	Loss: 5.6686
Training Epoch: 0 [296/50000]	Loss: 5.7004
Training Epoch: 0 [304/50000]	Loss: 5.2427
Training Epoch: 0 [312/50000]	Loss: 4.7887
Training Epoch: 0 [320/50000]	Loss: 5.2090
Training Epoch: 0 [328/50000]	Loss: 5.3957
Training Epoch: 0 [336/50000]	Loss: 5.0713
Training Epoch: 0 [344/50000]	Loss: 4.5926
Training Epoch: 0 [352/50000]	Loss: 4.7339
Training Epoch: 0 [360/50000]	Loss: 5.5261
Training Epoch: 0 [368/50000]	Loss: 4.9192
Training Epoch: 0 [376/50000]	Loss: 4.8243
Training Epoch: 0 [384/50000]	Loss: 4.6552
Training Epoch: 0 [392/50000]	Loss: 5.0619
Training Epoch: 0 [400/50000]	Loss: 4.6065
Profile done with power limit 150W
epoch 1 train time consumed: 3.01s
Validation Epoch: 0, Average loss: 0.6418, Accuracy: 0.0102
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 150000, 'lr': 0.0012, 'energy': 105.44767274031068, 'time': 2.0632556869995824, 'accuracy': 0.0102, 'total_cost': 3581.251491515092}
[run job] Launching job with BS 8: and LR: 0.0012 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00120+pl125', 'ZEUS_COST_THRESH': '6916.519661364283', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0012', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0012', '--power_limit', '125']
[run job] cost_ub=6916.519661364283
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00120+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0012
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8424
Training Epoch: 0 [24/50000]	Loss: 4.7710
Training Epoch: 0 [32/50000]	Loss: 4.9684
Training Epoch: 0 [40/50000]	Loss: 4.9576
Training Epoch: 0 [48/50000]	Loss: 6.1881
Training Epoch: 0 [56/50000]	Loss: 5.9942
Training Epoch: 0 [64/50000]	Loss: 5.2851
Training Epoch: 0 [72/50000]	Loss: 5.6328
Training Epoch: 0 [80/50000]	Loss: 5.5684
Training Epoch: 0 [88/50000]	Loss: 5.3246
Training Epoch: 0 [96/50000]	Loss: 6.5854
Training Epoch: 0 [104/50000]	Loss: 6.3683
Training Epoch: 0 [112/50000]	Loss: 5.4135
Training Epoch: 0 [120/50000]	Loss: 6.0898
Training Epoch: 0 [128/50000]	Loss: 6.3001
Training Epoch: 0 [136/50000]	Loss: 5.8557
Training Epoch: 0 [144/50000]	Loss: 5.2752
Training Epoch: 0 [152/50000]	Loss: 5.3565
Training Epoch: 0 [160/50000]	Loss: 6.3649
Training Epoch: 0 [168/50000]	Loss: 5.6577
Training Epoch: 0 [176/50000]	Loss: 5.1793
Training Epoch: 0 [184/50000]	Loss: 5.5586
Training Epoch: 0 [192/50000]	Loss: 4.6160
Training Epoch: 0 [200/50000]	Loss: 5.9066
Training Epoch: 0 [208/50000]	Loss: 5.6025
Training Epoch: 0 [216/50000]	Loss: 4.8977
Training Epoch: 0 [224/50000]	Loss: 5.4180
Training Epoch: 0 [232/50000]	Loss: 4.8790
Training Epoch: 0 [240/50000]	Loss: 5.2177
Training Epoch: 0 [248/50000]	Loss: 4.9037
Training Epoch: 0 [256/50000]	Loss: 5.5197
Training Epoch: 0 [264/50000]	Loss: 5.0457
Training Epoch: 0 [272/50000]	Loss: 5.9469
Training Epoch: 0 [280/50000]	Loss: 5.3546
Training Epoch: 0 [288/50000]	Loss: 5.6182
Training Epoch: 0 [296/50000]	Loss: 5.6525
Training Epoch: 0 [304/50000]	Loss: 5.4187
Training Epoch: 0 [312/50000]	Loss: 4.7573
Training Epoch: 0 [320/50000]	Loss: 5.1450
Training Epoch: 0 [328/50000]	Loss: 5.3367
Training Epoch: 0 [336/50000]	Loss: 4.9747
Training Epoch: 0 [344/50000]	Loss: 4.6217
Training Epoch: 0 [352/50000]	Loss: 4.7630
Training Epoch: 0 [360/50000]	Loss: 5.5628
Training Epoch: 0 [368/50000]	Loss: 4.9655
Training Epoch: 0 [376/50000]	Loss: 5.0467
Training Epoch: 0 [384/50000]	Loss: 4.5706
Training Epoch: 0 [392/50000]	Loss: 4.8174
Training Epoch: 0 [400/50000]	Loss: 4.4981
Profile done with power limit 125W
epoch 1 train time consumed: 3.10s
Validation Epoch: 0, Average loss: 0.6357, Accuracy: 0.0100
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 125000, 'lr': 0.0012, 'energy': 104.64361946978879, 'time': 2.1366213340006652, 'accuracy': 0.01, 'total_cost': 3780.9447822890797}
[run job] Launching job with BS 8: and LR: 0.0012 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs8+lr0.00120+pl100', 'ZEUS_COST_THRESH': '6916.519661364283', 'ZEUS_BATCH_SIZE': '8', 'ZEUS_LEARNING_RATE': '0.0012', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '8', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0012', '--power_limit', '100']
[run job] cost_ub=6916.519661364283
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs8+lr0.00120+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0012
batch size arg: 8
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [8/50000]	Loss: 4.6550
Training Epoch: 0 [16/50000]	Loss: 4.8424
Training Epoch: 0 [24/50000]	Loss: 4.7710
Training Epoch: 0 [32/50000]	Loss: 4.9684
Training Epoch: 0 [40/50000]	Loss: 4.9613
Training Epoch: 0 [48/50000]	Loss: 6.2143
Training Epoch: 0 [56/50000]	Loss: 5.9764
Training Epoch: 0 [64/50000]	Loss: 5.2312
Training Epoch: 0 [72/50000]	Loss: 5.6764
Training Epoch: 0 [80/50000]	Loss: 5.6029
Training Epoch: 0 [88/50000]	Loss: 5.3149
Training Epoch: 0 [96/50000]	Loss: 6.5749
Training Epoch: 0 [104/50000]	Loss: 6.3438
Training Epoch: 0 [112/50000]	Loss: 5.3811
Training Epoch: 0 [120/50000]	Loss: 6.0715
Training Epoch: 0 [128/50000]	Loss: 6.3572
Training Epoch: 0 [136/50000]	Loss: 5.9430
Training Epoch: 0 [144/50000]	Loss: 5.2943
Training Epoch: 0 [152/50000]	Loss: 5.4103
Training Epoch: 0 [160/50000]	Loss: 6.2574
Training Epoch: 0 [168/50000]	Loss: 5.7352
Training Epoch: 0 [176/50000]	Loss: 5.1122
Training Epoch: 0 [184/50000]	Loss: 5.6332
Training Epoch: 0 [192/50000]	Loss: 4.6470
Training Epoch: 0 [200/50000]	Loss: 5.9957
Training Epoch: 0 [208/50000]	Loss: 5.6104
Training Epoch: 0 [216/50000]	Loss: 4.8360
Training Epoch: 0 [224/50000]	Loss: 5.4838
Training Epoch: 0 [232/50000]	Loss: 4.8386
Training Epoch: 0 [240/50000]	Loss: 5.3471
Training Epoch: 0 [248/50000]	Loss: 5.0198
Training Epoch: 0 [256/50000]	Loss: 5.4547
Training Epoch: 0 [264/50000]	Loss: 4.9429
Training Epoch: 0 [272/50000]	Loss: 6.0375
Training Epoch: 0 [280/50000]	Loss: 5.2169
Training Epoch: 0 [288/50000]	Loss: 5.5652
Training Epoch: 0 [296/50000]	Loss: 5.6789
Training Epoch: 0 [304/50000]	Loss: 5.4027
Training Epoch: 0 [312/50000]	Loss: 4.7378
Training Epoch: 0 [320/50000]	Loss: 5.2521
Training Epoch: 0 [328/50000]	Loss: 5.4569
Training Epoch: 0 [336/50000]	Loss: 5.0850
Training Epoch: 0 [344/50000]	Loss: 4.5766
Training Epoch: 0 [352/50000]	Loss: 4.8281
Training Epoch: 0 [360/50000]	Loss: 5.5910
Training Epoch: 0 [368/50000]	Loss: 4.8768
Training Epoch: 0 [376/50000]	Loss: 5.1459
Training Epoch: 0 [384/50000]	Loss: 4.7050
Training Epoch: 0 [392/50000]	Loss: 4.8695
Training Epoch: 0 [400/50000]	Loss: 4.5505
Profile done with power limit 100W
epoch 1 train time consumed: 3.10s
Validation Epoch: 0, Average loss: 0.6341, Accuracy: 0.0110
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 8, 'pl': 100000, 'lr': 0.0012, 'energy': 98.85381112977177, 'time': 2.1527620870001556, 'accuracy': 0.011, 'total_cost': 3460.7956151838007}

[Power Profiler] with batch size 16 and learning rate 0.0011313708498984763
[run job] Launching job with BS 16: and LR: 0.0011313708498984763 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00113+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0011313708498984763', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0011313708498984763', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00113+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0011313708498984763
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6490
Training Epoch: 0 [48/50000]	Loss: 4.9718
Training Epoch: 0 [64/50000]	Loss: 5.0903
Training Epoch: 0 [80/50000]	Loss: 5.0091
Training Epoch: 0 [96/50000]	Loss: 5.2247
Training Epoch: 0 [112/50000]	Loss: 5.2756
Training Epoch: 0 [128/50000]	Loss: 5.5316
Training Epoch: 0 [144/50000]	Loss: 5.3331
Training Epoch: 0 [160/50000]	Loss: 5.5151
Training Epoch: 0 [176/50000]	Loss: 5.2496
Training Epoch: 0 [192/50000]	Loss: 4.9326
Training Epoch: 0 [208/50000]	Loss: 5.5415
Training Epoch: 0 [224/50000]	Loss: 5.0178
Training Epoch: 0 [240/50000]	Loss: 5.0435
Training Epoch: 0 [256/50000]	Loss: 5.3229
Training Epoch: 0 [272/50000]	Loss: 4.9788
Training Epoch: 0 [288/50000]	Loss: 5.2909
Training Epoch: 0 [304/50000]	Loss: 5.4066
Training Epoch: 0 [320/50000]	Loss: 4.9469
Training Epoch: 0 [336/50000]	Loss: 5.2789
Training Epoch: 0 [352/50000]	Loss: 4.7441
Training Epoch: 0 [368/50000]	Loss: 5.5857
Training Epoch: 0 [384/50000]	Loss: 4.8695
Training Epoch: 0 [400/50000]	Loss: 4.8443
Training Epoch: 0 [416/50000]	Loss: 4.6932
Training Epoch: 0 [432/50000]	Loss: 4.5161
Training Epoch: 0 [448/50000]	Loss: 5.0030
Training Epoch: 0 [464/50000]	Loss: 4.9399
Training Epoch: 0 [480/50000]	Loss: 5.1249
Training Epoch: 0 [496/50000]	Loss: 4.9573
Training Epoch: 0 [512/50000]	Loss: 4.9478
Training Epoch: 0 [528/50000]	Loss: 4.6824
Training Epoch: 0 [544/50000]	Loss: 4.7299
Training Epoch: 0 [560/50000]	Loss: 4.6467
Training Epoch: 0 [576/50000]	Loss: 4.6874
Training Epoch: 0 [592/50000]	Loss: 4.9936
Training Epoch: 0 [608/50000]	Loss: 5.0501
Training Epoch: 0 [624/50000]	Loss: 5.7873
Training Epoch: 0 [640/50000]	Loss: 5.0339
Training Epoch: 0 [656/50000]	Loss: 5.1309
Training Epoch: 0 [672/50000]	Loss: 4.6338
Training Epoch: 0 [688/50000]	Loss: 5.0002
Training Epoch: 0 [704/50000]	Loss: 4.5104
Training Epoch: 0 [720/50000]	Loss: 4.9869
Training Epoch: 0 [736/50000]	Loss: 4.8397
Training Epoch: 0 [752/50000]	Loss: 4.8692
Training Epoch: 0 [768/50000]	Loss: 5.2208
Training Epoch: 0 [784/50000]	Loss: 4.8458
Training Epoch: 0 [800/50000]	Loss: 4.9300
Profile done with power limit 175W
epoch 1 train time consumed: 3.51s
Validation Epoch: 0, Average loss: 0.3036, Accuracy: 0.0136
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 175000, 'lr': 0.0011313708498984763, 'energy': 119.16474429591176, 'time': 2.399495442999978, 'accuracy': 0.0136, 'total_cost': 6245.2690043651855}
[run job] Launching job with BS 16: and LR: 0.0011313708498984763 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00113+pl150', 'ZEUS_COST_THRESH': '12490.538008730371', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0011313708498984763', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0011313708498984763', '--power_limit', '150']
[run job] cost_ub=12490.538008730371
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00113+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0011313708498984763
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6490
Training Epoch: 0 [48/50000]	Loss: 4.9712
Training Epoch: 0 [64/50000]	Loss: 5.0812
Training Epoch: 0 [80/50000]	Loss: 5.0019
Training Epoch: 0 [96/50000]	Loss: 5.1906
Training Epoch: 0 [112/50000]	Loss: 5.3195
Training Epoch: 0 [128/50000]	Loss: 5.5452
Training Epoch: 0 [144/50000]	Loss: 5.3130
Training Epoch: 0 [160/50000]	Loss: 5.4563
Training Epoch: 0 [176/50000]	Loss: 5.2171
Training Epoch: 0 [192/50000]	Loss: 4.9865
Training Epoch: 0 [208/50000]	Loss: 5.5453
Training Epoch: 0 [224/50000]	Loss: 5.0070
Training Epoch: 0 [240/50000]	Loss: 5.0890
Training Epoch: 0 [256/50000]	Loss: 5.3301
Training Epoch: 0 [272/50000]	Loss: 4.9890
Training Epoch: 0 [288/50000]	Loss: 5.3830
Training Epoch: 0 [304/50000]	Loss: 5.4726
Training Epoch: 0 [320/50000]	Loss: 4.8929
Training Epoch: 0 [336/50000]	Loss: 5.2449
Training Epoch: 0 [352/50000]	Loss: 4.7837
Training Epoch: 0 [368/50000]	Loss: 5.5993
Training Epoch: 0 [384/50000]	Loss: 4.8462
Training Epoch: 0 [400/50000]	Loss: 4.8153
Training Epoch: 0 [416/50000]	Loss: 4.7819
Training Epoch: 0 [432/50000]	Loss: 4.5264
Training Epoch: 0 [448/50000]	Loss: 4.9582
Training Epoch: 0 [464/50000]	Loss: 4.9166
Training Epoch: 0 [480/50000]	Loss: 5.1677
Training Epoch: 0 [496/50000]	Loss: 5.0382
Training Epoch: 0 [512/50000]	Loss: 4.9984
Training Epoch: 0 [528/50000]	Loss: 4.6572
Training Epoch: 0 [544/50000]	Loss: 4.8083
Training Epoch: 0 [560/50000]	Loss: 4.6687
Training Epoch: 0 [576/50000]	Loss: 4.5617
Training Epoch: 0 [592/50000]	Loss: 4.9772
Training Epoch: 0 [608/50000]	Loss: 4.9956
Training Epoch: 0 [624/50000]	Loss: 5.6945
Training Epoch: 0 [640/50000]	Loss: 5.0324
Training Epoch: 0 [656/50000]	Loss: 5.1831
Training Epoch: 0 [672/50000]	Loss: 4.5740
Training Epoch: 0 [688/50000]	Loss: 5.0859
Training Epoch: 0 [704/50000]	Loss: 4.4982
Training Epoch: 0 [720/50000]	Loss: 4.9802
Training Epoch: 0 [736/50000]	Loss: 4.8780
Training Epoch: 0 [752/50000]	Loss: 4.9557
Training Epoch: 0 [768/50000]	Loss: 5.2106
Training Epoch: 0 [784/50000]	Loss: 4.7787
Training Epoch: 0 [800/50000]	Loss: 4.8696
Profile done with power limit 150W
epoch 1 train time consumed: 3.53s
Validation Epoch: 0, Average loss: 0.3018, Accuracy: 0.0155
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 150000, 'lr': 0.0011313708498984763, 'energy': 119.00673838707917, 'time': 2.428186985999673, 'accuracy': 0.0155, 'total_cost': 5544.425704328077}
[run job] Launching job with BS 16: and LR: 0.0011313708498984763 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00113+pl125', 'ZEUS_COST_THRESH': '11088.851408656154', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0011313708498984763', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0011313708498984763', '--power_limit', '125']
[run job] cost_ub=11088.851408656154
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00113+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0011313708498984763
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6490
Training Epoch: 0 [48/50000]	Loss: 4.9718
Training Epoch: 0 [64/50000]	Loss: 5.0907
Training Epoch: 0 [80/50000]	Loss: 5.0010
Training Epoch: 0 [96/50000]	Loss: 5.1925
Training Epoch: 0 [112/50000]	Loss: 5.3497
Training Epoch: 0 [128/50000]	Loss: 5.5452
Training Epoch: 0 [144/50000]	Loss: 5.3235
Training Epoch: 0 [160/50000]	Loss: 5.4709
Training Epoch: 0 [176/50000]	Loss: 5.2559
Training Epoch: 0 [192/50000]	Loss: 4.9643
Training Epoch: 0 [208/50000]	Loss: 5.5614
Training Epoch: 0 [224/50000]	Loss: 5.0579
Training Epoch: 0 [240/50000]	Loss: 5.0100
Training Epoch: 0 [256/50000]	Loss: 5.2944
Training Epoch: 0 [272/50000]	Loss: 5.0355
Training Epoch: 0 [288/50000]	Loss: 5.4019
Training Epoch: 0 [304/50000]	Loss: 5.4997
Training Epoch: 0 [320/50000]	Loss: 4.9340
Training Epoch: 0 [336/50000]	Loss: 5.2275
Training Epoch: 0 [352/50000]	Loss: 4.7048
Training Epoch: 0 [368/50000]	Loss: 5.5395
Training Epoch: 0 [384/50000]	Loss: 4.9539
Training Epoch: 0 [400/50000]	Loss: 4.8100
Training Epoch: 0 [416/50000]	Loss: 4.7943
Training Epoch: 0 [432/50000]	Loss: 4.5678
Training Epoch: 0 [448/50000]	Loss: 5.0083
Training Epoch: 0 [464/50000]	Loss: 4.9785
Training Epoch: 0 [480/50000]	Loss: 5.1103
Training Epoch: 0 [496/50000]	Loss: 4.9138
Training Epoch: 0 [512/50000]	Loss: 4.9251
Training Epoch: 0 [528/50000]	Loss: 4.7112
Training Epoch: 0 [544/50000]	Loss: 4.7990
Training Epoch: 0 [560/50000]	Loss: 4.6374
Training Epoch: 0 [576/50000]	Loss: 4.6438
Training Epoch: 0 [592/50000]	Loss: 4.9731
Training Epoch: 0 [608/50000]	Loss: 4.9492
Training Epoch: 0 [624/50000]	Loss: 5.6572
Training Epoch: 0 [640/50000]	Loss: 4.9359
Training Epoch: 0 [656/50000]	Loss: 5.1678
Training Epoch: 0 [672/50000]	Loss: 4.6046
Training Epoch: 0 [688/50000]	Loss: 5.0250
Training Epoch: 0 [704/50000]	Loss: 4.4981
Training Epoch: 0 [720/50000]	Loss: 4.9181
Training Epoch: 0 [736/50000]	Loss: 4.8815
Training Epoch: 0 [752/50000]	Loss: 5.0178
Training Epoch: 0 [768/50000]	Loss: 5.1869
Training Epoch: 0 [784/50000]	Loss: 4.7875
Training Epoch: 0 [800/50000]	Loss: 4.8758
Profile done with power limit 125W
epoch 1 train time consumed: 3.50s
Validation Epoch: 0, Average loss: 0.3023, Accuracy: 0.0124
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 125000, 'lr': 0.0011313708498984763, 'energy': 118.46771862727344, 'time': 2.377351772000111, 'accuracy': 0.0124, 'total_cost': 6786.697884598553}
[run job] Launching job with BS 16: and LR: 0.0011313708498984763 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00113+pl100', 'ZEUS_COST_THRESH': '11088.851408656154', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0011313708498984763', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0011313708498984763', '--power_limit', '100']
[run job] cost_ub=11088.851408656154
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00113+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0011313708498984763
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6490
Training Epoch: 0 [48/50000]	Loss: 4.9718
Training Epoch: 0 [64/50000]	Loss: 5.0877
Training Epoch: 0 [80/50000]	Loss: 4.9882
Training Epoch: 0 [96/50000]	Loss: 5.2299
Training Epoch: 0 [112/50000]	Loss: 5.3396
Training Epoch: 0 [128/50000]	Loss: 5.5101
Training Epoch: 0 [144/50000]	Loss: 5.3101
Training Epoch: 0 [160/50000]	Loss: 5.4634
Training Epoch: 0 [176/50000]	Loss: 5.1884
Training Epoch: 0 [192/50000]	Loss: 4.9439
Training Epoch: 0 [208/50000]	Loss: 5.5903
Training Epoch: 0 [224/50000]	Loss: 5.0131
Training Epoch: 0 [240/50000]	Loss: 5.0221
Training Epoch: 0 [256/50000]	Loss: 5.2532
Training Epoch: 0 [272/50000]	Loss: 4.9969
Training Epoch: 0 [288/50000]	Loss: 5.3245
Training Epoch: 0 [304/50000]	Loss: 5.5211
Training Epoch: 0 [320/50000]	Loss: 4.9429
Training Epoch: 0 [336/50000]	Loss: 5.2522
Training Epoch: 0 [352/50000]	Loss: 4.7841
Training Epoch: 0 [368/50000]	Loss: 5.6115
Training Epoch: 0 [384/50000]	Loss: 4.8640
Training Epoch: 0 [400/50000]	Loss: 4.8933
Training Epoch: 0 [416/50000]	Loss: 4.7753
Training Epoch: 0 [432/50000]	Loss: 4.5640
Training Epoch: 0 [448/50000]	Loss: 4.9516
Training Epoch: 0 [464/50000]	Loss: 4.9478
Training Epoch: 0 [480/50000]	Loss: 5.1021
Training Epoch: 0 [496/50000]	Loss: 4.9788
Training Epoch: 0 [512/50000]	Loss: 4.9476
Training Epoch: 0 [528/50000]	Loss: 4.6576
Training Epoch: 0 [544/50000]	Loss: 4.7632
Training Epoch: 0 [560/50000]	Loss: 4.6554
Training Epoch: 0 [576/50000]	Loss: 4.5850
Training Epoch: 0 [592/50000]	Loss: 4.9268
Training Epoch: 0 [608/50000]	Loss: 4.9499
Training Epoch: 0 [624/50000]	Loss: 5.6366
Training Epoch: 0 [640/50000]	Loss: 4.9704
Training Epoch: 0 [656/50000]	Loss: 5.1874
Training Epoch: 0 [672/50000]	Loss: 4.6475
Training Epoch: 0 [688/50000]	Loss: 4.9808
Training Epoch: 0 [704/50000]	Loss: 4.4593
Training Epoch: 0 [720/50000]	Loss: 5.0008
Training Epoch: 0 [736/50000]	Loss: 4.8127
Training Epoch: 0 [752/50000]	Loss: 4.9222
Training Epoch: 0 [768/50000]	Loss: 5.2501
Training Epoch: 0 [784/50000]	Loss: 4.7623
Training Epoch: 0 [800/50000]	Loss: 4.9665
Profile done with power limit 100W
epoch 1 train time consumed: 3.86s
Validation Epoch: 0, Average loss: 0.3022, Accuracy: 0.0117
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 100000, 'lr': 0.0011313708498984763, 'energy': 98.80763278300427, 'time': 2.764119159999609, 'accuracy': 0.0117, 'total_cost': 8336.293304465842}

[Power Profiler] with batch size 16 and learning rate 0.0014142135623730952
[run job] Launching job with BS 16: and LR: 0.0014142135623730952 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00141+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0014142135623730952', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0014142135623730952', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00141+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0014142135623730952
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6726
Training Epoch: 0 [48/50000]	Loss: 5.0938
Training Epoch: 0 [64/50000]	Loss: 5.2576
Training Epoch: 0 [80/50000]	Loss: 5.2411
Training Epoch: 0 [96/50000]	Loss: 5.4986
Training Epoch: 0 [112/50000]	Loss: 5.5740
Training Epoch: 0 [128/50000]	Loss: 5.7687
Training Epoch: 0 [144/50000]	Loss: 5.4101
Training Epoch: 0 [160/50000]	Loss: 5.6376
Training Epoch: 0 [176/50000]	Loss: 5.3560
Training Epoch: 0 [192/50000]	Loss: 5.0667
Training Epoch: 0 [208/50000]	Loss: 5.7313
Training Epoch: 0 [224/50000]	Loss: 5.0408
Training Epoch: 0 [240/50000]	Loss: 5.0685
Training Epoch: 0 [256/50000]	Loss: 5.3152
Training Epoch: 0 [272/50000]	Loss: 5.2205
Training Epoch: 0 [288/50000]	Loss: 5.5586
Training Epoch: 0 [304/50000]	Loss: 5.6004
Training Epoch: 0 [320/50000]	Loss: 4.9987
Training Epoch: 0 [336/50000]	Loss: 5.3928
Training Epoch: 0 [352/50000]	Loss: 4.8828
Training Epoch: 0 [368/50000]	Loss: 5.7458
Training Epoch: 0 [384/50000]	Loss: 4.8711
Training Epoch: 0 [400/50000]	Loss: 4.9819
Training Epoch: 0 [416/50000]	Loss: 4.7909
Training Epoch: 0 [432/50000]	Loss: 4.5382
Training Epoch: 0 [448/50000]	Loss: 5.1542
Training Epoch: 0 [464/50000]	Loss: 4.9793
Training Epoch: 0 [480/50000]	Loss: 5.2842
Training Epoch: 0 [496/50000]	Loss: 4.9819
Training Epoch: 0 [512/50000]	Loss: 4.9396
Training Epoch: 0 [528/50000]	Loss: 4.7909
Training Epoch: 0 [544/50000]	Loss: 4.8163
Training Epoch: 0 [560/50000]	Loss: 4.7198
Training Epoch: 0 [576/50000]	Loss: 4.6796
Training Epoch: 0 [592/50000]	Loss: 5.0515
Training Epoch: 0 [608/50000]	Loss: 4.9658
Training Epoch: 0 [624/50000]	Loss: 5.7762
Training Epoch: 0 [640/50000]	Loss: 4.9918
Training Epoch: 0 [656/50000]	Loss: 5.2249
Training Epoch: 0 [672/50000]	Loss: 4.7039
Training Epoch: 0 [688/50000]	Loss: 5.0262
Training Epoch: 0 [704/50000]	Loss: 4.6007
Training Epoch: 0 [720/50000]	Loss: 4.9458
Training Epoch: 0 [736/50000]	Loss: 4.9167
Training Epoch: 0 [752/50000]	Loss: 4.9990
Training Epoch: 0 [768/50000]	Loss: 5.2656
Training Epoch: 0 [784/50000]	Loss: 4.7498
Training Epoch: 0 [800/50000]	Loss: 5.0128
Profile done with power limit 175W
epoch 1 train time consumed: 3.48s
Validation Epoch: 0, Average loss: 0.3025, Accuracy: 0.0127
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 175000, 'lr': 0.0014142135623730952, 'energy': 119.16706917530874, 'time': 2.379566980999698, 'accuracy': 0.0127, 'total_cost': 6632.927629007235}
[run job] Launching job with BS 16: and LR: 0.0014142135623730952 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00141+pl150', 'ZEUS_COST_THRESH': '13265.85525801447', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0014142135623730952', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0014142135623730952', '--power_limit', '150']
[run job] cost_ub=13265.85525801447
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00141+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0014142135623730952
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6726
Training Epoch: 0 [48/50000]	Loss: 5.0941
Training Epoch: 0 [64/50000]	Loss: 5.2527
Training Epoch: 0 [80/50000]	Loss: 5.2543
Training Epoch: 0 [96/50000]	Loss: 5.4843
Training Epoch: 0 [112/50000]	Loss: 5.6180
Training Epoch: 0 [128/50000]	Loss: 5.8070
Training Epoch: 0 [144/50000]	Loss: 5.4355
Training Epoch: 0 [160/50000]	Loss: 5.6711
Training Epoch: 0 [176/50000]	Loss: 5.3262
Training Epoch: 0 [192/50000]	Loss: 5.0868
Training Epoch: 0 [208/50000]	Loss: 5.7155
Training Epoch: 0 [224/50000]	Loss: 5.1011
Training Epoch: 0 [240/50000]	Loss: 5.0623
Training Epoch: 0 [256/50000]	Loss: 5.2860
Training Epoch: 0 [272/50000]	Loss: 5.1320
Training Epoch: 0 [288/50000]	Loss: 5.4361
Training Epoch: 0 [304/50000]	Loss: 5.5982
Training Epoch: 0 [320/50000]	Loss: 5.0143
Training Epoch: 0 [336/50000]	Loss: 5.3121
Training Epoch: 0 [352/50000]	Loss: 4.9174
Training Epoch: 0 [368/50000]	Loss: 5.6731
Training Epoch: 0 [384/50000]	Loss: 4.9825
Training Epoch: 0 [400/50000]	Loss: 4.9084
Training Epoch: 0 [416/50000]	Loss: 4.8276
Training Epoch: 0 [432/50000]	Loss: 4.5728
Training Epoch: 0 [448/50000]	Loss: 5.1315
Training Epoch: 0 [464/50000]	Loss: 5.0828
Training Epoch: 0 [480/50000]	Loss: 5.1956
Training Epoch: 0 [496/50000]	Loss: 4.9800
Training Epoch: 0 [512/50000]	Loss: 4.9785
Training Epoch: 0 [528/50000]	Loss: 4.7381
Training Epoch: 0 [544/50000]	Loss: 4.9022
Training Epoch: 0 [560/50000]	Loss: 4.6052
Training Epoch: 0 [576/50000]	Loss: 4.6762
Training Epoch: 0 [592/50000]	Loss: 5.0535
Training Epoch: 0 [608/50000]	Loss: 4.9664
Training Epoch: 0 [624/50000]	Loss: 5.7297
Training Epoch: 0 [640/50000]	Loss: 4.9358
Training Epoch: 0 [656/50000]	Loss: 5.2078
Training Epoch: 0 [672/50000]	Loss: 4.6418
Training Epoch: 0 [688/50000]	Loss: 4.9548
Training Epoch: 0 [704/50000]	Loss: 4.5668
Training Epoch: 0 [720/50000]	Loss: 4.9879
Training Epoch: 0 [736/50000]	Loss: 4.9596
Training Epoch: 0 [752/50000]	Loss: 4.9938
Training Epoch: 0 [768/50000]	Loss: 5.2289
Training Epoch: 0 [784/50000]	Loss: 4.8407
Training Epoch: 0 [800/50000]	Loss: 5.0277
Profile done with power limit 150W
epoch 1 train time consumed: 3.49s
Validation Epoch: 0, Average loss: 0.3029, Accuracy: 0.0113
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 150000, 'lr': 0.0014142135623730952, 'energy': 119.536327530137, 'time': 2.405282826000075, 'accuracy': 0.0113, 'total_cost': 7534.6185424994455}
[run job] Launching job with BS 16: and LR: 0.0014142135623730952 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00141+pl125', 'ZEUS_COST_THRESH': '13265.85525801447', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0014142135623730952', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0014142135623730952', '--power_limit', '125']
[run job] cost_ub=13265.85525801447
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00141+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0014142135623730952
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6726
Training Epoch: 0 [48/50000]	Loss: 5.0941
Training Epoch: 0 [64/50000]	Loss: 5.2492
Training Epoch: 0 [80/50000]	Loss: 5.2371
Training Epoch: 0 [96/50000]	Loss: 5.4567
Training Epoch: 0 [112/50000]	Loss: 5.5606
Training Epoch: 0 [128/50000]	Loss: 5.7647
Training Epoch: 0 [144/50000]	Loss: 5.4220
Training Epoch: 0 [160/50000]	Loss: 5.6429
Training Epoch: 0 [176/50000]	Loss: 5.3441
Training Epoch: 0 [192/50000]	Loss: 5.0142
Training Epoch: 0 [208/50000]	Loss: 5.7168
Training Epoch: 0 [224/50000]	Loss: 5.1331
Training Epoch: 0 [240/50000]	Loss: 5.0839
Training Epoch: 0 [256/50000]	Loss: 5.3086
Training Epoch: 0 [272/50000]	Loss: 5.1565
Training Epoch: 0 [288/50000]	Loss: 5.6053
Training Epoch: 0 [304/50000]	Loss: 5.5626
Training Epoch: 0 [320/50000]	Loss: 5.0316
Training Epoch: 0 [336/50000]	Loss: 5.3462
Training Epoch: 0 [352/50000]	Loss: 4.8368
Training Epoch: 0 [368/50000]	Loss: 5.7070
Training Epoch: 0 [384/50000]	Loss: 5.0190
Training Epoch: 0 [400/50000]	Loss: 4.9276
Training Epoch: 0 [416/50000]	Loss: 4.8596
Training Epoch: 0 [432/50000]	Loss: 4.6297
Training Epoch: 0 [448/50000]	Loss: 5.0793
Training Epoch: 0 [464/50000]	Loss: 5.0383
Training Epoch: 0 [480/50000]	Loss: 5.2729
Training Epoch: 0 [496/50000]	Loss: 5.0200
Training Epoch: 0 [512/50000]	Loss: 5.0054
Training Epoch: 0 [528/50000]	Loss: 4.7744
Training Epoch: 0 [544/50000]	Loss: 4.8901
Training Epoch: 0 [560/50000]	Loss: 4.6829
Training Epoch: 0 [576/50000]	Loss: 4.6730
Training Epoch: 0 [592/50000]	Loss: 5.0363
Training Epoch: 0 [608/50000]	Loss: 4.9755
Training Epoch: 0 [624/50000]	Loss: 5.7180
Training Epoch: 0 [640/50000]	Loss: 4.9896
Training Epoch: 0 [656/50000]	Loss: 5.1601
Training Epoch: 0 [672/50000]	Loss: 4.7248
Training Epoch: 0 [688/50000]	Loss: 5.0218
Training Epoch: 0 [704/50000]	Loss: 4.5563
Training Epoch: 0 [720/50000]	Loss: 4.9400
Training Epoch: 0 [736/50000]	Loss: 4.9934
Training Epoch: 0 [752/50000]	Loss: 5.0091
Training Epoch: 0 [768/50000]	Loss: 5.3135
Training Epoch: 0 [784/50000]	Loss: 4.8414
Training Epoch: 0 [800/50000]	Loss: 5.0004
Profile done with power limit 125W
epoch 1 train time consumed: 3.50s
Validation Epoch: 0, Average loss: 0.3040, Accuracy: 0.0115
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 125000, 'lr': 0.0014142135623730952, 'energy': 119.09760162455575, 'time': 2.385159720000047, 'accuracy': 0.0115, 'total_cost': 7342.032261999832}
[run job] Launching job with BS 16: and LR: 0.0014142135623730952 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00141+pl100', 'ZEUS_COST_THRESH': '13265.85525801447', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0014142135623730952', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0014142135623730952', '--power_limit', '100']
[run job] cost_ub=13265.85525801447
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00141+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0014142135623730952
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6726
Training Epoch: 0 [48/50000]	Loss: 5.0938
Training Epoch: 0 [64/50000]	Loss: 5.2524
Training Epoch: 0 [80/50000]	Loss: 5.2296
Training Epoch: 0 [96/50000]	Loss: 5.4772
Training Epoch: 0 [112/50000]	Loss: 5.5416
Training Epoch: 0 [128/50000]	Loss: 5.7914
Training Epoch: 0 [144/50000]	Loss: 5.4284
Training Epoch: 0 [160/50000]	Loss: 5.6515
Training Epoch: 0 [176/50000]	Loss: 5.2687
Training Epoch: 0 [192/50000]	Loss: 5.0978
Training Epoch: 0 [208/50000]	Loss: 5.7046
Training Epoch: 0 [224/50000]	Loss: 5.1296
Training Epoch: 0 [240/50000]	Loss: 5.0599
Training Epoch: 0 [256/50000]	Loss: 5.2741
Training Epoch: 0 [272/50000]	Loss: 5.1587
Training Epoch: 0 [288/50000]	Loss: 5.5490
Training Epoch: 0 [304/50000]	Loss: 5.6420
Training Epoch: 0 [320/50000]	Loss: 5.0106
Training Epoch: 0 [336/50000]	Loss: 5.4246
Training Epoch: 0 [352/50000]	Loss: 4.8463
Training Epoch: 0 [368/50000]	Loss: 5.6449
Training Epoch: 0 [384/50000]	Loss: 5.0386
Training Epoch: 0 [400/50000]	Loss: 4.9667
Training Epoch: 0 [416/50000]	Loss: 4.8411
Training Epoch: 0 [432/50000]	Loss: 4.5669
Training Epoch: 0 [448/50000]	Loss: 5.0845
Training Epoch: 0 [464/50000]	Loss: 5.0524
Training Epoch: 0 [480/50000]	Loss: 5.2740
Training Epoch: 0 [496/50000]	Loss: 4.9246
Training Epoch: 0 [512/50000]	Loss: 4.9866
Training Epoch: 0 [528/50000]	Loss: 4.7021
Training Epoch: 0 [544/50000]	Loss: 4.8536
Training Epoch: 0 [560/50000]	Loss: 4.6559
Training Epoch: 0 [576/50000]	Loss: 4.6276
Training Epoch: 0 [592/50000]	Loss: 5.0112
Training Epoch: 0 [608/50000]	Loss: 5.0426
Training Epoch: 0 [624/50000]	Loss: 5.7496
Training Epoch: 0 [640/50000]	Loss: 4.9107
Training Epoch: 0 [656/50000]	Loss: 5.2404
Training Epoch: 0 [672/50000]	Loss: 4.6646
Training Epoch: 0 [688/50000]	Loss: 5.0217
Training Epoch: 0 [704/50000]	Loss: 4.5282
Training Epoch: 0 [720/50000]	Loss: 4.9680
Training Epoch: 0 [736/50000]	Loss: 5.0093
Training Epoch: 0 [752/50000]	Loss: 4.9102
Training Epoch: 0 [768/50000]	Loss: 5.3251
Training Epoch: 0 [784/50000]	Loss: 4.8107
Training Epoch: 0 [800/50000]	Loss: 4.9754
Profile done with power limit 100W
epoch 1 train time consumed: 3.84s
Validation Epoch: 0, Average loss: 0.3031, Accuracy: 0.0107
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 100000, 'lr': 0.0014142135623730952, 'energy': 98.86307504392245, 'time': 2.720416665999437, 'accuracy': 0.0107, 'total_cost': 8972.475505638475}

[Power Profiler] with batch size 16 and learning rate 0.0016970562748477142
[run job] Launching job with BS 16: and LR: 0.0016970562748477142 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00170+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0016970562748477142', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016970562748477142', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00170+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0016970562748477142
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6893
Training Epoch: 0 [48/50000]	Loss: 5.2452
Training Epoch: 0 [64/50000]	Loss: 5.4695
Training Epoch: 0 [80/50000]	Loss: 5.3562
Training Epoch: 0 [96/50000]	Loss: 5.7835
Training Epoch: 0 [112/50000]	Loss: 5.7633
Training Epoch: 0 [128/50000]	Loss: 5.9494
Training Epoch: 0 [144/50000]	Loss: 5.5290
Training Epoch: 0 [160/50000]	Loss: 5.7479
Training Epoch: 0 [176/50000]	Loss: 5.3502
Training Epoch: 0 [192/50000]	Loss: 5.1491
Training Epoch: 0 [208/50000]	Loss: 5.9424
Training Epoch: 0 [224/50000]	Loss: 5.2105
Training Epoch: 0 [240/50000]	Loss: 5.1588
Training Epoch: 0 [256/50000]	Loss: 5.4209
Training Epoch: 0 [272/50000]	Loss: 5.3492
Training Epoch: 0 [288/50000]	Loss: 5.8560
Training Epoch: 0 [304/50000]	Loss: 5.7596
Training Epoch: 0 [320/50000]	Loss: 5.1286
Training Epoch: 0 [336/50000]	Loss: 5.4168
Training Epoch: 0 [352/50000]	Loss: 4.9572
Training Epoch: 0 [368/50000]	Loss: 5.6753
Training Epoch: 0 [384/50000]	Loss: 5.0176
Training Epoch: 0 [400/50000]	Loss: 4.9249
Training Epoch: 0 [416/50000]	Loss: 4.8086
Training Epoch: 0 [432/50000]	Loss: 4.5311
Training Epoch: 0 [448/50000]	Loss: 5.2769
Training Epoch: 0 [464/50000]	Loss: 4.9421
Training Epoch: 0 [480/50000]	Loss: 5.4511
Training Epoch: 0 [496/50000]	Loss: 4.7732
Training Epoch: 0 [512/50000]	Loss: 5.1545
Training Epoch: 0 [528/50000]	Loss: 4.8306
Training Epoch: 0 [544/50000]	Loss: 5.0692
Training Epoch: 0 [560/50000]	Loss: 4.7484
Training Epoch: 0 [576/50000]	Loss: 4.5344
Training Epoch: 0 [592/50000]	Loss: 5.0471
Training Epoch: 0 [608/50000]	Loss: 5.0928
Training Epoch: 0 [624/50000]	Loss: 5.7328
Training Epoch: 0 [640/50000]	Loss: 4.9487
Training Epoch: 0 [656/50000]	Loss: 5.2539
Training Epoch: 0 [672/50000]	Loss: 4.6589
Training Epoch: 0 [688/50000]	Loss: 5.0643
Training Epoch: 0 [704/50000]	Loss: 4.5950
Training Epoch: 0 [720/50000]	Loss: 4.9782
Training Epoch: 0 [736/50000]	Loss: 5.0322
Training Epoch: 0 [752/50000]	Loss: 4.9699
Training Epoch: 0 [768/50000]	Loss: 5.1774
Training Epoch: 0 [784/50000]	Loss: 4.7677
Training Epoch: 0 [800/50000]	Loss: 5.0695
Profile done with power limit 175W
epoch 1 train time consumed: 3.44s
Validation Epoch: 0, Average loss: 0.3155, Accuracy: 0.0137
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 175000, 'lr': 0.0016970562748477142, 'energy': 120.03575224834562, 'time': 2.36030059299992, 'accuracy': 0.0137, 'total_cost': 6100.058888538975}
[run job] Launching job with BS 16: and LR: 0.0016970562748477142 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00170+pl150', 'ZEUS_COST_THRESH': '12200.11777707795', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0016970562748477142', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016970562748477142', '--power_limit', '150']
[run job] cost_ub=12200.11777707795
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00170+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0016970562748477142
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6893
Training Epoch: 0 [48/50000]	Loss: 5.2455
Training Epoch: 0 [64/50000]	Loss: 5.4550
Training Epoch: 0 [80/50000]	Loss: 5.3921
Training Epoch: 0 [96/50000]	Loss: 5.7744
Training Epoch: 0 [112/50000]	Loss: 5.8211
Training Epoch: 0 [128/50000]	Loss: 5.9910
Training Epoch: 0 [144/50000]	Loss: 5.5579
Training Epoch: 0 [160/50000]	Loss: 5.7310
Training Epoch: 0 [176/50000]	Loss: 5.4096
Training Epoch: 0 [192/50000]	Loss: 5.1336
Training Epoch: 0 [208/50000]	Loss: 5.9953
Training Epoch: 0 [224/50000]	Loss: 5.2462
Training Epoch: 0 [240/50000]	Loss: 5.1023
Training Epoch: 0 [256/50000]	Loss: 5.3778
Training Epoch: 0 [272/50000]	Loss: 5.4331
Training Epoch: 0 [288/50000]	Loss: 5.8725
Training Epoch: 0 [304/50000]	Loss: 5.8378
Training Epoch: 0 [320/50000]	Loss: 5.0425
Training Epoch: 0 [336/50000]	Loss: 5.4400
Training Epoch: 0 [352/50000]	Loss: 5.0096
Training Epoch: 0 [368/50000]	Loss: 5.6925
Training Epoch: 0 [384/50000]	Loss: 4.9493
Training Epoch: 0 [400/50000]	Loss: 4.8299
Training Epoch: 0 [416/50000]	Loss: 4.8926
Training Epoch: 0 [432/50000]	Loss: 4.4702
Training Epoch: 0 [448/50000]	Loss: 5.2452
Training Epoch: 0 [464/50000]	Loss: 4.8923
Training Epoch: 0 [480/50000]	Loss: 5.4755
Training Epoch: 0 [496/50000]	Loss: 4.8587
Training Epoch: 0 [512/50000]	Loss: 5.1133
Training Epoch: 0 [528/50000]	Loss: 4.8673
Training Epoch: 0 [544/50000]	Loss: 4.9944
Training Epoch: 0 [560/50000]	Loss: 4.6831
Training Epoch: 0 [576/50000]	Loss: 4.5276
Training Epoch: 0 [592/50000]	Loss: 5.0301
Training Epoch: 0 [608/50000]	Loss: 5.0816
Training Epoch: 0 [624/50000]	Loss: 5.7144
Training Epoch: 0 [640/50000]	Loss: 4.9568
Training Epoch: 0 [656/50000]	Loss: 5.2889
Training Epoch: 0 [672/50000]	Loss: 4.7273
Training Epoch: 0 [688/50000]	Loss: 5.1528
Training Epoch: 0 [704/50000]	Loss: 4.6438
Training Epoch: 0 [720/50000]	Loss: 4.9644
Training Epoch: 0 [736/50000]	Loss: 4.9275
Training Epoch: 0 [752/50000]	Loss: 4.8303
Training Epoch: 0 [768/50000]	Loss: 5.1422
Training Epoch: 0 [784/50000]	Loss: 4.7107
Training Epoch: 0 [800/50000]	Loss: 5.0494
Profile done with power limit 150W
epoch 1 train time consumed: 3.47s
Validation Epoch: 0, Average loss: 0.3806, Accuracy: 0.0181
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 150000, 'lr': 0.0016970562748477142, 'energy': 119.10154138373669, 'time': 2.380568048999521, 'accuracy': 0.0181, 'total_cost': 4655.949947295753}
[run job] Launching job with BS 16: and LR: 0.0016970562748477142 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00170+pl125', 'ZEUS_COST_THRESH': '9311.899894591506', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0016970562748477142', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016970562748477142', '--power_limit', '125']
[run job] cost_ub=9311.899894591506
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00170+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0016970562748477142
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6893
Training Epoch: 0 [48/50000]	Loss: 5.2453
Training Epoch: 0 [64/50000]	Loss: 5.4590
Training Epoch: 0 [80/50000]	Loss: 5.3749
Training Epoch: 0 [96/50000]	Loss: 5.7293
Training Epoch: 0 [112/50000]	Loss: 5.7824
Training Epoch: 0 [128/50000]	Loss: 6.0234
Training Epoch: 0 [144/50000]	Loss: 5.5514
Training Epoch: 0 [160/50000]	Loss: 5.7300
Training Epoch: 0 [176/50000]	Loss: 5.3965
Training Epoch: 0 [192/50000]	Loss: 5.0902
Training Epoch: 0 [208/50000]	Loss: 5.9307
Training Epoch: 0 [224/50000]	Loss: 5.2019
Training Epoch: 0 [240/50000]	Loss: 5.1117
Training Epoch: 0 [256/50000]	Loss: 5.4237
Training Epoch: 0 [272/50000]	Loss: 5.3321
Training Epoch: 0 [288/50000]	Loss: 5.8600
Training Epoch: 0 [304/50000]	Loss: 5.7664
Training Epoch: 0 [320/50000]	Loss: 5.0793
Training Epoch: 0 [336/50000]	Loss: 5.3711
Training Epoch: 0 [352/50000]	Loss: 4.9965
Training Epoch: 0 [368/50000]	Loss: 5.6827
Training Epoch: 0 [384/50000]	Loss: 4.8673
Training Epoch: 0 [400/50000]	Loss: 4.8248
Training Epoch: 0 [416/50000]	Loss: 4.9420
Training Epoch: 0 [432/50000]	Loss: 4.6357
Training Epoch: 0 [448/50000]	Loss: 5.2584
Training Epoch: 0 [464/50000]	Loss: 5.0566
Training Epoch: 0 [480/50000]	Loss: 5.4635
Training Epoch: 0 [496/50000]	Loss: 4.8610
Training Epoch: 0 [512/50000]	Loss: 5.1444
Training Epoch: 0 [528/50000]	Loss: 4.7039
Training Epoch: 0 [544/50000]	Loss: 4.9866
Training Epoch: 0 [560/50000]	Loss: 4.5277
Training Epoch: 0 [576/50000]	Loss: 4.4214
Training Epoch: 0 [592/50000]	Loss: 5.0588
Training Epoch: 0 [608/50000]	Loss: 5.0977
Training Epoch: 0 [624/50000]	Loss: 5.6683
Training Epoch: 0 [640/50000]	Loss: 5.0169
Training Epoch: 0 [656/50000]	Loss: 5.3541
Training Epoch: 0 [672/50000]	Loss: 4.7383
Training Epoch: 0 [688/50000]	Loss: 5.0733
Training Epoch: 0 [704/50000]	Loss: 4.5247
Training Epoch: 0 [720/50000]	Loss: 5.0170
Training Epoch: 0 [736/50000]	Loss: 4.9086
Training Epoch: 0 [752/50000]	Loss: 4.7462
Training Epoch: 0 [768/50000]	Loss: 5.1855
Training Epoch: 0 [784/50000]	Loss: 4.6532
Training Epoch: 0 [800/50000]	Loss: 4.9562
Profile done with power limit 125W
epoch 1 train time consumed: 3.59s
Validation Epoch: 0, Average loss: 0.3596, Accuracy: 0.0183
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 125000, 'lr': 0.0016970562748477142, 'energy': 118.21730940759197, 'time': 2.453952830000162, 'accuracy': 0.0183, 'total_cost': 4745.032105205814}
[run job] Launching job with BS 16: and LR: 0.0016970562748477142 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs16+lr0.00170+pl100', 'ZEUS_COST_THRESH': '9311.899894591506', 'ZEUS_BATCH_SIZE': '16', 'ZEUS_LEARNING_RATE': '0.0016970562748477142', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '16', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016970562748477142', '--power_limit', '100']
[run job] cost_ub=9311.899894591506
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs16+lr0.00170+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0016970562748477142
batch size arg: 16
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [16/50000]	Loss: 4.6697
Training Epoch: 0 [32/50000]	Loss: 4.6893
Training Epoch: 0 [48/50000]	Loss: 5.2471
Training Epoch: 0 [64/50000]	Loss: 5.4498
Training Epoch: 0 [80/50000]	Loss: 5.3863
Training Epoch: 0 [96/50000]	Loss: 5.7651
Training Epoch: 0 [112/50000]	Loss: 5.7600
Training Epoch: 0 [128/50000]	Loss: 5.9640
Training Epoch: 0 [144/50000]	Loss: 5.5339
Training Epoch: 0 [160/50000]	Loss: 5.8117
Training Epoch: 0 [176/50000]	Loss: 5.3980
Training Epoch: 0 [192/50000]	Loss: 5.1453
Training Epoch: 0 [208/50000]	Loss: 5.9513
Training Epoch: 0 [224/50000]	Loss: 5.1964
Training Epoch: 0 [240/50000]	Loss: 5.1468
Training Epoch: 0 [256/50000]	Loss: 5.3617
Training Epoch: 0 [272/50000]	Loss: 5.3489
Training Epoch: 0 [288/50000]	Loss: 5.8907
Training Epoch: 0 [304/50000]	Loss: 5.7386
Training Epoch: 0 [320/50000]	Loss: 5.0832
Training Epoch: 0 [336/50000]	Loss: 5.4404
Training Epoch: 0 [352/50000]	Loss: 5.0523
Training Epoch: 0 [368/50000]	Loss: 5.7750
Training Epoch: 0 [384/50000]	Loss: 5.0088
Training Epoch: 0 [400/50000]	Loss: 4.9656
Training Epoch: 0 [416/50000]	Loss: 4.9232
Training Epoch: 0 [432/50000]	Loss: 4.6790
Training Epoch: 0 [448/50000]	Loss: 5.2288
Training Epoch: 0 [464/50000]	Loss: 5.0706
Training Epoch: 0 [480/50000]	Loss: 5.4122
Training Epoch: 0 [496/50000]	Loss: 4.9502
Training Epoch: 0 [512/50000]	Loss: 5.0348
Training Epoch: 0 [528/50000]	Loss: 4.9009
Training Epoch: 0 [544/50000]	Loss: 4.9791
Training Epoch: 0 [560/50000]	Loss: 4.7871
Training Epoch: 0 [576/50000]	Loss: 4.6843
Training Epoch: 0 [592/50000]	Loss: 5.0712
Training Epoch: 0 [608/50000]	Loss: 5.0052
Training Epoch: 0 [624/50000]	Loss: 5.8236
Training Epoch: 0 [640/50000]	Loss: 5.0077
Training Epoch: 0 [656/50000]	Loss: 5.2578
Training Epoch: 0 [672/50000]	Loss: 4.6448
Training Epoch: 0 [688/50000]	Loss: 5.0399
Training Epoch: 0 [704/50000]	Loss: 4.6750
Training Epoch: 0 [720/50000]	Loss: 5.0553
Training Epoch: 0 [736/50000]	Loss: 5.0673
Training Epoch: 0 [752/50000]	Loss: 4.9141
Training Epoch: 0 [768/50000]	Loss: 5.2868
Training Epoch: 0 [784/50000]	Loss: 4.8118
Training Epoch: 0 [800/50000]	Loss: 4.9850
Profile done with power limit 100W
epoch 1 train time consumed: 3.91s
Validation Epoch: 0, Average loss: 0.3044, Accuracy: 0.0129
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 16, 'pl': 100000, 'lr': 0.0016970562748477142, 'energy': 98.71348214406946, 'time': 2.781845909999902, 'accuracy': 0.0129, 'total_cost': 7608.861605205358}

[Power Profiler] with batch size 32 and learning rate 0.0016
[run job] Launching job with BS 32: and LR: 0.0016 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00160+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0016', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00160+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0016
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 4.8917
Training Epoch: 0 [96/50016]	Loss: 4.9881
Training Epoch: 0 [128/50016]	Loss: 5.1889
Training Epoch: 0 [160/50016]	Loss: 5.3171
Training Epoch: 0 [192/50016]	Loss: 5.0892
Training Epoch: 0 [224/50016]	Loss: 5.1217
Training Epoch: 0 [256/50016]	Loss: 5.1263
Training Epoch: 0 [288/50016]	Loss: 5.0478
Training Epoch: 0 [320/50016]	Loss: 5.1280
Training Epoch: 0 [352/50016]	Loss: 4.9934
Training Epoch: 0 [384/50016]	Loss: 5.3253
Training Epoch: 0 [416/50016]	Loss: 4.9902
Training Epoch: 0 [448/50016]	Loss: 4.8048
Training Epoch: 0 [480/50016]	Loss: 5.0610
Training Epoch: 0 [512/50016]	Loss: 4.9898
Training Epoch: 0 [544/50016]	Loss: 4.7750
Training Epoch: 0 [576/50016]	Loss: 4.6044
Training Epoch: 0 [608/50016]	Loss: 5.0858
Training Epoch: 0 [640/50016]	Loss: 5.4281
Training Epoch: 0 [672/50016]	Loss: 4.8971
Training Epoch: 0 [704/50016]	Loss: 4.6016
Training Epoch: 0 [736/50016]	Loss: 5.0039
Training Epoch: 0 [768/50016]	Loss: 5.3308
Training Epoch: 0 [800/50016]	Loss: 4.9414
Training Epoch: 0 [832/50016]	Loss: 4.9974
Training Epoch: 0 [864/50016]	Loss: 5.2592
Training Epoch: 0 [896/50016]	Loss: 4.6226
Training Epoch: 0 [928/50016]	Loss: 4.7751
Training Epoch: 0 [960/50016]	Loss: 4.7043
Training Epoch: 0 [992/50016]	Loss: 4.7762
Training Epoch: 0 [1024/50016]	Loss: 4.7745
Training Epoch: 0 [1056/50016]	Loss: 5.0124
Training Epoch: 0 [1088/50016]	Loss: 4.8053
Training Epoch: 0 [1120/50016]	Loss: 4.8758
Training Epoch: 0 [1152/50016]	Loss: 4.6037
Training Epoch: 0 [1184/50016]	Loss: 4.7586
Training Epoch: 0 [1216/50016]	Loss: 4.6304
Training Epoch: 0 [1248/50016]	Loss: 4.8279
Training Epoch: 0 [1280/50016]	Loss: 4.7706
Training Epoch: 0 [1312/50016]	Loss: 4.8357
Training Epoch: 0 [1344/50016]	Loss: 4.7550
Training Epoch: 0 [1376/50016]	Loss: 4.5781
Training Epoch: 0 [1408/50016]	Loss: 4.6824
Training Epoch: 0 [1440/50016]	Loss: 4.7651
Training Epoch: 0 [1472/50016]	Loss: 4.3689
Training Epoch: 0 [1504/50016]	Loss: 4.9413
Training Epoch: 0 [1536/50016]	Loss: 4.6308
Training Epoch: 0 [1568/50016]	Loss: 4.8206
Training Epoch: 0 [1600/50016]	Loss: 4.9109
Profile done with power limit 175W
epoch 1 train time consumed: 4.56s
Validation Epoch: 0, Average loss: 0.1756, Accuracy: 0.0229
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 175000, 'lr': 0.0016, 'energy': 134.39973256858428, 'time': 3.211133675000383, 'accuracy': 0.022863418530351436, 'total_cost': 9922.276425075765}
[run job] Launching job with BS 32: and LR: 0.0016 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00160+pl150', 'ZEUS_COST_THRESH': '19844.55285015153', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0016', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016', '--power_limit', '150']
[run job] cost_ub=19844.55285015153
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00160+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0016
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 4.8917
Training Epoch: 0 [96/50016]	Loss: 4.9878
Training Epoch: 0 [128/50016]	Loss: 5.1853
Training Epoch: 0 [160/50016]	Loss: 5.2974
Training Epoch: 0 [192/50016]	Loss: 5.1206
Training Epoch: 0 [224/50016]	Loss: 5.1099
Training Epoch: 0 [256/50016]	Loss: 5.1369
Training Epoch: 0 [288/50016]	Loss: 5.0369
Training Epoch: 0 [320/50016]	Loss: 5.1437
Training Epoch: 0 [352/50016]	Loss: 4.9560
Training Epoch: 0 [384/50016]	Loss: 5.3216
Training Epoch: 0 [416/50016]	Loss: 4.9691
Training Epoch: 0 [448/50016]	Loss: 4.8701
Training Epoch: 0 [480/50016]	Loss: 5.1260
Training Epoch: 0 [512/50016]	Loss: 5.0166
Training Epoch: 0 [544/50016]	Loss: 4.7914
Training Epoch: 0 [576/50016]	Loss: 4.6095
Training Epoch: 0 [608/50016]	Loss: 5.0277
Training Epoch: 0 [640/50016]	Loss: 5.4980
Training Epoch: 0 [672/50016]	Loss: 4.9410
Training Epoch: 0 [704/50016]	Loss: 4.7021
Training Epoch: 0 [736/50016]	Loss: 5.0649
Training Epoch: 0 [768/50016]	Loss: 5.2262
Training Epoch: 0 [800/50016]	Loss: 4.9312
Training Epoch: 0 [832/50016]	Loss: 5.0968
Training Epoch: 0 [864/50016]	Loss: 5.2188
Training Epoch: 0 [896/50016]	Loss: 4.5550
Training Epoch: 0 [928/50016]	Loss: 4.7154
Training Epoch: 0 [960/50016]	Loss: 4.7186
Training Epoch: 0 [992/50016]	Loss: 4.7948
Training Epoch: 0 [1024/50016]	Loss: 4.7051
Training Epoch: 0 [1056/50016]	Loss: 4.9896
Training Epoch: 0 [1088/50016]	Loss: 4.7099
Training Epoch: 0 [1120/50016]	Loss: 4.9370
Training Epoch: 0 [1152/50016]	Loss: 4.7304
Training Epoch: 0 [1184/50016]	Loss: 4.7508
Training Epoch: 0 [1216/50016]	Loss: 4.6056
Training Epoch: 0 [1248/50016]	Loss: 4.8362
Training Epoch: 0 [1280/50016]	Loss: 4.6888
Training Epoch: 0 [1312/50016]	Loss: 4.6529
Training Epoch: 0 [1344/50016]	Loss: 4.7436
Training Epoch: 0 [1376/50016]	Loss: 4.7248
Training Epoch: 0 [1408/50016]	Loss: 4.6998
Training Epoch: 0 [1440/50016]	Loss: 4.9563
Training Epoch: 0 [1472/50016]	Loss: 4.3693
Training Epoch: 0 [1504/50016]	Loss: 4.6334
Training Epoch: 0 [1536/50016]	Loss: 4.7366
Training Epoch: 0 [1568/50016]	Loss: 4.6612
Training Epoch: 0 [1600/50016]	Loss: 5.1191
Profile done with power limit 150W
epoch 1 train time consumed: 4.53s
Validation Epoch: 0, Average loss: 0.1903, Accuracy: 0.0231
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 150000, 'lr': 0.0016, 'energy': 134.73216590648912, 'time': 3.2192176340004153, 'accuracy': 0.023063099041533548, 'total_cost': 9861.128012758349}
[run job] Launching job with BS 32: and LR: 0.0016 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00160+pl125', 'ZEUS_COST_THRESH': '19722.256025516697', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0016', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016', '--power_limit', '125']
[run job] cost_ub=19722.256025516697
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00160+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0016
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 4.8917
Training Epoch: 0 [96/50016]	Loss: 4.9879
Training Epoch: 0 [128/50016]	Loss: 5.1899
Training Epoch: 0 [160/50016]	Loss: 5.3179
Training Epoch: 0 [192/50016]	Loss: 5.1197
Training Epoch: 0 [224/50016]	Loss: 5.1362
Training Epoch: 0 [256/50016]	Loss: 5.1333
Training Epoch: 0 [288/50016]	Loss: 5.1208
Training Epoch: 0 [320/50016]	Loss: 5.1183
Training Epoch: 0 [352/50016]	Loss: 4.8973
Training Epoch: 0 [384/50016]	Loss: 5.3236
Training Epoch: 0 [416/50016]	Loss: 4.9667
Training Epoch: 0 [448/50016]	Loss: 4.8519
Training Epoch: 0 [480/50016]	Loss: 5.0636
Training Epoch: 0 [512/50016]	Loss: 5.0198
Training Epoch: 0 [544/50016]	Loss: 4.7618
Training Epoch: 0 [576/50016]	Loss: 4.6037
Training Epoch: 0 [608/50016]	Loss: 5.0767
Training Epoch: 0 [640/50016]	Loss: 5.4435
Training Epoch: 0 [672/50016]	Loss: 4.9285
Training Epoch: 0 [704/50016]	Loss: 4.6464
Training Epoch: 0 [736/50016]	Loss: 5.0191
Training Epoch: 0 [768/50016]	Loss: 5.3710
Training Epoch: 0 [800/50016]	Loss: 4.8895
Training Epoch: 0 [832/50016]	Loss: 5.0761
Training Epoch: 0 [864/50016]	Loss: 5.2320
Training Epoch: 0 [896/50016]	Loss: 4.5674
Training Epoch: 0 [928/50016]	Loss: 4.7832
Training Epoch: 0 [960/50016]	Loss: 4.7447
Training Epoch: 0 [992/50016]	Loss: 4.8003
Training Epoch: 0 [1024/50016]	Loss: 4.6716
Training Epoch: 0 [1056/50016]	Loss: 4.9372
Training Epoch: 0 [1088/50016]	Loss: 4.7287
Training Epoch: 0 [1120/50016]	Loss: 4.9218
Training Epoch: 0 [1152/50016]	Loss: 4.7283
Training Epoch: 0 [1184/50016]	Loss: 4.7612
Training Epoch: 0 [1216/50016]	Loss: 4.6662
Training Epoch: 0 [1248/50016]	Loss: 4.8339
Training Epoch: 0 [1280/50016]	Loss: 4.7071
Training Epoch: 0 [1312/50016]	Loss: 4.7627
Training Epoch: 0 [1344/50016]	Loss: 4.7857
Training Epoch: 0 [1376/50016]	Loss: 4.7325
Training Epoch: 0 [1408/50016]	Loss: 4.6507
Training Epoch: 0 [1440/50016]	Loss: 4.8464
Training Epoch: 0 [1472/50016]	Loss: 4.4329
Training Epoch: 0 [1504/50016]	Loss: 4.7898
Training Epoch: 0 [1536/50016]	Loss: 4.7647
Training Epoch: 0 [1568/50016]	Loss: 4.7488
Training Epoch: 0 [1600/50016]	Loss: 5.2034
Profile done with power limit 125W
epoch 1 train time consumed: 4.67s
Validation Epoch: 0, Average loss: 0.1584, Accuracy: 0.0198
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 125000, 'lr': 0.0016, 'energy': 123.95053005834089, 'time': 3.311414985999363, 'accuracy': 0.019768370607028754, 'total_cost': 11822.29308403585}
[run job] Launching job with BS 32: and LR: 0.0016 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00160+pl100', 'ZEUS_COST_THRESH': '19722.256025516697', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0016', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0016', '--power_limit', '100']
[run job] cost_ub=19722.256025516697
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00160+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0016
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 4.8917
Training Epoch: 0 [96/50016]	Loss: 4.9879
Training Epoch: 0 [128/50016]	Loss: 5.1874
Training Epoch: 0 [160/50016]	Loss: 5.3256
Training Epoch: 0 [192/50016]	Loss: 5.1224
Training Epoch: 0 [224/50016]	Loss: 5.1596
Training Epoch: 0 [256/50016]	Loss: 5.1340
Training Epoch: 0 [288/50016]	Loss: 5.0507
Training Epoch: 0 [320/50016]	Loss: 5.1407
Training Epoch: 0 [352/50016]	Loss: 4.9343
Training Epoch: 0 [384/50016]	Loss: 5.3699
Training Epoch: 0 [416/50016]	Loss: 4.9815
Training Epoch: 0 [448/50016]	Loss: 4.8368
Training Epoch: 0 [480/50016]	Loss: 5.1091
Training Epoch: 0 [512/50016]	Loss: 4.9640
Training Epoch: 0 [544/50016]	Loss: 4.7949
Training Epoch: 0 [576/50016]	Loss: 4.6306
Training Epoch: 0 [608/50016]	Loss: 5.1323
Training Epoch: 0 [640/50016]	Loss: 5.4250
Training Epoch: 0 [672/50016]	Loss: 4.8884
Training Epoch: 0 [704/50016]	Loss: 4.6448
Training Epoch: 0 [736/50016]	Loss: 5.0364
Training Epoch: 0 [768/50016]	Loss: 5.3956
Training Epoch: 0 [800/50016]	Loss: 4.9254
Training Epoch: 0 [832/50016]	Loss: 5.0823
Training Epoch: 0 [864/50016]	Loss: 5.1808
Training Epoch: 0 [896/50016]	Loss: 4.5499
Training Epoch: 0 [928/50016]	Loss: 4.7847
Training Epoch: 0 [960/50016]	Loss: 4.7183
Training Epoch: 0 [992/50016]	Loss: 4.8481
Training Epoch: 0 [1024/50016]	Loss: 4.7146
Training Epoch: 0 [1056/50016]	Loss: 4.9773
Training Epoch: 0 [1088/50016]	Loss: 4.6841
Training Epoch: 0 [1120/50016]	Loss: 4.9317
Training Epoch: 0 [1152/50016]	Loss: 4.7864
Training Epoch: 0 [1184/50016]	Loss: 4.8077
Training Epoch: 0 [1216/50016]	Loss: 4.6828
Training Epoch: 0 [1248/50016]	Loss: 4.8727
Training Epoch: 0 [1280/50016]	Loss: 4.6883
Training Epoch: 0 [1312/50016]	Loss: 4.7472
Training Epoch: 0 [1344/50016]	Loss: 4.6873
Training Epoch: 0 [1376/50016]	Loss: 4.8154
Training Epoch: 0 [1408/50016]	Loss: 4.7026
Training Epoch: 0 [1440/50016]	Loss: 4.9081
Training Epoch: 0 [1472/50016]	Loss: 4.3762
Training Epoch: 0 [1504/50016]	Loss: 4.8198
Training Epoch: 0 [1536/50016]	Loss: 4.6674
Training Epoch: 0 [1568/50016]	Loss: 4.8705
Training Epoch: 0 [1600/50016]	Loss: 5.0649
Profile done with power limit 100W
epoch 1 train time consumed: 5.70s
Validation Epoch: 0, Average loss: 0.1585, Accuracy: 0.0234
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 100000, 'lr': 0.0016, 'energy': 99.14109322039597, 'time': 4.215710283999215, 'accuracy': 0.02336261980830671, 'total_cost': 12695.11170678655}

[Power Profiler] with batch size 32 and learning rate 0.002
[run job] Launching job with BS 32: and LR: 0.002 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00200+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.002', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.002', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00200+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.002
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.0068
Training Epoch: 0 [96/50016]	Loss: 5.1678
Training Epoch: 0 [128/50016]	Loss: 5.4304
Training Epoch: 0 [160/50016]	Loss: 5.5318
Training Epoch: 0 [192/50016]	Loss: 5.2598
Training Epoch: 0 [224/50016]	Loss: 5.2553
Training Epoch: 0 [256/50016]	Loss: 5.2094
Training Epoch: 0 [288/50016]	Loss: 5.2708
Training Epoch: 0 [320/50016]	Loss: 5.2143
Training Epoch: 0 [352/50016]	Loss: 5.0432
Training Epoch: 0 [384/50016]	Loss: 5.5032
Training Epoch: 0 [416/50016]	Loss: 5.0375
Training Epoch: 0 [448/50016]	Loss: 4.8843
Training Epoch: 0 [480/50016]	Loss: 5.2087
Training Epoch: 0 [512/50016]	Loss: 4.9837
Training Epoch: 0 [544/50016]	Loss: 4.9111
Training Epoch: 0 [576/50016]	Loss: 4.6392
Training Epoch: 0 [608/50016]	Loss: 5.1193
Training Epoch: 0 [640/50016]	Loss: 5.5504
Training Epoch: 0 [672/50016]	Loss: 4.9541
Training Epoch: 0 [704/50016]	Loss: 4.6749
Training Epoch: 0 [736/50016]	Loss: 5.0580
Training Epoch: 0 [768/50016]	Loss: 5.4139
Training Epoch: 0 [800/50016]	Loss: 4.9693
Training Epoch: 0 [832/50016]	Loss: 5.1051
Training Epoch: 0 [864/50016]	Loss: 5.3486
Training Epoch: 0 [896/50016]	Loss: 4.7423
Training Epoch: 0 [928/50016]	Loss: 4.8540
Training Epoch: 0 [960/50016]	Loss: 4.6358
Training Epoch: 0 [992/50016]	Loss: 4.7515
Training Epoch: 0 [1024/50016]	Loss: 4.6191
Training Epoch: 0 [1056/50016]	Loss: 4.9508
Training Epoch: 0 [1088/50016]	Loss: 4.7630
Training Epoch: 0 [1120/50016]	Loss: 4.8828
Training Epoch: 0 [1152/50016]	Loss: 4.6171
Training Epoch: 0 [1184/50016]	Loss: 4.5224
Training Epoch: 0 [1216/50016]	Loss: 4.5598
Training Epoch: 0 [1248/50016]	Loss: 4.6535
Training Epoch: 0 [1280/50016]	Loss: 4.7053
Training Epoch: 0 [1312/50016]	Loss: 4.5730
Training Epoch: 0 [1344/50016]	Loss: 4.6340
Training Epoch: 0 [1376/50016]	Loss: 4.6159
Training Epoch: 0 [1408/50016]	Loss: 4.5632
Training Epoch: 0 [1440/50016]	Loss: 4.6637
Training Epoch: 0 [1472/50016]	Loss: 4.3511
Training Epoch: 0 [1504/50016]	Loss: 4.9156
Training Epoch: 0 [1536/50016]	Loss: 4.4806
Training Epoch: 0 [1568/50016]	Loss: 4.9604
Training Epoch: 0 [1600/50016]	Loss: 4.9071
Profile done with power limit 175W
epoch 1 train time consumed: 4.64s
Validation Epoch: 0, Average loss: 0.2129, Accuracy: 0.0241
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 175000, 'lr': 0.002, 'energy': 132.32088611587577, 'time': 3.295887951999248, 'accuracy': 0.02406150159744409, 'total_cost': 9673.328505131878}
[run job] Launching job with BS 32: and LR: 0.002 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00200+pl150', 'ZEUS_COST_THRESH': '19346.657010263756', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.002', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.002', '--power_limit', '150']
[run job] cost_ub=19346.657010263756
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00200+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.002
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.0068
Training Epoch: 0 [96/50016]	Loss: 5.1680
Training Epoch: 0 [128/50016]	Loss: 5.4386
Training Epoch: 0 [160/50016]	Loss: 5.5160
Training Epoch: 0 [192/50016]	Loss: 5.2325
Training Epoch: 0 [224/50016]	Loss: 5.2908
Training Epoch: 0 [256/50016]	Loss: 5.1788
Training Epoch: 0 [288/50016]	Loss: 5.2153
Training Epoch: 0 [320/50016]	Loss: 5.2647
Training Epoch: 0 [352/50016]	Loss: 5.0215
Training Epoch: 0 [384/50016]	Loss: 5.4966
Training Epoch: 0 [416/50016]	Loss: 5.0233
Training Epoch: 0 [448/50016]	Loss: 4.9243
Training Epoch: 0 [480/50016]	Loss: 5.2276
Training Epoch: 0 [512/50016]	Loss: 5.0844
Training Epoch: 0 [544/50016]	Loss: 4.9219
Training Epoch: 0 [576/50016]	Loss: 4.6692
Training Epoch: 0 [608/50016]	Loss: 5.1297
Training Epoch: 0 [640/50016]	Loss: 5.4094
Training Epoch: 0 [672/50016]	Loss: 4.9315
Training Epoch: 0 [704/50016]	Loss: 4.6743
Training Epoch: 0 [736/50016]	Loss: 5.0522
Training Epoch: 0 [768/50016]	Loss: 5.3215
Training Epoch: 0 [800/50016]	Loss: 4.8595
Training Epoch: 0 [832/50016]	Loss: 5.0287
Training Epoch: 0 [864/50016]	Loss: 5.3749
Training Epoch: 0 [896/50016]	Loss: 4.7361
Training Epoch: 0 [928/50016]	Loss: 4.9315
Training Epoch: 0 [960/50016]	Loss: 4.6975
Training Epoch: 0 [992/50016]	Loss: 4.7694
Training Epoch: 0 [1024/50016]	Loss: 4.6936
Training Epoch: 0 [1056/50016]	Loss: 4.9327
Training Epoch: 0 [1088/50016]	Loss: 4.6836
Training Epoch: 0 [1120/50016]	Loss: 4.9115
Training Epoch: 0 [1152/50016]	Loss: 4.6370
Training Epoch: 0 [1184/50016]	Loss: 4.5116
Training Epoch: 0 [1216/50016]	Loss: 4.5868
Training Epoch: 0 [1248/50016]	Loss: 4.5822
Training Epoch: 0 [1280/50016]	Loss: 4.7278
Training Epoch: 0 [1312/50016]	Loss: 4.5956
Training Epoch: 0 [1344/50016]	Loss: 4.6400
Training Epoch: 0 [1376/50016]	Loss: 4.6903
Training Epoch: 0 [1408/50016]	Loss: 4.5683
Training Epoch: 0 [1440/50016]	Loss: 4.6903
Training Epoch: 0 [1472/50016]	Loss: 4.3221
Training Epoch: 0 [1504/50016]	Loss: 4.9228
Training Epoch: 0 [1536/50016]	Loss: 4.5467
Training Epoch: 0 [1568/50016]	Loss: 5.0251
Training Epoch: 0 [1600/50016]	Loss: 4.7935
Profile done with power limit 150W
epoch 1 train time consumed: 4.62s
Validation Epoch: 0, Average loss: 0.1912, Accuracy: 0.0283
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 150000, 'lr': 0.002, 'energy': 134.38611198381696, 'time': 3.262331803000052, 'accuracy': 0.02825479233226837, 'total_cost': 8155.7726774127495}
[run job] Launching job with BS 32: and LR: 0.002 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00200+pl125', 'ZEUS_COST_THRESH': '16311.545354825499', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.002', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.002', '--power_limit', '125']
[run job] cost_ub=16311.545354825499
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00200+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.002
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.0068
Training Epoch: 0 [96/50016]	Loss: 5.1688
Training Epoch: 0 [128/50016]	Loss: 5.4356
Training Epoch: 0 [160/50016]	Loss: 5.5275
Training Epoch: 0 [192/50016]	Loss: 5.2584
Training Epoch: 0 [224/50016]	Loss: 5.2404
Training Epoch: 0 [256/50016]	Loss: 5.2100
Training Epoch: 0 [288/50016]	Loss: 5.2318
Training Epoch: 0 [320/50016]	Loss: 5.2402
Training Epoch: 0 [352/50016]	Loss: 5.0148
Training Epoch: 0 [384/50016]	Loss: 5.5208
Training Epoch: 0 [416/50016]	Loss: 5.0516
Training Epoch: 0 [448/50016]	Loss: 4.9492
Training Epoch: 0 [480/50016]	Loss: 5.1649
Training Epoch: 0 [512/50016]	Loss: 4.9469
Training Epoch: 0 [544/50016]	Loss: 4.8829
Training Epoch: 0 [576/50016]	Loss: 4.5488
Training Epoch: 0 [608/50016]	Loss: 5.1777
Training Epoch: 0 [640/50016]	Loss: 5.5837
Training Epoch: 0 [672/50016]	Loss: 5.0251
Training Epoch: 0 [704/50016]	Loss: 4.7109
Training Epoch: 0 [736/50016]	Loss: 5.1137
Training Epoch: 0 [768/50016]	Loss: 5.1551
Training Epoch: 0 [800/50016]	Loss: 4.9701
Training Epoch: 0 [832/50016]	Loss: 4.9860
Training Epoch: 0 [864/50016]	Loss: 5.2453
Training Epoch: 0 [896/50016]	Loss: 4.8003
Training Epoch: 0 [928/50016]	Loss: 4.7719
Training Epoch: 0 [960/50016]	Loss: 4.6627
Training Epoch: 0 [992/50016]	Loss: 4.6793
Training Epoch: 0 [1024/50016]	Loss: 4.7732
Training Epoch: 0 [1056/50016]	Loss: 4.8305
Training Epoch: 0 [1088/50016]	Loss: 4.6478
Training Epoch: 0 [1120/50016]	Loss: 4.7035
Training Epoch: 0 [1152/50016]	Loss: 4.6480
Training Epoch: 0 [1184/50016]	Loss: 4.6550
Training Epoch: 0 [1216/50016]	Loss: 4.5201
Training Epoch: 0 [1248/50016]	Loss: 4.5009
Training Epoch: 0 [1280/50016]	Loss: 4.6737
Training Epoch: 0 [1312/50016]	Loss: 4.5274
Training Epoch: 0 [1344/50016]	Loss: 4.8282
Training Epoch: 0 [1376/50016]	Loss: 4.5942
Training Epoch: 0 [1408/50016]	Loss: 4.5976
Training Epoch: 0 [1440/50016]	Loss: 4.7871
Training Epoch: 0 [1472/50016]	Loss: 4.4224
Training Epoch: 0 [1504/50016]	Loss: 4.7683
Training Epoch: 0 [1536/50016]	Loss: 4.5322
Training Epoch: 0 [1568/50016]	Loss: 4.7460
Training Epoch: 0 [1600/50016]	Loss: 4.8344
Profile done with power limit 125W
epoch 1 train time consumed: 4.77s
Validation Epoch: 0, Average loss: 0.1716, Accuracy: 0.0273
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 125000, 'lr': 0.002, 'energy': 122.52282521081285, 'time': 3.3966093929993804, 'accuracy': 0.027256389776357828, 'total_cost': 8792.29926825141}
[run job] Launching job with BS 32: and LR: 0.002 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00200+pl100', 'ZEUS_COST_THRESH': '16311.545354825499', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.002', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.002', '--power_limit', '100']
[run job] cost_ub=16311.545354825499
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00200+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.002
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.0068
Training Epoch: 0 [96/50016]	Loss: 5.1677
Training Epoch: 0 [128/50016]	Loss: 5.4379
Training Epoch: 0 [160/50016]	Loss: 5.5458
Training Epoch: 0 [192/50016]	Loss: 5.2281
Training Epoch: 0 [224/50016]	Loss: 5.2531
Training Epoch: 0 [256/50016]	Loss: 5.2239
Training Epoch: 0 [288/50016]	Loss: 5.2063
Training Epoch: 0 [320/50016]	Loss: 5.2539
Training Epoch: 0 [352/50016]	Loss: 4.9971
Training Epoch: 0 [384/50016]	Loss: 5.5149
Training Epoch: 0 [416/50016]	Loss: 5.0247
Training Epoch: 0 [448/50016]	Loss: 4.8661
Training Epoch: 0 [480/50016]	Loss: 5.1378
Training Epoch: 0 [512/50016]	Loss: 4.8804
Training Epoch: 0 [544/50016]	Loss: 4.9100
Training Epoch: 0 [576/50016]	Loss: 4.6204
Training Epoch: 0 [608/50016]	Loss: 5.2277
Training Epoch: 0 [640/50016]	Loss: 5.6635
Training Epoch: 0 [672/50016]	Loss: 5.0974
Training Epoch: 0 [704/50016]	Loss: 4.6485
Training Epoch: 0 [736/50016]	Loss: 4.9635
Training Epoch: 0 [768/50016]	Loss: 5.0130
Training Epoch: 0 [800/50016]	Loss: 4.7055
Training Epoch: 0 [832/50016]	Loss: 5.0145
Training Epoch: 0 [864/50016]	Loss: 5.2377
Training Epoch: 0 [896/50016]	Loss: 4.8026
Training Epoch: 0 [928/50016]	Loss: 4.8497
Training Epoch: 0 [960/50016]	Loss: 4.7291
Training Epoch: 0 [992/50016]	Loss: 4.6827
Training Epoch: 0 [1024/50016]	Loss: 4.8782
Training Epoch: 0 [1056/50016]	Loss: 4.7784
Training Epoch: 0 [1088/50016]	Loss: 4.5478
Training Epoch: 0 [1120/50016]	Loss: 4.7316
Training Epoch: 0 [1152/50016]	Loss: 4.7216
Training Epoch: 0 [1184/50016]	Loss: 4.9551
Training Epoch: 0 [1216/50016]	Loss: 4.6178
Training Epoch: 0 [1248/50016]	Loss: 4.5428
Training Epoch: 0 [1280/50016]	Loss: 4.7522
Training Epoch: 0 [1312/50016]	Loss: 4.5341
Training Epoch: 0 [1344/50016]	Loss: 4.7173
Training Epoch: 0 [1376/50016]	Loss: 4.5681
Training Epoch: 0 [1408/50016]	Loss: 4.6022
Training Epoch: 0 [1440/50016]	Loss: 4.6465
Training Epoch: 0 [1472/50016]	Loss: 4.5690
Training Epoch: 0 [1504/50016]	Loss: 4.9139
Training Epoch: 0 [1536/50016]	Loss: 4.4892
Training Epoch: 0 [1568/50016]	Loss: 4.8514
Training Epoch: 0 [1600/50016]	Loss: 4.7123
Profile done with power limit 100W
epoch 1 train time consumed: 5.77s
Validation Epoch: 0, Average loss: 0.1555, Accuracy: 0.0217
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 100000, 'lr': 0.002, 'energy': 99.24976024989799, 'time': 4.28600145099972, 'accuracy': 0.021665335463258786, 'total_cost': 13916.775695848903}

[Power Profiler] with batch size 32 and learning rate 0.0024
[run job] Launching job with BS 32: and LR: 0.0024 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00240+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0024', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0024', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00240+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0024
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.1427
Training Epoch: 0 [96/50016]	Loss: 5.3807
Training Epoch: 0 [128/50016]	Loss: 5.6582
Training Epoch: 0 [160/50016]	Loss: 5.6614
Training Epoch: 0 [192/50016]	Loss: 5.3421
Training Epoch: 0 [224/50016]	Loss: 5.3778
Training Epoch: 0 [256/50016]	Loss: 5.2388
Training Epoch: 0 [288/50016]	Loss: 5.4010
Training Epoch: 0 [320/50016]	Loss: 5.3698
Training Epoch: 0 [352/50016]	Loss: 5.1276
Training Epoch: 0 [384/50016]	Loss: 5.5559
Training Epoch: 0 [416/50016]	Loss: 5.0920
Training Epoch: 0 [448/50016]	Loss: 4.9196
Training Epoch: 0 [480/50016]	Loss: 5.2034
Training Epoch: 0 [512/50016]	Loss: 4.8264
Training Epoch: 0 [544/50016]	Loss: 4.9058
Training Epoch: 0 [576/50016]	Loss: 4.4794
Training Epoch: 0 [608/50016]	Loss: 5.1917
Training Epoch: 0 [640/50016]	Loss: 5.5222
Training Epoch: 0 [672/50016]	Loss: 5.0574
Training Epoch: 0 [704/50016]	Loss: 4.7091
Training Epoch: 0 [736/50016]	Loss: 4.8750
Training Epoch: 0 [768/50016]	Loss: 5.1237
Training Epoch: 0 [800/50016]	Loss: 4.6605
Training Epoch: 0 [832/50016]	Loss: 4.7843
Training Epoch: 0 [864/50016]	Loss: 5.3369
Training Epoch: 0 [896/50016]	Loss: 4.8880
Training Epoch: 0 [928/50016]	Loss: 5.0196
Training Epoch: 0 [960/50016]	Loss: 4.7862
Training Epoch: 0 [992/50016]	Loss: 4.8020
Training Epoch: 0 [1024/50016]	Loss: 4.9685
Training Epoch: 0 [1056/50016]	Loss: 4.8562
Training Epoch: 0 [1088/50016]	Loss: 4.7311
Training Epoch: 0 [1120/50016]	Loss: 4.7482
Training Epoch: 0 [1152/50016]	Loss: 4.6737
Training Epoch: 0 [1184/50016]	Loss: 4.8158
Training Epoch: 0 [1216/50016]	Loss: 4.5587
Training Epoch: 0 [1248/50016]	Loss: 4.5101
Training Epoch: 0 [1280/50016]	Loss: 4.7838
Training Epoch: 0 [1312/50016]	Loss: 4.5425
Training Epoch: 0 [1344/50016]	Loss: 4.7013
Training Epoch: 0 [1376/50016]	Loss: 4.5438
Training Epoch: 0 [1408/50016]	Loss: 4.7301
Training Epoch: 0 [1440/50016]	Loss: 4.6715
Training Epoch: 0 [1472/50016]	Loss: 4.5539
Training Epoch: 0 [1504/50016]	Loss: 4.9250
Training Epoch: 0 [1536/50016]	Loss: 4.5057
Training Epoch: 0 [1568/50016]	Loss: 4.9007
Training Epoch: 0 [1600/50016]	Loss: 4.6755
Profile done with power limit 175W
epoch 1 train time consumed: 4.49s
Validation Epoch: 0, Average loss: 0.1484, Accuracy: 0.0234
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 175000, 'lr': 0.0024, 'energy': 135.17509046388213, 'time': 3.1425559039998916, 'accuracy': 0.02336261980830671, 'total_cost': 9505.383126586603}
[run job] Launching job with BS 32: and LR: 0.0024 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00240+pl150', 'ZEUS_COST_THRESH': '19010.766253173206', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0024', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0024', '--power_limit', '150']
[run job] cost_ub=19010.766253173206
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00240+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0024
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.1427
Training Epoch: 0 [96/50016]	Loss: 5.3809
Training Epoch: 0 [128/50016]	Loss: 5.6658
Training Epoch: 0 [160/50016]	Loss: 5.6744
Training Epoch: 0 [192/50016]	Loss: 5.3478
Training Epoch: 0 [224/50016]	Loss: 5.3784
Training Epoch: 0 [256/50016]	Loss: 5.2824
Training Epoch: 0 [288/50016]	Loss: 5.4479
Training Epoch: 0 [320/50016]	Loss: 5.3711
Training Epoch: 0 [352/50016]	Loss: 5.1033
Training Epoch: 0 [384/50016]	Loss: 5.6101
Training Epoch: 0 [416/50016]	Loss: 5.0691
Training Epoch: 0 [448/50016]	Loss: 4.9943
Training Epoch: 0 [480/50016]	Loss: 5.3102
Training Epoch: 0 [512/50016]	Loss: 5.1509
Training Epoch: 0 [544/50016]	Loss: 5.0575
Training Epoch: 0 [576/50016]	Loss: 4.6561
Training Epoch: 0 [608/50016]	Loss: 5.1526
Training Epoch: 0 [640/50016]	Loss: 5.6171
Training Epoch: 0 [672/50016]	Loss: 5.0177
Training Epoch: 0 [704/50016]	Loss: 4.6526
Training Epoch: 0 [736/50016]	Loss: 5.1214
Training Epoch: 0 [768/50016]	Loss: 5.2702
Training Epoch: 0 [800/50016]	Loss: 4.8187
Training Epoch: 0 [832/50016]	Loss: 4.9405
Training Epoch: 0 [864/50016]	Loss: 5.2713
Training Epoch: 0 [896/50016]	Loss: 4.8286
Training Epoch: 0 [928/50016]	Loss: 4.8283
Training Epoch: 0 [960/50016]	Loss: 4.7162
Training Epoch: 0 [992/50016]	Loss: 4.6664
Training Epoch: 0 [1024/50016]	Loss: 4.7421
Training Epoch: 0 [1056/50016]	Loss: 4.8533
Training Epoch: 0 [1088/50016]	Loss: 4.6897
Training Epoch: 0 [1120/50016]	Loss: 4.7488
Training Epoch: 0 [1152/50016]	Loss: 4.6787
Training Epoch: 0 [1184/50016]	Loss: 4.6468
Training Epoch: 0 [1216/50016]	Loss: 4.5026
Training Epoch: 0 [1248/50016]	Loss: 4.5552
Training Epoch: 0 [1280/50016]	Loss: 4.6986
Training Epoch: 0 [1312/50016]	Loss: 4.5199
Training Epoch: 0 [1344/50016]	Loss: 4.7173
Training Epoch: 0 [1376/50016]	Loss: 4.5924
Training Epoch: 0 [1408/50016]	Loss: 4.5584
Training Epoch: 0 [1440/50016]	Loss: 4.6898
Training Epoch: 0 [1472/50016]	Loss: 4.5395
Training Epoch: 0 [1504/50016]	Loss: 4.9627
Training Epoch: 0 [1536/50016]	Loss: 4.5383
Training Epoch: 0 [1568/50016]	Loss: 4.8337
Training Epoch: 0 [1600/50016]	Loss: 4.7034
Profile done with power limit 150W
epoch 1 train time consumed: 4.56s
Validation Epoch: 0, Average loss: 0.1612, Accuracy: 0.0251
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 150000, 'lr': 0.0024, 'energy': 134.54793800671587, 'time': 3.221142706000137, 'accuracy': 0.025059904153354632, 'total_cost': 9080.638770828476}
[run job] Launching job with BS 32: and LR: 0.0024 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00240+pl125', 'ZEUS_COST_THRESH': '18161.277541656953', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0024', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0024', '--power_limit', '125']
[run job] cost_ub=18161.277541656953
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00240+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0024
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.1427
Training Epoch: 0 [96/50016]	Loss: 5.3813
Training Epoch: 0 [128/50016]	Loss: 5.6481
Training Epoch: 0 [160/50016]	Loss: 5.6664
Training Epoch: 0 [192/50016]	Loss: 5.3503
Training Epoch: 0 [224/50016]	Loss: 5.4250
Training Epoch: 0 [256/50016]	Loss: 5.3121
Training Epoch: 0 [288/50016]	Loss: 5.4336
Training Epoch: 0 [320/50016]	Loss: 5.3906
Training Epoch: 0 [352/50016]	Loss: 5.1918
Training Epoch: 0 [384/50016]	Loss: 5.5386
Training Epoch: 0 [416/50016]	Loss: 5.0402
Training Epoch: 0 [448/50016]	Loss: 4.8401
Training Epoch: 0 [480/50016]	Loss: 5.1291
Training Epoch: 0 [512/50016]	Loss: 4.8515
Training Epoch: 0 [544/50016]	Loss: 4.9547
Training Epoch: 0 [576/50016]	Loss: 4.5107
Training Epoch: 0 [608/50016]	Loss: 5.2513
Training Epoch: 0 [640/50016]	Loss: 5.5179
Training Epoch: 0 [672/50016]	Loss: 5.1606
Training Epoch: 0 [704/50016]	Loss: 4.6851
Training Epoch: 0 [736/50016]	Loss: 4.8790
Training Epoch: 0 [768/50016]	Loss: 5.3608
Training Epoch: 0 [800/50016]	Loss: 4.6737
Training Epoch: 0 [832/50016]	Loss: 4.6995
Training Epoch: 0 [864/50016]	Loss: 5.2496
Training Epoch: 0 [896/50016]	Loss: 4.8692
Training Epoch: 0 [928/50016]	Loss: 5.0282
Training Epoch: 0 [960/50016]	Loss: 4.8856
Training Epoch: 0 [992/50016]	Loss: 4.8437
Training Epoch: 0 [1024/50016]	Loss: 4.9462
Training Epoch: 0 [1056/50016]	Loss: 4.8936
Training Epoch: 0 [1088/50016]	Loss: 4.7118
Training Epoch: 0 [1120/50016]	Loss: 4.7068
Training Epoch: 0 [1152/50016]	Loss: 4.6753
Training Epoch: 0 [1184/50016]	Loss: 4.8649
Training Epoch: 0 [1216/50016]	Loss: 4.9171
Training Epoch: 0 [1248/50016]	Loss: 4.6405
Training Epoch: 0 [1280/50016]	Loss: 4.8807
Training Epoch: 0 [1312/50016]	Loss: 4.7226
Training Epoch: 0 [1344/50016]	Loss: 4.6686
Training Epoch: 0 [1376/50016]	Loss: 4.5271
Training Epoch: 0 [1408/50016]	Loss: 4.8680
Training Epoch: 0 [1440/50016]	Loss: 4.5815
Training Epoch: 0 [1472/50016]	Loss: 4.6581
Training Epoch: 0 [1504/50016]	Loss: 4.6896
Training Epoch: 0 [1536/50016]	Loss: 4.7507
Training Epoch: 0 [1568/50016]	Loss: 4.5182
Training Epoch: 0 [1600/50016]	Loss: 4.5495
Profile done with power limit 125W
epoch 1 train time consumed: 4.67s
Validation Epoch: 0, Average loss: 0.1480, Accuracy: 0.0127
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 125000, 'lr': 0.0024, 'energy': 123.407782296289, 'time': 3.338589549000062, 'accuracy': 0.012679712460063898, 'total_cost': 18580.894603133274}
[run job] Launching job with BS 32: and LR: 0.0024 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs32+lr0.00240+pl100', 'ZEUS_COST_THRESH': '18161.277541656953', 'ZEUS_BATCH_SIZE': '32', 'ZEUS_LEARNING_RATE': '0.0024', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '32', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0024', '--power_limit', '100']
[run job] cost_ub=18161.277541656953
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs32+lr0.00240+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0024
batch size arg: 32
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [32/50016]	Loss: 4.6525
Training Epoch: 0 [64/50016]	Loss: 5.1427
Training Epoch: 0 [96/50016]	Loss: 5.3801
Training Epoch: 0 [128/50016]	Loss: 5.6655
Training Epoch: 0 [160/50016]	Loss: 5.6675
Training Epoch: 0 [192/50016]	Loss: 5.3581
Training Epoch: 0 [224/50016]	Loss: 5.3932
Training Epoch: 0 [256/50016]	Loss: 5.2709
Training Epoch: 0 [288/50016]	Loss: 5.4329
Training Epoch: 0 [320/50016]	Loss: 5.3779
Training Epoch: 0 [352/50016]	Loss: 5.1303
Training Epoch: 0 [384/50016]	Loss: 5.5396
Training Epoch: 0 [416/50016]	Loss: 5.1296
Training Epoch: 0 [448/50016]	Loss: 4.9485
Training Epoch: 0 [480/50016]	Loss: 5.2613
Training Epoch: 0 [512/50016]	Loss: 5.0911
Training Epoch: 0 [544/50016]	Loss: 5.0345
Training Epoch: 0 [576/50016]	Loss: 4.5397
Training Epoch: 0 [608/50016]	Loss: 5.1492
Training Epoch: 0 [640/50016]	Loss: 5.4768
Training Epoch: 0 [672/50016]	Loss: 5.0658
Training Epoch: 0 [704/50016]	Loss: 4.5854
Training Epoch: 0 [736/50016]	Loss: 4.8778
Training Epoch: 0 [768/50016]	Loss: 5.0227
Training Epoch: 0 [800/50016]	Loss: 4.6628
Training Epoch: 0 [832/50016]	Loss: 4.7833
Training Epoch: 0 [864/50016]	Loss: 5.2894
Training Epoch: 0 [896/50016]	Loss: 4.8473
Training Epoch: 0 [928/50016]	Loss: 4.8670
Training Epoch: 0 [960/50016]	Loss: 4.6986
Training Epoch: 0 [992/50016]	Loss: 4.7309
Training Epoch: 0 [1024/50016]	Loss: 4.8340
Training Epoch: 0 [1056/50016]	Loss: 4.8524
Training Epoch: 0 [1088/50016]	Loss: 4.7514
Training Epoch: 0 [1120/50016]	Loss: 4.7131
Training Epoch: 0 [1152/50016]	Loss: 4.7043
Training Epoch: 0 [1184/50016]	Loss: 4.7786
Training Epoch: 0 [1216/50016]	Loss: 4.5671
Training Epoch: 0 [1248/50016]	Loss: 4.5467
Training Epoch: 0 [1280/50016]	Loss: 4.7851
Training Epoch: 0 [1312/50016]	Loss: 4.5485
Training Epoch: 0 [1344/50016]	Loss: 4.7551
Training Epoch: 0 [1376/50016]	Loss: 4.6024
Training Epoch: 0 [1408/50016]	Loss: 4.5605
Training Epoch: 0 [1440/50016]	Loss: 4.6570
Training Epoch: 0 [1472/50016]	Loss: 4.6019
Training Epoch: 0 [1504/50016]	Loss: 5.0022
Training Epoch: 0 [1536/50016]	Loss: 4.5622
Training Epoch: 0 [1568/50016]	Loss: 4.6654
Training Epoch: 0 [1600/50016]	Loss: 4.6867
Profile done with power limit 100W
epoch 1 train time consumed: 5.73s
Validation Epoch: 0, Average loss: 0.1516, Accuracy: 0.0175
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 32, 'pl': 100000, 'lr': 0.0024, 'energy': 99.23250042026665, 'time': 4.241730383000686, 'accuracy': 0.017472044728434506, 'total_cost': 17079.47519489072}

[Power Profiler] with batch size 64 and learning rate 0.0022627416997969526
[run job] Launching job with BS 64: and LR: 0.0022627416997969526 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00226+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0022627416997969526', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0022627416997969526', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00226+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0022627416997969526
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 4.8843
Training Epoch: 0 [192/50048]	Loss: 5.0517
Training Epoch: 0 [256/50048]	Loss: 5.2091
Training Epoch: 0 [320/50048]	Loss: 5.1359
Training Epoch: 0 [384/50048]	Loss: 5.1298
Training Epoch: 0 [448/50048]	Loss: 4.9138
Training Epoch: 0 [512/50048]	Loss: 5.0961
Training Epoch: 0 [576/50048]	Loss: 4.6815
Training Epoch: 0 [640/50048]	Loss: 5.3360
Training Epoch: 0 [704/50048]	Loss: 4.8625
Training Epoch: 0 [768/50048]	Loss: 5.1795
Training Epoch: 0 [832/50048]	Loss: 5.0482
Training Epoch: 0 [896/50048]	Loss: 5.0080
Training Epoch: 0 [960/50048]	Loss: 4.9458
Training Epoch: 0 [1024/50048]	Loss: 4.9706
Training Epoch: 0 [1088/50048]	Loss: 4.9869
Training Epoch: 0 [1152/50048]	Loss: 4.8403
Training Epoch: 0 [1216/50048]	Loss: 4.8062
Training Epoch: 0 [1280/50048]	Loss: 4.7562
Training Epoch: 0 [1344/50048]	Loss: 4.7423
Training Epoch: 0 [1408/50048]	Loss: 4.6018
Training Epoch: 0 [1472/50048]	Loss: 4.5994
Training Epoch: 0 [1536/50048]	Loss: 4.6986
Training Epoch: 0 [1600/50048]	Loss: 4.8736
Training Epoch: 0 [1664/50048]	Loss: 4.8367
Training Epoch: 0 [1728/50048]	Loss: 4.7505
Training Epoch: 0 [1792/50048]	Loss: 4.6568
Training Epoch: 0 [1856/50048]	Loss: 4.8734
Training Epoch: 0 [1920/50048]	Loss: 4.5723
Training Epoch: 0 [1984/50048]	Loss: 4.5877
Training Epoch: 0 [2048/50048]	Loss: 4.5641
Training Epoch: 0 [2112/50048]	Loss: 4.8165
Training Epoch: 0 [2176/50048]	Loss: 4.6615
Training Epoch: 0 [2240/50048]	Loss: 4.6250
Training Epoch: 0 [2304/50048]	Loss: 4.6876
Training Epoch: 0 [2368/50048]	Loss: 4.6195
Training Epoch: 0 [2432/50048]	Loss: 4.5779
Training Epoch: 0 [2496/50048]	Loss: 4.6279
Training Epoch: 0 [2560/50048]	Loss: 4.5997
Training Epoch: 0 [2624/50048]	Loss: 4.5295
Training Epoch: 0 [2688/50048]	Loss: 4.5281
Training Epoch: 0 [2752/50048]	Loss: 4.5021
Training Epoch: 0 [2816/50048]	Loss: 4.4119
Training Epoch: 0 [2880/50048]	Loss: 4.3816
Training Epoch: 0 [2944/50048]	Loss: 4.5442
Training Epoch: 0 [3008/50048]	Loss: 4.4791
Training Epoch: 0 [3072/50048]	Loss: 4.6186
Training Epoch: 0 [3136/50048]	Loss: 4.5763
Training Epoch: 0 [3200/50048]	Loss: 4.4886
Profile done with power limit 175W
epoch 1 train time consumed: 7.19s
Validation Epoch: 0, Average loss: 0.0721, Accuracy: 0.0163
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 175000, 'lr': 0.0022627416997969526, 'energy': 145.10972820806694, 'time': 5.261411970000154, 'accuracy': 0.016321656050955414, 'total_cost': 45371.02581526445}
[run job] Launching job with BS 64: and LR: 0.0022627416997969526 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00226+pl150', 'ZEUS_COST_THRESH': '90742.0516305289', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0022627416997969526', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0022627416997969526', '--power_limit', '150']
[run job] cost_ub=90742.0516305289
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00226+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0022627416997969526
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 4.8843
Training Epoch: 0 [192/50048]	Loss: 5.0511
Training Epoch: 0 [256/50048]	Loss: 5.1978
Training Epoch: 0 [320/50048]	Loss: 5.1192
Training Epoch: 0 [384/50048]	Loss: 5.1819
Training Epoch: 0 [448/50048]	Loss: 4.9119
Training Epoch: 0 [512/50048]	Loss: 5.1386
Training Epoch: 0 [576/50048]	Loss: 4.6777
Training Epoch: 0 [640/50048]	Loss: 5.3071
Training Epoch: 0 [704/50048]	Loss: 4.8835
Training Epoch: 0 [768/50048]	Loss: 5.1847
Training Epoch: 0 [832/50048]	Loss: 5.0739
Training Epoch: 0 [896/50048]	Loss: 4.9998
Training Epoch: 0 [960/50048]	Loss: 4.8612
Training Epoch: 0 [1024/50048]	Loss: 4.9548
Training Epoch: 0 [1088/50048]	Loss: 4.9868
Training Epoch: 0 [1152/50048]	Loss: 4.8240
Training Epoch: 0 [1216/50048]	Loss: 4.8358
Training Epoch: 0 [1280/50048]	Loss: 4.7437
Training Epoch: 0 [1344/50048]	Loss: 4.7749
Training Epoch: 0 [1408/50048]	Loss: 4.6161
Training Epoch: 0 [1472/50048]	Loss: 4.6543
Training Epoch: 0 [1536/50048]	Loss: 4.8208
Training Epoch: 0 [1600/50048]	Loss: 4.9205
Training Epoch: 0 [1664/50048]	Loss: 4.7978
Training Epoch: 0 [1728/50048]	Loss: 4.6257
Training Epoch: 0 [1792/50048]	Loss: 4.5644
Training Epoch: 0 [1856/50048]	Loss: 4.7586
Training Epoch: 0 [1920/50048]	Loss: 4.6668
Training Epoch: 0 [1984/50048]	Loss: 4.5924
Training Epoch: 0 [2048/50048]	Loss: 4.5680
Training Epoch: 0 [2112/50048]	Loss: 4.5966
Training Epoch: 0 [2176/50048]	Loss: 4.7372
Training Epoch: 0 [2240/50048]	Loss: 4.6207
Training Epoch: 0 [2304/50048]	Loss: 4.6427
Training Epoch: 0 [2368/50048]	Loss: 4.6774
Training Epoch: 0 [2432/50048]	Loss: 4.5524
Training Epoch: 0 [2496/50048]	Loss: 4.5332
Training Epoch: 0 [2560/50048]	Loss: 4.6609
Training Epoch: 0 [2624/50048]	Loss: 4.4517
Training Epoch: 0 [2688/50048]	Loss: 4.5418
Training Epoch: 0 [2752/50048]	Loss: 4.4588
Training Epoch: 0 [2816/50048]	Loss: 4.4291
Training Epoch: 0 [2880/50048]	Loss: 4.4124
Training Epoch: 0 [2944/50048]	Loss: 4.4320
Training Epoch: 0 [3008/50048]	Loss: 4.3345
Training Epoch: 0 [3072/50048]	Loss: 4.6186
Training Epoch: 0 [3136/50048]	Loss: 4.6630
Training Epoch: 0 [3200/50048]	Loss: 4.4423
Profile done with power limit 150W
epoch 1 train time consumed: 7.15s
Validation Epoch: 0, Average loss: 0.0726, Accuracy: 0.0184
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 150000, 'lr': 0.0022627416997969526, 'energy': 146.32442579153795, 'time': 5.249690893999286, 'accuracy': 0.018411624203821655, 'total_cost': 40133.87010620067}
[run job] Launching job with BS 64: and LR: 0.0022627416997969526 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00226+pl125', 'ZEUS_COST_THRESH': '80267.74021240135', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0022627416997969526', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0022627416997969526', '--power_limit', '125']
[run job] cost_ub=80267.74021240135
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00226+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0022627416997969526
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 4.8843
Training Epoch: 0 [192/50048]	Loss: 5.0515
Training Epoch: 0 [256/50048]	Loss: 5.1982
Training Epoch: 0 [320/50048]	Loss: 5.1138
Training Epoch: 0 [384/50048]	Loss: 5.1654
Training Epoch: 0 [448/50048]	Loss: 4.9055
Training Epoch: 0 [512/50048]	Loss: 5.1086
Training Epoch: 0 [576/50048]	Loss: 4.6756
Training Epoch: 0 [640/50048]	Loss: 5.3406
Training Epoch: 0 [704/50048]	Loss: 4.8354
Training Epoch: 0 [768/50048]	Loss: 5.1766
Training Epoch: 0 [832/50048]	Loss: 5.0566
Training Epoch: 0 [896/50048]	Loss: 4.9996
Training Epoch: 0 [960/50048]	Loss: 4.8608
Training Epoch: 0 [1024/50048]	Loss: 4.8909
Training Epoch: 0 [1088/50048]	Loss: 4.9663
Training Epoch: 0 [1152/50048]	Loss: 4.8521
Training Epoch: 0 [1216/50048]	Loss: 4.8117
Training Epoch: 0 [1280/50048]	Loss: 4.7511
Training Epoch: 0 [1344/50048]	Loss: 4.7739
Training Epoch: 0 [1408/50048]	Loss: 4.5827
Training Epoch: 0 [1472/50048]	Loss: 4.6084
Training Epoch: 0 [1536/50048]	Loss: 4.7633
Training Epoch: 0 [1600/50048]	Loss: 4.8856
Training Epoch: 0 [1664/50048]	Loss: 4.8809
Training Epoch: 0 [1728/50048]	Loss: 4.7014
Training Epoch: 0 [1792/50048]	Loss: 4.6521
Training Epoch: 0 [1856/50048]	Loss: 4.9395
Training Epoch: 0 [1920/50048]	Loss: 4.6251
Training Epoch: 0 [1984/50048]	Loss: 4.6222
Training Epoch: 0 [2048/50048]	Loss: 4.5809
Training Epoch: 0 [2112/50048]	Loss: 4.8045
Training Epoch: 0 [2176/50048]	Loss: 4.7617
Training Epoch: 0 [2240/50048]	Loss: 4.6365
Training Epoch: 0 [2304/50048]	Loss: 4.7391
Training Epoch: 0 [2368/50048]	Loss: 4.6853
Training Epoch: 0 [2432/50048]	Loss: 4.5257
Training Epoch: 0 [2496/50048]	Loss: 4.5850
Training Epoch: 0 [2560/50048]	Loss: 4.5565
Training Epoch: 0 [2624/50048]	Loss: 4.4966
Training Epoch: 0 [2688/50048]	Loss: 4.5454
Training Epoch: 0 [2752/50048]	Loss: 4.4950
Training Epoch: 0 [2816/50048]	Loss: 4.4667
Training Epoch: 0 [2880/50048]	Loss: 4.4168
Training Epoch: 0 [2944/50048]	Loss: 4.5031
Training Epoch: 0 [3008/50048]	Loss: 4.4446
Training Epoch: 0 [3072/50048]	Loss: 4.5771
Training Epoch: 0 [3136/50048]	Loss: 4.6024
Training Epoch: 0 [3200/50048]	Loss: 4.5107
Profile done with power limit 125W
epoch 1 train time consumed: 7.86s
Validation Epoch: 0, Average loss: 0.0742, Accuracy: 0.0174
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 125000, 'lr': 0.0022627416997969526, 'energy': 122.99167093461277, 'time': 5.858322099000361, 'accuracy': 0.01741640127388535, 'total_cost': 47272.133683158}
[run job] Launching job with BS 64: and LR: 0.0022627416997969526 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00226+pl100', 'ZEUS_COST_THRESH': '80267.74021240135', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0022627416997969526', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0022627416997969526', '--power_limit', '100']
[run job] cost_ub=80267.74021240135
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00226+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0022627416997969526
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 4.8843
Training Epoch: 0 [192/50048]	Loss: 5.0515
Training Epoch: 0 [256/50048]	Loss: 5.2007
Training Epoch: 0 [320/50048]	Loss: 5.1186
Training Epoch: 0 [384/50048]	Loss: 5.1549
Training Epoch: 0 [448/50048]	Loss: 4.9190
Training Epoch: 0 [512/50048]	Loss: 5.1300
Training Epoch: 0 [576/50048]	Loss: 4.7154
Training Epoch: 0 [640/50048]	Loss: 5.3040
Training Epoch: 0 [704/50048]	Loss: 4.8615
Training Epoch: 0 [768/50048]	Loss: 5.1908
Training Epoch: 0 [832/50048]	Loss: 5.0710
Training Epoch: 0 [896/50048]	Loss: 5.0363
Training Epoch: 0 [960/50048]	Loss: 4.8599
Training Epoch: 0 [1024/50048]	Loss: 4.9596
Training Epoch: 0 [1088/50048]	Loss: 4.9833
Training Epoch: 0 [1152/50048]	Loss: 4.8367
Training Epoch: 0 [1216/50048]	Loss: 4.8195
Training Epoch: 0 [1280/50048]	Loss: 4.7931
Training Epoch: 0 [1344/50048]	Loss: 4.7763
Training Epoch: 0 [1408/50048]	Loss: 4.5865
Training Epoch: 0 [1472/50048]	Loss: 4.6400
Training Epoch: 0 [1536/50048]	Loss: 4.7670
Training Epoch: 0 [1600/50048]	Loss: 4.9051
Training Epoch: 0 [1664/50048]	Loss: 4.8476
Training Epoch: 0 [1728/50048]	Loss: 4.6522
Training Epoch: 0 [1792/50048]	Loss: 4.5885
Training Epoch: 0 [1856/50048]	Loss: 4.7566
Training Epoch: 0 [1920/50048]	Loss: 4.6454
Training Epoch: 0 [1984/50048]	Loss: 4.5922
Training Epoch: 0 [2048/50048]	Loss: 4.5348
Training Epoch: 0 [2112/50048]	Loss: 4.6534
Training Epoch: 0 [2176/50048]	Loss: 4.6888
Training Epoch: 0 [2240/50048]	Loss: 4.6033
Training Epoch: 0 [2304/50048]	Loss: 4.6496
Training Epoch: 0 [2368/50048]	Loss: 4.6535
Training Epoch: 0 [2432/50048]	Loss: 4.5717
Training Epoch: 0 [2496/50048]	Loss: 4.5503
Training Epoch: 0 [2560/50048]	Loss: 4.5815
Training Epoch: 0 [2624/50048]	Loss: 4.3964
Training Epoch: 0 [2688/50048]	Loss: 4.5253
Training Epoch: 0 [2752/50048]	Loss: 4.4659
Training Epoch: 0 [2816/50048]	Loss: 4.4224
Training Epoch: 0 [2880/50048]	Loss: 4.3545
Training Epoch: 0 [2944/50048]	Loss: 4.4128
Training Epoch: 0 [3008/50048]	Loss: 4.3111
Training Epoch: 0 [3072/50048]	Loss: 4.5777
Training Epoch: 0 [3136/50048]	Loss: 4.6222
Training Epoch: 0 [3200/50048]	Loss: 4.4055
Profile done with power limit 100W
epoch 1 train time consumed: 15.95s
Validation Epoch: 0, Average loss: 0.0715, Accuracy: 0.0225
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 100000, 'lr': 0.0022627416997969526, 'energy': 99.27927074219913, 'time': 12.526939458000015, 'accuracy': 0.022492038216560508, 'total_cost': 78039.32178186439}

[Power Profiler] with batch size 64 and learning rate 0.0028284271247461905
[run job] Launching job with BS 64: and LR: 0.0028284271247461905 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00283+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0028284271247461905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0028284271247461905', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00283+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0028284271247461905
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.0397
Training Epoch: 0 [192/50048]	Loss: 5.2130
Training Epoch: 0 [256/50048]	Loss: 5.3856
Training Epoch: 0 [320/50048]	Loss: 5.2486
Training Epoch: 0 [384/50048]	Loss: 5.2680
Training Epoch: 0 [448/50048]	Loss: 4.9936
Training Epoch: 0 [512/50048]	Loss: 5.1737
Training Epoch: 0 [576/50048]	Loss: 4.7049
Training Epoch: 0 [640/50048]	Loss: 5.4893
Training Epoch: 0 [704/50048]	Loss: 4.8294
Training Epoch: 0 [768/50048]	Loss: 5.1620
Training Epoch: 0 [832/50048]	Loss: 4.9144
Training Epoch: 0 [896/50048]	Loss: 4.9864
Training Epoch: 0 [960/50048]	Loss: 4.8652
Training Epoch: 0 [1024/50048]	Loss: 4.7849
Training Epoch: 0 [1088/50048]	Loss: 4.7824
Training Epoch: 0 [1152/50048]	Loss: 4.7797
Training Epoch: 0 [1216/50048]	Loss: 4.7038
Training Epoch: 0 [1280/50048]	Loss: 4.5950
Training Epoch: 0 [1344/50048]	Loss: 4.8796
Training Epoch: 0 [1408/50048]	Loss: 4.5566
Training Epoch: 0 [1472/50048]	Loss: 4.6303
Training Epoch: 0 [1536/50048]	Loss: 4.7747
Training Epoch: 0 [1600/50048]	Loss: 4.9175
Training Epoch: 0 [1664/50048]	Loss: 4.8818
Training Epoch: 0 [1728/50048]	Loss: 4.7904
Training Epoch: 0 [1792/50048]	Loss: 4.7371
Training Epoch: 0 [1856/50048]	Loss: 4.8479
Training Epoch: 0 [1920/50048]	Loss: 4.6462
Training Epoch: 0 [1984/50048]	Loss: 4.5829
Training Epoch: 0 [2048/50048]	Loss: 4.6012
Training Epoch: 0 [2112/50048]	Loss: 4.7949
Training Epoch: 0 [2176/50048]	Loss: 4.6128
Training Epoch: 0 [2240/50048]	Loss: 4.5604
Training Epoch: 0 [2304/50048]	Loss: 4.6033
Training Epoch: 0 [2368/50048]	Loss: 4.6045
Training Epoch: 0 [2432/50048]	Loss: 4.6742
Training Epoch: 0 [2496/50048]	Loss: 4.7461
Training Epoch: 0 [2560/50048]	Loss: 4.4934
Training Epoch: 0 [2624/50048]	Loss: 4.5723
Training Epoch: 0 [2688/50048]	Loss: 4.5623
Training Epoch: 0 [2752/50048]	Loss: 4.5331
Training Epoch: 0 [2816/50048]	Loss: 4.4793
Training Epoch: 0 [2880/50048]	Loss: 4.4313
Training Epoch: 0 [2944/50048]	Loss: 4.5760
Training Epoch: 0 [3008/50048]	Loss: 4.5960
Training Epoch: 0 [3072/50048]	Loss: 4.6069
Training Epoch: 0 [3136/50048]	Loss: 4.5379
Training Epoch: 0 [3200/50048]	Loss: 4.5580
Profile done with power limit 175W
epoch 1 train time consumed: 7.13s
Validation Epoch: 0, Average loss: 0.0755, Accuracy: 0.0212
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 175000, 'lr': 0.0028284271247461905, 'energy': 145.7028131758694, 'time': 5.22996264899939, 'accuracy': 0.02119824840764331, 'total_cost': 34726.95206656886}
[run job] Launching job with BS 64: and LR: 0.0028284271247461905 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00283+pl150', 'ZEUS_COST_THRESH': '69453.90413313772', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0028284271247461905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0028284271247461905', '--power_limit', '150']
[run job] cost_ub=69453.90413313772
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00283+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0028284271247461905
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.0397
Training Epoch: 0 [192/50048]	Loss: 5.2130
Training Epoch: 0 [256/50048]	Loss: 5.3842
Training Epoch: 0 [320/50048]	Loss: 5.2492
Training Epoch: 0 [384/50048]	Loss: 5.2276
Training Epoch: 0 [448/50048]	Loss: 4.9719
Training Epoch: 0 [512/50048]	Loss: 5.1713
Training Epoch: 0 [576/50048]	Loss: 4.6774
Training Epoch: 0 [640/50048]	Loss: 5.5131
Training Epoch: 0 [704/50048]	Loss: 4.8591
Training Epoch: 0 [768/50048]	Loss: 5.1802
Training Epoch: 0 [832/50048]	Loss: 5.0495
Training Epoch: 0 [896/50048]	Loss: 5.0493
Training Epoch: 0 [960/50048]	Loss: 4.8779
Training Epoch: 0 [1024/50048]	Loss: 4.7659
Training Epoch: 0 [1088/50048]	Loss: 4.8009
Training Epoch: 0 [1152/50048]	Loss: 4.8028
Training Epoch: 0 [1216/50048]	Loss: 4.7424
Training Epoch: 0 [1280/50048]	Loss: 4.5500
Training Epoch: 0 [1344/50048]	Loss: 4.8461
Training Epoch: 0 [1408/50048]	Loss: 4.5859
Training Epoch: 0 [1472/50048]	Loss: 4.5805
Training Epoch: 0 [1536/50048]	Loss: 4.6969
Training Epoch: 0 [1600/50048]	Loss: 4.8567
Training Epoch: 0 [1664/50048]	Loss: 4.9031
Training Epoch: 0 [1728/50048]	Loss: 4.7072
Training Epoch: 0 [1792/50048]	Loss: 4.6118
Training Epoch: 0 [1856/50048]	Loss: 4.7681
Training Epoch: 0 [1920/50048]	Loss: 4.6223
Training Epoch: 0 [1984/50048]	Loss: 4.5627
Training Epoch: 0 [2048/50048]	Loss: 4.6301
Training Epoch: 0 [2112/50048]	Loss: 4.5214
Training Epoch: 0 [2176/50048]	Loss: 4.7142
Training Epoch: 0 [2240/50048]	Loss: 4.6415
Training Epoch: 0 [2304/50048]	Loss: 4.7467
Training Epoch: 0 [2368/50048]	Loss: 4.6435
Training Epoch: 0 [2432/50048]	Loss: 4.5417
Training Epoch: 0 [2496/50048]	Loss: 4.5476
Training Epoch: 0 [2560/50048]	Loss: 4.6125
Training Epoch: 0 [2624/50048]	Loss: 4.5134
Training Epoch: 0 [2688/50048]	Loss: 4.4599
Training Epoch: 0 [2752/50048]	Loss: 4.6417
Training Epoch: 0 [2816/50048]	Loss: 4.5635
Training Epoch: 0 [2880/50048]	Loss: 4.5883
Training Epoch: 0 [2944/50048]	Loss: 4.5041
Training Epoch: 0 [3008/50048]	Loss: 4.4921
Training Epoch: 0 [3072/50048]	Loss: 4.6338
Training Epoch: 0 [3136/50048]	Loss: 4.8209
Training Epoch: 0 [3200/50048]	Loss: 4.5281
Profile done with power limit 150W
epoch 1 train time consumed: 7.13s
Validation Epoch: 0, Average loss: 0.0743, Accuracy: 0.0120
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 150000, 'lr': 0.0028284271247461905, 'energy': 145.8979284030171, 'time': 5.247484172000441, 'accuracy': 0.0120421974522293, 'total_cost': 61334.93970369811}
[run job] Launching job with BS 64: and LR: 0.0028284271247461905 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00283+pl125', 'ZEUS_COST_THRESH': '69453.90413313772', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0028284271247461905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0028284271247461905', '--power_limit', '125']
[run job] cost_ub=69453.90413313772
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00283+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0028284271247461905
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.0397
Training Epoch: 0 [192/50048]	Loss: 5.2133
Training Epoch: 0 [256/50048]	Loss: 5.3898
Training Epoch: 0 [320/50048]	Loss: 5.2647
Training Epoch: 0 [384/50048]	Loss: 5.2515
Training Epoch: 0 [448/50048]	Loss: 4.9971
Training Epoch: 0 [512/50048]	Loss: 5.1878
Training Epoch: 0 [576/50048]	Loss: 4.7047
Training Epoch: 0 [640/50048]	Loss: 5.5158
Training Epoch: 0 [704/50048]	Loss: 4.9237
Training Epoch: 0 [768/50048]	Loss: 5.1957
Training Epoch: 0 [832/50048]	Loss: 4.9823
Training Epoch: 0 [896/50048]	Loss: 5.0011
Training Epoch: 0 [960/50048]	Loss: 4.8004
Training Epoch: 0 [1024/50048]	Loss: 4.7934
Training Epoch: 0 [1088/50048]	Loss: 4.8192
Training Epoch: 0 [1152/50048]	Loss: 4.7654
Training Epoch: 0 [1216/50048]	Loss: 4.6730
Training Epoch: 0 [1280/50048]	Loss: 4.6163
Training Epoch: 0 [1344/50048]	Loss: 4.8674
Training Epoch: 0 [1408/50048]	Loss: 4.5637
Training Epoch: 0 [1472/50048]	Loss: 4.5616
Training Epoch: 0 [1536/50048]	Loss: 4.7617
Training Epoch: 0 [1600/50048]	Loss: 4.8976
Training Epoch: 0 [1664/50048]	Loss: 4.8431
Training Epoch: 0 [1728/50048]	Loss: 4.6815
Training Epoch: 0 [1792/50048]	Loss: 4.6856
Training Epoch: 0 [1856/50048]	Loss: 4.7669
Training Epoch: 0 [1920/50048]	Loss: 4.6654
Training Epoch: 0 [1984/50048]	Loss: 4.5288
Training Epoch: 0 [2048/50048]	Loss: 4.6337
Training Epoch: 0 [2112/50048]	Loss: 4.6067
Training Epoch: 0 [2176/50048]	Loss: 4.6993
Training Epoch: 0 [2240/50048]	Loss: 4.5777
Training Epoch: 0 [2304/50048]	Loss: 4.6978
Training Epoch: 0 [2368/50048]	Loss: 4.6524
Training Epoch: 0 [2432/50048]	Loss: 4.5505
Training Epoch: 0 [2496/50048]	Loss: 4.5757
Training Epoch: 0 [2560/50048]	Loss: 4.6275
Training Epoch: 0 [2624/50048]	Loss: 4.4883
Training Epoch: 0 [2688/50048]	Loss: 4.4783
Training Epoch: 0 [2752/50048]	Loss: 4.5567
Training Epoch: 0 [2816/50048]	Loss: 4.5066
Training Epoch: 0 [2880/50048]	Loss: 4.5324
Training Epoch: 0 [2944/50048]	Loss: 4.4933
Training Epoch: 0 [3008/50048]	Loss: 4.5097
Training Epoch: 0 [3072/50048]	Loss: 4.6311
Training Epoch: 0 [3136/50048]	Loss: 4.7195
Training Epoch: 0 [3200/50048]	Loss: 4.6664
Profile done with power limit 125W
epoch 1 train time consumed: 7.85s
Validation Epoch: 0, Average loss: 0.0711, Accuracy: 0.0246
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 125000, 'lr': 0.0028284271247461905, 'energy': 123.16743348535297, 'time': 5.865504272999715, 'accuracy': 0.024582006369426753, 'total_cost': 33533.49583916567}
[run job] Launching job with BS 64: and LR: 0.0028284271247461905 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00283+pl100', 'ZEUS_COST_THRESH': '67066.99167833134', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0028284271247461905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0028284271247461905', '--power_limit', '100']
[run job] cost_ub=67066.99167833134
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00283+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0028284271247461905
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.0397
Training Epoch: 0 [192/50048]	Loss: 5.2109
Training Epoch: 0 [256/50048]	Loss: 5.3950
Training Epoch: 0 [320/50048]	Loss: 5.2495
Training Epoch: 0 [384/50048]	Loss: 5.2639
Training Epoch: 0 [448/50048]	Loss: 4.9673
Training Epoch: 0 [512/50048]	Loss: 5.2093
Training Epoch: 0 [576/50048]	Loss: 4.7158
Training Epoch: 0 [640/50048]	Loss: 5.4592
Training Epoch: 0 [704/50048]	Loss: 4.8887
Training Epoch: 0 [768/50048]	Loss: 5.1816
Training Epoch: 0 [832/50048]	Loss: 5.0195
Training Epoch: 0 [896/50048]	Loss: 4.9759
Training Epoch: 0 [960/50048]	Loss: 4.9014
Training Epoch: 0 [1024/50048]	Loss: 4.7472
Training Epoch: 0 [1088/50048]	Loss: 4.8265
Training Epoch: 0 [1152/50048]	Loss: 4.8055
Training Epoch: 0 [1216/50048]	Loss: 4.8437
Training Epoch: 0 [1280/50048]	Loss: 4.6314
Training Epoch: 0 [1344/50048]	Loss: 4.7637
Training Epoch: 0 [1408/50048]	Loss: 4.6044
Training Epoch: 0 [1472/50048]	Loss: 4.6179
Training Epoch: 0 [1536/50048]	Loss: 4.7290
Training Epoch: 0 [1600/50048]	Loss: 4.7369
Training Epoch: 0 [1664/50048]	Loss: 4.8404
Training Epoch: 0 [1728/50048]	Loss: 4.8065
Training Epoch: 0 [1792/50048]	Loss: 4.6384
Training Epoch: 0 [1856/50048]	Loss: 4.7213
Training Epoch: 0 [1920/50048]	Loss: 4.6598
Training Epoch: 0 [1984/50048]	Loss: 4.5031
Training Epoch: 0 [2048/50048]	Loss: 4.6849
Training Epoch: 0 [2112/50048]	Loss: 4.6781
Training Epoch: 0 [2176/50048]	Loss: 4.7322
Training Epoch: 0 [2240/50048]	Loss: 4.5974
Training Epoch: 0 [2304/50048]	Loss: 4.7525
Training Epoch: 0 [2368/50048]	Loss: 4.6846
Training Epoch: 0 [2432/50048]	Loss: 4.5518
Training Epoch: 0 [2496/50048]	Loss: 4.6455
Training Epoch: 0 [2560/50048]	Loss: 4.5397
Training Epoch: 0 [2624/50048]	Loss: 4.4505
Training Epoch: 0 [2688/50048]	Loss: 4.4791
Training Epoch: 0 [2752/50048]	Loss: 4.6440
Training Epoch: 0 [2816/50048]	Loss: 4.4647
Training Epoch: 0 [2880/50048]	Loss: 4.4687
Training Epoch: 0 [2944/50048]	Loss: 4.5551
Training Epoch: 0 [3008/50048]	Loss: 4.3949
Training Epoch: 0 [3072/50048]	Loss: 4.4556
Training Epoch: 0 [3136/50048]	Loss: 4.8931
Training Epoch: 0 [3200/50048]	Loss: 4.6095
Profile done with power limit 100W
epoch 1 train time consumed: 15.94s
Validation Epoch: 0, Average loss: 0.0715, Accuracy: 0.0155
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 100000, 'lr': 0.0028284271247461905, 'energy': 99.61297737397913, 'time': 12.508404917999542, 'accuracy': 0.01552547770700637, 'total_cost': 112890.6795920867}

[Power Profiler] with batch size 64 and learning rate 0.0033941125496954284
[run job] Launching job with BS 64: and LR: 0.0033941125496954284 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00339+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0033941125496954284', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0033941125496954284', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00339+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0033941125496954284
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.2218
Training Epoch: 0 [192/50048]	Loss: 5.4171
Training Epoch: 0 [256/50048]	Loss: 5.5674
Training Epoch: 0 [320/50048]	Loss: 5.3614
Training Epoch: 0 [384/50048]	Loss: 5.3728
Training Epoch: 0 [448/50048]	Loss: 5.0402
Training Epoch: 0 [512/50048]	Loss: 5.1491
Training Epoch: 0 [576/50048]	Loss: 4.7766
Training Epoch: 0 [640/50048]	Loss: 5.4694
Training Epoch: 0 [704/50048]	Loss: 4.7409
Training Epoch: 0 [768/50048]	Loss: 4.8480
Training Epoch: 0 [832/50048]	Loss: 4.7872
Training Epoch: 0 [896/50048]	Loss: 4.9636
Training Epoch: 0 [960/50048]	Loss: 4.9474
Training Epoch: 0 [1024/50048]	Loss: 4.8168
Training Epoch: 0 [1088/50048]	Loss: 4.8168
Training Epoch: 0 [1152/50048]	Loss: 4.8066
Training Epoch: 0 [1216/50048]	Loss: 4.6885
Training Epoch: 0 [1280/50048]	Loss: 4.6442
Training Epoch: 0 [1344/50048]	Loss: 4.8030
Training Epoch: 0 [1408/50048]	Loss: 4.5519
Training Epoch: 0 [1472/50048]	Loss: 4.5909
Training Epoch: 0 [1536/50048]	Loss: 4.6690
Training Epoch: 0 [1600/50048]	Loss: 4.7418
Training Epoch: 0 [1664/50048]	Loss: 4.8095
Training Epoch: 0 [1728/50048]	Loss: 4.7714
Training Epoch: 0 [1792/50048]	Loss: 4.7013
Training Epoch: 0 [1856/50048]	Loss: 4.7411
Training Epoch: 0 [1920/50048]	Loss: 4.5817
Training Epoch: 0 [1984/50048]	Loss: 4.6078
Training Epoch: 0 [2048/50048]	Loss: 4.5737
Training Epoch: 0 [2112/50048]	Loss: 4.7587
Training Epoch: 0 [2176/50048]	Loss: 4.5707
Training Epoch: 0 [2240/50048]	Loss: 4.5945
Training Epoch: 0 [2304/50048]	Loss: 4.5426
Training Epoch: 0 [2368/50048]	Loss: 4.7447
Training Epoch: 0 [2432/50048]	Loss: 4.6962
Training Epoch: 0 [2496/50048]	Loss: 4.6731
Training Epoch: 0 [2560/50048]	Loss: 4.5533
Training Epoch: 0 [2624/50048]	Loss: 4.5290
Training Epoch: 0 [2688/50048]	Loss: 4.4911
Training Epoch: 0 [2752/50048]	Loss: 4.5156
Training Epoch: 0 [2816/50048]	Loss: 4.4931
Training Epoch: 0 [2880/50048]	Loss: 4.4894
Training Epoch: 0 [2944/50048]	Loss: 4.6069
Training Epoch: 0 [3008/50048]	Loss: 4.6917
Training Epoch: 0 [3072/50048]	Loss: 4.6842
Training Epoch: 0 [3136/50048]	Loss: 4.6029
Training Epoch: 0 [3200/50048]	Loss: 4.6377
Profile done with power limit 175W
epoch 1 train time consumed: 7.13s
Validation Epoch: 0, Average loss: 0.0863, Accuracy: 0.0196
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 175000, 'lr': 0.0033941125496954284, 'energy': 145.25828745877072, 'time': 5.233205909999924, 'accuracy': 0.019605891719745222, 'total_cost': 37569.82731314708}
[run job] Launching job with BS 64: and LR: 0.0033941125496954284 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00339+pl150', 'ZEUS_COST_THRESH': '75139.65462629416', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0033941125496954284', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0033941125496954284', '--power_limit', '150']
[run job] cost_ub=75139.65462629416
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00339+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0033941125496954284
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.2218
Training Epoch: 0 [192/50048]	Loss: 5.4170
Training Epoch: 0 [256/50048]	Loss: 5.5470
Training Epoch: 0 [320/50048]	Loss: 5.3575
Training Epoch: 0 [384/50048]	Loss: 5.3808
Training Epoch: 0 [448/50048]	Loss: 5.1152
Training Epoch: 0 [512/50048]	Loss: 5.2754
Training Epoch: 0 [576/50048]	Loss: 4.8080
Training Epoch: 0 [640/50048]	Loss: 5.5725
Training Epoch: 0 [704/50048]	Loss: 4.7840
Training Epoch: 0 [768/50048]	Loss: 5.1080
Training Epoch: 0 [832/50048]	Loss: 4.8327
Training Epoch: 0 [896/50048]	Loss: 4.8668
Training Epoch: 0 [960/50048]	Loss: 4.8120
Training Epoch: 0 [1024/50048]	Loss: 4.7474
Training Epoch: 0 [1088/50048]	Loss: 4.7384
Training Epoch: 0 [1152/50048]	Loss: 4.8239
Training Epoch: 0 [1216/50048]	Loss: 4.8171
Training Epoch: 0 [1280/50048]	Loss: 4.5822
Training Epoch: 0 [1344/50048]	Loss: 4.7595
Training Epoch: 0 [1408/50048]	Loss: 4.5850
Training Epoch: 0 [1472/50048]	Loss: 4.6353
Training Epoch: 0 [1536/50048]	Loss: 4.7792
Training Epoch: 0 [1600/50048]	Loss: 4.9199
Training Epoch: 0 [1664/50048]	Loss: 4.7852
Training Epoch: 0 [1728/50048]	Loss: 4.6713
Training Epoch: 0 [1792/50048]	Loss: 4.5775
Training Epoch: 0 [1856/50048]	Loss: 4.5876
Training Epoch: 0 [1920/50048]	Loss: 4.5999
Training Epoch: 0 [1984/50048]	Loss: 4.5215
Training Epoch: 0 [2048/50048]	Loss: 4.5966
Training Epoch: 0 [2112/50048]	Loss: 4.6760
Training Epoch: 0 [2176/50048]	Loss: 4.6784
Training Epoch: 0 [2240/50048]	Loss: 4.6235
Training Epoch: 0 [2304/50048]	Loss: 4.6120
Training Epoch: 0 [2368/50048]	Loss: 4.6326
Training Epoch: 0 [2432/50048]	Loss: 4.5545
Training Epoch: 0 [2496/50048]	Loss: 4.5590
Training Epoch: 0 [2560/50048]	Loss: 4.5558
Training Epoch: 0 [2624/50048]	Loss: 4.4943
Training Epoch: 0 [2688/50048]	Loss: 4.4356
Training Epoch: 0 [2752/50048]	Loss: 4.5870
Training Epoch: 0 [2816/50048]	Loss: 4.5288
Training Epoch: 0 [2880/50048]	Loss: 4.5442
Training Epoch: 0 [2944/50048]	Loss: 4.5544
Training Epoch: 0 [3008/50048]	Loss: 4.4608
Training Epoch: 0 [3072/50048]	Loss: 4.5879
Training Epoch: 0 [3136/50048]	Loss: 4.7056
Training Epoch: 0 [3200/50048]	Loss: 4.5313
Profile done with power limit 150W
epoch 1 train time consumed: 7.19s
Validation Epoch: 0, Average loss: 0.0768, Accuracy: 0.0172
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 150000, 'lr': 0.0033941125496954284, 'energy': 145.52415454699613, 'time': 5.262827325000217, 'accuracy': 0.01721735668789809, 'total_cost': 43022.9506216271}
[run job] Launching job with BS 64: and LR: 0.0033941125496954284 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00339+pl125', 'ZEUS_COST_THRESH': '75139.65462629416', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0033941125496954284', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0033941125496954284', '--power_limit', '125']
[run job] cost_ub=75139.65462629416
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00339+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0033941125496954284
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.2218
Training Epoch: 0 [192/50048]	Loss: 5.4178
Training Epoch: 0 [256/50048]	Loss: 5.5765
Training Epoch: 0 [320/50048]	Loss: 5.3833
Training Epoch: 0 [384/50048]	Loss: 5.3686
Training Epoch: 0 [448/50048]	Loss: 5.0896
Training Epoch: 0 [512/50048]	Loss: 5.2030
Training Epoch: 0 [576/50048]	Loss: 4.7361
Training Epoch: 0 [640/50048]	Loss: 5.5101
Training Epoch: 0 [704/50048]	Loss: 4.6978
Training Epoch: 0 [768/50048]	Loss: 4.8893
Training Epoch: 0 [832/50048]	Loss: 4.7328
Training Epoch: 0 [896/50048]	Loss: 4.8526
Training Epoch: 0 [960/50048]	Loss: 4.9128
Training Epoch: 0 [1024/50048]	Loss: 4.7738
Training Epoch: 0 [1088/50048]	Loss: 4.7871
Training Epoch: 0 [1152/50048]	Loss: 4.8577
Training Epoch: 0 [1216/50048]	Loss: 4.7113
Training Epoch: 0 [1280/50048]	Loss: 4.6685
Training Epoch: 0 [1344/50048]	Loss: 4.7994
Training Epoch: 0 [1408/50048]	Loss: 4.5549
Training Epoch: 0 [1472/50048]	Loss: 4.5983
Training Epoch: 0 [1536/50048]	Loss: 4.7074
Training Epoch: 0 [1600/50048]	Loss: 4.9431
Training Epoch: 0 [1664/50048]	Loss: 4.8279
Training Epoch: 0 [1728/50048]	Loss: 4.7686
Training Epoch: 0 [1792/50048]	Loss: 4.6628
Training Epoch: 0 [1856/50048]	Loss: 4.7662
Training Epoch: 0 [1920/50048]	Loss: 4.6485
Training Epoch: 0 [1984/50048]	Loss: 4.5242
Training Epoch: 0 [2048/50048]	Loss: 4.5820
Training Epoch: 0 [2112/50048]	Loss: 4.7421
Training Epoch: 0 [2176/50048]	Loss: 4.5869
Training Epoch: 0 [2240/50048]	Loss: 4.6065
Training Epoch: 0 [2304/50048]	Loss: 4.5676
Training Epoch: 0 [2368/50048]	Loss: 4.6034
Training Epoch: 0 [2432/50048]	Loss: 4.5665
Training Epoch: 0 [2496/50048]	Loss: 4.5627
Training Epoch: 0 [2560/50048]	Loss: 4.5518
Training Epoch: 0 [2624/50048]	Loss: 4.4320
Training Epoch: 0 [2688/50048]	Loss: 4.4977
Training Epoch: 0 [2752/50048]	Loss: 4.5297
Training Epoch: 0 [2816/50048]	Loss: 4.4735
Training Epoch: 0 [2880/50048]	Loss: 4.5145
Training Epoch: 0 [2944/50048]	Loss: 4.5658
Training Epoch: 0 [3008/50048]	Loss: 4.5777
Training Epoch: 0 [3072/50048]	Loss: 4.6083
Training Epoch: 0 [3136/50048]	Loss: 4.5672
Training Epoch: 0 [3200/50048]	Loss: 4.4846
Profile done with power limit 125W
epoch 1 train time consumed: 7.85s
Validation Epoch: 0, Average loss: 0.0896, Accuracy: 0.0217
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 125000, 'lr': 0.0033941125496954284, 'energy': 123.09051693515889, 'time': 5.87623262499983, 'accuracy': 0.021695859872611464, 'total_cost': 38063.42237458014}
[run job] Launching job with BS 64: and LR: 0.0033941125496954284 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs64+lr0.00339+pl100', 'ZEUS_COST_THRESH': '75139.65462629416', 'ZEUS_BATCH_SIZE': '64', 'ZEUS_LEARNING_RATE': '0.0033941125496954284', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '64', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0033941125496954284', '--power_limit', '100']
[run job] cost_ub=75139.65462629416
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs64+lr0.00339+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0033941125496954284
batch size arg: 64
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [64/50048]	Loss: 4.6943
Training Epoch: 0 [128/50048]	Loss: 5.2218
Training Epoch: 0 [192/50048]	Loss: 5.4158
Training Epoch: 0 [256/50048]	Loss: 5.5741
Training Epoch: 0 [320/50048]	Loss: 5.3614
Training Epoch: 0 [384/50048]	Loss: 5.3210
Training Epoch: 0 [448/50048]	Loss: 5.0702
Training Epoch: 0 [512/50048]	Loss: 5.1778
Training Epoch: 0 [576/50048]	Loss: 4.7239
Training Epoch: 0 [640/50048]	Loss: 5.5379
Training Epoch: 0 [704/50048]	Loss: 4.8133
Training Epoch: 0 [768/50048]	Loss: 5.0430
Training Epoch: 0 [832/50048]	Loss: 4.9344
Training Epoch: 0 [896/50048]	Loss: 4.9968
Training Epoch: 0 [960/50048]	Loss: 4.7373
Training Epoch: 0 [1024/50048]	Loss: 4.7656
Training Epoch: 0 [1088/50048]	Loss: 4.8237
Training Epoch: 0 [1152/50048]	Loss: 4.7946
Training Epoch: 0 [1216/50048]	Loss: 4.6240
Training Epoch: 0 [1280/50048]	Loss: 4.5420
Training Epoch: 0 [1344/50048]	Loss: 4.7010
Training Epoch: 0 [1408/50048]	Loss: 4.5970
Training Epoch: 0 [1472/50048]	Loss: 4.6592
Training Epoch: 0 [1536/50048]	Loss: 4.7071
Training Epoch: 0 [1600/50048]	Loss: 4.8870
Training Epoch: 0 [1664/50048]	Loss: 4.7582
Training Epoch: 0 [1728/50048]	Loss: 4.5777
Training Epoch: 0 [1792/50048]	Loss: 4.5612
Training Epoch: 0 [1856/50048]	Loss: 4.9076
Training Epoch: 0 [1920/50048]	Loss: 4.6897
Training Epoch: 0 [1984/50048]	Loss: 4.5605
Training Epoch: 0 [2048/50048]	Loss: 4.6538
Training Epoch: 0 [2112/50048]	Loss: 4.7212
Training Epoch: 0 [2176/50048]	Loss: 4.5905
Training Epoch: 0 [2240/50048]	Loss: 4.6080
Training Epoch: 0 [2304/50048]	Loss: 4.6175
Training Epoch: 0 [2368/50048]	Loss: 4.5527
Training Epoch: 0 [2432/50048]	Loss: 4.5391
Training Epoch: 0 [2496/50048]	Loss: 4.5220
Training Epoch: 0 [2560/50048]	Loss: 4.5737
Training Epoch: 0 [2624/50048]	Loss: 4.4865
Training Epoch: 0 [2688/50048]	Loss: 4.4889
Training Epoch: 0 [2752/50048]	Loss: 4.5196
Training Epoch: 0 [2816/50048]	Loss: 4.4764
Training Epoch: 0 [2880/50048]	Loss: 4.4856
Training Epoch: 0 [2944/50048]	Loss: 4.5250
Training Epoch: 0 [3008/50048]	Loss: 4.5178
Training Epoch: 0 [3072/50048]	Loss: 4.6941
Training Epoch: 0 [3136/50048]	Loss: 4.6495
Training Epoch: 0 [3200/50048]	Loss: 4.4962
Profile done with power limit 100W
epoch 1 train time consumed: 15.98s
Validation Epoch: 0, Average loss: 0.0839, Accuracy: 0.0196
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 64, 'pl': 100000, 'lr': 0.0033941125496954284, 'energy': 99.35673791499923, 'time': 12.526997709999705, 'accuracy': 0.019605891719745222, 'total_cost': 89527.88564953797}

[Power Profiler] with batch size 128 and learning rate 0.0032
[run job] Launching job with BS 128: and LR: 0.0032 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00320+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0032', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0032', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00320+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0032
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.1136
Training Epoch: 0 [384/50048]	Loss: 5.3868
Training Epoch: 0 [512/50048]	Loss: 5.1064
Training Epoch: 0 [640/50048]	Loss: 4.9931
Training Epoch: 0 [768/50048]	Loss: 4.9896
Training Epoch: 0 [896/50048]	Loss: 5.0229
Training Epoch: 0 [1024/50048]	Loss: 5.0193
Training Epoch: 0 [1152/50048]	Loss: 4.9430
Training Epoch: 0 [1280/50048]	Loss: 4.9061
Training Epoch: 0 [1408/50048]	Loss: 4.6511
Training Epoch: 0 [1536/50048]	Loss: 4.7958
Training Epoch: 0 [1664/50048]	Loss: 4.8361
Training Epoch: 0 [1792/50048]	Loss: 4.5692
Training Epoch: 0 [1920/50048]	Loss: 4.6989
Training Epoch: 0 [2048/50048]	Loss: 4.5480
Training Epoch: 0 [2176/50048]	Loss: 4.7069
Training Epoch: 0 [2304/50048]	Loss: 4.6269
Training Epoch: 0 [2432/50048]	Loss: 4.6097
Training Epoch: 0 [2560/50048]	Loss: 4.6302
Training Epoch: 0 [2688/50048]	Loss: 4.5636
Training Epoch: 0 [2816/50048]	Loss: 4.6491
Training Epoch: 0 [2944/50048]	Loss: 4.4825
Training Epoch: 0 [3072/50048]	Loss: 4.5921
Training Epoch: 0 [3200/50048]	Loss: 4.6118
Training Epoch: 0 [3328/50048]	Loss: 4.5761
Training Epoch: 0 [3456/50048]	Loss: 4.5128
Training Epoch: 0 [3584/50048]	Loss: 4.5058
Training Epoch: 0 [3712/50048]	Loss: 4.7791
Training Epoch: 0 [3840/50048]	Loss: 4.5301
Training Epoch: 0 [3968/50048]	Loss: 4.6139
Training Epoch: 0 [4096/50048]	Loss: 4.6349
Training Epoch: 0 [4224/50048]	Loss: 4.5013
Training Epoch: 0 [4352/50048]	Loss: 4.4599
Training Epoch: 0 [4480/50048]	Loss: 4.4308
Training Epoch: 0 [4608/50048]	Loss: 4.4992
Training Epoch: 0 [4736/50048]	Loss: 4.3966
Training Epoch: 0 [4864/50048]	Loss: 4.4924
Training Epoch: 0 [4992/50048]	Loss: 4.4326
Training Epoch: 0 [5120/50048]	Loss: 4.4796
Training Epoch: 0 [5248/50048]	Loss: 4.4323
Training Epoch: 0 [5376/50048]	Loss: 4.4361
Training Epoch: 0 [5504/50048]	Loss: 4.5073
Training Epoch: 0 [5632/50048]	Loss: 4.4386
Training Epoch: 0 [5760/50048]	Loss: 4.3678
Training Epoch: 0 [5888/50048]	Loss: 4.3065
Training Epoch: 0 [6016/50048]	Loss: 4.3242
Training Epoch: 0 [6144/50048]	Loss: 4.1685
Training Epoch: 0 [6272/50048]	Loss: 4.4710
Training Epoch: 0 [6400/50048]	Loss: 4.3151
Profile done with power limit 175W
epoch 1 train time consumed: 11.40s
Validation Epoch: 0, Average loss: 0.0371, Accuracy: 0.0326
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 175000, 'lr': 0.0032, 'energy': 148.9784703180723, 'time': 8.581660894999914, 'accuracy': 0.032634493670886076, 'total_cost': 73850.87737089292}
[run job] Launching job with BS 128: and LR: 0.0032 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00320+pl150', 'ZEUS_COST_THRESH': '147701.75474178584', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0032', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0032', '--power_limit', '150']
[run job] cost_ub=147701.75474178584
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00320+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0032
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.1136
Training Epoch: 0 [384/50048]	Loss: 5.3871
Training Epoch: 0 [512/50048]	Loss: 5.1155
Training Epoch: 0 [640/50048]	Loss: 4.9942
Training Epoch: 0 [768/50048]	Loss: 5.0041
Training Epoch: 0 [896/50048]	Loss: 5.0240
Training Epoch: 0 [1024/50048]	Loss: 5.0167
Training Epoch: 0 [1152/50048]	Loss: 4.9033
Training Epoch: 0 [1280/50048]	Loss: 4.9077
Training Epoch: 0 [1408/50048]	Loss: 4.6584
Training Epoch: 0 [1536/50048]	Loss: 4.8034
Training Epoch: 0 [1664/50048]	Loss: 4.8370
Training Epoch: 0 [1792/50048]	Loss: 4.5592
Training Epoch: 0 [1920/50048]	Loss: 4.7699
Training Epoch: 0 [2048/50048]	Loss: 4.5268
Training Epoch: 0 [2176/50048]	Loss: 4.7527
Training Epoch: 0 [2304/50048]	Loss: 4.6461
Training Epoch: 0 [2432/50048]	Loss: 4.5999
Training Epoch: 0 [2560/50048]	Loss: 4.6426
Training Epoch: 0 [2688/50048]	Loss: 4.6183
Training Epoch: 0 [2816/50048]	Loss: 4.5877
Training Epoch: 0 [2944/50048]	Loss: 4.5266
Training Epoch: 0 [3072/50048]	Loss: 4.6089
Training Epoch: 0 [3200/50048]	Loss: 4.6519
Training Epoch: 0 [3328/50048]	Loss: 4.5906
Training Epoch: 0 [3456/50048]	Loss: 4.5320
Training Epoch: 0 [3584/50048]	Loss: 4.5790
Training Epoch: 0 [3712/50048]	Loss: 4.8149
Training Epoch: 0 [3840/50048]	Loss: 4.5233
Training Epoch: 0 [3968/50048]	Loss: 4.5517
Training Epoch: 0 [4096/50048]	Loss: 4.6810
Training Epoch: 0 [4224/50048]	Loss: 4.5327
Training Epoch: 0 [4352/50048]	Loss: 4.4249
Training Epoch: 0 [4480/50048]	Loss: 4.4437
Training Epoch: 0 [4608/50048]	Loss: 4.5333
Training Epoch: 0 [4736/50048]	Loss: 4.4026
Training Epoch: 0 [4864/50048]	Loss: 4.4907
Training Epoch: 0 [4992/50048]	Loss: 4.4308
Training Epoch: 0 [5120/50048]	Loss: 4.4187
Training Epoch: 0 [5248/50048]	Loss: 4.3922
Training Epoch: 0 [5376/50048]	Loss: 4.3639
Training Epoch: 0 [5504/50048]	Loss: 4.3901
Training Epoch: 0 [5632/50048]	Loss: 4.4613
Training Epoch: 0 [5760/50048]	Loss: 4.3798
Training Epoch: 0 [5888/50048]	Loss: 4.2659
Training Epoch: 0 [6016/50048]	Loss: 4.2611
Training Epoch: 0 [6144/50048]	Loss: 4.1279
Training Epoch: 0 [6272/50048]	Loss: 4.4716
Training Epoch: 0 [6400/50048]	Loss: 4.3078
Profile done with power limit 150W
epoch 1 train time consumed: 11.48s
Validation Epoch: 0, Average loss: 0.0377, Accuracy: 0.0306
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 150000, 'lr': 0.0032, 'energy': 147.0278171473753, 'time': 8.674355674999788, 'accuracy': 0.030557753164556962, 'total_cost': 79714.33308274878}
[run job] Launching job with BS 128: and LR: 0.0032 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00320+pl125', 'ZEUS_COST_THRESH': '147701.75474178584', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0032', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0032', '--power_limit', '125']
[run job] cost_ub=147701.75474178584
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00320+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0032
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.1136
Training Epoch: 0 [384/50048]	Loss: 5.3870
Training Epoch: 0 [512/50048]	Loss: 5.1073
Training Epoch: 0 [640/50048]	Loss: 4.9959
Training Epoch: 0 [768/50048]	Loss: 4.9963
Training Epoch: 0 [896/50048]	Loss: 5.0438
Training Epoch: 0 [1024/50048]	Loss: 5.0616
Training Epoch: 0 [1152/50048]	Loss: 4.9314
Training Epoch: 0 [1280/50048]	Loss: 4.9268
Training Epoch: 0 [1408/50048]	Loss: 4.6735
Training Epoch: 0 [1536/50048]	Loss: 4.7621
Training Epoch: 0 [1664/50048]	Loss: 4.7982
Training Epoch: 0 [1792/50048]	Loss: 4.5720
Training Epoch: 0 [1920/50048]	Loss: 4.7662
Training Epoch: 0 [2048/50048]	Loss: 4.5085
Training Epoch: 0 [2176/50048]	Loss: 4.7582
Training Epoch: 0 [2304/50048]	Loss: 4.6534
Training Epoch: 0 [2432/50048]	Loss: 4.5682
Training Epoch: 0 [2560/50048]	Loss: 4.6153
Training Epoch: 0 [2688/50048]	Loss: 4.5946
Training Epoch: 0 [2816/50048]	Loss: 4.6038
Training Epoch: 0 [2944/50048]	Loss: 4.4669
Training Epoch: 0 [3072/50048]	Loss: 4.6017
Training Epoch: 0 [3200/50048]	Loss: 4.5908
Training Epoch: 0 [3328/50048]	Loss: 4.5510
Training Epoch: 0 [3456/50048]	Loss: 4.5125
Training Epoch: 0 [3584/50048]	Loss: 4.5265
Training Epoch: 0 [3712/50048]	Loss: 4.8381
Training Epoch: 0 [3840/50048]	Loss: 4.4942
Training Epoch: 0 [3968/50048]	Loss: 4.5060
Training Epoch: 0 [4096/50048]	Loss: 4.7047
Training Epoch: 0 [4224/50048]	Loss: 4.5016
Training Epoch: 0 [4352/50048]	Loss: 4.3922
Training Epoch: 0 [4480/50048]	Loss: 4.3583
Training Epoch: 0 [4608/50048]	Loss: 4.4196
Training Epoch: 0 [4736/50048]	Loss: 4.3433
Training Epoch: 0 [4864/50048]	Loss: 4.4548
Training Epoch: 0 [4992/50048]	Loss: 4.3623
Training Epoch: 0 [5120/50048]	Loss: 4.3623
Training Epoch: 0 [5248/50048]	Loss: 4.3576
Training Epoch: 0 [5376/50048]	Loss: 4.3259
Training Epoch: 0 [5504/50048]	Loss: 4.3102
Training Epoch: 0 [5632/50048]	Loss: 4.3907
Training Epoch: 0 [5760/50048]	Loss: 4.3515
Training Epoch: 0 [5888/50048]	Loss: 4.2156
Training Epoch: 0 [6016/50048]	Loss: 4.2472
Training Epoch: 0 [6144/50048]	Loss: 4.0950
Training Epoch: 0 [6272/50048]	Loss: 4.4186
Training Epoch: 0 [6400/50048]	Loss: 4.2617
Profile done with power limit 125W
epoch 1 train time consumed: 12.80s
Validation Epoch: 0, Average loss: 0.0361, Accuracy: 0.0358
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 125000, 'lr': 0.0032, 'energy': 123.18685461386492, 'time': 9.77295614400009, 'accuracy': 0.035799050632911396, 'total_cost': 76585.26184532142}
[run job] Launching job with BS 128: and LR: 0.0032 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00320+pl100', 'ZEUS_COST_THRESH': '147701.75474178584', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0032', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0032', '--power_limit', '100']
[run job] cost_ub=147701.75474178584
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00320+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0032
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.1136
Training Epoch: 0 [384/50048]	Loss: 5.3868
Training Epoch: 0 [512/50048]	Loss: 5.1023
Training Epoch: 0 [640/50048]	Loss: 5.0016
Training Epoch: 0 [768/50048]	Loss: 5.0162
Training Epoch: 0 [896/50048]	Loss: 5.0199
Training Epoch: 0 [1024/50048]	Loss: 5.0493
Training Epoch: 0 [1152/50048]	Loss: 4.9305
Training Epoch: 0 [1280/50048]	Loss: 4.9316
Training Epoch: 0 [1408/50048]	Loss: 4.6641
Training Epoch: 0 [1536/50048]	Loss: 4.7903
Training Epoch: 0 [1664/50048]	Loss: 4.8016
Training Epoch: 0 [1792/50048]	Loss: 4.5775
Training Epoch: 0 [1920/50048]	Loss: 4.7273
Training Epoch: 0 [2048/50048]	Loss: 4.5134
Training Epoch: 0 [2176/50048]	Loss: 4.7710
Training Epoch: 0 [2304/50048]	Loss: 4.6421
Training Epoch: 0 [2432/50048]	Loss: 4.5952
Training Epoch: 0 [2560/50048]	Loss: 4.6358
Training Epoch: 0 [2688/50048]	Loss: 4.5884
Training Epoch: 0 [2816/50048]	Loss: 4.6739
Training Epoch: 0 [2944/50048]	Loss: 4.4822
Training Epoch: 0 [3072/50048]	Loss: 4.5918
Training Epoch: 0 [3200/50048]	Loss: 4.5912
Training Epoch: 0 [3328/50048]	Loss: 4.5696
Training Epoch: 0 [3456/50048]	Loss: 4.5085
Training Epoch: 0 [3584/50048]	Loss: 4.5080
Training Epoch: 0 [3712/50048]	Loss: 4.7697
Training Epoch: 0 [3840/50048]	Loss: 4.5384
Training Epoch: 0 [3968/50048]	Loss: 4.5325
Training Epoch: 0 [4096/50048]	Loss: 4.6619
Training Epoch: 0 [4224/50048]	Loss: 4.5238
Training Epoch: 0 [4352/50048]	Loss: 4.4243
Training Epoch: 0 [4480/50048]	Loss: 4.4275
Training Epoch: 0 [4608/50048]	Loss: 4.4250
Training Epoch: 0 [4736/50048]	Loss: 4.3753
Training Epoch: 0 [4864/50048]	Loss: 4.4630
Training Epoch: 0 [4992/50048]	Loss: 4.4165
Training Epoch: 0 [5120/50048]	Loss: 4.4208
Training Epoch: 0 [5248/50048]	Loss: 4.4011
Training Epoch: 0 [5376/50048]	Loss: 4.3357
Training Epoch: 0 [5504/50048]	Loss: 4.3293
Training Epoch: 0 [5632/50048]	Loss: 4.4034
Training Epoch: 0 [5760/50048]	Loss: 4.3289
Training Epoch: 0 [5888/50048]	Loss: 4.2771
Training Epoch: 0 [6016/50048]	Loss: 4.2541
Training Epoch: 0 [6144/50048]	Loss: 4.1164
Training Epoch: 0 [6272/50048]	Loss: 4.4569
Training Epoch: 0 [6400/50048]	Loss: 4.2974
Profile done with power limit 100W
epoch 1 train time consumed: 27.07s
Validation Epoch: 0, Average loss: 0.0375, Accuracy: 0.0319
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 100000, 'lr': 0.0032, 'energy': 99.81397833826829, 'time': 21.101496047999717, 'accuracy': 0.031942246835443035, 'total_cost': 184994.31958074955}

[Power Profiler] with batch size 128 and learning rate 0.004
[run job] Launching job with BS 128: and LR: 0.004 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00400+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.004', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00400+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.004
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.3519
Training Epoch: 0 [384/50048]	Loss: 5.6633
Training Epoch: 0 [512/50048]	Loss: 5.2177
Training Epoch: 0 [640/50048]	Loss: 5.0005
Training Epoch: 0 [768/50048]	Loss: 4.9821
Training Epoch: 0 [896/50048]	Loss: 5.0363
Training Epoch: 0 [1024/50048]	Loss: 4.9258
Training Epoch: 0 [1152/50048]	Loss: 4.8585
Training Epoch: 0 [1280/50048]	Loss: 4.8026
Training Epoch: 0 [1408/50048]	Loss: 4.6345
Training Epoch: 0 [1536/50048]	Loss: 4.8386
Training Epoch: 0 [1664/50048]	Loss: 5.0009
Training Epoch: 0 [1792/50048]	Loss: 4.5747
Training Epoch: 0 [1920/50048]	Loss: 4.7661
Training Epoch: 0 [2048/50048]	Loss: 4.5130
Training Epoch: 0 [2176/50048]	Loss: 4.6814
Training Epoch: 0 [2304/50048]	Loss: 4.6017
Training Epoch: 0 [2432/50048]	Loss: 4.5240
Training Epoch: 0 [2560/50048]	Loss: 4.5780
Training Epoch: 0 [2688/50048]	Loss: 4.6093
Training Epoch: 0 [2816/50048]	Loss: 4.5493
Training Epoch: 0 [2944/50048]	Loss: 4.5290
Training Epoch: 0 [3072/50048]	Loss: 4.6456
Training Epoch: 0 [3200/50048]	Loss: 4.6077
Training Epoch: 0 [3328/50048]	Loss: 4.5404
Training Epoch: 0 [3456/50048]	Loss: 4.4868
Training Epoch: 0 [3584/50048]	Loss: 4.5365
Training Epoch: 0 [3712/50048]	Loss: 4.7816
Training Epoch: 0 [3840/50048]	Loss: 4.5692
Training Epoch: 0 [3968/50048]	Loss: 4.5396
Training Epoch: 0 [4096/50048]	Loss: 4.6347
Training Epoch: 0 [4224/50048]	Loss: 4.5484
Training Epoch: 0 [4352/50048]	Loss: 4.5191
Training Epoch: 0 [4480/50048]	Loss: 4.4738
Training Epoch: 0 [4608/50048]	Loss: 4.4741
Training Epoch: 0 [4736/50048]	Loss: 4.4360
Training Epoch: 0 [4864/50048]	Loss: 4.4733
Training Epoch: 0 [4992/50048]	Loss: 4.4266
Training Epoch: 0 [5120/50048]	Loss: 4.4380
Training Epoch: 0 [5248/50048]	Loss: 4.4212
Training Epoch: 0 [5376/50048]	Loss: 4.3906
Training Epoch: 0 [5504/50048]	Loss: 4.5146
Training Epoch: 0 [5632/50048]	Loss: 4.4967
Training Epoch: 0 [5760/50048]	Loss: 4.3920
Training Epoch: 0 [5888/50048]	Loss: 4.3424
Training Epoch: 0 [6016/50048]	Loss: 4.3178
Training Epoch: 0 [6144/50048]	Loss: 4.1978
Training Epoch: 0 [6272/50048]	Loss: 4.4911
Training Epoch: 0 [6400/50048]	Loss: 4.2888
Profile done with power limit 175W
epoch 1 train time consumed: 11.39s
Validation Epoch: 0, Average loss: 0.0358, Accuracy: 0.0357
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 175000, 'lr': 0.004, 'energy': 148.8167006289492, 'time': 8.586337287999413, 'accuracy': 0.035700158227848104, 'total_cost': 67545.46480326989}
[run job] Launching job with BS 128: and LR: 0.004 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00400+pl150', 'ZEUS_COST_THRESH': '135090.92960653978', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.004', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004', '--power_limit', '150']
[run job] cost_ub=135090.92960653978
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00400+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.004
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.3519
Training Epoch: 0 [384/50048]	Loss: 5.6633
Training Epoch: 0 [512/50048]	Loss: 5.2313
Training Epoch: 0 [640/50048]	Loss: 5.0021
Training Epoch: 0 [768/50048]	Loss: 4.9483
Training Epoch: 0 [896/50048]	Loss: 5.0091
Training Epoch: 0 [1024/50048]	Loss: 4.9117
Training Epoch: 0 [1152/50048]	Loss: 4.8639
Training Epoch: 0 [1280/50048]	Loss: 4.7979
Training Epoch: 0 [1408/50048]	Loss: 4.6302
Training Epoch: 0 [1536/50048]	Loss: 4.7637
Training Epoch: 0 [1664/50048]	Loss: 5.0216
Training Epoch: 0 [1792/50048]	Loss: 4.6206
Training Epoch: 0 [1920/50048]	Loss: 4.8010
Training Epoch: 0 [2048/50048]	Loss: 4.5260
Training Epoch: 0 [2176/50048]	Loss: 4.6889
Training Epoch: 0 [2304/50048]	Loss: 4.6348
Training Epoch: 0 [2432/50048]	Loss: 4.5461
Training Epoch: 0 [2560/50048]	Loss: 4.5766
Training Epoch: 0 [2688/50048]	Loss: 4.5974
Training Epoch: 0 [2816/50048]	Loss: 4.5318
Training Epoch: 0 [2944/50048]	Loss: 4.5542
Training Epoch: 0 [3072/50048]	Loss: 4.6667
Training Epoch: 0 [3200/50048]	Loss: 4.6292
Training Epoch: 0 [3328/50048]	Loss: 4.5424
Training Epoch: 0 [3456/50048]	Loss: 4.5010
Training Epoch: 0 [3584/50048]	Loss: 4.5678
Training Epoch: 0 [3712/50048]	Loss: 4.7192
Training Epoch: 0 [3840/50048]	Loss: 4.5973
Training Epoch: 0 [3968/50048]	Loss: 4.6459
Training Epoch: 0 [4096/50048]	Loss: 4.5871
Training Epoch: 0 [4224/50048]	Loss: 4.5880
Training Epoch: 0 [4352/50048]	Loss: 4.5867
Training Epoch: 0 [4480/50048]	Loss: 4.5071
Training Epoch: 0 [4608/50048]	Loss: 4.5415
Training Epoch: 0 [4736/50048]	Loss: 4.5461
Training Epoch: 0 [4864/50048]	Loss: 4.5416
Training Epoch: 0 [4992/50048]	Loss: 4.5384
Training Epoch: 0 [5120/50048]	Loss: 4.4838
Training Epoch: 0 [5248/50048]	Loss: 4.4850
Training Epoch: 0 [5376/50048]	Loss: 4.5131
Training Epoch: 0 [5504/50048]	Loss: 4.4697
Training Epoch: 0 [5632/50048]	Loss: 4.5205
Training Epoch: 0 [5760/50048]	Loss: 4.4104
Training Epoch: 0 [5888/50048]	Loss: 4.4314
Training Epoch: 0 [6016/50048]	Loss: 4.3932
Training Epoch: 0 [6144/50048]	Loss: 4.2318
Training Epoch: 0 [6272/50048]	Loss: 4.5932
Training Epoch: 0 [6400/50048]	Loss: 4.3615
Profile done with power limit 150W
epoch 1 train time consumed: 11.46s
Validation Epoch: 0, Average loss: 0.0383, Accuracy: 0.0331
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 150000, 'lr': 0.004, 'energy': 147.1548925032678, 'time': 8.657553351999923, 'accuracy': 0.033128955696202535, 'total_cost': 73385.9202514543}
[run job] Launching job with BS 128: and LR: 0.004 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00400+pl125', 'ZEUS_COST_THRESH': '135090.92960653978', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.004', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004', '--power_limit', '125']
[run job] cost_ub=135090.92960653978
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00400+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.004
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.3519
Training Epoch: 0 [384/50048]	Loss: 5.6630
Training Epoch: 0 [512/50048]	Loss: 5.2341
Training Epoch: 0 [640/50048]	Loss: 5.0114
Training Epoch: 0 [768/50048]	Loss: 4.9821
Training Epoch: 0 [896/50048]	Loss: 5.0081
Training Epoch: 0 [1024/50048]	Loss: 4.9186
Training Epoch: 0 [1152/50048]	Loss: 4.8576
Training Epoch: 0 [1280/50048]	Loss: 4.8324
Training Epoch: 0 [1408/50048]	Loss: 4.6415
Training Epoch: 0 [1536/50048]	Loss: 4.8454
Training Epoch: 0 [1664/50048]	Loss: 5.0466
Training Epoch: 0 [1792/50048]	Loss: 4.5703
Training Epoch: 0 [1920/50048]	Loss: 4.7073
Training Epoch: 0 [2048/50048]	Loss: 4.5254
Training Epoch: 0 [2176/50048]	Loss: 4.7022
Training Epoch: 0 [2304/50048]	Loss: 4.6127
Training Epoch: 0 [2432/50048]	Loss: 4.5309
Training Epoch: 0 [2560/50048]	Loss: 4.5848
Training Epoch: 0 [2688/50048]	Loss: 4.5599
Training Epoch: 0 [2816/50048]	Loss: 4.5958
Training Epoch: 0 [2944/50048]	Loss: 4.5166
Training Epoch: 0 [3072/50048]	Loss: 4.6418
Training Epoch: 0 [3200/50048]	Loss: 4.7560
Training Epoch: 0 [3328/50048]	Loss: 4.5471
Training Epoch: 0 [3456/50048]	Loss: 4.4917
Training Epoch: 0 [3584/50048]	Loss: 4.5416
Training Epoch: 0 [3712/50048]	Loss: 4.7453
Training Epoch: 0 [3840/50048]	Loss: 4.6483
Training Epoch: 0 [3968/50048]	Loss: 4.5775
Training Epoch: 0 [4096/50048]	Loss: 4.5861
Training Epoch: 0 [4224/50048]	Loss: 4.5928
Training Epoch: 0 [4352/50048]	Loss: 4.5280
Training Epoch: 0 [4480/50048]	Loss: 4.4723
Training Epoch: 0 [4608/50048]	Loss: 4.5191
Training Epoch: 0 [4736/50048]	Loss: 4.4445
Training Epoch: 0 [4864/50048]	Loss: 4.5209
Training Epoch: 0 [4992/50048]	Loss: 4.4191
Training Epoch: 0 [5120/50048]	Loss: 4.4783
Training Epoch: 0 [5248/50048]	Loss: 4.4310
Training Epoch: 0 [5376/50048]	Loss: 4.3971
Training Epoch: 0 [5504/50048]	Loss: 4.5230
Training Epoch: 0 [5632/50048]	Loss: 4.5505
Training Epoch: 0 [5760/50048]	Loss: 4.4386
Training Epoch: 0 [5888/50048]	Loss: 4.3763
Training Epoch: 0 [6016/50048]	Loss: 4.3946
Training Epoch: 0 [6144/50048]	Loss: 4.2508
Training Epoch: 0 [6272/50048]	Loss: 4.5626
Training Epoch: 0 [6400/50048]	Loss: 4.3282
Profile done with power limit 125W
epoch 1 train time consumed: 12.78s
Validation Epoch: 0, Average loss: 0.0374, Accuracy: 0.0285
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 125000, 'lr': 0.004, 'energy': 123.1703149009547, 'time': 9.75116239899944, 'accuracy': 0.028481012658227847, 'total_cost': 96049.33103243413}
[run job] Launching job with BS 128: and LR: 0.004 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00400+pl100', 'ZEUS_COST_THRESH': '135090.92960653978', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.004', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004', '--power_limit', '100']
[run job] cost_ub=135090.92960653978
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00400+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.004
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.3519
Training Epoch: 0 [384/50048]	Loss: 5.6623
Training Epoch: 0 [512/50048]	Loss: 5.2194
Training Epoch: 0 [640/50048]	Loss: 5.0266
Training Epoch: 0 [768/50048]	Loss: 4.9692
Training Epoch: 0 [896/50048]	Loss: 5.0164
Training Epoch: 0 [1024/50048]	Loss: 4.9290
Training Epoch: 0 [1152/50048]	Loss: 4.8610
Training Epoch: 0 [1280/50048]	Loss: 4.8268
Training Epoch: 0 [1408/50048]	Loss: 4.6334
Training Epoch: 0 [1536/50048]	Loss: 4.6972
Training Epoch: 0 [1664/50048]	Loss: 4.9950
Training Epoch: 0 [1792/50048]	Loss: 4.7446
Training Epoch: 0 [1920/50048]	Loss: 4.7684
Training Epoch: 0 [2048/50048]	Loss: 4.5152
Training Epoch: 0 [2176/50048]	Loss: 4.6847
Training Epoch: 0 [2304/50048]	Loss: 4.6203
Training Epoch: 0 [2432/50048]	Loss: 4.5484
Training Epoch: 0 [2560/50048]	Loss: 4.5765
Training Epoch: 0 [2688/50048]	Loss: 4.5510
Training Epoch: 0 [2816/50048]	Loss: 4.5244
Training Epoch: 0 [2944/50048]	Loss: 4.5453
Training Epoch: 0 [3072/50048]	Loss: 4.6525
Training Epoch: 0 [3200/50048]	Loss: 4.6055
Training Epoch: 0 [3328/50048]	Loss: 4.5458
Training Epoch: 0 [3456/50048]	Loss: 4.5023
Training Epoch: 0 [3584/50048]	Loss: 4.5749
Training Epoch: 0 [3712/50048]	Loss: 4.7481
Training Epoch: 0 [3840/50048]	Loss: 4.5516
Training Epoch: 0 [3968/50048]	Loss: 4.5524
Training Epoch: 0 [4096/50048]	Loss: 4.5942
Training Epoch: 0 [4224/50048]	Loss: 4.5942
Training Epoch: 0 [4352/50048]	Loss: 4.5534
Training Epoch: 0 [4480/50048]	Loss: 4.4912
Training Epoch: 0 [4608/50048]	Loss: 4.5036
Training Epoch: 0 [4736/50048]	Loss: 4.4367
Training Epoch: 0 [4864/50048]	Loss: 4.4855
Training Epoch: 0 [4992/50048]	Loss: 4.4090
Training Epoch: 0 [5120/50048]	Loss: 4.4462
Training Epoch: 0 [5248/50048]	Loss: 4.4522
Training Epoch: 0 [5376/50048]	Loss: 4.4272
Training Epoch: 0 [5504/50048]	Loss: 4.4516
Training Epoch: 0 [5632/50048]	Loss: 4.5351
Training Epoch: 0 [5760/50048]	Loss: 4.4329
Training Epoch: 0 [5888/50048]	Loss: 4.3646
Training Epoch: 0 [6016/50048]	Loss: 4.3640
Training Epoch: 0 [6144/50048]	Loss: 4.2246
Training Epoch: 0 [6272/50048]	Loss: 4.5466
Training Epoch: 0 [6400/50048]	Loss: 4.3071
Profile done with power limit 100W
epoch 1 train time consumed: 27.12s
Validation Epoch: 0, Average loss: 0.0395, Accuracy: 0.0315
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 100000, 'lr': 0.004, 'energy': 99.58444681957485, 'time': 21.132204231999822, 'accuracy': 0.031546677215189875, 'total_cost': 187585.82870661828}

[Power Profiler] with batch size 128 and learning rate 0.0048
[run job] Launching job with BS 128: and LR: 0.0048 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00480+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0048', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0048', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00480+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0048
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.6144
Training Epoch: 0 [384/50048]	Loss: 5.9809
Training Epoch: 0 [512/50048]	Loss: 5.3676
Training Epoch: 0 [640/50048]	Loss: 5.0926
Training Epoch: 0 [768/50048]	Loss: 5.1142
Training Epoch: 0 [896/50048]	Loss: 5.0354
Training Epoch: 0 [1024/50048]	Loss: 4.9323
Training Epoch: 0 [1152/50048]	Loss: 4.8304
Training Epoch: 0 [1280/50048]	Loss: 4.7866
Training Epoch: 0 [1408/50048]	Loss: 4.5757
Training Epoch: 0 [1536/50048]	Loss: 4.7033
Training Epoch: 0 [1664/50048]	Loss: 5.0438
Training Epoch: 0 [1792/50048]	Loss: 4.6108
Training Epoch: 0 [1920/50048]	Loss: 4.7018
Training Epoch: 0 [2048/50048]	Loss: 4.5533
Training Epoch: 0 [2176/50048]	Loss: 4.7450
Training Epoch: 0 [2304/50048]	Loss: 4.5910
Training Epoch: 0 [2432/50048]	Loss: 4.5629
Training Epoch: 0 [2560/50048]	Loss: 4.6183
Training Epoch: 0 [2688/50048]	Loss: 4.5766
Training Epoch: 0 [2816/50048]	Loss: 4.6698
Training Epoch: 0 [2944/50048]	Loss: 4.6946
Training Epoch: 0 [3072/50048]	Loss: 4.6376
Training Epoch: 0 [3200/50048]	Loss: 4.6319
Training Epoch: 0 [3328/50048]	Loss: 4.5953
Training Epoch: 0 [3456/50048]	Loss: 4.5440
Training Epoch: 0 [3584/50048]	Loss: 4.6037
Training Epoch: 0 [3712/50048]	Loss: 4.7148
Training Epoch: 0 [3840/50048]	Loss: 4.6377
Training Epoch: 0 [3968/50048]	Loss: 4.5541
Training Epoch: 0 [4096/50048]	Loss: 4.6915
Training Epoch: 0 [4224/50048]	Loss: 4.5622
Training Epoch: 0 [4352/50048]	Loss: 4.5584
Training Epoch: 0 [4480/50048]	Loss: 4.5360
Training Epoch: 0 [4608/50048]	Loss: 4.6145
Training Epoch: 0 [4736/50048]	Loss: 4.4727
Training Epoch: 0 [4864/50048]	Loss: 4.5765
Training Epoch: 0 [4992/50048]	Loss: 4.5270
Training Epoch: 0 [5120/50048]	Loss: 4.5390
Training Epoch: 0 [5248/50048]	Loss: 4.4770
Training Epoch: 0 [5376/50048]	Loss: 4.5089
Training Epoch: 0 [5504/50048]	Loss: 4.5272
Training Epoch: 0 [5632/50048]	Loss: 4.5992
Training Epoch: 0 [5760/50048]	Loss: 4.4810
Training Epoch: 0 [5888/50048]	Loss: 4.4607
Training Epoch: 0 [6016/50048]	Loss: 4.4485
Training Epoch: 0 [6144/50048]	Loss: 4.3427
Training Epoch: 0 [6272/50048]	Loss: 4.5932
Training Epoch: 0 [6400/50048]	Loss: 4.3968
Profile done with power limit 175W
epoch 1 train time consumed: 11.39s
Validation Epoch: 0, Average loss: 0.0370, Accuracy: 0.0296
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 175000, 'lr': 0.0048, 'energy': 149.0205349970376, 'time': 8.582197853999787, 'accuracy': 0.029568829113924052, 'total_cost': 81512.82807800097}
[run job] Launching job with BS 128: and LR: 0.0048 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00480+pl150', 'ZEUS_COST_THRESH': '163025.65615600193', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0048', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0048', '--power_limit', '150']
[run job] cost_ub=163025.65615600193
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00480+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0048
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.6144
Training Epoch: 0 [384/50048]	Loss: 5.9814
Training Epoch: 0 [512/50048]	Loss: 5.3755
Training Epoch: 0 [640/50048]	Loss: 5.0848
Training Epoch: 0 [768/50048]	Loss: 5.0392
Training Epoch: 0 [896/50048]	Loss: 5.0476
Training Epoch: 0 [1024/50048]	Loss: 4.9313
Training Epoch: 0 [1152/50048]	Loss: 4.8192
Training Epoch: 0 [1280/50048]	Loss: 4.7793
Training Epoch: 0 [1408/50048]	Loss: 4.5564
Training Epoch: 0 [1536/50048]	Loss: 4.7469
Training Epoch: 0 [1664/50048]	Loss: 5.0210
Training Epoch: 0 [1792/50048]	Loss: 4.6317
Training Epoch: 0 [1920/50048]	Loss: 4.8707
Training Epoch: 0 [2048/50048]	Loss: 4.5363
Training Epoch: 0 [2176/50048]	Loss: 4.7772
Training Epoch: 0 [2304/50048]	Loss: 4.5791
Training Epoch: 0 [2432/50048]	Loss: 4.5873
Training Epoch: 0 [2560/50048]	Loss: 4.7007
Training Epoch: 0 [2688/50048]	Loss: 4.6262
Training Epoch: 0 [2816/50048]	Loss: 4.5639
Training Epoch: 0 [2944/50048]	Loss: 4.5427
Training Epoch: 0 [3072/50048]	Loss: 4.6572
Training Epoch: 0 [3200/50048]	Loss: 4.5799
Training Epoch: 0 [3328/50048]	Loss: 4.5252
Training Epoch: 0 [3456/50048]	Loss: 4.4918
Training Epoch: 0 [3584/50048]	Loss: 4.5853
Training Epoch: 0 [3712/50048]	Loss: 4.8439
Training Epoch: 0 [3840/50048]	Loss: 4.5869
Training Epoch: 0 [3968/50048]	Loss: 4.5198
Training Epoch: 0 [4096/50048]	Loss: 4.6591
Training Epoch: 0 [4224/50048]	Loss: 4.6062
Training Epoch: 0 [4352/50048]	Loss: 4.5325
Training Epoch: 0 [4480/50048]	Loss: 4.4730
Training Epoch: 0 [4608/50048]	Loss: 4.5319
Training Epoch: 0 [4736/50048]	Loss: 4.4888
Training Epoch: 0 [4864/50048]	Loss: 4.5653
Training Epoch: 0 [4992/50048]	Loss: 4.4511
Training Epoch: 0 [5120/50048]	Loss: 4.4732
Training Epoch: 0 [5248/50048]	Loss: 4.4860
Training Epoch: 0 [5376/50048]	Loss: 4.4611
Training Epoch: 0 [5504/50048]	Loss: 4.4910
Training Epoch: 0 [5632/50048]	Loss: 4.4894
Training Epoch: 0 [5760/50048]	Loss: 4.4536
Training Epoch: 0 [5888/50048]	Loss: 4.4604
Training Epoch: 0 [6016/50048]	Loss: 4.3855
Training Epoch: 0 [6144/50048]	Loss: 4.2778
Training Epoch: 0 [6272/50048]	Loss: 4.6109
Training Epoch: 0 [6400/50048]	Loss: 4.3688
Profile done with power limit 150W
epoch 1 train time consumed: 11.46s
Validation Epoch: 0, Average loss: 0.0382, Accuracy: 0.0201
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 150000, 'lr': 0.0048, 'energy': 147.41780777783632, 'time': 8.644098458999906, 'accuracy': 0.0200751582278481, 'total_cost': 120918.19784385287}
[run job] Launching job with BS 128: and LR: 0.0048 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00480+pl125', 'ZEUS_COST_THRESH': '163025.65615600193', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0048', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0048', '--power_limit', '125']
[run job] cost_ub=163025.65615600193
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00480+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0048
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.6144
Training Epoch: 0 [384/50048]	Loss: 5.9805
Training Epoch: 0 [512/50048]	Loss: 5.3626
Training Epoch: 0 [640/50048]	Loss: 5.0893
Training Epoch: 0 [768/50048]	Loss: 5.1177
Training Epoch: 0 [896/50048]	Loss: 5.0630
Training Epoch: 0 [1024/50048]	Loss: 4.9374
Training Epoch: 0 [1152/50048]	Loss: 4.7952
Training Epoch: 0 [1280/50048]	Loss: 4.8005
Training Epoch: 0 [1408/50048]	Loss: 4.5549
Training Epoch: 0 [1536/50048]	Loss: 4.7246
Training Epoch: 0 [1664/50048]	Loss: 4.9743
Training Epoch: 0 [1792/50048]	Loss: 4.6411
Training Epoch: 0 [1920/50048]	Loss: 4.7987
Training Epoch: 0 [2048/50048]	Loss: 4.5534
Training Epoch: 0 [2176/50048]	Loss: 4.7513
Training Epoch: 0 [2304/50048]	Loss: 4.5686
Training Epoch: 0 [2432/50048]	Loss: 4.5309
Training Epoch: 0 [2560/50048]	Loss: 4.5759
Training Epoch: 0 [2688/50048]	Loss: 4.5060
Training Epoch: 0 [2816/50048]	Loss: 4.5971
Training Epoch: 0 [2944/50048]	Loss: 4.5688
Training Epoch: 0 [3072/50048]	Loss: 4.6415
Training Epoch: 0 [3200/50048]	Loss: 4.5756
Training Epoch: 0 [3328/50048]	Loss: 4.5407
Training Epoch: 0 [3456/50048]	Loss: 4.5045
Training Epoch: 0 [3584/50048]	Loss: 4.5371
Training Epoch: 0 [3712/50048]	Loss: 4.9135
Training Epoch: 0 [3840/50048]	Loss: 4.6064
Training Epoch: 0 [3968/50048]	Loss: 4.5367
Training Epoch: 0 [4096/50048]	Loss: 4.6888
Training Epoch: 0 [4224/50048]	Loss: 4.5778
Training Epoch: 0 [4352/50048]	Loss: 4.5421
Training Epoch: 0 [4480/50048]	Loss: 4.4466
Training Epoch: 0 [4608/50048]	Loss: 4.4729
Training Epoch: 0 [4736/50048]	Loss: 4.3881
Training Epoch: 0 [4864/50048]	Loss: 4.4851
Training Epoch: 0 [4992/50048]	Loss: 4.4570
Training Epoch: 0 [5120/50048]	Loss: 4.4955
Training Epoch: 0 [5248/50048]	Loss: 4.4439
Training Epoch: 0 [5376/50048]	Loss: 4.4265
Training Epoch: 0 [5504/50048]	Loss: 4.4961
Training Epoch: 0 [5632/50048]	Loss: 4.4656
Training Epoch: 0 [5760/50048]	Loss: 4.4531
Training Epoch: 0 [5888/50048]	Loss: 4.3665
Training Epoch: 0 [6016/50048]	Loss: 4.3385
Training Epoch: 0 [6144/50048]	Loss: 4.2853
Training Epoch: 0 [6272/50048]	Loss: 4.5334
Training Epoch: 0 [6400/50048]	Loss: 4.3552
Profile done with power limit 125W
epoch 1 train time consumed: 12.77s
Validation Epoch: 0, Average loss: 0.0372, Accuracy: 0.0337
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 125000, 'lr': 0.0048, 'energy': 123.38598166462499, 'time': 9.740170862999548, 'accuracy': 0.03372231012658228, 'total_cost': 81030.07515613262}
[run job] Launching job with BS 128: and LR: 0.0048 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs128+lr0.00480+pl100', 'ZEUS_COST_THRESH': '162060.15031226524', 'ZEUS_BATCH_SIZE': '128', 'ZEUS_LEARNING_RATE': '0.0048', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '128', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0048', '--power_limit', '100']
[run job] cost_ub=162060.15031226524
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs128+lr0.00480+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0048
batch size arg: 128
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [128/50048]	Loss: 4.6535
Training Epoch: 0 [256/50048]	Loss: 5.6144
Training Epoch: 0 [384/50048]	Loss: 5.9812
Training Epoch: 0 [512/50048]	Loss: 5.3787
Training Epoch: 0 [640/50048]	Loss: 5.0979
Training Epoch: 0 [768/50048]	Loss: 5.1022
Training Epoch: 0 [896/50048]	Loss: 5.0620
Training Epoch: 0 [1024/50048]	Loss: 4.9430
Training Epoch: 0 [1152/50048]	Loss: 4.7916
Training Epoch: 0 [1280/50048]	Loss: 4.8008
Training Epoch: 0 [1408/50048]	Loss: 4.5622
Training Epoch: 0 [1536/50048]	Loss: 4.7554
Training Epoch: 0 [1664/50048]	Loss: 4.9989
Training Epoch: 0 [1792/50048]	Loss: 4.6441
Training Epoch: 0 [1920/50048]	Loss: 4.5768
Training Epoch: 0 [2048/50048]	Loss: 4.5443
Training Epoch: 0 [2176/50048]	Loss: 4.6619
Training Epoch: 0 [2304/50048]	Loss: 4.5980
Training Epoch: 0 [2432/50048]	Loss: 4.5920
Training Epoch: 0 [2560/50048]	Loss: 4.5491
Training Epoch: 0 [2688/50048]	Loss: 4.5091
Training Epoch: 0 [2816/50048]	Loss: 4.8324
Training Epoch: 0 [2944/50048]	Loss: 4.6095
Training Epoch: 0 [3072/50048]	Loss: 4.6366
Training Epoch: 0 [3200/50048]	Loss: 4.7664
Training Epoch: 0 [3328/50048]	Loss: 4.5607
Training Epoch: 0 [3456/50048]	Loss: 4.5102
Training Epoch: 0 [3584/50048]	Loss: 4.5278
Training Epoch: 0 [3712/50048]	Loss: 4.7521
Training Epoch: 0 [3840/50048]	Loss: 4.7049
Training Epoch: 0 [3968/50048]	Loss: 4.6790
Training Epoch: 0 [4096/50048]	Loss: 4.6083
Training Epoch: 0 [4224/50048]	Loss: 4.5841
Training Epoch: 0 [4352/50048]	Loss: 4.5970
Training Epoch: 0 [4480/50048]	Loss: 4.5230
Training Epoch: 0 [4608/50048]	Loss: 4.6323
Training Epoch: 0 [4736/50048]	Loss: 4.4649
Training Epoch: 0 [4864/50048]	Loss: 4.5764
Training Epoch: 0 [4992/50048]	Loss: 4.5282
Training Epoch: 0 [5120/50048]	Loss: 4.4950
Training Epoch: 0 [5248/50048]	Loss: 4.4623
Training Epoch: 0 [5376/50048]	Loss: 4.5293
Training Epoch: 0 [5504/50048]	Loss: 4.6477
Training Epoch: 0 [5632/50048]	Loss: 4.6453
Training Epoch: 0 [5760/50048]	Loss: 4.4603
Training Epoch: 0 [5888/50048]	Loss: 4.4598
Training Epoch: 0 [6016/50048]	Loss: 4.5009
Training Epoch: 0 [6144/50048]	Loss: 4.4372
Training Epoch: 0 [6272/50048]	Loss: 4.5876
Training Epoch: 0 [6400/50048]	Loss: 4.3989
Profile done with power limit 100W
epoch 1 train time consumed: 27.12s
Validation Epoch: 0, Average loss: 0.0360, Accuracy: 0.0219
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 128, 'pl': 100000, 'lr': 0.0048, 'energy': 99.17341922530359, 'time': 21.13086388800002, 'accuracy': 0.02185522151898734, 'total_cost': 270750.3269318511}

[Power Profiler] with batch size 256 and learning rate 0.004525483399593905
[run job] Launching job with BS 256: and LR: 0.004525483399593905 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00453+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.004525483399593905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004525483399593905', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00453+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.004525483399593905
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.5787
Training Epoch: 0 [768/50176]	Loss: 5.3842
Training Epoch: 0 [1024/50176]	Loss: 5.1329
Training Epoch: 0 [1280/50176]	Loss: 4.9732
Training Epoch: 0 [1536/50176]	Loss: 4.9497
Training Epoch: 0 [1792/50176]	Loss: 4.7108
Training Epoch: 0 [2048/50176]	Loss: 4.6200
Training Epoch: 0 [2304/50176]	Loss: 4.7953
Training Epoch: 0 [2560/50176]	Loss: 4.7023
Training Epoch: 0 [2816/50176]	Loss: 4.6599
Training Epoch: 0 [3072/50176]	Loss: 4.6427
Training Epoch: 0 [3328/50176]	Loss: 4.6179
Training Epoch: 0 [3584/50176]	Loss: 4.6210
Training Epoch: 0 [3840/50176]	Loss: 4.6809
Training Epoch: 0 [4096/50176]	Loss: 4.6952
Training Epoch: 0 [4352/50176]	Loss: 4.6342
Training Epoch: 0 [4608/50176]	Loss: 4.5061
Training Epoch: 0 [4864/50176]	Loss: 4.5794
Training Epoch: 0 [5120/50176]	Loss: 4.5210
Training Epoch: 0 [5376/50176]	Loss: 4.5114
Training Epoch: 0 [5632/50176]	Loss: 4.6488
Training Epoch: 0 [5888/50176]	Loss: 4.4974
Training Epoch: 0 [6144/50176]	Loss: 4.4517
Training Epoch: 0 [6400/50176]	Loss: 4.5783
Training Epoch: 0 [6656/50176]	Loss: 4.5511
Training Epoch: 0 [6912/50176]	Loss: 4.4458
Training Epoch: 0 [7168/50176]	Loss: 4.4935
Training Epoch: 0 [7424/50176]	Loss: 4.4198
Training Epoch: 0 [7680/50176]	Loss: 4.3774
Training Epoch: 0 [7936/50176]	Loss: 4.4053
Training Epoch: 0 [8192/50176]	Loss: 4.3730
Training Epoch: 0 [8448/50176]	Loss: 4.4152
Training Epoch: 0 [8704/50176]	Loss: 4.3674
Training Epoch: 0 [8960/50176]	Loss: 4.3705
Training Epoch: 0 [9216/50176]	Loss: 4.3331
Training Epoch: 0 [9472/50176]	Loss: 4.2989
Training Epoch: 0 [9728/50176]	Loss: 4.3101
Training Epoch: 0 [9984/50176]	Loss: 4.3045
Training Epoch: 0 [10240/50176]	Loss: 4.3410
Training Epoch: 0 [10496/50176]	Loss: 4.2852
Training Epoch: 0 [10752/50176]	Loss: 4.1849
Training Epoch: 0 [11008/50176]	Loss: 4.1678
Training Epoch: 0 [11264/50176]	Loss: 4.2912
Training Epoch: 0 [11520/50176]	Loss: 4.1731
Training Epoch: 0 [11776/50176]	Loss: 4.2290
Training Epoch: 0 [12032/50176]	Loss: 4.2724
Training Epoch: 0 [12288/50176]	Loss: 4.1200
Training Epoch: 0 [12544/50176]	Loss: 4.1500
Training Epoch: 0 [12800/50176]	Loss: 4.1493
Profile done with power limit 175W
epoch 1 train time consumed: 12.75s
Validation Epoch: 0, Average loss: 0.0186, Accuracy: 0.0362
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 175000, 'lr': 0.004525483399593905, 'energy': 155.91938687912497, 'time': 9.552171844999975, 'accuracy': 0.03623046875, 'total_cost': 147675.17230652165}
[run job] Launching job with BS 256: and LR: 0.004525483399593905 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00453+pl150', 'ZEUS_COST_THRESH': '295350.3446130433', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.004525483399593905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004525483399593905', '--power_limit', '150']
[run job] cost_ub=295350.3446130433
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00453+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.004525483399593905
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.5787
Training Epoch: 0 [768/50176]	Loss: 5.3850
Training Epoch: 0 [1024/50176]	Loss: 5.1332
Training Epoch: 0 [1280/50176]	Loss: 4.9861
Training Epoch: 0 [1536/50176]	Loss: 4.9609
Training Epoch: 0 [1792/50176]	Loss: 4.7179
Training Epoch: 0 [2048/50176]	Loss: 4.6129
Training Epoch: 0 [2304/50176]	Loss: 4.7758
Training Epoch: 0 [2560/50176]	Loss: 4.6909
Training Epoch: 0 [2816/50176]	Loss: 4.6912
Training Epoch: 0 [3072/50176]	Loss: 4.6372
Training Epoch: 0 [3328/50176]	Loss: 4.6129
Training Epoch: 0 [3584/50176]	Loss: 4.6488
Training Epoch: 0 [3840/50176]	Loss: 4.7079
Training Epoch: 0 [4096/50176]	Loss: 4.7125
Training Epoch: 0 [4352/50176]	Loss: 4.6227
Training Epoch: 0 [4608/50176]	Loss: 4.4959
Training Epoch: 0 [4864/50176]	Loss: 4.5424
Training Epoch: 0 [5120/50176]	Loss: 4.5237
Training Epoch: 0 [5376/50176]	Loss: 4.4784
Training Epoch: 0 [5632/50176]	Loss: 4.6361
Training Epoch: 0 [5888/50176]	Loss: 4.4445
Training Epoch: 0 [6144/50176]	Loss: 4.4022
Training Epoch: 0 [6400/50176]	Loss: 4.5273
Training Epoch: 0 [6656/50176]	Loss: 4.5312
Training Epoch: 0 [6912/50176]	Loss: 4.4167
Training Epoch: 0 [7168/50176]	Loss: 4.4810
Training Epoch: 0 [7424/50176]	Loss: 4.4049
Training Epoch: 0 [7680/50176]	Loss: 4.3373
Training Epoch: 0 [7936/50176]	Loss: 4.3997
Training Epoch: 0 [8192/50176]	Loss: 4.2998
Training Epoch: 0 [8448/50176]	Loss: 4.3535
Training Epoch: 0 [8704/50176]	Loss: 4.3267
Training Epoch: 0 [8960/50176]	Loss: 4.3012
Training Epoch: 0 [9216/50176]	Loss: 4.3173
Training Epoch: 0 [9472/50176]	Loss: 4.2626
Training Epoch: 0 [9728/50176]	Loss: 4.3027
Training Epoch: 0 [9984/50176]	Loss: 4.2621
Training Epoch: 0 [10240/50176]	Loss: 4.3349
Training Epoch: 0 [10496/50176]	Loss: 4.2182
Training Epoch: 0 [10752/50176]	Loss: 4.1791
Training Epoch: 0 [11008/50176]	Loss: 4.2041
Training Epoch: 0 [11264/50176]	Loss: 4.3139
Training Epoch: 0 [11520/50176]	Loss: 4.2332
Training Epoch: 0 [11776/50176]	Loss: 4.2720
Training Epoch: 0 [12032/50176]	Loss: 4.2894
Training Epoch: 0 [12288/50176]	Loss: 4.2021
Training Epoch: 0 [12544/50176]	Loss: 4.1771
Training Epoch: 0 [12800/50176]	Loss: 4.1464
Profile done with power limit 150W
epoch 1 train time consumed: 13.06s
Validation Epoch: 0, Average loss: 0.0175, Accuracy: 0.0429
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 150000, 'lr': 0.004525483399593905, 'energy': 147.4030785013206, 'time': 9.83002341700012, 'accuracy': 0.04287109375, 'total_cost': 128392.00194245356}
[run job] Launching job with BS 256: and LR: 0.004525483399593905 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00453+pl125', 'ZEUS_COST_THRESH': '256784.0038849071', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.004525483399593905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004525483399593905', '--power_limit', '125']
[run job] cost_ub=256784.0038849071
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00453+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.004525483399593905
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.5787
Training Epoch: 0 [768/50176]	Loss: 5.3853
Training Epoch: 0 [1024/50176]	Loss: 5.1341
Training Epoch: 0 [1280/50176]	Loss: 4.9834
Training Epoch: 0 [1536/50176]	Loss: 4.9785
Training Epoch: 0 [1792/50176]	Loss: 4.7186
Training Epoch: 0 [2048/50176]	Loss: 4.6224
Training Epoch: 0 [2304/50176]	Loss: 4.7864
Training Epoch: 0 [2560/50176]	Loss: 4.6739
Training Epoch: 0 [2816/50176]	Loss: 4.6636
Training Epoch: 0 [3072/50176]	Loss: 4.6493
Training Epoch: 0 [3328/50176]	Loss: 4.6115
Training Epoch: 0 [3584/50176]	Loss: 4.5682
Training Epoch: 0 [3840/50176]	Loss: 4.7262
Training Epoch: 0 [4096/50176]	Loss: 4.7035
Training Epoch: 0 [4352/50176]	Loss: 4.6429
Training Epoch: 0 [4608/50176]	Loss: 4.5111
Training Epoch: 0 [4864/50176]	Loss: 4.5382
Training Epoch: 0 [5120/50176]	Loss: 4.5963
Training Epoch: 0 [5376/50176]	Loss: 4.5119
Training Epoch: 0 [5632/50176]	Loss: 4.6233
Training Epoch: 0 [5888/50176]	Loss: 4.4683
Training Epoch: 0 [6144/50176]	Loss: 4.4302
Training Epoch: 0 [6400/50176]	Loss: 4.5884
Training Epoch: 0 [6656/50176]	Loss: 4.5207
Training Epoch: 0 [6912/50176]	Loss: 4.4395
Training Epoch: 0 [7168/50176]	Loss: 4.4784
Training Epoch: 0 [7424/50176]	Loss: 4.4134
Training Epoch: 0 [7680/50176]	Loss: 4.3693
Training Epoch: 0 [7936/50176]	Loss: 4.4279
Training Epoch: 0 [8192/50176]	Loss: 4.3653
Training Epoch: 0 [8448/50176]	Loss: 4.4223
Training Epoch: 0 [8704/50176]	Loss: 4.3351
Training Epoch: 0 [8960/50176]	Loss: 4.3684
Training Epoch: 0 [9216/50176]	Loss: 4.3350
Training Epoch: 0 [9472/50176]	Loss: 4.3607
Training Epoch: 0 [9728/50176]	Loss: 4.3750
Training Epoch: 0 [9984/50176]	Loss: 4.3349
Training Epoch: 0 [10240/50176]	Loss: 4.4427
Training Epoch: 0 [10496/50176]	Loss: 4.3401
Training Epoch: 0 [10752/50176]	Loss: 4.2962
Training Epoch: 0 [11008/50176]	Loss: 4.2900
Training Epoch: 0 [11264/50176]	Loss: 4.3080
Training Epoch: 0 [11520/50176]	Loss: 4.3001
Training Epoch: 0 [11776/50176]	Loss: 4.3032
Training Epoch: 0 [12032/50176]	Loss: 4.2713
Training Epoch: 0 [12288/50176]	Loss: 4.2580
Training Epoch: 0 [12544/50176]	Loss: 4.1999
Training Epoch: 0 [12800/50176]	Loss: 4.1855
Profile done with power limit 125W
epoch 1 train time consumed: 14.83s
Validation Epoch: 0, Average loss: 0.0168, Accuracy: 0.0405
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 125000, 'lr': 0.004525483399593905, 'energy': 123.29927210807593, 'time': 11.289662802000748, 'accuracy': 0.04052734375, 'total_cost': 155839.52485739498}
[run job] Launching job with BS 256: and LR: 0.004525483399593905 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00453+pl100', 'ZEUS_COST_THRESH': '256784.0038849071', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.004525483399593905', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.004525483399593905', '--power_limit', '100']
[run job] cost_ub=256784.0038849071
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00453+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.004525483399593905
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.5787
Training Epoch: 0 [768/50176]	Loss: 5.3852
Training Epoch: 0 [1024/50176]	Loss: 5.1467
Training Epoch: 0 [1280/50176]	Loss: 4.9709
Training Epoch: 0 [1536/50176]	Loss: 4.9607
Training Epoch: 0 [1792/50176]	Loss: 4.7120
Training Epoch: 0 [2048/50176]	Loss: 4.6132
Training Epoch: 0 [2304/50176]	Loss: 4.7834
Training Epoch: 0 [2560/50176]	Loss: 4.6944
Training Epoch: 0 [2816/50176]	Loss: 4.6664
Training Epoch: 0 [3072/50176]	Loss: 4.6571
Training Epoch: 0 [3328/50176]	Loss: 4.6151
Training Epoch: 0 [3584/50176]	Loss: 4.5953
Training Epoch: 0 [3840/50176]	Loss: 4.6801
Training Epoch: 0 [4096/50176]	Loss: 4.7037
Training Epoch: 0 [4352/50176]	Loss: 4.6073
Training Epoch: 0 [4608/50176]	Loss: 4.5083
Training Epoch: 0 [4864/50176]	Loss: 4.5445
Training Epoch: 0 [5120/50176]	Loss: 4.5509
Training Epoch: 0 [5376/50176]	Loss: 4.4935
Training Epoch: 0 [5632/50176]	Loss: 4.6433
Training Epoch: 0 [5888/50176]	Loss: 4.4530
Training Epoch: 0 [6144/50176]	Loss: 4.3602
Training Epoch: 0 [6400/50176]	Loss: 4.5188
Training Epoch: 0 [6656/50176]	Loss: 4.4875
Training Epoch: 0 [6912/50176]	Loss: 4.4630
Training Epoch: 0 [7168/50176]	Loss: 4.5261
Training Epoch: 0 [7424/50176]	Loss: 4.4269
Training Epoch: 0 [7680/50176]	Loss: 4.3555
Training Epoch: 0 [7936/50176]	Loss: 4.3917
Training Epoch: 0 [8192/50176]	Loss: 4.3116
Training Epoch: 0 [8448/50176]	Loss: 4.3857
Training Epoch: 0 [8704/50176]	Loss: 4.3254
Training Epoch: 0 [8960/50176]	Loss: 4.3471
Training Epoch: 0 [9216/50176]	Loss: 4.3108
Training Epoch: 0 [9472/50176]	Loss: 4.3164
Training Epoch: 0 [9728/50176]	Loss: 4.3051
Training Epoch: 0 [9984/50176]	Loss: 4.2669
Training Epoch: 0 [10240/50176]	Loss: 4.3230
Training Epoch: 0 [10496/50176]	Loss: 4.2517
Training Epoch: 0 [10752/50176]	Loss: 4.1816
Training Epoch: 0 [11008/50176]	Loss: 4.1740
Training Epoch: 0 [11264/50176]	Loss: 4.3176
Training Epoch: 0 [11520/50176]	Loss: 4.1734
Training Epoch: 0 [11776/50176]	Loss: 4.2369
Training Epoch: 0 [12032/50176]	Loss: 4.2698
Training Epoch: 0 [12288/50176]	Loss: 4.1332
Training Epoch: 0 [12544/50176]	Loss: 4.1735
Training Epoch: 0 [12800/50176]	Loss: 4.1224
Profile done with power limit 100W
epoch 1 train time consumed: 37.29s
Validation Epoch: 0, Average loss: 0.0183, Accuracy: 0.0353
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 100000, 'lr': 0.004525483399593905, 'energy': 103.70600854399089, 'time': 29.120980145999965, 'accuracy': 0.03525390625, 'total_cost': 461332.5583937365}

[Power Profiler] with batch size 256 and learning rate 0.005656854249492381
[run job] Launching job with BS 256: and LR: 0.005656854249492381 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00566+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.005656854249492381', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.005656854249492381', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00566+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.005656854249492381
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.9997
Training Epoch: 0 [768/50176]	Loss: 5.7285
Training Epoch: 0 [1024/50176]	Loss: 5.1536
Training Epoch: 0 [1280/50176]	Loss: 4.8560
Training Epoch: 0 [1536/50176]	Loss: 4.7822
Training Epoch: 0 [1792/50176]	Loss: 4.6408
Training Epoch: 0 [2048/50176]	Loss: 4.6415
Training Epoch: 0 [2304/50176]	Loss: 4.7630
Training Epoch: 0 [2560/50176]	Loss: 4.6495
Training Epoch: 0 [2816/50176]	Loss: 4.6384
Training Epoch: 0 [3072/50176]	Loss: 4.6469
Training Epoch: 0 [3328/50176]	Loss: 4.5692
Training Epoch: 0 [3584/50176]	Loss: 4.5897
Training Epoch: 0 [3840/50176]	Loss: 4.5972
Training Epoch: 0 [4096/50176]	Loss: 4.6173
Training Epoch: 0 [4352/50176]	Loss: 4.6234
Training Epoch: 0 [4608/50176]	Loss: 4.5430
Training Epoch: 0 [4864/50176]	Loss: 4.5385
Training Epoch: 0 [5120/50176]	Loss: 4.7509
Training Epoch: 0 [5376/50176]	Loss: 4.5511
Training Epoch: 0 [5632/50176]	Loss: 4.6401
Training Epoch: 0 [5888/50176]	Loss: 4.5780
Training Epoch: 0 [6144/50176]	Loss: 4.5335
Training Epoch: 0 [6400/50176]	Loss: 4.6640
Training Epoch: 0 [6656/50176]	Loss: 4.6945
Training Epoch: 0 [6912/50176]	Loss: 4.4899
Training Epoch: 0 [7168/50176]	Loss: 4.5261
Training Epoch: 0 [7424/50176]	Loss: 4.4906
Training Epoch: 0 [7680/50176]	Loss: 4.4701
Training Epoch: 0 [7936/50176]	Loss: 4.4476
Training Epoch: 0 [8192/50176]	Loss: 4.5204
Training Epoch: 0 [8448/50176]	Loss: 4.4783
Training Epoch: 0 [8704/50176]	Loss: 4.4286
Training Epoch: 0 [8960/50176]	Loss: 4.4122
Training Epoch: 0 [9216/50176]	Loss: 4.4053
Training Epoch: 0 [9472/50176]	Loss: 4.4226
Training Epoch: 0 [9728/50176]	Loss: 4.3560
Training Epoch: 0 [9984/50176]	Loss: 4.3860
Training Epoch: 0 [10240/50176]	Loss: 4.4425
Training Epoch: 0 [10496/50176]	Loss: 4.3572
Training Epoch: 0 [10752/50176]	Loss: 4.3456
Training Epoch: 0 [11008/50176]	Loss: 4.3074
Training Epoch: 0 [11264/50176]	Loss: 4.3686
Training Epoch: 0 [11520/50176]	Loss: 4.3336
Training Epoch: 0 [11776/50176]	Loss: 4.4298
Training Epoch: 0 [12032/50176]	Loss: 4.3840
Training Epoch: 0 [12288/50176]	Loss: 4.3505
Training Epoch: 0 [12544/50176]	Loss: 4.2782
Training Epoch: 0 [12800/50176]	Loss: 4.3224
Profile done with power limit 175W
epoch 1 train time consumed: 12.68s
Validation Epoch: 0, Average loss: 0.0180, Accuracy: 0.0337
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 175000, 'lr': 0.005656854249492381, 'energy': 155.90059069301043, 'time': 9.537220911999611, 'accuracy': 0.03369140625, 'total_cost': 158556.61006591207}
[run job] Launching job with BS 256: and LR: 0.005656854249492381 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00566+pl150', 'ZEUS_COST_THRESH': '317113.22013182414', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.005656854249492381', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.005656854249492381', '--power_limit', '150']
[run job] cost_ub=317113.22013182414
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00566+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.005656854249492381
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.9997
Training Epoch: 0 [768/50176]	Loss: 5.7261
Training Epoch: 0 [1024/50176]	Loss: 5.1513
Training Epoch: 0 [1280/50176]	Loss: 4.8573
Training Epoch: 0 [1536/50176]	Loss: 4.7881
Training Epoch: 0 [1792/50176]	Loss: 4.6433
Training Epoch: 0 [2048/50176]	Loss: 4.6428
Training Epoch: 0 [2304/50176]	Loss: 4.7681
Training Epoch: 0 [2560/50176]	Loss: 4.6551
Training Epoch: 0 [2816/50176]	Loss: 4.6381
Training Epoch: 0 [3072/50176]	Loss: 4.6476
Training Epoch: 0 [3328/50176]	Loss: 4.5718
Training Epoch: 0 [3584/50176]	Loss: 4.6134
Training Epoch: 0 [3840/50176]	Loss: 4.6174
Training Epoch: 0 [4096/50176]	Loss: 4.6395
Training Epoch: 0 [4352/50176]	Loss: 4.6084
Training Epoch: 0 [4608/50176]	Loss: 4.5488
Training Epoch: 0 [4864/50176]	Loss: 4.5417
Training Epoch: 0 [5120/50176]	Loss: 4.5996
Training Epoch: 0 [5376/50176]	Loss: 4.5398
Training Epoch: 0 [5632/50176]	Loss: 4.6263
Training Epoch: 0 [5888/50176]	Loss: 4.5476
Training Epoch: 0 [6144/50176]	Loss: 4.5719
Training Epoch: 0 [6400/50176]	Loss: 4.6312
Training Epoch: 0 [6656/50176]	Loss: 4.6974
Training Epoch: 0 [6912/50176]	Loss: 4.4911
Training Epoch: 0 [7168/50176]	Loss: 4.5548
Training Epoch: 0 [7424/50176]	Loss: 4.4851
Training Epoch: 0 [7680/50176]	Loss: 4.4935
Training Epoch: 0 [7936/50176]	Loss: 4.5361
Training Epoch: 0 [8192/50176]	Loss: 4.5361
Training Epoch: 0 [8448/50176]	Loss: 4.5083
Training Epoch: 0 [8704/50176]	Loss: 4.4386
Training Epoch: 0 [8960/50176]	Loss: 4.4281
Training Epoch: 0 [9216/50176]	Loss: 4.4239
Training Epoch: 0 [9472/50176]	Loss: 4.4567
Training Epoch: 0 [9728/50176]	Loss: 4.4065
Training Epoch: 0 [9984/50176]	Loss: 4.4614
Training Epoch: 0 [10240/50176]	Loss: 4.3952
Training Epoch: 0 [10496/50176]	Loss: 4.3755
Training Epoch: 0 [10752/50176]	Loss: 4.4197
Training Epoch: 0 [11008/50176]	Loss: 4.3762
Training Epoch: 0 [11264/50176]	Loss: 4.4761
Training Epoch: 0 [11520/50176]	Loss: 4.3525
Training Epoch: 0 [11776/50176]	Loss: 4.3854
Training Epoch: 0 [12032/50176]	Loss: 4.3669
Training Epoch: 0 [12288/50176]	Loss: 4.4674
Training Epoch: 0 [12544/50176]	Loss: 4.2699
Training Epoch: 0 [12800/50176]	Loss: 4.3565
Profile done with power limit 150W
epoch 1 train time consumed: 13.11s
Validation Epoch: 0, Average loss: 0.0207, Accuracy: 0.0266
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 150000, 'lr': 0.005656854249492381, 'energy': 145.82195437352894, 'time': 9.866974491000292, 'accuracy': 0.0265625, 'total_cost': 207989.60553421278}
[run job] Launching job with BS 256: and LR: 0.005656854249492381 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00566+pl125', 'ZEUS_COST_THRESH': '317113.22013182414', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.005656854249492381', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.005656854249492381', '--power_limit', '125']
[run job] cost_ub=317113.22013182414
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00566+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.005656854249492381
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.9997
Training Epoch: 0 [768/50176]	Loss: 5.7267
Training Epoch: 0 [1024/50176]	Loss: 5.1730
Training Epoch: 0 [1280/50176]	Loss: 4.8589
Training Epoch: 0 [1536/50176]	Loss: 4.7881
Training Epoch: 0 [1792/50176]	Loss: 4.6421
Training Epoch: 0 [2048/50176]	Loss: 4.6417
Training Epoch: 0 [2304/50176]	Loss: 4.7640
Training Epoch: 0 [2560/50176]	Loss: 4.6612
Training Epoch: 0 [2816/50176]	Loss: 4.6415
Training Epoch: 0 [3072/50176]	Loss: 4.6473
Training Epoch: 0 [3328/50176]	Loss: 4.5685
Training Epoch: 0 [3584/50176]	Loss: 4.6342
Training Epoch: 0 [3840/50176]	Loss: 4.6625
Training Epoch: 0 [4096/50176]	Loss: 4.6168
Training Epoch: 0 [4352/50176]	Loss: 4.6044
Training Epoch: 0 [4608/50176]	Loss: 4.5790
Training Epoch: 0 [4864/50176]	Loss: 4.5439
Training Epoch: 0 [5120/50176]	Loss: 4.5732
Training Epoch: 0 [5376/50176]	Loss: 4.5412
Training Epoch: 0 [5632/50176]	Loss: 4.5895
Training Epoch: 0 [5888/50176]	Loss: 4.6460
Training Epoch: 0 [6144/50176]	Loss: 4.5988
Training Epoch: 0 [6400/50176]	Loss: 4.6040
Training Epoch: 0 [6656/50176]	Loss: 4.6258
Training Epoch: 0 [6912/50176]	Loss: 4.4851
Training Epoch: 0 [7168/50176]	Loss: 4.5189
Training Epoch: 0 [7424/50176]	Loss: 4.4992
Training Epoch: 0 [7680/50176]	Loss: 4.4720
Training Epoch: 0 [7936/50176]	Loss: 4.4659
Training Epoch: 0 [8192/50176]	Loss: 4.5048
Training Epoch: 0 [8448/50176]	Loss: 4.4610
Training Epoch: 0 [8704/50176]	Loss: 4.4346
Training Epoch: 0 [8960/50176]	Loss: 4.4030
Training Epoch: 0 [9216/50176]	Loss: 4.4069
Training Epoch: 0 [9472/50176]	Loss: 4.4457
Training Epoch: 0 [9728/50176]	Loss: 4.3769
Training Epoch: 0 [9984/50176]	Loss: 4.4379
Training Epoch: 0 [10240/50176]	Loss: 4.4263
Training Epoch: 0 [10496/50176]	Loss: 4.3736
Training Epoch: 0 [10752/50176]	Loss: 4.3843
Training Epoch: 0 [11008/50176]	Loss: 4.3441
Training Epoch: 0 [11264/50176]	Loss: 4.3626
Training Epoch: 0 [11520/50176]	Loss: 4.3356
Training Epoch: 0 [11776/50176]	Loss: 4.3821
Training Epoch: 0 [12032/50176]	Loss: 4.3265
Training Epoch: 0 [12288/50176]	Loss: 4.3624
Training Epoch: 0 [12544/50176]	Loss: 4.2532
Training Epoch: 0 [12800/50176]	Loss: 4.3400
Profile done with power limit 125W
epoch 1 train time consumed: 14.75s
Validation Epoch: 0, Average loss: 0.0222, Accuracy: 0.0304
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 125000, 'lr': 0.005656854249492381, 'energy': 123.36524310632723, 'time': 11.229428693000045, 'accuracy': 0.03037109375, 'total_cost': 206846.6047377661}
[run job] Launching job with BS 256: and LR: 0.005656854249492381 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00566+pl100', 'ZEUS_COST_THRESH': '317113.22013182414', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.005656854249492381', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.005656854249492381', '--power_limit', '100']
[run job] cost_ub=317113.22013182414
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00566+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.005656854249492381
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 5.9997
Training Epoch: 0 [768/50176]	Loss: 5.7252
Training Epoch: 0 [1024/50176]	Loss: 5.1633
Training Epoch: 0 [1280/50176]	Loss: 4.8556
Training Epoch: 0 [1536/50176]	Loss: 4.7848
Training Epoch: 0 [1792/50176]	Loss: 4.6417
Training Epoch: 0 [2048/50176]	Loss: 4.6353
Training Epoch: 0 [2304/50176]	Loss: 4.7728
Training Epoch: 0 [2560/50176]	Loss: 4.6693
Training Epoch: 0 [2816/50176]	Loss: 4.6377
Training Epoch: 0 [3072/50176]	Loss: 4.6625
Training Epoch: 0 [3328/50176]	Loss: 4.5708
Training Epoch: 0 [3584/50176]	Loss: 4.6085
Training Epoch: 0 [3840/50176]	Loss: 4.6724
Training Epoch: 0 [4096/50176]	Loss: 4.6094
Training Epoch: 0 [4352/50176]	Loss: 4.6006
Training Epoch: 0 [4608/50176]	Loss: 4.6653
Training Epoch: 0 [4864/50176]	Loss: 4.5300
Training Epoch: 0 [5120/50176]	Loss: 4.5425
Training Epoch: 0 [5376/50176]	Loss: 4.5316
Training Epoch: 0 [5632/50176]	Loss: 4.6800
Training Epoch: 0 [5888/50176]	Loss: 4.5896
Training Epoch: 0 [6144/50176]	Loss: 4.5412
Training Epoch: 0 [6400/50176]	Loss: 4.5594
Training Epoch: 0 [6656/50176]	Loss: 4.5981
Training Epoch: 0 [6912/50176]	Loss: 4.4734
Training Epoch: 0 [7168/50176]	Loss: 4.5824
Training Epoch: 0 [7424/50176]	Loss: 4.5279
Training Epoch: 0 [7680/50176]	Loss: 4.4685
Training Epoch: 0 [7936/50176]	Loss: 4.4632
Training Epoch: 0 [8192/50176]	Loss: 4.4864
Training Epoch: 0 [8448/50176]	Loss: 4.4802
Training Epoch: 0 [8704/50176]	Loss: 4.4089
Training Epoch: 0 [8960/50176]	Loss: 4.4116
Training Epoch: 0 [9216/50176]	Loss: 4.4179
Training Epoch: 0 [9472/50176]	Loss: 4.4359
Training Epoch: 0 [9728/50176]	Loss: 4.3738
Training Epoch: 0 [9984/50176]	Loss: 4.3837
Training Epoch: 0 [10240/50176]	Loss: 4.3702
Training Epoch: 0 [10496/50176]	Loss: 4.3044
Training Epoch: 0 [10752/50176]	Loss: 4.3001
Training Epoch: 0 [11008/50176]	Loss: 4.2654
Training Epoch: 0 [11264/50176]	Loss: 4.4031
Training Epoch: 0 [11520/50176]	Loss: 4.3065
Training Epoch: 0 [11776/50176]	Loss: 4.4132
Training Epoch: 0 [12032/50176]	Loss: 4.3240
Training Epoch: 0 [12288/50176]	Loss: 4.3050
Training Epoch: 0 [12544/50176]	Loss: 4.3046
Training Epoch: 0 [12800/50176]	Loss: 4.3104
Profile done with power limit 100W
epoch 1 train time consumed: 36.98s
Validation Epoch: 0, Average loss: 0.0194, Accuracy: 0.0295
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 100000, 'lr': 0.005656854249492381, 'energy': 103.64135022267682, 'time': 29.25982000699969, 'accuracy': 0.0294921875, 'total_cost': 554087.2177574108}

[Power Profiler] with batch size 256 and learning rate 0.006788225099390857
[run job] Launching job with BS 256: and LR: 0.006788225099390857 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00679+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.006788225099390857', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006788225099390857', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00679+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.006788225099390857
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 6.4519
Training Epoch: 0 [768/50176]	Loss: 6.0623
Training Epoch: 0 [1024/50176]	Loss: 5.2398
Training Epoch: 0 [1280/50176]	Loss: 4.8773
Training Epoch: 0 [1536/50176]	Loss: 4.8122
Training Epoch: 0 [1792/50176]	Loss: 4.6243
Training Epoch: 0 [2048/50176]	Loss: 4.6101
Training Epoch: 0 [2304/50176]	Loss: 4.7146
Training Epoch: 0 [2560/50176]	Loss: 4.6393
Training Epoch: 0 [2816/50176]	Loss: 4.5956
Training Epoch: 0 [3072/50176]	Loss: 4.7040
Training Epoch: 0 [3328/50176]	Loss: 4.5615
Training Epoch: 0 [3584/50176]	Loss: 4.6355
Training Epoch: 0 [3840/50176]	Loss: 4.7994
Training Epoch: 0 [4096/50176]	Loss: 4.6091
Training Epoch: 0 [4352/50176]	Loss: 4.5688
Training Epoch: 0 [4608/50176]	Loss: 4.6023
Training Epoch: 0 [4864/50176]	Loss: 4.4976
Training Epoch: 0 [5120/50176]	Loss: 4.5106
Training Epoch: 0 [5376/50176]	Loss: 4.5028
Training Epoch: 0 [5632/50176]	Loss: 4.5605
Training Epoch: 0 [5888/50176]	Loss: 4.4900
Training Epoch: 0 [6144/50176]	Loss: 4.5150
Training Epoch: 0 [6400/50176]	Loss: 4.6961
Training Epoch: 0 [6656/50176]	Loss: 4.6969
Training Epoch: 0 [6912/50176]	Loss: 4.4402
Training Epoch: 0 [7168/50176]	Loss: 4.4984
Training Epoch: 0 [7424/50176]	Loss: 4.4990
Training Epoch: 0 [7680/50176]	Loss: 4.4899
Training Epoch: 0 [7936/50176]	Loss: 4.4958
Training Epoch: 0 [8192/50176]	Loss: 4.4751
Training Epoch: 0 [8448/50176]	Loss: 4.4810
Training Epoch: 0 [8704/50176]	Loss: 4.4647
Training Epoch: 0 [8960/50176]	Loss: 4.4210
Training Epoch: 0 [9216/50176]	Loss: 4.3753
Training Epoch: 0 [9472/50176]	Loss: 4.4054
Training Epoch: 0 [9728/50176]	Loss: 4.3922
Training Epoch: 0 [9984/50176]	Loss: 4.3880
Training Epoch: 0 [10240/50176]	Loss: 4.4240
Training Epoch: 0 [10496/50176]	Loss: 4.3761
Training Epoch: 0 [10752/50176]	Loss: 4.3414
Training Epoch: 0 [11008/50176]	Loss: 4.3144
Training Epoch: 0 [11264/50176]	Loss: 4.3198
Training Epoch: 0 [11520/50176]	Loss: 4.3066
Training Epoch: 0 [11776/50176]	Loss: 4.4030
Training Epoch: 0 [12032/50176]	Loss: 4.4038
Training Epoch: 0 [12288/50176]	Loss: 4.3520
Training Epoch: 0 [12544/50176]	Loss: 4.3127
Training Epoch: 0 [12800/50176]	Loss: 4.3237
Profile done with power limit 175W
epoch 1 train time consumed: 12.72s
Validation Epoch: 0, Average loss: 0.0191, Accuracy: 0.0319
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 175000, 'lr': 0.006788225099390857, 'energy': 155.47073581725616, 'time': 9.557385568000427, 'accuracy': 0.03193359375, 'total_cost': 167635.15484818222}
[run job] Launching job with BS 256: and LR: 0.006788225099390857 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00679+pl150', 'ZEUS_COST_THRESH': '335270.30969636445', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.006788225099390857', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006788225099390857', '--power_limit', '150']
[run job] cost_ub=335270.30969636445
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00679+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.006788225099390857
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 6.4519
Training Epoch: 0 [768/50176]	Loss: 6.0632
Training Epoch: 0 [1024/50176]	Loss: 5.2412
Training Epoch: 0 [1280/50176]	Loss: 4.8770
Training Epoch: 0 [1536/50176]	Loss: 4.8118
Training Epoch: 0 [1792/50176]	Loss: 4.6236
Training Epoch: 0 [2048/50176]	Loss: 4.6167
Training Epoch: 0 [2304/50176]	Loss: 4.7234
Training Epoch: 0 [2560/50176]	Loss: 4.6333
Training Epoch: 0 [2816/50176]	Loss: 4.6003
Training Epoch: 0 [3072/50176]	Loss: 4.6840
Training Epoch: 0 [3328/50176]	Loss: 4.5545
Training Epoch: 0 [3584/50176]	Loss: 4.6450
Training Epoch: 0 [3840/50176]	Loss: 4.7551
Training Epoch: 0 [4096/50176]	Loss: 4.6016
Training Epoch: 0 [4352/50176]	Loss: 4.5872
Training Epoch: 0 [4608/50176]	Loss: 4.6227
Training Epoch: 0 [4864/50176]	Loss: 4.5021
Training Epoch: 0 [5120/50176]	Loss: 4.5161
Training Epoch: 0 [5376/50176]	Loss: 4.5455
Training Epoch: 0 [5632/50176]	Loss: 4.5416
Training Epoch: 0 [5888/50176]	Loss: 4.6077
Training Epoch: 0 [6144/50176]	Loss: 4.5037
Training Epoch: 0 [6400/50176]	Loss: 4.7377
Training Epoch: 0 [6656/50176]	Loss: 4.5573
Training Epoch: 0 [6912/50176]	Loss: 4.4534
Training Epoch: 0 [7168/50176]	Loss: 4.5114
Training Epoch: 0 [7424/50176]	Loss: 4.4970
Training Epoch: 0 [7680/50176]	Loss: 4.4855
Training Epoch: 0 [7936/50176]	Loss: 4.4745
Training Epoch: 0 [8192/50176]	Loss: 4.4600
Training Epoch: 0 [8448/50176]	Loss: 4.5020
Training Epoch: 0 [8704/50176]	Loss: 4.5102
Training Epoch: 0 [8960/50176]	Loss: 4.4398
Training Epoch: 0 [9216/50176]	Loss: 4.3920
Training Epoch: 0 [9472/50176]	Loss: 4.4124
Training Epoch: 0 [9728/50176]	Loss: 4.3998
Training Epoch: 0 [9984/50176]	Loss: 4.3860
Training Epoch: 0 [10240/50176]	Loss: 4.4010
Training Epoch: 0 [10496/50176]	Loss: 4.3595
Training Epoch: 0 [10752/50176]	Loss: 4.3581
Training Epoch: 0 [11008/50176]	Loss: 4.3047
Training Epoch: 0 [11264/50176]	Loss: 4.3836
Training Epoch: 0 [11520/50176]	Loss: 4.3345
Training Epoch: 0 [11776/50176]	Loss: 4.3690
Training Epoch: 0 [12032/50176]	Loss: 4.3981
Training Epoch: 0 [12288/50176]	Loss: 4.3336
Training Epoch: 0 [12544/50176]	Loss: 4.2729
Training Epoch: 0 [12800/50176]	Loss: 4.3321
Profile done with power limit 150W
epoch 1 train time consumed: 13.07s
Validation Epoch: 0, Average loss: 0.0181, Accuracy: 0.0247
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 150000, 'lr': 0.006788225099390857, 'energy': 147.12001266866085, 'time': 9.834012895999876, 'accuracy': 0.02470703125, 'total_cost': 222871.6053634556}
[run job] Launching job with BS 256: and LR: 0.006788225099390857 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00679+pl125', 'ZEUS_COST_THRESH': '335270.30969636445', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.006788225099390857', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006788225099390857', '--power_limit', '125']
[run job] cost_ub=335270.30969636445
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00679+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.006788225099390857
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 6.4519
Training Epoch: 0 [768/50176]	Loss: 6.0619
Training Epoch: 0 [1024/50176]	Loss: 5.2351
Training Epoch: 0 [1280/50176]	Loss: 4.8772
Training Epoch: 0 [1536/50176]	Loss: 4.8135
Training Epoch: 0 [1792/50176]	Loss: 4.6228
Training Epoch: 0 [2048/50176]	Loss: 4.6162
Training Epoch: 0 [2304/50176]	Loss: 4.7254
Training Epoch: 0 [2560/50176]	Loss: 4.6363
Training Epoch: 0 [2816/50176]	Loss: 4.5903
Training Epoch: 0 [3072/50176]	Loss: 4.6984
Training Epoch: 0 [3328/50176]	Loss: 4.5545
Training Epoch: 0 [3584/50176]	Loss: 4.6375
Training Epoch: 0 [3840/50176]	Loss: 4.8092
Training Epoch: 0 [4096/50176]	Loss: 4.6253
Training Epoch: 0 [4352/50176]	Loss: 4.5771
Training Epoch: 0 [4608/50176]	Loss: 4.6026
Training Epoch: 0 [4864/50176]	Loss: 4.5177
Training Epoch: 0 [5120/50176]	Loss: 4.5095
Training Epoch: 0 [5376/50176]	Loss: 4.5462
Training Epoch: 0 [5632/50176]	Loss: 4.5715
Training Epoch: 0 [5888/50176]	Loss: 4.5194
Training Epoch: 0 [6144/50176]	Loss: 4.4877
Training Epoch: 0 [6400/50176]	Loss: 4.7286
Training Epoch: 0 [6656/50176]	Loss: 4.5314
Training Epoch: 0 [6912/50176]	Loss: 4.4594
Training Epoch: 0 [7168/50176]	Loss: 4.4891
Training Epoch: 0 [7424/50176]	Loss: 4.4862
Training Epoch: 0 [7680/50176]	Loss: 4.4606
Training Epoch: 0 [7936/50176]	Loss: 4.4465
Training Epoch: 0 [8192/50176]	Loss: 4.5031
Training Epoch: 0 [8448/50176]	Loss: 4.4632
Training Epoch: 0 [8704/50176]	Loss: 4.4056
Training Epoch: 0 [8960/50176]	Loss: 4.4104
Training Epoch: 0 [9216/50176]	Loss: 4.3574
Training Epoch: 0 [9472/50176]	Loss: 4.4273
Training Epoch: 0 [9728/50176]	Loss: 4.3542
Training Epoch: 0 [9984/50176]	Loss: 4.4128
Training Epoch: 0 [10240/50176]	Loss: 4.4087
Training Epoch: 0 [10496/50176]	Loss: 4.3357
Training Epoch: 0 [10752/50176]	Loss: 4.3215
Training Epoch: 0 [11008/50176]	Loss: 4.3077
Training Epoch: 0 [11264/50176]	Loss: 4.4330
Training Epoch: 0 [11520/50176]	Loss: 4.3108
Training Epoch: 0 [11776/50176]	Loss: 4.4331
Training Epoch: 0 [12032/50176]	Loss: 4.3786
Training Epoch: 0 [12288/50176]	Loss: 4.3470
Training Epoch: 0 [12544/50176]	Loss: 4.3183
Training Epoch: 0 [12800/50176]	Loss: 4.3391
Profile done with power limit 125W
epoch 1 train time consumed: 14.76s
Validation Epoch: 0, Average loss: 0.0207, Accuracy: 0.0225
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 125000, 'lr': 0.006788225099390857, 'energy': 123.08172107379892, 'time': 11.268294911999874, 'accuracy': 0.0224609375, 'total_cost': 280656.59321283834}
[run job] Launching job with BS 256: and LR: 0.006788225099390857 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs256+lr0.00679+pl100', 'ZEUS_COST_THRESH': '335270.30969636445', 'ZEUS_BATCH_SIZE': '256', 'ZEUS_LEARNING_RATE': '0.006788225099390857', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '256', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006788225099390857', '--power_limit', '100']
[run job] cost_ub=335270.30969636445
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs256+lr0.00679+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.006788225099390857
batch size arg: 256
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [256/50176]	Loss: 4.6571
Training Epoch: 0 [512/50176]	Loss: 6.4519
Training Epoch: 0 [768/50176]	Loss: 6.0627
Training Epoch: 0 [1024/50176]	Loss: 5.2349
Training Epoch: 0 [1280/50176]	Loss: 4.8711
Training Epoch: 0 [1536/50176]	Loss: 4.8086
Training Epoch: 0 [1792/50176]	Loss: 4.6241
Training Epoch: 0 [2048/50176]	Loss: 4.6143
Training Epoch: 0 [2304/50176]	Loss: 4.7335
Training Epoch: 0 [2560/50176]	Loss: 4.6347
Training Epoch: 0 [2816/50176]	Loss: 4.5929
Training Epoch: 0 [3072/50176]	Loss: 4.7342
Training Epoch: 0 [3328/50176]	Loss: 4.5474
Training Epoch: 0 [3584/50176]	Loss: 4.6435
Training Epoch: 0 [3840/50176]	Loss: 4.6388
Training Epoch: 0 [4096/50176]	Loss: 4.5990
Training Epoch: 0 [4352/50176]	Loss: 4.5658
Training Epoch: 0 [4608/50176]	Loss: 4.6212
Training Epoch: 0 [4864/50176]	Loss: 4.5390
Training Epoch: 0 [5120/50176]	Loss: 4.5290
Training Epoch: 0 [5376/50176]	Loss: 4.5348
Training Epoch: 0 [5632/50176]	Loss: 4.5677
Training Epoch: 0 [5888/50176]	Loss: 4.4893
Training Epoch: 0 [6144/50176]	Loss: 4.4581
Training Epoch: 0 [6400/50176]	Loss: 4.7108
Training Epoch: 0 [6656/50176]	Loss: 4.6216
Training Epoch: 0 [6912/50176]	Loss: 4.4635
Training Epoch: 0 [7168/50176]	Loss: 4.5048
Training Epoch: 0 [7424/50176]	Loss: 4.6679
Training Epoch: 0 [7680/50176]	Loss: 4.4901
Training Epoch: 0 [7936/50176]	Loss: 4.4691
Training Epoch: 0 [8192/50176]	Loss: 4.5034
Training Epoch: 0 [8448/50176]	Loss: 4.5076
Training Epoch: 0 [8704/50176]	Loss: 4.4848
Training Epoch: 0 [8960/50176]	Loss: 4.4430
Training Epoch: 0 [9216/50176]	Loss: 4.4097
Training Epoch: 0 [9472/50176]	Loss: 4.4992
Training Epoch: 0 [9728/50176]	Loss: 4.4211
Training Epoch: 0 [9984/50176]	Loss: 4.4156
Training Epoch: 0 [10240/50176]	Loss: 4.4384
Training Epoch: 0 [10496/50176]	Loss: 4.3837
Training Epoch: 0 [10752/50176]	Loss: 4.3615
Training Epoch: 0 [11008/50176]	Loss: 4.3323
Training Epoch: 0 [11264/50176]	Loss: 4.3838
Training Epoch: 0 [11520/50176]	Loss: 4.3584
Training Epoch: 0 [11776/50176]	Loss: 4.4281
Training Epoch: 0 [12032/50176]	Loss: 4.3933
Training Epoch: 0 [12288/50176]	Loss: 4.4124
Training Epoch: 0 [12544/50176]	Loss: 4.3762
Training Epoch: 0 [12800/50176]	Loss: 4.3558
Profile done with power limit 100W
epoch 1 train time consumed: 36.58s
Validation Epoch: 0, Average loss: 0.0220, Accuracy: 0.0157
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 256, 'pl': 100000, 'lr': 0.006788225099390857, 'energy': 103.88811103396927, 'time': 28.756018905999554, 'accuracy': 0.01572265625, 'total_cost': 1021464.5877533336}

[Power Profiler] with batch size 512 and learning rate 0.0064
[run job] Launching job with BS 512: and LR: 0.0064 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00640+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0064', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0064', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00640+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0064
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 5.9978
Training Epoch: 0 [1536/50176]	Loss: 5.4433
Training Epoch: 0 [2048/50176]	Loss: 4.6766
Training Epoch: 0 [2560/50176]	Loss: 4.8383
Training Epoch: 0 [3072/50176]	Loss: 4.7388
Training Epoch: 0 [3584/50176]	Loss: 4.6574
Training Epoch: 0 [4096/50176]	Loss: 4.7537
Training Epoch: 0 [4608/50176]	Loss: 4.6097
Training Epoch: 0 [5120/50176]	Loss: 4.5777
Training Epoch: 0 [5632/50176]	Loss: 4.6717
Training Epoch: 0 [6144/50176]	Loss: 4.6518
Training Epoch: 0 [6656/50176]	Loss: 4.6699
Training Epoch: 0 [7168/50176]	Loss: 4.6092
Training Epoch: 0 [7680/50176]	Loss: 4.5837
Training Epoch: 0 [8192/50176]	Loss: 4.5912
Training Epoch: 0 [8704/50176]	Loss: 4.5941
Training Epoch: 0 [9216/50176]	Loss: 4.5694
Training Epoch: 0 [9728/50176]	Loss: 4.6623
Training Epoch: 0 [10240/50176]	Loss: 4.5440
Training Epoch: 0 [10752/50176]	Loss: 4.5231
Training Epoch: 0 [11264/50176]	Loss: 4.5256
Training Epoch: 0 [11776/50176]	Loss: 4.5580
Training Epoch: 0 [12288/50176]	Loss: 4.5794
Training Epoch: 0 [12800/50176]	Loss: 4.5152
Training Epoch: 0 [13312/50176]	Loss: 4.4957
Training Epoch: 0 [13824/50176]	Loss: 4.4581
Training Epoch: 0 [14336/50176]	Loss: 4.4638
Training Epoch: 0 [14848/50176]	Loss: 4.4079
Training Epoch: 0 [15360/50176]	Loss: 4.3614
Training Epoch: 0 [15872/50176]	Loss: 4.3772
Training Epoch: 0 [16384/50176]	Loss: 4.2904
Training Epoch: 0 [16896/50176]	Loss: 4.3312
Training Epoch: 0 [17408/50176]	Loss: 4.3618
Training Epoch: 0 [17920/50176]	Loss: 4.3852
Training Epoch: 0 [18432/50176]	Loss: 4.2905
Training Epoch: 0 [18944/50176]	Loss: 4.2296
Training Epoch: 0 [19456/50176]	Loss: 4.2820
Training Epoch: 0 [19968/50176]	Loss: 4.2577
Training Epoch: 0 [20480/50176]	Loss: 4.2466
Training Epoch: 0 [20992/50176]	Loss: 4.1796
Training Epoch: 0 [21504/50176]	Loss: 4.2424
Training Epoch: 0 [22016/50176]	Loss: 4.3021
Training Epoch: 0 [22528/50176]	Loss: 4.2436
Training Epoch: 0 [23040/50176]	Loss: 4.2126
Training Epoch: 0 [23552/50176]	Loss: 4.2587
Training Epoch: 0 [24064/50176]	Loss: 4.2654
Training Epoch: 0 [24576/50176]	Loss: 4.2043
Training Epoch: 0 [25088/50176]	Loss: 4.2113
Training Epoch: 0 [25600/50176]	Loss: 4.1735
Profile done with power limit 175W
epoch 1 train time consumed: 23.90s
Validation Epoch: 0, Average loss: 0.0089, Accuracy: 0.0440
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 175000, 'lr': 0.0064, 'energy': 155.35449930459717, 'time': 18.259374762000334, 'accuracy': 0.04404296875, 'total_cost': 463601.75766465336}
[run job] Launching job with BS 512: and LR: 0.0064 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00640+pl150', 'ZEUS_COST_THRESH': '927203.5153293067', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0064', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0064', '--power_limit', '150']
[run job] cost_ub=927203.5153293067
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00640+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0064
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 5.9978
Training Epoch: 0 [1536/50176]	Loss: 5.4436
Training Epoch: 0 [2048/50176]	Loss: 4.6774
Training Epoch: 0 [2560/50176]	Loss: 4.8405
Training Epoch: 0 [3072/50176]	Loss: 4.7425
Training Epoch: 0 [3584/50176]	Loss: 4.6558
Training Epoch: 0 [4096/50176]	Loss: 4.7504
Training Epoch: 0 [4608/50176]	Loss: 4.5817
Training Epoch: 0 [5120/50176]	Loss: 4.5783
Training Epoch: 0 [5632/50176]	Loss: 4.6619
Training Epoch: 0 [6144/50176]	Loss: 4.7294
Training Epoch: 0 [6656/50176]	Loss: 4.8173
Training Epoch: 0 [7168/50176]	Loss: 4.7952
Training Epoch: 0 [7680/50176]	Loss: 4.6412
Training Epoch: 0 [8192/50176]	Loss: 4.6093
Training Epoch: 0 [8704/50176]	Loss: 4.6015
Training Epoch: 0 [9216/50176]	Loss: 4.6008
Training Epoch: 0 [9728/50176]	Loss: 4.5802
Training Epoch: 0 [10240/50176]	Loss: 4.5647
Training Epoch: 0 [10752/50176]	Loss: 4.5311
Training Epoch: 0 [11264/50176]	Loss: 4.5431
Training Epoch: 0 [11776/50176]	Loss: 4.5258
Training Epoch: 0 [12288/50176]	Loss: 4.5345
Training Epoch: 0 [12800/50176]	Loss: 4.5047
Training Epoch: 0 [13312/50176]	Loss: 4.5123
Training Epoch: 0 [13824/50176]	Loss: 4.4687
Training Epoch: 0 [14336/50176]	Loss: 4.4636
Training Epoch: 0 [14848/50176]	Loss: 4.4019
Training Epoch: 0 [15360/50176]	Loss: 4.3791
Training Epoch: 0 [15872/50176]	Loss: 4.3796
Training Epoch: 0 [16384/50176]	Loss: 4.2741
Training Epoch: 0 [16896/50176]	Loss: 4.3228
Training Epoch: 0 [17408/50176]	Loss: 4.3753
Training Epoch: 0 [17920/50176]	Loss: 4.3838
Training Epoch: 0 [18432/50176]	Loss: 4.2923
Training Epoch: 0 [18944/50176]	Loss: 4.2440
Training Epoch: 0 [19456/50176]	Loss: 4.2800
Training Epoch: 0 [19968/50176]	Loss: 4.2908
Training Epoch: 0 [20480/50176]	Loss: 4.2746
Training Epoch: 0 [20992/50176]	Loss: 4.1962
Training Epoch: 0 [21504/50176]	Loss: 4.2727
Training Epoch: 0 [22016/50176]	Loss: 4.2668
Training Epoch: 0 [22528/50176]	Loss: 4.2254
Training Epoch: 0 [23040/50176]	Loss: 4.1909
Training Epoch: 0 [23552/50176]	Loss: 4.2589
Training Epoch: 0 [24064/50176]	Loss: 4.2003
Training Epoch: 0 [24576/50176]	Loss: 4.2275
Training Epoch: 0 [25088/50176]	Loss: 4.2164
Training Epoch: 0 [25600/50176]	Loss: 4.1925
Profile done with power limit 150W
epoch 1 train time consumed: 24.64s
Validation Epoch: 0, Average loss: 0.0084, Accuracy: 0.0437
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 150000, 'lr': 0.0064, 'energy': 147.14267818165072, 'time': 18.868340670999714, 'accuracy': 0.04365234375, 'total_cost': 483271.92798096576}
[run job] Launching job with BS 512: and LR: 0.0064 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00640+pl125', 'ZEUS_COST_THRESH': '927203.5153293067', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0064', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0064', '--power_limit', '125']
[run job] cost_ub=927203.5153293067
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00640+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0064
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 5.9978
Training Epoch: 0 [1536/50176]	Loss: 5.4432
Training Epoch: 0 [2048/50176]	Loss: 4.6758
Training Epoch: 0 [2560/50176]	Loss: 4.8376
Training Epoch: 0 [3072/50176]	Loss: 4.7435
Training Epoch: 0 [3584/50176]	Loss: 4.6654
Training Epoch: 0 [4096/50176]	Loss: 4.7359
Training Epoch: 0 [4608/50176]	Loss: 4.6543
Training Epoch: 0 [5120/50176]	Loss: 4.5729
Training Epoch: 0 [5632/50176]	Loss: 4.6973
Training Epoch: 0 [6144/50176]	Loss: 4.6337
Training Epoch: 0 [6656/50176]	Loss: 4.6483
Training Epoch: 0 [7168/50176]	Loss: 4.6114
Training Epoch: 0 [7680/50176]	Loss: 4.5956
Training Epoch: 0 [8192/50176]	Loss: 4.5844
Training Epoch: 0 [8704/50176]	Loss: 4.5905
Training Epoch: 0 [9216/50176]	Loss: 4.5698
Training Epoch: 0 [9728/50176]	Loss: 4.5692
Training Epoch: 0 [10240/50176]	Loss: 4.5427
Training Epoch: 0 [10752/50176]	Loss: 4.5318
Training Epoch: 0 [11264/50176]	Loss: 4.5737
Training Epoch: 0 [11776/50176]	Loss: 4.6482
Training Epoch: 0 [12288/50176]	Loss: 4.5247
Training Epoch: 0 [12800/50176]	Loss: 4.6101
Training Epoch: 0 [13312/50176]	Loss: 4.4746
Training Epoch: 0 [13824/50176]	Loss: 4.5343
Training Epoch: 0 [14336/50176]	Loss: 4.4887
Training Epoch: 0 [14848/50176]	Loss: 4.4370
Training Epoch: 0 [15360/50176]	Loss: 4.5229
Training Epoch: 0 [15872/50176]	Loss: 4.3898
Training Epoch: 0 [16384/50176]	Loss: 4.3070
Training Epoch: 0 [16896/50176]	Loss: 4.3564
Training Epoch: 0 [17408/50176]	Loss: 4.3754
Training Epoch: 0 [17920/50176]	Loss: 4.3871
Training Epoch: 0 [18432/50176]	Loss: 4.2903
Training Epoch: 0 [18944/50176]	Loss: 4.2370
Training Epoch: 0 [19456/50176]	Loss: 4.2717
Training Epoch: 0 [19968/50176]	Loss: 4.2594
Training Epoch: 0 [20480/50176]	Loss: 4.2526
Training Epoch: 0 [20992/50176]	Loss: 4.1765
Training Epoch: 0 [21504/50176]	Loss: 4.2509
Training Epoch: 0 [22016/50176]	Loss: 4.3513
Training Epoch: 0 [22528/50176]	Loss: 4.2270
Training Epoch: 0 [23040/50176]	Loss: 4.1700
Training Epoch: 0 [23552/50176]	Loss: 4.2513
Training Epoch: 0 [24064/50176]	Loss: 4.2595
Training Epoch: 0 [24576/50176]	Loss: 4.2064
Training Epoch: 0 [25088/50176]	Loss: 4.2157
Training Epoch: 0 [25600/50176]	Loss: 4.2154
Profile done with power limit 125W
epoch 1 train time consumed: 28.44s
Validation Epoch: 0, Average loss: 0.0083, Accuracy: 0.0455
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 125000, 'lr': 0.0064, 'energy': 122.70043395781727, 'time': 21.921265439999843, 'accuracy': 0.0455078125, 'total_cost': 538303.1576572879}
[run job] Launching job with BS 512: and LR: 0.0064 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00640+pl100', 'ZEUS_COST_THRESH': '927203.5153293067', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0064', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0064', '--power_limit', '100']
[run job] cost_ub=927203.5153293067
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00640+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0064
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 5.9978
Training Epoch: 0 [1536/50176]	Loss: 5.4433
Training Epoch: 0 [2048/50176]	Loss: 4.6762
Training Epoch: 0 [2560/50176]	Loss: 4.8457
Training Epoch: 0 [3072/50176]	Loss: 4.7468
Training Epoch: 0 [3584/50176]	Loss: 4.6666
Training Epoch: 0 [4096/50176]	Loss: 4.7019
Training Epoch: 0 [4608/50176]	Loss: 4.5867
Training Epoch: 0 [5120/50176]	Loss: 4.6806
Training Epoch: 0 [5632/50176]	Loss: 4.8386
Training Epoch: 0 [6144/50176]	Loss: 4.7386
Training Epoch: 0 [6656/50176]	Loss: 4.6689
Training Epoch: 0 [7168/50176]	Loss: 4.6196
Training Epoch: 0 [7680/50176]	Loss: 4.5855
Training Epoch: 0 [8192/50176]	Loss: 4.5894
Training Epoch: 0 [8704/50176]	Loss: 4.6016
Training Epoch: 0 [9216/50176]	Loss: 4.5847
Training Epoch: 0 [9728/50176]	Loss: 4.5794
Training Epoch: 0 [10240/50176]	Loss: 4.5432
Training Epoch: 0 [10752/50176]	Loss: 4.5669
Training Epoch: 0 [11264/50176]	Loss: 4.5473
Training Epoch: 0 [11776/50176]	Loss: 4.6357
Training Epoch: 0 [12288/50176]	Loss: 4.5910
Training Epoch: 0 [12800/50176]	Loss: 4.4725
Training Epoch: 0 [13312/50176]	Loss: 4.5116
Training Epoch: 0 [13824/50176]	Loss: 4.4669
Training Epoch: 0 [14336/50176]	Loss: 4.4430
Training Epoch: 0 [14848/50176]	Loss: 4.4416
Training Epoch: 0 [15360/50176]	Loss: 4.4125
Training Epoch: 0 [15872/50176]	Loss: 4.3755
Training Epoch: 0 [16384/50176]	Loss: 4.3431
Training Epoch: 0 [16896/50176]	Loss: 4.3117
Training Epoch: 0 [17408/50176]	Loss: 4.4304
Training Epoch: 0 [17920/50176]	Loss: 4.4062
Training Epoch: 0 [18432/50176]	Loss: 4.2752
Training Epoch: 0 [18944/50176]	Loss: 4.2799
Training Epoch: 0 [19456/50176]	Loss: 4.2870
Training Epoch: 0 [19968/50176]	Loss: 4.2849
Training Epoch: 0 [20480/50176]	Loss: 4.2743
Training Epoch: 0 [20992/50176]	Loss: 4.2239
Training Epoch: 0 [21504/50176]	Loss: 4.2545
Training Epoch: 0 [22016/50176]	Loss: 4.2838
Training Epoch: 0 [22528/50176]	Loss: 4.2273
Training Epoch: 0 [23040/50176]	Loss: 4.1896
Training Epoch: 0 [23552/50176]	Loss: 4.2537
Training Epoch: 0 [24064/50176]	Loss: 4.2198
Training Epoch: 0 [24576/50176]	Loss: 4.2184
Training Epoch: 0 [25088/50176]	Loss: 4.1916
Training Epoch: 0 [25600/50176]	Loss: 4.2390
Profile done with power limit 100W
epoch 1 train time consumed: 67.05s
Validation Epoch: 0, Average loss: 0.0089, Accuracy: 0.0458
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 100000, 'lr': 0.0064, 'energy': 104.45880232575144, 'time': 52.132640353999705, 'accuracy': 0.04580078125, 'total_cost': 1270947.7100621178}

[Power Profiler] with batch size 512 and learning rate 0.008
[run job] Launching job with BS 512: and LR: 0.008 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00800+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.008', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00800+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.008
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 6.5227
Training Epoch: 0 [1536/50176]	Loss: 5.3000
Training Epoch: 0 [2048/50176]	Loss: 4.6746
Training Epoch: 0 [2560/50176]	Loss: 4.8321
Training Epoch: 0 [3072/50176]	Loss: 4.6687
Training Epoch: 0 [3584/50176]	Loss: 4.5914
Training Epoch: 0 [4096/50176]	Loss: 5.1593
Training Epoch: 0 [4608/50176]	Loss: 4.8725
Training Epoch: 0 [5120/50176]	Loss: 4.7424
Training Epoch: 0 [5632/50176]	Loss: 4.6406
Training Epoch: 0 [6144/50176]	Loss: 4.7371
Training Epoch: 0 [6656/50176]	Loss: 4.7203
Training Epoch: 0 [7168/50176]	Loss: 4.6144
Training Epoch: 0 [7680/50176]	Loss: 4.5998
Training Epoch: 0 [8192/50176]	Loss: 4.6211
Training Epoch: 0 [8704/50176]	Loss: 4.6047
Training Epoch: 0 [9216/50176]	Loss: 4.6421
Training Epoch: 0 [9728/50176]	Loss: 4.6580
Training Epoch: 0 [10240/50176]	Loss: 4.5707
Training Epoch: 0 [10752/50176]	Loss: 4.5247
Training Epoch: 0 [11264/50176]	Loss: 4.5303
Training Epoch: 0 [11776/50176]	Loss: 4.5652
Training Epoch: 0 [12288/50176]	Loss: 4.5498
Training Epoch: 0 [12800/50176]	Loss: 4.5697
Training Epoch: 0 [13312/50176]	Loss: 4.5451
Training Epoch: 0 [13824/50176]	Loss: 4.5314
Training Epoch: 0 [14336/50176]	Loss: 4.4975
Training Epoch: 0 [14848/50176]	Loss: 4.4749
Training Epoch: 0 [15360/50176]	Loss: 4.4676
Training Epoch: 0 [15872/50176]	Loss: 4.4548
Training Epoch: 0 [16384/50176]	Loss: 4.4699
Training Epoch: 0 [16896/50176]	Loss: 4.4438
Training Epoch: 0 [17408/50176]	Loss: 4.5009
Training Epoch: 0 [17920/50176]	Loss: 4.5114
Training Epoch: 0 [18432/50176]	Loss: 4.3968
Training Epoch: 0 [18944/50176]	Loss: 4.3974
Training Epoch: 0 [19456/50176]	Loss: 4.3773
Training Epoch: 0 [19968/50176]	Loss: 4.3547
Training Epoch: 0 [20480/50176]	Loss: 4.3800
Training Epoch: 0 [20992/50176]	Loss: 4.3099
Training Epoch: 0 [21504/50176]	Loss: 4.3826
Training Epoch: 0 [22016/50176]	Loss: 4.4489
Training Epoch: 0 [22528/50176]	Loss: 4.3505
Training Epoch: 0 [23040/50176]	Loss: 4.3373
Training Epoch: 0 [23552/50176]	Loss: 4.4305
Training Epoch: 0 [24064/50176]	Loss: 4.3635
Training Epoch: 0 [24576/50176]	Loss: 4.3215
Training Epoch: 0 [25088/50176]	Loss: 4.3198
Training Epoch: 0 [25600/50176]	Loss: 4.3185
Profile done with power limit 175W
epoch 1 train time consumed: 23.92s
Validation Epoch: 0, Average loss: 0.0088, Accuracy: 0.0259
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 175000, 'lr': 0.008, 'energy': 155.53172338170768, 'time': 18.256932941999366, 'accuracy': 0.02587890625, 'total_cost': 788894.1477175589}
[run job] Launching job with BS 512: and LR: 0.008 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00800+pl150', 'ZEUS_COST_THRESH': '1577788.2954351178', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.008', '--power_limit', '150']
[run job] cost_ub=1577788.2954351178
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00800+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.008
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 6.5227
Training Epoch: 0 [1536/50176]	Loss: 5.3000
Training Epoch: 0 [2048/50176]	Loss: 4.6772
Training Epoch: 0 [2560/50176]	Loss: 4.8299
Training Epoch: 0 [3072/50176]	Loss: 4.6754
Training Epoch: 0 [3584/50176]	Loss: 4.5927
Training Epoch: 0 [4096/50176]	Loss: 4.8476
Training Epoch: 0 [4608/50176]	Loss: 4.6610
Training Epoch: 0 [5120/50176]	Loss: 4.8534
Training Epoch: 0 [5632/50176]	Loss: 4.6533
Training Epoch: 0 [6144/50176]	Loss: 4.6405
Training Epoch: 0 [6656/50176]	Loss: 4.6970
Training Epoch: 0 [7168/50176]	Loss: 4.6303
Training Epoch: 0 [7680/50176]	Loss: 4.6051
Training Epoch: 0 [8192/50176]	Loss: 4.6439
Training Epoch: 0 [8704/50176]	Loss: 4.6366
Training Epoch: 0 [9216/50176]	Loss: 4.5991
Training Epoch: 0 [9728/50176]	Loss: 4.6846
Training Epoch: 0 [10240/50176]	Loss: 4.5549
Training Epoch: 0 [10752/50176]	Loss: 4.5817
Training Epoch: 0 [11264/50176]	Loss: 4.5817
Training Epoch: 0 [11776/50176]	Loss: 4.5982
Training Epoch: 0 [12288/50176]	Loss: 4.6369
Training Epoch: 0 [12800/50176]	Loss: 4.5623
Training Epoch: 0 [13312/50176]	Loss: 4.5082
Training Epoch: 0 [13824/50176]	Loss: 4.5303
Training Epoch: 0 [14336/50176]	Loss: 4.5236
Training Epoch: 0 [14848/50176]	Loss: 4.5074
Training Epoch: 0 [15360/50176]	Loss: 4.5092
Training Epoch: 0 [15872/50176]	Loss: 4.4452
Training Epoch: 0 [16384/50176]	Loss: 4.4540
Training Epoch: 0 [16896/50176]	Loss: 4.4428
Training Epoch: 0 [17408/50176]	Loss: 4.5009
Training Epoch: 0 [17920/50176]	Loss: 4.4983
Training Epoch: 0 [18432/50176]	Loss: 4.4050
Training Epoch: 0 [18944/50176]	Loss: 4.3793
Training Epoch: 0 [19456/50176]	Loss: 4.3519
Training Epoch: 0 [19968/50176]	Loss: 4.3549
Training Epoch: 0 [20480/50176]	Loss: 4.3765
Training Epoch: 0 [20992/50176]	Loss: 4.2979
Training Epoch: 0 [21504/50176]	Loss: 4.3438
Training Epoch: 0 [22016/50176]	Loss: 4.3631
Training Epoch: 0 [22528/50176]	Loss: 4.3526
Training Epoch: 0 [23040/50176]	Loss: 4.3166
Training Epoch: 0 [23552/50176]	Loss: 4.3256
Training Epoch: 0 [24064/50176]	Loss: 4.3333
Training Epoch: 0 [24576/50176]	Loss: 4.2839
Training Epoch: 0 [25088/50176]	Loss: 4.2979
Training Epoch: 0 [25600/50176]	Loss: 4.2450
Profile done with power limit 150W
epoch 1 train time consumed: 24.66s
Validation Epoch: 0, Average loss: 0.0084, Accuracy: 0.0397
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 150000, 'lr': 0.008, 'energy': 147.1116439254758, 'time': 18.857723672000247, 'accuracy': 0.03974609375, 'total_cost': 530469.6157419946}
[run job] Launching job with BS 512: and LR: 0.008 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00800+pl125', 'ZEUS_COST_THRESH': '1060939.2314839892', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.008', '--power_limit', '125']
[run job] cost_ub=1060939.2314839892
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00800+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.008
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 6.5227
Training Epoch: 0 [1536/50176]	Loss: 5.3001
Training Epoch: 0 [2048/50176]	Loss: 4.6777
Training Epoch: 0 [2560/50176]	Loss: 4.8317
Training Epoch: 0 [3072/50176]	Loss: 4.6645
Training Epoch: 0 [3584/50176]	Loss: 4.6234
Training Epoch: 0 [4096/50176]	Loss: 4.6528
Training Epoch: 0 [4608/50176]	Loss: 4.6045
Training Epoch: 0 [5120/50176]	Loss: 4.7198
Training Epoch: 0 [5632/50176]	Loss: 4.9718
Training Epoch: 0 [6144/50176]	Loss: 4.6273
Training Epoch: 0 [6656/50176]	Loss: 4.7708
Training Epoch: 0 [7168/50176]	Loss: 4.7122
Training Epoch: 0 [7680/50176]	Loss: 4.6764
Training Epoch: 0 [8192/50176]	Loss: 4.6377
Training Epoch: 0 [8704/50176]	Loss: 4.6384
Training Epoch: 0 [9216/50176]	Loss: 4.6660
Training Epoch: 0 [9728/50176]	Loss: 4.8303
Training Epoch: 0 [10240/50176]	Loss: 4.5918
Training Epoch: 0 [10752/50176]	Loss: 4.5952
Training Epoch: 0 [11264/50176]	Loss: 4.5771
Training Epoch: 0 [11776/50176]	Loss: 4.6375
Training Epoch: 0 [12288/50176]	Loss: 4.6509
Training Epoch: 0 [12800/50176]	Loss: 4.6306
Training Epoch: 0 [13312/50176]	Loss: 4.5533
Training Epoch: 0 [13824/50176]	Loss: 4.5571
Training Epoch: 0 [14336/50176]	Loss: 4.5176
Training Epoch: 0 [14848/50176]	Loss: 4.5311
Training Epoch: 0 [15360/50176]	Loss: 4.5360
Training Epoch: 0 [15872/50176]	Loss: 4.5078
Training Epoch: 0 [16384/50176]	Loss: 4.5125
Training Epoch: 0 [16896/50176]	Loss: 4.4824
Training Epoch: 0 [17408/50176]	Loss: 4.5081
Training Epoch: 0 [17920/50176]	Loss: 4.4922
Training Epoch: 0 [18432/50176]	Loss: 4.4490
Training Epoch: 0 [18944/50176]	Loss: 4.4450
Training Epoch: 0 [19456/50176]	Loss: 4.4571
Training Epoch: 0 [19968/50176]	Loss: 4.4204
Training Epoch: 0 [20480/50176]	Loss: 4.4367
Training Epoch: 0 [20992/50176]	Loss: 4.3832
Training Epoch: 0 [21504/50176]	Loss: 4.4276
Training Epoch: 0 [22016/50176]	Loss: 4.4328
Training Epoch: 0 [22528/50176]	Loss: 4.4258
Training Epoch: 0 [23040/50176]	Loss: 4.4025
Training Epoch: 0 [23552/50176]	Loss: 4.4618
Training Epoch: 0 [24064/50176]	Loss: 4.4150
Training Epoch: 0 [24576/50176]	Loss: 4.3840
Training Epoch: 0 [25088/50176]	Loss: 4.3743
Training Epoch: 0 [25600/50176]	Loss: 4.3920
Profile done with power limit 125W
epoch 1 train time consumed: 28.36s
Validation Epoch: 0, Average loss: 0.0088, Accuracy: 0.0209
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 125000, 'lr': 0.008, 'energy': 122.8194037242472, 'time': 21.874707311999373, 'accuracy': 0.0208984375, 'total_cost': 1169707.8941823721}
[run job] Launching job with BS 512: and LR: 0.008 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00800+pl100', 'ZEUS_COST_THRESH': '1060939.2314839892', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.008', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.008', '--power_limit', '100']
[run job] cost_ub=1060939.2314839892
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00800+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.008
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 6.5227
Training Epoch: 0 [1536/50176]	Loss: 5.2997
Training Epoch: 0 [2048/50176]	Loss: 4.6752
Training Epoch: 0 [2560/50176]	Loss: 4.8234
Training Epoch: 0 [3072/50176]	Loss: 4.6728
Training Epoch: 0 [3584/50176]	Loss: 4.5841
Training Epoch: 0 [4096/50176]	Loss: 4.6458
Training Epoch: 0 [4608/50176]	Loss: 4.6426
Training Epoch: 0 [5120/50176]	Loss: 4.9013
Training Epoch: 0 [5632/50176]	Loss: 4.8241
Training Epoch: 0 [6144/50176]	Loss: 4.7362
Training Epoch: 0 [6656/50176]	Loss: 4.8527
Training Epoch: 0 [7168/50176]	Loss: 4.6634
Training Epoch: 0 [7680/50176]	Loss: 4.6089
Training Epoch: 0 [8192/50176]	Loss: 4.6701
Training Epoch: 0 [8704/50176]	Loss: 4.6774
Training Epoch: 0 [9216/50176]	Loss: 4.7056
Training Epoch: 0 [9728/50176]	Loss: 4.6813
Training Epoch: 0 [10240/50176]	Loss: 4.5753
Training Epoch: 0 [10752/50176]	Loss: 4.5729
Training Epoch: 0 [11264/50176]	Loss: 4.5360
Training Epoch: 0 [11776/50176]	Loss: 4.5803
Training Epoch: 0 [12288/50176]	Loss: 4.5645
Training Epoch: 0 [12800/50176]	Loss: 4.5441
Training Epoch: 0 [13312/50176]	Loss: 4.5438
Training Epoch: 0 [13824/50176]	Loss: 4.5639
Training Epoch: 0 [14336/50176]	Loss: 4.5212
Training Epoch: 0 [14848/50176]	Loss: 4.5012
Training Epoch: 0 [15360/50176]	Loss: 4.4952
Training Epoch: 0 [15872/50176]	Loss: 4.4575
Training Epoch: 0 [16384/50176]	Loss: 4.4652
Training Epoch: 0 [16896/50176]	Loss: 4.4692
Training Epoch: 0 [17408/50176]	Loss: 4.5301
Training Epoch: 0 [17920/50176]	Loss: 4.5040
Training Epoch: 0 [18432/50176]	Loss: 4.4332
Training Epoch: 0 [18944/50176]	Loss: 4.4495
Training Epoch: 0 [19456/50176]	Loss: 4.4580
Training Epoch: 0 [19968/50176]	Loss: 4.4284
Training Epoch: 0 [20480/50176]	Loss: 4.4309
Training Epoch: 0 [20992/50176]	Loss: 4.4023
Training Epoch: 0 [21504/50176]	Loss: 4.4338
Training Epoch: 0 [22016/50176]	Loss: 4.4384
Training Epoch: 0 [22528/50176]	Loss: 4.3432
Training Epoch: 0 [23040/50176]	Loss: 4.3942
Training Epoch: 0 [23552/50176]	Loss: 4.4374
Training Epoch: 0 [24064/50176]	Loss: 4.4263
Training Epoch: 0 [24576/50176]	Loss: 4.3983
Training Epoch: 0 [25088/50176]	Loss: 4.3478
Training Epoch: 0 [25600/50176]	Loss: 4.3925
Profile done with power limit 100W
epoch 1 train time consumed: 66.16s
Validation Epoch: 0, Average loss: 0.0090, Accuracy: 0.0268
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 100000, 'lr': 0.008, 'energy': 104.40182747563215, 'time': 52.12807164900005, 'accuracy': 0.0267578125, 'total_cost': 2175263.1876476174}

[Power Profiler] with batch size 512 and learning rate 0.0096
[run job] Launching job with BS 512: and LR: 0.0096 and PL: 175
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00960+pl175', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0096', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '175', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0096', '--power_limit', '175']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00960+pl175.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 175
learning rate arg: 0.0096
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 175W.
Warm-up started with power limit 175W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 7.0369
Training Epoch: 0 [1536/50176]	Loss: 5.2669
Training Epoch: 0 [2048/50176]	Loss: 4.6948
Training Epoch: 0 [2560/50176]	Loss: 4.8467
Training Epoch: 0 [3072/50176]	Loss: 4.6838
Training Epoch: 0 [3584/50176]	Loss: 4.5818
Training Epoch: 0 [4096/50176]	Loss: 4.8714
Training Epoch: 0 [4608/50176]	Loss: 4.6816
Training Epoch: 0 [5120/50176]	Loss: 4.6015
Training Epoch: 0 [5632/50176]	Loss: 4.6435
Training Epoch: 0 [6144/50176]	Loss: 4.5954
Training Epoch: 0 [6656/50176]	Loss: 4.7010
Training Epoch: 0 [7168/50176]	Loss: 4.5767
Training Epoch: 0 [7680/50176]	Loss: 4.5588
Training Epoch: 0 [8192/50176]	Loss: 4.6292
Training Epoch: 0 [8704/50176]	Loss: 4.6165
Training Epoch: 0 [9216/50176]	Loss: 4.5710
Training Epoch: 0 [9728/50176]	Loss: 4.5478
Training Epoch: 0 [10240/50176]	Loss: 4.6179
Training Epoch: 0 [10752/50176]	Loss: 4.5301
Training Epoch: 0 [11264/50176]	Loss: 4.5396
Training Epoch: 0 [11776/50176]	Loss: 4.5455
Training Epoch: 0 [12288/50176]	Loss: 4.6152
Training Epoch: 0 [12800/50176]	Loss: 4.6380
Training Epoch: 0 [13312/50176]	Loss: 4.5504
Training Epoch: 0 [13824/50176]	Loss: 4.5496
Training Epoch: 0 [14336/50176]	Loss: 4.5195
Training Epoch: 0 [14848/50176]	Loss: 4.4837
Training Epoch: 0 [15360/50176]	Loss: 4.5337
Training Epoch: 0 [15872/50176]	Loss: 4.5043
Training Epoch: 0 [16384/50176]	Loss: 4.4701
Training Epoch: 0 [16896/50176]	Loss: 4.5079
Training Epoch: 0 [17408/50176]	Loss: 4.5095
Training Epoch: 0 [17920/50176]	Loss: 4.5978
Training Epoch: 0 [18432/50176]	Loss: 4.4450
Training Epoch: 0 [18944/50176]	Loss: 4.4718
Training Epoch: 0 [19456/50176]	Loss: 4.4314
Training Epoch: 0 [19968/50176]	Loss: 4.3829
Training Epoch: 0 [20480/50176]	Loss: 4.4240
Training Epoch: 0 [20992/50176]	Loss: 4.3560
Training Epoch: 0 [21504/50176]	Loss: 4.3712
Training Epoch: 0 [22016/50176]	Loss: 4.4753
Training Epoch: 0 [22528/50176]	Loss: 4.4356
Training Epoch: 0 [23040/50176]	Loss: 4.4467
Training Epoch: 0 [23552/50176]	Loss: 4.5402
Training Epoch: 0 [24064/50176]	Loss: 4.4217
Training Epoch: 0 [24576/50176]	Loss: 4.3616
Training Epoch: 0 [25088/50176]	Loss: 4.4381
Training Epoch: 0 [25600/50176]	Loss: 4.3789
Profile done with power limit 175W
epoch 1 train time consumed: 23.90s
Validation Epoch: 0, Average loss: 0.0105, Accuracy: 0.0186
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 175000, 'lr': 0.0096, 'energy': 155.31576707086091, 'time': 18.265146060000006, 'accuracy': 0.0185546875, 'total_cost': 1100790.7853689662}
[run job] Launching job with BS 512: and LR: 0.0096 and PL: 150
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00960+pl150', 'ZEUS_COST_THRESH': '2201581.5707379323', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0096', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '150', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0096', '--power_limit', '150']
[run job] cost_ub=2201581.5707379323
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00960+pl150.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 150
learning rate arg: 0.0096
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 150W.
Warm-up started with power limit 150W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 7.0369
Training Epoch: 0 [1536/50176]	Loss: 5.2669
Training Epoch: 0 [2048/50176]	Loss: 4.6951
Training Epoch: 0 [2560/50176]	Loss: 4.8518
Training Epoch: 0 [3072/50176]	Loss: 4.6862
Training Epoch: 0 [3584/50176]	Loss: 4.5842
Training Epoch: 0 [4096/50176]	Loss: 5.0070
Training Epoch: 0 [4608/50176]	Loss: 5.7272
Training Epoch: 0 [5120/50176]	Loss: 4.6441
Training Epoch: 0 [5632/50176]	Loss: 4.6231
Training Epoch: 0 [6144/50176]	Loss: 4.6107
Training Epoch: 0 [6656/50176]	Loss: 4.7048
Training Epoch: 0 [7168/50176]	Loss: 4.5956
Training Epoch: 0 [7680/50176]	Loss: 4.6234
Training Epoch: 0 [8192/50176]	Loss: 4.7895
Training Epoch: 0 [8704/50176]	Loss: 4.7013
Training Epoch: 0 [9216/50176]	Loss: 4.6673
Training Epoch: 0 [9728/50176]	Loss: 4.6447
Training Epoch: 0 [10240/50176]	Loss: 4.6469
Training Epoch: 0 [10752/50176]	Loss: 4.6220
Training Epoch: 0 [11264/50176]	Loss: 4.6003
Training Epoch: 0 [11776/50176]	Loss: 4.5768
Training Epoch: 0 [12288/50176]	Loss: 4.6002
Training Epoch: 0 [12800/50176]	Loss: 4.6407
Training Epoch: 0 [13312/50176]	Loss: 4.6511
Training Epoch: 0 [13824/50176]	Loss: 4.5948
Training Epoch: 0 [14336/50176]	Loss: 4.5749
Training Epoch: 0 [14848/50176]	Loss: 4.5443
Training Epoch: 0 [15360/50176]	Loss: 4.5637
Training Epoch: 0 [15872/50176]	Loss: 4.5184
Training Epoch: 0 [16384/50176]	Loss: 4.5073
Training Epoch: 0 [16896/50176]	Loss: 4.5308
Training Epoch: 0 [17408/50176]	Loss: 4.5702
Training Epoch: 0 [17920/50176]	Loss: 4.6167
Training Epoch: 0 [18432/50176]	Loss: 4.4923
Training Epoch: 0 [18944/50176]	Loss: 4.4966
Training Epoch: 0 [19456/50176]	Loss: 4.4951
Training Epoch: 0 [19968/50176]	Loss: 4.4584
Training Epoch: 0 [20480/50176]	Loss: 4.4299
Training Epoch: 0 [20992/50176]	Loss: 4.4247
Training Epoch: 0 [21504/50176]	Loss: 4.4673
Training Epoch: 0 [22016/50176]	Loss: 4.5218
Training Epoch: 0 [22528/50176]	Loss: 4.4575
Training Epoch: 0 [23040/50176]	Loss: 4.4530
Training Epoch: 0 [23552/50176]	Loss: 4.4827
Training Epoch: 0 [24064/50176]	Loss: 4.4684
Training Epoch: 0 [24576/50176]	Loss: 4.4511
Training Epoch: 0 [25088/50176]	Loss: 4.4060
Training Epoch: 0 [25600/50176]	Loss: 4.4014
Profile done with power limit 150W
epoch 1 train time consumed: 24.63s
Validation Epoch: 0, Average loss: 0.0089, Accuracy: 0.0189
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 150000, 'lr': 0.0096, 'energy': 147.1554368061888, 'time': 18.852905548000308, 'accuracy': 0.0189453125, 'total_cost': 1112609.1944867838}
[run job] Launching job with BS 512: and LR: 0.0096 and PL: 125
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00960+pl125', 'ZEUS_COST_THRESH': '2201581.5707379323', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0096', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '125', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0096', '--power_limit', '125']
[run job] cost_ub=2201581.5707379323
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00960+pl125.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 125
learning rate arg: 0.0096
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 125W.
Warm-up started with power limit 125W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 7.0369
Training Epoch: 0 [1536/50176]	Loss: 5.2666
Training Epoch: 0 [2048/50176]	Loss: 4.6941
Training Epoch: 0 [2560/50176]	Loss: 4.8603
Training Epoch: 0 [3072/50176]	Loss: 4.6867
Training Epoch: 0 [3584/50176]	Loss: 4.5824
Training Epoch: 0 [4096/50176]	Loss: 4.7066
Training Epoch: 0 [4608/50176]	Loss: 4.7345
Training Epoch: 0 [5120/50176]	Loss: 4.6012
Training Epoch: 0 [5632/50176]	Loss: 4.6487
Training Epoch: 0 [6144/50176]	Loss: 4.6085
Training Epoch: 0 [6656/50176]	Loss: 4.6780
Training Epoch: 0 [7168/50176]	Loss: 4.5858
Training Epoch: 0 [7680/50176]	Loss: 4.5772
Training Epoch: 0 [8192/50176]	Loss: 4.5861
Training Epoch: 0 [8704/50176]	Loss: 4.5965
Training Epoch: 0 [9216/50176]	Loss: 4.5650
Training Epoch: 0 [9728/50176]	Loss: 4.5633
Training Epoch: 0 [10240/50176]	Loss: 4.5626
Training Epoch: 0 [10752/50176]	Loss: 4.5327
Training Epoch: 0 [11264/50176]	Loss: 4.5311
Training Epoch: 0 [11776/50176]	Loss: 4.5396
Training Epoch: 0 [12288/50176]	Loss: 4.6413
Training Epoch: 0 [12800/50176]	Loss: 4.6610
Training Epoch: 0 [13312/50176]	Loss: 4.5680
Training Epoch: 0 [13824/50176]	Loss: 4.5288
Training Epoch: 0 [14336/50176]	Loss: 4.5127
Training Epoch: 0 [14848/50176]	Loss: 4.4923
Training Epoch: 0 [15360/50176]	Loss: 4.5218
Training Epoch: 0 [15872/50176]	Loss: 4.5068
Training Epoch: 0 [16384/50176]	Loss: 4.4409
Training Epoch: 0 [16896/50176]	Loss: 4.4903
Training Epoch: 0 [17408/50176]	Loss: 4.5271
Training Epoch: 0 [17920/50176]	Loss: 4.5629
Training Epoch: 0 [18432/50176]	Loss: 4.4467
Training Epoch: 0 [18944/50176]	Loss: 4.4710
Training Epoch: 0 [19456/50176]	Loss: 4.4407
Training Epoch: 0 [19968/50176]	Loss: 4.4130
Training Epoch: 0 [20480/50176]	Loss: 4.4165
Training Epoch: 0 [20992/50176]	Loss: 4.3439
Training Epoch: 0 [21504/50176]	Loss: 4.3657
Training Epoch: 0 [22016/50176]	Loss: 4.4571
Training Epoch: 0 [22528/50176]	Loss: 4.3922
Training Epoch: 0 [23040/50176]	Loss: 4.4544
Training Epoch: 0 [23552/50176]	Loss: 4.4598
Training Epoch: 0 [24064/50176]	Loss: 4.4739
Training Epoch: 0 [24576/50176]	Loss: 4.4116
Training Epoch: 0 [25088/50176]	Loss: 4.3987
Training Epoch: 0 [25600/50176]	Loss: 4.3738
Profile done with power limit 125W
epoch 1 train time consumed: 28.38s
Validation Epoch: 0, Average loss: 0.0097, Accuracy: 0.0184
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 125000, 'lr': 0.0096, 'energy': 122.78084887609639, 'time': 21.854060644999663, 'accuracy': 0.018359375, 'total_cost': 1330220.3549561386}
[run job] Launching job with BS 512: and LR: 0.0096 and PL: 100
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948', 'ZEUS_JOB_ID': 'bs512+lr0.00960+pl100', 'ZEUS_COST_THRESH': '2201581.5707379323', 'ZEUS_BATCH_SIZE': '512', 'ZEUS_LEARNING_RATE': '0.0096', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_POWER_LIMIT': '100', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_LOG_PREFIX': '/workspace/zeus_logs'}
[run job] cwd=/workspace/zeus/zeus2
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '512', '--epochs', '100', '--seed', '1', '--learning_rate', '0.0096', '--power_limit', '100']
[run job] cost_ub=2201581.5707379323
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs8+adam+lr0.001+tm0.5+me100+eta0.5+beta2.0+2022112613391669487948/bs512+lr0.00960+pl100.train.log'
Files already downloaded and verified
Files already downloaded and verified
power limit arg: 100
learning rate arg: 0.0096
batch size arg: 512
ProfileDataLoader constructor: called constructor of DataLoader!
ProfileDataLoader constructor: called constructor of DataLoader!
Launching Zeus monitor 0...
[GPU_0] Set GPU power limit to 100W.
Warm-up started with power limit 100W
Training Epoch: 0 [512/50176]	Loss: 4.6290
Training Epoch: 0 [1024/50176]	Loss: 7.0369
Training Epoch: 0 [1536/50176]	Loss: 5.2666
Training Epoch: 0 [2048/50176]	Loss: 4.6916
Training Epoch: 0 [2560/50176]	Loss: 4.9103
Training Epoch: 0 [3072/50176]	Loss: 4.6876
Training Epoch: 0 [3584/50176]	Loss: 4.5829
Training Epoch: 0 [4096/50176]	Loss: 4.6934
Training Epoch: 0 [4608/50176]	Loss: 4.6852
Training Epoch: 0 [5120/50176]	Loss: 4.6168
Training Epoch: 0 [5632/50176]	Loss: 4.6297
Training Epoch: 0 [6144/50176]	Loss: 4.5927
Training Epoch: 0 [6656/50176]	Loss: 4.6952
Training Epoch: 0 [7168/50176]	Loss: 4.5961
Training Epoch: 0 [7680/50176]	Loss: 4.5882
Training Epoch: 0 [8192/50176]	Loss: 4.6092
Training Epoch: 0 [8704/50176]	Loss: 4.6139
Training Epoch: 0 [9216/50176]	Loss: 4.6041
Training Epoch: 0 [9728/50176]	Loss: 4.6394
Training Epoch: 0 [10240/50176]	Loss: 4.5639
Training Epoch: 0 [10752/50176]	Loss: 4.5469
Training Epoch: 0 [11264/50176]	Loss: 4.5567
Training Epoch: 0 [11776/50176]	Loss: 4.5907
Training Epoch: 0 [12288/50176]	Loss: 4.6674
Training Epoch: 0 [12800/50176]	Loss: 4.6166
Training Epoch: 0 [13312/50176]	Loss: 4.6012
Training Epoch: 0 [13824/50176]	Loss: 4.5945
Training Epoch: 0 [14336/50176]	Loss: 4.5398
Training Epoch: 0 [14848/50176]	Loss: 4.5495
Training Epoch: 0 [15360/50176]	Loss: 4.5422
Training Epoch: 0 [15872/50176]	Loss: 4.5230
Training Epoch: 0 [16384/50176]	Loss: 4.4756
Training Epoch: 0 [16896/50176]	Loss: 4.4959
Training Epoch: 0 [17408/50176]	Loss: 4.5165
Training Epoch: 0 [17920/50176]	Loss: 4.6495
Training Epoch: 0 [18432/50176]	Loss: 4.4697
Training Epoch: 0 [18944/50176]	Loss: 4.4929
Training Epoch: 0 [19456/50176]	Loss: 4.4738
Training Epoch: 0 [19968/50176]	Loss: 4.4639
Training Epoch: 0 [20480/50176]	Loss: 4.4376
Training Epoch: 0 [20992/50176]	Loss: 4.4073
Training Epoch: 0 [21504/50176]	Loss: 4.4372
Training Epoch: 0 [22016/50176]	Loss: 4.5135
Training Epoch: 0 [22528/50176]	Loss: 4.4261
Training Epoch: 0 [23040/50176]	Loss: 4.4609
Training Epoch: 0 [23552/50176]	Loss: 4.5187
Training Epoch: 0 [24064/50176]	Loss: 4.4672
Training Epoch: 0 [24576/50176]	Loss: 4.4283
Training Epoch: 0 [25088/50176]	Loss: 4.4821
Training Epoch: 0 [25600/50176]	Loss: 4.3995
Profile done with power limit 100W
epoch 1 train time consumed: 66.13s
Validation Epoch: 0, Average loss: 0.0101, Accuracy: 0.0194
Stopped Zeus monitor 0.

[run job] Job terminated with exit code 0.
[run job] stats={'bs': 512, 'pl': 100000, 'lr': 0.0096, 'energy': 104.40500870325072, 'time': 52.10634294400006, 'accuracy': 0.01943359375, 'total_cost': 2993838.15913794}
[Power Profiler]
[HistoryEntry(bs=8, pl=175, energy=97.75108605305954, time=2.214743546999671, accuracy=0.0118, total_cost=3317.713255653092), HistoryEntry(bs=8, pl=150, energy=99.9819681527312, time=2.1725833950004017, accuracy=0.0131, total_cost=2932.8349072609126), HistoryEntry(bs=8, pl=125, energy=100.77161556104932, time=2.2163420710003265, accuracy=0.0103, total_cost=3804.7643402669814), HistoryEntry(bs=8, pl=100, energy=97.99115913009724, time=2.2401014269998996, accuracy=0.0111, total_cost=3567.0035683800565), HistoryEntry(bs=8, pl=175, energy=103.5316350735005, time=2.1396361090000937, accuracy=0.0131, total_cost=2889.9052250225686), HistoryEntry(bs=8, pl=150, energy=105.71358638633863, time=2.077709589000733, accuracy=0.0117, total_cost=3143.8266797485626), HistoryEntry(bs=8, pl=125, energy=103.66378236774052, time=2.140584773000228, accuracy=0.0117, total_cost=3237.16997068162), HistoryEntry(bs=8, pl=100, energy=96.84755958985113, time=2.2785308219999933, accuracy=0.0113, total_cost=3562.9804976424157), HistoryEntry(bs=8, pl=175, energy=103.61932284042622, time=2.11055593600031, accuracy=0.0108, total_cost=3458.2598306821415), HistoryEntry(bs=8, pl=150, energy=105.44767274031068, time=2.0632556869995824, accuracy=0.0102, total_cost=3581.251491515092), HistoryEntry(bs=8, pl=125, energy=104.64361946978879, time=2.1366213340006652, accuracy=0.01, total_cost=3780.9447822890797), HistoryEntry(bs=8, pl=100, energy=98.85381112977177, time=2.1527620870001556, accuracy=0.011, total_cost=3460.7956151838007), HistoryEntry(bs=16, pl=175, energy=119.16474429591176, time=2.399495442999978, accuracy=0.0136, total_cost=6245.2690043651855), HistoryEntry(bs=16, pl=150, energy=119.00673838707917, time=2.428186985999673, accuracy=0.0155, total_cost=5544.425704328077), HistoryEntry(bs=16, pl=125, energy=118.46771862727344, time=2.377351772000111, accuracy=0.0124, total_cost=6786.697884598553), HistoryEntry(bs=16, pl=100, energy=98.80763278300427, time=2.764119159999609, accuracy=0.0117, total_cost=8336.293304465842), HistoryEntry(bs=16, pl=175, energy=119.16706917530874, time=2.379566980999698, accuracy=0.0127, total_cost=6632.927629007235), HistoryEntry(bs=16, pl=150, energy=119.536327530137, time=2.405282826000075, accuracy=0.0113, total_cost=7534.6185424994455), HistoryEntry(bs=16, pl=125, energy=119.09760162455575, time=2.385159720000047, accuracy=0.0115, total_cost=7342.032261999832), HistoryEntry(bs=16, pl=100, energy=98.86307504392245, time=2.720416665999437, accuracy=0.0107, total_cost=8972.475505638475), HistoryEntry(bs=16, pl=175, energy=120.03575224834562, time=2.36030059299992, accuracy=0.0137, total_cost=6100.058888538975), HistoryEntry(bs=16, pl=150, energy=119.10154138373669, time=2.380568048999521, accuracy=0.0181, total_cost=4655.949947295753), HistoryEntry(bs=16, pl=125, energy=118.21730940759197, time=2.453952830000162, accuracy=0.0183, total_cost=4745.032105205814), HistoryEntry(bs=16, pl=100, energy=98.71348214406946, time=2.781845909999902, accuracy=0.0129, total_cost=7608.861605205358), HistoryEntry(bs=32, pl=175, energy=134.39973256858428, time=3.211133675000383, accuracy=0.022863418530351436, total_cost=9922.276425075765), HistoryEntry(bs=32, pl=150, energy=134.73216590648912, time=3.2192176340004153, accuracy=0.023063099041533548, total_cost=9861.128012758349), HistoryEntry(bs=32, pl=125, energy=123.95053005834089, time=3.311414985999363, accuracy=0.019768370607028754, total_cost=11822.29308403585), HistoryEntry(bs=32, pl=100, energy=99.14109322039597, time=4.215710283999215, accuracy=0.02336261980830671, total_cost=12695.11170678655), HistoryEntry(bs=32, pl=175, energy=132.32088611587577, time=3.295887951999248, accuracy=0.02406150159744409, total_cost=9673.328505131878), HistoryEntry(bs=32, pl=150, energy=134.38611198381696, time=3.262331803000052, accuracy=0.02825479233226837, total_cost=8155.7726774127495), HistoryEntry(bs=32, pl=125, energy=122.52282521081285, time=3.3966093929993804, accuracy=0.027256389776357828, total_cost=8792.29926825141), HistoryEntry(bs=32, pl=100, energy=99.24976024989799, time=4.28600145099972, accuracy=0.021665335463258786, total_cost=13916.775695848903), HistoryEntry(bs=32, pl=175, energy=135.17509046388213, time=3.1425559039998916, accuracy=0.02336261980830671, total_cost=9505.383126586603), HistoryEntry(bs=32, pl=150, energy=134.54793800671587, time=3.221142706000137, accuracy=0.025059904153354632, total_cost=9080.638770828476), HistoryEntry(bs=32, pl=125, energy=123.407782296289, time=3.338589549000062, accuracy=0.012679712460063898, total_cost=18580.894603133274), HistoryEntry(bs=32, pl=100, energy=99.23250042026665, time=4.241730383000686, accuracy=0.017472044728434506, total_cost=17079.47519489072), HistoryEntry(bs=64, pl=175, energy=145.10972820806694, time=5.261411970000154, accuracy=0.016321656050955414, total_cost=45371.02581526445), HistoryEntry(bs=64, pl=150, energy=146.32442579153795, time=5.249690893999286, accuracy=0.018411624203821655, total_cost=40133.87010620067), HistoryEntry(bs=64, pl=125, energy=122.99167093461277, time=5.858322099000361, accuracy=0.01741640127388535, total_cost=47272.133683158), HistoryEntry(bs=64, pl=100, energy=99.27927074219913, time=12.526939458000015, accuracy=0.022492038216560508, total_cost=78039.32178186439), HistoryEntry(bs=64, pl=175, energy=145.7028131758694, time=5.22996264899939, accuracy=0.02119824840764331, total_cost=34726.95206656886), HistoryEntry(bs=64, pl=150, energy=145.8979284030171, time=5.247484172000441, accuracy=0.0120421974522293, total_cost=61334.93970369811), HistoryEntry(bs=64, pl=125, energy=123.16743348535297, time=5.865504272999715, accuracy=0.024582006369426753, total_cost=33533.49583916567), HistoryEntry(bs=64, pl=100, energy=99.61297737397913, time=12.508404917999542, accuracy=0.01552547770700637, total_cost=112890.6795920867), HistoryEntry(bs=64, pl=175, energy=145.25828745877072, time=5.233205909999924, accuracy=0.019605891719745222, total_cost=37569.82731314708), HistoryEntry(bs=64, pl=150, energy=145.52415454699613, time=5.262827325000217, accuracy=0.01721735668789809, total_cost=43022.9506216271), HistoryEntry(bs=64, pl=125, energy=123.09051693515889, time=5.87623262499983, accuracy=0.021695859872611464, total_cost=38063.42237458014), HistoryEntry(bs=64, pl=100, energy=99.35673791499923, time=12.526997709999705, accuracy=0.019605891719745222, total_cost=89527.88564953797), HistoryEntry(bs=128, pl=175, energy=148.9784703180723, time=8.581660894999914, accuracy=0.032634493670886076, total_cost=73850.87737089292), HistoryEntry(bs=128, pl=150, energy=147.0278171473753, time=8.674355674999788, accuracy=0.030557753164556962, total_cost=79714.33308274878), HistoryEntry(bs=128, pl=125, energy=123.18685461386492, time=9.77295614400009, accuracy=0.035799050632911396, total_cost=76585.26184532142), HistoryEntry(bs=128, pl=100, energy=99.81397833826829, time=21.101496047999717, accuracy=0.031942246835443035, total_cost=184994.31958074955), HistoryEntry(bs=128, pl=175, energy=148.8167006289492, time=8.586337287999413, accuracy=0.035700158227848104, total_cost=67545.46480326989), HistoryEntry(bs=128, pl=150, energy=147.1548925032678, time=8.657553351999923, accuracy=0.033128955696202535, total_cost=73385.9202514543), HistoryEntry(bs=128, pl=125, energy=123.1703149009547, time=9.75116239899944, accuracy=0.028481012658227847, total_cost=96049.33103243413), HistoryEntry(bs=128, pl=100, energy=99.58444681957485, time=21.132204231999822, accuracy=0.031546677215189875, total_cost=187585.82870661828), HistoryEntry(bs=128, pl=175, energy=149.0205349970376, time=8.582197853999787, accuracy=0.029568829113924052, total_cost=81512.82807800097), HistoryEntry(bs=128, pl=150, energy=147.41780777783632, time=8.644098458999906, accuracy=0.0200751582278481, total_cost=120918.19784385287), HistoryEntry(bs=128, pl=125, energy=123.38598166462499, time=9.740170862999548, accuracy=0.03372231012658228, total_cost=81030.07515613262), HistoryEntry(bs=128, pl=100, energy=99.17341922530359, time=21.13086388800002, accuracy=0.02185522151898734, total_cost=270750.3269318511), HistoryEntry(bs=256, pl=175, energy=155.91938687912497, time=9.552171844999975, accuracy=0.03623046875, total_cost=147675.17230652165), HistoryEntry(bs=256, pl=150, energy=147.4030785013206, time=9.83002341700012, accuracy=0.04287109375, total_cost=128392.00194245356), HistoryEntry(bs=256, pl=125, energy=123.29927210807593, time=11.289662802000748, accuracy=0.04052734375, total_cost=155839.52485739498), HistoryEntry(bs=256, pl=100, energy=103.70600854399089, time=29.120980145999965, accuracy=0.03525390625, total_cost=461332.5583937365), HistoryEntry(bs=256, pl=175, energy=155.90059069301043, time=9.537220911999611, accuracy=0.03369140625, total_cost=158556.61006591207), HistoryEntry(bs=256, pl=150, energy=145.82195437352894, time=9.866974491000292, accuracy=0.0265625, total_cost=207989.60553421278), HistoryEntry(bs=256, pl=125, energy=123.36524310632723, time=11.229428693000045, accuracy=0.03037109375, total_cost=206846.6047377661), HistoryEntry(bs=256, pl=100, energy=103.64135022267682, time=29.25982000699969, accuracy=0.0294921875, total_cost=554087.2177574108), HistoryEntry(bs=256, pl=175, energy=155.47073581725616, time=9.557385568000427, accuracy=0.03193359375, total_cost=167635.15484818222), HistoryEntry(bs=256, pl=150, energy=147.12001266866085, time=9.834012895999876, accuracy=0.02470703125, total_cost=222871.6053634556), HistoryEntry(bs=256, pl=125, energy=123.08172107379892, time=11.268294911999874, accuracy=0.0224609375, total_cost=280656.59321283834), HistoryEntry(bs=256, pl=100, energy=103.88811103396927, time=28.756018905999554, accuracy=0.01572265625, total_cost=1021464.5877533336), HistoryEntry(bs=512, pl=175, energy=155.35449930459717, time=18.259374762000334, accuracy=0.04404296875, total_cost=463601.75766465336), HistoryEntry(bs=512, pl=150, energy=147.14267818165072, time=18.868340670999714, accuracy=0.04365234375, total_cost=483271.92798096576), HistoryEntry(bs=512, pl=125, energy=122.70043395781727, time=21.921265439999843, accuracy=0.0455078125, total_cost=538303.1576572879), HistoryEntry(bs=512, pl=100, energy=104.45880232575144, time=52.132640353999705, accuracy=0.04580078125, total_cost=1270947.7100621178), HistoryEntry(bs=512, pl=175, energy=155.53172338170768, time=18.256932941999366, accuracy=0.02587890625, total_cost=788894.1477175589), HistoryEntry(bs=512, pl=150, energy=147.1116439254758, time=18.857723672000247, accuracy=0.03974609375, total_cost=530469.6157419946), HistoryEntry(bs=512, pl=125, energy=122.8194037242472, time=21.874707311999373, accuracy=0.0208984375, total_cost=1169707.8941823721), HistoryEntry(bs=512, pl=100, energy=104.40182747563215, time=52.12807164900005, accuracy=0.0267578125, total_cost=2175263.1876476174), HistoryEntry(bs=512, pl=175, energy=155.31576707086091, time=18.265146060000006, accuracy=0.0185546875, total_cost=1100790.7853689662), HistoryEntry(bs=512, pl=150, energy=147.1554368061888, time=18.852905548000308, accuracy=0.0189453125, total_cost=1112609.1944867838), HistoryEntry(bs=512, pl=125, energy=122.78084887609639, time=21.854060644999663, accuracy=0.018359375, total_cost=1330220.3549561386), HistoryEntry(bs=512, pl=100, energy=104.40500870325072, time=52.10634294400006, accuracy=0.01943359375, total_cost=2993838.15913794)]
optimized batch size: 64, learning rate: 0.0028284271247461905, power limit: 125
