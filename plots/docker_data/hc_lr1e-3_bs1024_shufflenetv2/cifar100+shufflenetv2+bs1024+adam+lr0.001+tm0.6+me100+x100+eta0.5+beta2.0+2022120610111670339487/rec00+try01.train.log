2022-12-06 10:11:31,368 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 10:11:31,368 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 10:11:31,368 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 10:11:31,410 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 10:11:31,410 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 10:11:33,494 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 10:11:33,495 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 10:11:33,616 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:11:33.644 [ZeusMonitor] Monitor started.
2022-12-06 15:11:33.644 [ZeusMonitor] Running indefinitely. 2022-12-06 15:11:33.644 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:11:33.644 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e1+gpu0.power.log
2022-12-06 10:11:34,487 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 10:11:34,487 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 10:11:45,374 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 10:12:18,532 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 10:12:20,167 [ZeusDataLoader(train)] train epoch 1 done: time=46.67 energy=6283.61
2022-12-06 10:12:20,170 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 4.6455
Training Epoch: 0 [3072/50176]	Loss: 4.6298
Training Epoch: 0 [4096/50176]	Loss: 4.6002
Training Epoch: 0 [5120/50176]	Loss: 4.5613
Training Epoch: 0 [6144/50176]	Loss: 4.5409
Training Epoch: 0 [7168/50176]	Loss: 4.5779
Training Epoch: 0 [8192/50176]	Loss: 4.5486
Training Epoch: 0 [9216/50176]	Loss: 4.5317
Training Epoch: 0 [10240/50176]	Loss: 4.5301
Training Epoch: 0 [11264/50176]	Loss: 4.4870
Training Epoch: 0 [12288/50176]	Loss: 4.5020
Training Epoch: 0 [13312/50176]	Loss: 4.4530
Training Epoch: 0 [14336/50176]	Loss: 4.4512
Training Epoch: 0 [15360/50176]	Loss: 4.4226
Training Epoch: 0 [16384/50176]	Loss: 4.4130
Training Epoch: 0 [17408/50176]	Loss: 4.4231
Training Epoch: 0 [18432/50176]	Loss: 4.4170
Training Epoch: 0 [19456/50176]	Loss: 4.3521
Training Epoch: 0 [20480/50176]	Loss: 4.3214
Training Epoch: 0 [21504/50176]	Loss: 4.3032
Training Epoch: 0 [22528/50176]	Loss: 4.2873
Training Epoch: 0 [23552/50176]	Loss: 4.2626
Training Epoch: 0 [24576/50176]	Loss: 4.2654
Training Epoch: 0 [25600/50176]	Loss: 4.2388
Training Epoch: 0 [26624/50176]	Loss: 4.1761
Training Epoch: 0 [27648/50176]	Loss: 4.2091
Training Epoch: 0 [28672/50176]	Loss: 4.1001
Training Epoch: 0 [29696/50176]	Loss: 4.1651
Training Epoch: 0 [30720/50176]	Loss: 4.1833
Training Epoch: 0 [31744/50176]	Loss: 4.1902
Training Epoch: 0 [32768/50176]	Loss: 4.0997
Training Epoch: 0 [33792/50176]	Loss: 4.0877
Training Epoch: 0 [34816/50176]	Loss: 4.1148
Training Epoch: 0 [35840/50176]	Loss: 4.0296
Training Epoch: 0 [36864/50176]	Loss: 4.0001
Training Epoch: 0 [37888/50176]	Loss: 4.0467
Training Epoch: 0 [38912/50176]	Loss: 4.0072
Training Epoch: 0 [39936/50176]	Loss: 3.9766
Training Epoch: 0 [40960/50176]	Loss: 3.9725
Training Epoch: 0 [41984/50176]	Loss: 3.9454
Training Epoch: 0 [43008/50176]	Loss: 4.0701
Training Epoch: 0 [44032/50176]	Loss: 3.9111
Training Epoch: 0 [45056/50176]	Loss: 3.9685
Training Epoch: 0 [46080/50176]	Loss: 3.9471
Training Epoch: 0 [47104/50176]	Loss: 3.9407
Training Epoch: 0 [48128/50176]	Loss: 3.9102
Training Epoch: 0 [49152/50176]	Loss: 3.9587
Training Epoch: 0 [50176/50176]	Loss: 3.8780
2022-12-06 15:12:23.886 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:12:23,926 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.75 energy=475.25
2022-12-06 10:12:23,927 [ZeusDataLoader(train)] Up to epoch 1: time=50.41, energy=6758.86, cost=7790.69
2022-12-06 10:12:23,928 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0043, Accuracy: 0.0601
2022-12-06 10:12:24,108 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:12:24.110 [ZeusMonitor] Monitor started.
2022-12-06 15:12:24.110 [ZeusMonitor] Running indefinitely. 2022-12-06 15:12:24.110 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:12:24.110 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e2+gpu0.power.log
2022-12-06 10:12:24,817 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 10:12:24,818 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 10:12:32,836 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 10:13:06,150 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 10:13:07,796 [ZeusDataLoader(train)] train epoch 2 done: time=43.86 energy=6145.92
2022-12-06 10:13:07,799 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 3.8331
Training Epoch: 1 [2048/50176]	Loss: 3.8346
Training Epoch: 1 [3072/50176]	Loss: 3.8690
Training Epoch: 1 [4096/50176]	Loss: 3.7973
Training Epoch: 1 [5120/50176]	Loss: 3.7616
Training Epoch: 1 [6144/50176]	Loss: 3.7889
Training Epoch: 1 [7168/50176]	Loss: 3.7646
Training Epoch: 1 [8192/50176]	Loss: 3.7304
Training Epoch: 1 [9216/50176]	Loss: 3.8546
Training Epoch: 1 [10240/50176]	Loss: 3.8196
Training Epoch: 1 [11264/50176]	Loss: 3.8218
Training Epoch: 1 [12288/50176]	Loss: 3.7495
Training Epoch: 1 [13312/50176]	Loss: 3.7004
Training Epoch: 1 [14336/50176]	Loss: 3.8147
Training Epoch: 1 [15360/50176]	Loss: 3.7930
Training Epoch: 1 [16384/50176]	Loss: 3.7493
Training Epoch: 1 [17408/50176]	Loss: 3.7878
Training Epoch: 1 [18432/50176]	Loss: 3.6363
Training Epoch: 1 [19456/50176]	Loss: 3.7750
Training Epoch: 1 [20480/50176]	Loss: 3.6719
Training Epoch: 1 [21504/50176]	Loss: 3.7063
Training Epoch: 1 [22528/50176]	Loss: 3.7043
Training Epoch: 1 [23552/50176]	Loss: 3.6397
Training Epoch: 1 [24576/50176]	Loss: 3.6561
Training Epoch: 1 [25600/50176]	Loss: 3.6192
Training Epoch: 1 [26624/50176]	Loss: 3.7146
Training Epoch: 1 [27648/50176]	Loss: 3.6337
Training Epoch: 1 [28672/50176]	Loss: 3.5924
Training Epoch: 1 [29696/50176]	Loss: 3.6887
Training Epoch: 1 [30720/50176]	Loss: 3.6391
Training Epoch: 1 [31744/50176]	Loss: 3.6492
Training Epoch: 1 [32768/50176]	Loss: 3.6402
Training Epoch: 1 [33792/50176]	Loss: 3.6613
Training Epoch: 1 [34816/50176]	Loss: 3.6421
Training Epoch: 1 [35840/50176]	Loss: 3.6782
Training Epoch: 1 [36864/50176]	Loss: 3.5857
Training Epoch: 1 [37888/50176]	Loss: 3.5965
Training Epoch: 1 [38912/50176]	Loss: 3.6308
Training Epoch: 1 [39936/50176]	Loss: 3.6387
Training Epoch: 1 [40960/50176]	Loss: 3.6293
Training Epoch: 1 [41984/50176]	Loss: 3.5114
Training Epoch: 1 [43008/50176]	Loss: 3.6501
Training Epoch: 1 [44032/50176]	Loss: 3.5691
Training Epoch: 1 [45056/50176]	Loss: 3.5848
Training Epoch: 1 [46080/50176]	Loss: 3.5687
Training Epoch: 1 [47104/50176]	Loss: 3.6031
Training Epoch: 1 [48128/50176]	Loss: 3.6089
Training Epoch: 1 [49152/50176]	Loss: 3.6102
Training Epoch: 1 [50176/50176]	Loss: 3.5465
2022-12-06 15:13:11.502 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:13:11,557 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.75 energy=470.05
2022-12-06 10:13:11,557 [ZeusDataLoader(train)] Up to epoch 2: time=98.03, energy=13374.83, cost=15264.64
2022-12-06 10:13:11,558 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0036, Accuracy: 0.1343
2022-12-06 10:13:11,694 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:13:11.698 [ZeusMonitor] Monitor started.
2022-12-06 15:13:11.698 [ZeusMonitor] Running indefinitely. 2022-12-06 15:13:11.698 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:13:11.698 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e3+gpu0.power.log
2022-12-06 10:13:12,392 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 10:13:12,392 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 10:13:21,057 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 10:13:57,254 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 10:13:59,034 [ZeusDataLoader(train)] train epoch 3 done: time=47.47 energy=5713.12
2022-12-06 10:13:59,037 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.4916
Training Epoch: 2 [2048/50176]	Loss: 3.6014
Training Epoch: 2 [3072/50176]	Loss: 3.4593
Training Epoch: 2 [4096/50176]	Loss: 3.4473
Training Epoch: 2 [5120/50176]	Loss: 3.4870
Training Epoch: 2 [6144/50176]	Loss: 3.4857
Training Epoch: 2 [7168/50176]	Loss: 3.5391
Training Epoch: 2 [8192/50176]	Loss: 3.5404
Training Epoch: 2 [9216/50176]	Loss: 3.4838
Training Epoch: 2 [10240/50176]	Loss: 3.4100
Training Epoch: 2 [11264/50176]	Loss: 3.3810
Training Epoch: 2 [12288/50176]	Loss: 3.4276
Training Epoch: 2 [13312/50176]	Loss: 3.4210
Training Epoch: 2 [14336/50176]	Loss: 3.5067
Training Epoch: 2 [15360/50176]	Loss: 3.4661
Training Epoch: 2 [16384/50176]	Loss: 3.5282
Training Epoch: 2 [17408/50176]	Loss: 3.4963
Training Epoch: 2 [18432/50176]	Loss: 3.4531
Training Epoch: 2 [19456/50176]	Loss: 3.5040
Training Epoch: 2 [20480/50176]	Loss: 3.4175
Training Epoch: 2 [21504/50176]	Loss: 3.4731
Training Epoch: 2 [22528/50176]	Loss: 3.4497
Training Epoch: 2 [23552/50176]	Loss: 3.4216
Training Epoch: 2 [24576/50176]	Loss: 3.5063
Training Epoch: 2 [25600/50176]	Loss: 3.4601
Training Epoch: 2 [26624/50176]	Loss: 3.5414
Training Epoch: 2 [27648/50176]	Loss: 3.4912
Training Epoch: 2 [28672/50176]	Loss: 3.4812
Training Epoch: 2 [29696/50176]	Loss: 3.4225
Training Epoch: 2 [30720/50176]	Loss: 3.4752
Training Epoch: 2 [31744/50176]	Loss: 3.4174
Training Epoch: 2 [32768/50176]	Loss: 3.4740
Training Epoch: 2 [33792/50176]	Loss: 3.4550
Training Epoch: 2 [34816/50176]	Loss: 3.4549
Training Epoch: 2 [35840/50176]	Loss: 3.3702
Training Epoch: 2 [36864/50176]	Loss: 3.4719
Training Epoch: 2 [37888/50176]	Loss: 3.5048
Training Epoch: 2 [38912/50176]	Loss: 3.4188
Training Epoch: 2 [39936/50176]	Loss: 3.3315
Training Epoch: 2 [40960/50176]	Loss: 3.4047
Training Epoch: 2 [41984/50176]	Loss: 3.4013
Training Epoch: 2 [43008/50176]	Loss: 3.4062
Training Epoch: 2 [44032/50176]	Loss: 3.3281
Training Epoch: 2 [45056/50176]	Loss: 3.4023
Training Epoch: 2 [46080/50176]	Loss: 3.3698
Training Epoch: 2 [47104/50176]	Loss: 3.3452
Training Epoch: 2 [48128/50176]	Loss: 3.3615
Training Epoch: 2 [49152/50176]	Loss: 3.3583
Training Epoch: 2 [50176/50176]	Loss: 3.2981
2022-12-06 15:14:02.923 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:14:02,937 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.89 energy=438.90
2022-12-06 10:14:02,937 [ZeusDataLoader(train)] Up to epoch 3: time=149.39, energy=19526.84, cost=22834.82
2022-12-06 10:14:02,938 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0033, Accuracy: 0.1779
2022-12-06 10:14:03,075 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:14:03.077 [ZeusMonitor] Monitor started.
2022-12-06 15:14:03.077 [ZeusMonitor] Running indefinitely. 2022-12-06 15:14:03.077 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:14:03.077 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e4+gpu0.power.log
2022-12-06 10:14:03,778 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 10:14:03,778 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 10:14:19,829 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 10:15:20,691 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 10:15:20,691 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 10:15:20,691 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-06 10:15:20,694 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 10:15:22,445 [ZeusDataLoader(train)] train epoch 4 done: time=79.50 energy=7662.17
2022-12-06 10:15:22,449 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.2777
Training Epoch: 3 [2048/50176]	Loss: 3.2307
Training Epoch: 3 [3072/50176]	Loss: 3.2464
Training Epoch: 3 [4096/50176]	Loss: 3.3112
Training Epoch: 3 [5120/50176]	Loss: 3.2815
Training Epoch: 3 [6144/50176]	Loss: 3.3076
Training Epoch: 3 [7168/50176]	Loss: 3.3399
Training Epoch: 3 [8192/50176]	Loss: 3.2997
Training Epoch: 3 [9216/50176]	Loss: 3.2671
Training Epoch: 3 [10240/50176]	Loss: 3.2437
Training Epoch: 3 [11264/50176]	Loss: 3.3103
Training Epoch: 3 [12288/50176]	Loss: 3.2560
Training Epoch: 3 [13312/50176]	Loss: 3.3061
Training Epoch: 3 [14336/50176]	Loss: 3.1998
Training Epoch: 3 [15360/50176]	Loss: 3.2204
Training Epoch: 3 [16384/50176]	Loss: 3.2602
Training Epoch: 3 [17408/50176]	Loss: 3.2329
Training Epoch: 3 [18432/50176]	Loss: 3.2750
Training Epoch: 3 [19456/50176]	Loss: 3.2503
Training Epoch: 3 [20480/50176]	Loss: 3.1837
Training Epoch: 3 [21504/50176]	Loss: 3.2600
Training Epoch: 3 [22528/50176]	Loss: 3.2170
Training Epoch: 3 [23552/50176]	Loss: 3.2235
Training Epoch: 3 [24576/50176]	Loss: 3.2285
Training Epoch: 3 [25600/50176]	Loss: 3.1573
Training Epoch: 3 [26624/50176]	Loss: 3.2827
Training Epoch: 3 [27648/50176]	Loss: 3.3164
Training Epoch: 3 [28672/50176]	Loss: 3.1803
Training Epoch: 3 [29696/50176]	Loss: 3.1875
Training Epoch: 3 [30720/50176]	Loss: 3.2186
Training Epoch: 3 [31744/50176]	Loss: 3.2219
Training Epoch: 3 [32768/50176]	Loss: 3.1993
Training Epoch: 3 [33792/50176]	Loss: 3.0554
Training Epoch: 3 [34816/50176]	Loss: 3.1888
Training Epoch: 3 [35840/50176]	Loss: 3.1824
Training Epoch: 3 [36864/50176]	Loss: 3.1576
Training Epoch: 3 [37888/50176]	Loss: 3.2108
Training Epoch: 3 [38912/50176]	Loss: 3.2328
Training Epoch: 3 [39936/50176]	Loss: 3.2456
Training Epoch: 3 [40960/50176]	Loss: 3.0934
Training Epoch: 3 [41984/50176]	Loss: 3.1899
Training Epoch: 3 [43008/50176]	Loss: 3.0527
Training Epoch: 3 [44032/50176]	Loss: 3.1182
Training Epoch: 3 [45056/50176]	Loss: 3.0927
Training Epoch: 3 [46080/50176]	Loss: 3.1346
Training Epoch: 3 [47104/50176]	Loss: 3.1089
Training Epoch: 3 [48128/50176]	Loss: 3.2795
Training Epoch: 3 [49152/50176]	Loss: 3.1363
Training Epoch: 3 [50176/50176]	Loss: 3.1269
2022-12-06 15:15:26.158 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:15:26,183 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 10:15:26,183 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+lr0.0010000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 143.7756220422888, "150000": 143.40712738575323, "125000": 122.48868740045154, "100000": 96.72232362161922}, "train_throughput": {"175000": 1.1470109333913145, "150000": 1.1409906882244738, "125000": 1.0501037720271307, "100000": 0.624481141380321}, "eval_power": {"175000": 125.24703968117582, "150000": 125.36180693481519, "125000": 112.75230768170896}, "eval_throughput": {"175000": 2.684416650194901, "150000": 2.6670077798065, "125000": 2.568989803717995}, "optimal_pl": 175000}
2022-12-06 10:15:26,183 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.73 energy=466.57
2022-12-06 10:15:26,183 [ZeusDataLoader(train)] Up to epoch 4: time=232.61, energy=27655.58, cost=34181.31
2022-12-06 10:15:26,183 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:15:26,183 [ZeusDataLoader(train)] Expected next epoch: time=279.06, energy=34264.21, cost=41549.56
2022-12-06 10:15:26,184 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0030, Accuracy: 0.2280
2022-12-06 10:15:26,362 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:15:26,363 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:15:26.364 [ZeusMonitor] Monitor started.
2022-12-06 15:15:26.364 [ZeusMonitor] Running indefinitely. 2022-12-06 15:15:26.364 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:15:26.364 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e5+gpu0.power.log
2022-12-06 10:16:09,692 [ZeusDataLoader(train)] train epoch 5 done: time=43.50 energy=6156.85
2022-12-06 10:16:09,696 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.1442
Training Epoch: 4 [2048/50176]	Loss: 3.0661
Training Epoch: 4 [3072/50176]	Loss: 3.0190
Training Epoch: 4 [4096/50176]	Loss: 3.0598
Training Epoch: 4 [5120/50176]	Loss: 3.0225
Training Epoch: 4 [6144/50176]	Loss: 3.0432
Training Epoch: 4 [7168/50176]	Loss: 3.0738
Training Epoch: 4 [8192/50176]	Loss: 3.0937
Training Epoch: 4 [9216/50176]	Loss: 3.0725
Training Epoch: 4 [10240/50176]	Loss: 3.0195
Training Epoch: 4 [11264/50176]	Loss: 3.0457
Training Epoch: 4 [12288/50176]	Loss: 3.0594
Training Epoch: 4 [13312/50176]	Loss: 3.0534
Training Epoch: 4 [14336/50176]	Loss: 3.0937
Training Epoch: 4 [15360/50176]	Loss: 3.0234
Training Epoch: 4 [16384/50176]	Loss: 2.9254
Training Epoch: 4 [17408/50176]	Loss: 3.1016
Training Epoch: 4 [18432/50176]	Loss: 3.0142
Training Epoch: 4 [19456/50176]	Loss: 3.0280
Training Epoch: 4 [20480/50176]	Loss: 3.0740
Training Epoch: 4 [21504/50176]	Loss: 3.0603
Training Epoch: 4 [22528/50176]	Loss: 3.0248
Training Epoch: 4 [23552/50176]	Loss: 3.0269
Training Epoch: 4 [24576/50176]	Loss: 3.0083
Training Epoch: 4 [25600/50176]	Loss: 2.9709
Training Epoch: 4 [26624/50176]	Loss: 2.9431
Training Epoch: 4 [27648/50176]	Loss: 3.0796
Training Epoch: 4 [28672/50176]	Loss: 2.9680
Training Epoch: 4 [29696/50176]	Loss: 3.0738
Training Epoch: 4 [30720/50176]	Loss: 3.0359
Training Epoch: 4 [31744/50176]	Loss: 2.9516
Training Epoch: 4 [32768/50176]	Loss: 3.0073
Training Epoch: 4 [33792/50176]	Loss: 2.9788
Training Epoch: 4 [34816/50176]	Loss: 2.9474
Training Epoch: 4 [35840/50176]	Loss: 3.0720
Training Epoch: 4 [36864/50176]	Loss: 2.9715
Training Epoch: 4 [37888/50176]	Loss: 3.1687
Training Epoch: 4 [38912/50176]	Loss: 2.9628
Training Epoch: 4 [39936/50176]	Loss: 2.9917
Training Epoch: 4 [40960/50176]	Loss: 2.9845
Training Epoch: 4 [41984/50176]	Loss: 2.9025
Training Epoch: 4 [43008/50176]	Loss: 2.9686
Training Epoch: 4 [44032/50176]	Loss: 2.8897
Training Epoch: 4 [45056/50176]	Loss: 2.9778
Training Epoch: 4 [46080/50176]	Loss: 2.9689
Training Epoch: 4 [47104/50176]	Loss: 2.9831
Training Epoch: 4 [48128/50176]	Loss: 2.9507
Training Epoch: 4 [49152/50176]	Loss: 2.9869
Training Epoch: 4 [50176/50176]	Loss: 3.0273
2022-12-06 15:16:13.328 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:16:13,343 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.64 energy=465.39
2022-12-06 10:16:13,343 [ZeusDataLoader(train)] Up to epoch 5: time=279.75, energy=34277.82, cost=41617.14
2022-12-06 10:16:13,343 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:16:13,343 [ZeusDataLoader(train)] Expected next epoch: time=326.20, energy=40886.45, cost=48985.38
2022-12-06 10:16:13,344 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0029, Accuracy: 0.2612
2022-12-06 10:16:13,486 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:16:13,486 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:16:13.488 [ZeusMonitor] Monitor started.
2022-12-06 15:16:13.488 [ZeusMonitor] Running indefinitely. 2022-12-06 15:16:13.488 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:16:13.488 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e6+gpu0.power.log
2022-12-06 10:16:56,885 [ZeusDataLoader(train)] train epoch 6 done: time=43.53 energy=6196.85
2022-12-06 10:16:56,888 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.7728
Training Epoch: 5 [2048/50176]	Loss: 2.8694
Training Epoch: 5 [3072/50176]	Loss: 2.9888
Training Epoch: 5 [4096/50176]	Loss: 2.8648
Training Epoch: 5 [5120/50176]	Loss: 2.8846
Training Epoch: 5 [6144/50176]	Loss: 2.9049
Training Epoch: 5 [7168/50176]	Loss: 2.8767
Training Epoch: 5 [8192/50176]	Loss: 2.8372
Training Epoch: 5 [9216/50176]	Loss: 2.8883
Training Epoch: 5 [10240/50176]	Loss: 2.9137
Training Epoch: 5 [11264/50176]	Loss: 2.9367
Training Epoch: 5 [12288/50176]	Loss: 2.7991
Training Epoch: 5 [13312/50176]	Loss: 2.8922
Training Epoch: 5 [14336/50176]	Loss: 2.8605
Training Epoch: 5 [15360/50176]	Loss: 2.9558
Training Epoch: 5 [16384/50176]	Loss: 2.8676
Training Epoch: 5 [17408/50176]	Loss: 2.9410
Training Epoch: 5 [18432/50176]	Loss: 2.8351
Training Epoch: 5 [19456/50176]	Loss: 2.9137
Training Epoch: 5 [20480/50176]	Loss: 2.8266
Training Epoch: 5 [21504/50176]	Loss: 2.8145
Training Epoch: 5 [22528/50176]	Loss: 2.8912
Training Epoch: 5 [23552/50176]	Loss: 2.8963
Training Epoch: 5 [24576/50176]	Loss: 2.9157
Training Epoch: 5 [25600/50176]	Loss: 2.9296
Training Epoch: 5 [26624/50176]	Loss: 2.7976
Training Epoch: 5 [27648/50176]	Loss: 2.8575
Training Epoch: 5 [28672/50176]	Loss: 2.8875
Training Epoch: 5 [29696/50176]	Loss: 2.8561
Training Epoch: 5 [30720/50176]	Loss: 2.8341
Training Epoch: 5 [31744/50176]	Loss: 2.8728
Training Epoch: 5 [32768/50176]	Loss: 2.8393
Training Epoch: 5 [33792/50176]	Loss: 2.7925
Training Epoch: 5 [34816/50176]	Loss: 2.8654
Training Epoch: 5 [35840/50176]	Loss: 2.9284
Training Epoch: 5 [36864/50176]	Loss: 2.7662
Training Epoch: 5 [37888/50176]	Loss: 2.8210
Training Epoch: 5 [38912/50176]	Loss: 2.7781
Training Epoch: 5 [39936/50176]	Loss: 2.8551
Training Epoch: 5 [40960/50176]	Loss: 2.7661
Training Epoch: 5 [41984/50176]	Loss: 2.8385
Training Epoch: 5 [43008/50176]	Loss: 2.7881
Training Epoch: 5 [44032/50176]	Loss: 2.8833
Training Epoch: 5 [45056/50176]	Loss: 2.9822
Training Epoch: 5 [46080/50176]	Loss: 2.7773
Training Epoch: 5 [47104/50176]	Loss: 2.7920
Training Epoch: 5 [48128/50176]	Loss: 2.8148
Training Epoch: 5 [49152/50176]	Loss: 2.8893
Training Epoch: 5 [50176/50176]	Loss: 2.8040
2022-12-06 15:17:00.541 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:17:00,557 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.66 energy=461.88
2022-12-06 10:17:00,557 [ZeusDataLoader(train)] Up to epoch 6: time=326.95, energy=40936.55, cost=49076.01
2022-12-06 10:17:00,557 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:17:00,557 [ZeusDataLoader(train)] Expected next epoch: time=373.39, energy=47545.18, cost=56444.25
2022-12-06 10:17:00,558 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0028, Accuracy: 0.2873
2022-12-06 10:17:00,695 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:17:00,695 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:17:00.699 [ZeusMonitor] Monitor started.
2022-12-06 15:17:00.699 [ZeusMonitor] Running indefinitely. 2022-12-06 15:17:00.699 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:17:00.699 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e7+gpu0.power.log
2022-12-06 10:17:44,119 [ZeusDataLoader(train)] train epoch 7 done: time=43.55 energy=6191.38
2022-12-06 10:17:44,122 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.6889
Training Epoch: 6 [2048/50176]	Loss: 2.7153
Training Epoch: 6 [3072/50176]	Loss: 2.7805
Training Epoch: 6 [4096/50176]	Loss: 2.7834
Training Epoch: 6 [5120/50176]	Loss: 2.6725
Training Epoch: 6 [6144/50176]	Loss: 2.7050
Training Epoch: 6 [7168/50176]	Loss: 2.7621
Training Epoch: 6 [8192/50176]	Loss: 2.7218
Training Epoch: 6 [9216/50176]	Loss: 2.8250
Training Epoch: 6 [10240/50176]	Loss: 2.7087
Training Epoch: 6 [11264/50176]	Loss: 2.7688
Training Epoch: 6 [12288/50176]	Loss: 2.7788
Training Epoch: 6 [13312/50176]	Loss: 2.7542
Training Epoch: 6 [14336/50176]	Loss: 2.7006
Training Epoch: 6 [15360/50176]	Loss: 2.6278
Training Epoch: 6 [16384/50176]	Loss: 2.7351
Training Epoch: 6 [17408/50176]	Loss: 2.6805
Training Epoch: 6 [18432/50176]	Loss: 2.7360
Training Epoch: 6 [19456/50176]	Loss: 2.6336
Training Epoch: 6 [20480/50176]	Loss: 2.7716
Training Epoch: 6 [21504/50176]	Loss: 2.7882
Training Epoch: 6 [22528/50176]	Loss: 2.7147
Training Epoch: 6 [23552/50176]	Loss: 2.7254
Training Epoch: 6 [24576/50176]	Loss: 2.6892
Training Epoch: 6 [25600/50176]	Loss: 2.6753
Training Epoch: 6 [26624/50176]	Loss: 2.6897
Training Epoch: 6 [27648/50176]	Loss: 2.7182
Training Epoch: 6 [28672/50176]	Loss: 2.5629
Training Epoch: 6 [29696/50176]	Loss: 2.6970
Training Epoch: 6 [30720/50176]	Loss: 2.7530
Training Epoch: 6 [31744/50176]	Loss: 2.6704
Training Epoch: 6 [32768/50176]	Loss: 2.6623
Training Epoch: 6 [33792/50176]	Loss: 2.7062
Training Epoch: 6 [34816/50176]	Loss: 2.7006
Training Epoch: 6 [35840/50176]	Loss: 2.6667
Training Epoch: 6 [36864/50176]	Loss: 2.7267
Training Epoch: 6 [37888/50176]	Loss: 2.7487
Training Epoch: 6 [38912/50176]	Loss: 2.7316
Training Epoch: 6 [39936/50176]	Loss: 2.6614
Training Epoch: 6 [40960/50176]	Loss: 2.6903
Training Epoch: 6 [41984/50176]	Loss: 2.6671
Training Epoch: 6 [43008/50176]	Loss: 2.6686
Training Epoch: 6 [44032/50176]	Loss: 2.6949
Training Epoch: 6 [45056/50176]	Loss: 2.6598
Training Epoch: 6 [46080/50176]	Loss: 2.7304
Training Epoch: 6 [47104/50176]	Loss: 2.6652
Training Epoch: 6 [48128/50176]	Loss: 2.6937
Training Epoch: 6 [49152/50176]	Loss: 2.6176
Training Epoch: 6 [50176/50176]	Loss: 2.6847
2022-12-06 15:17:47.808 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:17:47,828 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.70 energy=479.33
2022-12-06 10:17:47,828 [ZeusDataLoader(train)] Up to epoch 7: time=374.20, energy=47607.26, cost=56545.82
2022-12-06 10:17:47,828 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:17:47,828 [ZeusDataLoader(train)] Expected next epoch: time=420.64, energy=54215.89, cost=63914.06
2022-12-06 10:17:47,829 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0026, Accuracy: 0.3118
2022-12-06 10:17:48,002 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:17:48,002 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:17:48.016 [ZeusMonitor] Monitor started.
2022-12-06 15:17:48.016 [ZeusMonitor] Running indefinitely. 2022-12-06 15:17:48.016 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:17:48.016 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e8+gpu0.power.log
2022-12-06 10:18:31,439 [ZeusDataLoader(train)] train epoch 8 done: time=43.60 energy=6202.81
2022-12-06 10:18:31,442 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.6214
Training Epoch: 7 [2048/50176]	Loss: 2.6033
Training Epoch: 7 [3072/50176]	Loss: 2.5522
Training Epoch: 7 [4096/50176]	Loss: 2.5746
Training Epoch: 7 [5120/50176]	Loss: 2.6003
Training Epoch: 7 [6144/50176]	Loss: 2.5480
Training Epoch: 7 [7168/50176]	Loss: 2.5591
Training Epoch: 7 [8192/50176]	Loss: 2.5829
Training Epoch: 7 [9216/50176]	Loss: 2.4421
Training Epoch: 7 [10240/50176]	Loss: 2.4608
Training Epoch: 7 [11264/50176]	Loss: 2.5118
Training Epoch: 7 [12288/50176]	Loss: 2.6020
Training Epoch: 7 [13312/50176]	Loss: 2.5497
Training Epoch: 7 [14336/50176]	Loss: 2.6717
Training Epoch: 7 [15360/50176]	Loss: 2.5699
Training Epoch: 7 [16384/50176]	Loss: 2.5447
Training Epoch: 7 [17408/50176]	Loss: 2.6081
Training Epoch: 7 [18432/50176]	Loss: 2.5697
Training Epoch: 7 [19456/50176]	Loss: 2.5680
Training Epoch: 7 [20480/50176]	Loss: 2.5925
Training Epoch: 7 [21504/50176]	Loss: 2.6030
Training Epoch: 7 [22528/50176]	Loss: 2.6050
Training Epoch: 7 [23552/50176]	Loss: 2.5489
Training Epoch: 7 [24576/50176]	Loss: 2.5065
Training Epoch: 7 [25600/50176]	Loss: 2.5962
Training Epoch: 7 [26624/50176]	Loss: 2.5964
Training Epoch: 7 [27648/50176]	Loss: 2.6523
Training Epoch: 7 [28672/50176]	Loss: 2.5191
Training Epoch: 7 [29696/50176]	Loss: 2.5880
Training Epoch: 7 [30720/50176]	Loss: 2.5783
Training Epoch: 7 [31744/50176]	Loss: 2.6331
Training Epoch: 7 [32768/50176]	Loss: 2.5374
Training Epoch: 7 [33792/50176]	Loss: 2.6063
Training Epoch: 7 [34816/50176]	Loss: 2.6150
Training Epoch: 7 [35840/50176]	Loss: 2.5409
Training Epoch: 7 [36864/50176]	Loss: 2.5101
Training Epoch: 7 [37888/50176]	Loss: 2.4469
Training Epoch: 7 [38912/50176]	Loss: 2.5594
Training Epoch: 7 [39936/50176]	Loss: 2.6044
Training Epoch: 7 [40960/50176]	Loss: 2.5795
Training Epoch: 7 [41984/50176]	Loss: 2.5165
Training Epoch: 7 [43008/50176]	Loss: 2.5046
Training Epoch: 7 [44032/50176]	Loss: 2.5047
Training Epoch: 7 [45056/50176]	Loss: 2.5866
Training Epoch: 7 [46080/50176]	Loss: 2.6143
Training Epoch: 7 [47104/50176]	Loss: 2.5061
Training Epoch: 7 [48128/50176]	Loss: 2.5214
Training Epoch: 7 [49152/50176]	Loss: 2.6950
Training Epoch: 7 [50176/50176]	Loss: 2.4924
2022-12-06 15:18:35.179 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:18:35,207 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.76 energy=469.47
2022-12-06 10:18:35,208 [ZeusDataLoader(train)] Up to epoch 8: time=421.56, energy=54279.54, cost=64025.89
2022-12-06 10:18:35,208 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:18:35,208 [ZeusDataLoader(train)] Expected next epoch: time=468.00, energy=60888.16, cost=71394.13
2022-12-06 10:18:35,209 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0025, Accuracy: 0.3380
2022-12-06 10:18:35,383 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:18:35,383 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:18:35.385 [ZeusMonitor] Monitor started.
2022-12-06 15:18:35.385 [ZeusMonitor] Running indefinitely. 2022-12-06 15:18:35.385 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:18:35.385 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e9+gpu0.power.log
2022-12-06 10:19:18,782 [ZeusDataLoader(train)] train epoch 9 done: time=43.57 energy=6191.17
2022-12-06 10:19:18,785 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.4986
Training Epoch: 8 [2048/50176]	Loss: 2.5775
Training Epoch: 8 [3072/50176]	Loss: 2.5298
Training Epoch: 8 [4096/50176]	Loss: 2.4802
Training Epoch: 8 [5120/50176]	Loss: 2.3661
Training Epoch: 8 [6144/50176]	Loss: 2.4141
Training Epoch: 8 [7168/50176]	Loss: 2.4702
Training Epoch: 8 [8192/50176]	Loss: 2.4711
Training Epoch: 8 [9216/50176]	Loss: 2.4587
Training Epoch: 8 [10240/50176]	Loss: 2.4362
Training Epoch: 8 [11264/50176]	Loss: 2.4483
Training Epoch: 8 [12288/50176]	Loss: 2.4065
Training Epoch: 8 [13312/50176]	Loss: 2.4374
Training Epoch: 8 [14336/50176]	Loss: 2.4561
Training Epoch: 8 [15360/50176]	Loss: 2.5216
Training Epoch: 8 [16384/50176]	Loss: 2.4068
Training Epoch: 8 [17408/50176]	Loss: 2.5742
Training Epoch: 8 [18432/50176]	Loss: 2.4525
Training Epoch: 8 [19456/50176]	Loss: 2.4166
Training Epoch: 8 [20480/50176]	Loss: 2.4102
Training Epoch: 8 [21504/50176]	Loss: 2.3565
Training Epoch: 8 [22528/50176]	Loss: 2.4323
Training Epoch: 8 [23552/50176]	Loss: 2.3914
Training Epoch: 8 [24576/50176]	Loss: 2.5222
Training Epoch: 8 [25600/50176]	Loss: 2.4631
Training Epoch: 8 [26624/50176]	Loss: 2.4600
Training Epoch: 8 [27648/50176]	Loss: 2.3936
Training Epoch: 8 [28672/50176]	Loss: 2.4479
Training Epoch: 8 [29696/50176]	Loss: 2.4119
Training Epoch: 8 [30720/50176]	Loss: 2.4715
Training Epoch: 8 [31744/50176]	Loss: 2.4000
Training Epoch: 8 [32768/50176]	Loss: 2.4463
Training Epoch: 8 [33792/50176]	Loss: 2.4919
Training Epoch: 8 [34816/50176]	Loss: 2.4875
Training Epoch: 8 [35840/50176]	Loss: 2.5101
Training Epoch: 8 [36864/50176]	Loss: 2.4362
Training Epoch: 8 [37888/50176]	Loss: 2.4901
Training Epoch: 8 [38912/50176]	Loss: 2.4653
Training Epoch: 8 [39936/50176]	Loss: 2.4862
Training Epoch: 8 [40960/50176]	Loss: 2.3994
Training Epoch: 8 [41984/50176]	Loss: 2.4753
Training Epoch: 8 [43008/50176]	Loss: 2.4157
Training Epoch: 8 [44032/50176]	Loss: 2.4709
Training Epoch: 8 [45056/50176]	Loss: 2.4716
Training Epoch: 8 [46080/50176]	Loss: 2.4202
Training Epoch: 8 [47104/50176]	Loss: 2.5553
Training Epoch: 8 [48128/50176]	Loss: 2.3874
Training Epoch: 8 [49152/50176]	Loss: 2.4753
Training Epoch: 8 [50176/50176]	Loss: 2.4652
2022-12-06 15:19:22.488 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:19:22,532 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.74 energy=481.47
2022-12-06 10:19:22,533 [ZeusDataLoader(train)] Up to epoch 9: time=468.86, energy=60952.18, cost=71501.36
2022-12-06 10:19:22,533 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:19:22,533 [ZeusDataLoader(train)] Expected next epoch: time=515.31, energy=67560.80, cost=78869.61
2022-12-06 10:19:22,534 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0024, Accuracy: 0.3552
2022-12-06 10:19:22,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:19:22,702 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:19:22.712 [ZeusMonitor] Monitor started.
2022-12-06 15:19:22.712 [ZeusMonitor] Running indefinitely. 2022-12-06 15:19:22.712 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:19:22.712 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e10+gpu0.power.log
2022-12-06 10:20:06,116 [ZeusDataLoader(train)] train epoch 10 done: time=43.57 energy=6201.22
2022-12-06 10:20:06,119 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.3827
Training Epoch: 9 [2048/50176]	Loss: 2.3534
Training Epoch: 9 [3072/50176]	Loss: 2.3932
Training Epoch: 9 [4096/50176]	Loss: 2.3930
Training Epoch: 9 [5120/50176]	Loss: 2.4628
Training Epoch: 9 [6144/50176]	Loss: 2.3447
Training Epoch: 9 [7168/50176]	Loss: 2.3672
Training Epoch: 9 [8192/50176]	Loss: 2.3639
Training Epoch: 9 [9216/50176]	Loss: 2.2985
Training Epoch: 9 [10240/50176]	Loss: 2.3770
Training Epoch: 9 [11264/50176]	Loss: 2.4123
Training Epoch: 9 [12288/50176]	Loss: 2.3803
Training Epoch: 9 [13312/50176]	Loss: 2.3098
Training Epoch: 9 [14336/50176]	Loss: 2.3719
Training Epoch: 9 [15360/50176]	Loss: 2.3944
Training Epoch: 9 [16384/50176]	Loss: 2.3811
Training Epoch: 9 [17408/50176]	Loss: 2.3399
Training Epoch: 9 [18432/50176]	Loss: 2.4071
Training Epoch: 9 [19456/50176]	Loss: 2.3161
Training Epoch: 9 [20480/50176]	Loss: 2.3816
Training Epoch: 9 [21504/50176]	Loss: 2.3257
Training Epoch: 9 [22528/50176]	Loss: 2.3100
Training Epoch: 9 [23552/50176]	Loss: 2.2624
Training Epoch: 9 [24576/50176]	Loss: 2.3734
Training Epoch: 9 [25600/50176]	Loss: 2.3192
Training Epoch: 9 [26624/50176]	Loss: 2.2924
Training Epoch: 9 [27648/50176]	Loss: 2.3282
Training Epoch: 9 [28672/50176]	Loss: 2.4037
Training Epoch: 9 [29696/50176]	Loss: 2.4066
Training Epoch: 9 [30720/50176]	Loss: 2.2643
Training Epoch: 9 [31744/50176]	Loss: 2.3379
Training Epoch: 9 [32768/50176]	Loss: 2.2988
Training Epoch: 9 [33792/50176]	Loss: 2.2829
Training Epoch: 9 [34816/50176]	Loss: 2.3589
Training Epoch: 9 [35840/50176]	Loss: 2.3284
Training Epoch: 9 [36864/50176]	Loss: 2.3792
Training Epoch: 9 [37888/50176]	Loss: 2.3515
Training Epoch: 9 [38912/50176]	Loss: 2.3948
Training Epoch: 9 [39936/50176]	Loss: 2.3118
Training Epoch: 9 [40960/50176]	Loss: 2.3618
Training Epoch: 9 [41984/50176]	Loss: 2.2713
Training Epoch: 9 [43008/50176]	Loss: 2.3737
Training Epoch: 9 [44032/50176]	Loss: 2.3854
Training Epoch: 9 [45056/50176]	Loss: 2.3172
Training Epoch: 9 [46080/50176]	Loss: 2.3553
Training Epoch: 9 [47104/50176]	Loss: 2.3275
Training Epoch: 9 [48128/50176]	Loss: 2.3666
Training Epoch: 9 [49152/50176]	Loss: 2.3452
Training Epoch: 9 [50176/50176]	Loss: 2.3052
2022-12-06 15:20:09.791 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:20:09,803 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.68 energy=457.81
2022-12-06 10:20:09,803 [ZeusDataLoader(train)] Up to epoch 10: time=516.11, energy=67611.21, cost=78965.30
2022-12-06 10:20:09,803 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:20:09,803 [ZeusDataLoader(train)] Expected next epoch: time=562.56, energy=74219.84, cost=86333.55
2022-12-06 10:20:09,804 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0024, Accuracy: 0.3689
2022-12-06 10:20:09,978 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:20:09,979 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:20:09.981 [ZeusMonitor] Monitor started.
2022-12-06 15:20:09.981 [ZeusMonitor] Running indefinitely. 2022-12-06 15:20:09.981 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:20:09.981 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e11+gpu0.power.log
2022-12-06 10:20:53,372 [ZeusDataLoader(train)] train epoch 11 done: time=43.56 energy=6194.84
2022-12-06 10:20:53,375 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 2.2396
Training Epoch: 10 [2048/50176]	Loss: 2.2453
Training Epoch: 10 [3072/50176]	Loss: 2.1861
Training Epoch: 10 [4096/50176]	Loss: 2.3517
Training Epoch: 10 [5120/50176]	Loss: 2.3243
Training Epoch: 10 [6144/50176]	Loss: 2.2588
Training Epoch: 10 [7168/50176]	Loss: 2.2689
Training Epoch: 10 [8192/50176]	Loss: 2.2081
Training Epoch: 10 [9216/50176]	Loss: 2.1921
Training Epoch: 10 [10240/50176]	Loss: 2.1311
Training Epoch: 10 [11264/50176]	Loss: 2.3352
Training Epoch: 10 [12288/50176]	Loss: 2.1832
Training Epoch: 10 [13312/50176]	Loss: 2.3401
Training Epoch: 10 [14336/50176]	Loss: 2.2838
Training Epoch: 10 [15360/50176]	Loss: 2.2574
Training Epoch: 10 [16384/50176]	Loss: 2.3479
Training Epoch: 10 [17408/50176]	Loss: 2.3688
Training Epoch: 10 [18432/50176]	Loss: 2.1773
Training Epoch: 10 [19456/50176]	Loss: 2.2517
Training Epoch: 10 [20480/50176]	Loss: 2.2533
Training Epoch: 10 [21504/50176]	Loss: 2.3083
Training Epoch: 10 [22528/50176]	Loss: 2.2746
Training Epoch: 10 [23552/50176]	Loss: 2.1980
Training Epoch: 10 [24576/50176]	Loss: 2.2103
Training Epoch: 10 [25600/50176]	Loss: 2.2535
Training Epoch: 10 [26624/50176]	Loss: 2.2015
Training Epoch: 10 [27648/50176]	Loss: 2.1959
Training Epoch: 10 [28672/50176]	Loss: 2.3268
Training Epoch: 10 [29696/50176]	Loss: 2.3429
Training Epoch: 10 [30720/50176]	Loss: 2.2168
Training Epoch: 10 [31744/50176]	Loss: 2.3138
Training Epoch: 10 [32768/50176]	Loss: 2.2115
Training Epoch: 10 [33792/50176]	Loss: 2.1973
Training Epoch: 10 [34816/50176]	Loss: 2.2786
Training Epoch: 10 [35840/50176]	Loss: 2.3104
Training Epoch: 10 [36864/50176]	Loss: 2.2131
Training Epoch: 10 [37888/50176]	Loss: 2.1527
Training Epoch: 10 [38912/50176]	Loss: 2.2433
Training Epoch: 10 [39936/50176]	Loss: 2.3351
Training Epoch: 10 [40960/50176]	Loss: 2.1503
Training Epoch: 10 [41984/50176]	Loss: 2.1493
Training Epoch: 10 [43008/50176]	Loss: 2.2780
Training Epoch: 10 [44032/50176]	Loss: 2.1870
Training Epoch: 10 [45056/50176]	Loss: 2.2189
Training Epoch: 10 [46080/50176]	Loss: 2.1185
Training Epoch: 10 [47104/50176]	Loss: 2.2477
Training Epoch: 10 [48128/50176]	Loss: 2.2415
Training Epoch: 10 [49152/50176]	Loss: 2.2698
Training Epoch: 10 [50176/50176]	Loss: 2.2737
2022-12-06 15:20:57.074 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:20:57,114 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.73 energy=477.70
2022-12-06 10:20:57,114 [ZeusDataLoader(train)] Up to epoch 11: time=563.40, energy=74283.74, cost=86439.57
2022-12-06 10:20:57,114 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:20:57,114 [ZeusDataLoader(train)] Expected next epoch: time=609.85, energy=80892.37, cost=93807.81
2022-12-06 10:20:57,115 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0023, Accuracy: 0.3912
2022-12-06 10:20:57,288 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:20:57,288 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:20:57.290 [ZeusMonitor] Monitor started.
2022-12-06 15:20:57.290 [ZeusMonitor] Running indefinitely. 2022-12-06 15:20:57.290 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:20:57.290 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e12+gpu0.power.log
2022-12-06 10:21:40,673 [ZeusDataLoader(train)] train epoch 12 done: time=43.55 energy=6205.47
2022-12-06 10:21:40,676 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 2.0972
Training Epoch: 11 [2048/50176]	Loss: 2.1135
Training Epoch: 11 [3072/50176]	Loss: 2.0974
Training Epoch: 11 [4096/50176]	Loss: 2.1942
Training Epoch: 11 [5120/50176]	Loss: 2.2422
Training Epoch: 11 [6144/50176]	Loss: 2.0734
Training Epoch: 11 [7168/50176]	Loss: 2.0945
Training Epoch: 11 [8192/50176]	Loss: 2.1120
Training Epoch: 11 [9216/50176]	Loss: 2.1575
Training Epoch: 11 [10240/50176]	Loss: 2.2255
Training Epoch: 11 [11264/50176]	Loss: 2.0931
Training Epoch: 11 [12288/50176]	Loss: 2.1405
Training Epoch: 11 [13312/50176]	Loss: 2.2684
Training Epoch: 11 [14336/50176]	Loss: 2.1096
Training Epoch: 11 [15360/50176]	Loss: 2.2372
Training Epoch: 11 [16384/50176]	Loss: 2.0999
Training Epoch: 11 [17408/50176]	Loss: 2.1472
Training Epoch: 11 [18432/50176]	Loss: 2.1762
Training Epoch: 11 [19456/50176]	Loss: 2.1563
Training Epoch: 11 [20480/50176]	Loss: 2.2381
Training Epoch: 11 [21504/50176]	Loss: 2.1842
Training Epoch: 11 [22528/50176]	Loss: 2.2065
Training Epoch: 11 [23552/50176]	Loss: 2.2218
Training Epoch: 11 [24576/50176]	Loss: 2.1348
Training Epoch: 11 [25600/50176]	Loss: 2.1523
Training Epoch: 11 [26624/50176]	Loss: 2.0830
Training Epoch: 11 [27648/50176]	Loss: 2.1305
Training Epoch: 11 [28672/50176]	Loss: 2.1601
Training Epoch: 11 [29696/50176]	Loss: 2.1286
Training Epoch: 11 [30720/50176]	Loss: 2.1334
Training Epoch: 11 [31744/50176]	Loss: 2.1973
Training Epoch: 11 [32768/50176]	Loss: 2.1415
Training Epoch: 11 [33792/50176]	Loss: 2.1390
Training Epoch: 11 [34816/50176]	Loss: 2.2055
Training Epoch: 11 [35840/50176]	Loss: 2.1993
Training Epoch: 11 [36864/50176]	Loss: 2.1796
Training Epoch: 11 [37888/50176]	Loss: 2.1399
Training Epoch: 11 [38912/50176]	Loss: 2.1386
Training Epoch: 11 [39936/50176]	Loss: 2.1437
Training Epoch: 11 [40960/50176]	Loss: 2.1045
Training Epoch: 11 [41984/50176]	Loss: 2.1150
Training Epoch: 11 [43008/50176]	Loss: 2.2363
Training Epoch: 11 [44032/50176]	Loss: 2.1117
Training Epoch: 11 [45056/50176]	Loss: 2.2139
Training Epoch: 11 [46080/50176]	Loss: 2.0451
Training Epoch: 11 [47104/50176]	Loss: 2.1614
Training Epoch: 11 [48128/50176]	Loss: 2.1343
Training Epoch: 11 [49152/50176]	Loss: 2.1211
Training Epoch: 11 [50176/50176]	Loss: 2.1921
2022-12-06 15:21:44.317 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:21:44,330 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.65 energy=457.06
2022-12-06 10:21:44,331 [ZeusDataLoader(train)] Up to epoch 12: time=610.60, energy=80946.27, cost=93900.52
2022-12-06 10:21:44,331 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:21:44,331 [ZeusDataLoader(train)] Expected next epoch: time=657.04, energy=87554.90, cost=101268.76
2022-12-06 10:21:44,332 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0022, Accuracy: 0.4032
2022-12-06 10:21:44,505 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:21:44,506 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:21:44.508 [ZeusMonitor] Monitor started.
2022-12-06 15:21:44.508 [ZeusMonitor] Running indefinitely. 2022-12-06 15:21:44.508 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:21:44.508 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e13+gpu0.power.log
2022-12-06 10:22:27,902 [ZeusDataLoader(train)] train epoch 13 done: time=43.56 energy=6203.59
2022-12-06 10:22:27,905 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 2.0819
Training Epoch: 12 [2048/50176]	Loss: 2.0395
Training Epoch: 12 [3072/50176]	Loss: 2.0626
Training Epoch: 12 [4096/50176]	Loss: 2.0418
Training Epoch: 12 [5120/50176]	Loss: 1.9547
Training Epoch: 12 [6144/50176]	Loss: 2.0702
Training Epoch: 12 [7168/50176]	Loss: 2.1296
Training Epoch: 12 [8192/50176]	Loss: 1.9957
Training Epoch: 12 [9216/50176]	Loss: 2.0552
Training Epoch: 12 [10240/50176]	Loss: 2.0026
Training Epoch: 12 [11264/50176]	Loss: 2.1607
Training Epoch: 12 [12288/50176]	Loss: 2.0718
Training Epoch: 12 [13312/50176]	Loss: 2.0213
Training Epoch: 12 [14336/50176]	Loss: 2.1366
Training Epoch: 12 [15360/50176]	Loss: 1.9576
Training Epoch: 12 [16384/50176]	Loss: 2.0693
Training Epoch: 12 [17408/50176]	Loss: 2.1069
Training Epoch: 12 [18432/50176]	Loss: 2.0687
Training Epoch: 12 [19456/50176]	Loss: 2.0283
Training Epoch: 12 [20480/50176]	Loss: 2.0861
Training Epoch: 12 [21504/50176]	Loss: 2.1639
Training Epoch: 12 [22528/50176]	Loss: 2.0267
Training Epoch: 12 [23552/50176]	Loss: 2.0478
Training Epoch: 12 [24576/50176]	Loss: 2.0013
Training Epoch: 12 [25600/50176]	Loss: 2.1381
Training Epoch: 12 [26624/50176]	Loss: 2.1493
Training Epoch: 12 [27648/50176]	Loss: 2.0291
Training Epoch: 12 [28672/50176]	Loss: 2.0526
Training Epoch: 12 [29696/50176]	Loss: 2.1103
Training Epoch: 12 [30720/50176]	Loss: 2.0400
Training Epoch: 12 [31744/50176]	Loss: 2.0338
Training Epoch: 12 [32768/50176]	Loss: 2.1572
Training Epoch: 12 [33792/50176]	Loss: 2.0643
Training Epoch: 12 [34816/50176]	Loss: 2.0788
Training Epoch: 12 [35840/50176]	Loss: 2.0292
Training Epoch: 12 [36864/50176]	Loss: 2.1046
Training Epoch: 12 [37888/50176]	Loss: 2.0787
Training Epoch: 12 [38912/50176]	Loss: 2.0183
Training Epoch: 12 [39936/50176]	Loss: 2.1218
Training Epoch: 12 [40960/50176]	Loss: 1.9879
Training Epoch: 12 [41984/50176]	Loss: 2.1359
Training Epoch: 12 [43008/50176]	Loss: 2.0725
Training Epoch: 12 [44032/50176]	Loss: 2.1768
Training Epoch: 12 [45056/50176]	Loss: 1.9932
Training Epoch: 12 [46080/50176]	Loss: 2.1084
Training Epoch: 12 [47104/50176]	Loss: 2.0055
Training Epoch: 12 [48128/50176]	Loss: 2.0050
Training Epoch: 12 [49152/50176]	Loss: 2.0389
Training Epoch: 12 [50176/50176]	Loss: 1.9701
2022-12-06 15:22:31.571 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:22:31,601 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.69 energy=473.55
2022-12-06 10:22:31,601 [ZeusDataLoader(train)] Up to epoch 13: time=657.85, energy=87623.41, cost=101373.49
2022-12-06 10:22:31,601 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:22:31,601 [ZeusDataLoader(train)] Expected next epoch: time=704.29, energy=94232.03, cost=108741.74
2022-12-06 10:22:31,602 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0021, Accuracy: 0.4230
2022-12-06 10:22:31,779 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:22:31,779 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:22:31.781 [ZeusMonitor] Monitor started.
2022-12-06 15:22:31.781 [ZeusMonitor] Running indefinitely. 2022-12-06 15:22:31.781 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:22:31.781 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e14+gpu0.power.log
2022-12-06 10:23:15,166 [ZeusDataLoader(train)] train epoch 14 done: time=43.56 energy=6201.84
2022-12-06 10:23:15,169 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.9233
Training Epoch: 13 [2048/50176]	Loss: 1.9845
Training Epoch: 13 [3072/50176]	Loss: 2.0275
Training Epoch: 13 [4096/50176]	Loss: 1.9534
Training Epoch: 13 [5120/50176]	Loss: 1.9603
Training Epoch: 13 [6144/50176]	Loss: 1.9804
Training Epoch: 13 [7168/50176]	Loss: 1.9069
Training Epoch: 13 [8192/50176]	Loss: 1.9166
Training Epoch: 13 [9216/50176]	Loss: 1.9578
Training Epoch: 13 [10240/50176]	Loss: 2.0728
Training Epoch: 13 [11264/50176]	Loss: 1.9134
Training Epoch: 13 [12288/50176]	Loss: 1.9482
Training Epoch: 13 [13312/50176]	Loss: 1.9737
Training Epoch: 13 [14336/50176]	Loss: 1.9692
Training Epoch: 13 [15360/50176]	Loss: 1.9789
Training Epoch: 13 [16384/50176]	Loss: 1.9739
Training Epoch: 13 [17408/50176]	Loss: 1.9925
Training Epoch: 13 [18432/50176]	Loss: 1.9281
Training Epoch: 13 [19456/50176]	Loss: 1.9707
Training Epoch: 13 [20480/50176]	Loss: 1.8846
Training Epoch: 13 [21504/50176]	Loss: 2.0639
Training Epoch: 13 [22528/50176]	Loss: 1.9807
Training Epoch: 13 [23552/50176]	Loss: 2.0016
Training Epoch: 13 [24576/50176]	Loss: 1.9519
Training Epoch: 13 [25600/50176]	Loss: 2.0139
Training Epoch: 13 [26624/50176]	Loss: 2.0104
Training Epoch: 13 [27648/50176]	Loss: 1.9438
Training Epoch: 13 [28672/50176]	Loss: 1.9878
Training Epoch: 13 [29696/50176]	Loss: 1.9848
Training Epoch: 13 [30720/50176]	Loss: 1.9820
Training Epoch: 13 [31744/50176]	Loss: 2.0406
Training Epoch: 13 [32768/50176]	Loss: 1.8873
Training Epoch: 13 [33792/50176]	Loss: 2.0071
Training Epoch: 13 [34816/50176]	Loss: 2.0759
Training Epoch: 13 [35840/50176]	Loss: 2.0953
Training Epoch: 13 [36864/50176]	Loss: 1.9935
Training Epoch: 13 [37888/50176]	Loss: 2.0259
Training Epoch: 13 [38912/50176]	Loss: 1.9499
Training Epoch: 13 [39936/50176]	Loss: 1.9288
Training Epoch: 13 [40960/50176]	Loss: 2.0056
Training Epoch: 13 [41984/50176]	Loss: 1.9870
Training Epoch: 13 [43008/50176]	Loss: 1.9192
Training Epoch: 13 [44032/50176]	Loss: 2.0190
Training Epoch: 13 [45056/50176]	Loss: 1.9504
Training Epoch: 13 [46080/50176]	Loss: 1.9262
Training Epoch: 13 [47104/50176]	Loss: 1.9254
Training Epoch: 13 [48128/50176]	Loss: 2.0030
Training Epoch: 13 [49152/50176]	Loss: 1.8758
Training Epoch: 13 [50176/50176]	Loss: 2.0675
2022-12-06 15:23:18.851 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:23:18,866 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.69 energy=459.46
2022-12-06 10:23:18,866 [ZeusDataLoader(train)] Up to epoch 14: time=705.09, energy=94284.71, cost=108838.04
2022-12-06 10:23:18,866 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:23:18,866 [ZeusDataLoader(train)] Expected next epoch: time=751.54, energy=100893.33, cost=116206.29
2022-12-06 10:23:18,867 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0021, Accuracy: 0.4234
2022-12-06 10:23:19,043 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:23:19,043 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:23:19.045 [ZeusMonitor] Monitor started.
2022-12-06 15:23:19.045 [ZeusMonitor] Running indefinitely. 2022-12-06 15:23:19.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:23:19.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e15+gpu0.power.log
2022-12-06 10:24:02,489 [ZeusDataLoader(train)] train epoch 15 done: time=43.61 energy=6202.54
2022-12-06 10:24:02,493 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.8658
Training Epoch: 14 [2048/50176]	Loss: 1.9670
Training Epoch: 14 [3072/50176]	Loss: 1.9227
Training Epoch: 14 [4096/50176]	Loss: 2.0177
Training Epoch: 14 [5120/50176]	Loss: 1.8511
Training Epoch: 14 [6144/50176]	Loss: 1.8495
Training Epoch: 14 [7168/50176]	Loss: 1.8024
Training Epoch: 14 [8192/50176]	Loss: 1.9061
Training Epoch: 14 [9216/50176]	Loss: 1.8452
Training Epoch: 14 [10240/50176]	Loss: 1.8502
Training Epoch: 14 [11264/50176]	Loss: 1.8319
Training Epoch: 14 [12288/50176]	Loss: 1.9388
Training Epoch: 14 [13312/50176]	Loss: 1.8900
Training Epoch: 14 [14336/50176]	Loss: 1.8674
Training Epoch: 14 [15360/50176]	Loss: 1.8665
Training Epoch: 14 [16384/50176]	Loss: 1.8122
Training Epoch: 14 [17408/50176]	Loss: 1.9089
Training Epoch: 14 [18432/50176]	Loss: 1.8816
Training Epoch: 14 [19456/50176]	Loss: 1.8263
Training Epoch: 14 [20480/50176]	Loss: 1.9086
Training Epoch: 14 [21504/50176]	Loss: 1.8778
Training Epoch: 14 [22528/50176]	Loss: 1.8973
Training Epoch: 14 [23552/50176]	Loss: 1.9165
Training Epoch: 14 [24576/50176]	Loss: 1.9278
Training Epoch: 14 [25600/50176]	Loss: 2.0013
Training Epoch: 14 [26624/50176]	Loss: 1.8854
Training Epoch: 14 [27648/50176]	Loss: 1.7706
Training Epoch: 14 [28672/50176]	Loss: 1.9332
Training Epoch: 14 [29696/50176]	Loss: 1.9169
Training Epoch: 14 [30720/50176]	Loss: 1.8955
Training Epoch: 14 [31744/50176]	Loss: 1.9064
Training Epoch: 14 [32768/50176]	Loss: 2.0025
Training Epoch: 14 [33792/50176]	Loss: 1.9014
Training Epoch: 14 [34816/50176]	Loss: 1.8989
Training Epoch: 14 [35840/50176]	Loss: 1.9562
Training Epoch: 14 [36864/50176]	Loss: 2.0209
Training Epoch: 14 [37888/50176]	Loss: 1.8666
Training Epoch: 14 [38912/50176]	Loss: 1.9024
Training Epoch: 14 [39936/50176]	Loss: 1.8510
Training Epoch: 14 [40960/50176]	Loss: 1.9348
Training Epoch: 14 [41984/50176]	Loss: 2.0106
Training Epoch: 14 [43008/50176]	Loss: 1.9795
Training Epoch: 14 [44032/50176]	Loss: 1.8821
Training Epoch: 14 [45056/50176]	Loss: 1.9156
Training Epoch: 14 [46080/50176]	Loss: 1.9287
Training Epoch: 14 [47104/50176]	Loss: 1.8612
Training Epoch: 14 [48128/50176]	Loss: 1.9250
Training Epoch: 14 [49152/50176]	Loss: 1.9392
Training Epoch: 14 [50176/50176]	Loss: 1.9254
2022-12-06 15:24:06.175 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:24:06,207 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.71 energy=469.29
2022-12-06 10:24:06,208 [ZeusDataLoader(train)] Up to epoch 15: time=752.41, energy=100956.54, cost=116314.56
2022-12-06 10:24:06,208 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:24:06,208 [ZeusDataLoader(train)] Expected next epoch: time=798.86, energy=107565.17, cost=123682.80
2022-12-06 10:24:06,209 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0021, Accuracy: 0.4368
2022-12-06 10:24:06,386 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:24:06,387 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:24:06.388 [ZeusMonitor] Monitor started.
2022-12-06 15:24:06.388 [ZeusMonitor] Running indefinitely. 2022-12-06 15:24:06.388 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:24:06.389 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e16+gpu0.power.log
2022-12-06 10:24:49,861 [ZeusDataLoader(train)] train epoch 16 done: time=43.64 energy=6198.19
2022-12-06 10:24:49,865 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.8885
Training Epoch: 15 [2048/50176]	Loss: 1.7884
Training Epoch: 15 [3072/50176]	Loss: 1.7942
Training Epoch: 15 [4096/50176]	Loss: 1.8625
Training Epoch: 15 [5120/50176]	Loss: 1.7995
Training Epoch: 15 [6144/50176]	Loss: 1.8085
Training Epoch: 15 [7168/50176]	Loss: 1.7897
Training Epoch: 15 [8192/50176]	Loss: 1.8149
Training Epoch: 15 [9216/50176]	Loss: 1.8693
Training Epoch: 15 [10240/50176]	Loss: 1.7845
Training Epoch: 15 [11264/50176]	Loss: 1.7909
Training Epoch: 15 [12288/50176]	Loss: 1.9094
Training Epoch: 15 [13312/50176]	Loss: 1.7746
Training Epoch: 15 [14336/50176]	Loss: 1.7910
Training Epoch: 15 [15360/50176]	Loss: 1.8842
Training Epoch: 15 [16384/50176]	Loss: 1.9402
Training Epoch: 15 [17408/50176]	Loss: 1.8222
Training Epoch: 15 [18432/50176]	Loss: 1.8617
Training Epoch: 15 [19456/50176]	Loss: 1.8059
Training Epoch: 15 [20480/50176]	Loss: 1.8344
Training Epoch: 15 [21504/50176]	Loss: 1.7425
Training Epoch: 15 [22528/50176]	Loss: 1.9246
Training Epoch: 15 [23552/50176]	Loss: 1.8100
Training Epoch: 15 [24576/50176]	Loss: 1.7635
Training Epoch: 15 [25600/50176]	Loss: 1.8217
Training Epoch: 15 [26624/50176]	Loss: 1.8722
Training Epoch: 15 [27648/50176]	Loss: 1.8512
Training Epoch: 15 [28672/50176]	Loss: 1.7564
Training Epoch: 15 [29696/50176]	Loss: 1.7837
Training Epoch: 15 [30720/50176]	Loss: 1.8694
Training Epoch: 15 [31744/50176]	Loss: 1.9100
Training Epoch: 15 [32768/50176]	Loss: 1.7941
Training Epoch: 15 [33792/50176]	Loss: 1.8002
Training Epoch: 15 [34816/50176]	Loss: 1.9416
Training Epoch: 15 [35840/50176]	Loss: 1.9126
Training Epoch: 15 [36864/50176]	Loss: 1.7115
Training Epoch: 15 [37888/50176]	Loss: 1.8508
Training Epoch: 15 [38912/50176]	Loss: 1.7884
Training Epoch: 15 [39936/50176]	Loss: 1.7655
Training Epoch: 15 [40960/50176]	Loss: 1.8762
Training Epoch: 15 [41984/50176]	Loss: 1.8537
Training Epoch: 15 [43008/50176]	Loss: 1.8896
Training Epoch: 15 [44032/50176]	Loss: 1.8544
Training Epoch: 15 [45056/50176]	Loss: 1.8252
Training Epoch: 15 [46080/50176]	Loss: 1.8789
Training Epoch: 15 [47104/50176]	Loss: 1.7997
Training Epoch: 15 [48128/50176]	Loss: 1.8505
Training Epoch: 15 [49152/50176]	Loss: 1.7622
Training Epoch: 15 [50176/50176]	Loss: 1.7626
2022-12-06 15:24:53.550 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:24:53,578 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.71 energy=475.80
2022-12-06 10:24:53,579 [ZeusDataLoader(train)] Up to epoch 16: time=799.77, energy=107630.53, cost=123794.73
2022-12-06 10:24:53,579 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:24:53,579 [ZeusDataLoader(train)] Expected next epoch: time=846.21, energy=114239.16, cost=131162.98
2022-12-06 10:24:53,580 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0021, Accuracy: 0.4419
2022-12-06 10:24:53,758 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:24:53,759 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:24:53.761 [ZeusMonitor] Monitor started.
2022-12-06 15:24:53.761 [ZeusMonitor] Running indefinitely. 2022-12-06 15:24:53.761 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:24:53.761 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e17+gpu0.power.log
2022-12-06 10:25:37,245 [ZeusDataLoader(train)] train epoch 17 done: time=43.66 energy=6209.43
2022-12-06 10:25:37,248 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.7476
Training Epoch: 16 [2048/50176]	Loss: 1.7341
Training Epoch: 16 [3072/50176]	Loss: 1.6833
Training Epoch: 16 [4096/50176]	Loss: 1.7158
Training Epoch: 16 [5120/50176]	Loss: 1.7544
Training Epoch: 16 [6144/50176]	Loss: 1.6747
Training Epoch: 16 [7168/50176]	Loss: 1.7035
Training Epoch: 16 [8192/50176]	Loss: 1.6596
Training Epoch: 16 [9216/50176]	Loss: 1.7374
Training Epoch: 16 [10240/50176]	Loss: 1.7147
Training Epoch: 16 [11264/50176]	Loss: 1.8286
Training Epoch: 16 [12288/50176]	Loss: 1.7243
Training Epoch: 16 [13312/50176]	Loss: 1.7254
Training Epoch: 16 [14336/50176]	Loss: 1.7625
Training Epoch: 16 [15360/50176]	Loss: 1.8225
Training Epoch: 16 [16384/50176]	Loss: 1.7599
Training Epoch: 16 [17408/50176]	Loss: 1.7461
Training Epoch: 16 [18432/50176]	Loss: 1.7849
Training Epoch: 16 [19456/50176]	Loss: 1.7920
Training Epoch: 16 [20480/50176]	Loss: 1.6966
Training Epoch: 16 [21504/50176]	Loss: 1.7872
Training Epoch: 16 [22528/50176]	Loss: 1.7293
Training Epoch: 16 [23552/50176]	Loss: 1.7841
Training Epoch: 16 [24576/50176]	Loss: 1.7281
Training Epoch: 16 [25600/50176]	Loss: 1.7799
Training Epoch: 16 [26624/50176]	Loss: 1.7252
Training Epoch: 16 [27648/50176]	Loss: 1.8350
Training Epoch: 16 [28672/50176]	Loss: 1.7544
Training Epoch: 16 [29696/50176]	Loss: 1.7108
Training Epoch: 16 [30720/50176]	Loss: 1.7366
Training Epoch: 16 [31744/50176]	Loss: 1.7353
Training Epoch: 16 [32768/50176]	Loss: 1.7653
Training Epoch: 16 [33792/50176]	Loss: 1.7685
Training Epoch: 16 [34816/50176]	Loss: 1.7966
Training Epoch: 16 [35840/50176]	Loss: 1.8471
Training Epoch: 16 [36864/50176]	Loss: 1.7373
Training Epoch: 16 [37888/50176]	Loss: 1.6763
Training Epoch: 16 [38912/50176]	Loss: 1.7641
Training Epoch: 16 [39936/50176]	Loss: 1.8666
Training Epoch: 16 [40960/50176]	Loss: 1.7972
Training Epoch: 16 [41984/50176]	Loss: 1.8156
Training Epoch: 16 [43008/50176]	Loss: 1.7808
Training Epoch: 16 [44032/50176]	Loss: 1.8194
Training Epoch: 16 [45056/50176]	Loss: 1.8271
Training Epoch: 16 [46080/50176]	Loss: 1.7706
Training Epoch: 16 [47104/50176]	Loss: 1.8560
Training Epoch: 16 [48128/50176]	Loss: 1.8047
Training Epoch: 16 [49152/50176]	Loss: 1.8252
Training Epoch: 16 [50176/50176]	Loss: 1.7968
2022-12-06 15:25:40.947 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:25:41,002 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.75 energy=470.54
2022-12-06 10:25:41,003 [ZeusDataLoader(train)] Up to epoch 17: time=847.17, energy=114310.50, cost=131282.56
2022-12-06 10:25:41,003 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:25:41,003 [ZeusDataLoader(train)] Expected next epoch: time=893.61, energy=120919.13, cost=138650.81
2022-12-06 10:25:41,004 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0020, Accuracy: 0.4531
2022-12-06 10:25:41,142 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:25:41,143 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:25:41.146 [ZeusMonitor] Monitor started.
2022-12-06 15:25:41.146 [ZeusMonitor] Running indefinitely. 2022-12-06 15:25:41.146 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:25:41.147 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e18+gpu0.power.log
2022-12-06 10:26:24,624 [ZeusDataLoader(train)] train epoch 18 done: time=43.61 energy=6210.97
2022-12-06 10:26:24,627 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.7104
Training Epoch: 17 [2048/50176]	Loss: 1.6945
Training Epoch: 17 [3072/50176]	Loss: 1.5827
Training Epoch: 17 [4096/50176]	Loss: 1.6341
Training Epoch: 17 [5120/50176]	Loss: 1.7258
Training Epoch: 17 [6144/50176]	Loss: 1.6951
Training Epoch: 17 [7168/50176]	Loss: 1.6942
Training Epoch: 17 [8192/50176]	Loss: 1.6638
Training Epoch: 17 [9216/50176]	Loss: 1.6686
Training Epoch: 17 [10240/50176]	Loss: 1.6585
Training Epoch: 17 [11264/50176]	Loss: 1.6287
Training Epoch: 17 [12288/50176]	Loss: 1.6787
Training Epoch: 17 [13312/50176]	Loss: 1.6536
Training Epoch: 17 [14336/50176]	Loss: 1.7175
Training Epoch: 17 [15360/50176]	Loss: 1.6628
Training Epoch: 17 [16384/50176]	Loss: 1.6333
Training Epoch: 17 [17408/50176]	Loss: 1.7212
Training Epoch: 17 [18432/50176]	Loss: 1.6836
Training Epoch: 17 [19456/50176]	Loss: 1.6046
Training Epoch: 17 [20480/50176]	Loss: 1.6262
Training Epoch: 17 [21504/50176]	Loss: 1.6804
Training Epoch: 17 [22528/50176]	Loss: 1.8050
Training Epoch: 17 [23552/50176]	Loss: 1.6968
Training Epoch: 17 [24576/50176]	Loss: 1.7530
Training Epoch: 17 [25600/50176]	Loss: 1.7229
Training Epoch: 17 [26624/50176]	Loss: 1.7453
Training Epoch: 17 [27648/50176]	Loss: 1.7109
Training Epoch: 17 [28672/50176]	Loss: 1.7081
Training Epoch: 17 [29696/50176]	Loss: 1.7458
Training Epoch: 17 [30720/50176]	Loss: 1.7526
Training Epoch: 17 [31744/50176]	Loss: 1.7335
Training Epoch: 17 [32768/50176]	Loss: 1.6916
Training Epoch: 17 [33792/50176]	Loss: 1.7311
Training Epoch: 17 [34816/50176]	Loss: 1.7084
Training Epoch: 17 [35840/50176]	Loss: 1.6211
Training Epoch: 17 [36864/50176]	Loss: 1.7607
Training Epoch: 17 [37888/50176]	Loss: 1.6930
Training Epoch: 17 [38912/50176]	Loss: 1.7684
Training Epoch: 17 [39936/50176]	Loss: 1.7981
Training Epoch: 17 [40960/50176]	Loss: 1.6975
Training Epoch: 17 [41984/50176]	Loss: 1.7390
Training Epoch: 17 [43008/50176]	Loss: 1.6608
Training Epoch: 17 [44032/50176]	Loss: 1.7352
Training Epoch: 17 [45056/50176]	Loss: 1.7135
Training Epoch: 17 [46080/50176]	Loss: 1.6762
Training Epoch: 17 [47104/50176]	Loss: 1.6748
Training Epoch: 17 [48128/50176]	Loss: 1.6302
Training Epoch: 17 [49152/50176]	Loss: 1.7337
Training Epoch: 17 [50176/50176]	Loss: 1.7909
2022-12-06 15:26:28.288 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:26:28,312 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.68 energy=470.86
2022-12-06 10:26:28,313 [ZeusDataLoader(train)] Up to epoch 18: time=894.46, energy=120992.34, cost=138761.37
2022-12-06 10:26:28,313 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:26:28,313 [ZeusDataLoader(train)] Expected next epoch: time=940.90, energy=127600.97, cost=146129.61
2022-12-06 10:26:28,314 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0019, Accuracy: 0.4667
2022-12-06 10:26:28,449 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:26:28,450 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:26:28.453 [ZeusMonitor] Monitor started.
2022-12-06 15:26:28.453 [ZeusMonitor] Running indefinitely. 2022-12-06 15:26:28.453 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:26:28.453 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e19+gpu0.power.log
2022-12-06 10:27:11,996 [ZeusDataLoader(train)] train epoch 19 done: time=43.67 energy=6210.23
2022-12-06 10:27:11,999 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.6032
Training Epoch: 18 [2048/50176]	Loss: 1.6639
Training Epoch: 18 [3072/50176]	Loss: 1.6360
Training Epoch: 18 [4096/50176]	Loss: 1.5639
Training Epoch: 18 [5120/50176]	Loss: 1.6551
Training Epoch: 18 [6144/50176]	Loss: 1.6708
Training Epoch: 18 [7168/50176]	Loss: 1.5953
Training Epoch: 18 [8192/50176]	Loss: 1.6466
Training Epoch: 18 [9216/50176]	Loss: 1.6481
Training Epoch: 18 [10240/50176]	Loss: 1.6233
Training Epoch: 18 [11264/50176]	Loss: 1.6572
Training Epoch: 18 [12288/50176]	Loss: 1.6120
Training Epoch: 18 [13312/50176]	Loss: 1.6372
Training Epoch: 18 [14336/50176]	Loss: 1.6592
Training Epoch: 18 [15360/50176]	Loss: 1.6655
Training Epoch: 18 [16384/50176]	Loss: 1.6300
Training Epoch: 18 [17408/50176]	Loss: 1.6766
Training Epoch: 18 [18432/50176]	Loss: 1.6209
Training Epoch: 18 [19456/50176]	Loss: 1.7095
Training Epoch: 18 [20480/50176]	Loss: 1.5667
Training Epoch: 18 [21504/50176]	Loss: 1.6802
Training Epoch: 18 [22528/50176]	Loss: 1.6579
Training Epoch: 18 [23552/50176]	Loss: 1.5858
Training Epoch: 18 [24576/50176]	Loss: 1.5959
Training Epoch: 18 [25600/50176]	Loss: 1.6561
Training Epoch: 18 [26624/50176]	Loss: 1.5084
Training Epoch: 18 [27648/50176]	Loss: 1.6501
Training Epoch: 18 [28672/50176]	Loss: 1.6459
Training Epoch: 18 [29696/50176]	Loss: 1.6816
Training Epoch: 18 [30720/50176]	Loss: 1.6466
Training Epoch: 18 [31744/50176]	Loss: 1.6955
Training Epoch: 18 [32768/50176]	Loss: 1.6064
Training Epoch: 18 [33792/50176]	Loss: 1.6387
Training Epoch: 18 [34816/50176]	Loss: 1.6398
Training Epoch: 18 [35840/50176]	Loss: 1.7177
Training Epoch: 18 [36864/50176]	Loss: 1.6677
Training Epoch: 18 [37888/50176]	Loss: 1.6255
Training Epoch: 18 [38912/50176]	Loss: 1.6354
Training Epoch: 18 [39936/50176]	Loss: 1.6206
Training Epoch: 18 [40960/50176]	Loss: 1.6727
Training Epoch: 18 [41984/50176]	Loss: 1.6937
Training Epoch: 18 [43008/50176]	Loss: 1.6753
Training Epoch: 18 [44032/50176]	Loss: 1.6814
Training Epoch: 18 [45056/50176]	Loss: 1.6553
Training Epoch: 18 [46080/50176]	Loss: 1.6430
Training Epoch: 18 [47104/50176]	Loss: 1.6150
Training Epoch: 18 [48128/50176]	Loss: 1.6587
Training Epoch: 18 [49152/50176]	Loss: 1.7035
Training Epoch: 18 [50176/50176]	Loss: 1.7101
2022-12-06 15:27:15.720 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:27:15,752 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.74 energy=473.65
2022-12-06 10:27:15,752 [ZeusDataLoader(train)] Up to epoch 19: time=941.88, energy=127676.22, cost=146252.45
2022-12-06 10:27:15,752 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:27:15,752 [ZeusDataLoader(train)] Expected next epoch: time=988.32, energy=134284.84, cost=153620.69
2022-12-06 10:27:15,753 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0019, Accuracy: 0.4755
2022-12-06 10:27:15,927 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:27:15,927 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:27:15.941 [ZeusMonitor] Monitor started.
2022-12-06 15:27:15.941 [ZeusMonitor] Running indefinitely. 2022-12-06 15:27:15.941 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:27:15.941 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e20+gpu0.power.log
2022-12-06 10:27:59,322 [ZeusDataLoader(train)] train epoch 20 done: time=43.56 energy=6199.34
2022-12-06 10:27:59,325 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.5575
Training Epoch: 19 [2048/50176]	Loss: 1.5876
Training Epoch: 19 [3072/50176]	Loss: 1.5261
Training Epoch: 19 [4096/50176]	Loss: 1.6015
Training Epoch: 19 [5120/50176]	Loss: 1.5338
Training Epoch: 19 [6144/50176]	Loss: 1.5801
Training Epoch: 19 [7168/50176]	Loss: 1.5631
Training Epoch: 19 [8192/50176]	Loss: 1.5373
Training Epoch: 19 [9216/50176]	Loss: 1.5926
Training Epoch: 19 [10240/50176]	Loss: 1.6091
Training Epoch: 19 [11264/50176]	Loss: 1.5862
Training Epoch: 19 [12288/50176]	Loss: 1.5327
Training Epoch: 19 [13312/50176]	Loss: 1.5212
Training Epoch: 19 [14336/50176]	Loss: 1.5308
Training Epoch: 19 [15360/50176]	Loss: 1.6196
Training Epoch: 19 [16384/50176]	Loss: 1.5473
Training Epoch: 19 [17408/50176]	Loss: 1.6315
Training Epoch: 19 [18432/50176]	Loss: 1.5922
Training Epoch: 19 [19456/50176]	Loss: 1.5235
Training Epoch: 19 [20480/50176]	Loss: 1.6051
Training Epoch: 19 [21504/50176]	Loss: 1.5522
Training Epoch: 19 [22528/50176]	Loss: 1.6274
Training Epoch: 19 [23552/50176]	Loss: 1.6484
Training Epoch: 19 [24576/50176]	Loss: 1.5138
Training Epoch: 19 [25600/50176]	Loss: 1.5666
Training Epoch: 19 [26624/50176]	Loss: 1.6542
Training Epoch: 19 [27648/50176]	Loss: 1.5516
Training Epoch: 19 [28672/50176]	Loss: 1.5614
Training Epoch: 19 [29696/50176]	Loss: 1.6153
Training Epoch: 19 [30720/50176]	Loss: 1.6500
Training Epoch: 19 [31744/50176]	Loss: 1.5592
Training Epoch: 19 [32768/50176]	Loss: 1.6560
Training Epoch: 19 [33792/50176]	Loss: 1.6138
Training Epoch: 19 [34816/50176]	Loss: 1.5772
Training Epoch: 19 [35840/50176]	Loss: 1.5975
Training Epoch: 19 [36864/50176]	Loss: 1.6013
Training Epoch: 19 [37888/50176]	Loss: 1.5272
Training Epoch: 19 [38912/50176]	Loss: 1.6364
Training Epoch: 19 [39936/50176]	Loss: 1.5926
Training Epoch: 19 [40960/50176]	Loss: 1.4788
Training Epoch: 19 [41984/50176]	Loss: 1.7058
Training Epoch: 19 [43008/50176]	Loss: 1.6703
Training Epoch: 19 [44032/50176]	Loss: 1.5990
Training Epoch: 19 [45056/50176]	Loss: 1.6005
Training Epoch: 19 [46080/50176]	Loss: 1.5231
Training Epoch: 19 [47104/50176]	Loss: 1.5975
Training Epoch: 19 [48128/50176]	Loss: 1.5407
Training Epoch: 19 [49152/50176]	Loss: 1.6276
Training Epoch: 19 [50176/50176]	Loss: 1.5215
2022-12-06 15:28:02.983 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:28:03,021 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.69 energy=460.14
2022-12-06 10:28:03,022 [ZeusDataLoader(train)] Up to epoch 20: time=989.13, energy=134335.70, cost=153716.52
2022-12-06 10:28:03,022 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:28:03,022 [ZeusDataLoader(train)] Expected next epoch: time=1035.57, energy=140944.32, cost=161084.77
2022-12-06 10:28:03,023 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0019, Accuracy: 0.4766
2022-12-06 10:28:03,202 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:28:03,203 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:28:03.205 [ZeusMonitor] Monitor started.
2022-12-06 15:28:03.205 [ZeusMonitor] Running indefinitely. 2022-12-06 15:28:03.205 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:28:03.205 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e21+gpu0.power.log
2022-12-06 10:28:46,666 [ZeusDataLoader(train)] train epoch 21 done: time=43.64 energy=6216.26
2022-12-06 10:28:46,669 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.5175
Training Epoch: 20 [2048/50176]	Loss: 1.5338
Training Epoch: 20 [3072/50176]	Loss: 1.5558
Training Epoch: 20 [4096/50176]	Loss: 1.4590
Training Epoch: 20 [5120/50176]	Loss: 1.4122
Training Epoch: 20 [6144/50176]	Loss: 1.5466
Training Epoch: 20 [7168/50176]	Loss: 1.4346
Training Epoch: 20 [8192/50176]	Loss: 1.4773
Training Epoch: 20 [9216/50176]	Loss: 1.4959
Training Epoch: 20 [10240/50176]	Loss: 1.4833
Training Epoch: 20 [11264/50176]	Loss: 1.5226
Training Epoch: 20 [12288/50176]	Loss: 1.5161
Training Epoch: 20 [13312/50176]	Loss: 1.4319
Training Epoch: 20 [14336/50176]	Loss: 1.4996
Training Epoch: 20 [15360/50176]	Loss: 1.5152
Training Epoch: 20 [16384/50176]	Loss: 1.5571
Training Epoch: 20 [17408/50176]	Loss: 1.4815
Training Epoch: 20 [18432/50176]	Loss: 1.5302
Training Epoch: 20 [19456/50176]	Loss: 1.5237
Training Epoch: 20 [20480/50176]	Loss: 1.5198
Training Epoch: 20 [21504/50176]	Loss: 1.5957
Training Epoch: 20 [22528/50176]	Loss: 1.4937
Training Epoch: 20 [23552/50176]	Loss: 1.4108
Training Epoch: 20 [24576/50176]	Loss: 1.5558
Training Epoch: 20 [25600/50176]	Loss: 1.5703
Training Epoch: 20 [26624/50176]	Loss: 1.5336
Training Epoch: 20 [27648/50176]	Loss: 1.4554
Training Epoch: 20 [28672/50176]	Loss: 1.5242
Training Epoch: 20 [29696/50176]	Loss: 1.5258
Training Epoch: 20 [30720/50176]	Loss: 1.5501
Training Epoch: 20 [31744/50176]	Loss: 1.5188
Training Epoch: 20 [32768/50176]	Loss: 1.5756
Training Epoch: 20 [33792/50176]	Loss: 1.4905
Training Epoch: 20 [34816/50176]	Loss: 1.5369
Training Epoch: 20 [35840/50176]	Loss: 1.5245
Training Epoch: 20 [36864/50176]	Loss: 1.6057
Training Epoch: 20 [37888/50176]	Loss: 1.4900
Training Epoch: 20 [38912/50176]	Loss: 1.5424
Training Epoch: 20 [39936/50176]	Loss: 1.5397
Training Epoch: 20 [40960/50176]	Loss: 1.5625
Training Epoch: 20 [41984/50176]	Loss: 1.4967
Training Epoch: 20 [43008/50176]	Loss: 1.4921
Training Epoch: 20 [44032/50176]	Loss: 1.4816
Training Epoch: 20 [45056/50176]	Loss: 1.5528
Training Epoch: 20 [46080/50176]	Loss: 1.5430
Training Epoch: 20 [47104/50176]	Loss: 1.5751
Training Epoch: 20 [48128/50176]	Loss: 1.5638
Training Epoch: 20 [49152/50176]	Loss: 1.5825
Training Epoch: 20 [50176/50176]	Loss: 1.5513
2022-12-06 15:28:50.405 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:28:50,456 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.78 energy=484.21
2022-12-06 10:28:50,456 [ZeusDataLoader(train)] Up to epoch 21: time=1036.54, energy=141036.17, cost=161215.47
2022-12-06 10:28:50,456 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:28:50,456 [ZeusDataLoader(train)] Expected next epoch: time=1082.99, energy=147644.79, cost=168583.71
2022-12-06 10:28:50,457 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0019, Accuracy: 0.4845
2022-12-06 10:28:50,619 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:28:50,619 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:28:50.641 [ZeusMonitor] Monitor started.
2022-12-06 15:28:50.641 [ZeusMonitor] Running indefinitely. 2022-12-06 15:28:50.641 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:28:50.641 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e22+gpu0.power.log
2022-12-06 10:29:34,628 [ZeusDataLoader(train)] train epoch 22 done: time=44.16 energy=6250.68
2022-12-06 10:29:34,632 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.3976
Training Epoch: 21 [2048/50176]	Loss: 1.3435
Training Epoch: 21 [3072/50176]	Loss: 1.4452
Training Epoch: 21 [4096/50176]	Loss: 1.4268
Training Epoch: 21 [5120/50176]	Loss: 1.4801
Training Epoch: 21 [6144/50176]	Loss: 1.3837
Training Epoch: 21 [7168/50176]	Loss: 1.4017
Training Epoch: 21 [8192/50176]	Loss: 1.4562
Training Epoch: 21 [9216/50176]	Loss: 1.4371
Training Epoch: 21 [10240/50176]	Loss: 1.4279
Training Epoch: 21 [11264/50176]	Loss: 1.4233
Training Epoch: 21 [12288/50176]	Loss: 1.4574
Training Epoch: 21 [13312/50176]	Loss: 1.4751
Training Epoch: 21 [14336/50176]	Loss: 1.4780
Training Epoch: 21 [15360/50176]	Loss: 1.3595
Training Epoch: 21 [16384/50176]	Loss: 1.4872
Training Epoch: 21 [17408/50176]	Loss: 1.4518
Training Epoch: 21 [18432/50176]	Loss: 1.4247
Training Epoch: 21 [19456/50176]	Loss: 1.4820
Training Epoch: 21 [20480/50176]	Loss: 1.4334
Training Epoch: 21 [21504/50176]	Loss: 1.4537
Training Epoch: 21 [22528/50176]	Loss: 1.5038
Training Epoch: 21 [23552/50176]	Loss: 1.4280
Training Epoch: 21 [24576/50176]	Loss: 1.4222
Training Epoch: 21 [25600/50176]	Loss: 1.4998
Training Epoch: 21 [26624/50176]	Loss: 1.4992
Training Epoch: 21 [27648/50176]	Loss: 1.4964
Training Epoch: 21 [28672/50176]	Loss: 1.4644
Training Epoch: 21 [29696/50176]	Loss: 1.5211
Training Epoch: 21 [30720/50176]	Loss: 1.4056
Training Epoch: 21 [31744/50176]	Loss: 1.4964
Training Epoch: 21 [32768/50176]	Loss: 1.4588
Training Epoch: 21 [33792/50176]	Loss: 1.4922
Training Epoch: 21 [34816/50176]	Loss: 1.4269
Training Epoch: 21 [35840/50176]	Loss: 1.5405
Training Epoch: 21 [36864/50176]	Loss: 1.3786
Training Epoch: 21 [37888/50176]	Loss: 1.5541
Training Epoch: 21 [38912/50176]	Loss: 1.4772
Training Epoch: 21 [39936/50176]	Loss: 1.5687
Training Epoch: 21 [40960/50176]	Loss: 1.4541
Training Epoch: 21 [41984/50176]	Loss: 1.5344
Training Epoch: 21 [43008/50176]	Loss: 1.4957
Training Epoch: 21 [44032/50176]	Loss: 1.5154
Training Epoch: 21 [45056/50176]	Loss: 1.5091
Training Epoch: 21 [46080/50176]	Loss: 1.5070
Training Epoch: 21 [47104/50176]	Loss: 1.5377
Training Epoch: 21 [48128/50176]	Loss: 1.4748
Training Epoch: 21 [49152/50176]	Loss: 1.5163
Training Epoch: 21 [50176/50176]	Loss: 1.5529
2022-12-06 15:29:38.385 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:29:38,424 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.78 energy=484.72
2022-12-06 10:29:38,424 [ZeusDataLoader(train)] Up to epoch 22: time=1084.49, energy=147771.57, cost=168778.58
2022-12-06 10:29:38,424 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:29:38,424 [ZeusDataLoader(train)] Expected next epoch: time=1130.93, energy=154380.19, cost=176146.82
2022-12-06 10:29:38,425 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0019, Accuracy: 0.4840
2022-12-06 10:29:38,567 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:29:38,568 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:29:38.571 [ZeusMonitor] Monitor started.
2022-12-06 15:29:38.571 [ZeusMonitor] Running indefinitely. 2022-12-06 15:29:38.571 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:29:38.571 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e23+gpu0.power.log
2022-12-06 10:30:22,747 [ZeusDataLoader(train)] train epoch 23 done: time=44.31 energy=6257.67
2022-12-06 10:30:22,750 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.4230
Training Epoch: 22 [2048/50176]	Loss: 1.4242
Training Epoch: 22 [3072/50176]	Loss: 1.3677
Training Epoch: 22 [4096/50176]	Loss: 1.3097
Training Epoch: 22 [5120/50176]	Loss: 1.4208
Training Epoch: 22 [6144/50176]	Loss: 1.3906
Training Epoch: 22 [7168/50176]	Loss: 1.3742
Training Epoch: 22 [8192/50176]	Loss: 1.4632
Training Epoch: 22 [9216/50176]	Loss: 1.3487
Training Epoch: 22 [10240/50176]	Loss: 1.3174
Training Epoch: 22 [11264/50176]	Loss: 1.5037
Training Epoch: 22 [12288/50176]	Loss: 1.4833
Training Epoch: 22 [13312/50176]	Loss: 1.3245
Training Epoch: 22 [14336/50176]	Loss: 1.3867
Training Epoch: 22 [15360/50176]	Loss: 1.3828
Training Epoch: 22 [16384/50176]	Loss: 1.3804
Training Epoch: 22 [17408/50176]	Loss: 1.3878
Training Epoch: 22 [18432/50176]	Loss: 1.4031
Training Epoch: 22 [19456/50176]	Loss: 1.4065
Training Epoch: 22 [20480/50176]	Loss: 1.4838
Training Epoch: 22 [21504/50176]	Loss: 1.4115
Training Epoch: 22 [22528/50176]	Loss: 1.5048
Training Epoch: 22 [23552/50176]	Loss: 1.4376
Training Epoch: 22 [24576/50176]	Loss: 1.5213
Training Epoch: 22 [25600/50176]	Loss: 1.4000
Training Epoch: 22 [26624/50176]	Loss: 1.4536
Training Epoch: 22 [27648/50176]	Loss: 1.4357
Training Epoch: 22 [28672/50176]	Loss: 1.4590
Training Epoch: 22 [29696/50176]	Loss: 1.4245
Training Epoch: 22 [30720/50176]	Loss: 1.3845
Training Epoch: 22 [31744/50176]	Loss: 1.5561
Training Epoch: 22 [32768/50176]	Loss: 1.4510
Training Epoch: 22 [33792/50176]	Loss: 1.4103
Training Epoch: 22 [34816/50176]	Loss: 1.4562
Training Epoch: 22 [35840/50176]	Loss: 1.4745
Training Epoch: 22 [36864/50176]	Loss: 1.4022
Training Epoch: 22 [37888/50176]	Loss: 1.4427
Training Epoch: 22 [38912/50176]	Loss: 1.4176
Training Epoch: 22 [39936/50176]	Loss: 1.4359
Training Epoch: 22 [40960/50176]	Loss: 1.4520
Training Epoch: 22 [41984/50176]	Loss: 1.5176
Training Epoch: 22 [43008/50176]	Loss: 1.4580
Training Epoch: 22 [44032/50176]	Loss: 1.3531
Training Epoch: 22 [45056/50176]	Loss: 1.4554
Training Epoch: 22 [46080/50176]	Loss: 1.3710
Training Epoch: 22 [47104/50176]	Loss: 1.3850
Training Epoch: 22 [48128/50176]	Loss: 1.5375
Training Epoch: 22 [49152/50176]	Loss: 1.4715
Training Epoch: 22 [50176/50176]	Loss: 1.3678
2022-12-06 15:30:26.491 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:30:26,545 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.79 energy=483.18
2022-12-06 10:30:26,546 [ZeusDataLoader(train)] Up to epoch 23: time=1132.59, energy=154512.42, cost=176357.85
2022-12-06 10:30:26,546 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:30:26,546 [ZeusDataLoader(train)] Expected next epoch: time=1179.04, energy=161121.05, cost=183726.10
2022-12-06 10:30:26,547 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0018, Accuracy: 0.4954
2022-12-06 10:30:26,681 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:30:26,681 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:30:26.685 [ZeusMonitor] Monitor started.
2022-12-06 15:30:26.685 [ZeusMonitor] Running indefinitely. 2022-12-06 15:30:26.685 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:30:26.685 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e24+gpu0.power.log
2022-12-06 10:31:10,372 [ZeusDataLoader(train)] train epoch 24 done: time=43.82 energy=6226.26
2022-12-06 10:31:10,375 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.3303
Training Epoch: 23 [2048/50176]	Loss: 1.2437
Training Epoch: 23 [3072/50176]	Loss: 1.3016
Training Epoch: 23 [4096/50176]	Loss: 1.3808
Training Epoch: 23 [5120/50176]	Loss: 1.3141
Training Epoch: 23 [6144/50176]	Loss: 1.3930
Training Epoch: 23 [7168/50176]	Loss: 1.3672
Training Epoch: 23 [8192/50176]	Loss: 1.3172
Training Epoch: 23 [9216/50176]	Loss: 1.3045
Training Epoch: 23 [10240/50176]	Loss: 1.2804
Training Epoch: 23 [11264/50176]	Loss: 1.3936
Training Epoch: 23 [12288/50176]	Loss: 1.2880
Training Epoch: 23 [13312/50176]	Loss: 1.4518
Training Epoch: 23 [14336/50176]	Loss: 1.3543
Training Epoch: 23 [15360/50176]	Loss: 1.3007
Training Epoch: 23 [16384/50176]	Loss: 1.3892
Training Epoch: 23 [17408/50176]	Loss: 1.4074
Training Epoch: 23 [18432/50176]	Loss: 1.3305
Training Epoch: 23 [19456/50176]	Loss: 1.4239
Training Epoch: 23 [20480/50176]	Loss: 1.3487
Training Epoch: 23 [21504/50176]	Loss: 1.3756
Training Epoch: 23 [22528/50176]	Loss: 1.3628
Training Epoch: 23 [23552/50176]	Loss: 1.3090
Training Epoch: 23 [24576/50176]	Loss: 1.3261
Training Epoch: 23 [25600/50176]	Loss: 1.3735
Training Epoch: 23 [26624/50176]	Loss: 1.3239
Training Epoch: 23 [27648/50176]	Loss: 1.3102
Training Epoch: 23 [28672/50176]	Loss: 1.3186
Training Epoch: 23 [29696/50176]	Loss: 1.3538
Training Epoch: 23 [30720/50176]	Loss: 1.4256
Training Epoch: 23 [31744/50176]	Loss: 1.4156
Training Epoch: 23 [32768/50176]	Loss: 1.3444
Training Epoch: 23 [33792/50176]	Loss: 1.3338
Training Epoch: 23 [34816/50176]	Loss: 1.3618
Training Epoch: 23 [35840/50176]	Loss: 1.3940
Training Epoch: 23 [36864/50176]	Loss: 1.3416
Training Epoch: 23 [37888/50176]	Loss: 1.4087
Training Epoch: 23 [38912/50176]	Loss: 1.4114
Training Epoch: 23 [39936/50176]	Loss: 1.4150
Training Epoch: 23 [40960/50176]	Loss: 1.4589
Training Epoch: 23 [41984/50176]	Loss: 1.4431
Training Epoch: 23 [43008/50176]	Loss: 1.3710
Training Epoch: 23 [44032/50176]	Loss: 1.4073
Training Epoch: 23 [45056/50176]	Loss: 1.4137
Training Epoch: 23 [46080/50176]	Loss: 1.5053
Training Epoch: 23 [47104/50176]	Loss: 1.4058
Training Epoch: 23 [48128/50176]	Loss: 1.3890
Training Epoch: 23 [49152/50176]	Loss: 1.3224
Training Epoch: 23 [50176/50176]	Loss: 1.4060
2022-12-06 15:31:14.105 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:31:14,142 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.76 energy=468.98
2022-12-06 10:31:14,142 [ZeusDataLoader(train)] Up to epoch 24: time=1180.17, energy=161207.66, cost=183868.35
2022-12-06 10:31:14,142 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:31:14,142 [ZeusDataLoader(train)] Expected next epoch: time=1226.61, energy=167816.28, cost=191236.60
2022-12-06 10:31:14,143 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0019, Accuracy: 0.4934
2022-12-06 10:31:14,326 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:31:14,327 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:31:14.329 [ZeusMonitor] Monitor started.
2022-12-06 15:31:14.329 [ZeusMonitor] Running indefinitely. 2022-12-06 15:31:14.329 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:31:14.329 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e25+gpu0.power.log
2022-12-06 10:31:57,760 [ZeusDataLoader(train)] train epoch 25 done: time=43.61 energy=6209.03
2022-12-06 10:31:57,763 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 1.2502
Training Epoch: 24 [2048/50176]	Loss: 1.2031
Training Epoch: 24 [3072/50176]	Loss: 1.2962
Training Epoch: 24 [4096/50176]	Loss: 1.2164
Training Epoch: 24 [5120/50176]	Loss: 1.2703
Training Epoch: 24 [6144/50176]	Loss: 1.2370
Training Epoch: 24 [7168/50176]	Loss: 1.3070
Training Epoch: 24 [8192/50176]	Loss: 1.2861
Training Epoch: 24 [9216/50176]	Loss: 1.3358
Training Epoch: 24 [10240/50176]	Loss: 1.3212
Training Epoch: 24 [11264/50176]	Loss: 1.2383
Training Epoch: 24 [12288/50176]	Loss: 1.2592
Training Epoch: 24 [13312/50176]	Loss: 1.2966
Training Epoch: 24 [14336/50176]	Loss: 1.3246
Training Epoch: 24 [15360/50176]	Loss: 1.2388
Training Epoch: 24 [16384/50176]	Loss: 1.2633
Training Epoch: 24 [17408/50176]	Loss: 1.3063
Training Epoch: 24 [18432/50176]	Loss: 1.3581
Training Epoch: 24 [19456/50176]	Loss: 1.3465
Training Epoch: 24 [20480/50176]	Loss: 1.3243
Training Epoch: 24 [21504/50176]	Loss: 1.3091
Training Epoch: 24 [22528/50176]	Loss: 1.3139
Training Epoch: 24 [23552/50176]	Loss: 1.3045
Training Epoch: 24 [24576/50176]	Loss: 1.2107
Training Epoch: 24 [25600/50176]	Loss: 1.3673
Training Epoch: 24 [26624/50176]	Loss: 1.3001
Training Epoch: 24 [27648/50176]	Loss: 1.3829
Training Epoch: 24 [28672/50176]	Loss: 1.3065
Training Epoch: 24 [29696/50176]	Loss: 1.2634
Training Epoch: 24 [30720/50176]	Loss: 1.3931
Training Epoch: 24 [31744/50176]	Loss: 1.3607
Training Epoch: 24 [32768/50176]	Loss: 1.3486
Training Epoch: 24 [33792/50176]	Loss: 1.3922
Training Epoch: 24 [34816/50176]	Loss: 1.3586
Training Epoch: 24 [35840/50176]	Loss: 1.3718
Training Epoch: 24 [36864/50176]	Loss: 1.3264
Training Epoch: 24 [37888/50176]	Loss: 1.3345
Training Epoch: 24 [38912/50176]	Loss: 1.3413
Training Epoch: 24 [39936/50176]	Loss: 1.2779
Training Epoch: 24 [40960/50176]	Loss: 1.2787
Training Epoch: 24 [41984/50176]	Loss: 1.3972
Training Epoch: 24 [43008/50176]	Loss: 1.3995
Training Epoch: 24 [44032/50176]	Loss: 1.2682
Training Epoch: 24 [45056/50176]	Loss: 1.4083
Training Epoch: 24 [46080/50176]	Loss: 1.3503
Training Epoch: 24 [47104/50176]	Loss: 1.4645
Training Epoch: 24 [48128/50176]	Loss: 1.4859
Training Epoch: 24 [49152/50176]	Loss: 1.3358
Training Epoch: 24 [50176/50176]	Loss: 1.2820
2022-12-06 15:32:01.429 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:32:01,463 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.69 energy=476.44
2022-12-06 10:32:01,463 [ZeusDataLoader(train)] Up to epoch 25: time=1227.47, energy=167893.13, cost=191349.97
2022-12-06 10:32:01,464 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:32:01,464 [ZeusDataLoader(train)] Expected next epoch: time=1273.91, energy=174501.76, cost=198718.21
2022-12-06 10:32:01,465 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0018, Accuracy: 0.5056
2022-12-06 10:32:01,640 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:32:01,640 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:32:01.642 [ZeusMonitor] Monitor started.
2022-12-06 15:32:01.642 [ZeusMonitor] Running indefinitely. 2022-12-06 15:32:01.642 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:32:01.642 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e26+gpu0.power.log
2022-12-06 10:32:45,025 [ZeusDataLoader(train)] train epoch 26 done: time=43.55 energy=6203.09
2022-12-06 10:32:45,028 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 1.1731
Training Epoch: 25 [2048/50176]	Loss: 1.1727
Training Epoch: 25 [3072/50176]	Loss: 1.2640
Training Epoch: 25 [4096/50176]	Loss: 1.2998
Training Epoch: 25 [5120/50176]	Loss: 1.2451
Training Epoch: 25 [6144/50176]	Loss: 1.2798
Training Epoch: 25 [7168/50176]	Loss: 1.2594
Training Epoch: 25 [8192/50176]	Loss: 1.2610
Training Epoch: 25 [9216/50176]	Loss: 1.3259
Training Epoch: 25 [10240/50176]	Loss: 1.2311
Training Epoch: 25 [11264/50176]	Loss: 1.2075
Training Epoch: 25 [12288/50176]	Loss: 1.2751
Training Epoch: 25 [13312/50176]	Loss: 1.2189
Training Epoch: 25 [14336/50176]	Loss: 1.2056
Training Epoch: 25 [15360/50176]	Loss: 1.2836
Training Epoch: 25 [16384/50176]	Loss: 1.3611
Training Epoch: 25 [17408/50176]	Loss: 1.2636
Training Epoch: 25 [18432/50176]	Loss: 1.3122
Training Epoch: 25 [19456/50176]	Loss: 1.2431
Training Epoch: 25 [20480/50176]	Loss: 1.2918
Training Epoch: 25 [21504/50176]	Loss: 1.2311
Training Epoch: 25 [22528/50176]	Loss: 1.3157
Training Epoch: 25 [23552/50176]	Loss: 1.2298
Training Epoch: 25 [24576/50176]	Loss: 1.1947
Training Epoch: 25 [25600/50176]	Loss: 1.2352
Training Epoch: 25 [26624/50176]	Loss: 1.2742
Training Epoch: 25 [27648/50176]	Loss: 1.2932
Training Epoch: 25 [28672/50176]	Loss: 1.3567
Training Epoch: 25 [29696/50176]	Loss: 1.2944
Training Epoch: 25 [30720/50176]	Loss: 1.3067
Training Epoch: 25 [31744/50176]	Loss: 1.2704
Training Epoch: 25 [32768/50176]	Loss: 1.3179
Training Epoch: 25 [33792/50176]	Loss: 1.2486
Training Epoch: 25 [34816/50176]	Loss: 1.2202
Training Epoch: 25 [35840/50176]	Loss: 1.3344
Training Epoch: 25 [36864/50176]	Loss: 1.2712
Training Epoch: 25 [37888/50176]	Loss: 1.3395
Training Epoch: 25 [38912/50176]	Loss: 1.2710
Training Epoch: 25 [39936/50176]	Loss: 1.2536
Training Epoch: 25 [40960/50176]	Loss: 1.3257
Training Epoch: 25 [41984/50176]	Loss: 1.3376
Training Epoch: 25 [43008/50176]	Loss: 1.3061
Training Epoch: 25 [44032/50176]	Loss: 1.3668
Training Epoch: 25 [45056/50176]	Loss: 1.3814
Training Epoch: 25 [46080/50176]	Loss: 1.3184
Training Epoch: 25 [47104/50176]	Loss: 1.3116
Training Epoch: 25 [48128/50176]	Loss: 1.3445
Training Epoch: 25 [49152/50176]	Loss: 1.3273
Training Epoch: 25 [50176/50176]	Loss: 1.3452
2022-12-06 15:32:48.659 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:32:48,668 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.63 energy=456.71
2022-12-06 10:32:48,668 [ZeusDataLoader(train)] Up to epoch 26: time=1274.65, energy=174552.93, cost=198808.51
2022-12-06 10:32:48,668 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:32:48,668 [ZeusDataLoader(train)] Expected next epoch: time=1321.10, energy=181161.55, cost=206176.75
2022-12-06 10:32:48,669 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0018, Accuracy: 0.5107
2022-12-06 10:32:48,808 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:32:48,809 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:32:48.810 [ZeusMonitor] Monitor started.
2022-12-06 15:32:48.811 [ZeusMonitor] Running indefinitely. 2022-12-06 15:32:48.811 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:32:48.811 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e27+gpu0.power.log
2022-12-06 10:33:32,262 [ZeusDataLoader(train)] train epoch 27 done: time=43.58 energy=6200.22
2022-12-06 10:33:32,265 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 1.1735
Training Epoch: 26 [2048/50176]	Loss: 1.2650
Training Epoch: 26 [3072/50176]	Loss: 1.1965
Training Epoch: 26 [4096/50176]	Loss: 1.1946
Training Epoch: 26 [5120/50176]	Loss: 1.1662
Training Epoch: 26 [6144/50176]	Loss: 1.1941
Training Epoch: 26 [7168/50176]	Loss: 1.1955
Training Epoch: 26 [8192/50176]	Loss: 1.2178
Training Epoch: 26 [9216/50176]	Loss: 1.1341
Training Epoch: 26 [10240/50176]	Loss: 1.2886
Training Epoch: 26 [11264/50176]	Loss: 1.1663
Training Epoch: 26 [12288/50176]	Loss: 1.1782
Training Epoch: 26 [13312/50176]	Loss: 1.1490
Training Epoch: 26 [14336/50176]	Loss: 1.1913
Training Epoch: 26 [15360/50176]	Loss: 1.1538
Training Epoch: 26 [16384/50176]	Loss: 1.2610
Training Epoch: 26 [17408/50176]	Loss: 1.2459
Training Epoch: 26 [18432/50176]	Loss: 1.2265
Training Epoch: 26 [19456/50176]	Loss: 1.2376
Training Epoch: 26 [20480/50176]	Loss: 1.1913
Training Epoch: 26 [21504/50176]	Loss: 1.2237
Training Epoch: 26 [22528/50176]	Loss: 1.1783
Training Epoch: 26 [23552/50176]	Loss: 1.2645
Training Epoch: 26 [24576/50176]	Loss: 1.2020
Training Epoch: 26 [25600/50176]	Loss: 1.2345
Training Epoch: 26 [26624/50176]	Loss: 1.2278
Training Epoch: 26 [27648/50176]	Loss: 1.2432
Training Epoch: 26 [28672/50176]	Loss: 1.1700
Training Epoch: 26 [29696/50176]	Loss: 1.2163
Training Epoch: 26 [30720/50176]	Loss: 1.3216
Training Epoch: 26 [31744/50176]	Loss: 1.2336
Training Epoch: 26 [32768/50176]	Loss: 1.2351
Training Epoch: 26 [33792/50176]	Loss: 1.2843
Training Epoch: 26 [34816/50176]	Loss: 1.3240
Training Epoch: 26 [35840/50176]	Loss: 1.1828
Training Epoch: 26 [36864/50176]	Loss: 1.2424
Training Epoch: 26 [37888/50176]	Loss: 1.2553
Training Epoch: 26 [38912/50176]	Loss: 1.2106
Training Epoch: 26 [39936/50176]	Loss: 1.3466
Training Epoch: 26 [40960/50176]	Loss: 1.3047
Training Epoch: 26 [41984/50176]	Loss: 1.3095
Training Epoch: 26 [43008/50176]	Loss: 1.2615
Training Epoch: 26 [44032/50176]	Loss: 1.2887
Training Epoch: 26 [45056/50176]	Loss: 1.2704
Training Epoch: 26 [46080/50176]	Loss: 1.2724
Training Epoch: 26 [47104/50176]	Loss: 1.3193
Training Epoch: 26 [48128/50176]	Loss: 1.2808
Training Epoch: 26 [49152/50176]	Loss: 1.2150
Training Epoch: 26 [50176/50176]	Loss: 1.2457
2022-12-06 15:33:35.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:33:35,959 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.69 energy=472.50
2022-12-06 10:33:35,960 [ZeusDataLoader(train)] Up to epoch 27: time=1321.92, energy=181225.64, cost=206281.12
2022-12-06 10:33:35,960 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:33:35,960 [ZeusDataLoader(train)] Expected next epoch: time=1368.37, energy=187834.27, cost=213649.36
2022-12-06 10:33:35,961 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0018, Accuracy: 0.5070
2022-12-06 10:33:36,131 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:33:36,132 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:33:36.141 [ZeusMonitor] Monitor started.
2022-12-06 15:33:36.142 [ZeusMonitor] Running indefinitely. 2022-12-06 15:33:36.142 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:33:36.142 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e28+gpu0.power.log
2022-12-06 10:34:19,584 [ZeusDataLoader(train)] train epoch 28 done: time=43.62 energy=6200.04
2022-12-06 10:34:19,587 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 1.1630
Training Epoch: 27 [2048/50176]	Loss: 1.1866
Training Epoch: 27 [3072/50176]	Loss: 1.1502
Training Epoch: 27 [4096/50176]	Loss: 1.1972
Training Epoch: 27 [5120/50176]	Loss: 1.1412
Training Epoch: 27 [6144/50176]	Loss: 1.0985
Training Epoch: 27 [7168/50176]	Loss: 1.0714
Training Epoch: 27 [8192/50176]	Loss: 1.1560
Training Epoch: 27 [9216/50176]	Loss: 1.1067
Training Epoch: 27 [10240/50176]	Loss: 1.1602
Training Epoch: 27 [11264/50176]	Loss: 1.1631
Training Epoch: 27 [12288/50176]	Loss: 1.1760
Training Epoch: 27 [13312/50176]	Loss: 1.1988
Training Epoch: 27 [14336/50176]	Loss: 1.2222
Training Epoch: 27 [15360/50176]	Loss: 1.1537
Training Epoch: 27 [16384/50176]	Loss: 1.1631
Training Epoch: 27 [17408/50176]	Loss: 1.1268
Training Epoch: 27 [18432/50176]	Loss: 1.1813
Training Epoch: 27 [19456/50176]	Loss: 1.2113
Training Epoch: 27 [20480/50176]	Loss: 1.1206
Training Epoch: 27 [21504/50176]	Loss: 1.2543
Training Epoch: 27 [22528/50176]	Loss: 1.1534
Training Epoch: 27 [23552/50176]	Loss: 1.1340
Training Epoch: 27 [24576/50176]	Loss: 1.1241
Training Epoch: 27 [25600/50176]	Loss: 1.1962
Training Epoch: 27 [26624/50176]	Loss: 1.2652
Training Epoch: 27 [27648/50176]	Loss: 1.2005
Training Epoch: 27 [28672/50176]	Loss: 1.2307
Training Epoch: 27 [29696/50176]	Loss: 1.1446
Training Epoch: 27 [30720/50176]	Loss: 1.1975
Training Epoch: 27 [31744/50176]	Loss: 1.3058
Training Epoch: 27 [32768/50176]	Loss: 1.2271
Training Epoch: 27 [33792/50176]	Loss: 1.1694
Training Epoch: 27 [34816/50176]	Loss: 1.2979
Training Epoch: 27 [35840/50176]	Loss: 1.2440
Training Epoch: 27 [36864/50176]	Loss: 1.2127
Training Epoch: 27 [37888/50176]	Loss: 1.1991
Training Epoch: 27 [38912/50176]	Loss: 1.1918
Training Epoch: 27 [39936/50176]	Loss: 1.2118
Training Epoch: 27 [40960/50176]	Loss: 1.2133
Training Epoch: 27 [41984/50176]	Loss: 1.1536
Training Epoch: 27 [43008/50176]	Loss: 1.2198
Training Epoch: 27 [44032/50176]	Loss: 1.2752
Training Epoch: 27 [45056/50176]	Loss: 1.1820
Training Epoch: 27 [46080/50176]	Loss: 1.2797
Training Epoch: 27 [47104/50176]	Loss: 1.3073
Training Epoch: 27 [48128/50176]	Loss: 1.2475
Training Epoch: 27 [49152/50176]	Loss: 1.3233
Training Epoch: 27 [50176/50176]	Loss: 1.2660
2022-12-06 15:34:23.270 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:34:23,326 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.73 energy=473.13
2022-12-06 10:34:23,326 [ZeusDataLoader(train)] Up to epoch 28: time=1369.27, energy=187898.80, cost=213760.54
2022-12-06 10:34:23,327 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:34:23,327 [ZeusDataLoader(train)] Expected next epoch: time=1415.72, energy=194507.43, cost=221128.79
2022-12-06 10:34:23,328 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0018, Accuracy: 0.5161
2022-12-06 10:34:23,506 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:34:23,507 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:34:23.509 [ZeusMonitor] Monitor started.
2022-12-06 15:34:23.509 [ZeusMonitor] Running indefinitely. 2022-12-06 15:34:23.509 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:34:23.509 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e29+gpu0.power.log
2022-12-06 10:35:06,904 [ZeusDataLoader(train)] train epoch 29 done: time=43.57 energy=6205.56
2022-12-06 10:35:06,907 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 1.1030
Training Epoch: 28 [2048/50176]	Loss: 1.1356
Training Epoch: 28 [3072/50176]	Loss: 1.1005
Training Epoch: 28 [4096/50176]	Loss: 1.1708
Training Epoch: 28 [5120/50176]	Loss: 1.0676
Training Epoch: 28 [6144/50176]	Loss: 1.0899
Training Epoch: 28 [7168/50176]	Loss: 1.1228
Training Epoch: 28 [8192/50176]	Loss: 1.0996
Training Epoch: 28 [9216/50176]	Loss: 1.1323
Training Epoch: 28 [10240/50176]	Loss: 1.0496
Training Epoch: 28 [11264/50176]	Loss: 1.1223
Training Epoch: 28 [12288/50176]	Loss: 1.1003
Training Epoch: 28 [13312/50176]	Loss: 1.0928
Training Epoch: 28 [14336/50176]	Loss: 1.1152
Training Epoch: 28 [15360/50176]	Loss: 1.0797
Training Epoch: 28 [16384/50176]	Loss: 1.1322
Training Epoch: 28 [17408/50176]	Loss: 1.1976
Training Epoch: 28 [18432/50176]	Loss: 1.0610
Training Epoch: 28 [19456/50176]	Loss: 1.2232
Training Epoch: 28 [20480/50176]	Loss: 1.0752
Training Epoch: 28 [21504/50176]	Loss: 1.1448
Training Epoch: 28 [22528/50176]	Loss: 1.1776
Training Epoch: 28 [23552/50176]	Loss: 1.2335
Training Epoch: 28 [24576/50176]	Loss: 1.0666
Training Epoch: 28 [25600/50176]	Loss: 1.1646
Training Epoch: 28 [26624/50176]	Loss: 1.1101
Training Epoch: 28 [27648/50176]	Loss: 1.2269
Training Epoch: 28 [28672/50176]	Loss: 1.1251
Training Epoch: 28 [29696/50176]	Loss: 1.1385
Training Epoch: 28 [30720/50176]	Loss: 1.1171
Training Epoch: 28 [31744/50176]	Loss: 1.2316
Training Epoch: 28 [32768/50176]	Loss: 1.1437
Training Epoch: 28 [33792/50176]	Loss: 1.0973
Training Epoch: 28 [34816/50176]	Loss: 1.1391
Training Epoch: 28 [35840/50176]	Loss: 1.0976
Training Epoch: 28 [36864/50176]	Loss: 1.2366
Training Epoch: 28 [37888/50176]	Loss: 1.1443
Training Epoch: 28 [38912/50176]	Loss: 1.1645
Training Epoch: 28 [39936/50176]	Loss: 1.2510
Training Epoch: 28 [40960/50176]	Loss: 1.2561
Training Epoch: 28 [41984/50176]	Loss: 1.1695
Training Epoch: 28 [43008/50176]	Loss: 1.1438
Training Epoch: 28 [44032/50176]	Loss: 1.1934
Training Epoch: 28 [45056/50176]	Loss: 1.3638
Training Epoch: 28 [46080/50176]	Loss: 1.1577
Training Epoch: 28 [47104/50176]	Loss: 1.1729
Training Epoch: 28 [48128/50176]	Loss: 1.1024
Training Epoch: 28 [49152/50176]	Loss: 1.1932
Training Epoch: 28 [50176/50176]	Loss: 1.1939
2022-12-06 15:35:10.656 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:35:10,676 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.76 energy=478.31
2022-12-06 10:35:10,676 [ZeusDataLoader(train)] Up to epoch 29: time=1416.60, energy=194582.67, cost=221243.82
2022-12-06 10:35:10,676 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:35:10,676 [ZeusDataLoader(train)] Expected next epoch: time=1463.04, energy=201191.30, cost=228612.06
2022-12-06 10:35:10,677 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0018, Accuracy: 0.5169
2022-12-06 10:35:10,823 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:35:10,823 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:35:10.827 [ZeusMonitor] Monitor started.
2022-12-06 15:35:10.827 [ZeusMonitor] Running indefinitely. 2022-12-06 15:35:10.827 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:35:10.827 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e30+gpu0.power.log
2022-12-06 10:35:54,257 [ZeusDataLoader(train)] train epoch 30 done: time=43.57 energy=6202.70
2022-12-06 10:35:54,260 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 1.0577
Training Epoch: 29 [2048/50176]	Loss: 1.0253
Training Epoch: 29 [3072/50176]	Loss: 1.0623
Training Epoch: 29 [4096/50176]	Loss: 1.0728
Training Epoch: 29 [5120/50176]	Loss: 1.1483
Training Epoch: 29 [6144/50176]	Loss: 1.0773
Training Epoch: 29 [7168/50176]	Loss: 1.0514
Training Epoch: 29 [8192/50176]	Loss: 1.0215
Training Epoch: 29 [9216/50176]	Loss: 1.1169
Training Epoch: 29 [10240/50176]	Loss: 1.0428
Training Epoch: 29 [11264/50176]	Loss: 1.0706
Training Epoch: 29 [12288/50176]	Loss: 1.1207
Training Epoch: 29 [13312/50176]	Loss: 0.9971
Training Epoch: 29 [14336/50176]	Loss: 1.0302
Training Epoch: 29 [15360/50176]	Loss: 1.1806
Training Epoch: 29 [16384/50176]	Loss: 1.0976
Training Epoch: 29 [17408/50176]	Loss: 1.0420
Training Epoch: 29 [18432/50176]	Loss: 1.0725
Training Epoch: 29 [19456/50176]	Loss: 1.1921
Training Epoch: 29 [20480/50176]	Loss: 1.0715
Training Epoch: 29 [21504/50176]	Loss: 1.1049
Training Epoch: 29 [22528/50176]	Loss: 1.0583
Training Epoch: 29 [23552/50176]	Loss: 1.0822
Training Epoch: 29 [24576/50176]	Loss: 1.1136
Training Epoch: 29 [25600/50176]	Loss: 1.0941
Training Epoch: 29 [26624/50176]	Loss: 1.0750
Training Epoch: 29 [27648/50176]	Loss: 1.1584
Training Epoch: 29 [28672/50176]	Loss: 1.0608
Training Epoch: 29 [29696/50176]	Loss: 1.0808
Training Epoch: 29 [30720/50176]	Loss: 1.1491
Training Epoch: 29 [31744/50176]	Loss: 1.1366
Training Epoch: 29 [32768/50176]	Loss: 1.1210
Training Epoch: 29 [33792/50176]	Loss: 1.1140
Training Epoch: 29 [34816/50176]	Loss: 1.1771
Training Epoch: 29 [35840/50176]	Loss: 1.0165
Training Epoch: 29 [36864/50176]	Loss: 1.1567
Training Epoch: 29 [37888/50176]	Loss: 1.1168
Training Epoch: 29 [38912/50176]	Loss: 1.1278
Training Epoch: 29 [39936/50176]	Loss: 1.2005
Training Epoch: 29 [40960/50176]	Loss: 1.0879
Training Epoch: 29 [41984/50176]	Loss: 1.1235
Training Epoch: 29 [43008/50176]	Loss: 1.1597
Training Epoch: 29 [44032/50176]	Loss: 1.1119
Training Epoch: 29 [45056/50176]	Loss: 1.1656
Training Epoch: 29 [46080/50176]	Loss: 1.1048
Training Epoch: 29 [47104/50176]	Loss: 1.1123
Training Epoch: 29 [48128/50176]	Loss: 1.1590
Training Epoch: 29 [49152/50176]	Loss: 1.1289
Training Epoch: 29 [50176/50176]	Loss: 1.2606
2022-12-06 15:35:57.966 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:35:58,021 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.75 energy=470.93
2022-12-06 10:35:58,021 [ZeusDataLoader(train)] Up to epoch 30: time=1463.92, energy=201256.30, cost=228721.53
2022-12-06 10:35:58,021 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:35:58,021 [ZeusDataLoader(train)] Expected next epoch: time=1510.37, energy=207864.93, cost=236089.77
2022-12-06 10:35:58,022 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0018, Accuracy: 0.5231
2022-12-06 10:35:58,199 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:35:58,200 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:35:58.202 [ZeusMonitor] Monitor started.
2022-12-06 15:35:58.202 [ZeusMonitor] Running indefinitely. 2022-12-06 15:35:58.202 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:35:58.202 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e31+gpu0.power.log
2022-12-06 10:36:41,591 [ZeusDataLoader(train)] train epoch 31 done: time=43.56 energy=6193.98
2022-12-06 10:36:41,594 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 1.1547
Training Epoch: 30 [2048/50176]	Loss: 1.0784
Training Epoch: 30 [3072/50176]	Loss: 1.0566
Training Epoch: 30 [4096/50176]	Loss: 1.0574
Training Epoch: 30 [5120/50176]	Loss: 1.0100
Training Epoch: 30 [6144/50176]	Loss: 1.0643
Training Epoch: 30 [7168/50176]	Loss: 1.0414
Training Epoch: 30 [8192/50176]	Loss: 1.1220
Training Epoch: 30 [9216/50176]	Loss: 1.0641
Training Epoch: 30 [10240/50176]	Loss: 1.0882
Training Epoch: 30 [11264/50176]	Loss: 1.0273
Training Epoch: 30 [12288/50176]	Loss: 1.0523
Training Epoch: 30 [13312/50176]	Loss: 1.0539
Training Epoch: 30 [14336/50176]	Loss: 1.0612
Training Epoch: 30 [15360/50176]	Loss: 1.0395
Training Epoch: 30 [16384/50176]	Loss: 1.0608
Training Epoch: 30 [17408/50176]	Loss: 1.0461
Training Epoch: 30 [18432/50176]	Loss: 1.0305
Training Epoch: 30 [19456/50176]	Loss: 1.0072
Training Epoch: 30 [20480/50176]	Loss: 1.0091
Training Epoch: 30 [21504/50176]	Loss: 1.0125
Training Epoch: 30 [22528/50176]	Loss: 1.0196
Training Epoch: 30 [23552/50176]	Loss: 1.0517
Training Epoch: 30 [24576/50176]	Loss: 1.0927
Training Epoch: 30 [25600/50176]	Loss: 1.0341
Training Epoch: 30 [26624/50176]	Loss: 1.0442
Training Epoch: 30 [27648/50176]	Loss: 1.1282
Training Epoch: 30 [28672/50176]	Loss: 1.1393
Training Epoch: 30 [29696/50176]	Loss: 1.0762
Training Epoch: 30 [30720/50176]	Loss: 1.0733
Training Epoch: 30 [31744/50176]	Loss: 1.0301
Training Epoch: 30 [32768/50176]	Loss: 1.0908
Training Epoch: 30 [33792/50176]	Loss: 1.0949
Training Epoch: 30 [34816/50176]	Loss: 1.1353
Training Epoch: 30 [35840/50176]	Loss: 1.0659
Training Epoch: 30 [36864/50176]	Loss: 1.1095
Training Epoch: 30 [37888/50176]	Loss: 1.0837
Training Epoch: 30 [38912/50176]	Loss: 1.1504
Training Epoch: 30 [39936/50176]	Loss: 1.0658
Training Epoch: 30 [40960/50176]	Loss: 1.1592
Training Epoch: 30 [41984/50176]	Loss: 1.1097
Training Epoch: 30 [43008/50176]	Loss: 1.1166
Training Epoch: 30 [44032/50176]	Loss: 1.0604
Training Epoch: 30 [45056/50176]	Loss: 1.0805
Training Epoch: 30 [46080/50176]	Loss: 1.0724
Training Epoch: 30 [47104/50176]	Loss: 1.0598
Training Epoch: 30 [48128/50176]	Loss: 1.1137
Training Epoch: 30 [49152/50176]	Loss: 1.1529
Training Epoch: 30 [50176/50176]	Loss: 1.1769
2022-12-06 15:36:45.298 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:36:45,341 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.74 energy=474.30
2022-12-06 10:36:45,341 [ZeusDataLoader(train)] Up to epoch 31: time=1511.22, energy=207924.58, cost=236194.40
2022-12-06 10:36:45,341 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:36:45,341 [ZeusDataLoader(train)] Expected next epoch: time=1557.67, energy=214533.21, cost=243562.65
2022-12-06 10:36:45,342 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0018, Accuracy: 0.5235
2022-12-06 10:36:45,518 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:36:45,519 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:36:45.521 [ZeusMonitor] Monitor started.
2022-12-06 15:36:45.521 [ZeusMonitor] Running indefinitely. 2022-12-06 15:36:45.521 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:36:45.521 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e32+gpu0.power.log
2022-12-06 10:37:28,941 [ZeusDataLoader(train)] train epoch 32 done: time=43.59 energy=6194.22
2022-12-06 10:37:28,944 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 1.0020
Training Epoch: 31 [2048/50176]	Loss: 0.9226
Training Epoch: 31 [3072/50176]	Loss: 1.0659
Training Epoch: 31 [4096/50176]	Loss: 0.9851
Training Epoch: 31 [5120/50176]	Loss: 0.9855
Training Epoch: 31 [6144/50176]	Loss: 1.0110
Training Epoch: 31 [7168/50176]	Loss: 1.0127
Training Epoch: 31 [8192/50176]	Loss: 0.9786
Training Epoch: 31 [9216/50176]	Loss: 0.9562
Training Epoch: 31 [10240/50176]	Loss: 1.0701
Training Epoch: 31 [11264/50176]	Loss: 0.9482
Training Epoch: 31 [12288/50176]	Loss: 1.0202
Training Epoch: 31 [13312/50176]	Loss: 1.0660
Training Epoch: 31 [14336/50176]	Loss: 0.9429
Training Epoch: 31 [15360/50176]	Loss: 0.9904
Training Epoch: 31 [16384/50176]	Loss: 0.9865
Training Epoch: 31 [17408/50176]	Loss: 1.0166
Training Epoch: 31 [18432/50176]	Loss: 1.0023
Training Epoch: 31 [19456/50176]	Loss: 1.0393
Training Epoch: 31 [20480/50176]	Loss: 1.0336
Training Epoch: 31 [21504/50176]	Loss: 1.0318
Training Epoch: 31 [22528/50176]	Loss: 1.0509
Training Epoch: 31 [23552/50176]	Loss: 1.0176
Training Epoch: 31 [24576/50176]	Loss: 1.0153
Training Epoch: 31 [25600/50176]	Loss: 1.0047
Training Epoch: 31 [26624/50176]	Loss: 1.0116
Training Epoch: 31 [27648/50176]	Loss: 1.0115
Training Epoch: 31 [28672/50176]	Loss: 1.0394
Training Epoch: 31 [29696/50176]	Loss: 1.0036
Training Epoch: 31 [30720/50176]	Loss: 0.9843
Training Epoch: 31 [31744/50176]	Loss: 1.0489
Training Epoch: 31 [32768/50176]	Loss: 1.0976
Training Epoch: 31 [33792/50176]	Loss: 0.9907
Training Epoch: 31 [34816/50176]	Loss: 1.1291
Training Epoch: 31 [35840/50176]	Loss: 1.0445
Training Epoch: 31 [36864/50176]	Loss: 1.1020
Training Epoch: 31 [37888/50176]	Loss: 1.1243
Training Epoch: 31 [38912/50176]	Loss: 1.0846
Training Epoch: 31 [39936/50176]	Loss: 1.1092
Training Epoch: 31 [40960/50176]	Loss: 1.0925
Training Epoch: 31 [41984/50176]	Loss: 1.1060
Training Epoch: 31 [43008/50176]	Loss: 1.0179
Training Epoch: 31 [44032/50176]	Loss: 1.0573
Training Epoch: 31 [45056/50176]	Loss: 1.1041
Training Epoch: 31 [46080/50176]	Loss: 1.0562
Training Epoch: 31 [47104/50176]	Loss: 0.9779
Training Epoch: 31 [48128/50176]	Loss: 1.1551
Training Epoch: 31 [49152/50176]	Loss: 1.0523
Training Epoch: 31 [50176/50176]	Loss: 1.0682
2022-12-06 15:37:32.617 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:37:32,655 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.70 energy=469.65
2022-12-06 10:37:32,655 [ZeusDataLoader(train)] Up to epoch 32: time=1558.52, energy=214588.45, cost=243664.61
2022-12-06 10:37:32,656 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:37:32,656 [ZeusDataLoader(train)] Expected next epoch: time=1604.96, energy=221197.08, cost=251032.86
2022-12-06 10:37:32,657 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0018, Accuracy: 0.5314
2022-12-06 10:37:32,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:37:32,836 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:37:32.838 [ZeusMonitor] Monitor started.
2022-12-06 15:37:32.838 [ZeusMonitor] Running indefinitely. 2022-12-06 15:37:32.838 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:37:32.838 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e33+gpu0.power.log
2022-12-06 10:38:16,220 [ZeusDataLoader(train)] train epoch 33 done: time=43.56 energy=6193.15
2022-12-06 10:38:16,223 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.9469
Training Epoch: 32 [2048/50176]	Loss: 0.9222
Training Epoch: 32 [3072/50176]	Loss: 1.0001
Training Epoch: 32 [4096/50176]	Loss: 0.9676
Training Epoch: 32 [5120/50176]	Loss: 0.9482
Training Epoch: 32 [6144/50176]	Loss: 0.9942
Training Epoch: 32 [7168/50176]	Loss: 0.9490
Training Epoch: 32 [8192/50176]	Loss: 0.9747
Training Epoch: 32 [9216/50176]	Loss: 0.8948
Training Epoch: 32 [10240/50176]	Loss: 0.8935
Training Epoch: 32 [11264/50176]	Loss: 0.9600
Training Epoch: 32 [12288/50176]	Loss: 1.0573
Training Epoch: 32 [13312/50176]	Loss: 0.9428
Training Epoch: 32 [14336/50176]	Loss: 1.0291
Training Epoch: 32 [15360/50176]	Loss: 0.9277
Training Epoch: 32 [16384/50176]	Loss: 0.9106
Training Epoch: 32 [17408/50176]	Loss: 1.0096
Training Epoch: 32 [18432/50176]	Loss: 1.0072
Training Epoch: 32 [19456/50176]	Loss: 0.9632
Training Epoch: 32 [20480/50176]	Loss: 1.0077
Training Epoch: 32 [21504/50176]	Loss: 1.0283
Training Epoch: 32 [22528/50176]	Loss: 1.0204
Training Epoch: 32 [23552/50176]	Loss: 1.0310
Training Epoch: 32 [24576/50176]	Loss: 0.9538
Training Epoch: 32 [25600/50176]	Loss: 1.0662
Training Epoch: 32 [26624/50176]	Loss: 1.0025
Training Epoch: 32 [27648/50176]	Loss: 0.9100
Training Epoch: 32 [28672/50176]	Loss: 0.9757
Training Epoch: 32 [29696/50176]	Loss: 1.0333
Training Epoch: 32 [30720/50176]	Loss: 0.9572
Training Epoch: 32 [31744/50176]	Loss: 1.0129
Training Epoch: 32 [32768/50176]	Loss: 0.9554
Training Epoch: 32 [33792/50176]	Loss: 0.9921
Training Epoch: 32 [34816/50176]	Loss: 1.0314
Training Epoch: 32 [35840/50176]	Loss: 0.9644
Training Epoch: 32 [36864/50176]	Loss: 1.0634
Training Epoch: 32 [37888/50176]	Loss: 1.0137
Training Epoch: 32 [38912/50176]	Loss: 1.0395
Training Epoch: 32 [39936/50176]	Loss: 1.0489
Training Epoch: 32 [40960/50176]	Loss: 1.0078
Training Epoch: 32 [41984/50176]	Loss: 0.9407
Training Epoch: 32 [43008/50176]	Loss: 1.0743
Training Epoch: 32 [44032/50176]	Loss: 1.0377
Training Epoch: 32 [45056/50176]	Loss: 1.0130
Training Epoch: 32 [46080/50176]	Loss: 1.0390
Training Epoch: 32 [47104/50176]	Loss: 1.0292
Training Epoch: 32 [48128/50176]	Loss: 1.0367
Training Epoch: 32 [49152/50176]	Loss: 1.0766
Training Epoch: 32 [50176/50176]	Loss: 1.0305
2022-12-06 15:38:19.938 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:38:19,977 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.75 energy=481.01
2022-12-06 10:38:19,977 [ZeusDataLoader(train)] Up to epoch 33: time=1605.82, energy=221262.60, cost=251140.60
2022-12-06 10:38:19,977 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:38:19,977 [ZeusDataLoader(train)] Expected next epoch: time=1652.27, energy=227871.23, cost=258508.84
2022-12-06 10:38:19,978 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0018, Accuracy: 0.5272
2022-12-06 10:38:20,164 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:38:20,165 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:38:20.167 [ZeusMonitor] Monitor started.
2022-12-06 15:38:20.167 [ZeusMonitor] Running indefinitely. 2022-12-06 15:38:20.167 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:38:20.167 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e34+gpu0.power.log
2022-12-06 10:39:03,573 [ZeusDataLoader(train)] train epoch 34 done: time=43.59 energy=6193.89
2022-12-06 10:39:03,577 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.9153
Training Epoch: 33 [2048/50176]	Loss: 0.8491
Training Epoch: 33 [3072/50176]	Loss: 0.9769
Training Epoch: 33 [4096/50176]	Loss: 0.9502
Training Epoch: 33 [5120/50176]	Loss: 0.9450
Training Epoch: 33 [6144/50176]	Loss: 0.8716
Training Epoch: 33 [7168/50176]	Loss: 0.9407
Training Epoch: 33 [8192/50176]	Loss: 0.8664
Training Epoch: 33 [9216/50176]	Loss: 0.9488
Training Epoch: 33 [10240/50176]	Loss: 0.8935
Training Epoch: 33 [11264/50176]	Loss: 0.9734
Training Epoch: 33 [12288/50176]	Loss: 1.0197
Training Epoch: 33 [13312/50176]	Loss: 0.9415
Training Epoch: 33 [14336/50176]	Loss: 0.9209
Training Epoch: 33 [15360/50176]	Loss: 0.9702
Training Epoch: 33 [16384/50176]	Loss: 0.9490
Training Epoch: 33 [17408/50176]	Loss: 0.8811
Training Epoch: 33 [18432/50176]	Loss: 0.9856
Training Epoch: 33 [19456/50176]	Loss: 0.9184
Training Epoch: 33 [20480/50176]	Loss: 0.9137
Training Epoch: 33 [21504/50176]	Loss: 1.0101
Training Epoch: 33 [22528/50176]	Loss: 0.9484
Training Epoch: 33 [23552/50176]	Loss: 0.9625
Training Epoch: 33 [24576/50176]	Loss: 0.9662
Training Epoch: 33 [25600/50176]	Loss: 0.9979
Training Epoch: 33 [26624/50176]	Loss: 0.9070
Training Epoch: 33 [27648/50176]	Loss: 0.9117
Training Epoch: 33 [28672/50176]	Loss: 0.9785
Training Epoch: 33 [29696/50176]	Loss: 0.9592
Training Epoch: 33 [30720/50176]	Loss: 0.9875
Training Epoch: 33 [31744/50176]	Loss: 0.9439
Training Epoch: 33 [32768/50176]	Loss: 0.9592
Training Epoch: 33 [33792/50176]	Loss: 1.0156
Training Epoch: 33 [34816/50176]	Loss: 0.9487
Training Epoch: 33 [35840/50176]	Loss: 0.9375
Training Epoch: 33 [36864/50176]	Loss: 0.9139
Training Epoch: 33 [37888/50176]	Loss: 0.9779
Training Epoch: 33 [38912/50176]	Loss: 0.9985
Training Epoch: 33 [39936/50176]	Loss: 0.9692
Training Epoch: 33 [40960/50176]	Loss: 0.9658
Training Epoch: 33 [41984/50176]	Loss: 1.0067
Training Epoch: 33 [43008/50176]	Loss: 0.9857
Training Epoch: 33 [44032/50176]	Loss: 0.9770
Training Epoch: 33 [45056/50176]	Loss: 1.0797
Training Epoch: 33 [46080/50176]	Loss: 0.9412
Training Epoch: 33 [47104/50176]	Loss: 0.9994
Training Epoch: 33 [48128/50176]	Loss: 0.9507
Training Epoch: 33 [49152/50176]	Loss: 1.0046
Training Epoch: 33 [50176/50176]	Loss: 1.0439
2022-12-06 15:39:07.257 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:39:07,290 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.71 energy=477.48
2022-12-06 10:39:07,290 [ZeusDataLoader(train)] Up to epoch 34: time=1653.11, energy=227933.97, cost=258614.40
2022-12-06 10:39:07,290 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:39:07,290 [ZeusDataLoader(train)] Expected next epoch: time=1699.56, energy=234542.60, cost=265982.64
2022-12-06 10:39:07,291 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0018, Accuracy: 0.5277
2022-12-06 10:39:07,487 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:39:07,487 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:39:07.489 [ZeusMonitor] Monitor started.
2022-12-06 15:39:07.489 [ZeusMonitor] Running indefinitely. 2022-12-06 15:39:07.489 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:39:07.489 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e35+gpu0.power.log
2022-12-06 10:39:50,956 [ZeusDataLoader(train)] train epoch 35 done: time=43.66 energy=6202.69
2022-12-06 10:39:50,959 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.8336
Training Epoch: 34 [2048/50176]	Loss: 0.8758
Training Epoch: 34 [3072/50176]	Loss: 0.8352
Training Epoch: 34 [4096/50176]	Loss: 0.8493
Training Epoch: 34 [5120/50176]	Loss: 0.8936
Training Epoch: 34 [6144/50176]	Loss: 0.9526
Training Epoch: 34 [7168/50176]	Loss: 0.8611
Training Epoch: 34 [8192/50176]	Loss: 0.8961
Training Epoch: 34 [9216/50176]	Loss: 0.8694
Training Epoch: 34 [10240/50176]	Loss: 0.8857
Training Epoch: 34 [11264/50176]	Loss: 0.8430
Training Epoch: 34 [12288/50176]	Loss: 0.9368
Training Epoch: 34 [13312/50176]	Loss: 0.9050
Training Epoch: 34 [14336/50176]	Loss: 0.8620
Training Epoch: 34 [15360/50176]	Loss: 0.8786
Training Epoch: 34 [16384/50176]	Loss: 0.9864
Training Epoch: 34 [17408/50176]	Loss: 0.9369
Training Epoch: 34 [18432/50176]	Loss: 0.8929
Training Epoch: 34 [19456/50176]	Loss: 0.8374
Training Epoch: 34 [20480/50176]	Loss: 0.9374
Training Epoch: 34 [21504/50176]	Loss: 0.9544
Training Epoch: 34 [22528/50176]	Loss: 0.9071
Training Epoch: 34 [23552/50176]	Loss: 0.9386
Training Epoch: 34 [24576/50176]	Loss: 0.8204
Training Epoch: 34 [25600/50176]	Loss: 0.9897
Training Epoch: 34 [26624/50176]	Loss: 0.9510
Training Epoch: 34 [27648/50176]	Loss: 0.9711
Training Epoch: 34 [28672/50176]	Loss: 0.9481
Training Epoch: 34 [29696/50176]	Loss: 0.9592
Training Epoch: 34 [30720/50176]	Loss: 0.9983
Training Epoch: 34 [31744/50176]	Loss: 0.9668
Training Epoch: 34 [32768/50176]	Loss: 0.9742
Training Epoch: 34 [33792/50176]	Loss: 0.8737
Training Epoch: 34 [34816/50176]	Loss: 0.9137
Training Epoch: 34 [35840/50176]	Loss: 0.9635
Training Epoch: 34 [36864/50176]	Loss: 0.9484
Training Epoch: 34 [37888/50176]	Loss: 1.0034
Training Epoch: 34 [38912/50176]	Loss: 0.9005
Training Epoch: 34 [39936/50176]	Loss: 0.9806
Training Epoch: 34 [40960/50176]	Loss: 0.9576
Training Epoch: 34 [41984/50176]	Loss: 0.8863
Training Epoch: 34 [43008/50176]	Loss: 0.8810
Training Epoch: 34 [44032/50176]	Loss: 0.9349
Training Epoch: 34 [45056/50176]	Loss: 0.9684
Training Epoch: 34 [46080/50176]	Loss: 0.9520
Training Epoch: 34 [47104/50176]	Loss: 0.9594
Training Epoch: 34 [48128/50176]	Loss: 0.9615
Training Epoch: 34 [49152/50176]	Loss: 1.0597
Training Epoch: 34 [50176/50176]	Loss: 0.9241
2022-12-06 15:39:54.682 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:39:54,727 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.76 energy=470.25
2022-12-06 10:39:54,728 [ZeusDataLoader(train)] Up to epoch 35: time=1700.53, energy=234606.91, cost=266099.85
2022-12-06 10:39:54,728 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:39:54,728 [ZeusDataLoader(train)] Expected next epoch: time=1746.98, energy=241215.54, cost=273468.09
2022-12-06 10:39:54,729 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0018, Accuracy: 0.5335
2022-12-06 10:39:54,906 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:39:54,907 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:39:54.920 [ZeusMonitor] Monitor started.
2022-12-06 15:39:54.920 [ZeusMonitor] Running indefinitely. 2022-12-06 15:39:54.920 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:39:54.920 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e36+gpu0.power.log
2022-12-06 10:40:38,356 [ZeusDataLoader(train)] train epoch 36 done: time=43.62 energy=6206.41
2022-12-06 10:40:38,359 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.8446
Training Epoch: 35 [2048/50176]	Loss: 0.8917
Training Epoch: 35 [3072/50176]	Loss: 0.8658
Training Epoch: 35 [4096/50176]	Loss: 0.8407
Training Epoch: 35 [5120/50176]	Loss: 0.9047
Training Epoch: 35 [6144/50176]	Loss: 0.8210
Training Epoch: 35 [7168/50176]	Loss: 0.8310
Training Epoch: 35 [8192/50176]	Loss: 0.8168
Training Epoch: 35 [9216/50176]	Loss: 0.7934
Training Epoch: 35 [10240/50176]	Loss: 0.8581
Training Epoch: 35 [11264/50176]	Loss: 0.8816
Training Epoch: 35 [12288/50176]	Loss: 0.9336
Training Epoch: 35 [13312/50176]	Loss: 0.8679
Training Epoch: 35 [14336/50176]	Loss: 0.8830
Training Epoch: 35 [15360/50176]	Loss: 0.8673
Training Epoch: 35 [16384/50176]	Loss: 0.9133
Training Epoch: 35 [17408/50176]	Loss: 0.8875
Training Epoch: 35 [18432/50176]	Loss: 0.9127
Training Epoch: 35 [19456/50176]	Loss: 0.9130
Training Epoch: 35 [20480/50176]	Loss: 0.8146
Training Epoch: 35 [21504/50176]	Loss: 0.8847
Training Epoch: 35 [22528/50176]	Loss: 0.8857
Training Epoch: 35 [23552/50176]	Loss: 0.8744
Training Epoch: 35 [24576/50176]	Loss: 0.9171
Training Epoch: 35 [25600/50176]	Loss: 0.8801
Training Epoch: 35 [26624/50176]	Loss: 0.8660
Training Epoch: 35 [27648/50176]	Loss: 0.8720
Training Epoch: 35 [28672/50176]	Loss: 0.8804
Training Epoch: 35 [29696/50176]	Loss: 0.9054
Training Epoch: 35 [30720/50176]	Loss: 0.9531
Training Epoch: 35 [31744/50176]	Loss: 0.8849
Training Epoch: 35 [32768/50176]	Loss: 0.8321
Training Epoch: 35 [33792/50176]	Loss: 0.8670
Training Epoch: 35 [34816/50176]	Loss: 0.8438
Training Epoch: 35 [35840/50176]	Loss: 0.9067
Training Epoch: 35 [36864/50176]	Loss: 0.9537
Training Epoch: 35 [37888/50176]	Loss: 0.9540
Training Epoch: 35 [38912/50176]	Loss: 0.9133
Training Epoch: 35 [39936/50176]	Loss: 0.9572
Training Epoch: 35 [40960/50176]	Loss: 0.9062
Training Epoch: 35 [41984/50176]	Loss: 0.9407
Training Epoch: 35 [43008/50176]	Loss: 0.9246
Training Epoch: 35 [44032/50176]	Loss: 0.9257
Training Epoch: 35 [45056/50176]	Loss: 0.9595
Training Epoch: 35 [46080/50176]	Loss: 0.8823
Training Epoch: 35 [47104/50176]	Loss: 0.9149
Training Epoch: 35 [48128/50176]	Loss: 0.9578
Training Epoch: 35 [49152/50176]	Loss: 0.9497
Training Epoch: 35 [50176/50176]	Loss: 0.9370
2022-12-06 15:40:42.073 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:40:42,107 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.74 energy=469.69
2022-12-06 10:40:42,107 [ZeusDataLoader(train)] Up to epoch 36: time=1747.89, energy=241283.01, cost=273581.82
2022-12-06 10:40:42,107 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:40:42,107 [ZeusDataLoader(train)] Expected next epoch: time=1794.33, energy=247891.64, cost=280950.06
2022-12-06 10:40:42,108 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0019, Accuracy: 0.5326
2022-12-06 10:40:42,311 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:40:42,311 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:40:42.313 [ZeusMonitor] Monitor started.
2022-12-06 15:40:42.313 [ZeusMonitor] Running indefinitely. 2022-12-06 15:40:42.313 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:40:42.313 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e37+gpu0.power.log
2022-12-06 10:41:25,738 [ZeusDataLoader(train)] train epoch 37 done: time=43.62 energy=6202.41
2022-12-06 10:41:25,741 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.7527
Training Epoch: 36 [2048/50176]	Loss: 0.7821
Training Epoch: 36 [3072/50176]	Loss: 0.8142
Training Epoch: 36 [4096/50176]	Loss: 0.7933
Training Epoch: 36 [5120/50176]	Loss: 0.8280
Training Epoch: 36 [6144/50176]	Loss: 0.7418
Training Epoch: 36 [7168/50176]	Loss: 0.8506
Training Epoch: 36 [8192/50176]	Loss: 0.8145
Training Epoch: 36 [9216/50176]	Loss: 0.8357
Training Epoch: 36 [10240/50176]	Loss: 0.8536
Training Epoch: 36 [11264/50176]	Loss: 0.8393
Training Epoch: 36 [12288/50176]	Loss: 0.8379
Training Epoch: 36 [13312/50176]	Loss: 0.8076
Training Epoch: 36 [14336/50176]	Loss: 0.8147
Training Epoch: 36 [15360/50176]	Loss: 0.8167
Training Epoch: 36 [16384/50176]	Loss: 0.8313
Training Epoch: 36 [17408/50176]	Loss: 0.8017
Training Epoch: 36 [18432/50176]	Loss: 0.8455
Training Epoch: 36 [19456/50176]	Loss: 0.8427
Training Epoch: 36 [20480/50176]	Loss: 0.8547
Training Epoch: 36 [21504/50176]	Loss: 0.8021
Training Epoch: 36 [22528/50176]	Loss: 0.9261
Training Epoch: 36 [23552/50176]	Loss: 0.8525
Training Epoch: 36 [24576/50176]	Loss: 0.8935
Training Epoch: 36 [25600/50176]	Loss: 0.9287
Training Epoch: 36 [26624/50176]	Loss: 0.9181
Training Epoch: 36 [27648/50176]	Loss: 0.8869
Training Epoch: 36 [28672/50176]	Loss: 0.9008
Training Epoch: 36 [29696/50176]	Loss: 0.8383
Training Epoch: 36 [30720/50176]	Loss: 0.9005
Training Epoch: 36 [31744/50176]	Loss: 0.8938
Training Epoch: 36 [32768/50176]	Loss: 0.9150
Training Epoch: 36 [33792/50176]	Loss: 0.8620
Training Epoch: 36 [34816/50176]	Loss: 0.8663
Training Epoch: 36 [35840/50176]	Loss: 0.8640
Training Epoch: 36 [36864/50176]	Loss: 0.8684
Training Epoch: 36 [37888/50176]	Loss: 0.9179
Training Epoch: 36 [38912/50176]	Loss: 0.8103
Training Epoch: 36 [39936/50176]	Loss: 0.8994
Training Epoch: 36 [40960/50176]	Loss: 0.9276
Training Epoch: 36 [41984/50176]	Loss: 0.9062
Training Epoch: 36 [43008/50176]	Loss: 0.9356
Training Epoch: 36 [44032/50176]	Loss: 0.9500
Training Epoch: 36 [45056/50176]	Loss: 0.8934
Training Epoch: 36 [46080/50176]	Loss: 0.8937
Training Epoch: 36 [47104/50176]	Loss: 0.8877
Training Epoch: 36 [48128/50176]	Loss: 0.8874
Training Epoch: 36 [49152/50176]	Loss: 0.8804
Training Epoch: 36 [50176/50176]	Loss: 0.8692
2022-12-06 15:41:29.412 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:41:29,448 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.70 energy=457.89
2022-12-06 10:41:29,448 [ZeusDataLoader(train)] Up to epoch 37: time=1795.21, energy=247943.32, cost=281052.53
2022-12-06 10:41:29,448 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:41:29,448 [ZeusDataLoader(train)] Expected next epoch: time=1841.65, energy=254551.94, cost=288420.77
2022-12-06 10:41:29,449 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0019, Accuracy: 0.5261
2022-12-06 10:41:29,626 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:41:29,627 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:41:29.629 [ZeusMonitor] Monitor started.
2022-12-06 15:41:29.629 [ZeusMonitor] Running indefinitely. 2022-12-06 15:41:29.629 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:41:29.629 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e38+gpu0.power.log
2022-12-06 10:42:13,095 [ZeusDataLoader(train)] train epoch 38 done: time=43.64 energy=6206.02
2022-12-06 10:42:13,098 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.7908
Training Epoch: 37 [2048/50176]	Loss: 0.7901
Training Epoch: 37 [3072/50176]	Loss: 0.7447
Training Epoch: 37 [4096/50176]	Loss: 0.8118
Training Epoch: 37 [5120/50176]	Loss: 0.8140
Training Epoch: 37 [6144/50176]	Loss: 0.7684
Training Epoch: 37 [7168/50176]	Loss: 0.8009
Training Epoch: 37 [8192/50176]	Loss: 0.7965
Training Epoch: 37 [9216/50176]	Loss: 0.7795
Training Epoch: 37 [10240/50176]	Loss: 0.7884
Training Epoch: 37 [11264/50176]	Loss: 0.8255
Training Epoch: 37 [12288/50176]	Loss: 0.8628
Training Epoch: 37 [13312/50176]	Loss: 0.7781
Training Epoch: 37 [14336/50176]	Loss: 0.7870
Training Epoch: 37 [15360/50176]	Loss: 0.8382
Training Epoch: 37 [16384/50176]	Loss: 0.7981
Training Epoch: 37 [17408/50176]	Loss: 0.8428
Training Epoch: 37 [18432/50176]	Loss: 0.7891
Training Epoch: 37 [19456/50176]	Loss: 0.8320
Training Epoch: 37 [20480/50176]	Loss: 0.8330
Training Epoch: 37 [21504/50176]	Loss: 0.8166
Training Epoch: 37 [22528/50176]	Loss: 0.8492
Training Epoch: 37 [23552/50176]	Loss: 0.8041
Training Epoch: 37 [24576/50176]	Loss: 0.8211
Training Epoch: 37 [25600/50176]	Loss: 0.8071
Training Epoch: 37 [26624/50176]	Loss: 0.8451
Training Epoch: 37 [27648/50176]	Loss: 0.8811
Training Epoch: 37 [28672/50176]	Loss: 0.8696
Training Epoch: 37 [29696/50176]	Loss: 0.8509
Training Epoch: 37 [30720/50176]	Loss: 0.8271
Training Epoch: 37 [31744/50176]	Loss: 0.8492
Training Epoch: 37 [32768/50176]	Loss: 0.8729
Training Epoch: 37 [33792/50176]	Loss: 0.8291
Training Epoch: 37 [34816/50176]	Loss: 0.8708
Training Epoch: 37 [35840/50176]	Loss: 0.8576
Training Epoch: 37 [36864/50176]	Loss: 0.7656
Training Epoch: 37 [37888/50176]	Loss: 0.9280
Training Epoch: 37 [38912/50176]	Loss: 0.8749
Training Epoch: 37 [39936/50176]	Loss: 0.7900
Training Epoch: 37 [40960/50176]	Loss: 0.8652
Training Epoch: 37 [41984/50176]	Loss: 0.8324
Training Epoch: 37 [43008/50176]	Loss: 0.8720
Training Epoch: 37 [44032/50176]	Loss: 0.8877
Training Epoch: 37 [45056/50176]	Loss: 0.8867
Training Epoch: 37 [46080/50176]	Loss: 0.8171
Training Epoch: 37 [47104/50176]	Loss: 0.8798
Training Epoch: 37 [48128/50176]	Loss: 0.8984
Training Epoch: 37 [49152/50176]	Loss: 0.8349
Training Epoch: 37 [50176/50176]	Loss: 0.8939
2022-12-06 15:42:16.774 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:42:16,802 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.70 energy=473.09
2022-12-06 10:42:16,802 [ZeusDataLoader(train)] Up to epoch 38: time=1842.54, energy=254622.43, cost=288533.80
2022-12-06 10:42:16,802 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:42:16,802 [ZeusDataLoader(train)] Expected next epoch: time=1888.99, energy=261231.05, cost=295902.05
2022-12-06 10:42:16,803 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0019, Accuracy: 0.5371
2022-12-06 10:42:16,974 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:42:16,975 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:42:16.977 [ZeusMonitor] Monitor started.
2022-12-06 15:42:16.977 [ZeusMonitor] Running indefinitely. 2022-12-06 15:42:16.977 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:42:16.977 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e39+gpu0.power.log
2022-12-06 10:43:00,439 [ZeusDataLoader(train)] train epoch 39 done: time=43.63 energy=6201.73
2022-12-06 10:43:00,442 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.7755
Training Epoch: 38 [2048/50176]	Loss: 0.7747
Training Epoch: 38 [3072/50176]	Loss: 0.7351
Training Epoch: 38 [4096/50176]	Loss: 0.7222
Training Epoch: 38 [5120/50176]	Loss: 0.7934
Training Epoch: 38 [6144/50176]	Loss: 0.7259
Training Epoch: 38 [7168/50176]	Loss: 0.7474
Training Epoch: 38 [8192/50176]	Loss: 0.7565
Training Epoch: 38 [9216/50176]	Loss: 0.7689
Training Epoch: 38 [10240/50176]	Loss: 0.7831
Training Epoch: 38 [11264/50176]	Loss: 0.8043
Training Epoch: 38 [12288/50176]	Loss: 0.7528
Training Epoch: 38 [13312/50176]	Loss: 0.7780
Training Epoch: 38 [14336/50176]	Loss: 0.7802
Training Epoch: 38 [15360/50176]	Loss: 0.7984
Training Epoch: 38 [16384/50176]	Loss: 0.7210
Training Epoch: 38 [17408/50176]	Loss: 0.7764
Training Epoch: 38 [18432/50176]	Loss: 0.8198
Training Epoch: 38 [19456/50176]	Loss: 0.8084
Training Epoch: 38 [20480/50176]	Loss: 0.8300
Training Epoch: 38 [21504/50176]	Loss: 0.7681
Training Epoch: 38 [22528/50176]	Loss: 0.8240
Training Epoch: 38 [23552/50176]	Loss: 0.8344
Training Epoch: 38 [24576/50176]	Loss: 0.8638
Training Epoch: 38 [25600/50176]	Loss: 0.7427
Training Epoch: 38 [26624/50176]	Loss: 0.7953
Training Epoch: 38 [27648/50176]	Loss: 0.7621
Training Epoch: 38 [28672/50176]	Loss: 0.8547
Training Epoch: 38 [29696/50176]	Loss: 0.7315
Training Epoch: 38 [30720/50176]	Loss: 0.8179
Training Epoch: 38 [31744/50176]	Loss: 0.8122
Training Epoch: 38 [32768/50176]	Loss: 0.8229
Training Epoch: 38 [33792/50176]	Loss: 0.7666
Training Epoch: 38 [34816/50176]	Loss: 0.8225
Training Epoch: 38 [35840/50176]	Loss: 0.7586
Training Epoch: 38 [36864/50176]	Loss: 0.8733
Training Epoch: 38 [37888/50176]	Loss: 0.8246
Training Epoch: 38 [38912/50176]	Loss: 0.7427
Training Epoch: 38 [39936/50176]	Loss: 0.8321
Training Epoch: 38 [40960/50176]	Loss: 0.8481
Training Epoch: 38 [41984/50176]	Loss: 0.7909
Training Epoch: 38 [43008/50176]	Loss: 0.8972
Training Epoch: 38 [44032/50176]	Loss: 0.8305
Training Epoch: 38 [45056/50176]	Loss: 0.8144
Training Epoch: 38 [46080/50176]	Loss: 0.8024
Training Epoch: 38 [47104/50176]	Loss: 0.8411
Training Epoch: 38 [48128/50176]	Loss: 0.8017
Training Epoch: 38 [49152/50176]	Loss: 0.8401
Training Epoch: 38 [50176/50176]	Loss: 0.8261
2022-12-06 15:43:04.082 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:43:04,092 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.64 energy=455.63
2022-12-06 10:43:04,092 [ZeusDataLoader(train)] Up to epoch 39: time=1889.81, energy=261279.78, cost=295998.59
2022-12-06 10:43:04,092 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:43:04,092 [ZeusDataLoader(train)] Expected next epoch: time=1936.26, energy=267888.41, cost=303366.83
2022-12-06 10:43:04,093 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0019, Accuracy: 0.5318
2022-12-06 10:43:04,232 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:43:04,233 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:43:04.234 [ZeusMonitor] Monitor started.
2022-12-06 15:43:04.234 [ZeusMonitor] Running indefinitely. 2022-12-06 15:43:04.234 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:43:04.234 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e40+gpu0.power.log
2022-12-06 10:43:47,730 [ZeusDataLoader(train)] train epoch 40 done: time=43.63 energy=6210.54
2022-12-06 10:43:47,733 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.6910
Training Epoch: 39 [2048/50176]	Loss: 0.7067
Training Epoch: 39 [3072/50176]	Loss: 0.7076
Training Epoch: 39 [4096/50176]	Loss: 0.7229
Training Epoch: 39 [5120/50176]	Loss: 0.8256
Training Epoch: 39 [6144/50176]	Loss: 0.7418
Training Epoch: 39 [7168/50176]	Loss: 0.6867
Training Epoch: 39 [8192/50176]	Loss: 0.7594
Training Epoch: 39 [9216/50176]	Loss: 0.7329
Training Epoch: 39 [10240/50176]	Loss: 0.7469
Training Epoch: 39 [11264/50176]	Loss: 0.7469
Training Epoch: 39 [12288/50176]	Loss: 0.7522
Training Epoch: 39 [13312/50176]	Loss: 0.8082
Training Epoch: 39 [14336/50176]	Loss: 0.7261
Training Epoch: 39 [15360/50176]	Loss: 0.7433
Training Epoch: 39 [16384/50176]	Loss: 0.7055
Training Epoch: 39 [17408/50176]	Loss: 0.6769
Training Epoch: 39 [18432/50176]	Loss: 0.7484
Training Epoch: 39 [19456/50176]	Loss: 0.7270
Training Epoch: 39 [20480/50176]	Loss: 0.7537
Training Epoch: 39 [21504/50176]	Loss: 0.8196
Training Epoch: 39 [22528/50176]	Loss: 0.7529
Training Epoch: 39 [23552/50176]	Loss: 0.7326
Training Epoch: 39 [24576/50176]	Loss: 0.7335
Training Epoch: 39 [25600/50176]	Loss: 0.7785
Training Epoch: 39 [26624/50176]	Loss: 0.8013
Training Epoch: 39 [27648/50176]	Loss: 0.7460
Training Epoch: 39 [28672/50176]	Loss: 0.6870
Training Epoch: 39 [29696/50176]	Loss: 0.7950
Training Epoch: 39 [30720/50176]	Loss: 0.7293
Training Epoch: 39 [31744/50176]	Loss: 0.8183
Training Epoch: 39 [32768/50176]	Loss: 0.7189
Training Epoch: 39 [33792/50176]	Loss: 0.7825
Training Epoch: 39 [34816/50176]	Loss: 0.7974
Training Epoch: 39 [35840/50176]	Loss: 0.7562
Training Epoch: 39 [36864/50176]	Loss: 0.8157
Training Epoch: 39 [37888/50176]	Loss: 0.7420
Training Epoch: 39 [38912/50176]	Loss: 0.8190
Training Epoch: 39 [39936/50176]	Loss: 0.8050
Training Epoch: 39 [40960/50176]	Loss: 0.7871
Training Epoch: 39 [41984/50176]	Loss: 0.7901
Training Epoch: 39 [43008/50176]	Loss: 0.7445
Training Epoch: 39 [44032/50176]	Loss: 0.7958
Training Epoch: 39 [45056/50176]	Loss: 0.8197
Training Epoch: 39 [46080/50176]	Loss: 0.7735
Training Epoch: 39 [47104/50176]	Loss: 0.8140
Training Epoch: 39 [48128/50176]	Loss: 0.7574
Training Epoch: 39 [49152/50176]	Loss: 0.7847
Training Epoch: 39 [50176/50176]	Loss: 0.8507
2022-12-06 15:43:51.359 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:43:51,369 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.63 energy=458.57
2022-12-06 10:43:51,369 [ZeusDataLoader(train)] Up to epoch 40: time=1937.07, energy=267948.90, cost=303468.16
2022-12-06 10:43:51,369 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:43:51,370 [ZeusDataLoader(train)] Expected next epoch: time=1983.52, energy=274557.52, cost=310836.41
2022-12-06 10:43:51,370 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0019, Accuracy: 0.5407
2022-12-06 10:43:51,547 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:43:51,548 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:43:51.550 [ZeusMonitor] Monitor started.
2022-12-06 15:43:51.550 [ZeusMonitor] Running indefinitely. 2022-12-06 15:43:51.550 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:43:51.550 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e41+gpu0.power.log
2022-12-06 10:44:34,960 [ZeusDataLoader(train)] train epoch 41 done: time=43.58 energy=6193.69
2022-12-06 10:44:34,963 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.6161
Training Epoch: 40 [2048/50176]	Loss: 0.6895
Training Epoch: 40 [3072/50176]	Loss: 0.6783
Training Epoch: 40 [4096/50176]	Loss: 0.6680
Training Epoch: 40 [5120/50176]	Loss: 0.7050
Training Epoch: 40 [6144/50176]	Loss: 0.6912
Training Epoch: 40 [7168/50176]	Loss: 0.6919
Training Epoch: 40 [8192/50176]	Loss: 0.7113
Training Epoch: 40 [9216/50176]	Loss: 0.7054
Training Epoch: 40 [10240/50176]	Loss: 0.7115
Training Epoch: 40 [11264/50176]	Loss: 0.7221
Training Epoch: 40 [12288/50176]	Loss: 0.7382
Training Epoch: 40 [13312/50176]	Loss: 0.7494
Training Epoch: 40 [14336/50176]	Loss: 0.7279
Training Epoch: 40 [15360/50176]	Loss: 0.6822
Training Epoch: 40 [16384/50176]	Loss: 0.7020
Training Epoch: 40 [17408/50176]	Loss: 0.6717
Training Epoch: 40 [18432/50176]	Loss: 0.7712
Training Epoch: 40 [19456/50176]	Loss: 0.7129
Training Epoch: 40 [20480/50176]	Loss: 0.7449
Training Epoch: 40 [21504/50176]	Loss: 0.7062
Training Epoch: 40 [22528/50176]	Loss: 0.6629
Training Epoch: 40 [23552/50176]	Loss: 0.7382
Training Epoch: 40 [24576/50176]	Loss: 0.8214
Training Epoch: 40 [25600/50176]	Loss: 0.7899
Training Epoch: 40 [26624/50176]	Loss: 0.7238
Training Epoch: 40 [27648/50176]	Loss: 0.7058
Training Epoch: 40 [28672/50176]	Loss: 0.7227
Training Epoch: 40 [29696/50176]	Loss: 0.6965
Training Epoch: 40 [30720/50176]	Loss: 0.6843
Training Epoch: 40 [31744/50176]	Loss: 0.6919
Training Epoch: 40 [32768/50176]	Loss: 0.8356
Training Epoch: 40 [33792/50176]	Loss: 0.7950
Training Epoch: 40 [34816/50176]	Loss: 0.6886
Training Epoch: 40 [35840/50176]	Loss: 0.7006
Training Epoch: 40 [36864/50176]	Loss: 0.7050
Training Epoch: 40 [37888/50176]	Loss: 0.7102
Training Epoch: 40 [38912/50176]	Loss: 0.7346
Training Epoch: 40 [39936/50176]	Loss: 0.8432
Training Epoch: 40 [40960/50176]	Loss: 0.8015
Training Epoch: 40 [41984/50176]	Loss: 0.7539
Training Epoch: 40 [43008/50176]	Loss: 0.8823
Training Epoch: 40 [44032/50176]	Loss: 0.7975
Training Epoch: 40 [45056/50176]	Loss: 0.8113
Training Epoch: 40 [46080/50176]	Loss: 0.8177
Training Epoch: 40 [47104/50176]	Loss: 0.7766
Training Epoch: 40 [48128/50176]	Loss: 0.7734
Training Epoch: 40 [49152/50176]	Loss: 0.7667
Training Epoch: 40 [50176/50176]	Loss: 0.8227
2022-12-06 15:44:38.648 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:44:38,672 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.70 energy=469.13
2022-12-06 10:44:38,672 [ZeusDataLoader(train)] Up to epoch 41: time=1984.35, energy=274611.71, cost=310936.84
2022-12-06 10:44:38,673 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:44:38,673 [ZeusDataLoader(train)] Expected next epoch: time=2030.80, energy=281220.34, cost=318305.09
2022-12-06 10:44:38,674 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0019, Accuracy: 0.5321
2022-12-06 10:44:38,847 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:44:38,847 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:44:38.849 [ZeusMonitor] Monitor started.
2022-12-06 15:44:38.849 [ZeusMonitor] Running indefinitely. 2022-12-06 15:44:38.849 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:44:38.849 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e42+gpu0.power.log
2022-12-06 10:45:22,738 [ZeusDataLoader(train)] train epoch 42 done: time=44.06 energy=6237.50
2022-12-06 10:45:22,742 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.6645
Training Epoch: 41 [2048/50176]	Loss: 0.7094
Training Epoch: 41 [3072/50176]	Loss: 0.6913
Training Epoch: 41 [4096/50176]	Loss: 0.6693
Training Epoch: 41 [5120/50176]	Loss: 0.6768
Training Epoch: 41 [6144/50176]	Loss: 0.6764
Training Epoch: 41 [7168/50176]	Loss: 0.6896
Training Epoch: 41 [8192/50176]	Loss: 0.6972
Training Epoch: 41 [9216/50176]	Loss: 0.7042
Training Epoch: 41 [10240/50176]	Loss: 0.6539
Training Epoch: 41 [11264/50176]	Loss: 0.7002
Training Epoch: 41 [12288/50176]	Loss: 0.6953
Training Epoch: 41 [13312/50176]	Loss: 0.6952
Training Epoch: 41 [14336/50176]	Loss: 0.7183
Training Epoch: 41 [15360/50176]	Loss: 0.6908
Training Epoch: 41 [16384/50176]	Loss: 0.6895
Training Epoch: 41 [17408/50176]	Loss: 0.7303
Training Epoch: 41 [18432/50176]	Loss: 0.6530
Training Epoch: 41 [19456/50176]	Loss: 0.7516
Training Epoch: 41 [20480/50176]	Loss: 0.7507
Training Epoch: 41 [21504/50176]	Loss: 0.6819
Training Epoch: 41 [22528/50176]	Loss: 0.7146
Training Epoch: 41 [23552/50176]	Loss: 0.7656
Training Epoch: 41 [24576/50176]	Loss: 0.7191
Training Epoch: 41 [25600/50176]	Loss: 0.6843
Training Epoch: 41 [26624/50176]	Loss: 0.7288
Training Epoch: 41 [27648/50176]	Loss: 0.7700
Training Epoch: 41 [28672/50176]	Loss: 0.7428
Training Epoch: 41 [29696/50176]	Loss: 0.7303
Training Epoch: 41 [30720/50176]	Loss: 0.7477
Training Epoch: 41 [31744/50176]	Loss: 0.7587
Training Epoch: 41 [32768/50176]	Loss: 0.6837
Training Epoch: 41 [33792/50176]	Loss: 0.6895
Training Epoch: 41 [34816/50176]	Loss: 0.6912
Training Epoch: 41 [35840/50176]	Loss: 0.7265
Training Epoch: 41 [36864/50176]	Loss: 0.7384
Training Epoch: 41 [37888/50176]	Loss: 0.6921
Training Epoch: 41 [38912/50176]	Loss: 0.7444
Training Epoch: 41 [39936/50176]	Loss: 0.7743
Training Epoch: 41 [40960/50176]	Loss: 0.7995
Training Epoch: 41 [41984/50176]	Loss: 0.7138
Training Epoch: 41 [43008/50176]	Loss: 0.7140
Training Epoch: 41 [44032/50176]	Loss: 0.7548
Training Epoch: 41 [45056/50176]	Loss: 0.7261
Training Epoch: 41 [46080/50176]	Loss: 0.7102
Training Epoch: 41 [47104/50176]	Loss: 0.7654
Training Epoch: 41 [48128/50176]	Loss: 0.7577
Training Epoch: 41 [49152/50176]	Loss: 0.7552
Training Epoch: 41 [50176/50176]	Loss: 0.7031
2022-12-06 15:45:26.433 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:45:26,454 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.70 energy=470.99
2022-12-06 10:45:26,454 [ZeusDataLoader(train)] Up to epoch 42: time=2032.11, energy=281320.20, cost=318470.15
2022-12-06 10:45:26,454 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:45:26,454 [ZeusDataLoader(train)] Expected next epoch: time=2078.56, energy=287928.83, cost=325838.40
2022-12-06 10:45:26,455 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0019, Accuracy: 0.5336
2022-12-06 10:45:26,626 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:45:26,627 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:45:26.629 [ZeusMonitor] Monitor started.
2022-12-06 15:45:26.629 [ZeusMonitor] Running indefinitely. 2022-12-06 15:45:26.629 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:45:26.629 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e43+gpu0.power.log
2022-12-06 10:46:10,696 [ZeusDataLoader(train)] train epoch 43 done: time=44.23 energy=6244.24
2022-12-06 10:46:10,699 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.6203
Training Epoch: 42 [2048/50176]	Loss: 0.6452
Training Epoch: 42 [3072/50176]	Loss: 0.6168
Training Epoch: 42 [4096/50176]	Loss: 0.6726
Training Epoch: 42 [5120/50176]	Loss: 0.6238
Training Epoch: 42 [6144/50176]	Loss: 0.6769
Training Epoch: 42 [7168/50176]	Loss: 0.6152
Training Epoch: 42 [8192/50176]	Loss: 0.6532
Training Epoch: 42 [9216/50176]	Loss: 0.6127
Training Epoch: 42 [10240/50176]	Loss: 0.6989
Training Epoch: 42 [11264/50176]	Loss: 0.6233
Training Epoch: 42 [12288/50176]	Loss: 0.6746
Training Epoch: 42 [13312/50176]	Loss: 0.6437
Training Epoch: 42 [14336/50176]	Loss: 0.6470
Training Epoch: 42 [15360/50176]	Loss: 0.6207
Training Epoch: 42 [16384/50176]	Loss: 0.6242
Training Epoch: 42 [17408/50176]	Loss: 0.6457
Training Epoch: 42 [18432/50176]	Loss: 0.6679
Training Epoch: 42 [19456/50176]	Loss: 0.6790
Training Epoch: 42 [20480/50176]	Loss: 0.6199
Training Epoch: 42 [21504/50176]	Loss: 0.6823
Training Epoch: 42 [22528/50176]	Loss: 0.6526
Training Epoch: 42 [23552/50176]	Loss: 0.6324
Training Epoch: 42 [24576/50176]	Loss: 0.6585
Training Epoch: 42 [25600/50176]	Loss: 0.7229
Training Epoch: 42 [26624/50176]	Loss: 0.6405
Training Epoch: 42 [27648/50176]	Loss: 0.6816
Training Epoch: 42 [28672/50176]	Loss: 0.6866
Training Epoch: 42 [29696/50176]	Loss: 0.7441
Training Epoch: 42 [30720/50176]	Loss: 0.6689
Training Epoch: 42 [31744/50176]	Loss: 0.7058
Training Epoch: 42 [32768/50176]	Loss: 0.7109
Training Epoch: 42 [33792/50176]	Loss: 0.6415
Training Epoch: 42 [34816/50176]	Loss: 0.7015
Training Epoch: 42 [35840/50176]	Loss: 0.7280
Training Epoch: 42 [36864/50176]	Loss: 0.7990
Training Epoch: 42 [37888/50176]	Loss: 0.7466
Training Epoch: 42 [38912/50176]	Loss: 0.7109
Training Epoch: 42 [39936/50176]	Loss: 0.6652
Training Epoch: 42 [40960/50176]	Loss: 0.6809
Training Epoch: 42 [41984/50176]	Loss: 0.6968
Training Epoch: 42 [43008/50176]	Loss: 0.7724
Training Epoch: 42 [44032/50176]	Loss: 0.7206
Training Epoch: 42 [45056/50176]	Loss: 0.7315
Training Epoch: 42 [46080/50176]	Loss: 0.6703
Training Epoch: 42 [47104/50176]	Loss: 0.7102
Training Epoch: 42 [48128/50176]	Loss: 0.7105
Training Epoch: 42 [49152/50176]	Loss: 0.7596
Training Epoch: 42 [50176/50176]	Loss: 0.7570
2022-12-06 15:46:14.395 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:46:14,418 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.71 energy=466.91
2022-12-06 10:46:14,418 [ZeusDataLoader(train)] Up to epoch 43: time=2080.06, energy=288031.36, cost=326020.80
2022-12-06 10:46:14,418 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:46:14,418 [ZeusDataLoader(train)] Expected next epoch: time=2126.50, energy=294639.99, cost=333389.05
2022-12-06 10:46:14,419 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0019, Accuracy: 0.5381
2022-12-06 10:46:14,595 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:46:14,595 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:46:14.597 [ZeusMonitor] Monitor started.
2022-12-06 15:46:14.597 [ZeusMonitor] Running indefinitely. 2022-12-06 15:46:14.597 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:46:14.597 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e44+gpu0.power.log
2022-12-06 10:46:58,551 [ZeusDataLoader(train)] train epoch 44 done: time=44.12 energy=6242.36
2022-12-06 10:46:58,554 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.5826
Training Epoch: 43 [2048/50176]	Loss: 0.5698
Training Epoch: 43 [3072/50176]	Loss: 0.5586
Training Epoch: 43 [4096/50176]	Loss: 0.5712
Training Epoch: 43 [5120/50176]	Loss: 0.5707
Training Epoch: 43 [6144/50176]	Loss: 0.5890
Training Epoch: 43 [7168/50176]	Loss: 0.6349
Training Epoch: 43 [8192/50176]	Loss: 0.5919
Training Epoch: 43 [9216/50176]	Loss: 0.6544
Training Epoch: 43 [10240/50176]	Loss: 0.6514
Training Epoch: 43 [11264/50176]	Loss: 0.5821
Training Epoch: 43 [12288/50176]	Loss: 0.6488
Training Epoch: 43 [13312/50176]	Loss: 0.6305
Training Epoch: 43 [14336/50176]	Loss: 0.6503
Training Epoch: 43 [15360/50176]	Loss: 0.6696
Training Epoch: 43 [16384/50176]	Loss: 0.6579
Training Epoch: 43 [17408/50176]	Loss: 0.5895
Training Epoch: 43 [18432/50176]	Loss: 0.6019
Training Epoch: 43 [19456/50176]	Loss: 0.6951
Training Epoch: 43 [20480/50176]	Loss: 0.6054
Training Epoch: 43 [21504/50176]	Loss: 0.6783
Training Epoch: 43 [22528/50176]	Loss: 0.6190
Training Epoch: 43 [23552/50176]	Loss: 0.5860
Training Epoch: 43 [24576/50176]	Loss: 0.6211
Training Epoch: 43 [25600/50176]	Loss: 0.6830
Training Epoch: 43 [26624/50176]	Loss: 0.5946
Training Epoch: 43 [27648/50176]	Loss: 0.6600
Training Epoch: 43 [28672/50176]	Loss: 0.5983
Training Epoch: 43 [29696/50176]	Loss: 0.6104
Training Epoch: 43 [30720/50176]	Loss: 0.6501
Training Epoch: 43 [31744/50176]	Loss: 0.6372
Training Epoch: 43 [32768/50176]	Loss: 0.7032
Training Epoch: 43 [33792/50176]	Loss: 0.6179
Training Epoch: 43 [34816/50176]	Loss: 0.7601
Training Epoch: 43 [35840/50176]	Loss: 0.7087
Training Epoch: 43 [36864/50176]	Loss: 0.6622
Training Epoch: 43 [37888/50176]	Loss: 0.6505
Training Epoch: 43 [38912/50176]	Loss: 0.6799
Training Epoch: 43 [39936/50176]	Loss: 0.6326
Training Epoch: 43 [40960/50176]	Loss: 0.6674
Training Epoch: 43 [41984/50176]	Loss: 0.6381
Training Epoch: 43 [43008/50176]	Loss: 0.5901
Training Epoch: 43 [44032/50176]	Loss: 0.6976
Training Epoch: 43 [45056/50176]	Loss: 0.7137
Training Epoch: 43 [46080/50176]	Loss: 0.6522
Training Epoch: 43 [47104/50176]	Loss: 0.6631
Training Epoch: 43 [48128/50176]	Loss: 0.6626
Training Epoch: 43 [49152/50176]	Loss: 0.7152
Training Epoch: 43 [50176/50176]	Loss: 0.6787
2022-12-06 15:47:02.245 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:47:02,302 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.74 energy=470.01
2022-12-06 10:47:02,303 [ZeusDataLoader(train)] Up to epoch 44: time=2127.92, energy=294743.73, cost=333565.11
2022-12-06 10:47:02,303 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:47:02,303 [ZeusDataLoader(train)] Expected next epoch: time=2174.37, energy=301352.36, cost=340933.35
2022-12-06 10:47:02,304 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0020, Accuracy: 0.5435
2022-12-06 10:47:02,479 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:47:02,480 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:47:02.481 [ZeusMonitor] Monitor started.
2022-12-06 15:47:02.481 [ZeusMonitor] Running indefinitely. 2022-12-06 15:47:02.482 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:47:02.482 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e45+gpu0.power.log
2022-12-06 10:47:45,902 [ZeusDataLoader(train)] train epoch 45 done: time=43.59 energy=6193.10
2022-12-06 10:47:45,906 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.5662
Training Epoch: 44 [2048/50176]	Loss: 0.6241
Training Epoch: 44 [3072/50176]	Loss: 0.6028
Training Epoch: 44 [4096/50176]	Loss: 0.6050
Training Epoch: 44 [5120/50176]	Loss: 0.5461
Training Epoch: 44 [6144/50176]	Loss: 0.5575
Training Epoch: 44 [7168/50176]	Loss: 0.5362
Training Epoch: 44 [8192/50176]	Loss: 0.6298
Training Epoch: 44 [9216/50176]	Loss: 0.6165
Training Epoch: 44 [10240/50176]	Loss: 0.5468
Training Epoch: 44 [11264/50176]	Loss: 0.6444
Training Epoch: 44 [12288/50176]	Loss: 0.5998
Training Epoch: 44 [13312/50176]	Loss: 0.6058
Training Epoch: 44 [14336/50176]	Loss: 0.5974
Training Epoch: 44 [15360/50176]	Loss: 0.6295
Training Epoch: 44 [16384/50176]	Loss: 0.6168
Training Epoch: 44 [17408/50176]	Loss: 0.5838
Training Epoch: 44 [18432/50176]	Loss: 0.5344
Training Epoch: 44 [19456/50176]	Loss: 0.6074
Training Epoch: 44 [20480/50176]	Loss: 0.6055
Training Epoch: 44 [21504/50176]	Loss: 0.6478
Training Epoch: 44 [22528/50176]	Loss: 0.5576
Training Epoch: 44 [23552/50176]	Loss: 0.6100
Training Epoch: 44 [24576/50176]	Loss: 0.6266
Training Epoch: 44 [25600/50176]	Loss: 0.6263
Training Epoch: 44 [26624/50176]	Loss: 0.6108
Training Epoch: 44 [27648/50176]	Loss: 0.6018
Training Epoch: 44 [28672/50176]	Loss: 0.6292
Training Epoch: 44 [29696/50176]	Loss: 0.5804
Training Epoch: 44 [30720/50176]	Loss: 0.6064
Training Epoch: 44 [31744/50176]	Loss: 0.6397
Training Epoch: 44 [32768/50176]	Loss: 0.6234
Training Epoch: 44 [33792/50176]	Loss: 0.6879
Training Epoch: 44 [34816/50176]	Loss: 0.6700
Training Epoch: 44 [35840/50176]	Loss: 0.6228
Training Epoch: 44 [36864/50176]	Loss: 0.6415
Training Epoch: 44 [37888/50176]	Loss: 0.6535
Training Epoch: 44 [38912/50176]	Loss: 0.6331
Training Epoch: 44 [39936/50176]	Loss: 0.6098
Training Epoch: 44 [40960/50176]	Loss: 0.6303
Training Epoch: 44 [41984/50176]	Loss: 0.5638
Training Epoch: 44 [43008/50176]	Loss: 0.5811
Training Epoch: 44 [44032/50176]	Loss: 0.6027
Training Epoch: 44 [45056/50176]	Loss: 0.6456
Training Epoch: 44 [46080/50176]	Loss: 0.7517
Training Epoch: 44 [47104/50176]	Loss: 0.6462
Training Epoch: 44 [48128/50176]	Loss: 0.6481
Training Epoch: 44 [49152/50176]	Loss: 0.6563
Training Epoch: 44 [50176/50176]	Loss: 0.5973
2022-12-06 15:47:49.625 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:47:49,665 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.75 energy=471.12
2022-12-06 10:47:49,666 [ZeusDataLoader(train)] Up to epoch 45: time=2175.27, energy=301407.96, cost=341039.73
2022-12-06 10:47:49,666 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:47:49,666 [ZeusDataLoader(train)] Expected next epoch: time=2221.71, energy=308016.59, cost=348407.98
2022-12-06 10:47:49,667 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0020, Accuracy: 0.5336
2022-12-06 10:47:49,806 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:47:49,807 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:47:49.810 [ZeusMonitor] Monitor started.
2022-12-06 15:47:49.810 [ZeusMonitor] Running indefinitely. 2022-12-06 15:47:49.810 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:47:49.810 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e46+gpu0.power.log
2022-12-06 10:48:33,256 [ZeusDataLoader(train)] train epoch 46 done: time=43.58 energy=6203.68
2022-12-06 10:48:33,259 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.5593
Training Epoch: 45 [2048/50176]	Loss: 0.5748
Training Epoch: 45 [3072/50176]	Loss: 0.5248
Training Epoch: 45 [4096/50176]	Loss: 0.6172
Training Epoch: 45 [5120/50176]	Loss: 0.5269
Training Epoch: 45 [6144/50176]	Loss: 0.5672
Training Epoch: 45 [7168/50176]	Loss: 0.5592
Training Epoch: 45 [8192/50176]	Loss: 0.5892
Training Epoch: 45 [9216/50176]	Loss: 0.5458
Training Epoch: 45 [10240/50176]	Loss: 0.5730
Training Epoch: 45 [11264/50176]	Loss: 0.5906
Training Epoch: 45 [12288/50176]	Loss: 0.5943
Training Epoch: 45 [13312/50176]	Loss: 0.5498
Training Epoch: 45 [14336/50176]	Loss: 0.5915
Training Epoch: 45 [15360/50176]	Loss: 0.5583
Training Epoch: 45 [16384/50176]	Loss: 0.6157
Training Epoch: 45 [17408/50176]	Loss: 0.5426
Training Epoch: 45 [18432/50176]	Loss: 0.6089
Training Epoch: 45 [19456/50176]	Loss: 0.5708
Training Epoch: 45 [20480/50176]	Loss: 0.5893
Training Epoch: 45 [21504/50176]	Loss: 0.6011
Training Epoch: 45 [22528/50176]	Loss: 0.5944
Training Epoch: 45 [23552/50176]	Loss: 0.5821
Training Epoch: 45 [24576/50176]	Loss: 0.6076
Training Epoch: 45 [25600/50176]	Loss: 0.5676
Training Epoch: 45 [26624/50176]	Loss: 0.6352
Training Epoch: 45 [27648/50176]	Loss: 0.5918
Training Epoch: 45 [28672/50176]	Loss: 0.5720
Training Epoch: 45 [29696/50176]	Loss: 0.6224
Training Epoch: 45 [30720/50176]	Loss: 0.6151
Training Epoch: 45 [31744/50176]	Loss: 0.5824
Training Epoch: 45 [32768/50176]	Loss: 0.5836
Training Epoch: 45 [33792/50176]	Loss: 0.5933
Training Epoch: 45 [34816/50176]	Loss: 0.6368
Training Epoch: 45 [35840/50176]	Loss: 0.5781
Training Epoch: 45 [36864/50176]	Loss: 0.5762
Training Epoch: 45 [37888/50176]	Loss: 0.5961
Training Epoch: 45 [38912/50176]	Loss: 0.6326
Training Epoch: 45 [39936/50176]	Loss: 0.6034
Training Epoch: 45 [40960/50176]	Loss: 0.6177
Training Epoch: 45 [41984/50176]	Loss: 0.6127
Training Epoch: 45 [43008/50176]	Loss: 0.6401
Training Epoch: 45 [44032/50176]	Loss: 0.6557
Training Epoch: 45 [45056/50176]	Loss: 0.6882
Training Epoch: 45 [46080/50176]	Loss: 0.6591
Training Epoch: 45 [47104/50176]	Loss: 0.6867
Training Epoch: 45 [48128/50176]	Loss: 0.6369
Training Epoch: 45 [49152/50176]	Loss: 0.6564
Training Epoch: 45 [50176/50176]	Loss: 0.6426
2022-12-06 15:48:36.912 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:48:36,922 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.65 energy=455.07
2022-12-06 10:48:36,922 [ZeusDataLoader(train)] Up to epoch 46: time=2222.50, energy=308066.71, cost=348502.29
2022-12-06 10:48:36,923 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:48:36,923 [ZeusDataLoader(train)] Expected next epoch: time=2268.95, energy=314675.34, cost=355870.53
2022-12-06 10:48:36,924 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0020, Accuracy: 0.5429
2022-12-06 10:48:37,102 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:48:37,103 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:48:37.105 [ZeusMonitor] Monitor started.
2022-12-06 15:48:37.105 [ZeusMonitor] Running indefinitely. 2022-12-06 15:48:37.105 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:48:37.105 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e47+gpu0.power.log
2022-12-06 10:49:20,475 [ZeusDataLoader(train)] train epoch 47 done: time=43.54 energy=6199.92
2022-12-06 10:49:20,478 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.5110
Training Epoch: 46 [2048/50176]	Loss: 0.5256
Training Epoch: 46 [3072/50176]	Loss: 0.5624
Training Epoch: 46 [4096/50176]	Loss: 0.5040
Training Epoch: 46 [5120/50176]	Loss: 0.5328
Training Epoch: 46 [6144/50176]	Loss: 0.5497
Training Epoch: 46 [7168/50176]	Loss: 0.5366
Training Epoch: 46 [8192/50176]	Loss: 0.5050
Training Epoch: 46 [9216/50176]	Loss: 0.5362
Training Epoch: 46 [10240/50176]	Loss: 0.5447
Training Epoch: 46 [11264/50176]	Loss: 0.5914
Training Epoch: 46 [12288/50176]	Loss: 0.5734
Training Epoch: 46 [13312/50176]	Loss: 0.5214
Training Epoch: 46 [14336/50176]	Loss: 0.5042
Training Epoch: 46 [15360/50176]	Loss: 0.5482
Training Epoch: 46 [16384/50176]	Loss: 0.5848
Training Epoch: 46 [17408/50176]	Loss: 0.5541
Training Epoch: 46 [18432/50176]	Loss: 0.5653
Training Epoch: 46 [19456/50176]	Loss: 0.5791
Training Epoch: 46 [20480/50176]	Loss: 0.5408
Training Epoch: 46 [21504/50176]	Loss: 0.5939
Training Epoch: 46 [22528/50176]	Loss: 0.5968
Training Epoch: 46 [23552/50176]	Loss: 0.6392
Training Epoch: 46 [24576/50176]	Loss: 0.6181
Training Epoch: 46 [25600/50176]	Loss: 0.5950
Training Epoch: 46 [26624/50176]	Loss: 0.5295
Training Epoch: 46 [27648/50176]	Loss: 0.5768
Training Epoch: 46 [28672/50176]	Loss: 0.5579
Training Epoch: 46 [29696/50176]	Loss: 0.5783
Training Epoch: 46 [30720/50176]	Loss: 0.6044
Training Epoch: 46 [31744/50176]	Loss: 0.5649
Training Epoch: 46 [32768/50176]	Loss: 0.5398
Training Epoch: 46 [33792/50176]	Loss: 0.6168
Training Epoch: 46 [34816/50176]	Loss: 0.6561
Training Epoch: 46 [35840/50176]	Loss: 0.5782
Training Epoch: 46 [36864/50176]	Loss: 0.5996
Training Epoch: 46 [37888/50176]	Loss: 0.5721
Training Epoch: 46 [38912/50176]	Loss: 0.5979
Training Epoch: 46 [39936/50176]	Loss: 0.6158
Training Epoch: 46 [40960/50176]	Loss: 0.6249
Training Epoch: 46 [41984/50176]	Loss: 0.6004
Training Epoch: 46 [43008/50176]	Loss: 0.6007
Training Epoch: 46 [44032/50176]	Loss: 0.6137
Training Epoch: 46 [45056/50176]	Loss: 0.6445
Training Epoch: 46 [46080/50176]	Loss: 0.6083
Training Epoch: 46 [47104/50176]	Loss: 0.6840
Training Epoch: 46 [48128/50176]	Loss: 0.5958
Training Epoch: 46 [49152/50176]	Loss: 0.6083
Training Epoch: 46 [50176/50176]	Loss: 0.6645
2022-12-06 15:49:24.133 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:49:24,147 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.66 energy=463.09
2022-12-06 10:49:24,147 [ZeusDataLoader(train)] Up to epoch 47: time=2269.71, energy=314729.73, cost=355964.17
2022-12-06 10:49:24,147 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:49:24,147 [ZeusDataLoader(train)] Expected next epoch: time=2316.15, energy=321338.35, cost=363332.41
2022-12-06 10:49:24,148 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0021, Accuracy: 0.5357
2022-12-06 10:49:24,326 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:49:24,327 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:49:24.329 [ZeusMonitor] Monitor started.
2022-12-06 15:49:24.329 [ZeusMonitor] Running indefinitely. 2022-12-06 15:49:24.329 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:49:24.329 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e48+gpu0.power.log
2022-12-06 10:50:07,753 [ZeusDataLoader(train)] train epoch 48 done: time=43.60 energy=6198.26
2022-12-06 10:50:07,756 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.4939
Training Epoch: 47 [2048/50176]	Loss: 0.4920
Training Epoch: 47 [3072/50176]	Loss: 0.5168
Training Epoch: 47 [4096/50176]	Loss: 0.5051
Training Epoch: 47 [5120/50176]	Loss: 0.4995
Training Epoch: 47 [6144/50176]	Loss: 0.4648
Training Epoch: 47 [7168/50176]	Loss: 0.5210
Training Epoch: 47 [8192/50176]	Loss: 0.5293
Training Epoch: 47 [9216/50176]	Loss: 0.5031
Training Epoch: 47 [10240/50176]	Loss: 0.5423
Training Epoch: 47 [11264/50176]	Loss: 0.5749
Training Epoch: 47 [12288/50176]	Loss: 0.5114
Training Epoch: 47 [13312/50176]	Loss: 0.5279
Training Epoch: 47 [14336/50176]	Loss: 0.5746
Training Epoch: 47 [15360/50176]	Loss: 0.5314
Training Epoch: 47 [16384/50176]	Loss: 0.5035
Training Epoch: 47 [17408/50176]	Loss: 0.5295
Training Epoch: 47 [18432/50176]	Loss: 0.4703
Training Epoch: 47 [19456/50176]	Loss: 0.5239
Training Epoch: 47 [20480/50176]	Loss: 0.5360
Training Epoch: 47 [21504/50176]	Loss: 0.5353
Training Epoch: 47 [22528/50176]	Loss: 0.5524
Training Epoch: 47 [23552/50176]	Loss: 0.5454
Training Epoch: 47 [24576/50176]	Loss: 0.4899
Training Epoch: 47 [25600/50176]	Loss: 0.5670
Training Epoch: 47 [26624/50176]	Loss: 0.4929
Training Epoch: 47 [27648/50176]	Loss: 0.5111
Training Epoch: 47 [28672/50176]	Loss: 0.5528
Training Epoch: 47 [29696/50176]	Loss: 0.5543
Training Epoch: 47 [30720/50176]	Loss: 0.6014
Training Epoch: 47 [31744/50176]	Loss: 0.4990
Training Epoch: 47 [32768/50176]	Loss: 0.5876
Training Epoch: 47 [33792/50176]	Loss: 0.5694
Training Epoch: 47 [34816/50176]	Loss: 0.5178
Training Epoch: 47 [35840/50176]	Loss: 0.5845
Training Epoch: 47 [36864/50176]	Loss: 0.5518
Training Epoch: 47 [37888/50176]	Loss: 0.5695
Training Epoch: 47 [38912/50176]	Loss: 0.5329
Training Epoch: 47 [39936/50176]	Loss: 0.5828
Training Epoch: 47 [40960/50176]	Loss: 0.5820
Training Epoch: 47 [41984/50176]	Loss: 0.6014
Training Epoch: 47 [43008/50176]	Loss: 0.6028
Training Epoch: 47 [44032/50176]	Loss: 0.5858
Training Epoch: 47 [45056/50176]	Loss: 0.5550
Training Epoch: 47 [46080/50176]	Loss: 0.5847
Training Epoch: 47 [47104/50176]	Loss: 0.5145
Training Epoch: 47 [48128/50176]	Loss: 0.5706
Training Epoch: 47 [49152/50176]	Loss: 0.6274
Training Epoch: 47 [50176/50176]	Loss: 0.5813
2022-12-06 15:50:11.405 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:50:11,419 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.66 energy=455.77
2022-12-06 10:50:11,419 [ZeusDataLoader(train)] Up to epoch 48: time=2316.96, energy=321383.75, cost=363425.76
2022-12-06 10:50:11,419 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:50:11,420 [ZeusDataLoader(train)] Expected next epoch: time=2363.40, energy=327992.38, cost=370794.00
2022-12-06 10:50:11,420 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0020, Accuracy: 0.5402
2022-12-06 10:50:11,591 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:50:11,592 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:50:11.593 [ZeusMonitor] Monitor started.
2022-12-06 15:50:11.593 [ZeusMonitor] Running indefinitely. 2022-12-06 15:50:11.593 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:50:11.593 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e49+gpu0.power.log
2022-12-06 10:50:54,989 [ZeusDataLoader(train)] train epoch 49 done: time=43.56 energy=6193.67
2022-12-06 10:50:54,992 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.4952
Training Epoch: 48 [2048/50176]	Loss: 0.4363
Training Epoch: 48 [3072/50176]	Loss: 0.4549
Training Epoch: 48 [4096/50176]	Loss: 0.5083
Training Epoch: 48 [5120/50176]	Loss: 0.4161
Training Epoch: 48 [6144/50176]	Loss: 0.4630
Training Epoch: 48 [7168/50176]	Loss: 0.4324
Training Epoch: 48 [8192/50176]	Loss: 0.4573
Training Epoch: 48 [9216/50176]	Loss: 0.4660
Training Epoch: 48 [10240/50176]	Loss: 0.5389
Training Epoch: 48 [11264/50176]	Loss: 0.4904
Training Epoch: 48 [12288/50176]	Loss: 0.5239
Training Epoch: 48 [13312/50176]	Loss: 0.4650
Training Epoch: 48 [14336/50176]	Loss: 0.5347
Training Epoch: 48 [15360/50176]	Loss: 0.4993
Training Epoch: 48 [16384/50176]	Loss: 0.4929
Training Epoch: 48 [17408/50176]	Loss: 0.4877
Training Epoch: 48 [18432/50176]	Loss: 0.5185
Training Epoch: 48 [19456/50176]	Loss: 0.4879
Training Epoch: 48 [20480/50176]	Loss: 0.5431
Training Epoch: 48 [21504/50176]	Loss: 0.5351
Training Epoch: 48 [22528/50176]	Loss: 0.5075
Training Epoch: 48 [23552/50176]	Loss: 0.5205
Training Epoch: 48 [24576/50176]	Loss: 0.4946
Training Epoch: 48 [25600/50176]	Loss: 0.4630
Training Epoch: 48 [26624/50176]	Loss: 0.4769
Training Epoch: 48 [27648/50176]	Loss: 0.5491
Training Epoch: 48 [28672/50176]	Loss: 0.5480
Training Epoch: 48 [29696/50176]	Loss: 0.5201
Training Epoch: 48 [30720/50176]	Loss: 0.5461
Training Epoch: 48 [31744/50176]	Loss: 0.5374
Training Epoch: 48 [32768/50176]	Loss: 0.5085
Training Epoch: 48 [33792/50176]	Loss: 0.6070
Training Epoch: 48 [34816/50176]	Loss: 0.5918
Training Epoch: 48 [35840/50176]	Loss: 0.5437
Training Epoch: 48 [36864/50176]	Loss: 0.5333
Training Epoch: 48 [37888/50176]	Loss: 0.5159
Training Epoch: 48 [38912/50176]	Loss: 0.5331
Training Epoch: 48 [39936/50176]	Loss: 0.5452
Training Epoch: 48 [40960/50176]	Loss: 0.6223
Training Epoch: 48 [41984/50176]	Loss: 0.5849
Training Epoch: 48 [43008/50176]	Loss: 0.6337
Training Epoch: 48 [44032/50176]	Loss: 0.5714
Training Epoch: 48 [45056/50176]	Loss: 0.5429
Training Epoch: 48 [46080/50176]	Loss: 0.6036
Training Epoch: 48 [47104/50176]	Loss: 0.6274
Training Epoch: 48 [48128/50176]	Loss: 0.5441
Training Epoch: 48 [49152/50176]	Loss: 0.6398
Training Epoch: 48 [50176/50176]	Loss: 0.5632
2022-12-06 15:50:58.713 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:50:58,737 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.74 energy=473.64
2022-12-06 10:50:58,737 [ZeusDataLoader(train)] Up to epoch 49: time=2364.26, energy=328051.07, cost=370897.96
2022-12-06 10:50:58,737 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:50:58,737 [ZeusDataLoader(train)] Expected next epoch: time=2410.70, energy=334659.69, cost=378266.21
2022-12-06 10:50:58,738 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0021, Accuracy: 0.5325
2022-12-06 10:50:58,928 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:50:58,928 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:50:58.930 [ZeusMonitor] Monitor started.
2022-12-06 15:50:58.930 [ZeusMonitor] Running indefinitely. 2022-12-06 15:50:58.930 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:50:58.930 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e50+gpu0.power.log
2022-12-06 10:51:42,307 [ZeusDataLoader(train)] train epoch 50 done: time=43.56 energy=6199.87
2022-12-06 10:51:42,310 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 0.4527
Training Epoch: 49 [2048/50176]	Loss: 0.5124
Training Epoch: 49 [3072/50176]	Loss: 0.4472
Training Epoch: 49 [4096/50176]	Loss: 0.5005
Training Epoch: 49 [5120/50176]	Loss: 0.4740
Training Epoch: 49 [6144/50176]	Loss: 0.4814
Training Epoch: 49 [7168/50176]	Loss: 0.4929
Training Epoch: 49 [8192/50176]	Loss: 0.5085
Training Epoch: 49 [9216/50176]	Loss: 0.5334
Training Epoch: 49 [10240/50176]	Loss: 0.4541
Training Epoch: 49 [11264/50176]	Loss: 0.5226
Training Epoch: 49 [12288/50176]	Loss: 0.5104
Training Epoch: 49 [13312/50176]	Loss: 0.4787
Training Epoch: 49 [14336/50176]	Loss: 0.4953
Training Epoch: 49 [15360/50176]	Loss: 0.4875
Training Epoch: 49 [16384/50176]	Loss: 0.5114
Training Epoch: 49 [17408/50176]	Loss: 0.4167
Training Epoch: 49 [18432/50176]	Loss: 0.5325
Training Epoch: 49 [19456/50176]	Loss: 0.4735
Training Epoch: 49 [20480/50176]	Loss: 0.4560
Training Epoch: 49 [21504/50176]	Loss: 0.4901
Training Epoch: 49 [22528/50176]	Loss: 0.5683
Training Epoch: 49 [23552/50176]	Loss: 0.4924
Training Epoch: 49 [24576/50176]	Loss: 0.4884
Training Epoch: 49 [25600/50176]	Loss: 0.4974
Training Epoch: 49 [26624/50176]	Loss: 0.5236
Training Epoch: 49 [27648/50176]	Loss: 0.4945
Training Epoch: 49 [28672/50176]	Loss: 0.4624
Training Epoch: 49 [29696/50176]	Loss: 0.5142
Training Epoch: 49 [30720/50176]	Loss: 0.5367
Training Epoch: 49 [31744/50176]	Loss: 0.5188
Training Epoch: 49 [32768/50176]	Loss: 0.5125
Training Epoch: 49 [33792/50176]	Loss: 0.4816
Training Epoch: 49 [34816/50176]	Loss: 0.5500
Training Epoch: 49 [35840/50176]	Loss: 0.5832
Training Epoch: 49 [36864/50176]	Loss: 0.5375
Training Epoch: 49 [37888/50176]	Loss: 0.4786
Training Epoch: 49 [38912/50176]	Loss: 0.5669
Training Epoch: 49 [39936/50176]	Loss: 0.4894
Training Epoch: 49 [40960/50176]	Loss: 0.5197
Training Epoch: 49 [41984/50176]	Loss: 0.5868
Training Epoch: 49 [43008/50176]	Loss: 0.5051
Training Epoch: 49 [44032/50176]	Loss: 0.5025
Training Epoch: 49 [45056/50176]	Loss: 0.5087
Training Epoch: 49 [46080/50176]	Loss: 0.5163
Training Epoch: 49 [47104/50176]	Loss: 0.5630
Training Epoch: 49 [48128/50176]	Loss: 0.4988
Training Epoch: 49 [49152/50176]	Loss: 0.5589
Training Epoch: 49 [50176/50176]	Loss: 0.5365
2022-12-06 15:51:45.961 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:51:45,976 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.66 energy=464.64
2022-12-06 10:51:45,976 [ZeusDataLoader(train)] Up to epoch 50: time=2411.48, energy=334715.58, cost=378361.91
2022-12-06 10:51:45,976 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:51:45,976 [ZeusDataLoader(train)] Expected next epoch: time=2457.92, energy=341324.21, cost=385730.16
2022-12-06 10:51:45,977 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0021, Accuracy: 0.5427
2022-12-06 10:51:46,115 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:51:46,116 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:51:46.118 [ZeusMonitor] Monitor started.
2022-12-06 15:51:46.118 [ZeusMonitor] Running indefinitely. 2022-12-06 15:51:46.118 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:51:46.118 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e51+gpu0.power.log
2022-12-06 10:52:29,570 [ZeusDataLoader(train)] train epoch 51 done: time=43.58 energy=6194.13
2022-12-06 10:52:29,573 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 0.4082
Training Epoch: 50 [2048/50176]	Loss: 0.4391
Training Epoch: 50 [3072/50176]	Loss: 0.5025
Training Epoch: 50 [4096/50176]	Loss: 0.4583
Training Epoch: 50 [5120/50176]	Loss: 0.4800
Training Epoch: 50 [6144/50176]	Loss: 0.4738
Training Epoch: 50 [7168/50176]	Loss: 0.4556
Training Epoch: 50 [8192/50176]	Loss: 0.4786
Training Epoch: 50 [9216/50176]	Loss: 0.4582
Training Epoch: 50 [10240/50176]	Loss: 0.4834
Training Epoch: 50 [11264/50176]	Loss: 0.4526
Training Epoch: 50 [12288/50176]	Loss: 0.4467
Training Epoch: 50 [13312/50176]	Loss: 0.4473
Training Epoch: 50 [14336/50176]	Loss: 0.4383
Training Epoch: 50 [15360/50176]	Loss: 0.4531
Training Epoch: 50 [16384/50176]	Loss: 0.4635
Training Epoch: 50 [17408/50176]	Loss: 0.4709
Training Epoch: 50 [18432/50176]	Loss: 0.4400
Training Epoch: 50 [19456/50176]	Loss: 0.4713
Training Epoch: 50 [20480/50176]	Loss: 0.4601
Training Epoch: 50 [21504/50176]	Loss: 0.4521
Training Epoch: 50 [22528/50176]	Loss: 0.4349
Training Epoch: 50 [23552/50176]	Loss: 0.4438
Training Epoch: 50 [24576/50176]	Loss: 0.5037
Training Epoch: 50 [25600/50176]	Loss: 0.4757
Training Epoch: 50 [26624/50176]	Loss: 0.4638
Training Epoch: 50 [27648/50176]	Loss: 0.4715
Training Epoch: 50 [28672/50176]	Loss: 0.5031
Training Epoch: 50 [29696/50176]	Loss: 0.4631
Training Epoch: 50 [30720/50176]	Loss: 0.4667
Training Epoch: 50 [31744/50176]	Loss: 0.4904
Training Epoch: 50 [32768/50176]	Loss: 0.4723
Training Epoch: 50 [33792/50176]	Loss: 0.4365
Training Epoch: 50 [34816/50176]	Loss: 0.5296
Training Epoch: 50 [35840/50176]	Loss: 0.5088
Training Epoch: 50 [36864/50176]	Loss: 0.5425
Training Epoch: 50 [37888/50176]	Loss: 0.5130
Training Epoch: 50 [38912/50176]	Loss: 0.4595
Training Epoch: 50 [39936/50176]	Loss: 0.5186
Training Epoch: 50 [40960/50176]	Loss: 0.5363
Training Epoch: 50 [41984/50176]	Loss: 0.4798
Training Epoch: 50 [43008/50176]	Loss: 0.5023
Training Epoch: 50 [44032/50176]	Loss: 0.5482
Training Epoch: 50 [45056/50176]	Loss: 0.5629
Training Epoch: 50 [46080/50176]	Loss: 0.5199
Training Epoch: 50 [47104/50176]	Loss: 0.5581
Training Epoch: 50 [48128/50176]	Loss: 0.5422
Training Epoch: 50 [49152/50176]	Loss: 0.4596
Training Epoch: 50 [50176/50176]	Loss: 0.5188
2022-12-06 15:52:33.252 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:52:33,288 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.71 energy=469.72
2022-12-06 10:52:33,288 [ZeusDataLoader(train)] Up to epoch 51: time=2458.77, energy=341379.43, cost=385831.88
2022-12-06 10:52:33,288 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:52:33,288 [ZeusDataLoader(train)] Expected next epoch: time=2505.21, energy=347988.06, cost=393200.13
2022-12-06 10:52:33,289 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0021, Accuracy: 0.5380
2022-12-06 10:52:33,463 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:52:33,464 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:52:33.478 [ZeusMonitor] Monitor started.
2022-12-06 15:52:33.478 [ZeusMonitor] Running indefinitely. 2022-12-06 15:52:33.478 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:52:33.478 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e52+gpu0.power.log
2022-12-06 10:53:16,869 [ZeusDataLoader(train)] train epoch 52 done: time=43.57 energy=6199.53
2022-12-06 10:53:16,872 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 0.4339
Training Epoch: 51 [2048/50176]	Loss: 0.4566
Training Epoch: 51 [3072/50176]	Loss: 0.4180
Training Epoch: 51 [4096/50176]	Loss: 0.4241
Training Epoch: 51 [5120/50176]	Loss: 0.4214
Training Epoch: 51 [6144/50176]	Loss: 0.4004
Training Epoch: 51 [7168/50176]	Loss: 0.4445
Training Epoch: 51 [8192/50176]	Loss: 0.4371
Training Epoch: 51 [9216/50176]	Loss: 0.4373
Training Epoch: 51 [10240/50176]	Loss: 0.4229
Training Epoch: 51 [11264/50176]	Loss: 0.4612
Training Epoch: 51 [12288/50176]	Loss: 0.4847
Training Epoch: 51 [13312/50176]	Loss: 0.4291
Training Epoch: 51 [14336/50176]	Loss: 0.3685
Training Epoch: 51 [15360/50176]	Loss: 0.4590
Training Epoch: 51 [16384/50176]	Loss: 0.4724
Training Epoch: 51 [17408/50176]	Loss: 0.5024
Training Epoch: 51 [18432/50176]	Loss: 0.4991
Training Epoch: 51 [19456/50176]	Loss: 0.4683
Training Epoch: 51 [20480/50176]	Loss: 0.4291
Training Epoch: 51 [21504/50176]	Loss: 0.3890
Training Epoch: 51 [22528/50176]	Loss: 0.4428
Training Epoch: 51 [23552/50176]	Loss: 0.4976
Training Epoch: 51 [24576/50176]	Loss: 0.4668
Training Epoch: 51 [25600/50176]	Loss: 0.4790
Training Epoch: 51 [26624/50176]	Loss: 0.4372
Training Epoch: 51 [27648/50176]	Loss: 0.4365
Training Epoch: 51 [28672/50176]	Loss: 0.4612
Training Epoch: 51 [29696/50176]	Loss: 0.4837
Training Epoch: 51 [30720/50176]	Loss: 0.4644
Training Epoch: 51 [31744/50176]	Loss: 0.4671
Training Epoch: 51 [32768/50176]	Loss: 0.4353
Training Epoch: 51 [33792/50176]	Loss: 0.4953
Training Epoch: 51 [34816/50176]	Loss: 0.4672
Training Epoch: 51 [35840/50176]	Loss: 0.4881
Training Epoch: 51 [36864/50176]	Loss: 0.4681
Training Epoch: 51 [37888/50176]	Loss: 0.5070
Training Epoch: 51 [38912/50176]	Loss: 0.4437
Training Epoch: 51 [39936/50176]	Loss: 0.4328
Training Epoch: 51 [40960/50176]	Loss: 0.4954
Training Epoch: 51 [41984/50176]	Loss: 0.4960
Training Epoch: 51 [43008/50176]	Loss: 0.4372
Training Epoch: 51 [44032/50176]	Loss: 0.4776
Training Epoch: 51 [45056/50176]	Loss: 0.4883
Training Epoch: 51 [46080/50176]	Loss: 0.5171
Training Epoch: 51 [47104/50176]	Loss: 0.5607
Training Epoch: 51 [48128/50176]	Loss: 0.5158
Training Epoch: 51 [49152/50176]	Loss: 0.4788
Training Epoch: 51 [50176/50176]	Loss: 0.5087
2022-12-06 15:53:20.544 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:53:20,567 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.69 energy=460.99
2022-12-06 10:53:20,568 [ZeusDataLoader(train)] Up to epoch 52: time=2506.03, energy=348039.96, cost=393297.32
2022-12-06 10:53:20,568 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:53:20,568 [ZeusDataLoader(train)] Expected next epoch: time=2552.47, energy=354648.59, cost=400665.57
2022-12-06 10:53:20,569 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0021, Accuracy: 0.5401
2022-12-06 10:53:20,739 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:53:20,739 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:53:20.741 [ZeusMonitor] Monitor started.
2022-12-06 15:53:20.741 [ZeusMonitor] Running indefinitely. 2022-12-06 15:53:20.741 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:53:20.741 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e53+gpu0.power.log
2022-12-06 10:54:04,154 [ZeusDataLoader(train)] train epoch 53 done: time=43.58 energy=6204.10
2022-12-06 10:54:04,157 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 0.3997
Training Epoch: 52 [2048/50176]	Loss: 0.4084
Training Epoch: 52 [3072/50176]	Loss: 0.4161
Training Epoch: 52 [4096/50176]	Loss: 0.3999
Training Epoch: 52 [5120/50176]	Loss: 0.3855
Training Epoch: 52 [6144/50176]	Loss: 0.3851
Training Epoch: 52 [7168/50176]	Loss: 0.3853
Training Epoch: 52 [8192/50176]	Loss: 0.4271
Training Epoch: 52 [9216/50176]	Loss: 0.3957
Training Epoch: 52 [10240/50176]	Loss: 0.4248
Training Epoch: 52 [11264/50176]	Loss: 0.4063
Training Epoch: 52 [12288/50176]	Loss: 0.4217
Training Epoch: 52 [13312/50176]	Loss: 0.4156
Training Epoch: 52 [14336/50176]	Loss: 0.4265
Training Epoch: 52 [15360/50176]	Loss: 0.3531
Training Epoch: 52 [16384/50176]	Loss: 0.4239
Training Epoch: 52 [17408/50176]	Loss: 0.4013
Training Epoch: 52 [18432/50176]	Loss: 0.4199
Training Epoch: 52 [19456/50176]	Loss: 0.4126
Training Epoch: 52 [20480/50176]	Loss: 0.4390
Training Epoch: 52 [21504/50176]	Loss: 0.4427
Training Epoch: 52 [22528/50176]	Loss: 0.4528
Training Epoch: 52 [23552/50176]	Loss: 0.4168
Training Epoch: 52 [24576/50176]	Loss: 0.4539
Training Epoch: 52 [25600/50176]	Loss: 0.4835
Training Epoch: 52 [26624/50176]	Loss: 0.4442
Training Epoch: 52 [27648/50176]	Loss: 0.4630
Training Epoch: 52 [28672/50176]	Loss: 0.4641
Training Epoch: 52 [29696/50176]	Loss: 0.4770
Training Epoch: 52 [30720/50176]	Loss: 0.4264
Training Epoch: 52 [31744/50176]	Loss: 0.4496
Training Epoch: 52 [32768/50176]	Loss: 0.3798
Training Epoch: 52 [33792/50176]	Loss: 0.4716
Training Epoch: 52 [34816/50176]	Loss: 0.4226
Training Epoch: 52 [35840/50176]	Loss: 0.4750
Training Epoch: 52 [36864/50176]	Loss: 0.4667
Training Epoch: 52 [37888/50176]	Loss: 0.4351
Training Epoch: 52 [38912/50176]	Loss: 0.4697
Training Epoch: 52 [39936/50176]	Loss: 0.4537
Training Epoch: 52 [40960/50176]	Loss: 0.4642
Training Epoch: 52 [41984/50176]	Loss: 0.4255
Training Epoch: 52 [43008/50176]	Loss: 0.4194
Training Epoch: 52 [44032/50176]	Loss: 0.5085
Training Epoch: 52 [45056/50176]	Loss: 0.4442
Training Epoch: 52 [46080/50176]	Loss: 0.4854
Training Epoch: 52 [47104/50176]	Loss: 0.4727
Training Epoch: 52 [48128/50176]	Loss: 0.4723
Training Epoch: 52 [49152/50176]	Loss: 0.4565
Training Epoch: 52 [50176/50176]	Loss: 0.5222
2022-12-06 15:54:07.869 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:54:07,908 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.74 energy=478.65
2022-12-06 10:54:07,908 [ZeusDataLoader(train)] Up to epoch 53: time=2553.35, energy=354722.71, cost=400779.23
2022-12-06 10:54:07,908 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:54:07,908 [ZeusDataLoader(train)] Expected next epoch: time=2599.79, energy=361331.34, cost=408147.48
2022-12-06 10:54:07,909 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0022, Accuracy: 0.5482
2022-12-06 10:54:08,091 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:54:08,092 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:54:08.094 [ZeusMonitor] Monitor started.
2022-12-06 15:54:08.094 [ZeusMonitor] Running indefinitely. 2022-12-06 15:54:08.094 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:54:08.094 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e54+gpu0.power.log
2022-12-06 10:54:51,533 [ZeusDataLoader(train)] train epoch 54 done: time=43.62 energy=6205.75
2022-12-06 10:54:51,536 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 0.3753
Training Epoch: 53 [2048/50176]	Loss: 0.3797
Training Epoch: 53 [3072/50176]	Loss: 0.3947
Training Epoch: 53 [4096/50176]	Loss: 0.3921
Training Epoch: 53 [5120/50176]	Loss: 0.3717
Training Epoch: 53 [6144/50176]	Loss: 0.3869
Training Epoch: 53 [7168/50176]	Loss: 0.4375
Training Epoch: 53 [8192/50176]	Loss: 0.3806
Training Epoch: 53 [9216/50176]	Loss: 0.4012
Training Epoch: 53 [10240/50176]	Loss: 0.3939
Training Epoch: 53 [11264/50176]	Loss: 0.4125
Training Epoch: 53 [12288/50176]	Loss: 0.3693
Training Epoch: 53 [13312/50176]	Loss: 0.4063
Training Epoch: 53 [14336/50176]	Loss: 0.3909
Training Epoch: 53 [15360/50176]	Loss: 0.4269
Training Epoch: 53 [16384/50176]	Loss: 0.4026
Training Epoch: 53 [17408/50176]	Loss: 0.3813
Training Epoch: 53 [18432/50176]	Loss: 0.4020
Training Epoch: 53 [19456/50176]	Loss: 0.4742
Training Epoch: 53 [20480/50176]	Loss: 0.3719
Training Epoch: 53 [21504/50176]	Loss: 0.4123
Training Epoch: 53 [22528/50176]	Loss: 0.4135
Training Epoch: 53 [23552/50176]	Loss: 0.4087
Training Epoch: 53 [24576/50176]	Loss: 0.4339
Training Epoch: 53 [25600/50176]	Loss: 0.3935
Training Epoch: 53 [26624/50176]	Loss: 0.3767
Training Epoch: 53 [27648/50176]	Loss: 0.4598
Training Epoch: 53 [28672/50176]	Loss: 0.3738
Training Epoch: 53 [29696/50176]	Loss: 0.4541
Training Epoch: 53 [30720/50176]	Loss: 0.4101
Training Epoch: 53 [31744/50176]	Loss: 0.4580
Training Epoch: 53 [32768/50176]	Loss: 0.4435
Training Epoch: 53 [33792/50176]	Loss: 0.4728
Training Epoch: 53 [34816/50176]	Loss: 0.4319
Training Epoch: 53 [35840/50176]	Loss: 0.4562
Training Epoch: 53 [36864/50176]	Loss: 0.4375
Training Epoch: 53 [37888/50176]	Loss: 0.4534
Training Epoch: 53 [38912/50176]	Loss: 0.4430
Training Epoch: 53 [39936/50176]	Loss: 0.4685
Training Epoch: 53 [40960/50176]	Loss: 0.4756
Training Epoch: 53 [41984/50176]	Loss: 0.4731
Training Epoch: 53 [43008/50176]	Loss: 0.4996
Training Epoch: 53 [44032/50176]	Loss: 0.4853
Training Epoch: 53 [45056/50176]	Loss: 0.5275
Training Epoch: 53 [46080/50176]	Loss: 0.4592
Training Epoch: 53 [47104/50176]	Loss: 0.4506
Training Epoch: 53 [48128/50176]	Loss: 0.4215
Training Epoch: 53 [49152/50176]	Loss: 0.4758
Training Epoch: 53 [50176/50176]	Loss: 0.4861
2022-12-06 15:54:55.261 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:54:55,281 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.74 energy=470.71
2022-12-06 10:54:55,281 [ZeusDataLoader(train)] Up to epoch 54: time=2600.70, energy=361399.17, cost=408260.92
2022-12-06 10:54:55,282 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:54:55,282 [ZeusDataLoader(train)] Expected next epoch: time=2647.15, energy=368007.80, cost=415629.16
2022-12-06 10:54:55,282 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0022, Accuracy: 0.5423
2022-12-06 10:54:55,451 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:54:55,451 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:54:55.473 [ZeusMonitor] Monitor started.
2022-12-06 15:54:55.473 [ZeusMonitor] Running indefinitely. 2022-12-06 15:54:55.473 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:54:55.473 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e55+gpu0.power.log
2022-12-06 10:55:38,865 [ZeusDataLoader(train)] train epoch 55 done: time=43.57 energy=6196.39
2022-12-06 10:55:38,868 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 0.3847
Training Epoch: 54 [2048/50176]	Loss: 0.3988
Training Epoch: 54 [3072/50176]	Loss: 0.3412
Training Epoch: 54 [4096/50176]	Loss: 0.4050
Training Epoch: 54 [5120/50176]	Loss: 0.3626
Training Epoch: 54 [6144/50176]	Loss: 0.3602
Training Epoch: 54 [7168/50176]	Loss: 0.3882
Training Epoch: 54 [8192/50176]	Loss: 0.3854
Training Epoch: 54 [9216/50176]	Loss: 0.3813
Training Epoch: 54 [10240/50176]	Loss: 0.3744
Training Epoch: 54 [11264/50176]	Loss: 0.3817
Training Epoch: 54 [12288/50176]	Loss: 0.4028
Training Epoch: 54 [13312/50176]	Loss: 0.4410
Training Epoch: 54 [14336/50176]	Loss: 0.3753
Training Epoch: 54 [15360/50176]	Loss: 0.4367
Training Epoch: 54 [16384/50176]	Loss: 0.3545
Training Epoch: 54 [17408/50176]	Loss: 0.4063
Training Epoch: 54 [18432/50176]	Loss: 0.3962
Training Epoch: 54 [19456/50176]	Loss: 0.4370
Training Epoch: 54 [20480/50176]	Loss: 0.3614
Training Epoch: 54 [21504/50176]	Loss: 0.4601
Training Epoch: 54 [22528/50176]	Loss: 0.4302
Training Epoch: 54 [23552/50176]	Loss: 0.3834
Training Epoch: 54 [24576/50176]	Loss: 0.4091
Training Epoch: 54 [25600/50176]	Loss: 0.3988
Training Epoch: 54 [26624/50176]	Loss: 0.4266
Training Epoch: 54 [27648/50176]	Loss: 0.4306
Training Epoch: 54 [28672/50176]	Loss: 0.3890
Training Epoch: 54 [29696/50176]	Loss: 0.3844
Training Epoch: 54 [30720/50176]	Loss: 0.4022
Training Epoch: 54 [31744/50176]	Loss: 0.4350
Training Epoch: 54 [32768/50176]	Loss: 0.4168
Training Epoch: 54 [33792/50176]	Loss: 0.4457
Training Epoch: 54 [34816/50176]	Loss: 0.4669
Training Epoch: 54 [35840/50176]	Loss: 0.4674
Training Epoch: 54 [36864/50176]	Loss: 0.4202
Training Epoch: 54 [37888/50176]	Loss: 0.4442
Training Epoch: 54 [38912/50176]	Loss: 0.4392
Training Epoch: 54 [39936/50176]	Loss: 0.4278
Training Epoch: 54 [40960/50176]	Loss: 0.4276
Training Epoch: 54 [41984/50176]	Loss: 0.4336
Training Epoch: 54 [43008/50176]	Loss: 0.4488
Training Epoch: 54 [44032/50176]	Loss: 0.4038
Training Epoch: 54 [45056/50176]	Loss: 0.4427
Training Epoch: 54 [46080/50176]	Loss: 0.3939
Training Epoch: 54 [47104/50176]	Loss: 0.4374
Training Epoch: 54 [48128/50176]	Loss: 0.4276
Training Epoch: 54 [49152/50176]	Loss: 0.4527
Training Epoch: 54 [50176/50176]	Loss: 0.4371
2022-12-06 15:55:42.553 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:55:42,561 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.68 energy=475.43
2022-12-06 10:55:42,561 [ZeusDataLoader(train)] Up to epoch 55: time=2647.96, energy=368070.99, cost=415731.98
2022-12-06 10:55:42,561 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:55:42,561 [ZeusDataLoader(train)] Expected next epoch: time=2694.40, energy=374679.62, cost=423100.23
2022-12-06 10:55:42,562 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0022, Accuracy: 0.5465
2022-12-06 10:55:42,697 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:55:42,698 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:55:42.701 [ZeusMonitor] Monitor started.
2022-12-06 15:55:42.701 [ZeusMonitor] Running indefinitely. 2022-12-06 15:55:42.701 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:55:42.701 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e56+gpu0.power.log
2022-12-06 10:56:26,172 [ZeusDataLoader(train)] train epoch 56 done: time=43.60 energy=6198.45
2022-12-06 10:56:26,175 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 0.3484
Training Epoch: 55 [2048/50176]	Loss: 0.3674
Training Epoch: 55 [3072/50176]	Loss: 0.3220
Training Epoch: 55 [4096/50176]	Loss: 0.3617
Training Epoch: 55 [5120/50176]	Loss: 0.3664
Training Epoch: 55 [6144/50176]	Loss: 0.3406
Training Epoch: 55 [7168/50176]	Loss: 0.3594
Training Epoch: 55 [8192/50176]	Loss: 0.3836
Training Epoch: 55 [9216/50176]	Loss: 0.3695
Training Epoch: 55 [10240/50176]	Loss: 0.3703
Training Epoch: 55 [11264/50176]	Loss: 0.3570
Training Epoch: 55 [12288/50176]	Loss: 0.3573
Training Epoch: 55 [13312/50176]	Loss: 0.3441
Training Epoch: 55 [14336/50176]	Loss: 0.4272
Training Epoch: 55 [15360/50176]	Loss: 0.3662
Training Epoch: 55 [16384/50176]	Loss: 0.3180
Training Epoch: 55 [17408/50176]	Loss: 0.3797
Training Epoch: 55 [18432/50176]	Loss: 0.3756
Training Epoch: 55 [19456/50176]	Loss: 0.4288
Training Epoch: 55 [20480/50176]	Loss: 0.4167
Training Epoch: 55 [21504/50176]	Loss: 0.3959
Training Epoch: 55 [22528/50176]	Loss: 0.4014
Training Epoch: 55 [23552/50176]	Loss: 0.3818
Training Epoch: 55 [24576/50176]	Loss: 0.3738
Training Epoch: 55 [25600/50176]	Loss: 0.4038
Training Epoch: 55 [26624/50176]	Loss: 0.4326
Training Epoch: 55 [27648/50176]	Loss: 0.3990
Training Epoch: 55 [28672/50176]	Loss: 0.3858
Training Epoch: 55 [29696/50176]	Loss: 0.4179
Training Epoch: 55 [30720/50176]	Loss: 0.3658
Training Epoch: 55 [31744/50176]	Loss: 0.4104
Training Epoch: 55 [32768/50176]	Loss: 0.4362
Training Epoch: 55 [33792/50176]	Loss: 0.3780
Training Epoch: 55 [34816/50176]	Loss: 0.3970
Training Epoch: 55 [35840/50176]	Loss: 0.4478
Training Epoch: 55 [36864/50176]	Loss: 0.4624
Training Epoch: 55 [37888/50176]	Loss: 0.4478
Training Epoch: 55 [38912/50176]	Loss: 0.4090
Training Epoch: 55 [39936/50176]	Loss: 0.4221
Training Epoch: 55 [40960/50176]	Loss: 0.4060
Training Epoch: 55 [41984/50176]	Loss: 0.4269
Training Epoch: 55 [43008/50176]	Loss: 0.4385
Training Epoch: 55 [44032/50176]	Loss: 0.4251
Training Epoch: 55 [45056/50176]	Loss: 0.4158
Training Epoch: 55 [46080/50176]	Loss: 0.4487
Training Epoch: 55 [47104/50176]	Loss: 0.4628
Training Epoch: 55 [48128/50176]	Loss: 0.4773
Training Epoch: 55 [49152/50176]	Loss: 0.4316
Training Epoch: 55 [50176/50176]	Loss: 0.4713
2022-12-06 15:56:29.855 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:56:29,913 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.73 energy=474.73
2022-12-06 10:56:29,914 [ZeusDataLoader(train)] Up to epoch 56: time=2695.29, energy=374744.17, cost=423210.03
2022-12-06 10:56:29,914 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:56:29,914 [ZeusDataLoader(train)] Expected next epoch: time=2741.74, energy=381352.80, cost=430578.28
2022-12-06 10:56:29,915 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0022, Accuracy: 0.5410
2022-12-06 10:56:30,091 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:56:30,092 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:56:30.093 [ZeusMonitor] Monitor started.
2022-12-06 15:56:30.093 [ZeusMonitor] Running indefinitely. 2022-12-06 15:56:30.093 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:56:30.093 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e57+gpu0.power.log
2022-12-06 10:57:13,506 [ZeusDataLoader(train)] train epoch 57 done: time=43.58 energy=6195.63
2022-12-06 10:57:13,509 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 0.3241
Training Epoch: 56 [2048/50176]	Loss: 0.3678
Training Epoch: 56 [3072/50176]	Loss: 0.3605
Training Epoch: 56 [4096/50176]	Loss: 0.3342
Training Epoch: 56 [5120/50176]	Loss: 0.3719
Training Epoch: 56 [6144/50176]	Loss: 0.3439
Training Epoch: 56 [7168/50176]	Loss: 0.3868
Training Epoch: 56 [8192/50176]	Loss: 0.3721
Training Epoch: 56 [9216/50176]	Loss: 0.3441
Training Epoch: 56 [10240/50176]	Loss: 0.3759
Training Epoch: 56 [11264/50176]	Loss: 0.3450
Training Epoch: 56 [12288/50176]	Loss: 0.3597
Training Epoch: 56 [13312/50176]	Loss: 0.3784
Training Epoch: 56 [14336/50176]	Loss: 0.3437
Training Epoch: 56 [15360/50176]	Loss: 0.3618
Training Epoch: 56 [16384/50176]	Loss: 0.3531
Training Epoch: 56 [17408/50176]	Loss: 0.3711
Training Epoch: 56 [18432/50176]	Loss: 0.3948
Training Epoch: 56 [19456/50176]	Loss: 0.3386
Training Epoch: 56 [20480/50176]	Loss: 0.3663
Training Epoch: 56 [21504/50176]	Loss: 0.3911
Training Epoch: 56 [22528/50176]	Loss: 0.3825
Training Epoch: 56 [23552/50176]	Loss: 0.3648
Training Epoch: 56 [24576/50176]	Loss: 0.3767
Training Epoch: 56 [25600/50176]	Loss: 0.3236
Training Epoch: 56 [26624/50176]	Loss: 0.3605
Training Epoch: 56 [27648/50176]	Loss: 0.3462
Training Epoch: 56 [28672/50176]	Loss: 0.3940
Training Epoch: 56 [29696/50176]	Loss: 0.3486
Training Epoch: 56 [30720/50176]	Loss: 0.3775
Training Epoch: 56 [31744/50176]	Loss: 0.3655
Training Epoch: 56 [32768/50176]	Loss: 0.3924
Training Epoch: 56 [33792/50176]	Loss: 0.3887
Training Epoch: 56 [34816/50176]	Loss: 0.3982
Training Epoch: 56 [35840/50176]	Loss: 0.3974
Training Epoch: 56 [36864/50176]	Loss: 0.3613
Training Epoch: 56 [37888/50176]	Loss: 0.4096
Training Epoch: 56 [38912/50176]	Loss: 0.4186
Training Epoch: 56 [39936/50176]	Loss: 0.3619
Training Epoch: 56 [40960/50176]	Loss: 0.3800
Training Epoch: 56 [41984/50176]	Loss: 0.3973
Training Epoch: 56 [43008/50176]	Loss: 0.4199
Training Epoch: 56 [44032/50176]	Loss: 0.4078
Training Epoch: 56 [45056/50176]	Loss: 0.4262
Training Epoch: 56 [46080/50176]	Loss: 0.4075
Training Epoch: 56 [47104/50176]	Loss: 0.4092
Training Epoch: 56 [48128/50176]	Loss: 0.3642
Training Epoch: 56 [49152/50176]	Loss: 0.4304
Training Epoch: 56 [50176/50176]	Loss: 0.4174
2022-12-06 15:57:17.211 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:57:17,245 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.73 energy=475.09
2022-12-06 10:57:17,245 [ZeusDataLoader(train)] Up to epoch 57: time=2742.60, energy=381414.88, cost=430685.12
2022-12-06 10:57:17,245 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:57:17,245 [ZeusDataLoader(train)] Expected next epoch: time=2789.05, energy=388023.51, cost=438053.37
2022-12-06 10:57:17,246 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0022, Accuracy: 0.5478
2022-12-06 10:57:17,419 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:57:17,420 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:57:17.421 [ZeusMonitor] Monitor started.
2022-12-06 15:57:17.421 [ZeusMonitor] Running indefinitely. 2022-12-06 15:57:17.421 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:57:17.421 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e58+gpu0.power.log
2022-12-06 10:58:00,815 [ZeusDataLoader(train)] train epoch 58 done: time=43.56 energy=6192.84
2022-12-06 10:58:00,818 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 0.3469
Training Epoch: 57 [2048/50176]	Loss: 0.3787
Training Epoch: 57 [3072/50176]	Loss: 0.3581
Training Epoch: 57 [4096/50176]	Loss: 0.3593
Training Epoch: 57 [5120/50176]	Loss: 0.3405
Training Epoch: 57 [6144/50176]	Loss: 0.3496
Training Epoch: 57 [7168/50176]	Loss: 0.3617
Training Epoch: 57 [8192/50176]	Loss: 0.3378
Training Epoch: 57 [9216/50176]	Loss: 0.3448
Training Epoch: 57 [10240/50176]	Loss: 0.3131
Training Epoch: 57 [11264/50176]	Loss: 0.3533
Training Epoch: 57 [12288/50176]	Loss: 0.3529
Training Epoch: 57 [13312/50176]	Loss: 0.3134
Training Epoch: 57 [14336/50176]	Loss: 0.3535
Training Epoch: 57 [15360/50176]	Loss: 0.2914
Training Epoch: 57 [16384/50176]	Loss: 0.3269
Training Epoch: 57 [17408/50176]	Loss: 0.3494
Training Epoch: 57 [18432/50176]	Loss: 0.3153
Training Epoch: 57 [19456/50176]	Loss: 0.3566
Training Epoch: 57 [20480/50176]	Loss: 0.3373
Training Epoch: 57 [21504/50176]	Loss: 0.3540
Training Epoch: 57 [22528/50176]	Loss: 0.3355
Training Epoch: 57 [23552/50176]	Loss: 0.3580
Training Epoch: 57 [24576/50176]	Loss: 0.3302
Training Epoch: 57 [25600/50176]	Loss: 0.3317
Training Epoch: 57 [26624/50176]	Loss: 0.3495
Training Epoch: 57 [27648/50176]	Loss: 0.3436
Training Epoch: 57 [28672/50176]	Loss: 0.4051
Training Epoch: 57 [29696/50176]	Loss: 0.3596
Training Epoch: 57 [30720/50176]	Loss: 0.3448
Training Epoch: 57 [31744/50176]	Loss: 0.3744
Training Epoch: 57 [32768/50176]	Loss: 0.3681
Training Epoch: 57 [33792/50176]	Loss: 0.3639
Training Epoch: 57 [34816/50176]	Loss: 0.4044
Training Epoch: 57 [35840/50176]	Loss: 0.3617
Training Epoch: 57 [36864/50176]	Loss: 0.3446
Training Epoch: 57 [37888/50176]	Loss: 0.3613
Training Epoch: 57 [38912/50176]	Loss: 0.3720
Training Epoch: 57 [39936/50176]	Loss: 0.3401
Training Epoch: 57 [40960/50176]	Loss: 0.3460
Training Epoch: 57 [41984/50176]	Loss: 0.3866
Training Epoch: 57 [43008/50176]	Loss: 0.3864
Training Epoch: 57 [44032/50176]	Loss: 0.3698
Training Epoch: 57 [45056/50176]	Loss: 0.4014
Training Epoch: 57 [46080/50176]	Loss: 0.3788
Training Epoch: 57 [47104/50176]	Loss: 0.3703
Training Epoch: 57 [48128/50176]	Loss: 0.3791
Training Epoch: 57 [49152/50176]	Loss: 0.3808
Training Epoch: 57 [50176/50176]	Loss: 0.4462
2022-12-06 15:58:04.502 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:58:04,521 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.70 energy=470.83
2022-12-06 10:58:04,522 [ZeusDataLoader(train)] Up to epoch 58: time=2789.86, energy=388078.55, cost=438151.95
2022-12-06 10:58:04,522 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:58:04,522 [ZeusDataLoader(train)] Expected next epoch: time=2836.30, energy=394687.18, cost=445520.20
2022-12-06 10:58:04,523 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0022, Accuracy: 0.5477
2022-12-06 10:58:04,695 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:58:04,696 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:58:04.697 [ZeusMonitor] Monitor started.
2022-12-06 15:58:04.697 [ZeusMonitor] Running indefinitely. 2022-12-06 15:58:04.697 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:58:04.697 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e59+gpu0.power.log
2022-12-06 10:58:48,052 [ZeusDataLoader(train)] train epoch 59 done: time=43.52 energy=6195.35
2022-12-06 10:58:48,055 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 0.3047
Training Epoch: 58 [2048/50176]	Loss: 0.3477
Training Epoch: 58 [3072/50176]	Loss: 0.3163
Training Epoch: 58 [4096/50176]	Loss: 0.3074
Training Epoch: 58 [5120/50176]	Loss: 0.2776
Training Epoch: 58 [6144/50176]	Loss: 0.3062
Training Epoch: 58 [7168/50176]	Loss: 0.2816
Training Epoch: 58 [8192/50176]	Loss: 0.3166
Training Epoch: 58 [9216/50176]	Loss: 0.3425
Training Epoch: 58 [10240/50176]	Loss: 0.3415
Training Epoch: 58 [11264/50176]	Loss: 0.3232
Training Epoch: 58 [12288/50176]	Loss: 0.3551
Training Epoch: 58 [13312/50176]	Loss: 0.3339
Training Epoch: 58 [14336/50176]	Loss: 0.3177
Training Epoch: 58 [15360/50176]	Loss: 0.3178
Training Epoch: 58 [16384/50176]	Loss: 0.3320
Training Epoch: 58 [17408/50176]	Loss: 0.3566
Training Epoch: 58 [18432/50176]	Loss: 0.3170
Training Epoch: 58 [19456/50176]	Loss: 0.2859
Training Epoch: 58 [20480/50176]	Loss: 0.3490
Training Epoch: 58 [21504/50176]	Loss: 0.3663
Training Epoch: 58 [22528/50176]	Loss: 0.3205
Training Epoch: 58 [23552/50176]	Loss: 0.3674
Training Epoch: 58 [24576/50176]	Loss: 0.3420
Training Epoch: 58 [25600/50176]	Loss: 0.3589
Training Epoch: 58 [26624/50176]	Loss: 0.3023
Training Epoch: 58 [27648/50176]	Loss: 0.3586
Training Epoch: 58 [28672/50176]	Loss: 0.3401
Training Epoch: 58 [29696/50176]	Loss: 0.3608
Training Epoch: 58 [30720/50176]	Loss: 0.3982
Training Epoch: 58 [31744/50176]	Loss: 0.3754
Training Epoch: 58 [32768/50176]	Loss: 0.3459
Training Epoch: 58 [33792/50176]	Loss: 0.3700
Training Epoch: 58 [34816/50176]	Loss: 0.2985
Training Epoch: 58 [35840/50176]	Loss: 0.3692
Training Epoch: 58 [36864/50176]	Loss: 0.3371
Training Epoch: 58 [37888/50176]	Loss: 0.3637
Training Epoch: 58 [38912/50176]	Loss: 0.3495
Training Epoch: 58 [39936/50176]	Loss: 0.3629
Training Epoch: 58 [40960/50176]	Loss: 0.3900
Training Epoch: 58 [41984/50176]	Loss: 0.3328
Training Epoch: 58 [43008/50176]	Loss: 0.3986
Training Epoch: 58 [44032/50176]	Loss: 0.3857
Training Epoch: 58 [45056/50176]	Loss: 0.3844
Training Epoch: 58 [46080/50176]	Loss: 0.4334
Training Epoch: 58 [47104/50176]	Loss: 0.3741
Training Epoch: 58 [48128/50176]	Loss: 0.3553
Training Epoch: 58 [49152/50176]	Loss: 0.3908
Training Epoch: 58 [50176/50176]	Loss: 0.3813
2022-12-06 15:58:51.745 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:58:51,770 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.71 energy=472.58
2022-12-06 10:58:51,770 [ZeusDataLoader(train)] Up to epoch 59: time=2837.09, energy=394746.48, cost=445618.41
2022-12-06 10:58:51,770 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:58:51,770 [ZeusDataLoader(train)] Expected next epoch: time=2883.53, energy=401355.11, cost=452986.66
2022-12-06 10:58:51,771 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0023, Accuracy: 0.5401
2022-12-06 10:58:51,955 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:58:51,956 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:58:51.957 [ZeusMonitor] Monitor started.
2022-12-06 15:58:51.958 [ZeusMonitor] Running indefinitely. 2022-12-06 15:58:51.958 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:58:51.958 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e60+gpu0.power.log
2022-12-06 10:59:35,391 [ZeusDataLoader(train)] train epoch 60 done: time=43.61 energy=6194.64
2022-12-06 10:59:35,395 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 0.2764
Training Epoch: 59 [2048/50176]	Loss: 0.3073
Training Epoch: 59 [3072/50176]	Loss: 0.3239
Training Epoch: 59 [4096/50176]	Loss: 0.3121
Training Epoch: 59 [5120/50176]	Loss: 0.2925
Training Epoch: 59 [6144/50176]	Loss: 0.3216
Training Epoch: 59 [7168/50176]	Loss: 0.3234
Training Epoch: 59 [8192/50176]	Loss: 0.3328
Training Epoch: 59 [9216/50176]	Loss: 0.3078
Training Epoch: 59 [10240/50176]	Loss: 0.2868
Training Epoch: 59 [11264/50176]	Loss: 0.2751
Training Epoch: 59 [12288/50176]	Loss: 0.3091
Training Epoch: 59 [13312/50176]	Loss: 0.2892
Training Epoch: 59 [14336/50176]	Loss: 0.3024
Training Epoch: 59 [15360/50176]	Loss: 0.2924
Training Epoch: 59 [16384/50176]	Loss: 0.3018
Training Epoch: 59 [17408/50176]	Loss: 0.3331
Training Epoch: 59 [18432/50176]	Loss: 0.3048
Training Epoch: 59 [19456/50176]	Loss: 0.3408
Training Epoch: 59 [20480/50176]	Loss: 0.3414
Training Epoch: 59 [21504/50176]	Loss: 0.3355
Training Epoch: 59 [22528/50176]	Loss: 0.3144
Training Epoch: 59 [23552/50176]	Loss: 0.3448
Training Epoch: 59 [24576/50176]	Loss: 0.3037
Training Epoch: 59 [25600/50176]	Loss: 0.2984
Training Epoch: 59 [26624/50176]	Loss: 0.3255
Training Epoch: 59 [27648/50176]	Loss: 0.3443
Training Epoch: 59 [28672/50176]	Loss: 0.3389
Training Epoch: 59 [29696/50176]	Loss: 0.3813
Training Epoch: 59 [30720/50176]	Loss: 0.3502
Training Epoch: 59 [31744/50176]	Loss: 0.3244
Training Epoch: 59 [32768/50176]	Loss: 0.3709
Training Epoch: 59 [33792/50176]	Loss: 0.3465
Training Epoch: 59 [34816/50176]	Loss: 0.3530
Training Epoch: 59 [35840/50176]	Loss: 0.3894
Training Epoch: 59 [36864/50176]	Loss: 0.3889
Training Epoch: 59 [37888/50176]	Loss: 0.3370
Training Epoch: 59 [38912/50176]	Loss: 0.3513
Training Epoch: 59 [39936/50176]	Loss: 0.3171
Training Epoch: 59 [40960/50176]	Loss: 0.3427
Training Epoch: 59 [41984/50176]	Loss: 0.3706
Training Epoch: 59 [43008/50176]	Loss: 0.3774
Training Epoch: 59 [44032/50176]	Loss: 0.3823
Training Epoch: 59 [45056/50176]	Loss: 0.3430
Training Epoch: 59 [46080/50176]	Loss: 0.3775
Training Epoch: 59 [47104/50176]	Loss: 0.3298
Training Epoch: 59 [48128/50176]	Loss: 0.3329
Training Epoch: 59 [49152/50176]	Loss: 0.3650
Training Epoch: 59 [50176/50176]	Loss: 0.3505
2022-12-06 15:59:39.120 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 10:59:39,150 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.75 energy=471.40
2022-12-06 10:59:39,151 [ZeusDataLoader(train)] Up to epoch 60: time=2884.45, energy=401412.52, cost=453095.47
2022-12-06 10:59:39,151 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 10:59:39,151 [ZeusDataLoader(train)] Expected next epoch: time=2930.89, energy=408021.15, cost=460463.71
2022-12-06 10:59:39,152 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0023, Accuracy: 0.5426
2022-12-06 10:59:39,294 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 10:59:39,294 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 15:59:39.298 [ZeusMonitor] Monitor started.
2022-12-06 15:59:39.298 [ZeusMonitor] Running indefinitely. 2022-12-06 15:59:39.298 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 15:59:39.298 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e61+gpu0.power.log
2022-12-06 11:00:22,714 [ZeusDataLoader(train)] train epoch 61 done: time=43.55 energy=6193.34
2022-12-06 11:00:22,717 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.2874
Training Epoch: 60 [2048/50176]	Loss: 0.2907
Training Epoch: 60 [3072/50176]	Loss: 0.2588
Training Epoch: 60 [4096/50176]	Loss: 0.2506
Training Epoch: 60 [5120/50176]	Loss: 0.3529
Training Epoch: 60 [6144/50176]	Loss: 0.2700
Training Epoch: 60 [7168/50176]	Loss: 0.2899
Training Epoch: 60 [8192/50176]	Loss: 0.3139
Training Epoch: 60 [9216/50176]	Loss: 0.2908
Training Epoch: 60 [10240/50176]	Loss: 0.2820
Training Epoch: 60 [11264/50176]	Loss: 0.2812
Training Epoch: 60 [12288/50176]	Loss: 0.3257
Training Epoch: 60 [13312/50176]	Loss: 0.3013
Training Epoch: 60 [14336/50176]	Loss: 0.2921
Training Epoch: 60 [15360/50176]	Loss: 0.3021
Training Epoch: 60 [16384/50176]	Loss: 0.3022
Training Epoch: 60 [17408/50176]	Loss: 0.3279
Training Epoch: 60 [18432/50176]	Loss: 0.3202
Training Epoch: 60 [19456/50176]	Loss: 0.2999
Training Epoch: 60 [20480/50176]	Loss: 0.2882
Training Epoch: 60 [21504/50176]	Loss: 0.3009
Training Epoch: 60 [22528/50176]	Loss: 0.3359
Training Epoch: 60 [23552/50176]	Loss: 0.2955
Training Epoch: 60 [24576/50176]	Loss: 0.3025
Training Epoch: 60 [25600/50176]	Loss: 0.3318
Training Epoch: 60 [26624/50176]	Loss: 0.3242
Training Epoch: 60 [27648/50176]	Loss: 0.3350
Training Epoch: 60 [28672/50176]	Loss: 0.3232
Training Epoch: 60 [29696/50176]	Loss: 0.3092
Training Epoch: 60 [30720/50176]	Loss: 0.3572
Training Epoch: 60 [31744/50176]	Loss: 0.3271
Training Epoch: 60 [32768/50176]	Loss: 0.3508
Training Epoch: 60 [33792/50176]	Loss: 0.3144
Training Epoch: 60 [34816/50176]	Loss: 0.2875
Training Epoch: 60 [35840/50176]	Loss: 0.3029
Training Epoch: 60 [36864/50176]	Loss: 0.3206
Training Epoch: 60 [37888/50176]	Loss: 0.3297
Training Epoch: 60 [38912/50176]	Loss: 0.3357
Training Epoch: 60 [39936/50176]	Loss: 0.3422
Training Epoch: 60 [40960/50176]	Loss: 0.3292
Training Epoch: 60 [41984/50176]	Loss: 0.3186
Training Epoch: 60 [43008/50176]	Loss: 0.3328
Training Epoch: 60 [44032/50176]	Loss: 0.3215
Training Epoch: 60 [45056/50176]	Loss: 0.3192
Training Epoch: 60 [46080/50176]	Loss: 0.3361
Training Epoch: 60 [47104/50176]	Loss: 0.3179
Training Epoch: 60 [48128/50176]	Loss: 0.3361
Training Epoch: 60 [49152/50176]	Loss: 0.3735
Training Epoch: 60 [50176/50176]	Loss: 0.3757
2022-12-06 16:00:26.436 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:00:26,462 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.74 energy=474.37
2022-12-06 11:00:26,463 [ZeusDataLoader(train)] Up to epoch 61: time=2931.74, energy=408080.24, cost=460567.38
2022-12-06 11:00:26,463 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:00:26,463 [ZeusDataLoader(train)] Expected next epoch: time=2978.19, energy=414688.86, cost=467935.62
2022-12-06 11:00:26,464 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0023, Accuracy: 0.5399
2022-12-06 11:00:26,636 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:00:26,637 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:00:26.639 [ZeusMonitor] Monitor started.
2022-12-06 16:00:26.639 [ZeusMonitor] Running indefinitely. 2022-12-06 16:00:26.639 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:00:26.639 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e62+gpu0.power.log
2022-12-06 11:01:10,001 [ZeusDataLoader(train)] train epoch 62 done: time=43.53 energy=6193.21
2022-12-06 11:01:10,005 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.2718
Training Epoch: 61 [2048/50176]	Loss: 0.3074
Training Epoch: 61 [3072/50176]	Loss: 0.2750
Training Epoch: 61 [4096/50176]	Loss: 0.3100
Training Epoch: 61 [5120/50176]	Loss: 0.3194
Training Epoch: 61 [6144/50176]	Loss: 0.3157
Training Epoch: 61 [7168/50176]	Loss: 0.3009
Training Epoch: 61 [8192/50176]	Loss: 0.2639
Training Epoch: 61 [9216/50176]	Loss: 0.3107
Training Epoch: 61 [10240/50176]	Loss: 0.3033
Training Epoch: 61 [11264/50176]	Loss: 0.3043
Training Epoch: 61 [12288/50176]	Loss: 0.2881
Training Epoch: 61 [13312/50176]	Loss: 0.2818
Training Epoch: 61 [14336/50176]	Loss: 0.3166
Training Epoch: 61 [15360/50176]	Loss: 0.3021
Training Epoch: 61 [16384/50176]	Loss: 0.3435
Training Epoch: 61 [17408/50176]	Loss: 0.3052
Training Epoch: 61 [18432/50176]	Loss: 0.2916
Training Epoch: 61 [19456/50176]	Loss: 0.2911
Training Epoch: 61 [20480/50176]	Loss: 0.3338
Training Epoch: 61 [21504/50176]	Loss: 0.3026
Training Epoch: 61 [22528/50176]	Loss: 0.3238
Training Epoch: 61 [23552/50176]	Loss: 0.3012
Training Epoch: 61 [24576/50176]	Loss: 0.3046
Training Epoch: 61 [25600/50176]	Loss: 0.2809
Training Epoch: 61 [26624/50176]	Loss: 0.3040
Training Epoch: 61 [27648/50176]	Loss: 0.3195
Training Epoch: 61 [28672/50176]	Loss: 0.3422
Training Epoch: 61 [29696/50176]	Loss: 0.2973
Training Epoch: 61 [30720/50176]	Loss: 0.3240
Training Epoch: 61 [31744/50176]	Loss: 0.2943
Training Epoch: 61 [32768/50176]	Loss: 0.2932
Training Epoch: 61 [33792/50176]	Loss: 0.3482
Training Epoch: 61 [34816/50176]	Loss: 0.3237
Training Epoch: 61 [35840/50176]	Loss: 0.3489
Training Epoch: 61 [36864/50176]	Loss: 0.3586
Training Epoch: 61 [37888/50176]	Loss: 0.2889
Training Epoch: 61 [38912/50176]	Loss: 0.3155
Training Epoch: 61 [39936/50176]	Loss: 0.3257
Training Epoch: 61 [40960/50176]	Loss: 0.3184
Training Epoch: 61 [41984/50176]	Loss: 0.3480
Training Epoch: 61 [43008/50176]	Loss: 0.3536
Training Epoch: 61 [44032/50176]	Loss: 0.3456
Training Epoch: 61 [45056/50176]	Loss: 0.3177
Training Epoch: 61 [46080/50176]	Loss: 0.3698
Training Epoch: 61 [47104/50176]	Loss: 0.3209
Training Epoch: 61 [48128/50176]	Loss: 0.3683
Training Epoch: 61 [49152/50176]	Loss: 0.3575
Training Epoch: 61 [50176/50176]	Loss: 0.3677
2022-12-06 16:01:13.637 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:01:13,646 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.63 energy=455.99
2022-12-06 11:01:13,646 [ZeusDataLoader(train)] Up to epoch 62: time=2978.90, energy=414729.44, cost=468018.67
2022-12-06 11:01:13,646 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:01:13,646 [ZeusDataLoader(train)] Expected next epoch: time=3025.35, energy=421338.06, cost=475386.91
2022-12-06 11:01:13,647 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0023, Accuracy: 0.5489
2022-12-06 11:01:13,827 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:01:13,828 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:01:13.829 [ZeusMonitor] Monitor started.
2022-12-06 16:01:13.829 [ZeusMonitor] Running indefinitely. 2022-12-06 16:01:13.829 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:01:13.829 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e63+gpu0.power.log
2022-12-06 11:01:57,234 [ZeusDataLoader(train)] train epoch 63 done: time=43.58 energy=6196.10
2022-12-06 11:01:57,237 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.2149
Training Epoch: 62 [2048/50176]	Loss: 0.2378
Training Epoch: 62 [3072/50176]	Loss: 0.2525
Training Epoch: 62 [4096/50176]	Loss: 0.3001
Training Epoch: 62 [5120/50176]	Loss: 0.2917
Training Epoch: 62 [6144/50176]	Loss: 0.2480
Training Epoch: 62 [7168/50176]	Loss: 0.2744
Training Epoch: 62 [8192/50176]	Loss: 0.2820
Training Epoch: 62 [9216/50176]	Loss: 0.2982
Training Epoch: 62 [10240/50176]	Loss: 0.3025
Training Epoch: 62 [11264/50176]	Loss: 0.2838
Training Epoch: 62 [12288/50176]	Loss: 0.2819
Training Epoch: 62 [13312/50176]	Loss: 0.2422
Training Epoch: 62 [14336/50176]	Loss: 0.3090
Training Epoch: 62 [15360/50176]	Loss: 0.2797
Training Epoch: 62 [16384/50176]	Loss: 0.2985
Training Epoch: 62 [17408/50176]	Loss: 0.2997
Training Epoch: 62 [18432/50176]	Loss: 0.3097
Training Epoch: 62 [19456/50176]	Loss: 0.2854
Training Epoch: 62 [20480/50176]	Loss: 0.3178
Training Epoch: 62 [21504/50176]	Loss: 0.2925
Training Epoch: 62 [22528/50176]	Loss: 0.2980
Training Epoch: 62 [23552/50176]	Loss: 0.2691
Training Epoch: 62 [24576/50176]	Loss: 0.3022
Training Epoch: 62 [25600/50176]	Loss: 0.3088
Training Epoch: 62 [26624/50176]	Loss: 0.2778
Training Epoch: 62 [27648/50176]	Loss: 0.2960
Training Epoch: 62 [28672/50176]	Loss: 0.3052
Training Epoch: 62 [29696/50176]	Loss: 0.2969
Training Epoch: 62 [30720/50176]	Loss: 0.3235
Training Epoch: 62 [31744/50176]	Loss: 0.3709
Training Epoch: 62 [32768/50176]	Loss: 0.3083
Training Epoch: 62 [33792/50176]	Loss: 0.3066
Training Epoch: 62 [34816/50176]	Loss: 0.3334
Training Epoch: 62 [35840/50176]	Loss: 0.2987
Training Epoch: 62 [36864/50176]	Loss: 0.3306
Training Epoch: 62 [37888/50176]	Loss: 0.2850
Training Epoch: 62 [38912/50176]	Loss: 0.3388
Training Epoch: 62 [39936/50176]	Loss: 0.2718
Training Epoch: 62 [40960/50176]	Loss: 0.3132
Training Epoch: 62 [41984/50176]	Loss: 0.3316
Training Epoch: 62 [43008/50176]	Loss: 0.3028
Training Epoch: 62 [44032/50176]	Loss: 0.2792
Training Epoch: 62 [45056/50176]	Loss: 0.3402
Training Epoch: 62 [46080/50176]	Loss: 0.2749
Training Epoch: 62 [47104/50176]	Loss: 0.3533
Training Epoch: 62 [48128/50176]	Loss: 0.2736
Training Epoch: 62 [49152/50176]	Loss: 0.3720
Training Epoch: 62 [50176/50176]	Loss: 0.3700
2022-12-06 16:02:00.899 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:02:00,918 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.67 energy=470.16
2022-12-06 11:02:00,918 [ZeusDataLoader(train)] Up to epoch 63: time=3026.15, energy=421395.70, cost=475486.28
2022-12-06 11:02:00,918 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:02:00,918 [ZeusDataLoader(train)] Expected next epoch: time=3072.60, energy=428004.33, cost=482854.53
2022-12-06 11:02:00,919 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0023, Accuracy: 0.5488
2022-12-06 11:02:01,092 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:02:01,093 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:02:01.095 [ZeusMonitor] Monitor started.
2022-12-06 16:02:01.095 [ZeusMonitor] Running indefinitely. 2022-12-06 16:02:01.095 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:02:01.095 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e64+gpu0.power.log
2022-12-06 11:02:44,531 [ZeusDataLoader(train)] train epoch 64 done: time=43.60 energy=6202.58
2022-12-06 11:02:44,534 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 0.2668
Training Epoch: 63 [2048/50176]	Loss: 0.2765
Training Epoch: 63 [3072/50176]	Loss: 0.2762
Training Epoch: 63 [4096/50176]	Loss: 0.2706
Training Epoch: 63 [5120/50176]	Loss: 0.2538
Training Epoch: 63 [6144/50176]	Loss: 0.2634
Training Epoch: 63 [7168/50176]	Loss: 0.2717
Training Epoch: 63 [8192/50176]	Loss: 0.2640
Training Epoch: 63 [9216/50176]	Loss: 0.2576
Training Epoch: 63 [10240/50176]	Loss: 0.2715
Training Epoch: 63 [11264/50176]	Loss: 0.2992
Training Epoch: 63 [12288/50176]	Loss: 0.2671
Training Epoch: 63 [13312/50176]	Loss: 0.2491
Training Epoch: 63 [14336/50176]	Loss: 0.3023
Training Epoch: 63 [15360/50176]	Loss: 0.2910
Training Epoch: 63 [16384/50176]	Loss: 0.3058
Training Epoch: 63 [17408/50176]	Loss: 0.2602
Training Epoch: 63 [18432/50176]	Loss: 0.3064
Training Epoch: 63 [19456/50176]	Loss: 0.2866
Training Epoch: 63 [20480/50176]	Loss: 0.3040
Training Epoch: 63 [21504/50176]	Loss: 0.2945
Training Epoch: 63 [22528/50176]	Loss: 0.2697
Training Epoch: 63 [23552/50176]	Loss: 0.2900
Training Epoch: 63 [24576/50176]	Loss: 0.2608
Training Epoch: 63 [25600/50176]	Loss: 0.2788
Training Epoch: 63 [26624/50176]	Loss: 0.2811
Training Epoch: 63 [27648/50176]	Loss: 0.2794
Training Epoch: 63 [28672/50176]	Loss: 0.3115
Training Epoch: 63 [29696/50176]	Loss: 0.3037
Training Epoch: 63 [30720/50176]	Loss: 0.3247
Training Epoch: 63 [31744/50176]	Loss: 0.2770
Training Epoch: 63 [32768/50176]	Loss: 0.3210
Training Epoch: 63 [33792/50176]	Loss: 0.2935
Training Epoch: 63 [34816/50176]	Loss: 0.2715
Training Epoch: 63 [35840/50176]	Loss: 0.3109
Training Epoch: 63 [36864/50176]	Loss: 0.3092
Training Epoch: 63 [37888/50176]	Loss: 0.2888
Training Epoch: 63 [38912/50176]	Loss: 0.3235
Training Epoch: 63 [39936/50176]	Loss: 0.3053
Training Epoch: 63 [40960/50176]	Loss: 0.3055
Training Epoch: 63 [41984/50176]	Loss: 0.3418
Training Epoch: 63 [43008/50176]	Loss: 0.3463
Training Epoch: 63 [44032/50176]	Loss: 0.3076
Training Epoch: 63 [45056/50176]	Loss: 0.2844
Training Epoch: 63 [46080/50176]	Loss: 0.2969
Training Epoch: 63 [47104/50176]	Loss: 0.3458
Training Epoch: 63 [48128/50176]	Loss: 0.3082
Training Epoch: 63 [49152/50176]	Loss: 0.3449
Training Epoch: 63 [50176/50176]	Loss: 0.3427
2022-12-06 16:02:48.167 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:02:48,188 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.65 energy=460.83
2022-12-06 11:02:48,188 [ZeusDataLoader(train)] Up to epoch 64: time=3073.40, energy=428059.11, cost=482952.29
2022-12-06 11:02:48,188 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:02:48,188 [ZeusDataLoader(train)] Expected next epoch: time=3119.85, energy=434667.74, cost=490320.54
2022-12-06 11:02:48,189 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0024, Accuracy: 0.5429
2022-12-06 11:02:48,358 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:02:48,359 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:02:48.361 [ZeusMonitor] Monitor started.
2022-12-06 16:02:48.361 [ZeusMonitor] Running indefinitely. 2022-12-06 16:02:48.361 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:02:48.361 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e65+gpu0.power.log
2022-12-06 11:03:31,730 [ZeusDataLoader(train)] train epoch 65 done: time=43.53 energy=6202.20
2022-12-06 11:03:31,733 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 0.2488
Training Epoch: 64 [2048/50176]	Loss: 0.2363
Training Epoch: 64 [3072/50176]	Loss: 0.2492
Training Epoch: 64 [4096/50176]	Loss: 0.2422
Training Epoch: 64 [5120/50176]	Loss: 0.2893
Training Epoch: 64 [6144/50176]	Loss: 0.2449
Training Epoch: 64 [7168/50176]	Loss: 0.2557
Training Epoch: 64 [8192/50176]	Loss: 0.2808
Training Epoch: 64 [9216/50176]	Loss: 0.2651
Training Epoch: 64 [10240/50176]	Loss: 0.2997
Training Epoch: 64 [11264/50176]	Loss: 0.2538
Training Epoch: 64 [12288/50176]	Loss: 0.2471
Training Epoch: 64 [13312/50176]	Loss: 0.2959
Training Epoch: 64 [14336/50176]	Loss: 0.3034
Training Epoch: 64 [15360/50176]	Loss: 0.2669
Training Epoch: 64 [16384/50176]	Loss: 0.2557
Training Epoch: 64 [17408/50176]	Loss: 0.2781
Training Epoch: 64 [18432/50176]	Loss: 0.2715
Training Epoch: 64 [19456/50176]	Loss: 0.2627
Training Epoch: 64 [20480/50176]	Loss: 0.2715
Training Epoch: 64 [21504/50176]	Loss: 0.2600
Training Epoch: 64 [22528/50176]	Loss: 0.2882
Training Epoch: 64 [23552/50176]	Loss: 0.3057
Training Epoch: 64 [24576/50176]	Loss: 0.2628
Training Epoch: 64 [25600/50176]	Loss: 0.2857
Training Epoch: 64 [26624/50176]	Loss: 0.2469
Training Epoch: 64 [27648/50176]	Loss: 0.2541
Training Epoch: 64 [28672/50176]	Loss: 0.2458
Training Epoch: 64 [29696/50176]	Loss: 0.2761
Training Epoch: 64 [30720/50176]	Loss: 0.2822
Training Epoch: 64 [31744/50176]	Loss: 0.3065
Training Epoch: 64 [32768/50176]	Loss: 0.2927
Training Epoch: 64 [33792/50176]	Loss: 0.3392
Training Epoch: 64 [34816/50176]	Loss: 0.2738
Training Epoch: 64 [35840/50176]	Loss: 0.2900
Training Epoch: 64 [36864/50176]	Loss: 0.2581
Training Epoch: 64 [37888/50176]	Loss: 0.3124
Training Epoch: 64 [38912/50176]	Loss: 0.2903
Training Epoch: 64 [39936/50176]	Loss: 0.3089
Training Epoch: 64 [40960/50176]	Loss: 0.3132
Training Epoch: 64 [41984/50176]	Loss: 0.3150
Training Epoch: 64 [43008/50176]	Loss: 0.3094
Training Epoch: 64 [44032/50176]	Loss: 0.3117
Training Epoch: 64 [45056/50176]	Loss: 0.3197
Training Epoch: 64 [46080/50176]	Loss: 0.3243
Training Epoch: 64 [47104/50176]	Loss: 0.2788
Training Epoch: 64 [48128/50176]	Loss: 0.2867
Training Epoch: 64 [49152/50176]	Loss: 0.2607
Training Epoch: 64 [50176/50176]	Loss: 0.2873
2022-12-06 16:03:35.397 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:03:35,431 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.69 energy=459.82
2022-12-06 11:03:35,431 [ZeusDataLoader(train)] Up to epoch 65: time=3120.63, energy=434721.12, cost=490415.34
2022-12-06 11:03:35,431 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:03:35,431 [ZeusDataLoader(train)] Expected next epoch: time=3167.07, energy=441329.75, cost=497783.58
2022-12-06 11:03:35,432 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0024, Accuracy: 0.5427
2022-12-06 11:03:35,610 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:03:35,611 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:03:35.613 [ZeusMonitor] Monitor started.
2022-12-06 16:03:35.613 [ZeusMonitor] Running indefinitely. 2022-12-06 16:03:35.613 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:03:35.613 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e66+gpu0.power.log
2022-12-06 11:04:19,008 [ZeusDataLoader(train)] train epoch 66 done: time=43.57 energy=6193.01
2022-12-06 11:04:19,012 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.2354
Training Epoch: 65 [2048/50176]	Loss: 0.2142
Training Epoch: 65 [3072/50176]	Loss: 0.2358
Training Epoch: 65 [4096/50176]	Loss: 0.2161
Training Epoch: 65 [5120/50176]	Loss: 0.2570
Training Epoch: 65 [6144/50176]	Loss: 0.2410
Training Epoch: 65 [7168/50176]	Loss: 0.2656
Training Epoch: 65 [8192/50176]	Loss: 0.2409
Training Epoch: 65 [9216/50176]	Loss: 0.2517
Training Epoch: 65 [10240/50176]	Loss: 0.2674
Training Epoch: 65 [11264/50176]	Loss: 0.2477
Training Epoch: 65 [12288/50176]	Loss: 0.2504
Training Epoch: 65 [13312/50176]	Loss: 0.2343
Training Epoch: 65 [14336/50176]	Loss: 0.2562
Training Epoch: 65 [15360/50176]	Loss: 0.2606
Training Epoch: 65 [16384/50176]	Loss: 0.2667
Training Epoch: 65 [17408/50176]	Loss: 0.1931
Training Epoch: 65 [18432/50176]	Loss: 0.2667
Training Epoch: 65 [19456/50176]	Loss: 0.2422
Training Epoch: 65 [20480/50176]	Loss: 0.2493
Training Epoch: 65 [21504/50176]	Loss: 0.2614
Training Epoch: 65 [22528/50176]	Loss: 0.3086
Training Epoch: 65 [23552/50176]	Loss: 0.2772
Training Epoch: 65 [24576/50176]	Loss: 0.2616
Training Epoch: 65 [25600/50176]	Loss: 0.2611
Training Epoch: 65 [26624/50176]	Loss: 0.2618
Training Epoch: 65 [27648/50176]	Loss: 0.2935
Training Epoch: 65 [28672/50176]	Loss: 0.2435
Training Epoch: 65 [29696/50176]	Loss: 0.2907
Training Epoch: 65 [30720/50176]	Loss: 0.2951
Training Epoch: 65 [31744/50176]	Loss: 0.2720
Training Epoch: 65 [32768/50176]	Loss: 0.2709
Training Epoch: 65 [33792/50176]	Loss: 0.2676
Training Epoch: 65 [34816/50176]	Loss: 0.2983
Training Epoch: 65 [35840/50176]	Loss: 0.2970
Training Epoch: 65 [36864/50176]	Loss: 0.3089
Training Epoch: 65 [37888/50176]	Loss: 0.2990
Training Epoch: 65 [38912/50176]	Loss: 0.3010
Training Epoch: 65 [39936/50176]	Loss: 0.2807
Training Epoch: 65 [40960/50176]	Loss: 0.3131
Training Epoch: 65 [41984/50176]	Loss: 0.2806
Training Epoch: 65 [43008/50176]	Loss: 0.3038
Training Epoch: 65 [44032/50176]	Loss: 0.3003
Training Epoch: 65 [45056/50176]	Loss: 0.2779
Training Epoch: 65 [46080/50176]	Loss: 0.3170
Training Epoch: 65 [47104/50176]	Loss: 0.2687
Training Epoch: 65 [48128/50176]	Loss: 0.2970
Training Epoch: 65 [49152/50176]	Loss: 0.3060
Training Epoch: 65 [50176/50176]	Loss: 0.2746
2022-12-06 16:04:22.693 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:04:22,716 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.70 energy=472.71
2022-12-06 11:04:22,717 [ZeusDataLoader(train)] Up to epoch 66: time=3167.89, energy=441386.84, cost=497883.79
2022-12-06 11:04:22,717 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:04:22,717 [ZeusDataLoader(train)] Expected next epoch: time=3214.33, energy=447995.47, cost=505252.03
2022-12-06 11:04:22,718 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0025, Accuracy: 0.5422
2022-12-06 11:04:22,898 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:04:22,899 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:04:22.901 [ZeusMonitor] Monitor started.
2022-12-06 16:04:22.901 [ZeusMonitor] Running indefinitely. 2022-12-06 16:04:22.901 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:04:22.901 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e67+gpu0.power.log
2022-12-06 11:05:06,320 [ZeusDataLoader(train)] train epoch 67 done: time=43.59 energy=6204.45
2022-12-06 11:05:06,323 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.2390
Training Epoch: 66 [2048/50176]	Loss: 0.2440
Training Epoch: 66 [3072/50176]	Loss: 0.2285
Training Epoch: 66 [4096/50176]	Loss: 0.2701
Training Epoch: 66 [5120/50176]	Loss: 0.2361
Training Epoch: 66 [6144/50176]	Loss: 0.2585
Training Epoch: 66 [7168/50176]	Loss: 0.2485
Training Epoch: 66 [8192/50176]	Loss: 0.2754
Training Epoch: 66 [9216/50176]	Loss: 0.1986
Training Epoch: 66 [10240/50176]	Loss: 0.2395
Training Epoch: 66 [11264/50176]	Loss: 0.2422
Training Epoch: 66 [12288/50176]	Loss: 0.2440
Training Epoch: 66 [13312/50176]	Loss: 0.2274
Training Epoch: 66 [14336/50176]	Loss: 0.2503
Training Epoch: 66 [15360/50176]	Loss: 0.2380
Training Epoch: 66 [16384/50176]	Loss: 0.2779
Training Epoch: 66 [17408/50176]	Loss: 0.2591
Training Epoch: 66 [18432/50176]	Loss: 0.2349
Training Epoch: 66 [19456/50176]	Loss: 0.2164
Training Epoch: 66 [20480/50176]	Loss: 0.2769
Training Epoch: 66 [21504/50176]	Loss: 0.2583
Training Epoch: 66 [22528/50176]	Loss: 0.2586
Training Epoch: 66 [23552/50176]	Loss: 0.2613
Training Epoch: 66 [24576/50176]	Loss: 0.2919
Training Epoch: 66 [25600/50176]	Loss: 0.2525
Training Epoch: 66 [26624/50176]	Loss: 0.2669
Training Epoch: 66 [27648/50176]	Loss: 0.2582
Training Epoch: 66 [28672/50176]	Loss: 0.3449
Training Epoch: 66 [29696/50176]	Loss: 0.2776
Training Epoch: 66 [30720/50176]	Loss: 0.2733
Training Epoch: 66 [31744/50176]	Loss: 0.2761
Training Epoch: 66 [32768/50176]	Loss: 0.2582
Training Epoch: 66 [33792/50176]	Loss: 0.2591
Training Epoch: 66 [34816/50176]	Loss: 0.2631
Training Epoch: 66 [35840/50176]	Loss: 0.2606
Training Epoch: 66 [36864/50176]	Loss: 0.2564
Training Epoch: 66 [37888/50176]	Loss: 0.2644
Training Epoch: 66 [38912/50176]	Loss: 0.2979
Training Epoch: 66 [39936/50176]	Loss: 0.2909
Training Epoch: 66 [40960/50176]	Loss: 0.2825
Training Epoch: 66 [41984/50176]	Loss: 0.2651
Training Epoch: 66 [43008/50176]	Loss: 0.2766
Training Epoch: 66 [44032/50176]	Loss: 0.3014
Training Epoch: 66 [45056/50176]	Loss: 0.2718
Training Epoch: 66 [46080/50176]	Loss: 0.2987
Training Epoch: 66 [47104/50176]	Loss: 0.2578
Training Epoch: 66 [48128/50176]	Loss: 0.2564
Training Epoch: 66 [49152/50176]	Loss: 0.2921
Training Epoch: 66 [50176/50176]	Loss: 0.2921
2022-12-06 16:05:09.996 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:05:10,015 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.68 energy=462.18
2022-12-06 11:05:10,015 [ZeusDataLoader(train)] Up to epoch 67: time=3215.17, energy=448053.47, cost=505353.95
2022-12-06 11:05:10,015 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:05:10,015 [ZeusDataLoader(train)] Expected next epoch: time=3261.61, energy=454662.10, cost=512722.20
2022-12-06 11:05:10,016 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0024, Accuracy: 0.5490
2022-12-06 11:05:10,195 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:05:10,196 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:05:10.197 [ZeusMonitor] Monitor started.
2022-12-06 16:05:10.198 [ZeusMonitor] Running indefinitely. 2022-12-06 16:05:10.198 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:05:10.198 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e68+gpu0.power.log
2022-12-06 11:05:53,603 [ZeusDataLoader(train)] train epoch 68 done: time=43.58 energy=6205.48
2022-12-06 11:05:53,606 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.2029
Training Epoch: 67 [2048/50176]	Loss: 0.2416
Training Epoch: 67 [3072/50176]	Loss: 0.2559
Training Epoch: 67 [4096/50176]	Loss: 0.2528
Training Epoch: 67 [5120/50176]	Loss: 0.2339
Training Epoch: 67 [6144/50176]	Loss: 0.2507
Training Epoch: 67 [7168/50176]	Loss: 0.2452
Training Epoch: 67 [8192/50176]	Loss: 0.1847
Training Epoch: 67 [9216/50176]	Loss: 0.2730
Training Epoch: 67 [10240/50176]	Loss: 0.2768
Training Epoch: 67 [11264/50176]	Loss: 0.2482
Training Epoch: 67 [12288/50176]	Loss: 0.2410
Training Epoch: 67 [13312/50176]	Loss: 0.2333
Training Epoch: 67 [14336/50176]	Loss: 0.2406
Training Epoch: 67 [15360/50176]	Loss: 0.2387
Training Epoch: 67 [16384/50176]	Loss: 0.2420
Training Epoch: 67 [17408/50176]	Loss: 0.2309
Training Epoch: 67 [18432/50176]	Loss: 0.2755
Training Epoch: 67 [19456/50176]	Loss: 0.2604
Training Epoch: 67 [20480/50176]	Loss: 0.2556
Training Epoch: 67 [21504/50176]	Loss: 0.2089
Training Epoch: 67 [22528/50176]	Loss: 0.2381
Training Epoch: 67 [23552/50176]	Loss: 0.2635
Training Epoch: 67 [24576/50176]	Loss: 0.2459
Training Epoch: 67 [25600/50176]	Loss: 0.2570
Training Epoch: 67 [26624/50176]	Loss: 0.2490
Training Epoch: 67 [27648/50176]	Loss: 0.2480
Training Epoch: 67 [28672/50176]	Loss: 0.2531
Training Epoch: 67 [29696/50176]	Loss: 0.2743
Training Epoch: 67 [30720/50176]	Loss: 0.2533
Training Epoch: 67 [31744/50176]	Loss: 0.2831
Training Epoch: 67 [32768/50176]	Loss: 0.2372
Training Epoch: 67 [33792/50176]	Loss: 0.2751
Training Epoch: 67 [34816/50176]	Loss: 0.2444
Training Epoch: 67 [35840/50176]	Loss: 0.2587
Training Epoch: 67 [36864/50176]	Loss: 0.2539
Training Epoch: 67 [37888/50176]	Loss: 0.2583
Training Epoch: 67 [38912/50176]	Loss: 0.3044
Training Epoch: 67 [39936/50176]	Loss: 0.3008
Training Epoch: 67 [40960/50176]	Loss: 0.2752
Training Epoch: 67 [41984/50176]	Loss: 0.2743
Training Epoch: 67 [43008/50176]	Loss: 0.2523
Training Epoch: 67 [44032/50176]	Loss: 0.2810
Training Epoch: 67 [45056/50176]	Loss: 0.3000
Training Epoch: 67 [46080/50176]	Loss: 0.2578
Training Epoch: 67 [47104/50176]	Loss: 0.2811
Training Epoch: 67 [48128/50176]	Loss: 0.2525
Training Epoch: 67 [49152/50176]	Loss: 0.2205
Training Epoch: 67 [50176/50176]	Loss: 0.2972
2022-12-06 16:05:57.280 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:05:57,316 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.70 energy=472.54
2022-12-06 11:05:57,316 [ZeusDataLoader(train)] Up to epoch 68: time=3262.45, energy=454731.49, cost=512830.04
2022-12-06 11:05:57,317 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:05:57,317 [ZeusDataLoader(train)] Expected next epoch: time=3308.89, energy=461340.11, cost=520198.29
2022-12-06 11:05:57,318 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0025, Accuracy: 0.5474
2022-12-06 11:05:57,499 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:05:57,500 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:05:57.502 [ZeusMonitor] Monitor started.
2022-12-06 16:05:57.502 [ZeusMonitor] Running indefinitely. 2022-12-06 16:05:57.502 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:05:57.502 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e69+gpu0.power.log
2022-12-06 11:06:40,915 [ZeusDataLoader(train)] train epoch 69 done: time=43.59 energy=6201.72
2022-12-06 11:06:40,919 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.1841
Training Epoch: 68 [2048/50176]	Loss: 0.2149
Training Epoch: 68 [3072/50176]	Loss: 0.1868
Training Epoch: 68 [4096/50176]	Loss: 0.2019
Training Epoch: 68 [5120/50176]	Loss: 0.2310
Training Epoch: 68 [6144/50176]	Loss: 0.2173
Training Epoch: 68 [7168/50176]	Loss: 0.2104
Training Epoch: 68 [8192/50176]	Loss: 0.2437
Training Epoch: 68 [9216/50176]	Loss: 0.2632
Training Epoch: 68 [10240/50176]	Loss: 0.2298
Training Epoch: 68 [11264/50176]	Loss: 0.2172
Training Epoch: 68 [12288/50176]	Loss: 0.2467
Training Epoch: 68 [13312/50176]	Loss: 0.2214
Training Epoch: 68 [14336/50176]	Loss: 0.2111
Training Epoch: 68 [15360/50176]	Loss: 0.2471
Training Epoch: 68 [16384/50176]	Loss: 0.2150
Training Epoch: 68 [17408/50176]	Loss: 0.2459
Training Epoch: 68 [18432/50176]	Loss: 0.2167
Training Epoch: 68 [19456/50176]	Loss: 0.2192
Training Epoch: 68 [20480/50176]	Loss: 0.2569
Training Epoch: 68 [21504/50176]	Loss: 0.2612
Training Epoch: 68 [22528/50176]	Loss: 0.2365
Training Epoch: 68 [23552/50176]	Loss: 0.2633
Training Epoch: 68 [24576/50176]	Loss: 0.2255
Training Epoch: 68 [25600/50176]	Loss: 0.2418
Training Epoch: 68 [26624/50176]	Loss: 0.2539
Training Epoch: 68 [27648/50176]	Loss: 0.2460
Training Epoch: 68 [28672/50176]	Loss: 0.2604
Training Epoch: 68 [29696/50176]	Loss: 0.2513
Training Epoch: 68 [30720/50176]	Loss: 0.2519
Training Epoch: 68 [31744/50176]	Loss: 0.2587
Training Epoch: 68 [32768/50176]	Loss: 0.2319
Training Epoch: 68 [33792/50176]	Loss: 0.2514
Training Epoch: 68 [34816/50176]	Loss: 0.2391
Training Epoch: 68 [35840/50176]	Loss: 0.2758
Training Epoch: 68 [36864/50176]	Loss: 0.2612
Training Epoch: 68 [37888/50176]	Loss: 0.2914
Training Epoch: 68 [38912/50176]	Loss: 0.2459
Training Epoch: 68 [39936/50176]	Loss: 0.2646
Training Epoch: 68 [40960/50176]	Loss: 0.2688
Training Epoch: 68 [41984/50176]	Loss: 0.2679
Training Epoch: 68 [43008/50176]	Loss: 0.2362
Training Epoch: 68 [44032/50176]	Loss: 0.2663
Training Epoch: 68 [45056/50176]	Loss: 0.2724
Training Epoch: 68 [46080/50176]	Loss: 0.2400
Training Epoch: 68 [47104/50176]	Loss: 0.2979
Training Epoch: 68 [48128/50176]	Loss: 0.2738
Training Epoch: 68 [49152/50176]	Loss: 0.2750
Training Epoch: 68 [50176/50176]	Loss: 0.2402
2022-12-06 16:06:44.580 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:06:44,617 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.69 energy=472.43
2022-12-06 11:06:44,617 [ZeusDataLoader(train)] Up to epoch 69: time=3309.73, energy=461405.64, cost=520304.13
2022-12-06 11:06:44,617 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:06:44,617 [ZeusDataLoader(train)] Expected next epoch: time=3356.17, energy=468014.27, cost=527672.37
2022-12-06 11:06:44,618 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0024, Accuracy: 0.5435
2022-12-06 11:06:44,799 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:06:44,800 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:06:44.802 [ZeusMonitor] Monitor started.
2022-12-06 16:06:44.802 [ZeusMonitor] Running indefinitely. 2022-12-06 16:06:44.802 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:06:44.802 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e70+gpu0.power.log
2022-12-06 11:07:28,248 [ZeusDataLoader(train)] train epoch 70 done: time=43.62 energy=6209.42
2022-12-06 11:07:28,252 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.2038
Training Epoch: 69 [2048/50176]	Loss: 0.2072
Training Epoch: 69 [3072/50176]	Loss: 0.2294
Training Epoch: 69 [4096/50176]	Loss: 0.1993
Training Epoch: 69 [5120/50176]	Loss: 0.2037
Training Epoch: 69 [6144/50176]	Loss: 0.2190
Training Epoch: 69 [7168/50176]	Loss: 0.1979
Training Epoch: 69 [8192/50176]	Loss: 0.2126
Training Epoch: 69 [9216/50176]	Loss: 0.2489
Training Epoch: 69 [10240/50176]	Loss: 0.2288
Training Epoch: 69 [11264/50176]	Loss: 0.2070
Training Epoch: 69 [12288/50176]	Loss: 0.2096
Training Epoch: 69 [13312/50176]	Loss: 0.2207
Training Epoch: 69 [14336/50176]	Loss: 0.2290
Training Epoch: 69 [15360/50176]	Loss: 0.2401
Training Epoch: 69 [16384/50176]	Loss: 0.1958
Training Epoch: 69 [17408/50176]	Loss: 0.2445
Training Epoch: 69 [18432/50176]	Loss: 0.2168
Training Epoch: 69 [19456/50176]	Loss: 0.2237
Training Epoch: 69 [20480/50176]	Loss: 0.2289
Training Epoch: 69 [21504/50176]	Loss: 0.2092
Training Epoch: 69 [22528/50176]	Loss: 0.2586
Training Epoch: 69 [23552/50176]	Loss: 0.2456
Training Epoch: 69 [24576/50176]	Loss: 0.2190
Training Epoch: 69 [25600/50176]	Loss: 0.2643
Training Epoch: 69 [26624/50176]	Loss: 0.2323
Training Epoch: 69 [27648/50176]	Loss: 0.2310
Training Epoch: 69 [28672/50176]	Loss: 0.2039
Training Epoch: 69 [29696/50176]	Loss: 0.2500
Training Epoch: 69 [30720/50176]	Loss: 0.2323
Training Epoch: 69 [31744/50176]	Loss: 0.2521
Training Epoch: 69 [32768/50176]	Loss: 0.2029
Training Epoch: 69 [33792/50176]	Loss: 0.2724
Training Epoch: 69 [34816/50176]	Loss: 0.2623
Training Epoch: 69 [35840/50176]	Loss: 0.2253
Training Epoch: 69 [36864/50176]	Loss: 0.2383
Training Epoch: 69 [37888/50176]	Loss: 0.2418
Training Epoch: 69 [38912/50176]	Loss: 0.2654
Training Epoch: 69 [39936/50176]	Loss: 0.2436
Training Epoch: 69 [40960/50176]	Loss: 0.2231
Training Epoch: 69 [41984/50176]	Loss: 0.2755
Training Epoch: 69 [43008/50176]	Loss: 0.3026
Training Epoch: 69 [44032/50176]	Loss: 0.2542
Training Epoch: 69 [45056/50176]	Loss: 0.2682
Training Epoch: 69 [46080/50176]	Loss: 0.2871
Training Epoch: 69 [47104/50176]	Loss: 0.2586
Training Epoch: 69 [48128/50176]	Loss: 0.2679
Training Epoch: 69 [49152/50176]	Loss: 0.2386
Training Epoch: 69 [50176/50176]	Loss: 0.2999
2022-12-06 16:07:31.928 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:07:31,954 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.69 energy=463.34
2022-12-06 11:07:31,954 [ZeusDataLoader(train)] Up to epoch 70: time=3357.05, energy=468078.40, cost=527780.76
2022-12-06 11:07:31,954 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:07:31,954 [ZeusDataLoader(train)] Expected next epoch: time=3403.49, energy=474687.03, cost=535149.00
2022-12-06 11:07:31,955 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0025, Accuracy: 0.5474
2022-12-06 11:07:32,135 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:07:32,136 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:07:32.138 [ZeusMonitor] Monitor started.
2022-12-06 16:07:32.138 [ZeusMonitor] Running indefinitely. 2022-12-06 16:07:32.138 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:07:32.138 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e71+gpu0.power.log
2022-12-06 11:08:15,594 [ZeusDataLoader(train)] train epoch 71 done: time=43.63 energy=6207.10
2022-12-06 11:08:15,598 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.1765
Training Epoch: 70 [2048/50176]	Loss: 0.1944
Training Epoch: 70 [3072/50176]	Loss: 0.2109
Training Epoch: 70 [4096/50176]	Loss: 0.2107
Training Epoch: 70 [5120/50176]	Loss: 0.2231
Training Epoch: 70 [6144/50176]	Loss: 0.2359
Training Epoch: 70 [7168/50176]	Loss: 0.2578
Training Epoch: 70 [8192/50176]	Loss: 0.2207
Training Epoch: 70 [9216/50176]	Loss: 0.2274
Training Epoch: 70 [10240/50176]	Loss: 0.2395
Training Epoch: 70 [11264/50176]	Loss: 0.2020
Training Epoch: 70 [12288/50176]	Loss: 0.2096
Training Epoch: 70 [13312/50176]	Loss: 0.2281
Training Epoch: 70 [14336/50176]	Loss: 0.2469
Training Epoch: 70 [15360/50176]	Loss: 0.2272
Training Epoch: 70 [16384/50176]	Loss: 0.2306
Training Epoch: 70 [17408/50176]	Loss: 0.2409
Training Epoch: 70 [18432/50176]	Loss: 0.2186
Training Epoch: 70 [19456/50176]	Loss: 0.2235
Training Epoch: 70 [20480/50176]	Loss: 0.2248
Training Epoch: 70 [21504/50176]	Loss: 0.2448
Training Epoch: 70 [22528/50176]	Loss: 0.2477
Training Epoch: 70 [23552/50176]	Loss: 0.2357
Training Epoch: 70 [24576/50176]	Loss: 0.2132
Training Epoch: 70 [25600/50176]	Loss: 0.2220
Training Epoch: 70 [26624/50176]	Loss: 0.2161
Training Epoch: 70 [27648/50176]	Loss: 0.2422
Training Epoch: 70 [28672/50176]	Loss: 0.2311
Training Epoch: 70 [29696/50176]	Loss: 0.2048
Training Epoch: 70 [30720/50176]	Loss: 0.2545
Training Epoch: 70 [31744/50176]	Loss: 0.2182
Training Epoch: 70 [32768/50176]	Loss: 0.2414
Training Epoch: 70 [33792/50176]	Loss: 0.2567
Training Epoch: 70 [34816/50176]	Loss: 0.2176
Training Epoch: 70 [35840/50176]	Loss: 0.2670
Training Epoch: 70 [36864/50176]	Loss: 0.2622
Training Epoch: 70 [37888/50176]	Loss: 0.2381
Training Epoch: 70 [38912/50176]	Loss: 0.2459
Training Epoch: 70 [39936/50176]	Loss: 0.2478
Training Epoch: 70 [40960/50176]	Loss: 0.2783
Training Epoch: 70 [41984/50176]	Loss: 0.2620
Training Epoch: 70 [43008/50176]	Loss: 0.2549
Training Epoch: 70 [44032/50176]	Loss: 0.2604
Training Epoch: 70 [45056/50176]	Loss: 0.2637
Training Epoch: 70 [46080/50176]	Loss: 0.2515
Training Epoch: 70 [47104/50176]	Loss: 0.2302
Training Epoch: 70 [48128/50176]	Loss: 0.2439
Training Epoch: 70 [49152/50176]	Loss: 0.2705
Training Epoch: 70 [50176/50176]	Loss: 0.2638
2022-12-06 16:08:19.256 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:08:19,293 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.69 energy=474.93
2022-12-06 11:08:19,294 [ZeusDataLoader(train)] Up to epoch 71: time=3404.36, energy=474760.44, cost=535262.09
2022-12-06 11:08:19,294 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:08:19,294 [ZeusDataLoader(train)] Expected next epoch: time=3450.81, energy=481369.06, cost=542630.34
2022-12-06 11:08:19,295 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0025, Accuracy: 0.5459
2022-12-06 11:08:19,431 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:08:19,432 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:08:19.435 [ZeusMonitor] Monitor started.
2022-12-06 16:08:19.436 [ZeusMonitor] Running indefinitely. 2022-12-06 16:08:19.436 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:08:19.436 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e72+gpu0.power.log
2022-12-06 11:09:03,571 [ZeusDataLoader(train)] train epoch 72 done: time=44.27 energy=6285.32
2022-12-06 11:09:03,574 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.1812
Training Epoch: 71 [2048/50176]	Loss: 0.2199
Training Epoch: 71 [3072/50176]	Loss: 0.2242
Training Epoch: 71 [4096/50176]	Loss: 0.2184
Training Epoch: 71 [5120/50176]	Loss: 0.2087
Training Epoch: 71 [6144/50176]	Loss: 0.2124
Training Epoch: 71 [7168/50176]	Loss: 0.2489
Training Epoch: 71 [8192/50176]	Loss: 0.2181
Training Epoch: 71 [9216/50176]	Loss: 0.1759
Training Epoch: 71 [10240/50176]	Loss: 0.1802
Training Epoch: 71 [11264/50176]	Loss: 0.2044
Training Epoch: 71 [12288/50176]	Loss: 0.2203
Training Epoch: 71 [13312/50176]	Loss: 0.2444
Training Epoch: 71 [14336/50176]	Loss: 0.1957
Training Epoch: 71 [15360/50176]	Loss: 0.2282
Training Epoch: 71 [16384/50176]	Loss: 0.2124
Training Epoch: 71 [17408/50176]	Loss: 0.2051
Training Epoch: 71 [18432/50176]	Loss: 0.2600
Training Epoch: 71 [19456/50176]	Loss: 0.2160
Training Epoch: 71 [20480/50176]	Loss: 0.2197
Training Epoch: 71 [21504/50176]	Loss: 0.2082
Training Epoch: 71 [22528/50176]	Loss: 0.2344
Training Epoch: 71 [23552/50176]	Loss: 0.2525
Training Epoch: 71 [24576/50176]	Loss: 0.2168
Training Epoch: 71 [25600/50176]	Loss: 0.2096
Training Epoch: 71 [26624/50176]	Loss: 0.2116
Training Epoch: 71 [27648/50176]	Loss: 0.2162
Training Epoch: 71 [28672/50176]	Loss: 0.2044
Training Epoch: 71 [29696/50176]	Loss: 0.2441
Training Epoch: 71 [30720/50176]	Loss: 0.2388
Training Epoch: 71 [31744/50176]	Loss: 0.2497
Training Epoch: 71 [32768/50176]	Loss: 0.2475
Training Epoch: 71 [33792/50176]	Loss: 0.2444
Training Epoch: 71 [34816/50176]	Loss: 0.2268
Training Epoch: 71 [35840/50176]	Loss: 0.2185
Training Epoch: 71 [36864/50176]	Loss: 0.2302
Training Epoch: 71 [37888/50176]	Loss: 0.2087
Training Epoch: 71 [38912/50176]	Loss: 0.2427
Training Epoch: 71 [39936/50176]	Loss: 0.2258
Training Epoch: 71 [40960/50176]	Loss: 0.1954
Training Epoch: 71 [41984/50176]	Loss: 0.2586
Training Epoch: 71 [43008/50176]	Loss: 0.2245
Training Epoch: 71 [44032/50176]	Loss: 0.2258
Training Epoch: 71 [45056/50176]	Loss: 0.2290
Training Epoch: 71 [46080/50176]	Loss: 0.2306
Training Epoch: 71 [47104/50176]	Loss: 0.2247
Training Epoch: 71 [48128/50176]	Loss: 0.2184
Training Epoch: 71 [49152/50176]	Loss: 0.2362
Training Epoch: 71 [50176/50176]	Loss: 0.2123
2022-12-06 16:09:07.274 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:09:07,288 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.71 energy=476.85
2022-12-06 11:09:07,289 [ZeusDataLoader(train)] Up to epoch 72: time=3452.34, energy=481522.60, cost=542841.01
2022-12-06 11:09:07,289 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:09:07,289 [ZeusDataLoader(train)] Expected next epoch: time=3498.78, energy=488131.23, cost=550209.26
2022-12-06 11:09:07,290 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0025, Accuracy: 0.5498
2022-12-06 11:09:07,463 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:09:07,463 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:09:07.465 [ZeusMonitor] Monitor started.
2022-12-06 16:09:07.465 [ZeusMonitor] Running indefinitely. 2022-12-06 16:09:07.465 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:09:07.465 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e73+gpu0.power.log
2022-12-06 11:09:51,598 [ZeusDataLoader(train)] train epoch 73 done: time=44.30 energy=6310.95
2022-12-06 11:09:51,601 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.2025
Training Epoch: 72 [2048/50176]	Loss: 0.1982
Training Epoch: 72 [3072/50176]	Loss: 0.1895
Training Epoch: 72 [4096/50176]	Loss: 0.1915
Training Epoch: 72 [5120/50176]	Loss: 0.1650
Training Epoch: 72 [6144/50176]	Loss: 0.2071
Training Epoch: 72 [7168/50176]	Loss: 0.2058
Training Epoch: 72 [8192/50176]	Loss: 0.1728
Training Epoch: 72 [9216/50176]	Loss: 0.2299
Training Epoch: 72 [10240/50176]	Loss: 0.1883
Training Epoch: 72 [11264/50176]	Loss: 0.1892
Training Epoch: 72 [12288/50176]	Loss: 0.1904
Training Epoch: 72 [13312/50176]	Loss: 0.2037
Training Epoch: 72 [14336/50176]	Loss: 0.1832
Training Epoch: 72 [15360/50176]	Loss: 0.1815
Training Epoch: 72 [16384/50176]	Loss: 0.2228
Training Epoch: 72 [17408/50176]	Loss: 0.2091
Training Epoch: 72 [18432/50176]	Loss: 0.2066
Training Epoch: 72 [19456/50176]	Loss: 0.2058
Training Epoch: 72 [20480/50176]	Loss: 0.1955
Training Epoch: 72 [21504/50176]	Loss: 0.2084
Training Epoch: 72 [22528/50176]	Loss: 0.2189
Training Epoch: 72 [23552/50176]	Loss: 0.1973
Training Epoch: 72 [24576/50176]	Loss: 0.2200
Training Epoch: 72 [25600/50176]	Loss: 0.2081
Training Epoch: 72 [26624/50176]	Loss: 0.2041
Training Epoch: 72 [27648/50176]	Loss: 0.2323
Training Epoch: 72 [28672/50176]	Loss: 0.1807
Training Epoch: 72 [29696/50176]	Loss: 0.2151
Training Epoch: 72 [30720/50176]	Loss: 0.2349
Training Epoch: 72 [31744/50176]	Loss: 0.1991
Training Epoch: 72 [32768/50176]	Loss: 0.1653
Training Epoch: 72 [33792/50176]	Loss: 0.2123
Training Epoch: 72 [34816/50176]	Loss: 0.2240
Training Epoch: 72 [35840/50176]	Loss: 0.2334
Training Epoch: 72 [36864/50176]	Loss: 0.2357
Training Epoch: 72 [37888/50176]	Loss: 0.2435
Training Epoch: 72 [38912/50176]	Loss: 0.2365
Training Epoch: 72 [39936/50176]	Loss: 0.2257
Training Epoch: 72 [40960/50176]	Loss: 0.2265
Training Epoch: 72 [41984/50176]	Loss: 0.2361
Training Epoch: 72 [43008/50176]	Loss: 0.2307
Training Epoch: 72 [44032/50176]	Loss: 0.2165
Training Epoch: 72 [45056/50176]	Loss: 0.2292
Training Epoch: 72 [46080/50176]	Loss: 0.2600
Training Epoch: 72 [47104/50176]	Loss: 0.2454
Training Epoch: 72 [48128/50176]	Loss: 0.2249
Training Epoch: 72 [49152/50176]	Loss: 0.2463
Training Epoch: 72 [50176/50176]	Loss: 0.2465
2022-12-06 16:09:55.326 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:09:55,334 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.73 energy=479.31
2022-12-06 11:09:55,335 [ZeusDataLoader(train)] Up to epoch 73: time=3500.36, energy=488312.87, cost=550438.30
2022-12-06 11:09:55,335 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:09:55,335 [ZeusDataLoader(train)] Expected next epoch: time=3546.81, energy=494921.49, cost=557806.54
2022-12-06 11:09:55,336 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0025, Accuracy: 0.5480
2022-12-06 11:09:55,475 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:09:55,476 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:09:55.479 [ZeusMonitor] Monitor started.
2022-12-06 16:09:55.480 [ZeusMonitor] Running indefinitely. 2022-12-06 16:09:55.480 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:09:55.480 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e74+gpu0.power.log
2022-12-06 11:10:39,554 [ZeusDataLoader(train)] train epoch 74 done: time=44.21 energy=6319.81
2022-12-06 11:10:39,557 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.1839
Training Epoch: 73 [2048/50176]	Loss: 0.2372
Training Epoch: 73 [3072/50176]	Loss: 0.1738
Training Epoch: 73 [4096/50176]	Loss: 0.1937
Training Epoch: 73 [5120/50176]	Loss: 0.2013
Training Epoch: 73 [6144/50176]	Loss: 0.2013
Training Epoch: 73 [7168/50176]	Loss: 0.1683
Training Epoch: 73 [8192/50176]	Loss: 0.2028
Training Epoch: 73 [9216/50176]	Loss: 0.1985
Training Epoch: 73 [10240/50176]	Loss: 0.2189
Training Epoch: 73 [11264/50176]	Loss: 0.1749
Training Epoch: 73 [12288/50176]	Loss: 0.2140
Training Epoch: 73 [13312/50176]	Loss: 0.2084
Training Epoch: 73 [14336/50176]	Loss: 0.1792
Training Epoch: 73 [15360/50176]	Loss: 0.2246
Training Epoch: 73 [16384/50176]	Loss: 0.2208
Training Epoch: 73 [17408/50176]	Loss: 0.1791
Training Epoch: 73 [18432/50176]	Loss: 0.1655
Training Epoch: 73 [19456/50176]	Loss: 0.1932
Training Epoch: 73 [20480/50176]	Loss: 0.1998
Training Epoch: 73 [21504/50176]	Loss: 0.1943
Training Epoch: 73 [22528/50176]	Loss: 0.2368
Training Epoch: 73 [23552/50176]	Loss: 0.1813
Training Epoch: 73 [24576/50176]	Loss: 0.2004
Training Epoch: 73 [25600/50176]	Loss: 0.2024
Training Epoch: 73 [26624/50176]	Loss: 0.2057
Training Epoch: 73 [27648/50176]	Loss: 0.2101
Training Epoch: 73 [28672/50176]	Loss: 0.1954
Training Epoch: 73 [29696/50176]	Loss: 0.2438
Training Epoch: 73 [30720/50176]	Loss: 0.2219
Training Epoch: 73 [31744/50176]	Loss: 0.2056
Training Epoch: 73 [32768/50176]	Loss: 0.2305
Training Epoch: 73 [33792/50176]	Loss: 0.1954
Training Epoch: 73 [34816/50176]	Loss: 0.2144
Training Epoch: 73 [35840/50176]	Loss: 0.2216
Training Epoch: 73 [36864/50176]	Loss: 0.2360
Training Epoch: 73 [37888/50176]	Loss: 0.2605
Training Epoch: 73 [38912/50176]	Loss: 0.1805
Training Epoch: 73 [39936/50176]	Loss: 0.1894
Training Epoch: 73 [40960/50176]	Loss: 0.2420
Training Epoch: 73 [41984/50176]	Loss: 0.2135
Training Epoch: 73 [43008/50176]	Loss: 0.2212
Training Epoch: 73 [44032/50176]	Loss: 0.2239
Training Epoch: 73 [45056/50176]	Loss: 0.2598
Training Epoch: 73 [46080/50176]	Loss: 0.2267
Training Epoch: 73 [47104/50176]	Loss: 0.2465
Training Epoch: 73 [48128/50176]	Loss: 0.2250
Training Epoch: 73 [49152/50176]	Loss: 0.2128
Training Epoch: 73 [50176/50176]	Loss: 0.2354
2022-12-06 16:10:43.208 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:10:43,218 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.65 energy=463.25
2022-12-06 11:10:43,218 [ZeusDataLoader(train)] Up to epoch 74: time=3548.23, energy=495095.92, cost=558017.92
2022-12-06 11:10:43,218 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:10:43,218 [ZeusDataLoader(train)] Expected next epoch: time=3594.67, energy=501704.55, cost=565386.16
2022-12-06 11:10:43,219 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0025, Accuracy: 0.5573
2022-12-06 11:10:43,390 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:10:43,391 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:10:43.392 [ZeusMonitor] Monitor started.
2022-12-06 16:10:43.392 [ZeusMonitor] Running indefinitely. 2022-12-06 16:10:43.392 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:10:43.392 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e75+gpu0.power.log
2022-12-06 11:11:27,918 [ZeusDataLoader(train)] train epoch 75 done: time=44.69 energy=6350.92
2022-12-06 11:11:27,921 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.1557
Training Epoch: 74 [2048/50176]	Loss: 0.1894
Training Epoch: 74 [3072/50176]	Loss: 0.1926
Training Epoch: 74 [4096/50176]	Loss: 0.1893
Training Epoch: 74 [5120/50176]	Loss: 0.2005
Training Epoch: 74 [6144/50176]	Loss: 0.1970
Training Epoch: 74 [7168/50176]	Loss: 0.1850
Training Epoch: 74 [8192/50176]	Loss: 0.1762
Training Epoch: 74 [9216/50176]	Loss: 0.2014
Training Epoch: 74 [10240/50176]	Loss: 0.2035
Training Epoch: 74 [11264/50176]	Loss: 0.1917
Training Epoch: 74 [12288/50176]	Loss: 0.1970
Training Epoch: 74 [13312/50176]	Loss: 0.1820
Training Epoch: 74 [14336/50176]	Loss: 0.1873
Training Epoch: 74 [15360/50176]	Loss: 0.1801
Training Epoch: 74 [16384/50176]	Loss: 0.1938
Training Epoch: 74 [17408/50176]	Loss: 0.1814
Training Epoch: 74 [18432/50176]	Loss: 0.1912
Training Epoch: 74 [19456/50176]	Loss: 0.1606
Training Epoch: 74 [20480/50176]	Loss: 0.2177
Training Epoch: 74 [21504/50176]	Loss: 0.1776
Training Epoch: 74 [22528/50176]	Loss: 0.1921
Training Epoch: 74 [23552/50176]	Loss: 0.1840
Training Epoch: 74 [24576/50176]	Loss: 0.2179
Training Epoch: 74 [25600/50176]	Loss: 0.2024
Training Epoch: 74 [26624/50176]	Loss: 0.2015
Training Epoch: 74 [27648/50176]	Loss: 0.1810
Training Epoch: 74 [28672/50176]	Loss: 0.2055
Training Epoch: 74 [29696/50176]	Loss: 0.1976
Training Epoch: 74 [30720/50176]	Loss: 0.1911
Training Epoch: 74 [31744/50176]	Loss: 0.2204
Training Epoch: 74 [32768/50176]	Loss: 0.2588
Training Epoch: 74 [33792/50176]	Loss: 0.2106
Training Epoch: 74 [34816/50176]	Loss: 0.2325
Training Epoch: 74 [35840/50176]	Loss: 0.2150
Training Epoch: 74 [36864/50176]	Loss: 0.2007
Training Epoch: 74 [37888/50176]	Loss: 0.2010
Training Epoch: 74 [38912/50176]	Loss: 0.2379
Training Epoch: 74 [39936/50176]	Loss: 0.1902
Training Epoch: 74 [40960/50176]	Loss: 0.2155
Training Epoch: 74 [41984/50176]	Loss: 0.2330
Training Epoch: 74 [43008/50176]	Loss: 0.2212
Training Epoch: 74 [44032/50176]	Loss: 0.2279
Training Epoch: 74 [45056/50176]	Loss: 0.2575
Training Epoch: 74 [46080/50176]	Loss: 0.2343
Training Epoch: 74 [47104/50176]	Loss: 0.2615
Training Epoch: 74 [48128/50176]	Loss: 0.2194
Training Epoch: 74 [49152/50176]	Loss: 0.2526
Training Epoch: 74 [50176/50176]	Loss: 0.2260
2022-12-06 16:11:31.614 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:11:31,670 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.74 energy=478.63
2022-12-06 11:11:31,670 [ZeusDataLoader(train)] Up to epoch 75: time=3596.66, energy=501925.48, cost=565670.53
2022-12-06 11:11:31,670 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:11:31,670 [ZeusDataLoader(train)] Expected next epoch: time=3643.11, energy=508534.10, cost=573038.78
2022-12-06 11:11:31,671 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 0.0026, Accuracy: 0.5485
2022-12-06 11:11:31,851 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:11:31,852 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:11:31.854 [ZeusMonitor] Monitor started.
2022-12-06 16:11:31.854 [ZeusMonitor] Running indefinitely. 2022-12-06 16:11:31.854 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:11:31.854 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e76+gpu0.power.log
2022-12-06 11:12:16,747 [ZeusDataLoader(train)] train epoch 76 done: time=45.07 energy=6358.84
2022-12-06 11:12:16,750 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 0.1774
Training Epoch: 75 [2048/50176]	Loss: 0.1488
Training Epoch: 75 [3072/50176]	Loss: 0.1741
Training Epoch: 75 [4096/50176]	Loss: 0.1816
Training Epoch: 75 [5120/50176]	Loss: 0.1880
Training Epoch: 75 [6144/50176]	Loss: 0.1971
Training Epoch: 75 [7168/50176]	Loss: 0.1785
Training Epoch: 75 [8192/50176]	Loss: 0.1750
Training Epoch: 75 [9216/50176]	Loss: 0.1951
Training Epoch: 75 [10240/50176]	Loss: 0.2015
Training Epoch: 75 [11264/50176]	Loss: 0.1969
Training Epoch: 75 [12288/50176]	Loss: 0.2245
Training Epoch: 75 [13312/50176]	Loss: 0.2087
Training Epoch: 75 [14336/50176]	Loss: 0.1717
Training Epoch: 75 [15360/50176]	Loss: 0.1967
Training Epoch: 75 [16384/50176]	Loss: 0.1917
Training Epoch: 75 [17408/50176]	Loss: 0.1972
Training Epoch: 75 [18432/50176]	Loss: 0.2208
Training Epoch: 75 [19456/50176]	Loss: 0.1866
Training Epoch: 75 [20480/50176]	Loss: 0.2040
Training Epoch: 75 [21504/50176]	Loss: 0.2094
Training Epoch: 75 [22528/50176]	Loss: 0.2503
Training Epoch: 75 [23552/50176]	Loss: 0.1848
Training Epoch: 75 [24576/50176]	Loss: 0.1954
Training Epoch: 75 [25600/50176]	Loss: 0.2063
Training Epoch: 75 [26624/50176]	Loss: 0.2225
Training Epoch: 75 [27648/50176]	Loss: 0.1777
Training Epoch: 75 [28672/50176]	Loss: 0.1998
Training Epoch: 75 [29696/50176]	Loss: 0.2636
Training Epoch: 75 [30720/50176]	Loss: 0.2136
Training Epoch: 75 [31744/50176]	Loss: 0.2158
Training Epoch: 75 [32768/50176]	Loss: 0.2246
Training Epoch: 75 [33792/50176]	Loss: 0.1977
Training Epoch: 75 [34816/50176]	Loss: 0.2206
Training Epoch: 75 [35840/50176]	Loss: 0.1966
Training Epoch: 75 [36864/50176]	Loss: 0.2780
Training Epoch: 75 [37888/50176]	Loss: 0.2137
Training Epoch: 75 [38912/50176]	Loss: 0.2120
Training Epoch: 75 [39936/50176]	Loss: 0.1975
Training Epoch: 75 [40960/50176]	Loss: 0.1870
Training Epoch: 75 [41984/50176]	Loss: 0.2178
Training Epoch: 75 [43008/50176]	Loss: 0.2117
Training Epoch: 75 [44032/50176]	Loss: 0.2723
Training Epoch: 75 [45056/50176]	Loss: 0.1885
Training Epoch: 75 [46080/50176]	Loss: 0.2419
Training Epoch: 75 [47104/50176]	Loss: 0.2155
Training Epoch: 75 [48128/50176]	Loss: 0.2244
Training Epoch: 75 [49152/50176]	Loss: 0.2298
Training Epoch: 75 [50176/50176]	Loss: 0.2128
2022-12-06 16:12:20.434 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:12:20,463 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.71 energy=477.45
2022-12-06 11:12:20,463 [ZeusDataLoader(train)] Up to epoch 76: time=3645.43, energy=508761.77, cost=573356.24
2022-12-06 11:12:20,463 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:12:20,464 [ZeusDataLoader(train)] Expected next epoch: time=3691.88, energy=515370.40, cost=580724.49
2022-12-06 11:12:20,464 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 0.0025, Accuracy: 0.5515
2022-12-06 11:12:20,600 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:12:20,600 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:12:20.602 [ZeusMonitor] Monitor started.
2022-12-06 16:12:20.602 [ZeusMonitor] Running indefinitely. 2022-12-06 16:12:20.602 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:12:20.602 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e77+gpu0.power.log
2022-12-06 11:13:04,830 [ZeusDataLoader(train)] train epoch 77 done: time=44.36 energy=6327.92
2022-12-06 11:13:04,834 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 0.1694
Training Epoch: 76 [2048/50176]	Loss: 0.1725
Training Epoch: 76 [3072/50176]	Loss: 0.1906
Training Epoch: 76 [4096/50176]	Loss: 0.1639
Training Epoch: 76 [5120/50176]	Loss: 0.1892
Training Epoch: 76 [6144/50176]	Loss: 0.1947
Training Epoch: 76 [7168/50176]	Loss: 0.1753
Training Epoch: 76 [8192/50176]	Loss: 0.1708
Training Epoch: 76 [9216/50176]	Loss: 0.1652
Training Epoch: 76 [10240/50176]	Loss: 0.1997
Training Epoch: 76 [11264/50176]	Loss: 0.2005
Training Epoch: 76 [12288/50176]	Loss: 0.1992
Training Epoch: 76 [13312/50176]	Loss: 0.2285
Training Epoch: 76 [14336/50176]	Loss: 0.2043
Training Epoch: 76 [15360/50176]	Loss: 0.2184
Training Epoch: 76 [16384/50176]	Loss: 0.1880
Training Epoch: 76 [17408/50176]	Loss: 0.1881
Training Epoch: 76 [18432/50176]	Loss: 0.1868
Training Epoch: 76 [19456/50176]	Loss: 0.1721
Training Epoch: 76 [20480/50176]	Loss: 0.2253
Training Epoch: 76 [21504/50176]	Loss: 0.2287
Training Epoch: 76 [22528/50176]	Loss: 0.2098
Training Epoch: 76 [23552/50176]	Loss: 0.2096
Training Epoch: 76 [24576/50176]	Loss: 0.1997
Training Epoch: 76 [25600/50176]	Loss: 0.2239
Training Epoch: 76 [26624/50176]	Loss: 0.1958
Training Epoch: 76 [27648/50176]	Loss: 0.1777
Training Epoch: 76 [28672/50176]	Loss: 0.1964
Training Epoch: 76 [29696/50176]	Loss: 0.2142
Training Epoch: 76 [30720/50176]	Loss: 0.1874
Training Epoch: 76 [31744/50176]	Loss: 0.2243
Training Epoch: 76 [32768/50176]	Loss: 0.2042
Training Epoch: 76 [33792/50176]	Loss: 0.2251
Training Epoch: 76 [34816/50176]	Loss: 0.1809
Training Epoch: 76 [35840/50176]	Loss: 0.2235
Training Epoch: 76 [36864/50176]	Loss: 0.1819
Training Epoch: 76 [37888/50176]	Loss: 0.2224
Training Epoch: 76 [38912/50176]	Loss: 0.2211
Training Epoch: 76 [39936/50176]	Loss: 0.1928
Training Epoch: 76 [40960/50176]	Loss: 0.2317
Training Epoch: 76 [41984/50176]	Loss: 0.2080
Training Epoch: 76 [43008/50176]	Loss: 0.2343
Training Epoch: 76 [44032/50176]	Loss: 0.2577
Training Epoch: 76 [45056/50176]	Loss: 0.2468
Training Epoch: 76 [46080/50176]	Loss: 0.1950
Training Epoch: 76 [47104/50176]	Loss: 0.2067
Training Epoch: 76 [48128/50176]	Loss: 0.2198
Training Epoch: 76 [49152/50176]	Loss: 0.2199
Training Epoch: 76 [50176/50176]	Loss: 0.1960
2022-12-06 16:13:08.570 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:13:08,620 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.78 energy=490.31
2022-12-06 11:13:08,620 [ZeusDataLoader(train)] Up to epoch 77: time=3693.57, energy=515580.00, cost=580977.25
2022-12-06 11:13:08,620 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:13:08,620 [ZeusDataLoader(train)] Expected next epoch: time=3740.01, energy=522188.63, cost=588345.49
2022-12-06 11:13:08,621 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0026, Accuracy: 0.5478
2022-12-06 11:13:08,792 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:13:08,793 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:13:08.796 [ZeusMonitor] Monitor started.
2022-12-06 16:13:08.796 [ZeusMonitor] Running indefinitely. 2022-12-06 16:13:08.796 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:13:08.796 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e78+gpu0.power.log
2022-12-06 11:13:53,741 [ZeusDataLoader(train)] train epoch 78 done: time=45.11 energy=6371.96
2022-12-06 11:13:53,744 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 0.1707
Training Epoch: 77 [2048/50176]	Loss: 0.1684
Training Epoch: 77 [3072/50176]	Loss: 0.1640
Training Epoch: 77 [4096/50176]	Loss: 0.1999
Training Epoch: 77 [5120/50176]	Loss: 0.2128
Training Epoch: 77 [6144/50176]	Loss: 0.1874
Training Epoch: 77 [7168/50176]	Loss: 0.1608
Training Epoch: 77 [8192/50176]	Loss: 0.1708
Training Epoch: 77 [9216/50176]	Loss: 0.2109
Training Epoch: 77 [10240/50176]	Loss: 0.1771
Training Epoch: 77 [11264/50176]	Loss: 0.2007
Training Epoch: 77 [12288/50176]	Loss: 0.1670
Training Epoch: 77 [13312/50176]	Loss: 0.1638
Training Epoch: 77 [14336/50176]	Loss: 0.1805
Training Epoch: 77 [15360/50176]	Loss: 0.1920
Training Epoch: 77 [16384/50176]	Loss: 0.2034
Training Epoch: 77 [17408/50176]	Loss: 0.1810
Training Epoch: 77 [18432/50176]	Loss: 0.2214
Training Epoch: 77 [19456/50176]	Loss: 0.2090
Training Epoch: 77 [20480/50176]	Loss: 0.1664
Training Epoch: 77 [21504/50176]	Loss: 0.1784
Training Epoch: 77 [22528/50176]	Loss: 0.1723
Training Epoch: 77 [23552/50176]	Loss: 0.1859
Training Epoch: 77 [24576/50176]	Loss: 0.1984
Training Epoch: 77 [25600/50176]	Loss: 0.2112
Training Epoch: 77 [26624/50176]	Loss: 0.1576
Training Epoch: 77 [27648/50176]	Loss: 0.1855
Training Epoch: 77 [28672/50176]	Loss: 0.2192
Training Epoch: 77 [29696/50176]	Loss: 0.1877
Training Epoch: 77 [30720/50176]	Loss: 0.2077
Training Epoch: 77 [31744/50176]	Loss: 0.1843
Training Epoch: 77 [32768/50176]	Loss: 0.1996
Training Epoch: 77 [33792/50176]	Loss: 0.2134
Training Epoch: 77 [34816/50176]	Loss: 0.1957
Training Epoch: 77 [35840/50176]	Loss: 0.2315
Training Epoch: 77 [36864/50176]	Loss: 0.2259
Training Epoch: 77 [37888/50176]	Loss: 0.1843
Training Epoch: 77 [38912/50176]	Loss: 0.2121
Training Epoch: 77 [39936/50176]	Loss: 0.1768
Training Epoch: 77 [40960/50176]	Loss: 0.2162
Training Epoch: 77 [41984/50176]	Loss: 0.2106
Training Epoch: 77 [43008/50176]	Loss: 0.2160
Training Epoch: 77 [44032/50176]	Loss: 0.2258
Training Epoch: 77 [45056/50176]	Loss: 0.1835
Training Epoch: 77 [46080/50176]	Loss: 0.1782
Training Epoch: 77 [47104/50176]	Loss: 0.1844
Training Epoch: 77 [48128/50176]	Loss: 0.2283
Training Epoch: 77 [49152/50176]	Loss: 0.2477
Training Epoch: 77 [50176/50176]	Loss: 0.2221
2022-12-06 16:13:57.412 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:13:57,448 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.70 energy=480.97
2022-12-06 11:13:57,448 [ZeusDataLoader(train)] Up to epoch 78: time=3742.38, energy=522432.93, cost=588674.43
2022-12-06 11:13:57,448 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:13:57,448 [ZeusDataLoader(train)] Expected next epoch: time=3788.82, energy=529041.56, cost=596042.68
2022-12-06 11:13:57,449 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0026, Accuracy: 0.5485
2022-12-06 11:13:57,631 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:13:57,632 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:13:57.634 [ZeusMonitor] Monitor started.
2022-12-06 16:13:57.634 [ZeusMonitor] Running indefinitely. 2022-12-06 16:13:57.634 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:13:57.634 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e79+gpu0.power.log
2022-12-06 11:14:42,088 [ZeusDataLoader(train)] train epoch 79 done: time=44.63 energy=6336.53
2022-12-06 11:14:42,092 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 0.1642
Training Epoch: 78 [2048/50176]	Loss: 0.1926
Training Epoch: 78 [3072/50176]	Loss: 0.1775
Training Epoch: 78 [4096/50176]	Loss: 0.1752
Training Epoch: 78 [5120/50176]	Loss: 0.1570
Training Epoch: 78 [6144/50176]	Loss: 0.1652
Training Epoch: 78 [7168/50176]	Loss: 0.1509
Training Epoch: 78 [8192/50176]	Loss: 0.1889
Training Epoch: 78 [9216/50176]	Loss: 0.1644
Training Epoch: 78 [10240/50176]	Loss: 0.1858
Training Epoch: 78 [11264/50176]	Loss: 0.1856
Training Epoch: 78 [12288/50176]	Loss: 0.1488
Training Epoch: 78 [13312/50176]	Loss: 0.1976
Training Epoch: 78 [14336/50176]	Loss: 0.2040
Training Epoch: 78 [15360/50176]	Loss: 0.1531
Training Epoch: 78 [16384/50176]	Loss: 0.1770
Training Epoch: 78 [17408/50176]	Loss: 0.1920
Training Epoch: 78 [18432/50176]	Loss: 0.1832
Training Epoch: 78 [19456/50176]	Loss: 0.1842
Training Epoch: 78 [20480/50176]	Loss: 0.1806
Training Epoch: 78 [21504/50176]	Loss: 0.2153
Training Epoch: 78 [22528/50176]	Loss: 0.1692
Training Epoch: 78 [23552/50176]	Loss: 0.1780
Training Epoch: 78 [24576/50176]	Loss: 0.1905
Training Epoch: 78 [25600/50176]	Loss: 0.1948
Training Epoch: 78 [26624/50176]	Loss: 0.1678
Training Epoch: 78 [27648/50176]	Loss: 0.1990
Training Epoch: 78 [28672/50176]	Loss: 0.1672
Training Epoch: 78 [29696/50176]	Loss: 0.2063
Training Epoch: 78 [30720/50176]	Loss: 0.2008
Training Epoch: 78 [31744/50176]	Loss: 0.1726
Training Epoch: 78 [32768/50176]	Loss: 0.2237
Training Epoch: 78 [33792/50176]	Loss: 0.2268
Training Epoch: 78 [34816/50176]	Loss: 0.2032
Training Epoch: 78 [35840/50176]	Loss: 0.1919
Training Epoch: 78 [36864/50176]	Loss: 0.1897
Training Epoch: 78 [37888/50176]	Loss: 0.1785
Training Epoch: 78 [38912/50176]	Loss: 0.2105
Training Epoch: 78 [39936/50176]	Loss: 0.2055
Training Epoch: 78 [40960/50176]	Loss: 0.1951
Training Epoch: 78 [41984/50176]	Loss: 0.1712
Training Epoch: 78 [43008/50176]	Loss: 0.2009
Training Epoch: 78 [44032/50176]	Loss: 0.1809
Training Epoch: 78 [45056/50176]	Loss: 0.2075
Training Epoch: 78 [46080/50176]	Loss: 0.2317
Training Epoch: 78 [47104/50176]	Loss: 0.2018
Training Epoch: 78 [48128/50176]	Loss: 0.1955
Training Epoch: 78 [49152/50176]	Loss: 0.1643
Training Epoch: 78 [50176/50176]	Loss: 0.2203
2022-12-06 16:14:45.811 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:14:45,847 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.75 energy=479.66
2022-12-06 11:14:45,847 [ZeusDataLoader(train)] Up to epoch 79: time=3790.75, energy=529249.12, cost=596315.62
2022-12-06 11:14:45,847 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:14:45,847 [ZeusDataLoader(train)] Expected next epoch: time=3837.20, energy=535857.75, cost=603683.86
2022-12-06 11:14:45,848 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 0.0026, Accuracy: 0.5437
2022-12-06 11:14:46,022 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:14:46,023 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:14:46.033 [ZeusMonitor] Monitor started.
2022-12-06 16:14:46.033 [ZeusMonitor] Running indefinitely. 2022-12-06 16:14:46.033 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:14:46.033 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e80+gpu0.power.log
2022-12-06 11:15:30,875 [ZeusDataLoader(train)] train epoch 80 done: time=45.02 energy=6360.52
2022-12-06 11:15:30,878 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 0.1720
Training Epoch: 79 [2048/50176]	Loss: 0.1784
Training Epoch: 79 [3072/50176]	Loss: 0.1725
Training Epoch: 79 [4096/50176]	Loss: 0.1698
Training Epoch: 79 [5120/50176]	Loss: 0.1642
Training Epoch: 79 [6144/50176]	Loss: 0.1758
Training Epoch: 79 [7168/50176]	Loss: 0.1411
Training Epoch: 79 [8192/50176]	Loss: 0.1649
Training Epoch: 79 [9216/50176]	Loss: 0.1538
Training Epoch: 79 [10240/50176]	Loss: 0.1510
Training Epoch: 79 [11264/50176]	Loss: 0.1690
Training Epoch: 79 [12288/50176]	Loss: 0.1870
Training Epoch: 79 [13312/50176]	Loss: 0.1748
Training Epoch: 79 [14336/50176]	Loss: 0.1546
Training Epoch: 79 [15360/50176]	Loss: 0.1534
Training Epoch: 79 [16384/50176]	Loss: 0.1663
Training Epoch: 79 [17408/50176]	Loss: 0.1540
Training Epoch: 79 [18432/50176]	Loss: 0.1577
Training Epoch: 79 [19456/50176]	Loss: 0.2126
Training Epoch: 79 [20480/50176]	Loss: 0.1640
Training Epoch: 79 [21504/50176]	Loss: 0.1700
Training Epoch: 79 [22528/50176]	Loss: 0.2089
Training Epoch: 79 [23552/50176]	Loss: 0.1503
Training Epoch: 79 [24576/50176]	Loss: 0.1395
Training Epoch: 79 [25600/50176]	Loss: 0.1874
Training Epoch: 79 [26624/50176]	Loss: 0.1771
Training Epoch: 79 [27648/50176]	Loss: 0.1981
Training Epoch: 79 [28672/50176]	Loss: 0.1771
Training Epoch: 79 [29696/50176]	Loss: 0.2045
Training Epoch: 79 [30720/50176]	Loss: 0.1485
Training Epoch: 79 [31744/50176]	Loss: 0.1513
Training Epoch: 79 [32768/50176]	Loss: 0.1788
Training Epoch: 79 [33792/50176]	Loss: 0.1804
Training Epoch: 79 [34816/50176]	Loss: 0.1882
Training Epoch: 79 [35840/50176]	Loss: 0.2318
Training Epoch: 79 [36864/50176]	Loss: 0.1802
Training Epoch: 79 [37888/50176]	Loss: 0.1933
Training Epoch: 79 [38912/50176]	Loss: 0.1985
Training Epoch: 79 [39936/50176]	Loss: 0.1964
Training Epoch: 79 [40960/50176]	Loss: 0.1963
Training Epoch: 79 [41984/50176]	Loss: 0.1570
Training Epoch: 79 [43008/50176]	Loss: 0.1720
Training Epoch: 79 [44032/50176]	Loss: 0.1886
Training Epoch: 79 [45056/50176]	Loss: 0.1821
Training Epoch: 79 [46080/50176]	Loss: 0.2012
Training Epoch: 79 [47104/50176]	Loss: 0.2001
Training Epoch: 79 [48128/50176]	Loss: 0.2165
Training Epoch: 79 [49152/50176]	Loss: 0.1728
Training Epoch: 79 [50176/50176]	Loss: 0.1607
2022-12-06 16:15:34.566 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:15:34,590 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.70 energy=476.01
2022-12-06 11:15:34,590 [ZeusDataLoader(train)] Up to epoch 80: time=3839.48, energy=536085.65, cost=603997.12
2022-12-06 11:15:34,590 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:15:34,590 [ZeusDataLoader(train)] Expected next epoch: time=3885.92, energy=542694.28, cost=611365.37
2022-12-06 11:15:34,591 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 0.0026, Accuracy: 0.5502
2022-12-06 11:15:34,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:15:34,758 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:15:34.772 [ZeusMonitor] Monitor started.
2022-12-06 16:15:34.772 [ZeusMonitor] Running indefinitely. 2022-12-06 16:15:34.772 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:15:34.772 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e81+gpu0.power.log
2022-12-06 11:16:19,325 [ZeusDataLoader(train)] train epoch 81 done: time=44.73 energy=6343.73
2022-12-06 11:16:19,328 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 0.1267
Training Epoch: 80 [2048/50176]	Loss: 0.1498
Training Epoch: 80 [3072/50176]	Loss: 0.1904
Training Epoch: 80 [4096/50176]	Loss: 0.1481
Training Epoch: 80 [5120/50176]	Loss: 0.1574
Training Epoch: 80 [6144/50176]	Loss: 0.1539
Training Epoch: 80 [7168/50176]	Loss: 0.1672
Training Epoch: 80 [8192/50176]	Loss: 0.1520
Training Epoch: 80 [9216/50176]	Loss: 0.1416
Training Epoch: 80 [10240/50176]	Loss: 0.1482
Training Epoch: 80 [11264/50176]	Loss: 0.1610
Training Epoch: 80 [12288/50176]	Loss: 0.1580
Training Epoch: 80 [13312/50176]	Loss: 0.1682
Training Epoch: 80 [14336/50176]	Loss: 0.1510
Training Epoch: 80 [15360/50176]	Loss: 0.1643
Training Epoch: 80 [16384/50176]	Loss: 0.1708
Training Epoch: 80 [17408/50176]	Loss: 0.1687
Training Epoch: 80 [18432/50176]	Loss: 0.1649
Training Epoch: 80 [19456/50176]	Loss: 0.1449
Training Epoch: 80 [20480/50176]	Loss: 0.1845
Training Epoch: 80 [21504/50176]	Loss: 0.1527
Training Epoch: 80 [22528/50176]	Loss: 0.1549
Training Epoch: 80 [23552/50176]	Loss: 0.1792
Training Epoch: 80 [24576/50176]	Loss: 0.1773
Training Epoch: 80 [25600/50176]	Loss: 0.1669
Training Epoch: 80 [26624/50176]	Loss: 0.1766
Training Epoch: 80 [27648/50176]	Loss: 0.1832
Training Epoch: 80 [28672/50176]	Loss: 0.1429
Training Epoch: 80 [29696/50176]	Loss: 0.1605
Training Epoch: 80 [30720/50176]	Loss: 0.1762
Training Epoch: 80 [31744/50176]	Loss: 0.1937
Training Epoch: 80 [32768/50176]	Loss: 0.1778
Training Epoch: 80 [33792/50176]	Loss: 0.2053
Training Epoch: 80 [34816/50176]	Loss: 0.1726
Training Epoch: 80 [35840/50176]	Loss: 0.1690
Training Epoch: 80 [36864/50176]	Loss: 0.1854
Training Epoch: 80 [37888/50176]	Loss: 0.1924
Training Epoch: 80 [38912/50176]	Loss: 0.1954
Training Epoch: 80 [39936/50176]	Loss: 0.1792
Training Epoch: 80 [40960/50176]	Loss: 0.1710
Training Epoch: 80 [41984/50176]	Loss: 0.2172
Training Epoch: 80 [43008/50176]	Loss: 0.2099
Training Epoch: 80 [44032/50176]	Loss: 0.2000
Training Epoch: 80 [45056/50176]	Loss: 0.1883
Training Epoch: 80 [46080/50176]	Loss: 0.1596
Training Epoch: 80 [47104/50176]	Loss: 0.2236
Training Epoch: 80 [48128/50176]	Loss: 0.1610
Training Epoch: 80 [49152/50176]	Loss: 0.1759
Training Epoch: 80 [50176/50176]	Loss: 0.1854
2022-12-06 16:16:23.027 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:16:23,045 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.71 energy=477.86
2022-12-06 11:16:23,046 [ZeusDataLoader(train)] Up to epoch 81: time=3887.91, energy=542907.25, cost=611646.02
2022-12-06 11:16:23,046 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:16:23,046 [ZeusDataLoader(train)] Expected next epoch: time=3934.36, energy=549515.88, cost=619014.27
2022-12-06 11:16:23,047 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0027, Accuracy: 0.5473
2022-12-06 11:16:23,219 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:16:23,220 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:16:23.222 [ZeusMonitor] Monitor started.
2022-12-06 16:16:23.222 [ZeusMonitor] Running indefinitely. 2022-12-06 16:16:23.222 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:16:23.222 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e82+gpu0.power.log
2022-12-06 11:17:07,997 [ZeusDataLoader(train)] train epoch 82 done: time=44.94 energy=6358.15
2022-12-06 11:17:08,001 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 0.1290
Training Epoch: 81 [2048/50176]	Loss: 0.1391
Training Epoch: 81 [3072/50176]	Loss: 0.1619
Training Epoch: 81 [4096/50176]	Loss: 0.1666
Training Epoch: 81 [5120/50176]	Loss: 0.1704
Training Epoch: 81 [6144/50176]	Loss: 0.1505
Training Epoch: 81 [7168/50176]	Loss: 0.1708
Training Epoch: 81 [8192/50176]	Loss: 0.1421
Training Epoch: 81 [9216/50176]	Loss: 0.1479
Training Epoch: 81 [10240/50176]	Loss: 0.1344
Training Epoch: 81 [11264/50176]	Loss: 0.1655
Training Epoch: 81 [12288/50176]	Loss: 0.1671
Training Epoch: 81 [13312/50176]	Loss: 0.1569
Training Epoch: 81 [14336/50176]	Loss: 0.1679
Training Epoch: 81 [15360/50176]	Loss: 0.1696
Training Epoch: 81 [16384/50176]	Loss: 0.1355
Training Epoch: 81 [17408/50176]	Loss: 0.1576
Training Epoch: 81 [18432/50176]	Loss: 0.1530
Training Epoch: 81 [19456/50176]	Loss: 0.1646
Training Epoch: 81 [20480/50176]	Loss: 0.1784
Training Epoch: 81 [21504/50176]	Loss: 0.1560
Training Epoch: 81 [22528/50176]	Loss: 0.1910
Training Epoch: 81 [23552/50176]	Loss: 0.1822
Training Epoch: 81 [24576/50176]	Loss: 0.1334
Training Epoch: 81 [25600/50176]	Loss: 0.1827
Training Epoch: 81 [26624/50176]	Loss: 0.1886
Training Epoch: 81 [27648/50176]	Loss: 0.1614
Training Epoch: 81 [28672/50176]	Loss: 0.1812
Training Epoch: 81 [29696/50176]	Loss: 0.1697
Training Epoch: 81 [30720/50176]	Loss: 0.1478
Training Epoch: 81 [31744/50176]	Loss: 0.2041
Training Epoch: 81 [32768/50176]	Loss: 0.1748
Training Epoch: 81 [33792/50176]	Loss: 0.1740
Training Epoch: 81 [34816/50176]	Loss: 0.1486
Training Epoch: 81 [35840/50176]	Loss: 0.1755
Training Epoch: 81 [36864/50176]	Loss: 0.1519
Training Epoch: 81 [37888/50176]	Loss: 0.1822
Training Epoch: 81 [38912/50176]	Loss: 0.1834
Training Epoch: 81 [39936/50176]	Loss: 0.1865
Training Epoch: 81 [40960/50176]	Loss: 0.2001
Training Epoch: 81 [41984/50176]	Loss: 0.1855
Training Epoch: 81 [43008/50176]	Loss: 0.1710
Training Epoch: 81 [44032/50176]	Loss: 0.1835
Training Epoch: 81 [45056/50176]	Loss: 0.2035
Training Epoch: 81 [46080/50176]	Loss: 0.2124
Training Epoch: 81 [47104/50176]	Loss: 0.2036
Training Epoch: 81 [48128/50176]	Loss: 0.1859
Training Epoch: 81 [49152/50176]	Loss: 0.1875
Training Epoch: 81 [50176/50176]	Loss: 0.1639
2022-12-06 16:17:11.818 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:17:11,861 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.85 energy=490.18
2022-12-06 11:17:11,861 [ZeusDataLoader(train)] Up to epoch 82: time=3936.71, energy=549755.57, cost=619339.69
2022-12-06 11:17:11,861 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:17:11,861 [ZeusDataLoader(train)] Expected next epoch: time=3983.15, energy=556364.20, cost=626707.94
2022-12-06 11:17:11,862 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 0.0027, Accuracy: 0.5418
2022-12-06 11:17:12,038 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:17:12,039 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:17:12.041 [ZeusMonitor] Monitor started.
2022-12-06 16:17:12.041 [ZeusMonitor] Running indefinitely. 2022-12-06 16:17:12.041 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:17:12.041 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e83+gpu0.power.log
2022-12-06 11:17:56,336 [ZeusDataLoader(train)] train epoch 83 done: time=44.47 energy=6340.48
2022-12-06 11:17:56,340 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 0.1634
Training Epoch: 82 [2048/50176]	Loss: 0.1593
Training Epoch: 82 [3072/50176]	Loss: 0.1561
Training Epoch: 82 [4096/50176]	Loss: 0.1854
Training Epoch: 82 [5120/50176]	Loss: 0.1578
Training Epoch: 82 [6144/50176]	Loss: 0.1653
Training Epoch: 82 [7168/50176]	Loss: 0.1760
Training Epoch: 82 [8192/50176]	Loss: 0.2065
Training Epoch: 82 [9216/50176]	Loss: 0.1411
Training Epoch: 82 [10240/50176]	Loss: 0.1481
Training Epoch: 82 [11264/50176]	Loss: 0.1677
Training Epoch: 82 [12288/50176]	Loss: 0.1402
Training Epoch: 82 [13312/50176]	Loss: 0.1671
Training Epoch: 82 [14336/50176]	Loss: 0.1935
Training Epoch: 82 [15360/50176]	Loss: 0.1852
Training Epoch: 82 [16384/50176]	Loss: 0.1599
Training Epoch: 82 [17408/50176]	Loss: 0.1598
Training Epoch: 82 [18432/50176]	Loss: 0.1985
Training Epoch: 82 [19456/50176]	Loss: 0.1806
Training Epoch: 82 [20480/50176]	Loss: 0.1947
Training Epoch: 82 [21504/50176]	Loss: 0.1608
Training Epoch: 82 [22528/50176]	Loss: 0.1574
Training Epoch: 82 [23552/50176]	Loss: 0.1640
Training Epoch: 82 [24576/50176]	Loss: 0.1859
Training Epoch: 82 [25600/50176]	Loss: 0.1641
Training Epoch: 82 [26624/50176]	Loss: 0.1547
Training Epoch: 82 [27648/50176]	Loss: 0.1640
Training Epoch: 82 [28672/50176]	Loss: 0.1537
Training Epoch: 82 [29696/50176]	Loss: 0.1810
Training Epoch: 82 [30720/50176]	Loss: 0.1816
Training Epoch: 82 [31744/50176]	Loss: 0.1617
Training Epoch: 82 [32768/50176]	Loss: 0.1793
Training Epoch: 82 [33792/50176]	Loss: 0.1736
Training Epoch: 82 [34816/50176]	Loss: 0.1653
Training Epoch: 82 [35840/50176]	Loss: 0.1948
Training Epoch: 82 [36864/50176]	Loss: 0.1920
Training Epoch: 82 [37888/50176]	Loss: 0.1767
Training Epoch: 82 [38912/50176]	Loss: 0.1677
Training Epoch: 82 [39936/50176]	Loss: 0.1678
Training Epoch: 82 [40960/50176]	Loss: 0.1832
Training Epoch: 82 [41984/50176]	Loss: 0.1760
Training Epoch: 82 [43008/50176]	Loss: 0.1771
Training Epoch: 82 [44032/50176]	Loss: 0.1716
Training Epoch: 82 [45056/50176]	Loss: 0.1683
Training Epoch: 82 [46080/50176]	Loss: 0.1731
Training Epoch: 82 [47104/50176]	Loss: 0.1568
Training Epoch: 82 [48128/50176]	Loss: 0.2010
Training Epoch: 82 [49152/50176]	Loss: 0.1839
Training Epoch: 82 [50176/50176]	Loss: 0.1747
2022-12-06 16:17:59.988 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:18:00,003 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.66 energy=461.91
2022-12-06 11:18:00,003 [ZeusDataLoader(train)] Up to epoch 83: time=3984.83, energy=556557.96, cost=626951.48
2022-12-06 11:18:00,004 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:18:00,004 [ZeusDataLoader(train)] Expected next epoch: time=4031.27, energy=563166.59, cost=634319.73
2022-12-06 11:18:00,004 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 0.0027, Accuracy: 0.5524
2022-12-06 11:18:00,140 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:18:00,141 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:18:00.144 [ZeusMonitor] Monitor started.
2022-12-06 16:18:00.144 [ZeusMonitor] Running indefinitely. 2022-12-06 16:18:00.144 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:18:00.144 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e84+gpu0.power.log
2022-12-06 11:18:44,998 [ZeusDataLoader(train)] train epoch 84 done: time=44.99 energy=6367.83
2022-12-06 11:18:45,001 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 0.1302
Training Epoch: 83 [2048/50176]	Loss: 0.1274
Training Epoch: 83 [3072/50176]	Loss: 0.1418
Training Epoch: 83 [4096/50176]	Loss: 0.1476
Training Epoch: 83 [5120/50176]	Loss: 0.1376
Training Epoch: 83 [6144/50176]	Loss: 0.1436
Training Epoch: 83 [7168/50176]	Loss: 0.1714
Training Epoch: 83 [8192/50176]	Loss: 0.1818
Training Epoch: 83 [9216/50176]	Loss: 0.1460
Training Epoch: 83 [10240/50176]	Loss: 0.1443
Training Epoch: 83 [11264/50176]	Loss: 0.1790
Training Epoch: 83 [12288/50176]	Loss: 0.1500
Training Epoch: 83 [13312/50176]	Loss: 0.1598
Training Epoch: 83 [14336/50176]	Loss: 0.1445
Training Epoch: 83 [15360/50176]	Loss: 0.1648
Training Epoch: 83 [16384/50176]	Loss: 0.1593
Training Epoch: 83 [17408/50176]	Loss: 0.1593
Training Epoch: 83 [18432/50176]	Loss: 0.1910
Training Epoch: 83 [19456/50176]	Loss: 0.1624
Training Epoch: 83 [20480/50176]	Loss: 0.1639
Training Epoch: 83 [21504/50176]	Loss: 0.1296
Training Epoch: 83 [22528/50176]	Loss: 0.1531
Training Epoch: 83 [23552/50176]	Loss: 0.1445
Training Epoch: 83 [24576/50176]	Loss: 0.1465
Training Epoch: 83 [25600/50176]	Loss: 0.1516
Training Epoch: 83 [26624/50176]	Loss: 0.1570
Training Epoch: 83 [27648/50176]	Loss: 0.1818
Training Epoch: 83 [28672/50176]	Loss: 0.1578
Training Epoch: 83 [29696/50176]	Loss: 0.1532
Training Epoch: 83 [30720/50176]	Loss: 0.1660
Training Epoch: 83 [31744/50176]	Loss: 0.1841
Training Epoch: 83 [32768/50176]	Loss: 0.1716
Training Epoch: 83 [33792/50176]	Loss: 0.1748
Training Epoch: 83 [34816/50176]	Loss: 0.1618
Training Epoch: 83 [35840/50176]	Loss: 0.1930
Training Epoch: 83 [36864/50176]	Loss: 0.1935
Training Epoch: 83 [37888/50176]	Loss: 0.1469
Training Epoch: 83 [38912/50176]	Loss: 0.1523
Training Epoch: 83 [39936/50176]	Loss: 0.1785
Training Epoch: 83 [40960/50176]	Loss: 0.2001
Training Epoch: 83 [41984/50176]	Loss: 0.1756
Training Epoch: 83 [43008/50176]	Loss: 0.1665
Training Epoch: 83 [44032/50176]	Loss: 0.1800
Training Epoch: 83 [45056/50176]	Loss: 0.1822
Training Epoch: 83 [46080/50176]	Loss: 0.1850
Training Epoch: 83 [47104/50176]	Loss: 0.1785
Training Epoch: 83 [48128/50176]	Loss: 0.1868
Training Epoch: 83 [49152/50176]	Loss: 0.2098
Training Epoch: 83 [50176/50176]	Loss: 0.1689
2022-12-06 16:18:48.782 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:18:48,800 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.79 energy=487.85
2022-12-06 11:18:48,800 [ZeusDataLoader(train)] Up to epoch 84: time=4033.61, energy=563413.63, cost=634647.27
2022-12-06 11:18:48,800 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:18:48,800 [ZeusDataLoader(train)] Expected next epoch: time=4080.05, energy=570022.26, cost=642015.52
2022-12-06 11:18:48,801 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 0.0027, Accuracy: 0.5521
2022-12-06 11:18:48,975 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:18:48,976 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:18:48.978 [ZeusMonitor] Monitor started.
2022-12-06 16:18:48.978 [ZeusMonitor] Running indefinitely. 2022-12-06 16:18:48.978 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:18:48.978 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e85+gpu0.power.log
2022-12-06 11:19:33,200 [ZeusDataLoader(train)] train epoch 85 done: time=44.39 energy=6329.76
2022-12-06 11:19:33,203 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 0.1557
Training Epoch: 84 [2048/50176]	Loss: 0.1179
Training Epoch: 84 [3072/50176]	Loss: 0.1493
Training Epoch: 84 [4096/50176]	Loss: 0.1270
Training Epoch: 84 [5120/50176]	Loss: 0.1504
Training Epoch: 84 [6144/50176]	Loss: 0.1640
Training Epoch: 84 [7168/50176]	Loss: 0.1527
Training Epoch: 84 [8192/50176]	Loss: 0.1746
Training Epoch: 84 [9216/50176]	Loss: 0.1642
Training Epoch: 84 [10240/50176]	Loss: 0.1255
Training Epoch: 84 [11264/50176]	Loss: 0.1411
Training Epoch: 84 [12288/50176]	Loss: 0.1427
Training Epoch: 84 [13312/50176]	Loss: 0.1684
Training Epoch: 84 [14336/50176]	Loss: 0.1333
Training Epoch: 84 [15360/50176]	Loss: 0.1463
Training Epoch: 84 [16384/50176]	Loss: 0.1605
Training Epoch: 84 [17408/50176]	Loss: 0.1408
Training Epoch: 84 [18432/50176]	Loss: 0.1615
Training Epoch: 84 [19456/50176]	Loss: 0.1513
Training Epoch: 84 [20480/50176]	Loss: 0.1375
Training Epoch: 84 [21504/50176]	Loss: 0.1492
Training Epoch: 84 [22528/50176]	Loss: 0.1467
Training Epoch: 84 [23552/50176]	Loss: 0.1937
Training Epoch: 84 [24576/50176]	Loss: 0.1418
Training Epoch: 84 [25600/50176]	Loss: 0.1544
Training Epoch: 84 [26624/50176]	Loss: 0.1383
Training Epoch: 84 [27648/50176]	Loss: 0.1575
Training Epoch: 84 [28672/50176]	Loss: 0.1493
Training Epoch: 84 [29696/50176]	Loss: 0.2298
Training Epoch: 84 [30720/50176]	Loss: 0.1588
Training Epoch: 84 [31744/50176]	Loss: 0.1454
Training Epoch: 84 [32768/50176]	Loss: 0.1413
Training Epoch: 84 [33792/50176]	Loss: 0.1817
Training Epoch: 84 [34816/50176]	Loss: 0.1561
Training Epoch: 84 [35840/50176]	Loss: 0.1689
Training Epoch: 84 [36864/50176]	Loss: 0.1777
Training Epoch: 84 [37888/50176]	Loss: 0.1597
Training Epoch: 84 [38912/50176]	Loss: 0.1705
Training Epoch: 84 [39936/50176]	Loss: 0.1551
Training Epoch: 84 [40960/50176]	Loss: 0.1353
Training Epoch: 84 [41984/50176]	Loss: 0.2052
Training Epoch: 84 [43008/50176]	Loss: 0.1547
Training Epoch: 84 [44032/50176]	Loss: 0.1805
Training Epoch: 84 [45056/50176]	Loss: 0.1735
Training Epoch: 84 [46080/50176]	Loss: 0.1956
Training Epoch: 84 [47104/50176]	Loss: 0.2237
Training Epoch: 84 [48128/50176]	Loss: 0.2003
Training Epoch: 84 [49152/50176]	Loss: 0.1796
Training Epoch: 84 [50176/50176]	Loss: 0.1956
2022-12-06 16:19:36.866 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:19:36,886 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.68 energy=463.11
2022-12-06 11:19:36,886 [ZeusDataLoader(train)] Up to epoch 85: time=4081.67, energy=570206.50, cost=642249.48
2022-12-06 11:19:36,886 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:19:36,886 [ZeusDataLoader(train)] Expected next epoch: time=4128.12, energy=576815.12, cost=649617.73
2022-12-06 11:19:36,887 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 0.0027, Accuracy: 0.5444
2022-12-06 11:19:37,059 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:19:37,060 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:19:37.062 [ZeusMonitor] Monitor started.
2022-12-06 16:19:37.062 [ZeusMonitor] Running indefinitely. 2022-12-06 16:19:37.062 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:19:37.062 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e86+gpu0.power.log
2022-12-06 11:20:21,216 [ZeusDataLoader(train)] train epoch 86 done: time=44.32 energy=6328.21
2022-12-06 11:20:21,219 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 0.1633
Training Epoch: 85 [2048/50176]	Loss: 0.1483
Training Epoch: 85 [3072/50176]	Loss: 0.1516
Training Epoch: 85 [4096/50176]	Loss: 0.1351
Training Epoch: 85 [5120/50176]	Loss: 0.1204
Training Epoch: 85 [6144/50176]	Loss: 0.1788
Training Epoch: 85 [7168/50176]	Loss: 0.1576
Training Epoch: 85 [8192/50176]	Loss: 0.1545
Training Epoch: 85 [9216/50176]	Loss: 0.1408
Training Epoch: 85 [10240/50176]	Loss: 0.1791
Training Epoch: 85 [11264/50176]	Loss: 0.1477
Training Epoch: 85 [12288/50176]	Loss: 0.1689
Training Epoch: 85 [13312/50176]	Loss: 0.1386
Training Epoch: 85 [14336/50176]	Loss: 0.1457
Training Epoch: 85 [15360/50176]	Loss: 0.1573
Training Epoch: 85 [16384/50176]	Loss: 0.1506
Training Epoch: 85 [17408/50176]	Loss: 0.1742
Training Epoch: 85 [18432/50176]	Loss: 0.1740
Training Epoch: 85 [19456/50176]	Loss: 0.1653
Training Epoch: 85 [20480/50176]	Loss: 0.1803
Training Epoch: 85 [21504/50176]	Loss: 0.1829
Training Epoch: 85 [22528/50176]	Loss: 0.1472
Training Epoch: 85 [23552/50176]	Loss: 0.1468
Training Epoch: 85 [24576/50176]	Loss: 0.1582
Training Epoch: 85 [25600/50176]	Loss: 0.1518
Training Epoch: 85 [26624/50176]	Loss: 0.1672
Training Epoch: 85 [27648/50176]	Loss: 0.1670
Training Epoch: 85 [28672/50176]	Loss: 0.1662
Training Epoch: 85 [29696/50176]	Loss: 0.1772
Training Epoch: 85 [30720/50176]	Loss: 0.1685
Training Epoch: 85 [31744/50176]	Loss: 0.1534
Training Epoch: 85 [32768/50176]	Loss: 0.1666
Training Epoch: 85 [33792/50176]	Loss: 0.1903
Training Epoch: 85 [34816/50176]	Loss: 0.1920
Training Epoch: 85 [35840/50176]	Loss: 0.1749
Training Epoch: 85 [36864/50176]	Loss: 0.1918
Training Epoch: 85 [37888/50176]	Loss: 0.1644
Training Epoch: 85 [38912/50176]	Loss: 0.2127
Training Epoch: 85 [39936/50176]	Loss: 0.1771
Training Epoch: 85 [40960/50176]	Loss: 0.1777
Training Epoch: 85 [41984/50176]	Loss: 0.1444
Training Epoch: 85 [43008/50176]	Loss: 0.1642
Training Epoch: 85 [44032/50176]	Loss: 0.1785
Training Epoch: 85 [45056/50176]	Loss: 0.1808
Training Epoch: 85 [46080/50176]	Loss: 0.1622
Training Epoch: 85 [47104/50176]	Loss: 0.1558
Training Epoch: 85 [48128/50176]	Loss: 0.1696
Training Epoch: 85 [49152/50176]	Loss: 0.1713
Training Epoch: 85 [50176/50176]	Loss: 0.1778
2022-12-06 16:20:25.067 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:20:25,092 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.86 energy=484.14
2022-12-06 11:20:25,092 [ZeusDataLoader(train)] Up to epoch 86: time=4129.86, energy=577018.84, cost=649871.86
2022-12-06 11:20:25,092 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:20:25,092 [ZeusDataLoader(train)] Expected next epoch: time=4176.30, energy=583627.47, cost=657240.11
2022-12-06 11:20:25,093 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 0.0027, Accuracy: 0.5474
2022-12-06 11:20:25,267 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:20:25,268 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:20:25.270 [ZeusMonitor] Monitor started.
2022-12-06 16:20:25.270 [ZeusMonitor] Running indefinitely. 2022-12-06 16:20:25.270 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:20:25.270 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e87+gpu0.power.log
2022-12-06 11:21:09,500 [ZeusDataLoader(train)] train epoch 87 done: time=44.40 energy=6327.72
2022-12-06 11:21:09,503 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 0.1194
Training Epoch: 86 [2048/50176]	Loss: 0.1298
Training Epoch: 86 [3072/50176]	Loss: 0.1496
Training Epoch: 86 [4096/50176]	Loss: 0.1799
Training Epoch: 86 [5120/50176]	Loss: 0.1559
Training Epoch: 86 [6144/50176]	Loss: 0.1692
Training Epoch: 86 [7168/50176]	Loss: 0.1315
Training Epoch: 86 [8192/50176]	Loss: 0.1723
Training Epoch: 86 [9216/50176]	Loss: 0.1565
Training Epoch: 86 [10240/50176]	Loss: 0.1210
Training Epoch: 86 [11264/50176]	Loss: 0.1377
Training Epoch: 86 [12288/50176]	Loss: 0.1363
Training Epoch: 86 [13312/50176]	Loss: 0.1691
Training Epoch: 86 [14336/50176]	Loss: 0.1602
Training Epoch: 86 [15360/50176]	Loss: 0.1681
Training Epoch: 86 [16384/50176]	Loss: 0.1251
Training Epoch: 86 [17408/50176]	Loss: 0.1697
Training Epoch: 86 [18432/50176]	Loss: 0.1463
Training Epoch: 86 [19456/50176]	Loss: 0.1524
Training Epoch: 86 [20480/50176]	Loss: 0.1414
Training Epoch: 86 [21504/50176]	Loss: 0.1507
Training Epoch: 86 [22528/50176]	Loss: 0.1946
Training Epoch: 86 [23552/50176]	Loss: 0.1614
Training Epoch: 86 [24576/50176]	Loss: 0.1376
Training Epoch: 86 [25600/50176]	Loss: 0.1699
Training Epoch: 86 [26624/50176]	Loss: 0.1257
Training Epoch: 86 [27648/50176]	Loss: 0.1603
Training Epoch: 86 [28672/50176]	Loss: 0.1834
Training Epoch: 86 [29696/50176]	Loss: 0.1567
Training Epoch: 86 [30720/50176]	Loss: 0.1645
Training Epoch: 86 [31744/50176]	Loss: 0.1482
Training Epoch: 86 [32768/50176]	Loss: 0.1637
Training Epoch: 86 [33792/50176]	Loss: 0.1869
Training Epoch: 86 [34816/50176]	Loss: 0.1648
Training Epoch: 86 [35840/50176]	Loss: 0.1866
Training Epoch: 86 [36864/50176]	Loss: 0.1632
Training Epoch: 86 [37888/50176]	Loss: 0.1871
Training Epoch: 86 [38912/50176]	Loss: 0.1490
Training Epoch: 86 [39936/50176]	Loss: 0.1724
Training Epoch: 86 [40960/50176]	Loss: 0.1748
Training Epoch: 86 [41984/50176]	Loss: 0.1840
Training Epoch: 86 [43008/50176]	Loss: 0.1589
Training Epoch: 86 [44032/50176]	Loss: 0.1515
Training Epoch: 86 [45056/50176]	Loss: 0.1582
Training Epoch: 86 [46080/50176]	Loss: 0.1762
Training Epoch: 86 [47104/50176]	Loss: 0.1754
Training Epoch: 86 [48128/50176]	Loss: 0.1676
Training Epoch: 86 [49152/50176]	Loss: 0.1663
Training Epoch: 86 [50176/50176]	Loss: 0.1667
2022-12-06 16:21:13.197 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:21:13,207 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.70 energy=480.07
2022-12-06 11:21:13,208 [ZeusDataLoader(train)] Up to epoch 87: time=4177.95, energy=583826.63, cost=657484.06
2022-12-06 11:21:13,208 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:21:13,208 [ZeusDataLoader(train)] Expected next epoch: time=4224.40, energy=590435.26, cost=664852.30
2022-12-06 11:21:13,209 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 0.0027, Accuracy: 0.5516
2022-12-06 11:21:13,386 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:21:13,387 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:21:13.401 [ZeusMonitor] Monitor started.
2022-12-06 16:21:13.401 [ZeusMonitor] Running indefinitely. 2022-12-06 16:21:13.401 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:21:13.401 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e88+gpu0.power.log
2022-12-06 11:21:57,500 [ZeusDataLoader(train)] train epoch 88 done: time=44.28 energy=6317.07
2022-12-06 11:21:57,503 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 0.1250
Training Epoch: 87 [2048/50176]	Loss: 0.1608
Training Epoch: 87 [3072/50176]	Loss: 0.1353
Training Epoch: 87 [4096/50176]	Loss: 0.1573
Training Epoch: 87 [5120/50176]	Loss: 0.1395
Training Epoch: 87 [6144/50176]	Loss: 0.1411
Training Epoch: 87 [7168/50176]	Loss: 0.1329
Training Epoch: 87 [8192/50176]	Loss: 0.1579
Training Epoch: 87 [9216/50176]	Loss: 0.1447
Training Epoch: 87 [10240/50176]	Loss: 0.1397
Training Epoch: 87 [11264/50176]	Loss: 0.1795
Training Epoch: 87 [12288/50176]	Loss: 0.1521
Training Epoch: 87 [13312/50176]	Loss: 0.1686
Training Epoch: 87 [14336/50176]	Loss: 0.1358
Training Epoch: 87 [15360/50176]	Loss: 0.1440
Training Epoch: 87 [16384/50176]	Loss: 0.1767
Training Epoch: 87 [17408/50176]	Loss: 0.1345
Training Epoch: 87 [18432/50176]	Loss: 0.1649
Training Epoch: 87 [19456/50176]	Loss: 0.1408
Training Epoch: 87 [20480/50176]	Loss: 0.1773
Training Epoch: 87 [21504/50176]	Loss: 0.1692
Training Epoch: 87 [22528/50176]	Loss: 0.1916
Training Epoch: 87 [23552/50176]	Loss: 0.1302
Training Epoch: 87 [24576/50176]	Loss: 0.1724
Training Epoch: 87 [25600/50176]	Loss: 0.1749
Training Epoch: 87 [26624/50176]	Loss: 0.1472
Training Epoch: 87 [27648/50176]	Loss: 0.1449
Training Epoch: 87 [28672/50176]	Loss: 0.1516
Training Epoch: 87 [29696/50176]	Loss: 0.1722
Training Epoch: 87 [30720/50176]	Loss: 0.1761
Training Epoch: 87 [31744/50176]	Loss: 0.1426
Training Epoch: 87 [32768/50176]	Loss: 0.1517
Training Epoch: 87 [33792/50176]	Loss: 0.1631
Training Epoch: 87 [34816/50176]	Loss: 0.1723
Training Epoch: 87 [35840/50176]	Loss: 0.1676
Training Epoch: 87 [36864/50176]	Loss: 0.1577
Training Epoch: 87 [37888/50176]	Loss: 0.1733
Training Epoch: 87 [38912/50176]	Loss: 0.1608
Training Epoch: 87 [39936/50176]	Loss: 0.1640
Training Epoch: 87 [40960/50176]	Loss: 0.1810
Training Epoch: 87 [41984/50176]	Loss: 0.1532
Training Epoch: 87 [43008/50176]	Loss: 0.1791
Training Epoch: 87 [44032/50176]	Loss: 0.1668
Training Epoch: 87 [45056/50176]	Loss: 0.1700
Training Epoch: 87 [46080/50176]	Loss: 0.1882
Training Epoch: 87 [47104/50176]	Loss: 0.1838
Training Epoch: 87 [48128/50176]	Loss: 0.1665
Training Epoch: 87 [49152/50176]	Loss: 0.1751
Training Epoch: 87 [50176/50176]	Loss: 0.1872
2022-12-06 16:22:01.242 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:22:01,264 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.75 energy=479.29
2022-12-06 11:22:01,265 [ZeusDataLoader(train)] Up to epoch 88: time=4225.99, energy=590622.99, cost=665085.46
2022-12-06 11:22:01,265 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:22:01,265 [ZeusDataLoader(train)] Expected next epoch: time=4272.43, energy=597231.62, cost=672453.71
2022-12-06 11:22:01,266 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0027, Accuracy: 0.5517
2022-12-06 11:22:01,439 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:22:01,440 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:22:01.462 [ZeusMonitor] Monitor started.
2022-12-06 16:22:01.462 [ZeusMonitor] Running indefinitely. 2022-12-06 16:22:01.462 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:22:01.462 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e89+gpu0.power.log
2022-12-06 11:22:45,645 [ZeusDataLoader(train)] train epoch 89 done: time=44.37 energy=6325.15
2022-12-06 11:22:45,648 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 0.1165
Training Epoch: 88 [2048/50176]	Loss: 0.1386
Training Epoch: 88 [3072/50176]	Loss: 0.1452
Training Epoch: 88 [4096/50176]	Loss: 0.1407
Training Epoch: 88 [5120/50176]	Loss: 0.1608
Training Epoch: 88 [6144/50176]	Loss: 0.1661
Training Epoch: 88 [7168/50176]	Loss: 0.1773
Training Epoch: 88 [8192/50176]	Loss: 0.1306
Training Epoch: 88 [9216/50176]	Loss: 0.1336
Training Epoch: 88 [10240/50176]	Loss: 0.1488
Training Epoch: 88 [11264/50176]	Loss: 0.1324
Training Epoch: 88 [12288/50176]	Loss: 0.1377
Training Epoch: 88 [13312/50176]	Loss: 0.1313
Training Epoch: 88 [14336/50176]	Loss: 0.1472
Training Epoch: 88 [15360/50176]	Loss: 0.1762
Training Epoch: 88 [16384/50176]	Loss: 0.1196
Training Epoch: 88 [17408/50176]	Loss: 0.1334
Training Epoch: 88 [18432/50176]	Loss: 0.1539
Training Epoch: 88 [19456/50176]	Loss: 0.1425
Training Epoch: 88 [20480/50176]	Loss: 0.1741
Training Epoch: 88 [21504/50176]	Loss: 0.1478
Training Epoch: 88 [22528/50176]	Loss: 0.1263
Training Epoch: 88 [23552/50176]	Loss: 0.1500
Training Epoch: 88 [24576/50176]	Loss: 0.1469
Training Epoch: 88 [25600/50176]	Loss: 0.1506
Training Epoch: 88 [26624/50176]	Loss: 0.1607
Training Epoch: 88 [27648/50176]	Loss: 0.1671
Training Epoch: 88 [28672/50176]	Loss: 0.1195
Training Epoch: 88 [29696/50176]	Loss: 0.1454
Training Epoch: 88 [30720/50176]	Loss: 0.1540
Training Epoch: 88 [31744/50176]	Loss: 0.1685
Training Epoch: 88 [32768/50176]	Loss: 0.1743
Training Epoch: 88 [33792/50176]	Loss: 0.1790
Training Epoch: 88 [34816/50176]	Loss: 0.1453
Training Epoch: 88 [35840/50176]	Loss: 0.1549
Training Epoch: 88 [36864/50176]	Loss: 0.1628
Training Epoch: 88 [37888/50176]	Loss: 0.1491
Training Epoch: 88 [38912/50176]	Loss: 0.1666
Training Epoch: 88 [39936/50176]	Loss: 0.1808
Training Epoch: 88 [40960/50176]	Loss: 0.1485
Training Epoch: 88 [41984/50176]	Loss: 0.1573
Training Epoch: 88 [43008/50176]	Loss: 0.1511
Training Epoch: 88 [44032/50176]	Loss: 0.1248
Training Epoch: 88 [45056/50176]	Loss: 0.1720
Training Epoch: 88 [46080/50176]	Loss: 0.1623
Training Epoch: 88 [47104/50176]	Loss: 0.1717
Training Epoch: 88 [48128/50176]	Loss: 0.1565
Training Epoch: 88 [49152/50176]	Loss: 0.1575
Training Epoch: 88 [50176/50176]	Loss: 0.1748
2022-12-06 16:22:49.410 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:22:49,423 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.77 energy=467.55
2022-12-06 11:22:49,424 [ZeusDataLoader(train)] Up to epoch 89: time=4274.13, energy=597415.69, cost=672693.91
2022-12-06 11:22:49,424 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:22:49,424 [ZeusDataLoader(train)] Expected next epoch: time=4320.57, energy=604024.32, cost=680062.15
2022-12-06 11:22:49,425 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 0.0027, Accuracy: 0.5499
2022-12-06 11:22:49,595 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:22:49,596 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:22:49.597 [ZeusMonitor] Monitor started.
2022-12-06 16:22:49.597 [ZeusMonitor] Running indefinitely. 2022-12-06 16:22:49.597 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:22:49.597 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e90+gpu0.power.log
2022-12-06 11:23:34,249 [ZeusDataLoader(train)] train epoch 90 done: time=44.82 energy=6364.08
2022-12-06 11:23:34,253 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 0.1197
Training Epoch: 89 [2048/50176]	Loss: 0.1013
Training Epoch: 89 [3072/50176]	Loss: 0.1061
Training Epoch: 89 [4096/50176]	Loss: 0.1294
Training Epoch: 89 [5120/50176]	Loss: 0.1405
Training Epoch: 89 [6144/50176]	Loss: 0.1474
Training Epoch: 89 [7168/50176]	Loss: 0.1226
Training Epoch: 89 [8192/50176]	Loss: 0.1164
Training Epoch: 89 [9216/50176]	Loss: 0.1538
Training Epoch: 89 [10240/50176]	Loss: 0.1333
Training Epoch: 89 [11264/50176]	Loss: 0.1256
Training Epoch: 89 [12288/50176]	Loss: 0.1449
Training Epoch: 89 [13312/50176]	Loss: 0.1385
Training Epoch: 89 [14336/50176]	Loss: 0.1494
Training Epoch: 89 [15360/50176]	Loss: 0.1324
Training Epoch: 89 [16384/50176]	Loss: 0.1488
Training Epoch: 89 [17408/50176]	Loss: 0.1411
Training Epoch: 89 [18432/50176]	Loss: 0.1679
Training Epoch: 89 [19456/50176]	Loss: 0.1274
Training Epoch: 89 [20480/50176]	Loss: 0.1315
Training Epoch: 89 [21504/50176]	Loss: 0.1335
Training Epoch: 89 [22528/50176]	Loss: 0.1257
Training Epoch: 89 [23552/50176]	Loss: 0.1688
Training Epoch: 89 [24576/50176]	Loss: 0.1547
Training Epoch: 89 [25600/50176]	Loss: 0.1240
Training Epoch: 89 [26624/50176]	Loss: 0.1807
Training Epoch: 89 [27648/50176]	Loss: 0.1628
Training Epoch: 89 [28672/50176]	Loss: 0.1846
Training Epoch: 89 [29696/50176]	Loss: 0.1535
Training Epoch: 89 [30720/50176]	Loss: 0.1392
Training Epoch: 89 [31744/50176]	Loss: 0.1491
Training Epoch: 89 [32768/50176]	Loss: 0.1877
Training Epoch: 89 [33792/50176]	Loss: 0.1373
Training Epoch: 89 [34816/50176]	Loss: 0.1766
Training Epoch: 89 [35840/50176]	Loss: 0.1578
Training Epoch: 89 [36864/50176]	Loss: 0.1481
Training Epoch: 89 [37888/50176]	Loss: 0.1453
Training Epoch: 89 [38912/50176]	Loss: 0.1751
Training Epoch: 89 [39936/50176]	Loss: 0.1635
Training Epoch: 89 [40960/50176]	Loss: 0.1645
Training Epoch: 89 [41984/50176]	Loss: 0.1690
Training Epoch: 89 [43008/50176]	Loss: 0.1627
Training Epoch: 89 [44032/50176]	Loss: 0.1581
Training Epoch: 89 [45056/50176]	Loss: 0.1549
Training Epoch: 89 [46080/50176]	Loss: 0.1486
Training Epoch: 89 [47104/50176]	Loss: 0.1485
Training Epoch: 89 [48128/50176]	Loss: 0.1560
Training Epoch: 89 [49152/50176]	Loss: 0.1708
Training Epoch: 89 [50176/50176]	Loss: 0.1611
2022-12-06 16:23:37.898 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:23:37,913 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.65 energy=457.84
2022-12-06 11:23:37,913 [ZeusDataLoader(train)] Up to epoch 90: time=4322.60, energy=604237.61, cost=680345.93
2022-12-06 11:23:37,913 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:23:37,913 [ZeusDataLoader(train)] Expected next epoch: time=4369.04, energy=610846.24, cost=687714.18
2022-12-06 11:23:37,914 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0027, Accuracy: 0.5530
2022-12-06 11:23:38,087 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:23:38,088 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:23:38.090 [ZeusMonitor] Monitor started.
2022-12-06 16:23:38.090 [ZeusMonitor] Running indefinitely. 2022-12-06 16:23:38.090 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:23:38.090 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e91+gpu0.power.log
2022-12-06 11:24:22,450 [ZeusDataLoader(train)] train epoch 91 done: time=44.53 energy=6339.49
2022-12-06 11:24:22,454 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 0.1439
Training Epoch: 90 [2048/50176]	Loss: 0.1047
Training Epoch: 90 [3072/50176]	Loss: 0.1425
Training Epoch: 90 [4096/50176]	Loss: 0.1428
Training Epoch: 90 [5120/50176]	Loss: 0.1216
Training Epoch: 90 [6144/50176]	Loss: 0.1333
Training Epoch: 90 [7168/50176]	Loss: 0.1172
Training Epoch: 90 [8192/50176]	Loss: 0.1436
Training Epoch: 90 [9216/50176]	Loss: 0.1501
Training Epoch: 90 [10240/50176]	Loss: 0.1223
Training Epoch: 90 [11264/50176]	Loss: 0.1445
Training Epoch: 90 [12288/50176]	Loss: 0.1539
Training Epoch: 90 [13312/50176]	Loss: 0.1368
Training Epoch: 90 [14336/50176]	Loss: 0.1464
Training Epoch: 90 [15360/50176]	Loss: 0.1448
Training Epoch: 90 [16384/50176]	Loss: 0.1581
Training Epoch: 90 [17408/50176]	Loss: 0.1487
Training Epoch: 90 [18432/50176]	Loss: 0.1248
Training Epoch: 90 [19456/50176]	Loss: 0.1673
Training Epoch: 90 [20480/50176]	Loss: 0.1297
Training Epoch: 90 [21504/50176]	Loss: 0.1486
Training Epoch: 90 [22528/50176]	Loss: 0.1431
Training Epoch: 90 [23552/50176]	Loss: 0.1634
Training Epoch: 90 [24576/50176]	Loss: 0.1569
Training Epoch: 90 [25600/50176]	Loss: 0.1730
Training Epoch: 90 [26624/50176]	Loss: 0.1695
Training Epoch: 90 [27648/50176]	Loss: 0.1060
Training Epoch: 90 [28672/50176]	Loss: 0.1654
Training Epoch: 90 [29696/50176]	Loss: 0.1154
Training Epoch: 90 [30720/50176]	Loss: 0.1475
Training Epoch: 90 [31744/50176]	Loss: 0.1601
Training Epoch: 90 [32768/50176]	Loss: 0.1297
Training Epoch: 90 [33792/50176]	Loss: 0.1496
Training Epoch: 90 [34816/50176]	Loss: 0.1488
Training Epoch: 90 [35840/50176]	Loss: 0.1535
Training Epoch: 90 [36864/50176]	Loss: 0.1346
Training Epoch: 90 [37888/50176]	Loss: 0.1545
Training Epoch: 90 [38912/50176]	Loss: 0.1534
Training Epoch: 90 [39936/50176]	Loss: 0.1560
Training Epoch: 90 [40960/50176]	Loss: 0.1516
Training Epoch: 90 [41984/50176]	Loss: 0.1518
Training Epoch: 90 [43008/50176]	Loss: 0.1278
Training Epoch: 90 [44032/50176]	Loss: 0.1543
Training Epoch: 90 [45056/50176]	Loss: 0.1537
Training Epoch: 90 [46080/50176]	Loss: 0.1417
Training Epoch: 90 [47104/50176]	Loss: 0.1387
Training Epoch: 90 [48128/50176]	Loss: 0.1628
Training Epoch: 90 [49152/50176]	Loss: 0.1655
Training Epoch: 90 [50176/50176]	Loss: 0.1588
2022-12-06 16:24:26.097 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:24:26,108 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.65 energy=462.89
2022-12-06 11:24:26,109 [ZeusDataLoader(train)] Up to epoch 91: time=4370.77, energy=611039.99, cost=687962.42
2022-12-06 11:24:26,109 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:24:26,109 [ZeusDataLoader(train)] Expected next epoch: time=4417.22, energy=617648.62, cost=695330.67
2022-12-06 11:24:26,110 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 0.0028, Accuracy: 0.5503
2022-12-06 11:24:26,242 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:24:26,242 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:24:26.246 [ZeusMonitor] Monitor started.
2022-12-06 16:24:26.246 [ZeusMonitor] Running indefinitely. 2022-12-06 16:24:26.246 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:24:26.246 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e92+gpu0.power.log
2022-12-06 11:25:10,626 [ZeusDataLoader(train)] train epoch 92 done: time=44.51 energy=6334.37
2022-12-06 11:25:10,630 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 0.1428
Training Epoch: 91 [2048/50176]	Loss: 0.1431
Training Epoch: 91 [3072/50176]	Loss: 0.1401
Training Epoch: 91 [4096/50176]	Loss: 0.1222
Training Epoch: 91 [5120/50176]	Loss: 0.1233
Training Epoch: 91 [6144/50176]	Loss: 0.1258
Training Epoch: 91 [7168/50176]	Loss: 0.1336
Training Epoch: 91 [8192/50176]	Loss: 0.1209
Training Epoch: 91 [9216/50176]	Loss: 0.1308
Training Epoch: 91 [10240/50176]	Loss: 0.1284
Training Epoch: 91 [11264/50176]	Loss: 0.1280
Training Epoch: 91 [12288/50176]	Loss: 0.1377
Training Epoch: 91 [13312/50176]	Loss: 0.1465
Training Epoch: 91 [14336/50176]	Loss: 0.1336
Training Epoch: 91 [15360/50176]	Loss: 0.1352
Training Epoch: 91 [16384/50176]	Loss: 0.1338
Training Epoch: 91 [17408/50176]	Loss: 0.1319
Training Epoch: 91 [18432/50176]	Loss: 0.1426
Training Epoch: 91 [19456/50176]	Loss: 0.1423
Training Epoch: 91 [20480/50176]	Loss: 0.1584
Training Epoch: 91 [21504/50176]	Loss: 0.1451
Training Epoch: 91 [22528/50176]	Loss: 0.1210
Training Epoch: 91 [23552/50176]	Loss: 0.1437
Training Epoch: 91 [24576/50176]	Loss: 0.1345
Training Epoch: 91 [25600/50176]	Loss: 0.1392
Training Epoch: 91 [26624/50176]	Loss: 0.1316
Training Epoch: 91 [27648/50176]	Loss: 0.1164
Training Epoch: 91 [28672/50176]	Loss: 0.1360
Training Epoch: 91 [29696/50176]	Loss: 0.1574
Training Epoch: 91 [30720/50176]	Loss: 0.1510
Training Epoch: 91 [31744/50176]	Loss: 0.1299
Training Epoch: 91 [32768/50176]	Loss: 0.1446
Training Epoch: 91 [33792/50176]	Loss: 0.1300
Training Epoch: 91 [34816/50176]	Loss: 0.1499
Training Epoch: 91 [35840/50176]	Loss: 0.1120
Training Epoch: 91 [36864/50176]	Loss: 0.1578
Training Epoch: 91 [37888/50176]	Loss: 0.1488
Training Epoch: 91 [38912/50176]	Loss: 0.1556
Training Epoch: 91 [39936/50176]	Loss: 0.1454
Training Epoch: 91 [40960/50176]	Loss: 0.1620
Training Epoch: 91 [41984/50176]	Loss: 0.1593
Training Epoch: 91 [43008/50176]	Loss: 0.1779
Training Epoch: 91 [44032/50176]	Loss: 0.1457
Training Epoch: 91 [45056/50176]	Loss: 0.1303
Training Epoch: 91 [46080/50176]	Loss: 0.1478
Training Epoch: 91 [47104/50176]	Loss: 0.1364
Training Epoch: 91 [48128/50176]	Loss: 0.1472
Training Epoch: 91 [49152/50176]	Loss: 0.1433
Training Epoch: 91 [50176/50176]	Loss: 0.1509
2022-12-06 16:25:14.334 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:25:14,353 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.71 energy=485.26
2022-12-06 11:25:14,353 [ZeusDataLoader(train)] Up to epoch 92: time=4418.99, energy=617859.63, cost=695591.75
2022-12-06 11:25:14,353 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:25:14,353 [ZeusDataLoader(train)] Expected next epoch: time=4465.44, energy=624468.25, cost=702959.99
2022-12-06 11:25:14,354 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 0.0028, Accuracy: 0.5501
2022-12-06 11:25:14,533 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:25:14,533 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:25:14.541 [ZeusMonitor] Monitor started.
2022-12-06 16:25:14.541 [ZeusMonitor] Running indefinitely. 2022-12-06 16:25:14.541 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:25:14.542 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e93+gpu0.power.log
2022-12-06 11:25:58,807 [ZeusDataLoader(train)] train epoch 93 done: time=44.45 energy=6336.74
2022-12-06 11:25:58,812 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 0.1482
Training Epoch: 92 [2048/50176]	Loss: 0.1192
Training Epoch: 92 [3072/50176]	Loss: 0.1441
Training Epoch: 92 [4096/50176]	Loss: 0.1140
Training Epoch: 92 [5120/50176]	Loss: 0.1061
Training Epoch: 92 [6144/50176]	Loss: 0.1275
Training Epoch: 92 [7168/50176]	Loss: 0.1246
Training Epoch: 92 [8192/50176]	Loss: 0.1168
Training Epoch: 92 [9216/50176]	Loss: 0.1507
Training Epoch: 92 [10240/50176]	Loss: 0.1270
Training Epoch: 92 [11264/50176]	Loss: 0.1288
Training Epoch: 92 [12288/50176]	Loss: 0.1293
Training Epoch: 92 [13312/50176]	Loss: 0.1223
Training Epoch: 92 [14336/50176]	Loss: 0.1651
Training Epoch: 92 [15360/50176]	Loss: 0.1284
Training Epoch: 92 [16384/50176]	Loss: 0.1289
Training Epoch: 92 [17408/50176]	Loss: 0.1474
Training Epoch: 92 [18432/50176]	Loss: 0.1628
Training Epoch: 92 [19456/50176]	Loss: 0.1305
Training Epoch: 92 [20480/50176]	Loss: 0.1127
Training Epoch: 92 [21504/50176]	Loss: 0.1617
Training Epoch: 92 [22528/50176]	Loss: 0.1313
Training Epoch: 92 [23552/50176]	Loss: 0.1497
Training Epoch: 92 [24576/50176]	Loss: 0.1329
Training Epoch: 92 [25600/50176]	Loss: 0.1594
Training Epoch: 92 [26624/50176]	Loss: 0.1661
Training Epoch: 92 [27648/50176]	Loss: 0.1436
Training Epoch: 92 [28672/50176]	Loss: 0.1364
Training Epoch: 92 [29696/50176]	Loss: 0.1179
Training Epoch: 92 [30720/50176]	Loss: 0.1599
Training Epoch: 92 [31744/50176]	Loss: 0.1482
Training Epoch: 92 [32768/50176]	Loss: 0.1412
Training Epoch: 92 [33792/50176]	Loss: 0.1376
Training Epoch: 92 [34816/50176]	Loss: 0.1217
Training Epoch: 92 [35840/50176]	Loss: 0.1676
Training Epoch: 92 [36864/50176]	Loss: 0.1699
Training Epoch: 92 [37888/50176]	Loss: 0.1527
Training Epoch: 92 [38912/50176]	Loss: 0.1714
Training Epoch: 92 [39936/50176]	Loss: 0.1330
Training Epoch: 92 [40960/50176]	Loss: 0.1555
Training Epoch: 92 [41984/50176]	Loss: 0.1431
Training Epoch: 92 [43008/50176]	Loss: 0.1495
Training Epoch: 92 [44032/50176]	Loss: 0.1440
Training Epoch: 92 [45056/50176]	Loss: 0.1492
Training Epoch: 92 [46080/50176]	Loss: 0.1617
Training Epoch: 92 [47104/50176]	Loss: 0.1684
Training Epoch: 92 [48128/50176]	Loss: 0.1432
Training Epoch: 92 [49152/50176]	Loss: 0.1380
Training Epoch: 92 [50176/50176]	Loss: 0.1553
2022-12-06 16:26:02.470 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:26:02,489 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.67 energy=468.81
2022-12-06 11:26:02,490 [ZeusDataLoader(train)] Up to epoch 93: time=4467.11, energy=624665.17, cost=703204.62
2022-12-06 11:26:02,490 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:26:02,490 [ZeusDataLoader(train)] Expected next epoch: time=4513.55, energy=631273.80, cost=710572.87
2022-12-06 11:26:02,491 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0028, Accuracy: 0.5527
2022-12-06 11:26:02,666 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:26:02,667 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:26:02.676 [ZeusMonitor] Monitor started.
2022-12-06 16:26:02.677 [ZeusMonitor] Running indefinitely. 2022-12-06 16:26:02.677 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:26:02.677 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e94+gpu0.power.log
2022-12-06 11:26:47,337 [ZeusDataLoader(train)] train epoch 94 done: time=44.84 energy=6363.71
2022-12-06 11:26:47,340 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 0.1138
Training Epoch: 93 [2048/50176]	Loss: 0.1393
Training Epoch: 93 [3072/50176]	Loss: 0.1365
Training Epoch: 93 [4096/50176]	Loss: 0.1567
Training Epoch: 93 [5120/50176]	Loss: 0.1328
Training Epoch: 93 [6144/50176]	Loss: 0.1181
Training Epoch: 93 [7168/50176]	Loss: 0.1169
Training Epoch: 93 [8192/50176]	Loss: 0.1319
Training Epoch: 93 [9216/50176]	Loss: 0.1267
Training Epoch: 93 [10240/50176]	Loss: 0.1134
Training Epoch: 93 [11264/50176]	Loss: 0.1114
Training Epoch: 93 [12288/50176]	Loss: 0.1409
Training Epoch: 93 [13312/50176]	Loss: 0.1316
Training Epoch: 93 [14336/50176]	Loss: 0.1498
Training Epoch: 93 [15360/50176]	Loss: 0.1199
Training Epoch: 93 [16384/50176]	Loss: 0.1229
Training Epoch: 93 [17408/50176]	Loss: 0.1321
Training Epoch: 93 [18432/50176]	Loss: 0.1453
Training Epoch: 93 [19456/50176]	Loss: 0.1397
Training Epoch: 93 [20480/50176]	Loss: 0.1477
Training Epoch: 93 [21504/50176]	Loss: 0.1555
Training Epoch: 93 [22528/50176]	Loss: 0.1247
Training Epoch: 93 [23552/50176]	Loss: 0.1529
Training Epoch: 93 [24576/50176]	Loss: 0.1533
Training Epoch: 93 [25600/50176]	Loss: 0.1411
Training Epoch: 93 [26624/50176]	Loss: 0.1597
Training Epoch: 93 [27648/50176]	Loss: 0.1157
Training Epoch: 93 [28672/50176]	Loss: 0.1326
Training Epoch: 93 [29696/50176]	Loss: 0.1621
Training Epoch: 93 [30720/50176]	Loss: 0.1421
Training Epoch: 93 [31744/50176]	Loss: 0.1218
Training Epoch: 93 [32768/50176]	Loss: 0.1400
Training Epoch: 93 [33792/50176]	Loss: 0.1581
Training Epoch: 93 [34816/50176]	Loss: 0.1449
Training Epoch: 93 [35840/50176]	Loss: 0.1455
Training Epoch: 93 [36864/50176]	Loss: 0.1473
Training Epoch: 93 [37888/50176]	Loss: 0.1308
Training Epoch: 93 [38912/50176]	Loss: 0.1393
Training Epoch: 93 [39936/50176]	Loss: 0.1808
Training Epoch: 93 [40960/50176]	Loss: 0.1443
Training Epoch: 93 [41984/50176]	Loss: 0.1712
Training Epoch: 93 [43008/50176]	Loss: 0.1617
Training Epoch: 93 [44032/50176]	Loss: 0.1788
Training Epoch: 93 [45056/50176]	Loss: 0.1459
Training Epoch: 93 [46080/50176]	Loss: 0.1396
Training Epoch: 93 [47104/50176]	Loss: 0.1349
Training Epoch: 93 [48128/50176]	Loss: 0.1229
Training Epoch: 93 [49152/50176]	Loss: 0.1453
Training Epoch: 93 [50176/50176]	Loss: 0.1495
2022-12-06 16:26:51.111 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:26:51,123 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.77 energy=473.66
2022-12-06 11:26:51,123 [ZeusDataLoader(train)] Up to epoch 94: time=4515.72, energy=631502.54, cost=710876.93
2022-12-06 11:26:51,123 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:26:51,124 [ZeusDataLoader(train)] Expected next epoch: time=4562.17, energy=638111.16, cost=718245.17
2022-12-06 11:26:51,125 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 0.0028, Accuracy: 0.5549
2022-12-06 11:26:51,311 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:26:51,312 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:26:51.314 [ZeusMonitor] Monitor started.
2022-12-06 16:26:51.314 [ZeusMonitor] Running indefinitely. 2022-12-06 16:26:51.314 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:26:51.314 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e95+gpu0.power.log
2022-12-06 11:27:35,788 [ZeusDataLoader(train)] train epoch 95 done: time=44.66 energy=6359.72
2022-12-06 11:27:35,791 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 0.1144
Training Epoch: 94 [2048/50176]	Loss: 0.1512
Training Epoch: 94 [3072/50176]	Loss: 0.1130
Training Epoch: 94 [4096/50176]	Loss: 0.1355
Training Epoch: 94 [5120/50176]	Loss: 0.1359
Training Epoch: 94 [6144/50176]	Loss: 0.1404
Training Epoch: 94 [7168/50176]	Loss: 0.1412
Training Epoch: 94 [8192/50176]	Loss: 0.1293
Training Epoch: 94 [9216/50176]	Loss: 0.1451
Training Epoch: 94 [10240/50176]	Loss: 0.1488
Training Epoch: 94 [11264/50176]	Loss: 0.1132
Training Epoch: 94 [12288/50176]	Loss: 0.1101
Training Epoch: 94 [13312/50176]	Loss: 0.1348
Training Epoch: 94 [14336/50176]	Loss: 0.1477
Training Epoch: 94 [15360/50176]	Loss: 0.1316
Training Epoch: 94 [16384/50176]	Loss: 0.1429
Training Epoch: 94 [17408/50176]	Loss: 0.1353
Training Epoch: 94 [18432/50176]	Loss: 0.1542
Training Epoch: 94 [19456/50176]	Loss: 0.1250
Training Epoch: 94 [20480/50176]	Loss: 0.1356
Training Epoch: 94 [21504/50176]	Loss: 0.1127
Training Epoch: 94 [22528/50176]	Loss: 0.1643
Training Epoch: 94 [23552/50176]	Loss: 0.1341
Training Epoch: 94 [24576/50176]	Loss: 0.1350
Training Epoch: 94 [25600/50176]	Loss: 0.1252
Training Epoch: 94 [26624/50176]	Loss: 0.1586
Training Epoch: 94 [27648/50176]	Loss: 0.1353
Training Epoch: 94 [28672/50176]	Loss: 0.1081
Training Epoch: 94 [29696/50176]	Loss: 0.1071
Training Epoch: 94 [30720/50176]	Loss: 0.1643
Training Epoch: 94 [31744/50176]	Loss: 0.1526
Training Epoch: 94 [32768/50176]	Loss: 0.1312
Training Epoch: 94 [33792/50176]	Loss: 0.1183
Training Epoch: 94 [34816/50176]	Loss: 0.1318
Training Epoch: 94 [35840/50176]	Loss: 0.1324
Training Epoch: 94 [36864/50176]	Loss: 0.1355
Training Epoch: 94 [37888/50176]	Loss: 0.1182
Training Epoch: 94 [38912/50176]	Loss: 0.1333
Training Epoch: 94 [39936/50176]	Loss: 0.1548
Training Epoch: 94 [40960/50176]	Loss: 0.1381
Training Epoch: 94 [41984/50176]	Loss: 0.1491
Training Epoch: 94 [43008/50176]	Loss: 0.1656
Training Epoch: 94 [44032/50176]	Loss: 0.1565
Training Epoch: 94 [45056/50176]	Loss: 0.1572
Training Epoch: 94 [46080/50176]	Loss: 0.1673
Training Epoch: 94 [47104/50176]	Loss: 0.1380
Training Epoch: 94 [48128/50176]	Loss: 0.1570
Training Epoch: 94 [49152/50176]	Loss: 0.1250
Training Epoch: 94 [50176/50176]	Loss: 0.1716
2022-12-06 16:27:39.508 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:27:39,529 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.73 energy=474.03
2022-12-06 11:27:39,530 [ZeusDataLoader(train)] Up to epoch 95: time=4564.11, energy=638336.30, cost=718527.56
2022-12-06 11:27:39,530 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:27:39,530 [ZeusDataLoader(train)] Expected next epoch: time=4610.55, energy=644944.92, cost=725895.80
2022-12-06 11:27:39,531 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 0.0028, Accuracy: 0.5515
2022-12-06 11:27:39,711 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:27:39,712 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:27:39.713 [ZeusMonitor] Monitor started.
2022-12-06 16:27:39.713 [ZeusMonitor] Running indefinitely. 2022-12-06 16:27:39.713 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:27:39.713 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e96+gpu0.power.log
2022-12-06 11:28:24,151 [ZeusDataLoader(train)] train epoch 96 done: time=44.61 energy=6340.62
2022-12-06 11:28:24,154 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 0.1016
Training Epoch: 95 [2048/50176]	Loss: 0.1123
Training Epoch: 95 [3072/50176]	Loss: 0.1204
Training Epoch: 95 [4096/50176]	Loss: 0.1285
Training Epoch: 95 [5120/50176]	Loss: 0.1200
Training Epoch: 95 [6144/50176]	Loss: 0.1312
Training Epoch: 95 [7168/50176]	Loss: 0.1461
Training Epoch: 95 [8192/50176]	Loss: 0.1540
Training Epoch: 95 [9216/50176]	Loss: 0.1371
Training Epoch: 95 [10240/50176]	Loss: 0.1332
Training Epoch: 95 [11264/50176]	Loss: 0.1363
Training Epoch: 95 [12288/50176]	Loss: 0.1383
Training Epoch: 95 [13312/50176]	Loss: 0.1399
Training Epoch: 95 [14336/50176]	Loss: 0.1396
Training Epoch: 95 [15360/50176]	Loss: 0.1434
Training Epoch: 95 [16384/50176]	Loss: 0.1652
Training Epoch: 95 [17408/50176]	Loss: 0.1087
Training Epoch: 95 [18432/50176]	Loss: 0.1256
Training Epoch: 95 [19456/50176]	Loss: 0.1441
Training Epoch: 95 [20480/50176]	Loss: 0.1220
Training Epoch: 95 [21504/50176]	Loss: 0.1218
Training Epoch: 95 [22528/50176]	Loss: 0.1381
Training Epoch: 95 [23552/50176]	Loss: 0.1173
Training Epoch: 95 [24576/50176]	Loss: 0.1420
Training Epoch: 95 [25600/50176]	Loss: 0.1359
Training Epoch: 95 [26624/50176]	Loss: 0.1325
Training Epoch: 95 [27648/50176]	Loss: 0.1148
Training Epoch: 95 [28672/50176]	Loss: 0.1103
Training Epoch: 95 [29696/50176]	Loss: 0.1499
Training Epoch: 95 [30720/50176]	Loss: 0.1298
Training Epoch: 95 [31744/50176]	Loss: 0.1473
Training Epoch: 95 [32768/50176]	Loss: 0.1428
Training Epoch: 95 [33792/50176]	Loss: 0.1340
Training Epoch: 95 [34816/50176]	Loss: 0.1317
Training Epoch: 95 [35840/50176]	Loss: 0.1432
Training Epoch: 95 [36864/50176]	Loss: 0.1450
Training Epoch: 95 [37888/50176]	Loss: 0.1325
Training Epoch: 95 [38912/50176]	Loss: 0.1310
Training Epoch: 95 [39936/50176]	Loss: 0.1267
Training Epoch: 95 [40960/50176]	Loss: 0.1570
Training Epoch: 95 [41984/50176]	Loss: 0.1765
Training Epoch: 95 [43008/50176]	Loss: 0.1343
Training Epoch: 95 [44032/50176]	Loss: 0.1498
Training Epoch: 95 [45056/50176]	Loss: 0.1302
Training Epoch: 95 [46080/50176]	Loss: 0.1311
Training Epoch: 95 [47104/50176]	Loss: 0.1433
Training Epoch: 95 [48128/50176]	Loss: 0.1564
Training Epoch: 95 [49152/50176]	Loss: 0.1519
Training Epoch: 95 [50176/50176]	Loss: 0.1173
2022-12-06 16:28:27.889 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:28:27,927 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.76 energy=477.49
2022-12-06 11:28:27,927 [ZeusDataLoader(train)] Up to epoch 96: time=4612.48, energy=645154.42, cost=726169.64
2022-12-06 11:28:27,928 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:28:27,928 [ZeusDataLoader(train)] Expected next epoch: time=4658.93, energy=651763.04, cost=733537.89
2022-12-06 11:28:27,929 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 0.0028, Accuracy: 0.5516
2022-12-06 11:28:28,110 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:28:28,111 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:28:28.113 [ZeusMonitor] Monitor started.
2022-12-06 16:28:28.113 [ZeusMonitor] Running indefinitely. 2022-12-06 16:28:28.113 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:28:28.113 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e97+gpu0.power.log
2022-12-06 11:29:12,440 [ZeusDataLoader(train)] train epoch 97 done: time=44.50 energy=6330.97
2022-12-06 11:29:12,444 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 0.1180
Training Epoch: 96 [2048/50176]	Loss: 0.1137
Training Epoch: 96 [3072/50176]	Loss: 0.1110
Training Epoch: 96 [4096/50176]	Loss: 0.0894
Training Epoch: 96 [5120/50176]	Loss: 0.1346
Training Epoch: 96 [6144/50176]	Loss: 0.1474
Training Epoch: 96 [7168/50176]	Loss: 0.1361
Training Epoch: 96 [8192/50176]	Loss: 0.1331
Training Epoch: 96 [9216/50176]	Loss: 0.1380
Training Epoch: 96 [10240/50176]	Loss: 0.1116
Training Epoch: 96 [11264/50176]	Loss: 0.1148
Training Epoch: 96 [12288/50176]	Loss: 0.1228
Training Epoch: 96 [13312/50176]	Loss: 0.1055
Training Epoch: 96 [14336/50176]	Loss: 0.1195
Training Epoch: 96 [15360/50176]	Loss: 0.1485
Training Epoch: 96 [16384/50176]	Loss: 0.1208
Training Epoch: 96 [17408/50176]	Loss: 0.1463
Training Epoch: 96 [18432/50176]	Loss: 0.1212
Training Epoch: 96 [19456/50176]	Loss: 0.1268
Training Epoch: 96 [20480/50176]	Loss: 0.1209
Training Epoch: 96 [21504/50176]	Loss: 0.1497
Training Epoch: 96 [22528/50176]	Loss: 0.1379
Training Epoch: 96 [23552/50176]	Loss: 0.1407
Training Epoch: 96 [24576/50176]	Loss: 0.1371
Training Epoch: 96 [25600/50176]	Loss: 0.1603
Training Epoch: 96 [26624/50176]	Loss: 0.1105
Training Epoch: 96 [27648/50176]	Loss: 0.1460
Training Epoch: 96 [28672/50176]	Loss: 0.1551
Training Epoch: 96 [29696/50176]	Loss: 0.1281
Training Epoch: 96 [30720/50176]	Loss: 0.1322
Training Epoch: 96 [31744/50176]	Loss: 0.1247
Training Epoch: 96 [32768/50176]	Loss: 0.1180
Training Epoch: 96 [33792/50176]	Loss: 0.1252
Training Epoch: 96 [34816/50176]	Loss: 0.1752
Training Epoch: 96 [35840/50176]	Loss: 0.1436
Training Epoch: 96 [36864/50176]	Loss: 0.1102
Training Epoch: 96 [37888/50176]	Loss: 0.1715
Training Epoch: 96 [38912/50176]	Loss: 0.1095
Training Epoch: 96 [39936/50176]	Loss: 0.1319
Training Epoch: 96 [40960/50176]	Loss: 0.1157
Training Epoch: 96 [41984/50176]	Loss: 0.1366
Training Epoch: 96 [43008/50176]	Loss: 0.1470
Training Epoch: 96 [44032/50176]	Loss: 0.1289
Training Epoch: 96 [45056/50176]	Loss: 0.1496
Training Epoch: 96 [46080/50176]	Loss: 0.1281
Training Epoch: 96 [47104/50176]	Loss: 0.1737
Training Epoch: 96 [48128/50176]	Loss: 0.1354
Training Epoch: 96 [49152/50176]	Loss: 0.1347
Training Epoch: 96 [50176/50176]	Loss: 0.1681
2022-12-06 16:29:16.142 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:29:16,152 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.70 energy=475.42
2022-12-06 11:29:16,153 [ZeusDataLoader(train)] Up to epoch 97: time=4660.69, energy=651960.81, cost=733790.77
2022-12-06 11:29:16,153 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:29:16,153 [ZeusDataLoader(train)] Expected next epoch: time=4707.13, energy=658569.43, cost=741159.02
2022-12-06 11:29:16,154 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 0.0029, Accuracy: 0.5473
2022-12-06 11:29:16,331 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:29:16,331 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:29:16.333 [ZeusMonitor] Monitor started.
2022-12-06 16:29:16.333 [ZeusMonitor] Running indefinitely. 2022-12-06 16:29:16.333 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:29:16.333 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e98+gpu0.power.log
2022-12-06 11:30:00,585 [ZeusDataLoader(train)] train epoch 98 done: time=44.42 energy=6324.70
2022-12-06 11:30:00,588 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 0.1139
Training Epoch: 97 [2048/50176]	Loss: 0.1241
Training Epoch: 97 [3072/50176]	Loss: 0.1005
Training Epoch: 97 [4096/50176]	Loss: 0.1255
Training Epoch: 97 [5120/50176]	Loss: 0.1407
Training Epoch: 97 [6144/50176]	Loss: 0.1129
Training Epoch: 97 [7168/50176]	Loss: 0.1461
Training Epoch: 97 [8192/50176]	Loss: 0.1312
Training Epoch: 97 [9216/50176]	Loss: 0.1358
Training Epoch: 97 [10240/50176]	Loss: 0.1376
Training Epoch: 97 [11264/50176]	Loss: 0.1366
Training Epoch: 97 [12288/50176]	Loss: 0.1110
Training Epoch: 97 [13312/50176]	Loss: 0.1243
Training Epoch: 97 [14336/50176]	Loss: 0.1100
Training Epoch: 97 [15360/50176]	Loss: 0.1195
Training Epoch: 97 [16384/50176]	Loss: 0.1308
Training Epoch: 97 [17408/50176]	Loss: 0.1021
Training Epoch: 97 [18432/50176]	Loss: 0.1399
Training Epoch: 97 [19456/50176]	Loss: 0.1404
Training Epoch: 97 [20480/50176]	Loss: 0.1048
Training Epoch: 97 [21504/50176]	Loss: 0.1203
Training Epoch: 97 [22528/50176]	Loss: 0.1261
Training Epoch: 97 [23552/50176]	Loss: 0.1413
Training Epoch: 97 [24576/50176]	Loss: 0.1268
Training Epoch: 97 [25600/50176]	Loss: 0.1343
Training Epoch: 97 [26624/50176]	Loss: 0.1061
Training Epoch: 97 [27648/50176]	Loss: 0.1384
Training Epoch: 97 [28672/50176]	Loss: 0.1392
Training Epoch: 97 [29696/50176]	Loss: 0.1456
Training Epoch: 97 [30720/50176]	Loss: 0.1202
Training Epoch: 97 [31744/50176]	Loss: 0.1158
Training Epoch: 97 [32768/50176]	Loss: 0.1319
Training Epoch: 97 [33792/50176]	Loss: 0.1274
Training Epoch: 97 [34816/50176]	Loss: 0.1402
Training Epoch: 97 [35840/50176]	Loss: 0.1387
Training Epoch: 97 [36864/50176]	Loss: 0.1261
Training Epoch: 97 [37888/50176]	Loss: 0.1325
Training Epoch: 97 [38912/50176]	Loss: 0.1360
Training Epoch: 97 [39936/50176]	Loss: 0.1290
Training Epoch: 97 [40960/50176]	Loss: 0.1419
Training Epoch: 97 [41984/50176]	Loss: 0.1373
Training Epoch: 97 [43008/50176]	Loss: 0.1309
Training Epoch: 97 [44032/50176]	Loss: 0.1516
Training Epoch: 97 [45056/50176]	Loss: 0.1488
Training Epoch: 97 [46080/50176]	Loss: 0.1316
Training Epoch: 97 [47104/50176]	Loss: 0.1370
Training Epoch: 97 [48128/50176]	Loss: 0.1269
Training Epoch: 97 [49152/50176]	Loss: 0.1277
Training Epoch: 97 [50176/50176]	Loss: 0.1436
2022-12-06 16:30:04.291 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:30:04,308 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.71 energy=486.52
2022-12-06 11:30:04,308 [ZeusDataLoader(train)] Up to epoch 98: time=4708.82, energy=658772.02, cost=741408.19
2022-12-06 11:30:04,308 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:30:04,308 [ZeusDataLoader(train)] Expected next epoch: time=4755.27, energy=665380.65, cost=748776.44
2022-12-06 11:30:04,309 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0029, Accuracy: 0.5549
2022-12-06 11:30:04,479 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:30:04,480 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:30:04.482 [ZeusMonitor] Monitor started.
2022-12-06 16:30:04.482 [ZeusMonitor] Running indefinitely. 2022-12-06 16:30:04.482 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:30:04.482 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e99+gpu0.power.log
2022-12-06 11:30:49,337 [ZeusDataLoader(train)] train epoch 99 done: time=45.02 energy=6373.42
2022-12-06 11:30:49,340 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 0.0929
Training Epoch: 98 [2048/50176]	Loss: 0.1069
Training Epoch: 98 [3072/50176]	Loss: 0.1063
Training Epoch: 98 [4096/50176]	Loss: 0.1241
Training Epoch: 98 [5120/50176]	Loss: 0.1297
Training Epoch: 98 [6144/50176]	Loss: 0.1201
Training Epoch: 98 [7168/50176]	Loss: 0.1082
Training Epoch: 98 [8192/50176]	Loss: 0.1306
Training Epoch: 98 [9216/50176]	Loss: 0.1183
Training Epoch: 98 [10240/50176]	Loss: 0.1262
Training Epoch: 98 [11264/50176]	Loss: 0.1320
Training Epoch: 98 [12288/50176]	Loss: 0.1110
Training Epoch: 98 [13312/50176]	Loss: 0.1166
Training Epoch: 98 [14336/50176]	Loss: 0.1172
Training Epoch: 98 [15360/50176]	Loss: 0.1171
Training Epoch: 98 [16384/50176]	Loss: 0.1224
Training Epoch: 98 [17408/50176]	Loss: 0.1301
Training Epoch: 98 [18432/50176]	Loss: 0.1413
Training Epoch: 98 [19456/50176]	Loss: 0.1548
Training Epoch: 98 [20480/50176]	Loss: 0.1338
Training Epoch: 98 [21504/50176]	Loss: 0.1012
Training Epoch: 98 [22528/50176]	Loss: 0.1324
Training Epoch: 98 [23552/50176]	Loss: 0.1235
Training Epoch: 98 [24576/50176]	Loss: 0.1349
Training Epoch: 98 [25600/50176]	Loss: 0.1560
Training Epoch: 98 [26624/50176]	Loss: 0.1142
Training Epoch: 98 [27648/50176]	Loss: 0.1240
Training Epoch: 98 [28672/50176]	Loss: 0.1340
Training Epoch: 98 [29696/50176]	Loss: 0.1095
Training Epoch: 98 [30720/50176]	Loss: 0.1253
Training Epoch: 98 [31744/50176]	Loss: 0.1385
Training Epoch: 98 [32768/50176]	Loss: 0.1275
Training Epoch: 98 [33792/50176]	Loss: 0.1206
Training Epoch: 98 [34816/50176]	Loss: 0.1171
Training Epoch: 98 [35840/50176]	Loss: 0.1172
Training Epoch: 98 [36864/50176]	Loss: 0.1346
Training Epoch: 98 [37888/50176]	Loss: 0.1604
Training Epoch: 98 [38912/50176]	Loss: 0.1321
Training Epoch: 98 [39936/50176]	Loss: 0.1380
Training Epoch: 98 [40960/50176]	Loss: 0.1241
Training Epoch: 98 [41984/50176]	Loss: 0.1455
Training Epoch: 98 [43008/50176]	Loss: 0.1554
Training Epoch: 98 [44032/50176]	Loss: 0.1272
Training Epoch: 98 [45056/50176]	Loss: 0.1147
Training Epoch: 98 [46080/50176]	Loss: 0.1301
Training Epoch: 98 [47104/50176]	Loss: 0.1376
Training Epoch: 98 [48128/50176]	Loss: 0.1548
Training Epoch: 98 [49152/50176]	Loss: 0.1321
Training Epoch: 98 [50176/50176]	Loss: 0.1327
2022-12-06 16:30:53.160 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:30:53,217 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.87 energy=484.12
2022-12-06 11:30:53,217 [ZeusDataLoader(train)] Up to epoch 99: time=4757.71, energy=665629.56, cost=749114.77
2022-12-06 11:30:53,218 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:30:53,218 [ZeusDataLoader(train)] Expected next epoch: time=4804.16, energy=672238.19, cost=756483.02
2022-12-06 11:30:53,219 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0028, Accuracy: 0.5547
2022-12-06 11:30:53,399 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:30:53,400 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:30:53.402 [ZeusMonitor] Monitor started.
2022-12-06 16:30:53.402 [ZeusMonitor] Running indefinitely. 2022-12-06 16:30:53.402 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:30:53.402 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e100+gpu0.power.log
2022-12-06 11:31:38,123 [ZeusDataLoader(train)] train epoch 100 done: time=44.90 energy=6355.07
2022-12-06 11:31:38,126 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 0.1012
Training Epoch: 99 [2048/50176]	Loss: 0.0925
Training Epoch: 99 [3072/50176]	Loss: 0.1088
Training Epoch: 99 [4096/50176]	Loss: 0.1356
Training Epoch: 99 [5120/50176]	Loss: 0.0931
Training Epoch: 99 [6144/50176]	Loss: 0.1156
Training Epoch: 99 [7168/50176]	Loss: 0.1161
Training Epoch: 99 [8192/50176]	Loss: 0.1077
Training Epoch: 99 [9216/50176]	Loss: 0.1072
Training Epoch: 99 [10240/50176]	Loss: 0.1162
Training Epoch: 99 [11264/50176]	Loss: 0.1088
Training Epoch: 99 [12288/50176]	Loss: 0.1405
Training Epoch: 99 [13312/50176]	Loss: 0.1150
Training Epoch: 99 [14336/50176]	Loss: 0.0996
Training Epoch: 99 [15360/50176]	Loss: 0.1161
Training Epoch: 99 [16384/50176]	Loss: 0.1035
Training Epoch: 99 [17408/50176]	Loss: 0.1237
Training Epoch: 99 [18432/50176]	Loss: 0.1294
Training Epoch: 99 [19456/50176]	Loss: 0.0982
Training Epoch: 99 [20480/50176]	Loss: 0.1223
Training Epoch: 99 [21504/50176]	Loss: 0.1241
Training Epoch: 99 [22528/50176]	Loss: 0.1076
Training Epoch: 99 [23552/50176]	Loss: 0.1119
Training Epoch: 99 [24576/50176]	Loss: 0.1137
Training Epoch: 99 [25600/50176]	Loss: 0.1235
Training Epoch: 99 [26624/50176]	Loss: 0.1136
Training Epoch: 99 [27648/50176]	Loss: 0.1127
Training Epoch: 99 [28672/50176]	Loss: 0.1100
Training Epoch: 99 [29696/50176]	Loss: 0.1215
Training Epoch: 99 [30720/50176]	Loss: 0.1161
Training Epoch: 99 [31744/50176]	Loss: 0.1169
Training Epoch: 99 [32768/50176]	Loss: 0.1289
Training Epoch: 99 [33792/50176]	Loss: 0.1171
Training Epoch: 99 [34816/50176]	Loss: 0.1248
Training Epoch: 99 [35840/50176]	Loss: 0.1316
Training Epoch: 99 [36864/50176]	Loss: 0.1196
Training Epoch: 99 [37888/50176]	Loss: 0.1130
Training Epoch: 99 [38912/50176]	Loss: 0.1183
Training Epoch: 99 [39936/50176]	Loss: 0.1127
Training Epoch: 99 [40960/50176]	Loss: 0.1050
Training Epoch: 99 [41984/50176]	Loss: 0.1155
Training Epoch: 99 [43008/50176]	Loss: 0.1394
Training Epoch: 99 [44032/50176]	Loss: 0.1468
Training Epoch: 99 [45056/50176]	Loss: 0.1409
Training Epoch: 99 [46080/50176]	Loss: 0.1229
Training Epoch: 99 [47104/50176]	Loss: 0.1234
Training Epoch: 99 [48128/50176]	Loss: 0.1289
Training Epoch: 99 [49152/50176]	Loss: 0.1441
Training Epoch: 99 [50176/50176]	Loss: 0.1442
2022-12-06 16:31:41.820 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:31:41,837 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.70 energy=477.65
2022-12-06 11:31:41,837 [ZeusDataLoader(train)] Up to epoch 100: time=4806.31, energy=672462.27, cost=756783.64
2022-12-06 11:31:41,837 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-06 11:31:41,838 [ZeusDataLoader(train)] Training done.
2022-12-06 11:31:41,838 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/rec00+try01+bs1024+lr0.0010000.train.json: {"energy": 672462.2731224052, "time": 4806.314337210996, "cost": 756783.6410671647, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 0.0029, Accuracy: 0.5540
