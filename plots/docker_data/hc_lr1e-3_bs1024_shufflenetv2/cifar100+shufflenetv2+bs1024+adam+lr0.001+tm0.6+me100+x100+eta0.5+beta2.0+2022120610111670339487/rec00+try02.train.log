2022-12-06 11:31:47,954 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 11:31:47,954 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 11:31:47,954 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 11:31:47,995 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 11:31:47,995 [ZeusDataLoader(train)] Power profiling: OFF
2022-12-06 11:31:47,995 [ZeusDataLoader(train)] Loaded /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+lr0.0010000.power.json: {'job_id': 'rec00+try01', 'train_power': {'175000': 143.7756220422888, '150000': 143.40712738575323, '125000': 122.48868740045154, '100000': 96.72232362161922}, 'train_throughput': {'175000': 1.1470109333913145, '150000': 1.1409906882244738, '125000': 1.0501037720271307, '100000': 0.624481141380321}, 'eval_power': {'175000': 125.24703968117582, '150000': 125.36180693481519, '125000': 112.75230768170896}, 'eval_throughput': {'175000': 2.684416650194901, '150000': 2.6670077798065, '125000': 2.568989803717995}, 'optimal_pl': 175000}
2022-12-06 11:31:47,995 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 11:31:47,999 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 11:31:50,046 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 11:31:50,047 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 11:31:50,258 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:31:50,259 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:31:50.261 [ZeusMonitor] Monitor started.
2022-12-06 16:31:50.261 [ZeusMonitor] Running indefinitely. 2022-12-06 16:31:50.261 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:31:50.261 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e1+gpu0.power.log
2022-12-06 11:32:35,524 [ZeusDataLoader(train)] train epoch 1 done: time=45.47 energy=6356.76
2022-12-06 11:32:35,527 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 4.6455
Training Epoch: 0 [3072/50176]	Loss: 4.6298
Training Epoch: 0 [4096/50176]	Loss: 4.6005
Training Epoch: 0 [5120/50176]	Loss: 4.5609
Training Epoch: 0 [6144/50176]	Loss: 4.5394
Training Epoch: 0 [7168/50176]	Loss: 4.5746
Training Epoch: 0 [8192/50176]	Loss: 4.5532
Training Epoch: 0 [9216/50176]	Loss: 4.5374
Training Epoch: 0 [10240/50176]	Loss: 4.5369
Training Epoch: 0 [11264/50176]	Loss: 4.4908
Training Epoch: 0 [12288/50176]	Loss: 4.4987
Training Epoch: 0 [13312/50176]	Loss: 4.4565
Training Epoch: 0 [14336/50176]	Loss: 4.4504
Training Epoch: 0 [15360/50176]	Loss: 4.4228
Training Epoch: 0 [16384/50176]	Loss: 4.4171
Training Epoch: 0 [17408/50176]	Loss: 4.4239
Training Epoch: 0 [18432/50176]	Loss: 4.4170
Training Epoch: 0 [19456/50176]	Loss: 4.3503
Training Epoch: 0 [20480/50176]	Loss: 4.3215
Training Epoch: 0 [21504/50176]	Loss: 4.3190
Training Epoch: 0 [22528/50176]	Loss: 4.2946
Training Epoch: 0 [23552/50176]	Loss: 4.2681
Training Epoch: 0 [24576/50176]	Loss: 4.2728
Training Epoch: 0 [25600/50176]	Loss: 4.2487
Training Epoch: 0 [26624/50176]	Loss: 4.1941
Training Epoch: 0 [27648/50176]	Loss: 4.2016
Training Epoch: 0 [28672/50176]	Loss: 4.1091
Training Epoch: 0 [29696/50176]	Loss: 4.1755
Training Epoch: 0 [30720/50176]	Loss: 4.1756
Training Epoch: 0 [31744/50176]	Loss: 4.1736
Training Epoch: 0 [32768/50176]	Loss: 4.0967
Training Epoch: 0 [33792/50176]	Loss: 4.0965
Training Epoch: 0 [34816/50176]	Loss: 4.1013
Training Epoch: 0 [35840/50176]	Loss: 4.0565
Training Epoch: 0 [36864/50176]	Loss: 4.0162
Training Epoch: 0 [37888/50176]	Loss: 4.0570
Training Epoch: 0 [38912/50176]	Loss: 4.0059
Training Epoch: 0 [39936/50176]	Loss: 3.9932
Training Epoch: 0 [40960/50176]	Loss: 3.9546
Training Epoch: 0 [41984/50176]	Loss: 3.9573
Training Epoch: 0 [43008/50176]	Loss: 4.0899
Training Epoch: 0 [44032/50176]	Loss: 3.8921
Training Epoch: 0 [45056/50176]	Loss: 3.9747
Training Epoch: 0 [46080/50176]	Loss: 3.9437
Training Epoch: 0 [47104/50176]	Loss: 3.9465
Training Epoch: 0 [48128/50176]	Loss: 3.9054
Training Epoch: 0 [49152/50176]	Loss: 3.9545
Training Epoch: 0 [50176/50176]	Loss: 3.8659
2022-12-06 16:32:39.558 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:32:39,611 [ZeusDataLoader(eval)] eval epoch 1 done: time=4.08 energy=495.87
2022-12-06 11:32:39,611 [ZeusDataLoader(train)] Up to epoch 1: time=49.54, energy=6852.63, cost=7761.28
2022-12-06 11:32:39,611 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:32:39,612 [ZeusDataLoader(train)] Expected next epoch: time=95.99, energy=13461.26, cost=15129.53
2022-12-06 11:32:39,612 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0044, Accuracy: 0.0545
2022-12-06 11:32:39,807 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:32:39,808 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:32:39.809 [ZeusMonitor] Monitor started.
2022-12-06 16:32:39.809 [ZeusMonitor] Running indefinitely. 2022-12-06 16:32:39.810 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:32:39.810 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e2+gpu0.power.log
2022-12-06 11:33:27,123 [ZeusDataLoader(train)] train epoch 2 done: time=47.50 energy=6563.59
2022-12-06 11:33:27,126 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 3.8624
Training Epoch: 1 [2048/50176]	Loss: 3.8338
Training Epoch: 1 [3072/50176]	Loss: 3.8620
Training Epoch: 1 [4096/50176]	Loss: 3.7945
Training Epoch: 1 [5120/50176]	Loss: 3.7754
Training Epoch: 1 [6144/50176]	Loss: 3.8218
Training Epoch: 1 [7168/50176]	Loss: 3.7358
Training Epoch: 1 [8192/50176]	Loss: 3.7185
Training Epoch: 1 [9216/50176]	Loss: 3.8536
Training Epoch: 1 [10240/50176]	Loss: 3.8130
Training Epoch: 1 [11264/50176]	Loss: 3.8377
Training Epoch: 1 [12288/50176]	Loss: 3.7695
Training Epoch: 1 [13312/50176]	Loss: 3.7051
Training Epoch: 1 [14336/50176]	Loss: 3.8141
Training Epoch: 1 [15360/50176]	Loss: 3.7760
Training Epoch: 1 [16384/50176]	Loss: 3.7723
Training Epoch: 1 [17408/50176]	Loss: 3.7859
Training Epoch: 1 [18432/50176]	Loss: 3.6486
Training Epoch: 1 [19456/50176]	Loss: 3.7906
Training Epoch: 1 [20480/50176]	Loss: 3.6936
Training Epoch: 1 [21504/50176]	Loss: 3.7122
Training Epoch: 1 [22528/50176]	Loss: 3.7132
Training Epoch: 1 [23552/50176]	Loss: 3.6811
Training Epoch: 1 [24576/50176]	Loss: 3.6661
Training Epoch: 1 [25600/50176]	Loss: 3.6412
Training Epoch: 1 [26624/50176]	Loss: 3.7133
Training Epoch: 1 [27648/50176]	Loss: 3.6461
Training Epoch: 1 [28672/50176]	Loss: 3.6092
Training Epoch: 1 [29696/50176]	Loss: 3.6926
Training Epoch: 1 [30720/50176]	Loss: 3.6551
Training Epoch: 1 [31744/50176]	Loss: 3.6647
Training Epoch: 1 [32768/50176]	Loss: 3.6336
Training Epoch: 1 [33792/50176]	Loss: 3.6862
Training Epoch: 1 [34816/50176]	Loss: 3.6732
Training Epoch: 1 [35840/50176]	Loss: 3.6877
Training Epoch: 1 [36864/50176]	Loss: 3.5971
Training Epoch: 1 [37888/50176]	Loss: 3.5846
Training Epoch: 1 [38912/50176]	Loss: 3.6418
Training Epoch: 1 [39936/50176]	Loss: 3.6481
Training Epoch: 1 [40960/50176]	Loss: 3.6508
Training Epoch: 1 [41984/50176]	Loss: 3.5118
Training Epoch: 1 [43008/50176]	Loss: 3.6531
Training Epoch: 1 [44032/50176]	Loss: 3.5740
Training Epoch: 1 [45056/50176]	Loss: 3.6012
Training Epoch: 1 [46080/50176]	Loss: 3.5795
Training Epoch: 1 [47104/50176]	Loss: 3.6092
Training Epoch: 1 [48128/50176]	Loss: 3.6255
Training Epoch: 1 [49152/50176]	Loss: 3.6348
Training Epoch: 1 [50176/50176]	Loss: 3.5471
2022-12-06 16:33:31.052 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:33:31,091 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.96 energy=488.87
2022-12-06 11:33:31,091 [ZeusDataLoader(train)] Up to epoch 2: time=101.00, energy=13905.09, cost=15790.16
2022-12-06 11:33:31,091 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:33:31,091 [ZeusDataLoader(train)] Expected next epoch: time=147.45, energy=20513.72, cost=23158.41
2022-12-06 11:33:31,092 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0035, Accuracy: 0.1351
2022-12-06 11:33:31,295 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:33:31,295 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:33:31.305 [ZeusMonitor] Monitor started.
2022-12-06 16:33:31.305 [ZeusMonitor] Running indefinitely. 2022-12-06 16:33:31.305 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:33:31.305 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e3+gpu0.power.log
2022-12-06 11:34:18,285 [ZeusDataLoader(train)] train epoch 3 done: time=47.18 energy=6544.39
2022-12-06 11:34:18,288 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.5041
Training Epoch: 2 [2048/50176]	Loss: 3.5849
Training Epoch: 2 [3072/50176]	Loss: 3.4920
Training Epoch: 2 [4096/50176]	Loss: 3.4687
Training Epoch: 2 [5120/50176]	Loss: 3.4958
Training Epoch: 2 [6144/50176]	Loss: 3.5110
Training Epoch: 2 [7168/50176]	Loss: 3.5562
Training Epoch: 2 [8192/50176]	Loss: 3.5633
Training Epoch: 2 [9216/50176]	Loss: 3.4842
Training Epoch: 2 [10240/50176]	Loss: 3.4221
Training Epoch: 2 [11264/50176]	Loss: 3.4001
Training Epoch: 2 [12288/50176]	Loss: 3.4368
Training Epoch: 2 [13312/50176]	Loss: 3.4115
Training Epoch: 2 [14336/50176]	Loss: 3.5279
Training Epoch: 2 [15360/50176]	Loss: 3.5129
Training Epoch: 2 [16384/50176]	Loss: 3.5580
Training Epoch: 2 [17408/50176]	Loss: 3.5158
Training Epoch: 2 [18432/50176]	Loss: 3.4503
Training Epoch: 2 [19456/50176]	Loss: 3.5057
Training Epoch: 2 [20480/50176]	Loss: 3.4342
Training Epoch: 2 [21504/50176]	Loss: 3.5025
Training Epoch: 2 [22528/50176]	Loss: 3.4535
Training Epoch: 2 [23552/50176]	Loss: 3.4505
Training Epoch: 2 [24576/50176]	Loss: 3.5073
Training Epoch: 2 [25600/50176]	Loss: 3.4693
Training Epoch: 2 [26624/50176]	Loss: 3.5383
Training Epoch: 2 [27648/50176]	Loss: 3.5190
Training Epoch: 2 [28672/50176]	Loss: 3.5113
Training Epoch: 2 [29696/50176]	Loss: 3.4387
Training Epoch: 2 [30720/50176]	Loss: 3.4988
Training Epoch: 2 [31744/50176]	Loss: 3.4070
Training Epoch: 2 [32768/50176]	Loss: 3.5009
Training Epoch: 2 [33792/50176]	Loss: 3.4758
Training Epoch: 2 [34816/50176]	Loss: 3.4651
Training Epoch: 2 [35840/50176]	Loss: 3.4149
Training Epoch: 2 [36864/50176]	Loss: 3.4968
Training Epoch: 2 [37888/50176]	Loss: 3.5260
Training Epoch: 2 [38912/50176]	Loss: 3.4354
Training Epoch: 2 [39936/50176]	Loss: 3.3570
Training Epoch: 2 [40960/50176]	Loss: 3.4191
Training Epoch: 2 [41984/50176]	Loss: 3.4011
Training Epoch: 2 [43008/50176]	Loss: 3.4191
Training Epoch: 2 [44032/50176]	Loss: 3.3505
Training Epoch: 2 [45056/50176]	Loss: 3.3913
Training Epoch: 2 [46080/50176]	Loss: 3.3620
Training Epoch: 2 [47104/50176]	Loss: 3.3537
Training Epoch: 2 [48128/50176]	Loss: 3.3960
Training Epoch: 2 [49152/50176]	Loss: 3.3572
Training Epoch: 2 [50176/50176]	Loss: 3.3361
2022-12-06 16:34:22.165 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:34:22,184 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.89 energy=486.61
2022-12-06 11:34:22,184 [ZeusDataLoader(train)] Up to epoch 3: time=152.07, energy=20936.09, cost=23774.50
2022-12-06 11:34:22,184 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:34:22,184 [ZeusDataLoader(train)] Expected next epoch: time=198.52, energy=27544.72, cost=31142.75
2022-12-06 11:34:22,185 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0033, Accuracy: 0.1772
2022-12-06 11:34:22,378 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:34:22,378 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:34:22.392 [ZeusMonitor] Monitor started.
2022-12-06 16:34:22.392 [ZeusMonitor] Running indefinitely. 2022-12-06 16:34:22.392 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:34:22.392 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e4+gpu0.power.log
2022-12-06 11:35:06,915 [ZeusDataLoader(train)] train epoch 4 done: time=44.72 energy=6344.20
2022-12-06 11:35:06,918 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.2901
Training Epoch: 3 [2048/50176]	Loss: 3.2637
Training Epoch: 3 [3072/50176]	Loss: 3.2911
Training Epoch: 3 [4096/50176]	Loss: 3.3375
Training Epoch: 3 [5120/50176]	Loss: 3.3116
Training Epoch: 3 [6144/50176]	Loss: 3.3148
Training Epoch: 3 [7168/50176]	Loss: 3.3589
Training Epoch: 3 [8192/50176]	Loss: 3.3104
Training Epoch: 3 [9216/50176]	Loss: 3.2854
Training Epoch: 3 [10240/50176]	Loss: 3.2753
Training Epoch: 3 [11264/50176]	Loss: 3.3422
Training Epoch: 3 [12288/50176]	Loss: 3.2889
Training Epoch: 3 [13312/50176]	Loss: 3.3549
Training Epoch: 3 [14336/50176]	Loss: 3.2127
Training Epoch: 3 [15360/50176]	Loss: 3.2686
Training Epoch: 3 [16384/50176]	Loss: 3.3002
Training Epoch: 3 [17408/50176]	Loss: 3.2636
Training Epoch: 3 [18432/50176]	Loss: 3.2802
Training Epoch: 3 [19456/50176]	Loss: 3.2780
Training Epoch: 3 [20480/50176]	Loss: 3.2003
Training Epoch: 3 [21504/50176]	Loss: 3.2741
Training Epoch: 3 [22528/50176]	Loss: 3.2507
Training Epoch: 3 [23552/50176]	Loss: 3.2402
Training Epoch: 3 [24576/50176]	Loss: 3.2467
Training Epoch: 3 [25600/50176]	Loss: 3.1956
Training Epoch: 3 [26624/50176]	Loss: 3.3071
Training Epoch: 3 [27648/50176]	Loss: 3.3592
Training Epoch: 3 [28672/50176]	Loss: 3.2505
Training Epoch: 3 [29696/50176]	Loss: 3.2222
Training Epoch: 3 [30720/50176]	Loss: 3.2528
Training Epoch: 3 [31744/50176]	Loss: 3.2318
Training Epoch: 3 [32768/50176]	Loss: 3.2358
Training Epoch: 3 [33792/50176]	Loss: 3.0994
Training Epoch: 3 [34816/50176]	Loss: 3.2679
Training Epoch: 3 [35840/50176]	Loss: 3.1973
Training Epoch: 3 [36864/50176]	Loss: 3.1960
Training Epoch: 3 [37888/50176]	Loss: 3.2178
Training Epoch: 3 [38912/50176]	Loss: 3.2385
Training Epoch: 3 [39936/50176]	Loss: 3.2966
Training Epoch: 3 [40960/50176]	Loss: 3.1333
Training Epoch: 3 [41984/50176]	Loss: 3.1839
Training Epoch: 3 [43008/50176]	Loss: 3.0959
Training Epoch: 3 [44032/50176]	Loss: 3.1556
Training Epoch: 3 [45056/50176]	Loss: 3.1296
Training Epoch: 3 [46080/50176]	Loss: 3.1767
Training Epoch: 3 [47104/50176]	Loss: 3.1559
Training Epoch: 3 [48128/50176]	Loss: 3.2998
Training Epoch: 3 [49152/50176]	Loss: 3.1745
Training Epoch: 3 [50176/50176]	Loss: 3.1618
2022-12-06 16:35:10.716 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:35:10,728 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.80 energy=484.91
2022-12-06 11:35:10,728 [ZeusDataLoader(train)] Up to epoch 4: time=200.60, energy=27765.20, cost=31434.91
2022-12-06 11:35:10,729 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:35:10,729 [ZeusDataLoader(train)] Expected next epoch: time=247.04, energy=34373.83, cost=38803.16
2022-12-06 11:35:10,730 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0031, Accuracy: 0.2235
2022-12-06 11:35:10,887 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:35:10,888 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:35:10.892 [ZeusMonitor] Monitor started.
2022-12-06 16:35:10.892 [ZeusMonitor] Running indefinitely. 2022-12-06 16:35:10.892 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:35:10.892 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e5+gpu0.power.log
2022-12-06 11:35:55,070 [ZeusDataLoader(train)] train epoch 5 done: time=44.33 energy=6318.25
2022-12-06 11:35:55,073 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.1553
Training Epoch: 4 [2048/50176]	Loss: 3.1139
Training Epoch: 4 [3072/50176]	Loss: 3.0405
Training Epoch: 4 [4096/50176]	Loss: 3.0734
Training Epoch: 4 [5120/50176]	Loss: 3.0317
Training Epoch: 4 [6144/50176]	Loss: 3.1100
Training Epoch: 4 [7168/50176]	Loss: 3.0802
Training Epoch: 4 [8192/50176]	Loss: 3.1111
Training Epoch: 4 [9216/50176]	Loss: 3.1248
Training Epoch: 4 [10240/50176]	Loss: 3.0833
Training Epoch: 4 [11264/50176]	Loss: 3.0721
Training Epoch: 4 [12288/50176]	Loss: 3.0871
Training Epoch: 4 [13312/50176]	Loss: 3.0713
Training Epoch: 4 [14336/50176]	Loss: 3.1000
Training Epoch: 4 [15360/50176]	Loss: 3.0468
Training Epoch: 4 [16384/50176]	Loss: 2.9467
Training Epoch: 4 [17408/50176]	Loss: 3.0671
Training Epoch: 4 [18432/50176]	Loss: 3.0417
Training Epoch: 4 [19456/50176]	Loss: 3.0140
Training Epoch: 4 [20480/50176]	Loss: 3.0661
Training Epoch: 4 [21504/50176]	Loss: 3.0727
Training Epoch: 4 [22528/50176]	Loss: 3.0092
Training Epoch: 4 [23552/50176]	Loss: 3.0376
Training Epoch: 4 [24576/50176]	Loss: 3.0426
Training Epoch: 4 [25600/50176]	Loss: 2.9880
Training Epoch: 4 [26624/50176]	Loss: 2.9658
Training Epoch: 4 [27648/50176]	Loss: 3.1103
Training Epoch: 4 [28672/50176]	Loss: 2.9618
Training Epoch: 4 [29696/50176]	Loss: 3.0756
Training Epoch: 4 [30720/50176]	Loss: 3.0465
Training Epoch: 4 [31744/50176]	Loss: 3.0018
Training Epoch: 4 [32768/50176]	Loss: 3.0776
Training Epoch: 4 [33792/50176]	Loss: 2.9784
Training Epoch: 4 [34816/50176]	Loss: 2.9639
Training Epoch: 4 [35840/50176]	Loss: 3.0760
Training Epoch: 4 [36864/50176]	Loss: 2.9865
Training Epoch: 4 [37888/50176]	Loss: 3.1710
Training Epoch: 4 [38912/50176]	Loss: 2.9931
Training Epoch: 4 [39936/50176]	Loss: 3.0217
Training Epoch: 4 [40960/50176]	Loss: 2.9727
Training Epoch: 4 [41984/50176]	Loss: 2.9329
Training Epoch: 4 [43008/50176]	Loss: 2.9762
Training Epoch: 4 [44032/50176]	Loss: 2.9058
Training Epoch: 4 [45056/50176]	Loss: 3.0205
Training Epoch: 4 [46080/50176]	Loss: 3.0088
Training Epoch: 4 [47104/50176]	Loss: 3.0110
Training Epoch: 4 [48128/50176]	Loss: 2.9632
Training Epoch: 4 [49152/50176]	Loss: 3.0178
Training Epoch: 4 [50176/50176]	Loss: 3.0901
2022-12-06 16:35:58.977 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:35:58,986 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.91 energy=490.61
2022-12-06 11:35:58,987 [ZeusDataLoader(train)] Up to epoch 5: time=248.84, energy=34574.06, cost=39060.19
2022-12-06 11:35:58,987 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:35:58,987 [ZeusDataLoader(train)] Expected next epoch: time=295.28, energy=41182.69, cost=46428.43
2022-12-06 11:35:58,988 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0029, Accuracy: 0.2517
2022-12-06 11:35:59,132 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:35:59,133 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:35:59.136 [ZeusMonitor] Monitor started.
2022-12-06 16:35:59.136 [ZeusMonitor] Running indefinitely. 2022-12-06 16:35:59.136 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:35:59.136 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e6+gpu0.power.log
2022-12-06 11:36:43,374 [ZeusDataLoader(train)] train epoch 6 done: time=44.38 energy=6333.12
2022-12-06 11:36:43,377 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.8519
Training Epoch: 5 [2048/50176]	Loss: 2.8924
Training Epoch: 5 [3072/50176]	Loss: 3.0476
Training Epoch: 5 [4096/50176]	Loss: 2.8583
Training Epoch: 5 [5120/50176]	Loss: 2.8751
Training Epoch: 5 [6144/50176]	Loss: 2.9459
Training Epoch: 5 [7168/50176]	Loss: 2.8955
Training Epoch: 5 [8192/50176]	Loss: 2.8497
Training Epoch: 5 [9216/50176]	Loss: 2.8992
Training Epoch: 5 [10240/50176]	Loss: 2.9216
Training Epoch: 5 [11264/50176]	Loss: 2.9635
Training Epoch: 5 [12288/50176]	Loss: 2.8444
Training Epoch: 5 [13312/50176]	Loss: 2.9173
Training Epoch: 5 [14336/50176]	Loss: 2.8714
Training Epoch: 5 [15360/50176]	Loss: 2.9644
Training Epoch: 5 [16384/50176]	Loss: 2.9081
Training Epoch: 5 [17408/50176]	Loss: 2.9662
Training Epoch: 5 [18432/50176]	Loss: 2.8553
Training Epoch: 5 [19456/50176]	Loss: 2.9219
Training Epoch: 5 [20480/50176]	Loss: 2.9113
Training Epoch: 5 [21504/50176]	Loss: 2.8290
Training Epoch: 5 [22528/50176]	Loss: 2.9367
Training Epoch: 5 [23552/50176]	Loss: 2.9112
Training Epoch: 5 [24576/50176]	Loss: 2.9231
Training Epoch: 5 [25600/50176]	Loss: 2.9536
Training Epoch: 5 [26624/50176]	Loss: 2.8087
Training Epoch: 5 [27648/50176]	Loss: 2.8831
Training Epoch: 5 [28672/50176]	Loss: 2.9173
Training Epoch: 5 [29696/50176]	Loss: 2.8659
Training Epoch: 5 [30720/50176]	Loss: 2.8537
Training Epoch: 5 [31744/50176]	Loss: 2.8942
Training Epoch: 5 [32768/50176]	Loss: 2.8875
Training Epoch: 5 [33792/50176]	Loss: 2.8392
Training Epoch: 5 [34816/50176]	Loss: 2.8712
Training Epoch: 5 [35840/50176]	Loss: 2.9490
Training Epoch: 5 [36864/50176]	Loss: 2.8281
Training Epoch: 5 [37888/50176]	Loss: 2.7997
Training Epoch: 5 [38912/50176]	Loss: 2.8173
Training Epoch: 5 [39936/50176]	Loss: 2.8916
Training Epoch: 5 [40960/50176]	Loss: 2.8016
Training Epoch: 5 [41984/50176]	Loss: 2.8530
Training Epoch: 5 [43008/50176]	Loss: 2.8258
Training Epoch: 5 [44032/50176]	Loss: 2.8683
Training Epoch: 5 [45056/50176]	Loss: 2.9538
Training Epoch: 5 [46080/50176]	Loss: 2.7749
Training Epoch: 5 [47104/50176]	Loss: 2.8083
Training Epoch: 5 [48128/50176]	Loss: 2.8631
Training Epoch: 5 [49152/50176]	Loss: 2.8597
Training Epoch: 5 [50176/50176]	Loss: 2.8449
2022-12-06 16:36:47.113 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:36:47,162 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.78 energy=476.24
2022-12-06 11:36:47,162 [ZeusDataLoader(train)] Up to epoch 6: time=296.99, energy=41383.42, cost=46678.44
2022-12-06 11:36:47,162 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:36:47,162 [ZeusDataLoader(train)] Expected next epoch: time=343.44, energy=47992.05, cost=54046.68
2022-12-06 11:36:47,163 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0028, Accuracy: 0.2700
2022-12-06 11:36:47,349 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:36:47,350 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:36:47.351 [ZeusMonitor] Monitor started.
2022-12-06 16:36:47.352 [ZeusMonitor] Running indefinitely. 2022-12-06 16:36:47.352 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:36:47.352 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e7+gpu0.power.log
2022-12-06 11:37:31,590 [ZeusDataLoader(train)] train epoch 7 done: time=44.42 energy=6338.92
2022-12-06 11:37:31,593 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.7302
Training Epoch: 6 [2048/50176]	Loss: 2.7394
Training Epoch: 6 [3072/50176]	Loss: 2.8101
Training Epoch: 6 [4096/50176]	Loss: 2.7971
Training Epoch: 6 [5120/50176]	Loss: 2.7282
Training Epoch: 6 [6144/50176]	Loss: 2.7216
Training Epoch: 6 [7168/50176]	Loss: 2.7769
Training Epoch: 6 [8192/50176]	Loss: 2.7172
Training Epoch: 6 [9216/50176]	Loss: 2.8554
Training Epoch: 6 [10240/50176]	Loss: 2.7314
Training Epoch: 6 [11264/50176]	Loss: 2.7918
Training Epoch: 6 [12288/50176]	Loss: 2.8098
Training Epoch: 6 [13312/50176]	Loss: 2.7873
Training Epoch: 6 [14336/50176]	Loss: 2.7541
Training Epoch: 6 [15360/50176]	Loss: 2.6718
Training Epoch: 6 [16384/50176]	Loss: 2.7449
Training Epoch: 6 [17408/50176]	Loss: 2.7335
Training Epoch: 6 [18432/50176]	Loss: 2.7444
Training Epoch: 6 [19456/50176]	Loss: 2.7005
Training Epoch: 6 [20480/50176]	Loss: 2.7748
Training Epoch: 6 [21504/50176]	Loss: 2.8249
Training Epoch: 6 [22528/50176]	Loss: 2.7506
Training Epoch: 6 [23552/50176]	Loss: 2.7561
Training Epoch: 6 [24576/50176]	Loss: 2.7234
Training Epoch: 6 [25600/50176]	Loss: 2.7146
Training Epoch: 6 [26624/50176]	Loss: 2.7792
Training Epoch: 6 [27648/50176]	Loss: 2.7149
Training Epoch: 6 [28672/50176]	Loss: 2.6133
Training Epoch: 6 [29696/50176]	Loss: 2.7335
Training Epoch: 6 [30720/50176]	Loss: 2.7638
Training Epoch: 6 [31744/50176]	Loss: 2.7090
Training Epoch: 6 [32768/50176]	Loss: 2.7179
Training Epoch: 6 [33792/50176]	Loss: 2.7299
Training Epoch: 6 [34816/50176]	Loss: 2.7264
Training Epoch: 6 [35840/50176]	Loss: 2.7168
Training Epoch: 6 [36864/50176]	Loss: 2.7567
Training Epoch: 6 [37888/50176]	Loss: 2.7748
Training Epoch: 6 [38912/50176]	Loss: 2.7535
Training Epoch: 6 [39936/50176]	Loss: 2.6931
Training Epoch: 6 [40960/50176]	Loss: 2.7382
Training Epoch: 6 [41984/50176]	Loss: 2.6974
Training Epoch: 6 [43008/50176]	Loss: 2.6625
Training Epoch: 6 [44032/50176]	Loss: 2.7430
Training Epoch: 6 [45056/50176]	Loss: 2.6815
Training Epoch: 6 [46080/50176]	Loss: 2.7453
Training Epoch: 6 [47104/50176]	Loss: 2.6982
Training Epoch: 6 [48128/50176]	Loss: 2.7519
Training Epoch: 6 [49152/50176]	Loss: 2.6285
Training Epoch: 6 [50176/50176]	Loss: 2.7155
2022-12-06 16:37:35.279 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 11:37:35,298 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.70 energy=466.40
2022-12-06 11:37:35,298 [ZeusDataLoader(train)] Up to epoch 7: time=345.11, energy=48188.74, cost=54291.26
2022-12-06 11:37:35,299 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.44 energy=6608.63
2022-12-06 11:37:35,299 [ZeusDataLoader(train)] Expected next epoch: time=391.55, energy=54797.37, cost=61659.51
2022-12-06 11:37:35,300 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0027, Accuracy: 0.3104
2022-12-06 11:37:35,497 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 11:37:35,498 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-06 16:37:35.501 [ZeusMonitor] Monitor started.
2022-12-06 16:37:35.501 [ZeusMonitor] Running indefinitely. 2022-12-06 16:37:35.501 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 16:37:35.501 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120610111670339487/bs1024+e8+gpu0.power.log
Training Epoch: 7 [1024/50176]	Loss: 2.6783
Training Epoch: 7 [2048/50176]	Loss: 2.6054
Training Epoch: 7 [3072/50176]	Loss: 2.6037
Training Epoch: 7 [4096/50176]	Loss: 2.5878
Training Epoch: 7 [5120/50176]	Loss: 2.6507
Training Epoch: 7 [6144/50176]	Loss: 2.6093
Training Epoch: 7 [7168/50176]	Loss: 2.5939
Training Epoch: 7 [8192/50176]	Loss: 2.5789
Training Epoch: 7 [9216/50176]	Loss: 2.4731
Training Epoch: 7 [10240/50176]	Loss: 2.5160
Training Epoch: 7 [11264/50176]	Loss: 2.5651
Training Epoch: 7 [12288/50176]	Loss: 2.6686
Traceback (most recent call last):
  File "/workspace/zeus/examples/cifar100/train_lr.py", line 256, in <module>
    main(parse_args())
  File "/workspace/zeus/examples/cifar100/train_lr.py", line 188, in main
    train(train_loader, model, criterion, optimizer, epoch, args)
  File "/workspace/zeus/examples/cifar100/train_lr.py", line 212, in train
    optimizer.step()
  File "/root/.local/miniconda3/lib/python3.9/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/root/.local/miniconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/root/.local/miniconda3/lib/python3.9/site-packages/torch/optim/adam.py", line 133, in step
    F.adam(params_with_grad,
  File "/root/.local/miniconda3/lib/python3.9/site-packages/torch/optim/_functional.py", line 94, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt
2022-12-06 11:37:47,684 [ZeusDataLoader(train)] [GPU_0] Stopped Zeus monitor.
