2022-11-23 19:49:05,794 [Zeus2DataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-11-23 19:49:05,794 [Zeus2DataLoader(train)] Power profiling: ON
2022-11-23 19:49:07,818 [Zeus2DataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-11-23 19:49:07,819 [Zeus2DataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
hello from epochs()!
0
2022-11-23 19:49:07,944 [Zeus2DataLoader(train)] [GPU_0] Zeus monitor started.
2022-11-24 00:49:07.945 [ZeusMonitor] Monitor started.
2022-11-24 00:49:07.946 [ZeusMonitor] Running indefinitely. 2022-11-24 00:49:07.946 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-11-24 00:49:07.946 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.5+me100+x1+eta0.5+beta2.0+2022112319471669250835/bs8+e1+gpu0.power.log
2022-11-23 19:49:07,950 [Zeus2DataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-11-23 19:49:07,950 [Zeus2DataLoader(train)] Warm-up started with power limit 175W
2022-11-23 19:49:08,877 [Zeus2DataLoader(train)] Profile started with power limit 175W
2022-11-23 19:49:11,057 [Zeus2DataLoader(train)] Profile done with power limit 175W
2022-11-23 19:49:11,112 [Zeus2DataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-11-23 19:49:11,112 [Zeus2DataLoader(train)] Warm-up started with power limit 150W
2022-11-23 19:49:11,691 [Zeus2DataLoader(train)] Profile started with power limit 150W
2022-11-23 19:49:13,850 [Zeus2DataLoader(train)] Profile done with power limit 150W
2022-11-23 19:49:13,906 [Zeus2DataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-11-23 19:49:13,906 [Zeus2DataLoader(train)] Warm-up started with power limit 125W
2022-11-23 19:49:14,490 [Zeus2DataLoader(train)] Profile started with power limit 125W
2022-11-23 19:49:16,624 [Zeus2DataLoader(train)] Profile done with power limit 125W
2022-11-23 19:49:16,679 [Zeus2DataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-11-23 19:49:16,680 [Zeus2DataLoader(train)] Warm-up started with power limit 100W
2022-11-23 19:49:17,245 [Zeus2DataLoader(train)] Profile started with power limit 100W
Training Epoch: 0 [8/50000]	Loss: 4.6229
Training Epoch: 0 [16/50000]	Loss: 4.6818
Training Epoch: 0 [24/50000]	Loss: 4.6157
Training Epoch: 0 [32/50000]	Loss: 4.5902
Training Epoch: 0 [40/50000]	Loss: 4.6397
Training Epoch: 0 [48/50000]	Loss: 4.6823
Training Epoch: 0 [56/50000]	Loss: 4.4936
Training Epoch: 0 [64/50000]	Loss: 4.5907
Training Epoch: 0 [72/50000]	Loss: 4.5740
Training Epoch: 0 [80/50000]	Loss: 4.6586
Training Epoch: 0 [88/50000]	Loss: 4.6915
Training Epoch: 0 [96/50000]	Loss: 4.8661
Training Epoch: 0 [104/50000]	Loss: 4.6615
Training Epoch: 0 [112/50000]	Loss: 4.6938
Training Epoch: 0 [120/50000]	Loss: 4.7001
Training Epoch: 0 [128/50000]	Loss: 4.7206
Training Epoch: 0 [136/50000]	Loss: 4.5339
Training Epoch: 0 [144/50000]	Loss: 4.5213
Training Epoch: 0 [152/50000]	Loss: 4.6792
Training Epoch: 0 [160/50000]	Loss: 4.7112
Training Epoch: 0 [168/50000]	Loss: 4.4547
Training Epoch: 0 [176/50000]	Loss: 4.5663
Training Epoch: 0 [184/50000]	Loss: 4.9074
Training Epoch: 0 [192/50000]	Loss: 4.7448
Training Epoch: 0 [200/50000]	Loss: 4.8028
Training Epoch: 0 [208/50000]	Loss: 4.6359
Training Epoch: 0 [216/50000]	Loss: 4.6596
Training Epoch: 0 [224/50000]	Loss: 4.6124
Training Epoch: 0 [232/50000]	Loss: 4.6531
Training Epoch: 0 [240/50000]	Loss: 4.6309
Training Epoch: 0 [248/50000]	Loss: 4.7079
Training Epoch: 0 [256/50000]	Loss: 4.5380
Training Epoch: 0 [264/50000]	Loss: 4.4854
Training Epoch: 0 [272/50000]	Loss: 4.6978
Training Epoch: 0 [280/50000]	Loss: 4.8172
Training Epoch: 0 [288/50000]	Loss: 4.7097
Training Epoch: 0 [296/50000]	Loss: 4.5875
Training Epoch: 0 [304/50000]	Loss: 4.6837
Training Epoch: 0 [312/50000]	Loss: 4.6074
Training Epoch: 0 [320/50000]	Loss: 4.8383
Training Epoch: 0 [328/50000]	Loss: 4.8266
Training Epoch: 0 [336/50000]	Loss: 4.7732
Training Epoch: 0 [344/50000]	Loss: 4.6551
Training Epoch: 0 [352/50000]	Loss: 4.7271
Training Epoch: 0 [360/50000]	Loss: 4.9550
Training Epoch: 0 [368/50000]	Loss: 4.4830
Training Epoch: 0 [376/50000]	Loss: 4.7202
Training Epoch: 0 [384/50000]	Loss: 4.6160
Training Epoch: 0 [392/50000]	Loss: 4.6839
Training Epoch: 0 [400/50000]	Loss: 4.5744
Training Epoch: 0 [408/50000]	Loss: 4.9521
Training Epoch: 0 [416/50000]	Loss: 4.5794
Training Epoch: 0 [424/50000]	Loss: 4.6477
Training Epoch: 0 [432/50000]	Loss: 4.6383
Training Epoch: 0 [440/50000]	Loss: 4.6836
Training Epoch: 0 [448/50000]	Loss: 4.4877
Training Epoch: 0 [456/50000]	Loss: 4.7846
Training Epoch: 0 [464/50000]	Loss: 4.6214
Training Epoch: 0 [472/50000]	Loss: 4.7331
Training Epoch: 0 [480/50000]	Loss: 4.5142
Training Epoch: 0 [488/50000]	Loss: 4.5103
Training Epoch: 0 [496/50000]	Loss: 4.5662
Training Epoch: 0 [504/50000]	Loss: 4.5507
Training Epoch: 0 [512/50000]	Loss: 4.7233
Training Epoch: 0 [520/50000]	Loss: 4.5817
Training Epoch: 0 [528/50000]	Loss: 4.8535
Training Epoch: 0 [536/50000]	Loss: 4.6707
Training Epoch: 0 [544/50000]	Loss: 4.7154
Training Epoch: 0 [552/50000]	Loss: 4.4571
Training Epoch: 0 [560/50000]	Loss: 5.0466
Training Epoch: 0 [568/50000]	Loss: 4.6521
Training Epoch: 0 [576/50000]	Loss: 4.6109
Training Epoch: 0 [584/50000]	Loss: 4.5365
Training Epoch: 0 [592/50000]	Loss: 4.5689
Training Epoch: 0 [600/50000]	Loss: 4.7560
Training Epoch: 0 [608/50000]	Loss: 4.6391
Training Epoch: 0 [616/50000]	Loss: 4.7876
Training Epoch: 0 [624/50000]	Loss: 4.9481
Training Epoch: 0 [632/50000]	Loss: 4.7045
Training Epoch: 0 [640/50000]	Loss: 4.5347
Training Epoch: 0 [648/50000]	Loss: 4.5663
Training Epoch: 0 [656/50000]	Loss: 4.5341
Training Epoch: 0 [664/50000]	Loss: 4.5395
Training Epoch: 0 [672/50000]	Loss: 4.6577
Training Epoch: 0 [680/50000]	Loss: 4.4159
Training Epoch: 0 [688/50000]	Loss: 4.5676
Training Epoch: 0 [696/50000]	Loss: 4.6400
Training Epoch: 0 [704/50000]	Loss: 4.8157
Training Epoch: 0 [712/50000]	Loss: 4.7951
Training Epoch: 0 [720/50000]	Loss: 4.7903
Training Epoch: 0 [728/50000]	Loss: 4.6233
Training Epoch: 0 [736/50000]	Loss: 4.5653
Training Epoch: 0 [744/50000]	Loss: 4.7323
Training Epoch: 0 [752/50000]	Loss: 4.4887
Training Epoch: 0 [760/50000]	Loss: 4.4468
Training Epoch: 0 [768/50000]	Loss: 4.6460
Training Epoch: 0 [776/50000]	Loss: 4.4312
Training Epoch: 0 [784/50000]	Loss: 4.4871
Training Epoch: 0 [792/50000]	Loss: 4.4713
Training Epoch: 0 [800/50000]	Loss: 4.6444
Training Epoch: 0 [808/50000]	Loss: 4.7165
Training Epoch: 0 [816/50000]	Loss: 4.6103
Training Epoch: 0 [824/50000]	Loss: 4.6256
Training Epoch: 0 [832/50000]	Loss: 4.5883
Training Epoch: 0 [840/50000]	Loss: 4.7534
Training Epoch: 0 [848/50000]	Loss: 4.4845
Training Epoch: 0 [856/50000]	Loss: 4.7263
Training Epoch: 0 [864/50000]	Loss: 4.7919
Training Epoch: 0 [872/50000]	Loss: 4.4670
Training Epoch: 0 [880/50000]	Loss: 4.5225
Training Epoch: 0 [888/50000]	Loss: 4.4588
Training Epoch: 0 [896/50000]	Loss: 4.5546
Training Epoch: 0 [904/50000]	Loss: 4.7021
Training Epoch: 0 [912/50000]	Loss: 4.5523
Training Epoch: 0 [920/50000]	Loss: 4.8540
Training Epoch: 0 [928/50000]	Loss: 4.5645
Training Epoch: 0 [936/50000]	Loss: 4.5300
Training Epoch: 0 [944/50000]	Loss: 4.4872
Training Epoch: 0 [952/50000]	Loss: 4.5015
Training Epoch: 0 [960/50000]	Loss: 4.6383
Training Epoch: 0 [968/50000]	Loss: 4.5734
Training Epoch: 0 [976/50000]	Loss: 4.7571
Training Epoch: 0 [984/50000]	Loss: 4.4093
Training Epoch: 0 [992/50000]	Loss: 4.5945
Training Epoch: 0 [1000/50000]	Loss: 4.6876
Training Epoch: 0 [1008/50000]	Loss: 4.8467
Training Epoch: 0 [1016/50000]	Loss: 4.6157
Training Epoch: 0 [1024/50000]	Loss: 4.7009
Training Epoch: 0 [1032/50000]	Loss: 4.6206
Training Epoch: 0 [1040/50000]	Loss: 4.7018
Training Epoch: 0 [1048/50000]	Loss: 4.5656
Training Epoch: 0 [1056/50000]	Loss: 4.5453
Training Epoch: 0 [1064/50000]	Loss: 4.7235
Training Epoch: 0 [1072/50000]	Loss: 4.7531
Training Epoch: 0 [1080/50000]	Loss: 4.5791
Training Epoch: 0 [1088/50000]	Loss: 4.5346
Training Epoch: 0 [1096/50000]	Loss: 4.5263
Training Epoch: 0 [1104/50000]	Loss: 4.7996
Training Epoch: 0 [1112/50000]	Loss: 4.8455
Training Epoch: 0 [1120/50000]	Loss: 4.6667
Training Epoch: 0 [1128/50000]	Loss: 4.7375
Training Epoch: 0 [1136/50000]	Loss: 4.5272
Training Epoch: 0 [1144/50000]	Loss: 4.8666
Training Epoch: 0 [1152/50000]	Loss: 4.6575
Training Epoch: 0 [1160/50000]	Loss: 4.7149
Training Epoch: 0 [1168/50000]	Loss: 4.6749
Training Epoch: 0 [1176/50000]	Loss: 4.7467
Training Epoch: 0 [1184/50000]	Loss: 4.7155
Training Epoch: 0 [1192/50000]	Loss: 4.4262
Training Epoch: 0 [1200/50000]	Loss: 4.5102
Training Epoch: 0 [1208/50000]	Loss: 4.5119
Training Epoch: 0 [1216/50000]	Loss: 4.5994
Training Epoch: 0 [1224/50000]	Loss: 4.6607
Training Epoch: 0 [1232/50000]	Loss: 4.7844
Training Epoch: 0 [1240/50000]	Loss: 4.5381
Training Epoch: 0 [1248/50000]	Loss: 4.4999
Training Epoch: 0 [1256/50000]	Loss: 4.8665
Training Epoch: 0 [1264/50000]	Loss: 4.7654
Training Epoch: 0 [1272/50000]	Loss: 4.5344
Training Epoch: 0 [1280/50000]	Loss: 4.4929
Training Epoch: 0 [1288/50000]	Loss: 4.7386
Training Epoch: 0 [1296/50000]	Loss: 4.4516
Training Epoch: 0 [1304/50000]	Loss: 4.6532
Training Epoch: 0 [1312/50000]	Loss: 4.6525
Training Epoch: 0 [1320/50000]	Loss: 4.7382
Training Epoch: 0 [1328/50000]	Loss: 4.7125
Training Epoch: 0 [1336/50000]	Loss: 4.5196
Training Epoch: 0 [1344/50000]	Loss: 4.8139
Training Epoch: 0 [1352/50000]	Loss: 4.4800
Training Epoch: 0 [1360/50000]	Loss: 4.4942
Training Epoch: 0 [1368/50000]	Loss: 4.5172
Training Epoch: 0 [1376/50000]	Loss: 4.6554
Training Epoch: 0 [1384/50000]	Loss: 4.6755
Training Epoch: 0 [1392/50000]	Loss: 4.5518
Training Epoch: 0 [1400/50000]	Loss: 4.6588
Training Epoch: 0 [1408/50000]	Loss: 4.8474
Training Epoch: 0 [1416/50000]	Loss: 4.4486
Training Epoch: 0 [1424/50000]	Loss: 4.7004
Training Epoch: 0 [1432/50000]	Loss: 4.5822
Training Epoch: 0 [1440/50000]	Loss: 4.6399
Training Epoch: 0 [1448/50000]	Loss: 4.6385
Training Epoch: 0 [1456/50000]	Loss: 4.4914
Training Epoch: 0 [1464/50000]	Loss: 4.4388
Training Epoch: 0 [1472/50000]	Loss: 4.5770
Training Epoch: 0 [1480/50000]	Loss: 4.6402
Training Epoch: 0 [1488/50000]	Loss: 4.6513
Training Epoch: 0 [1496/50000]	Loss: 4.8221
Training Epoch: 0 [1504/50000]	Loss: 4.4715
Training Epoch: 0 [1512/50000]	Loss: 4.6402
2022-11-23 19:49:19,331 [Zeus2DataLoader(train)] Profile done with power limit 100W
2022-11-23 19:49:19,331 [Zeus2DataLoader(train)] This was the last power limit to explore.
2022-11-23 19:49:19,331 [Zeus2DataLoader(train)] Cost-optimal power limit is 100W
2022-11-23 19:49:19,381 [Zeus2DataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1520/50000]	Loss: 4.5748
Training Epoch: 0 [1528/50000]	Loss: 4.4139
Training Epoch: 0 [1536/50000]	Loss: 4.7628
Training Epoch: 0 [1544/50000]	Loss: 4.6753
Training Epoch: 0 [1552/50000]	Loss: 4.5389
Training Epoch: 0 [1560/50000]	Loss: 4.6053
Training Epoch: 0 [1568/50000]	Loss: 4.6590
Training Epoch: 0 [1576/50000]	Loss: 4.6485
Training Epoch: 0 [1584/50000]	Loss: 4.4809
Training Epoch: 0 [1592/50000]	Loss: 4.7207
Training Epoch: 0 [1600/50000]	Loss: 4.7614
Training Epoch: 0 [1608/50000]	Loss: 4.5068
Training Epoch: 0 [1616/50000]	Loss: 4.6492
Training Epoch: 0 [1624/50000]	Loss: 4.4481
Training Epoch: 0 [1632/50000]	Loss: 4.4320
2022-11-24 00:49:36.297 [ZeusMonitor] Caught signal 2, end monitoring.
2022-11-23 19:49:36,321 [Zeus2DataLoader(eval)] Power profiling done.
2022-11-23 19:49:36,321 [Zeus2DataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.5+me100+x1+eta0.5+beta2.0+2022112319471669250835/bs8.power.json: {"job_id": "rec04+try01", "train_power": {"175000": 99.0862347762465, "150000": 99.69324604859425, "125000": 100.48184078760903, "100000": 98.74282757991612}, "train_throughput": {"175000": 18.4795362704136, "150000": 18.564065547878958, "125000": 18.80483471585804, "100000": 19.22116759220639}, "eval_power": {"100000": 97.8824019137237}, "eval_throughput": {"100000": 73.82540545192101}, "optimal_pl": 100000}
2022-11-23 19:49:36,321 [Zeus2DataLoader(eval)] eval epoch 1 done: time=16.93 energy=1657.33
2022-11-23 19:49:36,321 [Zeus2DataLoader(train)] Up to epoch 1: time=16.93, energy=1657.33, cost=2310.20
2022-11-23 19:49:36,321 [Zeus2DataLoader(train)] Profiling done. Stopping.
2022-11-23 19:49:36,322 [Zeus2DataLoader(train)] Training done.
2022-11-23 19:49:36,322 [Zeus2DataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.5+me100+x1+eta0.5+beta2.0+2022112319471669250835/rec04+try01+bs8.train.json: {"energy": 1657.3292302720547, "time": 16.931840635999833, "cost": 2310.200670786013, "num_epochs": 1, "reached": true}
Validation Epoch: 0, Average loss: 0.5763, Accuracy: 0.0129
0
