[run job] Launching job with BS 1024: and LR: 0.006
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224', 'ZEUS_JOB_ID': 'rec00+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.006']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec00+try01.train.log'
2022-12-08 17:40:28,714 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 17:40:28,715 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 17:40:28,715 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 17:40:28,761 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 17:40:28,761 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 17:40:31,594 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 17:40:31,595 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 17:40:31,802 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:40:31.806 [ZeusMonitor] Monitor started.
2022-12-08 22:40:31.807 [ZeusMonitor] Running indefinitely. 2022-12-08 22:40:31.807 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:40:31.807 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e1+gpu0.power.log
2022-12-08 17:40:32,544 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 17:40:32,545 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 17:40:42,151 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 17:41:15,621 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 17:41:17,280 [ZeusDataLoader(train)] train epoch 1 done: time=45.68 energy=6781.57
2022-12-08 17:41:17,283 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 5.8632
Training Epoch: 0 [3072/50176]	Loss: 5.2699
Training Epoch: 0 [4096/50176]	Loss: 4.8855
Training Epoch: 0 [5120/50176]	Loss: 4.7573
Training Epoch: 0 [6144/50176]	Loss: 4.6781
Training Epoch: 0 [7168/50176]	Loss: 4.6426
Training Epoch: 0 [8192/50176]	Loss: 4.7275
Training Epoch: 0 [9216/50176]	Loss: 4.6437
Training Epoch: 0 [10240/50176]	Loss: 4.6414
Training Epoch: 0 [11264/50176]	Loss: 4.6721
Training Epoch: 0 [12288/50176]	Loss: 4.5973
Training Epoch: 0 [13312/50176]	Loss: 4.5862
Training Epoch: 0 [14336/50176]	Loss: 4.5620
Training Epoch: 0 [15360/50176]	Loss: 4.5414
Training Epoch: 0 [16384/50176]	Loss: 4.5028
Training Epoch: 0 [17408/50176]	Loss: 4.5458
Training Epoch: 0 [18432/50176]	Loss: 4.4966
Training Epoch: 0 [19456/50176]	Loss: 4.5342
Training Epoch: 0 [20480/50176]	Loss: 4.4832
Training Epoch: 0 [21504/50176]	Loss: 4.5200
Training Epoch: 0 [22528/50176]	Loss: 4.5125
Training Epoch: 0 [23552/50176]	Loss: 4.5563
Training Epoch: 0 [24576/50176]	Loss: 4.4795
Training Epoch: 0 [25600/50176]	Loss: 4.4510
Training Epoch: 0 [26624/50176]	Loss: 4.4510
Training Epoch: 0 [27648/50176]	Loss: 4.4488
Training Epoch: 0 [28672/50176]	Loss: 4.3745
Training Epoch: 0 [29696/50176]	Loss: 4.4119
Training Epoch: 0 [30720/50176]	Loss: 4.4485
Training Epoch: 0 [31744/50176]	Loss: 4.3951
Training Epoch: 0 [32768/50176]	Loss: 4.3704
Training Epoch: 0 [33792/50176]	Loss: 4.3347
Training Epoch: 0 [34816/50176]	Loss: 4.2917
Training Epoch: 0 [35840/50176]	Loss: 4.2593
Training Epoch: 0 [36864/50176]	Loss: 4.2441
Training Epoch: 0 [37888/50176]	Loss: 4.2790
Training Epoch: 0 [38912/50176]	Loss: 4.2264
Training Epoch: 0 [39936/50176]	Loss: 4.2756
Training Epoch: 0 [40960/50176]	Loss: 4.1909
Training Epoch: 0 [41984/50176]	Loss: 4.2077
Training Epoch: 0 [43008/50176]	Loss: 4.2196
Training Epoch: 0 [44032/50176]	Loss: 4.1797
Training Epoch: 0 [45056/50176]	Loss: 4.1827
Training Epoch: 0 [46080/50176]	Loss: 4.1264
Training Epoch: 0 [47104/50176]	Loss: 4.1664
Training Epoch: 0 [48128/50176]	Loss: 4.1285
Training Epoch: 0 [49152/50176]	Loss: 4.1425
Training Epoch: 0 [50176/50176]	Loss: 4.0654
2022-12-08 22:41:21.067 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:41:21,090 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.80 energy=537.92
2022-12-08 17:41:21,091 [ZeusDataLoader(train)] Up to epoch 1: time=49.48, energy=7319.49, cost=7988.92
2022-12-08 17:41:21,092 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0045, Accuracy: 0.0401
2022-12-08 17:41:21,252 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:41:21.256 [ZeusMonitor] Monitor started.
2022-12-08 22:41:21.256 [ZeusMonitor] Running indefinitely. 2022-12-08 22:41:21.256 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:41:21.256 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e2+gpu0.power.log
2022-12-08 17:41:22,006 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 17:41:22,006 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 17:41:30,321 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 17:42:04,854 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 17:42:06,574 [ZeusDataLoader(train)] train epoch 2 done: time=45.48 energy=6541.30
2022-12-08 17:42:06,578 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.0994
Training Epoch: 1 [2048/50176]	Loss: 4.0433
Training Epoch: 1 [3072/50176]	Loss: 4.1051
Training Epoch: 1 [4096/50176]	Loss: 4.0306
Training Epoch: 1 [5120/50176]	Loss: 4.0105
Training Epoch: 1 [6144/50176]	Loss: 4.0484
Training Epoch: 1 [7168/50176]	Loss: 3.9657
Training Epoch: 1 [8192/50176]	Loss: 3.9547
Training Epoch: 1 [9216/50176]	Loss: 4.0683
Training Epoch: 1 [10240/50176]	Loss: 4.0073
Training Epoch: 1 [11264/50176]	Loss: 4.0162
Training Epoch: 1 [12288/50176]	Loss: 3.9958
Training Epoch: 1 [13312/50176]	Loss: 3.9218
Training Epoch: 1 [14336/50176]	Loss: 4.0264
Training Epoch: 1 [15360/50176]	Loss: 3.9464
Training Epoch: 1 [16384/50176]	Loss: 3.9559
Training Epoch: 1 [17408/50176]	Loss: 3.9147
Training Epoch: 1 [18432/50176]	Loss: 3.8249
Training Epoch: 1 [19456/50176]	Loss: 3.9286
Training Epoch: 1 [20480/50176]	Loss: 3.8567
Training Epoch: 1 [21504/50176]	Loss: 3.8629
Training Epoch: 1 [22528/50176]	Loss: 3.8126
Training Epoch: 1 [23552/50176]	Loss: 3.8272
Training Epoch: 1 [24576/50176]	Loss: 3.8096
Training Epoch: 1 [25600/50176]	Loss: 3.8063
Training Epoch: 1 [26624/50176]	Loss: 3.8112
Training Epoch: 1 [27648/50176]	Loss: 3.7862
Training Epoch: 1 [28672/50176]	Loss: 3.7061
Training Epoch: 1 [29696/50176]	Loss: 3.8431
Training Epoch: 1 [30720/50176]	Loss: 3.7565
Training Epoch: 1 [31744/50176]	Loss: 3.7601
Training Epoch: 1 [32768/50176]	Loss: 3.7005
Training Epoch: 1 [33792/50176]	Loss: 3.8117
Training Epoch: 1 [34816/50176]	Loss: 3.7567
Training Epoch: 1 [35840/50176]	Loss: 3.7877
Training Epoch: 1 [36864/50176]	Loss: 3.7252
Training Epoch: 1 [37888/50176]	Loss: 3.7060
Training Epoch: 1 [38912/50176]	Loss: 3.7408
Training Epoch: 1 [39936/50176]	Loss: 3.7013
Training Epoch: 1 [40960/50176]	Loss: 3.7496
Training Epoch: 1 [41984/50176]	Loss: 3.6677
Training Epoch: 1 [43008/50176]	Loss: 3.7348
Training Epoch: 1 [44032/50176]	Loss: 3.6602
Training Epoch: 1 [45056/50176]	Loss: 3.6832
Training Epoch: 1 [46080/50176]	Loss: 3.6301
Training Epoch: 1 [47104/50176]	Loss: 3.6557
Training Epoch: 1 [48128/50176]	Loss: 3.6898
Training Epoch: 1 [49152/50176]	Loss: 3.6428
Training Epoch: 1 [50176/50176]	Loss: 3.6130
2022-12-08 22:42:10.362 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:42:10,392 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.81 energy=512.99
2022-12-08 17:42:10,393 [ZeusDataLoader(train)] Up to epoch 2: time=98.76, energy=14373.77, cost=15828.23
2022-12-08 17:42:10,394 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0036, Accuracy: 0.1147
2022-12-08 22:42:10.583 [ZeusMonitor] Monitor started.
2022-12-08 22:42:10.583 [ZeusMonitor] Running indefinitely. 2022-12-08 22:42:10.583 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:42:10.583 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e3+gpu0.power.log
2022-12-08 17:42:10,592 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:42:11,328 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 17:42:11,329 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 17:42:20,722 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 17:42:59,971 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 17:43:01,906 [ZeusDataLoader(train)] train epoch 3 done: time=51.50 energy=6243.61
2022-12-08 17:43:01,910 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.6010
Training Epoch: 2 [2048/50176]	Loss: 3.6103
Training Epoch: 2 [3072/50176]	Loss: 3.5408
Training Epoch: 2 [4096/50176]	Loss: 3.5474
Training Epoch: 2 [5120/50176]	Loss: 3.5615
Training Epoch: 2 [6144/50176]	Loss: 3.5118
Training Epoch: 2 [7168/50176]	Loss: 3.5781
Training Epoch: 2 [8192/50176]	Loss: 3.6333
Training Epoch: 2 [9216/50176]	Loss: 3.5512
Training Epoch: 2 [10240/50176]	Loss: 3.4561
Training Epoch: 2 [11264/50176]	Loss: 3.4487
Training Epoch: 2 [12288/50176]	Loss: 3.4830
Training Epoch: 2 [13312/50176]	Loss: 3.5397
Training Epoch: 2 [14336/50176]	Loss: 3.5475
Training Epoch: 2 [15360/50176]	Loss: 3.5429
Training Epoch: 2 [16384/50176]	Loss: 3.6258
Training Epoch: 2 [17408/50176]	Loss: 3.5708
Training Epoch: 2 [18432/50176]	Loss: 3.5620
Training Epoch: 2 [19456/50176]	Loss: 3.5041
Training Epoch: 2 [20480/50176]	Loss: 3.5126
Training Epoch: 2 [21504/50176]	Loss: 3.5501
Training Epoch: 2 [22528/50176]	Loss: 3.5103
Training Epoch: 2 [23552/50176]	Loss: 3.4881
Training Epoch: 2 [24576/50176]	Loss: 3.5544
Training Epoch: 2 [25600/50176]	Loss: 3.4901
Training Epoch: 2 [26624/50176]	Loss: 3.5318
Training Epoch: 2 [27648/50176]	Loss: 3.5128
Training Epoch: 2 [28672/50176]	Loss: 3.5095
Training Epoch: 2 [29696/50176]	Loss: 3.4310
Training Epoch: 2 [30720/50176]	Loss: 3.4492
Training Epoch: 2 [31744/50176]	Loss: 3.4235
Training Epoch: 2 [32768/50176]	Loss: 3.4655
Training Epoch: 2 [33792/50176]	Loss: 3.4868
Training Epoch: 2 [34816/50176]	Loss: 3.4430
Training Epoch: 2 [35840/50176]	Loss: 3.3876
Training Epoch: 2 [36864/50176]	Loss: 3.4032
Training Epoch: 2 [37888/50176]	Loss: 3.4732
Training Epoch: 2 [38912/50176]	Loss: 3.3762
Training Epoch: 2 [39936/50176]	Loss: 3.3504
Training Epoch: 2 [40960/50176]	Loss: 3.3681
Training Epoch: 2 [41984/50176]	Loss: 3.3494
Training Epoch: 2 [43008/50176]	Loss: 3.3577
Training Epoch: 2 [44032/50176]	Loss: 3.3083
Training Epoch: 2 [45056/50176]	Loss: 3.3707
Training Epoch: 2 [46080/50176]	Loss: 3.3618
Training Epoch: 2 [47104/50176]	Loss: 3.3058
Training Epoch: 2 [48128/50176]	Loss: 3.3387
Training Epoch: 2 [49152/50176]	Loss: 3.3245
Training Epoch: 2 [50176/50176]	Loss: 3.2574
2022-12-08 22:43:06.160 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:43:06,196 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.28 energy=481.81
2022-12-08 17:43:06,197 [ZeusDataLoader(train)] Up to epoch 3: time=154.54, energy=21099.19, cost=24071.91
2022-12-08 17:43:06,198 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0034, Accuracy: 0.1649
2022-12-08 17:43:06,414 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 22:43:06.417 [ZeusMonitor] Monitor started.
2022-12-08 22:43:06.417 [ZeusMonitor] Running indefinitely. 2022-12-08 22:43:06.417 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:43:06.417 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e4+gpu0.power.log
2022-12-08 17:43:07,189 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 17:43:07,189 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 17:43:32,248 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 17:45:15,740 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 17:45:15,743 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 17:45:18,135 [ZeusDataLoader(train)] train epoch 4 done: time=131.93 energy=13458.04
2022-12-08 17:45:18,138 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.2500
Training Epoch: 3 [2048/50176]	Loss: 3.2233
Training Epoch: 3 [3072/50176]	Loss: 3.2406
Training Epoch: 3 [4096/50176]	Loss: 3.3061
Training Epoch: 3 [5120/50176]	Loss: 3.2234
Training Epoch: 3 [6144/50176]	Loss: 3.2615
Training Epoch: 3 [7168/50176]	Loss: 3.2445
Training Epoch: 3 [8192/50176]	Loss: 3.2826
Training Epoch: 3 [9216/50176]	Loss: 3.2782
Training Epoch: 3 [10240/50176]	Loss: 3.2165
Training Epoch: 3 [11264/50176]	Loss: 3.2995
Training Epoch: 3 [12288/50176]	Loss: 3.2323
Training Epoch: 3 [13312/50176]	Loss: 3.3073
Training Epoch: 3 [14336/50176]	Loss: 3.2085
Training Epoch: 3 [15360/50176]	Loss: 3.1580
Training Epoch: 3 [16384/50176]	Loss: 3.2223
Training Epoch: 3 [17408/50176]	Loss: 3.1654
Training Epoch: 3 [18432/50176]	Loss: 3.2336
Training Epoch: 3 [19456/50176]	Loss: 3.1755
Training Epoch: 3 [20480/50176]	Loss: 3.1254
Training Epoch: 3 [21504/50176]	Loss: 3.1708
Training Epoch: 3 [22528/50176]	Loss: 3.0870
Training Epoch: 3 [23552/50176]	Loss: 3.1420
Training Epoch: 3 [24576/50176]	Loss: 3.1818
Training Epoch: 3 [25600/50176]	Loss: 3.0013
Training Epoch: 3 [26624/50176]	Loss: 3.2077
Training Epoch: 3 [27648/50176]	Loss: 3.1552
Training Epoch: 3 [28672/50176]	Loss: 3.0803
Training Epoch: 3 [29696/50176]	Loss: 3.1031
Training Epoch: 3 [30720/50176]	Loss: 3.0702
Training Epoch: 3 [31744/50176]	Loss: 3.0790
Training Epoch: 3 [32768/50176]	Loss: 3.0898
Training Epoch: 3 [33792/50176]	Loss: 2.9987
Training Epoch: 3 [34816/50176]	Loss: 3.0636
Training Epoch: 3 [35840/50176]	Loss: 3.0164
Training Epoch: 3 [36864/50176]	Loss: 3.0736
Training Epoch: 3 [37888/50176]	Loss: 3.1536
Training Epoch: 3 [38912/50176]	Loss: 3.1442
Training Epoch: 3 [39936/50176]	Loss: 3.0787
Training Epoch: 3 [40960/50176]	Loss: 2.9469
Training Epoch: 3 [41984/50176]	Loss: 3.0576
Training Epoch: 3 [43008/50176]	Loss: 2.9338
Training Epoch: 3 [44032/50176]	Loss: 2.9990
Training Epoch: 3 [45056/50176]	Loss: 2.9629
Training Epoch: 3 [46080/50176]	Loss: 3.0219
Training Epoch: 3 [47104/50176]	Loss: 2.9078
Training Epoch: 3 [48128/50176]	Loss: 3.1560
Training Epoch: 3 [49152/50176]	Loss: 2.9582
Training Epoch: 3 [50176/50176]	Loss: 2.9711
2022-12-08 22:45:21.925 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+lr0.0060000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 155.16304190626855, "150000": 146.66679122833526, "125000": 123.11079515402562, "100000": 102.24933636766599}, "train_throughput": {"175000": 1.1359478370950427, "150000": 1.1007655943504855, "125000": 0.9684575298543399, "100000": 0.3672341515196985}, "eval_power": {"175000": 137.48240735072176, "150000": 134.78162791311982, "125000": 112.630877961285}, "eval_throughput": {"175000": 2.6088153813743062, "150000": 2.6273896195624724, "125000": 2.337656921522037}, "optimal_pl": 175000}
2022-12-08 17:45:21,983 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.83 energy=526.99
2022-12-08 17:45:21,983 [ZeusDataLoader(train)] Up to epoch 4: time=290.30, energy=35084.23, cost=42943.33
2022-12-08 17:45:21,984 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:45:21,984 [ZeusDataLoader(train)] Expected next epoch: time=337.27, energy=42304.30, cost=50663.15
2022-12-08 17:45:21,985 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0030, Accuracy: 0.2454
2022-12-08 17:45:22,194 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:45:22,195 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:45:22.209 [ZeusMonitor] Monitor started.
2022-12-08 22:45:22.209 [ZeusMonitor] Running indefinitely. 2022-12-08 22:45:22.209 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:45:22.209 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e5+gpu0.power.log
2022-12-08 17:46:06,545 [ZeusDataLoader(train)] train epoch 5 done: time=44.55 energy=6772.30
2022-12-08 17:46:06,549 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.0218
Training Epoch: 4 [2048/50176]	Loss: 2.9175
Training Epoch: 4 [3072/50176]	Loss: 2.8868
Training Epoch: 4 [4096/50176]	Loss: 2.9163
Training Epoch: 4 [5120/50176]	Loss: 2.8734
Training Epoch: 4 [6144/50176]	Loss: 2.9483
Training Epoch: 4 [7168/50176]	Loss: 2.8958
Training Epoch: 4 [8192/50176]	Loss: 2.9441
Training Epoch: 4 [9216/50176]	Loss: 2.9258
Training Epoch: 4 [10240/50176]	Loss: 2.9399
Training Epoch: 4 [11264/50176]	Loss: 2.9048
Training Epoch: 4 [12288/50176]	Loss: 2.9027
Training Epoch: 4 [13312/50176]	Loss: 2.8627
Training Epoch: 4 [14336/50176]	Loss: 2.9328
Training Epoch: 4 [15360/50176]	Loss: 2.8763
Training Epoch: 4 [16384/50176]	Loss: 2.7590
Training Epoch: 4 [17408/50176]	Loss: 2.8388
Training Epoch: 4 [18432/50176]	Loss: 2.8530
Training Epoch: 4 [19456/50176]	Loss: 2.8599
Training Epoch: 4 [20480/50176]	Loss: 2.8334
Training Epoch: 4 [21504/50176]	Loss: 2.8754
Training Epoch: 4 [22528/50176]	Loss: 2.8043
Training Epoch: 4 [23552/50176]	Loss: 2.7655
Training Epoch: 4 [24576/50176]	Loss: 2.7927
Training Epoch: 4 [25600/50176]	Loss: 2.7855
Training Epoch: 4 [26624/50176]	Loss: 2.7518
Training Epoch: 4 [27648/50176]	Loss: 2.8340
Training Epoch: 4 [28672/50176]	Loss: 2.7310
Training Epoch: 4 [29696/50176]	Loss: 2.8430
Training Epoch: 4 [30720/50176]	Loss: 2.8383
Training Epoch: 4 [31744/50176]	Loss: 2.7944
Training Epoch: 4 [32768/50176]	Loss: 2.8265
Training Epoch: 4 [33792/50176]	Loss: 2.7853
Training Epoch: 4 [34816/50176]	Loss: 2.7118
Training Epoch: 4 [35840/50176]	Loss: 2.8437
Training Epoch: 4 [36864/50176]	Loss: 2.7828
Training Epoch: 4 [37888/50176]	Loss: 2.9519
Training Epoch: 4 [38912/50176]	Loss: 2.7773
Training Epoch: 4 [39936/50176]	Loss: 2.7428
Training Epoch: 4 [40960/50176]	Loss: 2.7217
Training Epoch: 4 [41984/50176]	Loss: 2.6957
Training Epoch: 4 [43008/50176]	Loss: 2.7389
Training Epoch: 4 [44032/50176]	Loss: 2.7021
Training Epoch: 4 [45056/50176]	Loss: 2.7359
Training Epoch: 4 [46080/50176]	Loss: 2.8238
Training Epoch: 4 [47104/50176]	Loss: 2.8524
Training Epoch: 4 [48128/50176]	Loss: 2.7892
Training Epoch: 4 [49152/50176]	Loss: 2.7825
Training Epoch: 4 [50176/50176]	Loss: 2.8959
2022-12-08 22:46:10.305 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:46:10,320 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.76 energy=511.24
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Up to epoch 5: time=338.61, energy=42367.77, cost=50812.67
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:46:10,321 [ZeusDataLoader(train)] Expected next epoch: time=385.58, energy=49587.84, cost=58532.48
2022-12-08 17:46:10,322 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0028, Accuracy: 0.2749
2022-12-08 17:46:10,563 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:46:10,564 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:46:10.578 [ZeusMonitor] Monitor started.
2022-12-08 22:46:10.578 [ZeusMonitor] Running indefinitely. 2022-12-08 22:46:10.578 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:46:10.578 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e6+gpu0.power.log
2022-12-08 17:46:54,973 [ZeusDataLoader(train)] train epoch 6 done: time=44.64 energy=6778.34
2022-12-08 17:46:54,977 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.5503
Training Epoch: 5 [2048/50176]	Loss: 2.6450
Training Epoch: 5 [3072/50176]	Loss: 2.7770
Training Epoch: 5 [4096/50176]	Loss: 2.6097
Training Epoch: 5 [5120/50176]	Loss: 2.6012
Training Epoch: 5 [6144/50176]	Loss: 2.6692
Training Epoch: 5 [7168/50176]	Loss: 2.5702
Training Epoch: 5 [8192/50176]	Loss: 2.5819
Training Epoch: 5 [9216/50176]	Loss: 2.5477
Training Epoch: 5 [10240/50176]	Loss: 2.6818
Training Epoch: 5 [11264/50176]	Loss: 2.7209
Training Epoch: 5 [12288/50176]	Loss: 2.5369
Training Epoch: 5 [13312/50176]	Loss: 2.6260
Training Epoch: 5 [14336/50176]	Loss: 2.5694
Training Epoch: 5 [15360/50176]	Loss: 2.6594
Training Epoch: 5 [16384/50176]	Loss: 2.5763
Training Epoch: 5 [17408/50176]	Loss: 2.6138
Training Epoch: 5 [18432/50176]	Loss: 2.5438
Training Epoch: 5 [19456/50176]	Loss: 2.6227
Training Epoch: 5 [20480/50176]	Loss: 2.6105
Training Epoch: 5 [21504/50176]	Loss: 2.5486
Training Epoch: 5 [22528/50176]	Loss: 2.6570
Training Epoch: 5 [23552/50176]	Loss: 2.6426
Training Epoch: 5 [24576/50176]	Loss: 2.6466
Training Epoch: 5 [25600/50176]	Loss: 2.5592
Training Epoch: 5 [26624/50176]	Loss: 2.5638
Training Epoch: 5 [27648/50176]	Loss: 2.5938
Training Epoch: 5 [28672/50176]	Loss: 2.6271
Training Epoch: 5 [29696/50176]	Loss: 2.5469
Training Epoch: 5 [30720/50176]	Loss: 2.5297
Training Epoch: 5 [31744/50176]	Loss: 2.6295
Training Epoch: 5 [32768/50176]	Loss: 2.6079
Training Epoch: 5 [33792/50176]	Loss: 2.5120
Training Epoch: 5 [34816/50176]	Loss: 2.5706
Training Epoch: 5 [35840/50176]	Loss: 2.6083
Training Epoch: 5 [36864/50176]	Loss: 2.4759
Training Epoch: 5 [37888/50176]	Loss: 2.4812
Training Epoch: 5 [38912/50176]	Loss: 2.5108
Training Epoch: 5 [39936/50176]	Loss: 2.5770
Training Epoch: 5 [40960/50176]	Loss: 2.4255
Training Epoch: 5 [41984/50176]	Loss: 2.5435
Training Epoch: 5 [43008/50176]	Loss: 2.5512
Training Epoch: 5 [44032/50176]	Loss: 2.5799
Training Epoch: 5 [45056/50176]	Loss: 2.6480
Training Epoch: 5 [46080/50176]	Loss: 2.4604
Training Epoch: 5 [47104/50176]	Loss: 2.5019
Training Epoch: 5 [48128/50176]	Loss: 2.5481
Training Epoch: 5 [49152/50176]	Loss: 2.5648
Training Epoch: 5 [50176/50176]	Loss: 2.5076
2022-12-08 22:46:58.792 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:46:58,821 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.84 energy=532.30
2022-12-08 17:46:58,821 [ZeusDataLoader(train)] Up to epoch 6: time=387.09, energy=49678.40, cost=58709.84
2022-12-08 17:46:58,821 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:46:58,822 [ZeusDataLoader(train)] Expected next epoch: time=434.06, energy=56898.47, cost=66429.66
2022-12-08 17:46:58,823 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0026, Accuracy: 0.3287
2022-12-08 17:46:59,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:46:59,043 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:46:59.045 [ZeusMonitor] Monitor started.
2022-12-08 22:46:59.045 [ZeusMonitor] Running indefinitely. 2022-12-08 22:46:59.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:46:59.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e7+gpu0.power.log
2022-12-08 17:47:43,115 [ZeusDataLoader(train)] train epoch 7 done: time=44.28 energy=6735.62
2022-12-08 17:47:43,119 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.4289
Training Epoch: 6 [2048/50176]	Loss: 2.3255
Training Epoch: 6 [3072/50176]	Loss: 2.4750
Training Epoch: 6 [4096/50176]	Loss: 2.4507
Training Epoch: 6 [5120/50176]	Loss: 2.3279
Training Epoch: 6 [6144/50176]	Loss: 2.4013
Training Epoch: 6 [7168/50176]	Loss: 2.3858
Training Epoch: 6 [8192/50176]	Loss: 2.3379
Training Epoch: 6 [9216/50176]	Loss: 2.4862
Training Epoch: 6 [10240/50176]	Loss: 2.4500
Training Epoch: 6 [11264/50176]	Loss: 2.3590
Training Epoch: 6 [12288/50176]	Loss: 2.4640
Training Epoch: 6 [13312/50176]	Loss: 2.3647
Training Epoch: 6 [14336/50176]	Loss: 2.3297
Training Epoch: 6 [15360/50176]	Loss: 2.2848
Training Epoch: 6 [16384/50176]	Loss: 2.3952
Training Epoch: 6 [17408/50176]	Loss: 2.3308
Training Epoch: 6 [18432/50176]	Loss: 2.4060
Training Epoch: 6 [19456/50176]	Loss: 2.3155
Training Epoch: 6 [20480/50176]	Loss: 2.4199
Training Epoch: 6 [21504/50176]	Loss: 2.4303
Training Epoch: 6 [22528/50176]	Loss: 2.3813
Training Epoch: 6 [23552/50176]	Loss: 2.3837
Training Epoch: 6 [24576/50176]	Loss: 2.3603
Training Epoch: 6 [25600/50176]	Loss: 2.3395
Training Epoch: 6 [26624/50176]	Loss: 2.4119
Training Epoch: 6 [27648/50176]	Loss: 2.3240
Training Epoch: 6 [28672/50176]	Loss: 2.2240
Training Epoch: 6 [29696/50176]	Loss: 2.3463
Training Epoch: 6 [30720/50176]	Loss: 2.2659
Training Epoch: 6 [31744/50176]	Loss: 2.2949
Training Epoch: 6 [32768/50176]	Loss: 2.2997
Training Epoch: 6 [33792/50176]	Loss: 2.3484
Training Epoch: 6 [34816/50176]	Loss: 2.3935
Training Epoch: 6 [35840/50176]	Loss: 2.3598
Training Epoch: 6 [36864/50176]	Loss: 2.4138
Training Epoch: 6 [37888/50176]	Loss: 2.4065
Training Epoch: 6 [38912/50176]	Loss: 2.3489
Training Epoch: 6 [39936/50176]	Loss: 2.4211
Training Epoch: 6 [40960/50176]	Loss: 2.3646
Training Epoch: 6 [41984/50176]	Loss: 2.3354
Training Epoch: 6 [43008/50176]	Loss: 2.3131
Training Epoch: 6 [44032/50176]	Loss: 2.3169
Training Epoch: 6 [45056/50176]	Loss: 2.3192
Training Epoch: 6 [46080/50176]	Loss: 2.4005
Training Epoch: 6 [47104/50176]	Loss: 2.2926
Training Epoch: 6 [48128/50176]	Loss: 2.3516
Training Epoch: 6 [49152/50176]	Loss: 2.3073
Training Epoch: 6 [50176/50176]	Loss: 2.3037
2022-12-08 22:47:46.878 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:47:46,914 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.79 energy=520.90
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Up to epoch 7: time=435.16, energy=56934.92, cost=66544.35
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:47:46,915 [ZeusDataLoader(train)] Expected next epoch: time=482.13, energy=64154.99, cost=74264.17
2022-12-08 17:47:46,916 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0023, Accuracy: 0.3712
2022-12-08 17:47:47,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:47:47,139 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:47:47.141 [ZeusMonitor] Monitor started.
2022-12-08 22:47:47.141 [ZeusMonitor] Running indefinitely. 2022-12-08 22:47:47.141 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:47:47.141 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e8+gpu0.power.log
2022-12-08 17:48:31,061 [ZeusDataLoader(train)] train epoch 8 done: time=44.14 energy=6699.75
2022-12-08 17:48:31,065 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.2442
Training Epoch: 7 [2048/50176]	Loss: 2.1902
Training Epoch: 7 [3072/50176]	Loss: 2.1735
Training Epoch: 7 [4096/50176]	Loss: 2.1470
Training Epoch: 7 [5120/50176]	Loss: 2.2346
Training Epoch: 7 [6144/50176]	Loss: 2.1513
Training Epoch: 7 [7168/50176]	Loss: 2.2158
Training Epoch: 7 [8192/50176]	Loss: 2.1925
Training Epoch: 7 [9216/50176]	Loss: 2.0649
Training Epoch: 7 [10240/50176]	Loss: 2.0871
Training Epoch: 7 [11264/50176]	Loss: 2.1284
Training Epoch: 7 [12288/50176]	Loss: 2.2311
Training Epoch: 7 [13312/50176]	Loss: 2.1979
Training Epoch: 7 [14336/50176]	Loss: 2.2673
Training Epoch: 7 [15360/50176]	Loss: 2.1679
Training Epoch: 7 [16384/50176]	Loss: 2.1993
Training Epoch: 7 [17408/50176]	Loss: 2.2400
Training Epoch: 7 [18432/50176]	Loss: 2.1729
Training Epoch: 7 [19456/50176]	Loss: 2.1509
Training Epoch: 7 [20480/50176]	Loss: 2.1874
Training Epoch: 7 [21504/50176]	Loss: 2.2800
Training Epoch: 7 [22528/50176]	Loss: 2.2041
Training Epoch: 7 [23552/50176]	Loss: 2.1650
Training Epoch: 7 [24576/50176]	Loss: 2.1513
Training Epoch: 7 [25600/50176]	Loss: 2.1585
Training Epoch: 7 [26624/50176]	Loss: 2.2813
Training Epoch: 7 [27648/50176]	Loss: 2.2404
Training Epoch: 7 [28672/50176]	Loss: 2.1195
Training Epoch: 7 [29696/50176]	Loss: 2.1746
Training Epoch: 7 [30720/50176]	Loss: 2.1869
Training Epoch: 7 [31744/50176]	Loss: 2.2177
Training Epoch: 7 [32768/50176]	Loss: 2.0978
Training Epoch: 7 [33792/50176]	Loss: 2.2193
Training Epoch: 7 [34816/50176]	Loss: 2.2286
Training Epoch: 7 [35840/50176]	Loss: 2.1220
Training Epoch: 7 [36864/50176]	Loss: 2.0427
Training Epoch: 7 [37888/50176]	Loss: 2.0819
Training Epoch: 7 [38912/50176]	Loss: 2.1658
Training Epoch: 7 [39936/50176]	Loss: 2.2385
Training Epoch: 7 [40960/50176]	Loss: 2.2245
Training Epoch: 7 [41984/50176]	Loss: 2.1026
Training Epoch: 7 [43008/50176]	Loss: 2.0612
Training Epoch: 7 [44032/50176]	Loss: 2.0901
Training Epoch: 7 [45056/50176]	Loss: 2.1326
Training Epoch: 7 [46080/50176]	Loss: 2.1906
Training Epoch: 7 [47104/50176]	Loss: 2.0932
Training Epoch: 7 [48128/50176]	Loss: 2.1108
Training Epoch: 7 [49152/50176]	Loss: 2.2335
Training Epoch: 7 [50176/50176]	Loss: 2.0281
2022-12-08 22:48:34.841 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:48:34,867 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.79 energy=532.56
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Up to epoch 8: time=483.09, energy=64167.24, cost=74354.28
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:48:34,867 [ZeusDataLoader(train)] Expected next epoch: time=530.06, energy=71387.31, cost=82074.10
2022-12-08 17:48:34,869 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0023, Accuracy: 0.3880
2022-12-08 17:48:35,070 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:48:35,071 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:48:35.073 [ZeusMonitor] Monitor started.
2022-12-08 22:48:35.073 [ZeusMonitor] Running indefinitely. 2022-12-08 22:48:35.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:48:35.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e9+gpu0.power.log
2022-12-08 17:49:19,074 [ZeusDataLoader(train)] train epoch 9 done: time=44.20 energy=6701.48
2022-12-08 17:49:19,079 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.1301
Training Epoch: 8 [2048/50176]	Loss: 2.1079
Training Epoch: 8 [3072/50176]	Loss: 2.0680
Training Epoch: 8 [4096/50176]	Loss: 2.0088
Training Epoch: 8 [5120/50176]	Loss: 1.9598
Training Epoch: 8 [6144/50176]	Loss: 2.0537
Training Epoch: 8 [7168/50176]	Loss: 2.0101
Training Epoch: 8 [8192/50176]	Loss: 2.0268
Training Epoch: 8 [9216/50176]	Loss: 2.0068
Training Epoch: 8 [10240/50176]	Loss: 2.0661
Training Epoch: 8 [11264/50176]	Loss: 2.0999
Training Epoch: 8 [12288/50176]	Loss: 2.0425
Training Epoch: 8 [13312/50176]	Loss: 2.0678
Training Epoch: 8 [14336/50176]	Loss: 2.0180
Training Epoch: 8 [15360/50176]	Loss: 2.0599
Training Epoch: 8 [16384/50176]	Loss: 2.0127
Training Epoch: 8 [17408/50176]	Loss: 2.1363
Training Epoch: 8 [18432/50176]	Loss: 2.0415
Training Epoch: 8 [19456/50176]	Loss: 2.0141
Training Epoch: 8 [20480/50176]	Loss: 1.9737
Training Epoch: 8 [21504/50176]	Loss: 1.9829
Training Epoch: 8 [22528/50176]	Loss: 2.0164
Training Epoch: 8 [23552/50176]	Loss: 2.0090
Training Epoch: 8 [24576/50176]	Loss: 2.0280
Training Epoch: 8 [25600/50176]	Loss: 2.0786
Training Epoch: 8 [26624/50176]	Loss: 2.0150
Training Epoch: 8 [27648/50176]	Loss: 1.9491
Training Epoch: 8 [28672/50176]	Loss: 2.0480
Training Epoch: 8 [29696/50176]	Loss: 1.9968
Training Epoch: 8 [30720/50176]	Loss: 2.0234
Training Epoch: 8 [31744/50176]	Loss: 2.0117
Training Epoch: 8 [32768/50176]	Loss: 1.9647
Training Epoch: 8 [33792/50176]	Loss: 2.0752
Training Epoch: 8 [34816/50176]	Loss: 2.0767
Training Epoch: 8 [35840/50176]	Loss: 2.0657
Training Epoch: 8 [36864/50176]	Loss: 2.0288
Training Epoch: 8 [37888/50176]	Loss: 2.0709
Training Epoch: 8 [38912/50176]	Loss: 1.9927
Training Epoch: 8 [39936/50176]	Loss: 2.1024
Training Epoch: 8 [40960/50176]	Loss: 2.0215
Training Epoch: 8 [41984/50176]	Loss: 2.0187
Training Epoch: 8 [43008/50176]	Loss: 2.0332
Training Epoch: 8 [44032/50176]	Loss: 2.0921
Training Epoch: 8 [45056/50176]	Loss: 2.0680
Training Epoch: 8 [46080/50176]	Loss: 1.9827
Training Epoch: 8 [47104/50176]	Loss: 2.0769
Training Epoch: 8 [48128/50176]	Loss: 1.9727
Training Epoch: 8 [49152/50176]	Loss: 2.0603
Training Epoch: 8 [50176/50176]	Loss: 2.0336
2022-12-08 22:49:22.875 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:49:22,897 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.81 energy=533.16
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Up to epoch 9: time=531.10, energy=71401.89, cost=82172.26
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:49:22,898 [ZeusDataLoader(train)] Expected next epoch: time=578.07, energy=78621.96, cost=89892.08
2022-12-08 17:49:22,899 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0021, Accuracy: 0.4270
2022-12-08 17:49:23,111 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:49:23,112 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:49:23.125 [ZeusMonitor] Monitor started.
2022-12-08 22:49:23.126 [ZeusMonitor] Running indefinitely. 2022-12-08 22:49:23.126 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:49:23.126 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e10+gpu0.power.log
2022-12-08 17:50:07,050 [ZeusDataLoader(train)] train epoch 10 done: time=44.14 energy=6704.10
2022-12-08 17:50:07,053 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 1.9361
Training Epoch: 9 [2048/50176]	Loss: 1.9446
Training Epoch: 9 [3072/50176]	Loss: 1.9394
Training Epoch: 9 [4096/50176]	Loss: 1.8574
Training Epoch: 9 [5120/50176]	Loss: 1.9815
Training Epoch: 9 [6144/50176]	Loss: 1.8259
Training Epoch: 9 [7168/50176]	Loss: 1.9257
Training Epoch: 9 [8192/50176]	Loss: 1.8961
Training Epoch: 9 [9216/50176]	Loss: 1.8751
Training Epoch: 9 [10240/50176]	Loss: 1.8940
Training Epoch: 9 [11264/50176]	Loss: 1.9890
Training Epoch: 9 [12288/50176]	Loss: 1.9454
Training Epoch: 9 [13312/50176]	Loss: 1.8927
Training Epoch: 9 [14336/50176]	Loss: 1.9174
Training Epoch: 9 [15360/50176]	Loss: 1.9308
Training Epoch: 9 [16384/50176]	Loss: 1.9454
Training Epoch: 9 [17408/50176]	Loss: 1.8163
Training Epoch: 9 [18432/50176]	Loss: 1.9166
Training Epoch: 9 [19456/50176]	Loss: 1.8412
Training Epoch: 9 [20480/50176]	Loss: 1.8722
Training Epoch: 9 [21504/50176]	Loss: 1.8621
Training Epoch: 9 [22528/50176]	Loss: 1.8531
Training Epoch: 9 [23552/50176]	Loss: 1.8713
Training Epoch: 9 [24576/50176]	Loss: 1.9091
Training Epoch: 9 [25600/50176]	Loss: 1.8503
Training Epoch: 9 [26624/50176]	Loss: 1.8347
Training Epoch: 9 [27648/50176]	Loss: 1.9752
Training Epoch: 9 [28672/50176]	Loss: 1.9023
Training Epoch: 9 [29696/50176]	Loss: 1.9307
Training Epoch: 9 [30720/50176]	Loss: 1.7952
Training Epoch: 9 [31744/50176]	Loss: 1.9511
Training Epoch: 9 [32768/50176]	Loss: 1.8943
Training Epoch: 9 [33792/50176]	Loss: 1.7993
Training Epoch: 9 [34816/50176]	Loss: 1.9102
Training Epoch: 9 [35840/50176]	Loss: 1.8720
Training Epoch: 9 [36864/50176]	Loss: 1.8744
Training Epoch: 9 [37888/50176]	Loss: 1.8915
Training Epoch: 9 [38912/50176]	Loss: 1.9170
Training Epoch: 9 [39936/50176]	Loss: 1.8772
Training Epoch: 9 [40960/50176]	Loss: 1.8852
Training Epoch: 9 [41984/50176]	Loss: 1.8248
Training Epoch: 9 [43008/50176]	Loss: 1.9289
Training Epoch: 9 [44032/50176]	Loss: 1.8984
Training Epoch: 9 [45056/50176]	Loss: 1.8610
Training Epoch: 9 [46080/50176]	Loss: 1.8177
Training Epoch: 9 [47104/50176]	Loss: 1.8795
Training Epoch: 9 [48128/50176]	Loss: 1.8246
Training Epoch: 9 [49152/50176]	Loss: 1.8220
Training Epoch: 9 [50176/50176]	Loss: 1.8449
2022-12-08 22:50:10.821 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:50:10,851 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.79 energy=534.01
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Up to epoch 10: time=579.03, energy=78640.00, cost=89985.37
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:50:10,852 [ZeusDataLoader(train)] Expected next epoch: time=626.00, energy=85860.07, cost=97705.19
2022-12-08 17:50:10,853 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0021, Accuracy: 0.4345
2022-12-08 17:50:11,034 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:50:11,035 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:50:11.039 [ZeusMonitor] Monitor started.
2022-12-08 22:50:11.039 [ZeusMonitor] Running indefinitely. 2022-12-08 22:50:11.039 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:50:11.039 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e11+gpu0.power.log
2022-12-08 17:50:55,009 [ZeusDataLoader(train)] train epoch 11 done: time=44.15 energy=6709.81
2022-12-08 17:50:55,013 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 1.7946
Training Epoch: 10 [2048/50176]	Loss: 1.8128
Training Epoch: 10 [3072/50176]	Loss: 1.7192
Training Epoch: 10 [4096/50176]	Loss: 1.8936
Training Epoch: 10 [5120/50176]	Loss: 1.7841
Training Epoch: 10 [6144/50176]	Loss: 1.8473
Training Epoch: 10 [7168/50176]	Loss: 1.7371
Training Epoch: 10 [8192/50176]	Loss: 1.7674
Training Epoch: 10 [9216/50176]	Loss: 1.7403
Training Epoch: 10 [10240/50176]	Loss: 1.6766
Training Epoch: 10 [11264/50176]	Loss: 1.9221
Training Epoch: 10 [12288/50176]	Loss: 1.7556
Training Epoch: 10 [13312/50176]	Loss: 1.8935
Training Epoch: 10 [14336/50176]	Loss: 1.9296
Training Epoch: 10 [15360/50176]	Loss: 1.8389
Training Epoch: 10 [16384/50176]	Loss: 1.8891
Training Epoch: 10 [17408/50176]	Loss: 1.8608
Training Epoch: 10 [18432/50176]	Loss: 1.7840
Training Epoch: 10 [19456/50176]	Loss: 1.8379
Training Epoch: 10 [20480/50176]	Loss: 1.7958
Training Epoch: 10 [21504/50176]	Loss: 1.7965
Training Epoch: 10 [22528/50176]	Loss: 1.8065
Training Epoch: 10 [23552/50176]	Loss: 1.7993
Training Epoch: 10 [24576/50176]	Loss: 1.7903
Training Epoch: 10 [25600/50176]	Loss: 1.7652
Training Epoch: 10 [26624/50176]	Loss: 1.7582
Training Epoch: 10 [27648/50176]	Loss: 1.7576
Training Epoch: 10 [28672/50176]	Loss: 1.8260
Training Epoch: 10 [29696/50176]	Loss: 1.8659
Training Epoch: 10 [30720/50176]	Loss: 1.7044
Training Epoch: 10 [31744/50176]	Loss: 1.8662
Training Epoch: 10 [32768/50176]	Loss: 1.7430
Training Epoch: 10 [33792/50176]	Loss: 1.7765
Training Epoch: 10 [34816/50176]	Loss: 1.8043
Training Epoch: 10 [35840/50176]	Loss: 1.8714
Training Epoch: 10 [36864/50176]	Loss: 1.8573
Training Epoch: 10 [37888/50176]	Loss: 1.7251
Training Epoch: 10 [38912/50176]	Loss: 1.7163
Training Epoch: 10 [39936/50176]	Loss: 1.8288
Training Epoch: 10 [40960/50176]	Loss: 1.6506
Training Epoch: 10 [41984/50176]	Loss: 1.6354
Training Epoch: 10 [43008/50176]	Loss: 1.8231
Training Epoch: 10 [44032/50176]	Loss: 1.7812
Training Epoch: 10 [45056/50176]	Loss: 1.6826
Training Epoch: 10 [46080/50176]	Loss: 1.6803
Training Epoch: 10 [47104/50176]	Loss: 1.8126
Training Epoch: 10 [48128/50176]	Loss: 1.7899
Training Epoch: 10 [49152/50176]	Loss: 1.8074
Training Epoch: 10 [50176/50176]	Loss: 1.8167
2022-12-08 22:50:58.779 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:50:58,821 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.80 energy=520.83
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Up to epoch 11: time=626.98, energy=85870.64, cost=97796.17
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:50:58,822 [ZeusDataLoader(train)] Expected next epoch: time=673.95, energy=93090.71, cost=105515.98
2022-12-08 17:50:58,823 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0019, Accuracy: 0.4778
2022-12-08 17:50:58,992 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:50:58,993 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:50:58.996 [ZeusMonitor] Monitor started.
2022-12-08 22:50:58.997 [ZeusMonitor] Running indefinitely. 2022-12-08 22:50:58.997 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:50:58.997 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e12+gpu0.power.log
2022-12-08 17:51:42,949 [ZeusDataLoader(train)] train epoch 12 done: time=44.12 energy=6705.17
2022-12-08 17:51:42,952 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 1.5707
Training Epoch: 11 [2048/50176]	Loss: 1.6079
Training Epoch: 11 [3072/50176]	Loss: 1.6174
Training Epoch: 11 [4096/50176]	Loss: 1.8180
Training Epoch: 11 [5120/50176]	Loss: 1.7361
Training Epoch: 11 [6144/50176]	Loss: 1.5298
Training Epoch: 11 [7168/50176]	Loss: 1.5999
Training Epoch: 11 [8192/50176]	Loss: 1.6825
Training Epoch: 11 [9216/50176]	Loss: 1.6315
Training Epoch: 11 [10240/50176]	Loss: 1.7589
Training Epoch: 11 [11264/50176]	Loss: 1.6254
Training Epoch: 11 [12288/50176]	Loss: 1.6280
Training Epoch: 11 [13312/50176]	Loss: 1.7432
Training Epoch: 11 [14336/50176]	Loss: 1.5908
Training Epoch: 11 [15360/50176]	Loss: 1.7472
Training Epoch: 11 [16384/50176]	Loss: 1.7103
Training Epoch: 11 [17408/50176]	Loss: 1.6438
Training Epoch: 11 [18432/50176]	Loss: 1.6711
Training Epoch: 11 [19456/50176]	Loss: 1.6510
Training Epoch: 11 [20480/50176]	Loss: 1.7686
Training Epoch: 11 [21504/50176]	Loss: 1.7671
Training Epoch: 11 [22528/50176]	Loss: 1.6975
Training Epoch: 11 [23552/50176]	Loss: 1.7639
Training Epoch: 11 [24576/50176]	Loss: 1.6437
Training Epoch: 11 [25600/50176]	Loss: 1.6597
Training Epoch: 11 [26624/50176]	Loss: 1.6928
Training Epoch: 11 [27648/50176]	Loss: 1.6786
Training Epoch: 11 [28672/50176]	Loss: 1.6538
Training Epoch: 11 [29696/50176]	Loss: 1.7255
Training Epoch: 11 [30720/50176]	Loss: 1.6312
Training Epoch: 11 [31744/50176]	Loss: 1.6984
Training Epoch: 11 [32768/50176]	Loss: 1.7194
Training Epoch: 11 [33792/50176]	Loss: 1.7601
Training Epoch: 11 [34816/50176]	Loss: 1.8226
Training Epoch: 11 [35840/50176]	Loss: 1.7074
Training Epoch: 11 [36864/50176]	Loss: 1.6516
Training Epoch: 11 [37888/50176]	Loss: 1.7150
Training Epoch: 11 [38912/50176]	Loss: 1.6905
Training Epoch: 11 [39936/50176]	Loss: 1.7073
Training Epoch: 11 [40960/50176]	Loss: 1.6626
Training Epoch: 11 [41984/50176]	Loss: 1.6990
Training Epoch: 11 [43008/50176]	Loss: 1.7132
Training Epoch: 11 [44032/50176]	Loss: 1.6417
Training Epoch: 11 [45056/50176]	Loss: 1.7342
Training Epoch: 11 [46080/50176]	Loss: 1.6015
Training Epoch: 11 [47104/50176]	Loss: 1.7173
Training Epoch: 11 [48128/50176]	Loss: 1.7137
Training Epoch: 11 [49152/50176]	Loss: 1.6672
Training Epoch: 11 [50176/50176]	Loss: 1.6790
2022-12-08 22:51:46.722 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:51:46,770 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.81 energy=531.98
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Up to epoch 12: time=674.91, energy=93107.79, cost=105608.24
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:51:46,770 [ZeusDataLoader(train)] Expected next epoch: time=721.88, energy=100327.86, cost=113328.06
2022-12-08 17:51:46,771 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0019, Accuracy: 0.4757
2022-12-08 17:51:46,997 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:51:46,998 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:51:47.000 [ZeusMonitor] Monitor started.
2022-12-08 22:51:47.000 [ZeusMonitor] Running indefinitely. 2022-12-08 22:51:47.000 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:51:47.000 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e13+gpu0.power.log
2022-12-08 17:52:30,927 [ZeusDataLoader(train)] train epoch 13 done: time=44.15 energy=6713.34
2022-12-08 17:52:30,931 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 1.6396
Training Epoch: 12 [2048/50176]	Loss: 1.5612
Training Epoch: 12 [3072/50176]	Loss: 1.6720
Training Epoch: 12 [4096/50176]	Loss: 1.5680
Training Epoch: 12 [5120/50176]	Loss: 1.5577
Training Epoch: 12 [6144/50176]	Loss: 1.6539
Training Epoch: 12 [7168/50176]	Loss: 1.6489
Training Epoch: 12 [8192/50176]	Loss: 1.4891
Training Epoch: 12 [9216/50176]	Loss: 1.6761
Training Epoch: 12 [10240/50176]	Loss: 1.5676
Training Epoch: 12 [11264/50176]	Loss: 1.7461
Training Epoch: 12 [12288/50176]	Loss: 1.5880
Training Epoch: 12 [13312/50176]	Loss: 1.5406
Training Epoch: 12 [14336/50176]	Loss: 1.5602
Training Epoch: 12 [15360/50176]	Loss: 1.5317
Training Epoch: 12 [16384/50176]	Loss: 1.5778
Training Epoch: 12 [17408/50176]	Loss: 1.5440
Training Epoch: 12 [18432/50176]	Loss: 1.6091
Training Epoch: 12 [19456/50176]	Loss: 1.5827
Training Epoch: 12 [20480/50176]	Loss: 1.6022
Training Epoch: 12 [21504/50176]	Loss: 1.7263
Training Epoch: 12 [22528/50176]	Loss: 1.5700
Training Epoch: 12 [23552/50176]	Loss: 1.6493
Training Epoch: 12 [24576/50176]	Loss: 1.5473
Training Epoch: 12 [25600/50176]	Loss: 1.6234
Training Epoch: 12 [26624/50176]	Loss: 1.6998
Training Epoch: 12 [27648/50176]	Loss: 1.5133
Training Epoch: 12 [28672/50176]	Loss: 1.6399
Training Epoch: 12 [29696/50176]	Loss: 1.6085
Training Epoch: 12 [30720/50176]	Loss: 1.5461
Training Epoch: 12 [31744/50176]	Loss: 1.5947
Training Epoch: 12 [32768/50176]	Loss: 1.6222
Training Epoch: 12 [33792/50176]	Loss: 1.5324
Training Epoch: 12 [34816/50176]	Loss: 1.5350
Training Epoch: 12 [35840/50176]	Loss: 1.6052
Training Epoch: 12 [36864/50176]	Loss: 1.6165
Training Epoch: 12 [37888/50176]	Loss: 1.6470
Training Epoch: 12 [38912/50176]	Loss: 1.5555
Training Epoch: 12 [39936/50176]	Loss: 1.6201
Training Epoch: 12 [40960/50176]	Loss: 1.5060
Training Epoch: 12 [41984/50176]	Loss: 1.6755
Training Epoch: 12 [43008/50176]	Loss: 1.5861
Training Epoch: 12 [44032/50176]	Loss: 1.6837
Training Epoch: 12 [45056/50176]	Loss: 1.5508
Training Epoch: 12 [46080/50176]	Loss: 1.6186
Training Epoch: 12 [47104/50176]	Loss: 1.5674
Training Epoch: 12 [48128/50176]	Loss: 1.5787
Training Epoch: 12 [49152/50176]	Loss: 1.6114
Training Epoch: 12 [50176/50176]	Loss: 1.5680
2022-12-08 22:52:34.669 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:52:34,704 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.77 energy=518.27
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Up to epoch 13: time=722.82, energy=100339.40, cost=113416.36
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:52:34,705 [ZeusDataLoader(train)] Expected next epoch: time=769.79, energy=107559.47, cost=121136.18
2022-12-08 17:52:34,706 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0018, Accuracy: 0.4959
2022-12-08 17:52:34,927 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:52:34,928 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:52:34.942 [ZeusMonitor] Monitor started.
2022-12-08 22:52:34.942 [ZeusMonitor] Running indefinitely. 2022-12-08 22:52:34.942 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:52:34.942 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e14+gpu0.power.log
2022-12-08 17:53:18,910 [ZeusDataLoader(train)] train epoch 14 done: time=44.20 energy=6713.76
2022-12-08 17:53:18,914 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 1.5313
Training Epoch: 13 [2048/50176]	Loss: 1.5063
Training Epoch: 13 [3072/50176]	Loss: 1.5353
Training Epoch: 13 [4096/50176]	Loss: 1.4375
Training Epoch: 13 [5120/50176]	Loss: 1.4878
Training Epoch: 13 [6144/50176]	Loss: 1.5568
Training Epoch: 13 [7168/50176]	Loss: 1.4620
Training Epoch: 13 [8192/50176]	Loss: 1.4524
Training Epoch: 13 [9216/50176]	Loss: 1.4674
Training Epoch: 13 [10240/50176]	Loss: 1.6480
Training Epoch: 13 [11264/50176]	Loss: 1.4386
Training Epoch: 13 [12288/50176]	Loss: 1.5121
Training Epoch: 13 [13312/50176]	Loss: 1.5336
Training Epoch: 13 [14336/50176]	Loss: 1.4871
Training Epoch: 13 [15360/50176]	Loss: 1.5454
Training Epoch: 13 [16384/50176]	Loss: 1.4949
Training Epoch: 13 [17408/50176]	Loss: 1.5407
Training Epoch: 13 [18432/50176]	Loss: 1.4587
Training Epoch: 13 [19456/50176]	Loss: 1.5056
Training Epoch: 13 [20480/50176]	Loss: 1.5041
Training Epoch: 13 [21504/50176]	Loss: 1.5126
Training Epoch: 13 [22528/50176]	Loss: 1.4790
Training Epoch: 13 [23552/50176]	Loss: 1.5166
Training Epoch: 13 [24576/50176]	Loss: 1.4762
Training Epoch: 13 [25600/50176]	Loss: 1.5386
Training Epoch: 13 [26624/50176]	Loss: 1.6107
Training Epoch: 13 [27648/50176]	Loss: 1.5045
Training Epoch: 13 [28672/50176]	Loss: 1.5085
Training Epoch: 13 [29696/50176]	Loss: 1.4687
Training Epoch: 13 [30720/50176]	Loss: 1.4862
Training Epoch: 13 [31744/50176]	Loss: 1.5409
Training Epoch: 13 [32768/50176]	Loss: 1.4634
Training Epoch: 13 [33792/50176]	Loss: 1.6120
Training Epoch: 13 [34816/50176]	Loss: 1.6203
Training Epoch: 13 [35840/50176]	Loss: 1.6160
Training Epoch: 13 [36864/50176]	Loss: 1.5447
Training Epoch: 13 [37888/50176]	Loss: 1.5829
Training Epoch: 13 [38912/50176]	Loss: 1.4629
Training Epoch: 13 [39936/50176]	Loss: 1.4810
Training Epoch: 13 [40960/50176]	Loss: 1.5770
Training Epoch: 13 [41984/50176]	Loss: 1.4942
Training Epoch: 13 [43008/50176]	Loss: 1.4354
Training Epoch: 13 [44032/50176]	Loss: 1.5650
Training Epoch: 13 [45056/50176]	Loss: 1.4945
Training Epoch: 13 [46080/50176]	Loss: 1.4949
Training Epoch: 13 [47104/50176]	Loss: 1.4769
Training Epoch: 13 [48128/50176]	Loss: 1.5229
Training Epoch: 13 [49152/50176]	Loss: 1.4808
Training Epoch: 13 [50176/50176]	Loss: 1.6495
2022-12-08 22:53:22.651 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:53:22,672 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.75 energy=516.93
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Up to epoch 14: time=770.76, energy=107570.09, cost=121226.91
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:53:22,672 [ZeusDataLoader(train)] Expected next epoch: time=817.73, energy=114790.16, cost=128946.72
2022-12-08 17:53:22,673 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0017, Accuracy: 0.5095
2022-12-08 17:53:22,888 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:53:22,889 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:53:22.903 [ZeusMonitor] Monitor started.
2022-12-08 22:53:22.903 [ZeusMonitor] Running indefinitely. 2022-12-08 22:53:22.903 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:53:22.903 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e15+gpu0.power.log
2022-12-08 17:54:07,040 [ZeusDataLoader(train)] train epoch 15 done: time=44.34 energy=6722.29
2022-12-08 17:54:07,052 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.3875
Training Epoch: 14 [2048/50176]	Loss: 1.4910
Training Epoch: 14 [3072/50176]	Loss: 1.4570
Training Epoch: 14 [4096/50176]	Loss: 1.5257
Training Epoch: 14 [5120/50176]	Loss: 1.3966
Training Epoch: 14 [6144/50176]	Loss: 1.4010
Training Epoch: 14 [7168/50176]	Loss: 1.3315
Training Epoch: 14 [8192/50176]	Loss: 1.3981
Training Epoch: 14 [9216/50176]	Loss: 1.3479
Training Epoch: 14 [10240/50176]	Loss: 1.3858
Training Epoch: 14 [11264/50176]	Loss: 1.3598
Training Epoch: 14 [12288/50176]	Loss: 1.4455
Training Epoch: 14 [13312/50176]	Loss: 1.4350
Training Epoch: 14 [14336/50176]	Loss: 1.3745
Training Epoch: 14 [15360/50176]	Loss: 1.4193
Training Epoch: 14 [16384/50176]	Loss: 1.3428
Training Epoch: 14 [17408/50176]	Loss: 1.4611
Training Epoch: 14 [18432/50176]	Loss: 1.4503
Training Epoch: 14 [19456/50176]	Loss: 1.4001
Training Epoch: 14 [20480/50176]	Loss: 1.3988
Training Epoch: 14 [21504/50176]	Loss: 1.4695
Training Epoch: 14 [22528/50176]	Loss: 1.4151
Training Epoch: 14 [23552/50176]	Loss: 1.4290
Training Epoch: 14 [24576/50176]	Loss: 1.4541
Training Epoch: 14 [25600/50176]	Loss: 1.5576
Training Epoch: 14 [26624/50176]	Loss: 1.3824
Training Epoch: 14 [27648/50176]	Loss: 1.3657
Training Epoch: 14 [28672/50176]	Loss: 1.5404
Training Epoch: 14 [29696/50176]	Loss: 1.4398
Training Epoch: 14 [30720/50176]	Loss: 1.4847
Training Epoch: 14 [31744/50176]	Loss: 1.4137
Training Epoch: 14 [32768/50176]	Loss: 1.5654
Training Epoch: 14 [33792/50176]	Loss: 1.4692
Training Epoch: 14 [34816/50176]	Loss: 1.4591
Training Epoch: 14 [35840/50176]	Loss: 1.4811
Training Epoch: 14 [36864/50176]	Loss: 1.5663
Training Epoch: 14 [37888/50176]	Loss: 1.4220
Training Epoch: 14 [38912/50176]	Loss: 1.4982
Training Epoch: 14 [39936/50176]	Loss: 1.4402
Training Epoch: 14 [40960/50176]	Loss: 1.4749
Training Epoch: 14 [41984/50176]	Loss: 1.5467
Training Epoch: 14 [43008/50176]	Loss: 1.4665
Training Epoch: 14 [44032/50176]	Loss: 1.4377
Training Epoch: 14 [45056/50176]	Loss: 1.5083
Training Epoch: 14 [46080/50176]	Loss: 1.4600
Training Epoch: 14 [47104/50176]	Loss: 1.4108
Training Epoch: 14 [48128/50176]	Loss: 1.4180
Training Epoch: 14 [49152/50176]	Loss: 1.4360
Training Epoch: 14 [50176/50176]	Loss: 1.4637
2022-12-08 22:54:11.423 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:54:11,467 [ZeusDataLoader(eval)] eval epoch 15 done: time=4.41 energy=561.95
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Up to epoch 15: time=819.51, energy=114854.33, cost=129134.05
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:54:11,468 [ZeusDataLoader(train)] Expected next epoch: time=866.48, energy=122074.40, cost=136853.87
2022-12-08 17:54:11,469 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0018, Accuracy: 0.4982
2022-12-08 17:54:11,703 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:54:11,704 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:54:11.706 [ZeusMonitor] Monitor started.
2022-12-08 22:54:11.706 [ZeusMonitor] Running indefinitely. 2022-12-08 22:54:11.706 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:54:11.706 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e16+gpu0.power.log
2022-12-08 17:54:55,733 [ZeusDataLoader(train)] train epoch 16 done: time=44.26 energy=6711.95
2022-12-08 17:54:55,737 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.4077
Training Epoch: 15 [2048/50176]	Loss: 1.3456
Training Epoch: 15 [3072/50176]	Loss: 1.3574
Training Epoch: 15 [4096/50176]	Loss: 1.3107
Training Epoch: 15 [5120/50176]	Loss: 1.3365
Training Epoch: 15 [6144/50176]	Loss: 1.3745
Training Epoch: 15 [7168/50176]	Loss: 1.3221
Training Epoch: 15 [8192/50176]	Loss: 1.4159
Training Epoch: 15 [9216/50176]	Loss: 1.3107
Training Epoch: 15 [10240/50176]	Loss: 1.3245
Training Epoch: 15 [11264/50176]	Loss: 1.3141
Training Epoch: 15 [12288/50176]	Loss: 1.4264
Training Epoch: 15 [13312/50176]	Loss: 1.2840
Training Epoch: 15 [14336/50176]	Loss: 1.3952
Training Epoch: 15 [15360/50176]	Loss: 1.3759
Training Epoch: 15 [16384/50176]	Loss: 1.4197
Training Epoch: 15 [17408/50176]	Loss: 1.3944
Training Epoch: 15 [18432/50176]	Loss: 1.3799
Training Epoch: 15 [19456/50176]	Loss: 1.3234
Training Epoch: 15 [20480/50176]	Loss: 1.3248
Training Epoch: 15 [21504/50176]	Loss: 1.2833
Training Epoch: 15 [22528/50176]	Loss: 1.4476
Training Epoch: 15 [23552/50176]	Loss: 1.3943
Training Epoch: 15 [24576/50176]	Loss: 1.3311
Training Epoch: 15 [25600/50176]	Loss: 1.3925
Training Epoch: 15 [26624/50176]	Loss: 1.3428
Training Epoch: 15 [27648/50176]	Loss: 1.3953
Training Epoch: 15 [28672/50176]	Loss: 1.3143
Training Epoch: 15 [29696/50176]	Loss: 1.3893
Training Epoch: 15 [30720/50176]	Loss: 1.3536
Training Epoch: 15 [31744/50176]	Loss: 1.3994
Training Epoch: 15 [32768/50176]	Loss: 1.3618
Training Epoch: 15 [33792/50176]	Loss: 1.3436
Training Epoch: 15 [34816/50176]	Loss: 1.4210
Training Epoch: 15 [35840/50176]	Loss: 1.3943
Training Epoch: 15 [36864/50176]	Loss: 1.3391
Training Epoch: 15 [37888/50176]	Loss: 1.3825
Training Epoch: 15 [38912/50176]	Loss: 1.3950
Training Epoch: 15 [39936/50176]	Loss: 1.3477
Training Epoch: 15 [40960/50176]	Loss: 1.4185
Training Epoch: 15 [41984/50176]	Loss: 1.4266
Training Epoch: 15 [43008/50176]	Loss: 1.4483
Training Epoch: 15 [44032/50176]	Loss: 1.3715
Training Epoch: 15 [45056/50176]	Loss: 1.3280
Training Epoch: 15 [46080/50176]	Loss: 1.3698
Training Epoch: 15 [47104/50176]	Loss: 1.3130
Training Epoch: 15 [48128/50176]	Loss: 1.4135
Training Epoch: 15 [49152/50176]	Loss: 1.3251
Training Epoch: 15 [50176/50176]	Loss: 1.3714
2022-12-08 22:54:59.529 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:54:59,550 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.80 energy=532.31
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Up to epoch 16: time=867.57, energy=122098.59, cost=136961.37
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:54:59,550 [ZeusDataLoader(train)] Expected next epoch: time=914.54, energy=129318.66, cost=144681.18
2022-12-08 17:54:59,551 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0017, Accuracy: 0.5340
2022-12-08 17:54:59,767 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:54:59,768 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:54:59.770 [ZeusMonitor] Monitor started.
2022-12-08 22:54:59.770 [ZeusMonitor] Running indefinitely. 2022-12-08 22:54:59.770 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:54:59.770 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e17+gpu0.power.log
2022-12-08 17:55:43,747 [ZeusDataLoader(train)] train epoch 17 done: time=44.19 energy=6713.34
2022-12-08 17:55:43,750 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.3181
Training Epoch: 16 [2048/50176]	Loss: 1.2958
Training Epoch: 16 [3072/50176]	Loss: 1.3340
Training Epoch: 16 [4096/50176]	Loss: 1.3040
Training Epoch: 16 [5120/50176]	Loss: 1.2892
Training Epoch: 16 [6144/50176]	Loss: 1.2403
Training Epoch: 16 [7168/50176]	Loss: 1.2275
Training Epoch: 16 [8192/50176]	Loss: 1.2198
Training Epoch: 16 [9216/50176]	Loss: 1.3040
Training Epoch: 16 [10240/50176]	Loss: 1.2650
Training Epoch: 16 [11264/50176]	Loss: 1.3311
Training Epoch: 16 [12288/50176]	Loss: 1.2985
Training Epoch: 16 [13312/50176]	Loss: 1.2995
Training Epoch: 16 [14336/50176]	Loss: 1.3174
Training Epoch: 16 [15360/50176]	Loss: 1.3985
Training Epoch: 16 [16384/50176]	Loss: 1.2712
Training Epoch: 16 [17408/50176]	Loss: 1.2606
Training Epoch: 16 [18432/50176]	Loss: 1.4036
Training Epoch: 16 [19456/50176]	Loss: 1.2756
Training Epoch: 16 [20480/50176]	Loss: 1.2616
Training Epoch: 16 [21504/50176]	Loss: 1.3026
Training Epoch: 16 [22528/50176]	Loss: 1.3157
Training Epoch: 16 [23552/50176]	Loss: 1.3090
Training Epoch: 16 [24576/50176]	Loss: 1.3112
Training Epoch: 16 [25600/50176]	Loss: 1.3005
Training Epoch: 16 [26624/50176]	Loss: 1.2985
Training Epoch: 16 [27648/50176]	Loss: 1.3783
Training Epoch: 16 [28672/50176]	Loss: 1.3751
Training Epoch: 16 [29696/50176]	Loss: 1.2497
Training Epoch: 16 [30720/50176]	Loss: 1.2845
Training Epoch: 16 [31744/50176]	Loss: 1.3242
Training Epoch: 16 [32768/50176]	Loss: 1.3276
Training Epoch: 16 [33792/50176]	Loss: 1.3002
Training Epoch: 16 [34816/50176]	Loss: 1.3174
Training Epoch: 16 [35840/50176]	Loss: 1.3340
Training Epoch: 16 [36864/50176]	Loss: 1.3608
Training Epoch: 16 [37888/50176]	Loss: 1.2988
Training Epoch: 16 [38912/50176]	Loss: 1.2887
Training Epoch: 16 [39936/50176]	Loss: 1.3946
Training Epoch: 16 [40960/50176]	Loss: 1.3690
Training Epoch: 16 [41984/50176]	Loss: 1.3252
Training Epoch: 16 [43008/50176]	Loss: 1.2814
Training Epoch: 16 [44032/50176]	Loss: 1.3295
Training Epoch: 16 [45056/50176]	Loss: 1.4379
Training Epoch: 16 [46080/50176]	Loss: 1.3777
Training Epoch: 16 [47104/50176]	Loss: 1.3326
Training Epoch: 16 [48128/50176]	Loss: 1.3765
Training Epoch: 16 [49152/50176]	Loss: 1.3803
Training Epoch: 16 [50176/50176]	Loss: 1.3294
2022-12-08 22:55:47.519 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:55:47,558 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=534.53
2022-12-08 17:55:47,558 [ZeusDataLoader(train)] Up to epoch 17: time=915.55, energy=129346.45, cost=144784.11
2022-12-08 17:55:47,559 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:55:47,559 [ZeusDataLoader(train)] Expected next epoch: time=962.52, energy=136566.52, cost=152503.92
2022-12-08 17:55:47,560 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0017, Accuracy: 0.5397
2022-12-08 17:55:47,780 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:55:47,781 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:55:47.783 [ZeusMonitor] Monitor started.
2022-12-08 22:55:47.783 [ZeusMonitor] Running indefinitely. 2022-12-08 22:55:47.783 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:55:47.783 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e18+gpu0.power.log
2022-12-08 17:56:31,734 [ZeusDataLoader(train)] train epoch 18 done: time=44.17 energy=6704.75
2022-12-08 17:56:31,738 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.2242
Training Epoch: 17 [2048/50176]	Loss: 1.2283
Training Epoch: 17 [3072/50176]	Loss: 1.1286
Training Epoch: 17 [4096/50176]	Loss: 1.1694
Training Epoch: 17 [5120/50176]	Loss: 1.2834
Training Epoch: 17 [6144/50176]	Loss: 1.2865
Training Epoch: 17 [7168/50176]	Loss: 1.2012
Training Epoch: 17 [8192/50176]	Loss: 1.2032
Training Epoch: 17 [9216/50176]	Loss: 1.2336
Training Epoch: 17 [10240/50176]	Loss: 1.1846
Training Epoch: 17 [11264/50176]	Loss: 1.2270
Training Epoch: 17 [12288/50176]	Loss: 1.2005
Training Epoch: 17 [13312/50176]	Loss: 1.2212
Training Epoch: 17 [14336/50176]	Loss: 1.2209
Training Epoch: 17 [15360/50176]	Loss: 1.2020
Training Epoch: 17 [16384/50176]	Loss: 1.1846
Training Epoch: 17 [17408/50176]	Loss: 1.2602
Training Epoch: 17 [18432/50176]	Loss: 1.3139
Training Epoch: 17 [19456/50176]	Loss: 1.1774
Training Epoch: 17 [20480/50176]	Loss: 1.2165
Training Epoch: 17 [21504/50176]	Loss: 1.2823
Training Epoch: 17 [22528/50176]	Loss: 1.3638
Training Epoch: 17 [23552/50176]	Loss: 1.2973
Training Epoch: 17 [24576/50176]	Loss: 1.2766
Training Epoch: 17 [25600/50176]	Loss: 1.2623
Training Epoch: 17 [26624/50176]	Loss: 1.2170
Training Epoch: 17 [27648/50176]	Loss: 1.2633
Training Epoch: 17 [28672/50176]	Loss: 1.2640
Training Epoch: 17 [29696/50176]	Loss: 1.3234
Training Epoch: 17 [30720/50176]	Loss: 1.3204
Training Epoch: 17 [31744/50176]	Loss: 1.2242
Training Epoch: 17 [32768/50176]	Loss: 1.2257
Training Epoch: 17 [33792/50176]	Loss: 1.2944
Training Epoch: 17 [34816/50176]	Loss: 1.2616
Training Epoch: 17 [35840/50176]	Loss: 1.1783
Training Epoch: 17 [36864/50176]	Loss: 1.3252
Training Epoch: 17 [37888/50176]	Loss: 1.2606
Training Epoch: 17 [38912/50176]	Loss: 1.3420
Training Epoch: 17 [39936/50176]	Loss: 1.2992
Training Epoch: 17 [40960/50176]	Loss: 1.2832
Training Epoch: 17 [41984/50176]	Loss: 1.3034
Training Epoch: 17 [43008/50176]	Loss: 1.2828
Training Epoch: 17 [44032/50176]	Loss: 1.3166
Training Epoch: 17 [45056/50176]	Loss: 1.2772
Training Epoch: 17 [46080/50176]	Loss: 1.2006
Training Epoch: 17 [47104/50176]	Loss: 1.2394
Training Epoch: 17 [48128/50176]	Loss: 1.3045
Training Epoch: 17 [49152/50176]	Loss: 1.2869
Training Epoch: 17 [50176/50176]	Loss: 1.3325
2022-12-08 22:56:35.436 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:56:35,460 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.71 energy=518.75
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Up to epoch 18: time=963.43, energy=136569.95, cost=152585.36
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:56:35,461 [ZeusDataLoader(train)] Expected next epoch: time=1010.40, energy=143790.02, cost=160305.17
2022-12-08 17:56:35,462 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0016, Accuracy: 0.5474
2022-12-08 17:56:35,722 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:56:35,723 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:56:35.733 [ZeusMonitor] Monitor started.
2022-12-08 22:56:35.733 [ZeusMonitor] Running indefinitely. 2022-12-08 22:56:35.733 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:56:35.733 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e19+gpu0.power.log
2022-12-08 17:57:19,729 [ZeusDataLoader(train)] train epoch 19 done: time=44.26 energy=6700.37
2022-12-08 17:57:19,732 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.1805
Training Epoch: 18 [2048/50176]	Loss: 1.1824
Training Epoch: 18 [3072/50176]	Loss: 1.2267
Training Epoch: 18 [4096/50176]	Loss: 1.1388
Training Epoch: 18 [5120/50176]	Loss: 1.1447
Training Epoch: 18 [6144/50176]	Loss: 1.1688
Training Epoch: 18 [7168/50176]	Loss: 1.1372
Training Epoch: 18 [8192/50176]	Loss: 1.1787
Training Epoch: 18 [9216/50176]	Loss: 1.1509
Training Epoch: 18 [10240/50176]	Loss: 1.1223
Training Epoch: 18 [11264/50176]	Loss: 1.2126
Training Epoch: 18 [12288/50176]	Loss: 1.1372
Training Epoch: 18 [13312/50176]	Loss: 1.2473
Training Epoch: 18 [14336/50176]	Loss: 1.2044
Training Epoch: 18 [15360/50176]	Loss: 1.2542
Training Epoch: 18 [16384/50176]	Loss: 1.1853
Training Epoch: 18 [17408/50176]	Loss: 1.2841
Training Epoch: 18 [18432/50176]	Loss: 1.2013
Training Epoch: 18 [19456/50176]	Loss: 1.2481
Training Epoch: 18 [20480/50176]	Loss: 1.1779
Training Epoch: 18 [21504/50176]	Loss: 1.2532
Training Epoch: 18 [22528/50176]	Loss: 1.2806
Training Epoch: 18 [23552/50176]	Loss: 1.1355
Training Epoch: 18 [24576/50176]	Loss: 1.1631
Training Epoch: 18 [25600/50176]	Loss: 1.1414
Training Epoch: 18 [26624/50176]	Loss: 1.0647
Training Epoch: 18 [27648/50176]	Loss: 1.1794
Training Epoch: 18 [28672/50176]	Loss: 1.1952
Training Epoch: 18 [29696/50176]	Loss: 1.2123
Training Epoch: 18 [30720/50176]	Loss: 1.2677
Training Epoch: 18 [31744/50176]	Loss: 1.2681
Training Epoch: 18 [32768/50176]	Loss: 1.2268
Training Epoch: 18 [33792/50176]	Loss: 1.2120
Training Epoch: 18 [34816/50176]	Loss: 1.1749
Training Epoch: 18 [35840/50176]	Loss: 1.2708
Training Epoch: 18 [36864/50176]	Loss: 1.2674
Training Epoch: 18 [37888/50176]	Loss: 1.1993
Training Epoch: 18 [38912/50176]	Loss: 1.2798
Training Epoch: 18 [39936/50176]	Loss: 1.2078
Training Epoch: 18 [40960/50176]	Loss: 1.2122
Training Epoch: 18 [41984/50176]	Loss: 1.2369
Training Epoch: 18 [43008/50176]	Loss: 1.2540
Training Epoch: 18 [44032/50176]	Loss: 1.2040
Training Epoch: 18 [45056/50176]	Loss: 1.1905
Training Epoch: 18 [46080/50176]	Loss: 1.2508
Training Epoch: 18 [47104/50176]	Loss: 1.2340
Training Epoch: 18 [48128/50176]	Loss: 1.1947
Training Epoch: 18 [49152/50176]	Loss: 1.2102
Training Epoch: 18 [50176/50176]	Loss: 1.2822
2022-12-08 22:57:23.515 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:57:23,568 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.83 energy=533.46
2022-12-08 17:57:23,568 [ZeusDataLoader(train)] Up to epoch 19: time=1011.52, energy=143803.78, cost=160409.66
2022-12-08 17:57:23,569 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:57:23,569 [ZeusDataLoader(train)] Expected next epoch: time=1058.49, energy=151023.85, cost=168129.48
2022-12-08 17:57:23,570 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0016, Accuracy: 0.5449
2022-12-08 17:57:23,801 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:57:23,802 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:57:23.804 [ZeusMonitor] Monitor started.
2022-12-08 22:57:23.816 [ZeusMonitor] Running indefinitely. 2022-12-08 22:57:23.816 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:57:23.816 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e20+gpu0.power.log
2022-12-08 17:58:07,726 [ZeusDataLoader(train)] train epoch 20 done: time=44.15 energy=6713.55
2022-12-08 17:58:07,730 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.0996
Training Epoch: 19 [2048/50176]	Loss: 1.1460
Training Epoch: 19 [3072/50176]	Loss: 1.1324
Training Epoch: 19 [4096/50176]	Loss: 1.1240
Training Epoch: 19 [5120/50176]	Loss: 1.0766
Training Epoch: 19 [6144/50176]	Loss: 1.1369
Training Epoch: 19 [7168/50176]	Loss: 1.0790
Training Epoch: 19 [8192/50176]	Loss: 1.1117
Training Epoch: 19 [9216/50176]	Loss: 1.1282
Training Epoch: 19 [10240/50176]	Loss: 1.1926
Training Epoch: 19 [11264/50176]	Loss: 1.1240
Training Epoch: 19 [12288/50176]	Loss: 1.1257
Training Epoch: 19 [13312/50176]	Loss: 1.0605
Training Epoch: 19 [14336/50176]	Loss: 1.1358
Training Epoch: 19 [15360/50176]	Loss: 1.1198
Training Epoch: 19 [16384/50176]	Loss: 1.1289
Training Epoch: 19 [17408/50176]	Loss: 1.2155
Training Epoch: 19 [18432/50176]	Loss: 1.1824
Training Epoch: 19 [19456/50176]	Loss: 1.1053
Training Epoch: 19 [20480/50176]	Loss: 1.1820
Training Epoch: 19 [21504/50176]	Loss: 1.0997
Training Epoch: 19 [22528/50176]	Loss: 1.2416
Training Epoch: 19 [23552/50176]	Loss: 1.1923
Training Epoch: 19 [24576/50176]	Loss: 1.1132
Training Epoch: 19 [25600/50176]	Loss: 1.1673
Training Epoch: 19 [26624/50176]	Loss: 1.1836
Training Epoch: 19 [27648/50176]	Loss: 1.1438
Training Epoch: 19 [28672/50176]	Loss: 1.0972
Training Epoch: 19 [29696/50176]	Loss: 1.2187
Training Epoch: 19 [30720/50176]	Loss: 1.1405
Training Epoch: 19 [31744/50176]	Loss: 1.2074
Training Epoch: 19 [32768/50176]	Loss: 1.1519
Training Epoch: 19 [33792/50176]	Loss: 1.1456
Training Epoch: 19 [34816/50176]	Loss: 1.1437
Training Epoch: 19 [35840/50176]	Loss: 1.1902
Training Epoch: 19 [36864/50176]	Loss: 1.2357
Training Epoch: 19 [37888/50176]	Loss: 1.1388
Training Epoch: 19 [38912/50176]	Loss: 1.2512
Training Epoch: 19 [39936/50176]	Loss: 1.1276
Training Epoch: 19 [40960/50176]	Loss: 1.1442
Training Epoch: 19 [41984/50176]	Loss: 1.2192
Training Epoch: 19 [43008/50176]	Loss: 1.2216
Training Epoch: 19 [44032/50176]	Loss: 1.1417
Training Epoch: 19 [45056/50176]	Loss: 1.1597
Training Epoch: 19 [46080/50176]	Loss: 1.1064
Training Epoch: 19 [47104/50176]	Loss: 1.1475
Training Epoch: 19 [48128/50176]	Loss: 1.1366
Training Epoch: 19 [49152/50176]	Loss: 1.1996
Training Epoch: 19 [50176/50176]	Loss: 1.0899
2022-12-08 22:58:11.463 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:58:11,472 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.73 energy=520.50
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Up to epoch 20: time=1059.40, energy=151037.82, cost=168216.40
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:58:11,473 [ZeusDataLoader(train)] Expected next epoch: time=1106.37, energy=158257.89, cost=175936.22
2022-12-08 17:58:11,474 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0015, Accuracy: 0.5787
2022-12-08 17:58:11,709 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:58:11,710 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:58:11.711 [ZeusMonitor] Monitor started.
2022-12-08 22:58:11.712 [ZeusMonitor] Running indefinitely. 2022-12-08 22:58:11.712 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:58:11.712 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e21+gpu0.power.log
2022-12-08 17:58:55,722 [ZeusDataLoader(train)] train epoch 21 done: time=44.24 energy=6704.38
2022-12-08 17:58:55,727 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.0224
Training Epoch: 20 [2048/50176]	Loss: 1.0808
Training Epoch: 20 [3072/50176]	Loss: 1.0784
Training Epoch: 20 [4096/50176]	Loss: 1.0036
Training Epoch: 20 [5120/50176]	Loss: 1.0109
Training Epoch: 20 [6144/50176]	Loss: 1.1248
Training Epoch: 20 [7168/50176]	Loss: 0.9923
Training Epoch: 20 [8192/50176]	Loss: 1.0411
Training Epoch: 20 [9216/50176]	Loss: 1.0218
Training Epoch: 20 [10240/50176]	Loss: 1.0074
Training Epoch: 20 [11264/50176]	Loss: 1.0735
Training Epoch: 20 [12288/50176]	Loss: 1.0426
Training Epoch: 20 [13312/50176]	Loss: 1.0474
Training Epoch: 20 [14336/50176]	Loss: 1.0875
Training Epoch: 20 [15360/50176]	Loss: 1.0762
Training Epoch: 20 [16384/50176]	Loss: 1.0763
Training Epoch: 20 [17408/50176]	Loss: 1.0636
Training Epoch: 20 [18432/50176]	Loss: 1.0809
Training Epoch: 20 [19456/50176]	Loss: 1.1109
Training Epoch: 20 [20480/50176]	Loss: 1.0559
Training Epoch: 20 [21504/50176]	Loss: 1.1329
Training Epoch: 20 [22528/50176]	Loss: 1.0699
Training Epoch: 20 [23552/50176]	Loss: 1.0487
Training Epoch: 20 [24576/50176]	Loss: 1.1285
Training Epoch: 20 [25600/50176]	Loss: 1.1319
Training Epoch: 20 [26624/50176]	Loss: 1.1022
Training Epoch: 20 [27648/50176]	Loss: 1.0101
Training Epoch: 20 [28672/50176]	Loss: 1.1882
Training Epoch: 20 [29696/50176]	Loss: 1.1234
Training Epoch: 20 [30720/50176]	Loss: 1.1323
Training Epoch: 20 [31744/50176]	Loss: 1.0599
Training Epoch: 20 [32768/50176]	Loss: 1.0561
Training Epoch: 20 [33792/50176]	Loss: 1.1001
Training Epoch: 20 [34816/50176]	Loss: 1.1536
Training Epoch: 20 [35840/50176]	Loss: 1.1016
Training Epoch: 20 [36864/50176]	Loss: 1.1570
Training Epoch: 20 [37888/50176]	Loss: 1.0958
Training Epoch: 20 [38912/50176]	Loss: 1.0626
Training Epoch: 20 [39936/50176]	Loss: 1.1221
Training Epoch: 20 [40960/50176]	Loss: 1.1705
Training Epoch: 20 [41984/50176]	Loss: 1.1143
Training Epoch: 20 [43008/50176]	Loss: 1.0879
Training Epoch: 20 [44032/50176]	Loss: 1.0745
Training Epoch: 20 [45056/50176]	Loss: 1.0779
Training Epoch: 20 [46080/50176]	Loss: 1.1198
Training Epoch: 20 [47104/50176]	Loss: 1.1569
Training Epoch: 20 [48128/50176]	Loss: 1.1203
Training Epoch: 20 [49152/50176]	Loss: 1.1748
Training Epoch: 20 [50176/50176]	Loss: 1.0981
2022-12-08 22:58:59.499 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:58:59,529 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.79 energy=532.95
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Up to epoch 21: time=1107.43, energy=158275.15, cost=176037.84
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:58:59,530 [ZeusDataLoader(train)] Expected next epoch: time=1154.40, energy=165495.22, cost=183757.66
2022-12-08 17:58:59,531 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0016, Accuracy: 0.5700
2022-12-08 17:58:59,756 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:58:59,757 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:58:59.759 [ZeusMonitor] Monitor started.
2022-12-08 22:58:59.759 [ZeusMonitor] Running indefinitely. 2022-12-08 22:58:59.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:58:59.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e22+gpu0.power.log
2022-12-08 17:59:43,693 [ZeusDataLoader(train)] train epoch 22 done: time=44.15 energy=6711.78
2022-12-08 17:59:43,697 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.0399
Training Epoch: 21 [2048/50176]	Loss: 0.9806
Training Epoch: 21 [3072/50176]	Loss: 1.0006
Training Epoch: 21 [4096/50176]	Loss: 1.0298
Training Epoch: 21 [5120/50176]	Loss: 1.0023
Training Epoch: 21 [6144/50176]	Loss: 0.9804
Training Epoch: 21 [7168/50176]	Loss: 0.9407
Training Epoch: 21 [8192/50176]	Loss: 1.0266
Training Epoch: 21 [9216/50176]	Loss: 1.0079
Training Epoch: 21 [10240/50176]	Loss: 0.9880
Training Epoch: 21 [11264/50176]	Loss: 0.9611
Training Epoch: 21 [12288/50176]	Loss: 0.9730
Training Epoch: 21 [13312/50176]	Loss: 1.0164
Training Epoch: 21 [14336/50176]	Loss: 1.0447
Training Epoch: 21 [15360/50176]	Loss: 1.0182
Training Epoch: 21 [16384/50176]	Loss: 1.0611
Training Epoch: 21 [17408/50176]	Loss: 1.0184
Training Epoch: 21 [18432/50176]	Loss: 0.9883
Training Epoch: 21 [19456/50176]	Loss: 0.9959
Training Epoch: 21 [20480/50176]	Loss: 0.9693
Training Epoch: 21 [21504/50176]	Loss: 1.0472
Training Epoch: 21 [22528/50176]	Loss: 1.1275
Training Epoch: 21 [23552/50176]	Loss: 1.0791
Training Epoch: 21 [24576/50176]	Loss: 1.0109
Training Epoch: 21 [25600/50176]	Loss: 1.0441
Training Epoch: 21 [26624/50176]	Loss: 1.1109
Training Epoch: 21 [27648/50176]	Loss: 1.0255
Training Epoch: 21 [28672/50176]	Loss: 1.0075
Training Epoch: 21 [29696/50176]	Loss: 1.1148
Training Epoch: 21 [30720/50176]	Loss: 1.0331
Training Epoch: 21 [31744/50176]	Loss: 1.0522
Training Epoch: 21 [32768/50176]	Loss: 1.0450
Training Epoch: 21 [33792/50176]	Loss: 1.0478
Training Epoch: 21 [34816/50176]	Loss: 1.0353
Training Epoch: 21 [35840/50176]	Loss: 1.0571
Training Epoch: 21 [36864/50176]	Loss: 0.9866
Training Epoch: 21 [37888/50176]	Loss: 1.1511
Training Epoch: 21 [38912/50176]	Loss: 1.0799
Training Epoch: 21 [39936/50176]	Loss: 1.1409
Training Epoch: 21 [40960/50176]	Loss: 1.0258
Training Epoch: 21 [41984/50176]	Loss: 1.0822
Training Epoch: 21 [43008/50176]	Loss: 1.0803
Training Epoch: 21 [44032/50176]	Loss: 1.1630
Training Epoch: 21 [45056/50176]	Loss: 1.1468
Training Epoch: 21 [46080/50176]	Loss: 1.0724
Training Epoch: 21 [47104/50176]	Loss: 1.0833
Training Epoch: 21 [48128/50176]	Loss: 1.1037
Training Epoch: 21 [49152/50176]	Loss: 1.1080
Training Epoch: 21 [50176/50176]	Loss: 1.1055
2022-12-08 22:59:47.496 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 17:59:47,518 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=530.56
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Up to epoch 22: time=1155.40, energy=165517.49, cost=183856.13
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 17:59:47,519 [ZeusDataLoader(train)] Expected next epoch: time=1202.37, energy=172737.57, cost=191575.94
2022-12-08 17:59:47,520 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0016, Accuracy: 0.5694
2022-12-08 17:59:47,709 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 17:59:47,710 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 22:59:47.712 [ZeusMonitor] Monitor started.
2022-12-08 22:59:47.712 [ZeusMonitor] Running indefinitely. 2022-12-08 22:59:47.712 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 22:59:47.712 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e23+gpu0.power.log
2022-12-08 18:00:31,680 [ZeusDataLoader(train)] train epoch 23 done: time=44.15 energy=6714.30
2022-12-08 18:00:31,684 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.0335
Training Epoch: 22 [2048/50176]	Loss: 0.9933
Training Epoch: 22 [3072/50176]	Loss: 0.9267
Training Epoch: 22 [4096/50176]	Loss: 0.8679
Training Epoch: 22 [5120/50176]	Loss: 0.9504
Training Epoch: 22 [6144/50176]	Loss: 0.9654
Training Epoch: 22 [7168/50176]	Loss: 0.9683
Training Epoch: 22 [8192/50176]	Loss: 0.9384
Training Epoch: 22 [9216/50176]	Loss: 0.9612
Training Epoch: 22 [10240/50176]	Loss: 0.8947
Training Epoch: 22 [11264/50176]	Loss: 1.0249
Training Epoch: 22 [12288/50176]	Loss: 1.0416
Training Epoch: 22 [13312/50176]	Loss: 0.9002
Training Epoch: 22 [14336/50176]	Loss: 1.0010
Training Epoch: 22 [15360/50176]	Loss: 0.9499
Training Epoch: 22 [16384/50176]	Loss: 1.0314
Training Epoch: 22 [17408/50176]	Loss: 0.9944
Training Epoch: 22 [18432/50176]	Loss: 0.9724
Training Epoch: 22 [19456/50176]	Loss: 0.9960
Training Epoch: 22 [20480/50176]	Loss: 1.0318
Training Epoch: 22 [21504/50176]	Loss: 0.9837
Training Epoch: 22 [22528/50176]	Loss: 1.0781
Training Epoch: 22 [23552/50176]	Loss: 1.0445
Training Epoch: 22 [24576/50176]	Loss: 1.0372
Training Epoch: 22 [25600/50176]	Loss: 1.0175
Training Epoch: 22 [26624/50176]	Loss: 1.0459
Training Epoch: 22 [27648/50176]	Loss: 1.0001
Training Epoch: 22 [28672/50176]	Loss: 1.0635
Training Epoch: 22 [29696/50176]	Loss: 1.0396
Training Epoch: 22 [30720/50176]	Loss: 0.9764
Training Epoch: 22 [31744/50176]	Loss: 1.1101
Training Epoch: 22 [32768/50176]	Loss: 1.0497
Training Epoch: 22 [33792/50176]	Loss: 1.0000
Training Epoch: 22 [34816/50176]	Loss: 1.0321
Training Epoch: 22 [35840/50176]	Loss: 1.0423
Training Epoch: 22 [36864/50176]	Loss: 1.0666
Training Epoch: 22 [37888/50176]	Loss: 1.0257
Training Epoch: 22 [38912/50176]	Loss: 0.9271
Training Epoch: 22 [39936/50176]	Loss: 0.9677
Training Epoch: 22 [40960/50176]	Loss: 1.0539
Training Epoch: 22 [41984/50176]	Loss: 1.0871
Training Epoch: 22 [43008/50176]	Loss: 1.0093
Training Epoch: 22 [44032/50176]	Loss: 0.9508
Training Epoch: 22 [45056/50176]	Loss: 1.0206
Training Epoch: 22 [46080/50176]	Loss: 1.0015
Training Epoch: 22 [47104/50176]	Loss: 1.0008
Training Epoch: 22 [48128/50176]	Loss: 1.1575
Training Epoch: 22 [49152/50176]	Loss: 1.0768
Training Epoch: 22 [50176/50176]	Loss: 1.0437
2022-12-08 23:00:35.455 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:00:35,506 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.81 energy=533.72
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Up to epoch 23: time=1203.36, energy=172765.51, cost=191677.08
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:00:35,506 [ZeusDataLoader(train)] Expected next epoch: time=1250.33, energy=179985.58, cost=199396.89
2022-12-08 18:00:35,507 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0018, Accuracy: 0.5539
2022-12-08 18:00:35,727 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:00:35,728 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:00:35.730 [ZeusMonitor] Monitor started.
2022-12-08 23:00:35.730 [ZeusMonitor] Running indefinitely. 2022-12-08 23:00:35.730 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:00:35.730 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e24+gpu0.power.log
2022-12-08 18:01:19,677 [ZeusDataLoader(train)] train epoch 24 done: time=44.16 energy=6702.96
2022-12-08 18:01:19,681 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 0.9594
Training Epoch: 23 [2048/50176]	Loss: 0.9093
Training Epoch: 23 [3072/50176]	Loss: 0.9103
Training Epoch: 23 [4096/50176]	Loss: 0.9519
Training Epoch: 23 [5120/50176]	Loss: 0.9176
Training Epoch: 23 [6144/50176]	Loss: 0.9061
Training Epoch: 23 [7168/50176]	Loss: 0.9425
Training Epoch: 23 [8192/50176]	Loss: 0.9394
Training Epoch: 23 [9216/50176]	Loss: 0.8686
Training Epoch: 23 [10240/50176]	Loss: 0.9025
Training Epoch: 23 [11264/50176]	Loss: 0.9677
Training Epoch: 23 [12288/50176]	Loss: 0.8823
Training Epoch: 23 [13312/50176]	Loss: 1.0299
Training Epoch: 23 [14336/50176]	Loss: 0.9018
Training Epoch: 23 [15360/50176]	Loss: 0.9059
Training Epoch: 23 [16384/50176]	Loss: 0.9938
Training Epoch: 23 [17408/50176]	Loss: 0.9755
Training Epoch: 23 [18432/50176]	Loss: 0.8884
Training Epoch: 23 [19456/50176]	Loss: 0.9360
Training Epoch: 23 [20480/50176]	Loss: 0.9351
Training Epoch: 23 [21504/50176]	Loss: 0.9434
Training Epoch: 23 [22528/50176]	Loss: 0.9429
Training Epoch: 23 [23552/50176]	Loss: 0.8839
Training Epoch: 23 [24576/50176]	Loss: 0.9654
Training Epoch: 23 [25600/50176]	Loss: 0.9264
Training Epoch: 23 [26624/50176]	Loss: 0.9329
Training Epoch: 23 [27648/50176]	Loss: 0.9228
Training Epoch: 23 [28672/50176]	Loss: 0.8807
Training Epoch: 23 [29696/50176]	Loss: 0.9471
Training Epoch: 23 [30720/50176]	Loss: 0.9477
Training Epoch: 23 [31744/50176]	Loss: 1.0028
Training Epoch: 23 [32768/50176]	Loss: 1.0035
Training Epoch: 23 [33792/50176]	Loss: 0.9763
Training Epoch: 23 [34816/50176]	Loss: 1.0167
Training Epoch: 23 [35840/50176]	Loss: 0.9678
Training Epoch: 23 [36864/50176]	Loss: 0.9211
Training Epoch: 23 [37888/50176]	Loss: 0.9571
Training Epoch: 23 [38912/50176]	Loss: 1.0435
Training Epoch: 23 [39936/50176]	Loss: 0.9775
Training Epoch: 23 [40960/50176]	Loss: 1.0609
Training Epoch: 23 [41984/50176]	Loss: 1.0160
Training Epoch: 23 [43008/50176]	Loss: 0.9981
Training Epoch: 23 [44032/50176]	Loss: 1.0281
Training Epoch: 23 [45056/50176]	Loss: 1.0014
Training Epoch: 23 [46080/50176]	Loss: 1.0655
Training Epoch: 23 [47104/50176]	Loss: 1.0163
Training Epoch: 23 [48128/50176]	Loss: 0.9543
Training Epoch: 23 [49152/50176]	Loss: 1.0085
Training Epoch: 23 [50176/50176]	Loss: 0.9549
2022-12-08 23:01:23.387 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:01:23,403 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.71 energy=515.10
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Up to epoch 24: time=1251.24, energy=179983.58, cost=199475.18
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:01:23,403 [ZeusDataLoader(train)] Expected next epoch: time=1298.21, energy=187203.65, cost=207195.00
2022-12-08 18:01:23,404 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0015, Accuracy: 0.5776
2022-12-08 18:01:23,636 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:01:23,637 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:01:23.639 [ZeusMonitor] Monitor started.
2022-12-08 23:01:23.639 [ZeusMonitor] Running indefinitely. 2022-12-08 23:01:23.639 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:01:23.639 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e25+gpu0.power.log
2022-12-08 18:02:07,602 [ZeusDataLoader(train)] train epoch 25 done: time=44.19 energy=6716.01
2022-12-08 18:02:07,605 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 0.8497
Training Epoch: 24 [2048/50176]	Loss: 0.8239
Training Epoch: 24 [3072/50176]	Loss: 0.8916
Training Epoch: 24 [4096/50176]	Loss: 0.8275
Training Epoch: 24 [5120/50176]	Loss: 0.8272
Training Epoch: 24 [6144/50176]	Loss: 0.8444
Training Epoch: 24 [7168/50176]	Loss: 0.9289
Training Epoch: 24 [8192/50176]	Loss: 0.8818
Training Epoch: 24 [9216/50176]	Loss: 0.8778
Training Epoch: 24 [10240/50176]	Loss: 0.9000
Training Epoch: 24 [11264/50176]	Loss: 0.8979
Training Epoch: 24 [12288/50176]	Loss: 0.8703
Training Epoch: 24 [13312/50176]	Loss: 0.8783
Training Epoch: 24 [14336/50176]	Loss: 0.9062
Training Epoch: 24 [15360/50176]	Loss: 0.8394
Training Epoch: 24 [16384/50176]	Loss: 0.8565
Training Epoch: 24 [17408/50176]	Loss: 0.9102
Training Epoch: 24 [18432/50176]	Loss: 0.9330
Training Epoch: 24 [19456/50176]	Loss: 0.9381
Training Epoch: 24 [20480/50176]	Loss: 0.9089
Training Epoch: 24 [21504/50176]	Loss: 0.9236
Training Epoch: 24 [22528/50176]	Loss: 0.8536
Training Epoch: 24 [23552/50176]	Loss: 0.9265
Training Epoch: 24 [24576/50176]	Loss: 0.8489
Training Epoch: 24 [25600/50176]	Loss: 0.9519
Training Epoch: 24 [26624/50176]	Loss: 0.9143
Training Epoch: 24 [27648/50176]	Loss: 0.9453
Training Epoch: 24 [28672/50176]	Loss: 0.9318
Training Epoch: 24 [29696/50176]	Loss: 0.8734
Training Epoch: 24 [30720/50176]	Loss: 0.9950
Training Epoch: 24 [31744/50176]	Loss: 1.0137
Training Epoch: 24 [32768/50176]	Loss: 0.9419
Training Epoch: 24 [33792/50176]	Loss: 0.9112
Training Epoch: 24 [34816/50176]	Loss: 1.0144
Training Epoch: 24 [35840/50176]	Loss: 0.9754
Training Epoch: 24 [36864/50176]	Loss: 0.9706
Training Epoch: 24 [37888/50176]	Loss: 0.9443
Training Epoch: 24 [38912/50176]	Loss: 1.0284
Training Epoch: 24 [39936/50176]	Loss: 0.9003
Training Epoch: 24 [40960/50176]	Loss: 0.9459
Training Epoch: 24 [41984/50176]	Loss: 0.9510
Training Epoch: 24 [43008/50176]	Loss: 0.9990
Training Epoch: 24 [44032/50176]	Loss: 0.8792
Training Epoch: 24 [45056/50176]	Loss: 0.9577
Training Epoch: 24 [46080/50176]	Loss: 0.9287
Training Epoch: 24 [47104/50176]	Loss: 1.0112
Training Epoch: 24 [48128/50176]	Loss: 1.0513
Training Epoch: 24 [49152/50176]	Loss: 0.9265
Training Epoch: 24 [50176/50176]	Loss: 0.9071
2022-12-08 23:02:11.347 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:02:11,394 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.78 energy=521.34
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Up to epoch 25: time=1299.21, energy=187220.93, cost=207291.12
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:02:11,394 [ZeusDataLoader(train)] Expected next epoch: time=1346.18, energy=194441.00, cost=215010.94
2022-12-08 18:02:11,395 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0015, Accuracy: 0.5864
2022-12-08 18:02:11,624 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:02:11,625 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:02:11.627 [ZeusMonitor] Monitor started.
2022-12-08 23:02:11.627 [ZeusMonitor] Running indefinitely. 2022-12-08 23:02:11.627 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:02:11.627 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e26+gpu0.power.log
2022-12-08 18:02:55,653 [ZeusDataLoader(train)] train epoch 26 done: time=44.25 energy=6717.97
2022-12-08 18:02:55,657 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 0.7817
Training Epoch: 25 [2048/50176]	Loss: 0.8126
Training Epoch: 25 [3072/50176]	Loss: 0.7912
Training Epoch: 25 [4096/50176]	Loss: 0.7865
Training Epoch: 25 [5120/50176]	Loss: 0.8205
Training Epoch: 25 [6144/50176]	Loss: 0.8306
Training Epoch: 25 [7168/50176]	Loss: 0.8118
Training Epoch: 25 [8192/50176]	Loss: 0.8368
Training Epoch: 25 [9216/50176]	Loss: 0.9178
Training Epoch: 25 [10240/50176]	Loss: 0.7736
Training Epoch: 25 [11264/50176]	Loss: 0.8464
Training Epoch: 25 [12288/50176]	Loss: 0.7867
Training Epoch: 25 [13312/50176]	Loss: 0.7926
Training Epoch: 25 [14336/50176]	Loss: 0.8565
Training Epoch: 25 [15360/50176]	Loss: 0.8830
Training Epoch: 25 [16384/50176]	Loss: 0.8991
Training Epoch: 25 [17408/50176]	Loss: 0.8748
Training Epoch: 25 [18432/50176]	Loss: 0.8482
Training Epoch: 25 [19456/50176]	Loss: 0.7775
Training Epoch: 25 [20480/50176]	Loss: 0.8431
Training Epoch: 25 [21504/50176]	Loss: 0.8355
Training Epoch: 25 [22528/50176]	Loss: 0.9205
Training Epoch: 25 [23552/50176]	Loss: 0.8153
Training Epoch: 25 [24576/50176]	Loss: 0.8043
Training Epoch: 25 [25600/50176]	Loss: 0.8200
Training Epoch: 25 [26624/50176]	Loss: 0.8917
Training Epoch: 25 [27648/50176]	Loss: 0.8583
Training Epoch: 25 [28672/50176]	Loss: 0.9093
Training Epoch: 25 [29696/50176]	Loss: 0.8533
Training Epoch: 25 [30720/50176]	Loss: 0.9219
Training Epoch: 25 [31744/50176]	Loss: 0.8377
Training Epoch: 25 [32768/50176]	Loss: 0.8721
Training Epoch: 25 [33792/50176]	Loss: 0.8096
Training Epoch: 25 [34816/50176]	Loss: 0.8573
Training Epoch: 25 [35840/50176]	Loss: 0.8617
Training Epoch: 25 [36864/50176]	Loss: 0.8712
Training Epoch: 25 [37888/50176]	Loss: 0.8721
Training Epoch: 25 [38912/50176]	Loss: 0.8583
Training Epoch: 25 [39936/50176]	Loss: 0.8433
Training Epoch: 25 [40960/50176]	Loss: 0.8536
Training Epoch: 25 [41984/50176]	Loss: 0.8914
Training Epoch: 25 [43008/50176]	Loss: 0.9574
Training Epoch: 25 [44032/50176]	Loss: 0.9148
Training Epoch: 25 [45056/50176]	Loss: 0.9517
Training Epoch: 25 [46080/50176]	Loss: 0.9180
Training Epoch: 25 [47104/50176]	Loss: 0.9390
Training Epoch: 25 [48128/50176]	Loss: 0.9522
Training Epoch: 25 [49152/50176]	Loss: 0.8915
Training Epoch: 25 [50176/50176]	Loss: 0.9449
2022-12-08 23:02:59.410 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:02:59,453 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.79 energy=524.25
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Up to epoch 26: time=1347.24, energy=194463.15, cost=215115.46
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:02:59,454 [ZeusDataLoader(train)] Expected next epoch: time=1394.21, energy=201683.22, cost=222835.27
2022-12-08 18:02:59,455 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0016, Accuracy: 0.5772
2022-12-08 18:02:59,671 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:02:59,672 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:02:59.674 [ZeusMonitor] Monitor started.
2022-12-08 23:02:59.674 [ZeusMonitor] Running indefinitely. 2022-12-08 23:02:59.674 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:02:59.674 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e27+gpu0.power.log
2022-12-08 18:03:43,658 [ZeusDataLoader(train)] train epoch 27 done: time=44.20 energy=6710.96
2022-12-08 18:03:43,662 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 0.7450
Training Epoch: 26 [2048/50176]	Loss: 0.7971
Training Epoch: 26 [3072/50176]	Loss: 0.8067
Training Epoch: 26 [4096/50176]	Loss: 0.7962
Training Epoch: 26 [5120/50176]	Loss: 0.8059
Training Epoch: 26 [6144/50176]	Loss: 0.7970
Training Epoch: 26 [7168/50176]	Loss: 0.7725
Training Epoch: 26 [8192/50176]	Loss: 0.7917
Training Epoch: 26 [9216/50176]	Loss: 0.7455
Training Epoch: 26 [10240/50176]	Loss: 0.8033
Training Epoch: 26 [11264/50176]	Loss: 0.7837
Training Epoch: 26 [12288/50176]	Loss: 0.8050
Training Epoch: 26 [13312/50176]	Loss: 0.7549
Training Epoch: 26 [14336/50176]	Loss: 0.7952
Training Epoch: 26 [15360/50176]	Loss: 0.7318
Training Epoch: 26 [16384/50176]	Loss: 0.7590
Training Epoch: 26 [17408/50176]	Loss: 0.7883
Training Epoch: 26 [18432/50176]	Loss: 0.8052
Training Epoch: 26 [19456/50176]	Loss: 0.7874
Training Epoch: 26 [20480/50176]	Loss: 0.7973
Training Epoch: 26 [21504/50176]	Loss: 0.8246
Training Epoch: 26 [22528/50176]	Loss: 0.8097
Training Epoch: 26 [23552/50176]	Loss: 0.8640
Training Epoch: 26 [24576/50176]	Loss: 0.8514
Training Epoch: 26 [25600/50176]	Loss: 0.8271
Training Epoch: 26 [26624/50176]	Loss: 0.8005
Training Epoch: 26 [27648/50176]	Loss: 0.8522
Training Epoch: 26 [28672/50176]	Loss: 0.8134
Training Epoch: 26 [29696/50176]	Loss: 0.8036
Training Epoch: 26 [30720/50176]	Loss: 0.9154
Training Epoch: 26 [31744/50176]	Loss: 0.8334
Training Epoch: 26 [32768/50176]	Loss: 0.8230
Training Epoch: 26 [33792/50176]	Loss: 0.8678
Training Epoch: 26 [34816/50176]	Loss: 0.9071
Training Epoch: 26 [35840/50176]	Loss: 0.8624
Training Epoch: 26 [36864/50176]	Loss: 0.8086
Training Epoch: 26 [37888/50176]	Loss: 0.7961
Training Epoch: 26 [38912/50176]	Loss: 0.8388
Training Epoch: 26 [39936/50176]	Loss: 0.9413
Training Epoch: 26 [40960/50176]	Loss: 0.8367
Training Epoch: 26 [41984/50176]	Loss: 0.8943
Training Epoch: 26 [43008/50176]	Loss: 0.9099
Training Epoch: 26 [44032/50176]	Loss: 0.8807
Training Epoch: 26 [45056/50176]	Loss: 0.8493
Training Epoch: 26 [46080/50176]	Loss: 0.9699
Training Epoch: 26 [47104/50176]	Loss: 0.9052
Training Epoch: 26 [48128/50176]	Loss: 0.8771
Training Epoch: 26 [49152/50176]	Loss: 0.8404
Training Epoch: 26 [50176/50176]	Loss: 0.8822
2022-12-08 23:03:47.401 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:03:47,420 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.75 energy=518.55
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Up to epoch 27: time=1395.19, energy=201692.65, cost=222925.37
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:03:47,420 [ZeusDataLoader(train)] Expected next epoch: time=1442.16, energy=208912.72, cost=230645.19
2022-12-08 18:03:47,421 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0017, Accuracy: 0.5618
2022-12-08 18:03:47,597 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:03:47,598 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:03:47.602 [ZeusMonitor] Monitor started.
2022-12-08 23:03:47.602 [ZeusMonitor] Running indefinitely. 2022-12-08 23:03:47.602 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:03:47.602 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e28+gpu0.power.log
2022-12-08 18:04:31,552 [ZeusDataLoader(train)] train epoch 28 done: time=44.12 energy=6713.77
2022-12-08 18:04:31,556 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 0.7124
Training Epoch: 27 [2048/50176]	Loss: 0.7896
Training Epoch: 27 [3072/50176]	Loss: 0.7285
Training Epoch: 27 [4096/50176]	Loss: 0.7905
Training Epoch: 27 [5120/50176]	Loss: 0.7588
Training Epoch: 27 [6144/50176]	Loss: 0.7686
Training Epoch: 27 [7168/50176]	Loss: 0.7025
Training Epoch: 27 [8192/50176]	Loss: 0.7771
Training Epoch: 27 [9216/50176]	Loss: 0.7713
Training Epoch: 27 [10240/50176]	Loss: 0.7586
Training Epoch: 27 [11264/50176]	Loss: 0.7957
Training Epoch: 27 [12288/50176]	Loss: 0.7240
Training Epoch: 27 [13312/50176]	Loss: 0.7602
Training Epoch: 27 [14336/50176]	Loss: 0.7217
Training Epoch: 27 [15360/50176]	Loss: 0.7337
Training Epoch: 27 [16384/50176]	Loss: 0.7919
Training Epoch: 27 [17408/50176]	Loss: 0.7034
Training Epoch: 27 [18432/50176]	Loss: 0.7688
Training Epoch: 27 [19456/50176]	Loss: 0.7390
Training Epoch: 27 [20480/50176]	Loss: 0.7222
Training Epoch: 27 [21504/50176]	Loss: 0.7552
Training Epoch: 27 [22528/50176]	Loss: 0.7204
Training Epoch: 27 [23552/50176]	Loss: 0.6827
Training Epoch: 27 [24576/50176]	Loss: 0.7502
Training Epoch: 27 [25600/50176]	Loss: 0.7779
Training Epoch: 27 [26624/50176]	Loss: 0.8067
Training Epoch: 27 [27648/50176]	Loss: 0.7930
Training Epoch: 27 [28672/50176]	Loss: 0.7989
Training Epoch: 27 [29696/50176]	Loss: 0.7726
Training Epoch: 27 [30720/50176]	Loss: 0.7547
Training Epoch: 27 [31744/50176]	Loss: 0.8990
Training Epoch: 27 [32768/50176]	Loss: 0.8071
Training Epoch: 27 [33792/50176]	Loss: 0.7952
Training Epoch: 27 [34816/50176]	Loss: 0.8327
Training Epoch: 27 [35840/50176]	Loss: 0.8870
Training Epoch: 27 [36864/50176]	Loss: 0.8047
Training Epoch: 27 [37888/50176]	Loss: 0.7683
Training Epoch: 27 [38912/50176]	Loss: 0.8412
Training Epoch: 27 [39936/50176]	Loss: 0.8537
Training Epoch: 27 [40960/50176]	Loss: 0.7968
Training Epoch: 27 [41984/50176]	Loss: 0.7996
Training Epoch: 27 [43008/50176]	Loss: 0.7352
Training Epoch: 27 [44032/50176]	Loss: 0.8457
Training Epoch: 27 [45056/50176]	Loss: 0.8160
Training Epoch: 27 [46080/50176]	Loss: 0.8516
Training Epoch: 27 [47104/50176]	Loss: 0.8853
Training Epoch: 27 [48128/50176]	Loss: 0.7799
Training Epoch: 27 [49152/50176]	Loss: 0.8724
Training Epoch: 27 [50176/50176]	Loss: 0.8675
2022-12-08 23:04:35.286 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:04:35,308 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=516.37
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Up to epoch 28: time=1443.05, energy=208922.79, cost=230728.69
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:04:35,309 [ZeusDataLoader(train)] Expected next epoch: time=1490.02, energy=216142.86, cost=238448.51
2022-12-08 18:04:35,310 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0016, Accuracy: 0.5922
2022-12-08 18:04:35,539 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:04:35,540 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:04:35.542 [ZeusMonitor] Monitor started.
2022-12-08 23:04:35.542 [ZeusMonitor] Running indefinitely. 2022-12-08 23:04:35.542 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:04:35.542 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e29+gpu0.power.log
2022-12-08 18:05:19,507 [ZeusDataLoader(train)] train epoch 29 done: time=44.19 energy=6703.86
2022-12-08 18:05:19,510 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 0.6693
Training Epoch: 28 [2048/50176]	Loss: 0.7472
Training Epoch: 28 [3072/50176]	Loss: 0.7091
Training Epoch: 28 [4096/50176]	Loss: 0.7409
Training Epoch: 28 [5120/50176]	Loss: 0.7067
Training Epoch: 28 [6144/50176]	Loss: 0.7037
Training Epoch: 28 [7168/50176]	Loss: 0.6796
Training Epoch: 28 [8192/50176]	Loss: 0.7296
Training Epoch: 28 [9216/50176]	Loss: 0.7201
Training Epoch: 28 [10240/50176]	Loss: 0.6446
Training Epoch: 28 [11264/50176]	Loss: 0.6976
Training Epoch: 28 [12288/50176]	Loss: 0.6912
Training Epoch: 28 [13312/50176]	Loss: 0.6971
Training Epoch: 28 [14336/50176]	Loss: 0.7557
Training Epoch: 28 [15360/50176]	Loss: 0.7058
Training Epoch: 28 [16384/50176]	Loss: 0.7441
Training Epoch: 28 [17408/50176]	Loss: 0.7034
Training Epoch: 28 [18432/50176]	Loss: 0.6708
Training Epoch: 28 [19456/50176]	Loss: 0.7937
Training Epoch: 28 [20480/50176]	Loss: 0.7568
Training Epoch: 28 [21504/50176]	Loss: 0.7364
Training Epoch: 28 [22528/50176]	Loss: 0.7532
Training Epoch: 28 [23552/50176]	Loss: 0.7677
Training Epoch: 28 [24576/50176]	Loss: 0.6802
Training Epoch: 28 [25600/50176]	Loss: 0.7244
Training Epoch: 28 [26624/50176]	Loss: 0.7458
Training Epoch: 28 [27648/50176]	Loss: 0.8077
Training Epoch: 28 [28672/50176]	Loss: 0.7615
Training Epoch: 28 [29696/50176]	Loss: 0.7257
Training Epoch: 28 [30720/50176]	Loss: 0.7712
Training Epoch: 28 [31744/50176]	Loss: 0.7746
Training Epoch: 28 [32768/50176]	Loss: 0.7521
Training Epoch: 28 [33792/50176]	Loss: 0.7518
Training Epoch: 28 [34816/50176]	Loss: 0.7686
Training Epoch: 28 [35840/50176]	Loss: 0.7591
Training Epoch: 28 [36864/50176]	Loss: 0.8182
Training Epoch: 28 [37888/50176]	Loss: 0.7423
Training Epoch: 28 [38912/50176]	Loss: 0.7591
Training Epoch: 28 [39936/50176]	Loss: 0.7851
Training Epoch: 28 [40960/50176]	Loss: 0.8794
Training Epoch: 28 [41984/50176]	Loss: 0.8324
Training Epoch: 28 [43008/50176]	Loss: 0.7585
Training Epoch: 28 [44032/50176]	Loss: 0.7653
Training Epoch: 28 [45056/50176]	Loss: 0.8923
Training Epoch: 28 [46080/50176]	Loss: 0.7772
Training Epoch: 28 [47104/50176]	Loss: 0.8493
Training Epoch: 28 [48128/50176]	Loss: 0.7496
Training Epoch: 28 [49152/50176]	Loss: 0.8210
Training Epoch: 28 [50176/50176]	Loss: 0.7761
2022-12-08 23:05:23.281 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:05:23,338 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.82 energy=531.92
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Up to epoch 29: time=1491.06, energy=216158.57, cost=238547.29
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:05:23,339 [ZeusDataLoader(train)] Expected next epoch: time=1538.03, energy=223378.64, cost=246267.11
2022-12-08 18:05:23,340 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0017, Accuracy: 0.5842
2022-12-08 18:05:23,556 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:05:23,557 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:05:23.559 [ZeusMonitor] Monitor started.
2022-12-08 23:05:23.559 [ZeusMonitor] Running indefinitely. 2022-12-08 23:05:23.559 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:05:23.559 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e30+gpu0.power.log
2022-12-08 18:06:07,505 [ZeusDataLoader(train)] train epoch 30 done: time=44.16 energy=6699.65
2022-12-08 18:06:07,508 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 0.6528
Training Epoch: 29 [2048/50176]	Loss: 0.6546
Training Epoch: 29 [3072/50176]	Loss: 0.6957
Training Epoch: 29 [4096/50176]	Loss: 0.6626
Training Epoch: 29 [5120/50176]	Loss: 0.7179
Training Epoch: 29 [6144/50176]	Loss: 0.6633
Training Epoch: 29 [7168/50176]	Loss: 0.6729
Training Epoch: 29 [8192/50176]	Loss: 0.6619
Training Epoch: 29 [9216/50176]	Loss: 0.6752
Training Epoch: 29 [10240/50176]	Loss: 0.7096
Training Epoch: 29 [11264/50176]	Loss: 0.7153
Training Epoch: 29 [12288/50176]	Loss: 0.7113
Training Epoch: 29 [13312/50176]	Loss: 0.5941
Training Epoch: 29 [14336/50176]	Loss: 0.6862
Training Epoch: 29 [15360/50176]	Loss: 0.7840
Training Epoch: 29 [16384/50176]	Loss: 0.7116
Training Epoch: 29 [17408/50176]	Loss: 0.6887
Training Epoch: 29 [18432/50176]	Loss: 0.6681
Training Epoch: 29 [19456/50176]	Loss: 0.7805
Training Epoch: 29 [20480/50176]	Loss: 0.6738
Training Epoch: 29 [21504/50176]	Loss: 0.6913
Training Epoch: 29 [22528/50176]	Loss: 0.6337
Training Epoch: 29 [23552/50176]	Loss: 0.6434
Training Epoch: 29 [24576/50176]	Loss: 0.6831
Training Epoch: 29 [25600/50176]	Loss: 0.6930
Training Epoch: 29 [26624/50176]	Loss: 0.6666
Training Epoch: 29 [27648/50176]	Loss: 0.7301
Training Epoch: 29 [28672/50176]	Loss: 0.6122
Training Epoch: 29 [29696/50176]	Loss: 0.6726
Training Epoch: 29 [30720/50176]	Loss: 0.7491
Training Epoch: 29 [31744/50176]	Loss: 0.6827
Training Epoch: 29 [32768/50176]	Loss: 0.7728
Training Epoch: 29 [33792/50176]	Loss: 0.7123
Training Epoch: 29 [34816/50176]	Loss: 0.7590
Training Epoch: 29 [35840/50176]	Loss: 0.6961
Training Epoch: 29 [36864/50176]	Loss: 0.7172
Training Epoch: 29 [37888/50176]	Loss: 0.7310
Training Epoch: 29 [38912/50176]	Loss: 0.7000
Training Epoch: 29 [39936/50176]	Loss: 0.7301
Training Epoch: 29 [40960/50176]	Loss: 0.8089
Training Epoch: 29 [41984/50176]	Loss: 0.7027
Training Epoch: 29 [43008/50176]	Loss: 0.8009
Training Epoch: 29 [44032/50176]	Loss: 0.7514
Training Epoch: 29 [45056/50176]	Loss: 0.7614
Training Epoch: 29 [46080/50176]	Loss: 0.7278
Training Epoch: 29 [47104/50176]	Loss: 0.7479
Training Epoch: 29 [48128/50176]	Loss: 0.7938
Training Epoch: 29 [49152/50176]	Loss: 0.7501
Training Epoch: 29 [50176/50176]	Loss: 0.8736
2022-12-08 23:06:11.302 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:06:11,322 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.81 energy=534.53
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Up to epoch 30: time=1539.02, energy=223392.75, cost=246361.01
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:06:11,322 [ZeusDataLoader(train)] Expected next epoch: time=1585.99, energy=230612.82, cost=254080.83
2022-12-08 18:06:11,324 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0016, Accuracy: 0.5872
2022-12-08 18:06:11,543 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:06:11,544 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:06:11.558 [ZeusMonitor] Monitor started.
2022-12-08 23:06:11.558 [ZeusMonitor] Running indefinitely. 2022-12-08 23:06:11.558 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:06:11.558 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e31+gpu0.power.log
2022-12-08 18:06:55,502 [ZeusDataLoader(train)] train epoch 31 done: time=44.17 energy=6709.65
2022-12-08 18:06:55,506 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 0.7199
Training Epoch: 30 [2048/50176]	Loss: 0.6457
Training Epoch: 30 [3072/50176]	Loss: 0.6391
Training Epoch: 30 [4096/50176]	Loss: 0.6106
Training Epoch: 30 [5120/50176]	Loss: 0.6285
Training Epoch: 30 [6144/50176]	Loss: 0.6186
Training Epoch: 30 [7168/50176]	Loss: 0.6855
Training Epoch: 30 [8192/50176]	Loss: 0.6234
Training Epoch: 30 [9216/50176]	Loss: 0.6546
Training Epoch: 30 [10240/50176]	Loss: 0.6351
Training Epoch: 30 [11264/50176]	Loss: 0.7007
Training Epoch: 30 [12288/50176]	Loss: 0.6832
Training Epoch: 30 [13312/50176]	Loss: 0.6347
Training Epoch: 30 [14336/50176]	Loss: 0.6518
Training Epoch: 30 [15360/50176]	Loss: 0.6562
Training Epoch: 30 [16384/50176]	Loss: 0.6865
Training Epoch: 30 [17408/50176]	Loss: 0.6482
Training Epoch: 30 [18432/50176]	Loss: 0.6450
Training Epoch: 30 [19456/50176]	Loss: 0.6388
Training Epoch: 30 [20480/50176]	Loss: 0.6368
Training Epoch: 30 [21504/50176]	Loss: 0.6433
Training Epoch: 30 [22528/50176]	Loss: 0.6410
Training Epoch: 30 [23552/50176]	Loss: 0.6519
Training Epoch: 30 [24576/50176]	Loss: 0.6579
Training Epoch: 30 [25600/50176]	Loss: 0.6728
Training Epoch: 30 [26624/50176]	Loss: 0.6763
Training Epoch: 30 [27648/50176]	Loss: 0.6992
Training Epoch: 30 [28672/50176]	Loss: 0.7025
Training Epoch: 30 [29696/50176]	Loss: 0.6764
Training Epoch: 30 [30720/50176]	Loss: 0.6817
Training Epoch: 30 [31744/50176]	Loss: 0.6316
Training Epoch: 30 [32768/50176]	Loss: 0.6788
Training Epoch: 30 [33792/50176]	Loss: 0.7306
Training Epoch: 30 [34816/50176]	Loss: 0.8009
Training Epoch: 30 [35840/50176]	Loss: 0.7248
Training Epoch: 30 [36864/50176]	Loss: 0.7167
Training Epoch: 30 [37888/50176]	Loss: 0.6978
Training Epoch: 30 [38912/50176]	Loss: 0.7941
Training Epoch: 30 [39936/50176]	Loss: 0.7001
Training Epoch: 30 [40960/50176]	Loss: 0.7374
Training Epoch: 30 [41984/50176]	Loss: 0.7349
Training Epoch: 30 [43008/50176]	Loss: 0.7650
Training Epoch: 30 [44032/50176]	Loss: 0.7013
Training Epoch: 30 [45056/50176]	Loss: 0.7236
Training Epoch: 30 [46080/50176]	Loss: 0.7042
Training Epoch: 30 [47104/50176]	Loss: 0.7407
Training Epoch: 30 [48128/50176]	Loss: 0.7097
Training Epoch: 30 [49152/50176]	Loss: 0.7549
Training Epoch: 30 [50176/50176]	Loss: 0.7920
2022-12-08 23:06:59.218 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:06:59,232 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.72 energy=514.73
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Up to epoch 31: time=1586.91, energy=230617.13, cost=254163.46
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:06:59,233 [ZeusDataLoader(train)] Expected next epoch: time=1633.88, energy=237837.20, cost=261883.28
2022-12-08 18:06:59,234 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0016, Accuracy: 0.5945
2022-12-08 18:06:59,471 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:06:59,471 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:06:59.485 [ZeusMonitor] Monitor started.
2022-12-08 23:06:59.485 [ZeusMonitor] Running indefinitely. 2022-12-08 23:06:59.486 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:06:59.486 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e32+gpu0.power.log
2022-12-08 18:07:43,362 [ZeusDataLoader(train)] train epoch 32 done: time=44.12 energy=6706.49
2022-12-08 18:07:43,365 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 0.5903
Training Epoch: 31 [2048/50176]	Loss: 0.5276
Training Epoch: 31 [3072/50176]	Loss: 0.5981
Training Epoch: 31 [4096/50176]	Loss: 0.5375
Training Epoch: 31 [5120/50176]	Loss: 0.5933
Training Epoch: 31 [6144/50176]	Loss: 0.5897
Training Epoch: 31 [7168/50176]	Loss: 0.6174
Training Epoch: 31 [8192/50176]	Loss: 0.5979
Training Epoch: 31 [9216/50176]	Loss: 0.6301
Training Epoch: 31 [10240/50176]	Loss: 0.6105
Training Epoch: 31 [11264/50176]	Loss: 0.5859
Training Epoch: 31 [12288/50176]	Loss: 0.6629
Training Epoch: 31 [13312/50176]	Loss: 0.6316
Training Epoch: 31 [14336/50176]	Loss: 0.5549
Training Epoch: 31 [15360/50176]	Loss: 0.6031
Training Epoch: 31 [16384/50176]	Loss: 0.6119
Training Epoch: 31 [17408/50176]	Loss: 0.6137
Training Epoch: 31 [18432/50176]	Loss: 0.6263
Training Epoch: 31 [19456/50176]	Loss: 0.6085
Training Epoch: 31 [20480/50176]	Loss: 0.6468
Training Epoch: 31 [21504/50176]	Loss: 0.6620
Training Epoch: 31 [22528/50176]	Loss: 0.6140
Training Epoch: 31 [23552/50176]	Loss: 0.6922
Training Epoch: 31 [24576/50176]	Loss: 0.6043
Training Epoch: 31 [25600/50176]	Loss: 0.6429
Training Epoch: 31 [26624/50176]	Loss: 0.6753
Training Epoch: 31 [27648/50176]	Loss: 0.6359
Training Epoch: 31 [28672/50176]	Loss: 0.5948
Training Epoch: 31 [29696/50176]	Loss: 0.6266
Training Epoch: 31 [30720/50176]	Loss: 0.6221
Training Epoch: 31 [31744/50176]	Loss: 0.7017
Training Epoch: 31 [32768/50176]	Loss: 0.6769
Training Epoch: 31 [33792/50176]	Loss: 0.6377
Training Epoch: 31 [34816/50176]	Loss: 0.7037
Training Epoch: 31 [35840/50176]	Loss: 0.6876
Training Epoch: 31 [36864/50176]	Loss: 0.6856
Training Epoch: 31 [37888/50176]	Loss: 0.6802
Training Epoch: 31 [38912/50176]	Loss: 0.7466
Training Epoch: 31 [39936/50176]	Loss: 0.7449
Training Epoch: 31 [40960/50176]	Loss: 0.6565
Training Epoch: 31 [41984/50176]	Loss: 0.6467
Training Epoch: 31 [43008/50176]	Loss: 0.6415
Training Epoch: 31 [44032/50176]	Loss: 0.6365
Training Epoch: 31 [45056/50176]	Loss: 0.7423
Training Epoch: 31 [46080/50176]	Loss: 0.7074
Training Epoch: 31 [47104/50176]	Loss: 0.6517
Training Epoch: 31 [48128/50176]	Loss: 0.7233
Training Epoch: 31 [49152/50176]	Loss: 0.6604
Training Epoch: 31 [50176/50176]	Loss: 0.6446
2022-12-08 23:07:47.154 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:07:47,176 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.80 energy=531.34
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Up to epoch 32: time=1634.83, energy=237854.96, cost=261975.50
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.97 energy=7220.07
2022-12-08 18:07:47,176 [ZeusDataLoader(train)] Expected next epoch: time=1681.80, energy=245075.03, cost=269695.32
2022-12-08 18:07:47,177 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5854
2022-12-08 18:07:47,395 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 18:07:47,396 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 23:07:47.410 [ZeusMonitor] Monitor started.
2022-12-08 23:07:47.410 [ZeusMonitor] Running indefinitely. 2022-12-08 23:07:47.410 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 23:07:47.410 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/bs1024+e33+gpu0.power.log
2022-12-08 18:08:31,403 [ZeusDataLoader(train)] train epoch 33 done: time=44.22 energy=6722.75
2022-12-08 18:08:31,407 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 0.5499
Training Epoch: 32 [2048/50176]	Loss: 0.5190
Training Epoch: 32 [3072/50176]	Loss: 0.6031
Training Epoch: 32 [4096/50176]	Loss: 0.5740
Training Epoch: 32 [5120/50176]	Loss: 0.6003
Training Epoch: 32 [6144/50176]	Loss: 0.5678
Training Epoch: 32 [7168/50176]	Loss: 0.5855
Training Epoch: 32 [8192/50176]	Loss: 0.6146
Training Epoch: 32 [9216/50176]	Loss: 0.5492
Training Epoch: 32 [10240/50176]	Loss: 0.5245
Training Epoch: 32 [11264/50176]	Loss: 0.5399
Training Epoch: 32 [12288/50176]	Loss: 0.5779
Training Epoch: 32 [13312/50176]	Loss: 0.5718
Training Epoch: 32 [14336/50176]	Loss: 0.6590
Training Epoch: 32 [15360/50176]	Loss: 0.5396
Training Epoch: 32 [16384/50176]	Loss: 0.5564
Training Epoch: 32 [17408/50176]	Loss: 0.6288
Training Epoch: 32 [18432/50176]	Loss: 0.5427
Training Epoch: 32 [19456/50176]	Loss: 0.5633
Training Epoch: 32 [20480/50176]	Loss: 0.5591
Training Epoch: 32 [21504/50176]	Loss: 0.6277
Training Epoch: 32 [22528/50176]	Loss: 0.6860
Training Epoch: 32 [23552/50176]	Loss: 0.6434
Training Epoch: 32 [24576/50176]	Loss: 0.5424
Training Epoch: 32 [25600/50176]	Loss: 0.6656
Training Epoch: 32 [26624/50176]	Loss: 0.5543
Training Epoch: 32 [27648/50176]	Loss: 0.5234
Training Epoch: 32 [28672/50176]	Loss: 0.5445
Training Epoch: 32 [29696/50176]	Loss: 0.6231
Training Epoch: 32 [30720/50176]	Loss: 0.5704
Training Epoch: 32 [31744/50176]	Loss: 0.6023
Training Epoch: 32 [32768/50176]	Loss: 0.6288
Training Epoch: 32 [33792/50176]	Loss: 0.6258
Training Epoch: 32 [34816/50176]	Loss: 0.6429
Training Epoch: 32 [35840/50176]	Loss: 0.5803
Training Epoch: 32 [36864/50176]	Loss: 0.6161
Training Epoch: 32 [37888/50176]	Loss: 0.5974
Training Epoch: 32 [38912/50176]	Loss: 0.6036
Training Epoch: 32 [39936/50176]	Loss: 0.6332
Training Epoch: 32 [40960/50176]	Loss: 0.6424
Training Epoch: 32 [41984/50176]	Loss: 0.5978
Training Epoch: 32 [43008/50176]	Loss: 0.6846
Training Epoch: 32 [44032/50176]	Loss: 0.6250
Training Epoch: 32 [45056/50176]	Loss: 0.6090
Training Epoch: 32 [46080/50176]	Loss: 0.7008
Training Epoch: 32 [47104/50176]	Loss: 0.6731
Training Epoch: 32 [48128/50176]	Loss: 0.6389
Training Epoch: 32 [49152/50176]	Loss: 0.6575
Training Epoch: 32 [50176/50176]	Loss: 0.7060
2022-12-08 23:08:35.161 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 18:08:35,174 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=512.67
2022-12-08 18:08:35,174 [ZeusDataLoader(train)] Up to epoch 33: time=1682.81, energy=245090.38, cost=269791.12
2022-12-08 18:08:35,174 [ZeusDataLoader(train)] Target metric 0.6 was reached! Stopping.
2022-12-08 18:08:35,175 [ZeusDataLoader(train)] Training done.
2022-12-08 18:08:35,175 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120817401670539224/rec00+try01+bs1024+lr0.0060000.train.json: {"energy": 245090.3820494143, "time": 1682.810654917026, "cost": 269791.12332994695, "num_epochs": 33, "reached": true}
Validation Epoch: 32, Average loss: 0.0016, Accuracy: 0.6007

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 245090.3820494143, 'time': 1682.810654917026, 'cost': 269791.12332994695, 'num_epochs': 33, 'reached': True}
[run job; power] power_stats={'job_id': 'rec00+try01', 'train_power': {'175000': 155.16304190626855, '150000': 146.66679122833526, '125000': 123.11079515402562, '100000': 102.24933636766599}, 'train_throughput': {'175000': 1.1359478370950427, '150000': 1.1007655943504855, '125000': 0.9684575298543399, '100000': 0.3672341515196985}, 'eval_power': {'175000': 137.48240735072176, '150000': 134.78162791311982, '125000': 112.630877961285}, 'eval_throughput': {'175000': 2.6088153813743062, '150000': 2.6273896195624724, '125000': 2.337656921522037}, 'optimal_pl': 175000}
[Zeus Master] cost=269791.12332994695

[Zeus Master] Reached target metric in 1 try.
