[run job] Launching job with BS 1024: and LR: 0.05
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec02+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.05']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec02+try01.train.log'
2022-12-06 13:10:46,042 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 13:10:46,042 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 13:10:46,043 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 13:10:46,085 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 13:10:46,085 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 13:10:48,189 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 13:10:48,190 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 13:10:48,354 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:10:48.356 [ZeusMonitor] Monitor started.
2022-12-06 18:10:48.356 [ZeusMonitor] Running indefinitely. 2022-12-06 18:10:48.356 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:10:48.356 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 13:10:49,039 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 13:10:49,040 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 13:10:57,656 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 13:11:31,383 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 13:11:33,032 [ZeusDataLoader(train)] train epoch 1 done: time=44.84 energy=6291.48
2022-12-06 13:11:33,035 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 18.3248
Training Epoch: 0 [3072/50176]	Loss: 9.6542
Training Epoch: 0 [4096/50176]	Loss: 8.4885
Training Epoch: 0 [5120/50176]	Loss: 9.8576
Training Epoch: 0 [6144/50176]	Loss: 10.6665
Training Epoch: 0 [7168/50176]	Loss: 7.0869
Training Epoch: 0 [8192/50176]	Loss: 7.3002
Training Epoch: 0 [9216/50176]	Loss: 5.6747
Training Epoch: 0 [10240/50176]	Loss: 5.6620
Training Epoch: 0 [11264/50176]	Loss: 5.8762
Training Epoch: 0 [12288/50176]	Loss: 5.1456
Training Epoch: 0 [13312/50176]	Loss: 5.2279
Training Epoch: 0 [14336/50176]	Loss: 4.6846
Training Epoch: 0 [15360/50176]	Loss: 5.2353
Training Epoch: 0 [16384/50176]	Loss: 5.2059
Training Epoch: 0 [17408/50176]	Loss: 4.6928
Training Epoch: 0 [18432/50176]	Loss: 4.8528
Training Epoch: 0 [19456/50176]	Loss: 4.6386
Training Epoch: 0 [20480/50176]	Loss: 4.7371
Training Epoch: 0 [21504/50176]	Loss: 4.7556
Training Epoch: 0 [22528/50176]	Loss: 5.0653
Training Epoch: 0 [23552/50176]	Loss: 5.1241
Training Epoch: 0 [24576/50176]	Loss: 4.9408
Training Epoch: 0 [25600/50176]	Loss: 4.7500
Training Epoch: 0 [26624/50176]	Loss: 4.6854
Training Epoch: 0 [27648/50176]	Loss: 4.6618
Training Epoch: 0 [28672/50176]	Loss: 4.6156
Training Epoch: 0 [29696/50176]	Loss: 4.6114
Training Epoch: 0 [30720/50176]	Loss: 4.6125
Training Epoch: 0 [31744/50176]	Loss: 4.6123
Training Epoch: 0 [32768/50176]	Loss: 4.6116
Training Epoch: 0 [33792/50176]	Loss: 4.6160
Training Epoch: 0 [34816/50176]	Loss: 4.6093
Training Epoch: 0 [35840/50176]	Loss: 4.6128
Training Epoch: 0 [36864/50176]	Loss: 4.6091
Training Epoch: 0 [37888/50176]	Loss: 4.6091
Training Epoch: 0 [38912/50176]	Loss: 4.6115
Training Epoch: 0 [39936/50176]	Loss: 4.6134
Training Epoch: 0 [40960/50176]	Loss: 4.6065
Training Epoch: 0 [41984/50176]	Loss: 4.6111
Training Epoch: 0 [43008/50176]	Loss: 4.6094
Training Epoch: 0 [44032/50176]	Loss: 4.6127
Training Epoch: 0 [45056/50176]	Loss: 4.6102
Training Epoch: 0 [46080/50176]	Loss: 4.6101
Training Epoch: 0 [47104/50176]	Loss: 4.6092
Training Epoch: 0 [48128/50176]	Loss: 4.6130
Training Epoch: 0 [49152/50176]	Loss: 4.6119
Training Epoch: 0 [50176/50176]	Loss: 4.6074
2022-12-06 18:11:36.698 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:11:36,709 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.67 energy=458.64
2022-12-06 13:11:36,709 [ZeusDataLoader(train)] Up to epoch 1: time=48.50, energy=6750.13, cost=7618.99
2022-12-06 13:11:36,710 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0045, Accuracy: 0.0099
2022-12-06 13:11:36,932 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:11:36.934 [ZeusMonitor] Monitor started.
2022-12-06 18:11:36.935 [ZeusMonitor] Running indefinitely. 2022-12-06 18:11:36.935 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:11:36.935 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 13:11:37,630 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 13:11:37,630 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 13:11:45,697 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 13:12:19,281 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 13:12:20,940 [ZeusDataLoader(train)] train epoch 2 done: time=44.22 energy=6197.37
2022-12-06 13:12:20,943 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.6100
Training Epoch: 1 [2048/50176]	Loss: 4.6059
Training Epoch: 1 [3072/50176]	Loss: 4.6088
Training Epoch: 1 [4096/50176]	Loss: 4.6063
Training Epoch: 1 [5120/50176]	Loss: 4.6098
Training Epoch: 1 [6144/50176]	Loss: 4.6078
Training Epoch: 1 [7168/50176]	Loss: 4.6071
Training Epoch: 1 [8192/50176]	Loss: 4.6068
Training Epoch: 1 [9216/50176]	Loss: 4.6119
Training Epoch: 1 [10240/50176]	Loss: 4.6093
Training Epoch: 1 [11264/50176]	Loss: 4.6076
Training Epoch: 1 [12288/50176]	Loss: 4.6057
Training Epoch: 1 [13312/50176]	Loss: 4.6111
Training Epoch: 1 [14336/50176]	Loss: 4.6057
Training Epoch: 1 [15360/50176]	Loss: 4.6097
Training Epoch: 1 [16384/50176]	Loss: 4.6103
Training Epoch: 1 [17408/50176]	Loss: 4.6089
Training Epoch: 1 [18432/50176]	Loss: 4.6070
Training Epoch: 1 [19456/50176]	Loss: 4.6092
Training Epoch: 1 [20480/50176]	Loss: 4.6126
Training Epoch: 1 [21504/50176]	Loss: 4.6079
Training Epoch: 1 [22528/50176]	Loss: 4.6068
Training Epoch: 1 [23552/50176]	Loss: 4.6095
Training Epoch: 1 [24576/50176]	Loss: 4.6063
Training Epoch: 1 [25600/50176]	Loss: 4.6092
Training Epoch: 1 [26624/50176]	Loss: 4.6104
Training Epoch: 1 [27648/50176]	Loss: 4.6109
Training Epoch: 1 [28672/50176]	Loss: 4.6076
Training Epoch: 1 [29696/50176]	Loss: 4.6105
Training Epoch: 1 [30720/50176]	Loss: 4.6071
Training Epoch: 1 [31744/50176]	Loss: 4.6116
Training Epoch: 1 [32768/50176]	Loss: 4.6098
Training Epoch: 1 [33792/50176]	Loss: 4.6083
Training Epoch: 1 [34816/50176]	Loss: 4.6082
Training Epoch: 1 [35840/50176]	Loss: 4.6095
Training Epoch: 1 [36864/50176]	Loss: 4.6091
Training Epoch: 1 [37888/50176]	Loss: 4.6104
Training Epoch: 1 [38912/50176]	Loss: 4.6070
Training Epoch: 1 [39936/50176]	Loss: 4.6081
Training Epoch: 1 [40960/50176]	Loss: 4.6089
Training Epoch: 1 [41984/50176]	Loss: 4.6101
Training Epoch: 1 [43008/50176]	Loss: 4.6083
Training Epoch: 1 [44032/50176]	Loss: 4.6106
Training Epoch: 1 [45056/50176]	Loss: 4.6087
Training Epoch: 1 [46080/50176]	Loss: 4.6095
Training Epoch: 1 [47104/50176]	Loss: 4.6086
Training Epoch: 1 [48128/50176]	Loss: 4.6092
Training Epoch: 1 [49152/50176]	Loss: 4.6070
Training Epoch: 1 [50176/50176]	Loss: 4.6065
2022-12-06 18:12:24.678 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:12:24,735 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.78 energy=472.13
2022-12-06 13:12:24,735 [ZeusDataLoader(train)] Up to epoch 2: time=96.51, energy=13419.63, cost=15154.39
2022-12-06 13:12:24,736 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0045, Accuracy: 0.0104
2022-12-06 13:12:24,968 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:12:24.970 [ZeusMonitor] Monitor started.
2022-12-06 18:12:24.970 [ZeusMonitor] Running indefinitely. 2022-12-06 18:12:24.970 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:12:24.970 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 13:12:25,667 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 13:12:25,667 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 13:12:34,341 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 13:13:10,547 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 13:13:12,344 [ZeusDataLoader(train)] train epoch 3 done: time=47.60 energy=5744.46
2022-12-06 13:13:12,348 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 4.6041
Training Epoch: 2 [2048/50176]	Loss: 4.6045
Training Epoch: 2 [3072/50176]	Loss: 4.6050
Training Epoch: 2 [4096/50176]	Loss: 4.6048
Training Epoch: 2 [5120/50176]	Loss: 4.6100
Training Epoch: 2 [6144/50176]	Loss: 4.6042
Training Epoch: 2 [7168/50176]	Loss: 4.6100
Training Epoch: 2 [8192/50176]	Loss: 4.6091
Training Epoch: 2 [9216/50176]	Loss: 4.6046
Training Epoch: 2 [10240/50176]	Loss: 4.6091
Training Epoch: 2 [11264/50176]	Loss: 4.6062
Training Epoch: 2 [12288/50176]	Loss: 4.6147
Training Epoch: 2 [13312/50176]	Loss: 4.6057
Training Epoch: 2 [14336/50176]	Loss: 4.6066
Training Epoch: 2 [15360/50176]	Loss: 4.6116
Training Epoch: 2 [16384/50176]	Loss: 4.6056
Training Epoch: 2 [17408/50176]	Loss: 4.6080
Training Epoch: 2 [18432/50176]	Loss: 4.6099
Training Epoch: 2 [19456/50176]	Loss: 4.6057
Training Epoch: 2 [20480/50176]	Loss: 4.6060
Training Epoch: 2 [21504/50176]	Loss: 4.6069
Training Epoch: 2 [22528/50176]	Loss: 4.6085
Training Epoch: 2 [23552/50176]	Loss: 4.5954
Training Epoch: 2 [24576/50176]	Loss: 4.6054
Training Epoch: 2 [25600/50176]	Loss: 4.6028
Training Epoch: 2 [26624/50176]	Loss: 4.6080
Training Epoch: 2 [27648/50176]	Loss: 4.6012
Training Epoch: 2 [28672/50176]	Loss: 4.5956
Training Epoch: 2 [29696/50176]	Loss: 4.5996
Training Epoch: 2 [30720/50176]	Loss: 4.6009
Training Epoch: 2 [31744/50176]	Loss: 4.6062
Training Epoch: 2 [32768/50176]	Loss: 4.5954
Training Epoch: 2 [33792/50176]	Loss: 4.5990
Training Epoch: 2 [34816/50176]	Loss: 4.5979
Training Epoch: 2 [35840/50176]	Loss: 4.5934
Training Epoch: 2 [36864/50176]	Loss: 4.5943
Training Epoch: 2 [37888/50176]	Loss: 4.5923
Training Epoch: 2 [38912/50176]	Loss: 4.5958
Training Epoch: 2 [39936/50176]	Loss: 4.5878
Training Epoch: 2 [40960/50176]	Loss: 4.5853
Training Epoch: 2 [41984/50176]	Loss: 4.5769
Training Epoch: 2 [43008/50176]	Loss: 4.5761
Training Epoch: 2 [44032/50176]	Loss: 4.5767
Training Epoch: 2 [45056/50176]	Loss: 4.5720
Training Epoch: 2 [46080/50176]	Loss: 4.5652
Training Epoch: 2 [47104/50176]	Loss: 4.5813
Training Epoch: 2 [48128/50176]	Loss: 4.5683
Training Epoch: 2 [49152/50176]	Loss: 4.5641
Training Epoch: 2 [50176/50176]	Loss: 4.5604
2022-12-06 18:13:16.248 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:13:16,270 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.91 energy=442.58
2022-12-06 13:13:16,270 [ZeusDataLoader(train)] Up to epoch 3: time=148.03, energy=19606.67, cost=22755.52
2022-12-06 13:13:16,271 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0045, Accuracy: 0.0096
2022-12-06 13:13:16,494 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 18:13:16.497 [ZeusMonitor] Monitor started.
2022-12-06 18:13:16.497 [ZeusMonitor] Running indefinitely. 2022-12-06 18:13:16.497 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:13:16.497 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 13:13:17,204 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 13:13:17,204 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 13:13:31,383 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 13:14:42,830 [ZeusDataLoader(train)] Cost-optimal power limit is 150W
2022-12-06 13:14:42,833 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 13:14:44,604 [ZeusDataLoader(train)] train epoch 4 done: time=88.32 energy=8477.40
2022-12-06 13:14:44,608 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 4.5546
Training Epoch: 3 [2048/50176]	Loss: 4.5400
Training Epoch: 3 [3072/50176]	Loss: 4.5409
Training Epoch: 3 [4096/50176]	Loss: 4.5386
Training Epoch: 3 [5120/50176]	Loss: 4.5368
Training Epoch: 3 [6144/50176]	Loss: 4.5295
Training Epoch: 3 [7168/50176]	Loss: 4.5255
Training Epoch: 3 [8192/50176]	Loss: 4.5267
Training Epoch: 3 [9216/50176]	Loss: 4.5127
Training Epoch: 3 [10240/50176]	Loss: 4.5111
Training Epoch: 3 [11264/50176]	Loss: 4.5181
Training Epoch: 3 [12288/50176]	Loss: 4.5275
Training Epoch: 3 [13312/50176]	Loss: 4.5051
Training Epoch: 3 [14336/50176]	Loss: 4.5430
Training Epoch: 3 [15360/50176]	Loss: 4.5179
Training Epoch: 3 [16384/50176]	Loss: 4.5008
Training Epoch: 3 [17408/50176]	Loss: 4.5007
Training Epoch: 3 [18432/50176]	Loss: 4.5071
Training Epoch: 3 [19456/50176]	Loss: 4.4909
Training Epoch: 3 [20480/50176]	Loss: 4.4857
Training Epoch: 3 [21504/50176]	Loss: 4.4944
Training Epoch: 3 [22528/50176]	Loss: 4.5224
Training Epoch: 3 [23552/50176]	Loss: 4.4823
Training Epoch: 3 [24576/50176]	Loss: 4.4610
Training Epoch: 3 [25600/50176]	Loss: 4.4714
Training Epoch: 3 [26624/50176]	Loss: 4.4762
Training Epoch: 3 [27648/50176]	Loss: 4.4962
Training Epoch: 3 [28672/50176]	Loss: 4.4876
Training Epoch: 3 [29696/50176]	Loss: 4.4937
Training Epoch: 3 [30720/50176]	Loss: 4.4834
Training Epoch: 3 [31744/50176]	Loss: 4.4987
Training Epoch: 3 [32768/50176]	Loss: 4.4708
Training Epoch: 3 [33792/50176]	Loss: 4.4667
Training Epoch: 3 [34816/50176]	Loss: 4.4746
Training Epoch: 3 [35840/50176]	Loss: 4.4729
Training Epoch: 3 [36864/50176]	Loss: 4.4979
Training Epoch: 3 [37888/50176]	Loss: 4.4790
Training Epoch: 3 [38912/50176]	Loss: 4.4548
Training Epoch: 3 [39936/50176]	Loss: 4.4672
Training Epoch: 3 [40960/50176]	Loss: 4.4553
Training Epoch: 3 [41984/50176]	Loss: 4.4356
Training Epoch: 3 [43008/50176]	Loss: 4.4459
Training Epoch: 3 [44032/50176]	Loss: 4.4417
Training Epoch: 3 [45056/50176]	Loss: 4.4565
Training Epoch: 3 [46080/50176]	Loss: 4.4689
Training Epoch: 3 [47104/50176]	Loss: 4.4303
Training Epoch: 3 [48128/50176]	Loss: 4.4885
Training Epoch: 3 [49152/50176]	Loss: 4.4463
Training Epoch: 3 [50176/50176]	Loss: 4.4546
2022-12-06 18:14:48.406 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.0500000.power.json: {"job_id": "rec02+try01", "train_power": {"175000": 144.47546303251323, "150000": 143.5043538909716, "125000": 122.98543544465625, "100000": 96.15303472348029}, "train_throughput": {"175000": 1.1271092756166952, "150000": 1.1318246084833394, "125000": 1.049840007140111, "100000": 0.5319577495376839}, "eval_power": {"175000": 125.11089176100826, "150000": 124.69307695790027, "125000": 113.06620903588392}, "eval_throughput": {"175000": 2.7278581345566275, "150000": 2.624264534414073, "125000": 2.5546916558312223}, "optimal_pl": 150000}
2022-12-06 13:14:48,428 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.81 energy=475.15
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Up to epoch 4: time=240.16, energy=28559.22, cost=35293.52
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:14:48,428 [ZeusDataLoader(train)] Expected next epoch: time=287.26, energy=35247.09, cost=42759.02
2022-12-06 13:14:48,429 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0045, Accuracy: 0.0119
2022-12-06 13:14:48,661 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:14:48,661 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:14:48.675 [ZeusMonitor] Monitor started.
2022-12-06 18:14:48.675 [ZeusMonitor] Running indefinitely. 2022-12-06 18:14:48.676 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:14:48.676 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 13:15:32,991 [ZeusDataLoader(train)] train epoch 5 done: time=44.55 energy=6209.66
2022-12-06 13:15:32,994 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 4.4229
Training Epoch: 4 [2048/50176]	Loss: 4.4662
Training Epoch: 4 [3072/50176]	Loss: 4.4378
Training Epoch: 4 [4096/50176]	Loss: 4.4631
Training Epoch: 4 [5120/50176]	Loss: 4.4164
Training Epoch: 4 [6144/50176]	Loss: 4.4094
Training Epoch: 4 [7168/50176]	Loss: 4.4154
Training Epoch: 4 [8192/50176]	Loss: 4.3952
Training Epoch: 4 [9216/50176]	Loss: 4.4234
Training Epoch: 4 [10240/50176]	Loss: 4.4119
Training Epoch: 4 [11264/50176]	Loss: 4.4238
Training Epoch: 4 [12288/50176]	Loss: 4.4240
Training Epoch: 4 [13312/50176]	Loss: 4.4064
Training Epoch: 4 [14336/50176]	Loss: 4.4450
Training Epoch: 4 [15360/50176]	Loss: 4.4185
Training Epoch: 4 [16384/50176]	Loss: 4.3778
Training Epoch: 4 [17408/50176]	Loss: 4.4190
Training Epoch: 4 [18432/50176]	Loss: 4.4299
Training Epoch: 4 [19456/50176]	Loss: 4.4157
Training Epoch: 4 [20480/50176]	Loss: 4.4335
Training Epoch: 4 [21504/50176]	Loss: 4.4315
Training Epoch: 4 [22528/50176]	Loss: 4.3946
Training Epoch: 4 [23552/50176]	Loss: 4.4123
Training Epoch: 4 [24576/50176]	Loss: 4.4416
Training Epoch: 4 [25600/50176]	Loss: 4.4351
Training Epoch: 4 [26624/50176]	Loss: 4.3964
Training Epoch: 4 [27648/50176]	Loss: 4.3849
Training Epoch: 4 [28672/50176]	Loss: 4.3928
Training Epoch: 4 [29696/50176]	Loss: 4.4009
Training Epoch: 4 [30720/50176]	Loss: 4.3545
Training Epoch: 4 [31744/50176]	Loss: 4.4025
Training Epoch: 4 [32768/50176]	Loss: 4.3859
Training Epoch: 4 [33792/50176]	Loss: 4.3677
Training Epoch: 4 [34816/50176]	Loss: 4.3899
Training Epoch: 4 [35840/50176]	Loss: 4.3831
Training Epoch: 4 [36864/50176]	Loss: 4.3746
Training Epoch: 4 [37888/50176]	Loss: 4.4176
Training Epoch: 4 [38912/50176]	Loss: 4.3668
Training Epoch: 4 [39936/50176]	Loss: 4.3535
Training Epoch: 4 [40960/50176]	Loss: 4.3762
Training Epoch: 4 [41984/50176]	Loss: 4.3694
Training Epoch: 4 [43008/50176]	Loss: 4.3847
Training Epoch: 4 [44032/50176]	Loss: 4.3879
Training Epoch: 4 [45056/50176]	Loss: 4.3841
Training Epoch: 4 [46080/50176]	Loss: 4.3782
Training Epoch: 4 [47104/50176]	Loss: 4.3140
Training Epoch: 4 [48128/50176]	Loss: 4.4134
Training Epoch: 4 [49152/50176]	Loss: 4.3367
Training Epoch: 4 [50176/50176]	Loss: 4.4112
2022-12-06 18:15:36.685 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:15:36,704 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.70 energy=468.99
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Up to epoch 5: time=288.41, energy=35237.86, cost=42855.24
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:15:36,705 [ZeusDataLoader(train)] Expected next epoch: time=335.52, energy=41925.74, cost=50320.74
2022-12-06 13:15:36,706 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0067, Accuracy: 0.0097
2022-12-06 13:15:36,934 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:15:36,935 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:15:36.954 [ZeusMonitor] Monitor started.
2022-12-06 18:15:36.954 [ZeusMonitor] Running indefinitely. 2022-12-06 18:15:36.954 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:15:36.954 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 13:16:21,194 [ZeusDataLoader(train)] train epoch 6 done: time=44.48 energy=6230.11
2022-12-06 13:16:21,197 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 4.3370
Training Epoch: 5 [2048/50176]	Loss: 4.3157
Training Epoch: 5 [3072/50176]	Loss: 4.3595
Training Epoch: 5 [4096/50176]	Loss: 4.3270
Training Epoch: 5 [5120/50176]	Loss: 4.3454
Training Epoch: 5 [6144/50176]	Loss: 4.3504
Training Epoch: 5 [7168/50176]	Loss: 4.3281
Training Epoch: 5 [8192/50176]	Loss: 4.3893
Training Epoch: 5 [9216/50176]	Loss: 4.3115
Training Epoch: 5 [10240/50176]	Loss: 4.3266
Training Epoch: 5 [11264/50176]	Loss: 4.3679
Training Epoch: 5 [12288/50176]	Loss: 4.3363
Training Epoch: 5 [13312/50176]	Loss: 4.3148
Training Epoch: 5 [14336/50176]	Loss: 4.3266
Training Epoch: 5 [15360/50176]	Loss: 4.3565
Training Epoch: 5 [16384/50176]	Loss: 4.3289
Training Epoch: 5 [17408/50176]	Loss: 4.3262
Training Epoch: 5 [18432/50176]	Loss: 4.3125
Training Epoch: 5 [19456/50176]	Loss: 4.3170
Training Epoch: 5 [20480/50176]	Loss: 4.2769
Training Epoch: 5 [21504/50176]	Loss: 4.2990
Training Epoch: 5 [22528/50176]	Loss: 4.3206
Training Epoch: 5 [23552/50176]	Loss: 4.3144
Training Epoch: 5 [24576/50176]	Loss: 4.3416
Training Epoch: 5 [25600/50176]	Loss: 4.2955
Training Epoch: 5 [26624/50176]	Loss: 4.2424
Training Epoch: 5 [27648/50176]	Loss: 4.2752
Training Epoch: 5 [28672/50176]	Loss: 4.2813
Training Epoch: 5 [29696/50176]	Loss: 4.2197
Training Epoch: 5 [30720/50176]	Loss: 4.2815
Training Epoch: 5 [31744/50176]	Loss: 4.2436
Training Epoch: 5 [32768/50176]	Loss: 4.2440
Training Epoch: 5 [33792/50176]	Loss: 4.1622
Training Epoch: 5 [34816/50176]	Loss: 4.2305
Training Epoch: 5 [35840/50176]	Loss: 4.2679
Training Epoch: 5 [36864/50176]	Loss: 4.1736
Training Epoch: 5 [37888/50176]	Loss: 4.2347
Training Epoch: 5 [38912/50176]	Loss: 4.1671
Training Epoch: 5 [39936/50176]	Loss: 4.1923
Training Epoch: 5 [40960/50176]	Loss: 4.2256
Training Epoch: 5 [41984/50176]	Loss: 4.1425
Training Epoch: 5 [43008/50176]	Loss: 4.1303
Training Epoch: 5 [44032/50176]	Loss: 4.1599
Training Epoch: 5 [45056/50176]	Loss: 4.2343
Training Epoch: 5 [46080/50176]	Loss: 4.1238
Training Epoch: 5 [47104/50176]	Loss: 4.1221
Training Epoch: 5 [48128/50176]	Loss: 4.1537
Training Epoch: 5 [49152/50176]	Loss: 4.1559
Training Epoch: 5 [50176/50176]	Loss: 4.1374
2022-12-06 18:16:24.948 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:16:24,995 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.79 energy=471.46
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Up to epoch 6: time=336.69, energy=41939.44, cost=50429.70
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:16:24,995 [ZeusDataLoader(train)] Expected next epoch: time=383.79, energy=48627.32, cost=57895.20
2022-12-06 13:16:24,996 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0086, Accuracy: 0.0100
2022-12-06 13:16:25,238 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:16:25,239 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:16:25.249 [ZeusMonitor] Monitor started.
2022-12-06 18:16:25.249 [ZeusMonitor] Running indefinitely. 2022-12-06 18:16:25.249 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:16:25.249 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 13:17:09,348 [ZeusDataLoader(train)] train epoch 7 done: time=44.34 energy=6238.97
2022-12-06 13:17:09,352 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 4.0880
Training Epoch: 6 [2048/50176]	Loss: 4.1424
Training Epoch: 6 [3072/50176]	Loss: 4.1310
Training Epoch: 6 [4096/50176]	Loss: 4.0792
Training Epoch: 6 [5120/50176]	Loss: 4.0517
Training Epoch: 6 [6144/50176]	Loss: 4.0352
Training Epoch: 6 [7168/50176]	Loss: 4.0580
Training Epoch: 6 [8192/50176]	Loss: 4.0583
Training Epoch: 6 [9216/50176]	Loss: 4.1307
Training Epoch: 6 [10240/50176]	Loss: 3.9948
Training Epoch: 6 [11264/50176]	Loss: 4.0655
Training Epoch: 6 [12288/50176]	Loss: 4.0000
Training Epoch: 6 [13312/50176]	Loss: 4.0349
Training Epoch: 6 [14336/50176]	Loss: 3.9934
Training Epoch: 6 [15360/50176]	Loss: 3.9712
Training Epoch: 6 [16384/50176]	Loss: 3.9803
Training Epoch: 6 [17408/50176]	Loss: 3.9739
Training Epoch: 6 [18432/50176]	Loss: 4.0286
Training Epoch: 6 [19456/50176]	Loss: 3.9929
Training Epoch: 6 [20480/50176]	Loss: 3.9561
Training Epoch: 6 [21504/50176]	Loss: 3.9791
Training Epoch: 6 [22528/50176]	Loss: 3.9464
Training Epoch: 6 [23552/50176]	Loss: 3.9529
Training Epoch: 6 [24576/50176]	Loss: 3.9266
Training Epoch: 6 [25600/50176]	Loss: 3.9697
Training Epoch: 6 [26624/50176]	Loss: 3.8853
Training Epoch: 6 [27648/50176]	Loss: 3.9416
Training Epoch: 6 [28672/50176]	Loss: 3.9314
Training Epoch: 6 [29696/50176]	Loss: 3.9620
Training Epoch: 6 [30720/50176]	Loss: 3.9156
Training Epoch: 6 [31744/50176]	Loss: 3.9200
Training Epoch: 6 [32768/50176]	Loss: 3.9253
Training Epoch: 6 [33792/50176]	Loss: 3.9275
Training Epoch: 6 [34816/50176]	Loss: 3.8720
Training Epoch: 6 [35840/50176]	Loss: 3.8569
Training Epoch: 6 [36864/50176]	Loss: 3.9067
Training Epoch: 6 [37888/50176]	Loss: 3.9438
Training Epoch: 6 [38912/50176]	Loss: 3.8670
Training Epoch: 6 [39936/50176]	Loss: 3.8932
Training Epoch: 6 [40960/50176]	Loss: 3.9111
Training Epoch: 6 [41984/50176]	Loss: 3.8301
Training Epoch: 6 [43008/50176]	Loss: 3.8448
Training Epoch: 6 [44032/50176]	Loss: 3.8966
Training Epoch: 6 [45056/50176]	Loss: 3.8798
Training Epoch: 6 [46080/50176]	Loss: 3.9060
Training Epoch: 6 [47104/50176]	Loss: 3.8501
Training Epoch: 6 [48128/50176]	Loss: 3.9035
Training Epoch: 6 [49152/50176]	Loss: 3.8522
Training Epoch: 6 [50176/50176]	Loss: 3.9127
2022-12-06 18:17:13.079 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:17:13,109 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.75 energy=467.30
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Up to epoch 7: time=384.78, energy=48645.71, cost=57990.99
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:17:13,109 [ZeusDataLoader(train)] Expected next epoch: time=431.88, energy=55333.59, cost=65456.49
2022-12-06 13:17:13,110 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0064, Accuracy: 0.0113
2022-12-06 13:17:13,304 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:17:13,305 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:17:13.308 [ZeusMonitor] Monitor started.
2022-12-06 18:17:13.309 [ZeusMonitor] Running indefinitely. 2022-12-06 18:17:13.309 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:17:13.309 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 13:17:57,371 [ZeusDataLoader(train)] train epoch 8 done: time=44.25 energy=6237.64
2022-12-06 13:17:57,375 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 3.8855
Training Epoch: 7 [2048/50176]	Loss: 3.8235
Training Epoch: 7 [3072/50176]	Loss: 3.8387
Training Epoch: 7 [4096/50176]	Loss: 3.8410
Training Epoch: 7 [5120/50176]	Loss: 3.8947
Training Epoch: 7 [6144/50176]	Loss: 3.8582
Training Epoch: 7 [7168/50176]	Loss: 3.7953
Training Epoch: 7 [8192/50176]	Loss: 3.7653
Training Epoch: 7 [9216/50176]	Loss: 3.6925
Training Epoch: 7 [10240/50176]	Loss: 3.7546
Training Epoch: 7 [11264/50176]	Loss: 3.8355
Training Epoch: 7 [12288/50176]	Loss: 3.7706
Training Epoch: 7 [13312/50176]	Loss: 3.7605
Training Epoch: 7 [14336/50176]	Loss: 3.8976
Training Epoch: 7 [15360/50176]	Loss: 3.8300
Training Epoch: 7 [16384/50176]	Loss: 3.7373
Training Epoch: 7 [17408/50176]	Loss: 3.7767
Training Epoch: 7 [18432/50176]	Loss: 3.8173
Training Epoch: 7 [19456/50176]	Loss: 3.8062
Training Epoch: 7 [20480/50176]	Loss: 3.8705
Training Epoch: 7 [21504/50176]	Loss: 3.8364
Training Epoch: 7 [22528/50176]	Loss: 3.8139
Training Epoch: 7 [23552/50176]	Loss: 3.7825
Training Epoch: 7 [24576/50176]	Loss: 3.7669
Training Epoch: 7 [25600/50176]	Loss: 3.7650
Training Epoch: 7 [26624/50176]	Loss: 3.7658
Training Epoch: 7 [27648/50176]	Loss: 3.8293
Training Epoch: 7 [28672/50176]	Loss: 3.7539
Training Epoch: 7 [29696/50176]	Loss: 3.7887
Training Epoch: 7 [30720/50176]	Loss: 3.7808
Training Epoch: 7 [31744/50176]	Loss: 3.7593
Training Epoch: 7 [32768/50176]	Loss: 3.7661
Training Epoch: 7 [33792/50176]	Loss: 3.8046
Training Epoch: 7 [34816/50176]	Loss: 3.7591
Training Epoch: 7 [35840/50176]	Loss: 3.7485
Training Epoch: 7 [36864/50176]	Loss: 3.7033
Training Epoch: 7 [37888/50176]	Loss: 3.6414
Training Epoch: 7 [38912/50176]	Loss: 3.7461
Training Epoch: 7 [39936/50176]	Loss: 3.7453
Training Epoch: 7 [40960/50176]	Loss: 3.7668
Training Epoch: 7 [41984/50176]	Loss: 3.7261
Training Epoch: 7 [43008/50176]	Loss: 3.7299
Training Epoch: 7 [44032/50176]	Loss: 3.5818
Training Epoch: 7 [45056/50176]	Loss: 3.6804
Training Epoch: 7 [46080/50176]	Loss: 3.7020
Training Epoch: 7 [47104/50176]	Loss: 3.6912
Training Epoch: 7 [48128/50176]	Loss: 3.6691
Training Epoch: 7 [49152/50176]	Loss: 3.7449
Training Epoch: 7 [50176/50176]	Loss: 3.7415
2022-12-06 18:18:01.141 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:18:01,184 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.80 energy=482.82
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Up to epoch 8: time=432.83, energy=55366.17, cost=65555.93
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:18:01,185 [ZeusDataLoader(train)] Expected next epoch: time=479.94, energy=62054.05, cost=73021.43
2022-12-06 13:18:01,186 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0287, Accuracy: 0.0098
2022-12-06 13:18:01,435 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:18:01,436 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:18:01.437 [ZeusMonitor] Monitor started.
2022-12-06 18:18:01.438 [ZeusMonitor] Running indefinitely. 2022-12-06 18:18:01.438 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:18:01.438 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 13:18:45,383 [ZeusDataLoader(train)] train epoch 9 done: time=44.19 energy=6215.68
2022-12-06 13:18:45,386 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 3.7167
Training Epoch: 8 [2048/50176]	Loss: 3.7783
Training Epoch: 8 [3072/50176]	Loss: 3.6691
Training Epoch: 8 [4096/50176]	Loss: 3.6184
Training Epoch: 8 [5120/50176]	Loss: 3.5526
Training Epoch: 8 [6144/50176]	Loss: 3.6874
Training Epoch: 8 [7168/50176]	Loss: 3.6088
Training Epoch: 8 [8192/50176]	Loss: 3.6665
Training Epoch: 8 [9216/50176]	Loss: 3.6195
Training Epoch: 8 [10240/50176]	Loss: 3.6425
Training Epoch: 8 [11264/50176]	Loss: 3.6232
Training Epoch: 8 [12288/50176]	Loss: 3.6110
Training Epoch: 8 [13312/50176]	Loss: 3.6462
Training Epoch: 8 [14336/50176]	Loss: 3.6471
Training Epoch: 8 [15360/50176]	Loss: 3.6155
Training Epoch: 8 [16384/50176]	Loss: 3.5903
Training Epoch: 8 [17408/50176]	Loss: 3.6779
Training Epoch: 8 [18432/50176]	Loss: 3.5571
Training Epoch: 8 [19456/50176]	Loss: 3.6141
Training Epoch: 8 [20480/50176]	Loss: 3.5472
Training Epoch: 8 [21504/50176]	Loss: 3.5880
Training Epoch: 8 [22528/50176]	Loss: 3.5784
Training Epoch: 8 [23552/50176]	Loss: 3.5864
Training Epoch: 8 [24576/50176]	Loss: 3.6889
Training Epoch: 8 [25600/50176]	Loss: 3.6071
Training Epoch: 8 [26624/50176]	Loss: 3.6306
Training Epoch: 8 [27648/50176]	Loss: 3.6268
Training Epoch: 8 [28672/50176]	Loss: 3.6085
Training Epoch: 8 [29696/50176]	Loss: 3.5546
Training Epoch: 8 [30720/50176]	Loss: 3.6113
Training Epoch: 8 [31744/50176]	Loss: 3.5428
Training Epoch: 8 [32768/50176]	Loss: 3.5420
Training Epoch: 8 [33792/50176]	Loss: 3.6460
Training Epoch: 8 [34816/50176]	Loss: 3.6094
Training Epoch: 8 [35840/50176]	Loss: 3.5463
Training Epoch: 8 [36864/50176]	Loss: 3.5694
Training Epoch: 8 [37888/50176]	Loss: 3.5850
Training Epoch: 8 [38912/50176]	Loss: 3.6629
Training Epoch: 8 [39936/50176]	Loss: 3.5807
Training Epoch: 8 [40960/50176]	Loss: 3.5355
Training Epoch: 8 [41984/50176]	Loss: 3.5152
Training Epoch: 8 [43008/50176]	Loss: 3.5730
Training Epoch: 8 [44032/50176]	Loss: 3.6281
Training Epoch: 8 [45056/50176]	Loss: 3.6646
Training Epoch: 8 [46080/50176]	Loss: 3.5877
Training Epoch: 8 [47104/50176]	Loss: 3.6010
Training Epoch: 8 [48128/50176]	Loss: 3.5382
Training Epoch: 8 [49152/50176]	Loss: 3.5998
Training Epoch: 8 [50176/50176]	Loss: 3.5700
2022-12-06 18:18:49.157 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:18:49,183 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.79 energy=480.29
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Up to epoch 9: time=480.81, energy=62062.14, cost=73102.04
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:18:49,184 [ZeusDataLoader(train)] Expected next epoch: time=527.91, energy=68750.02, cost=80567.53
2022-12-06 13:18:49,185 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0343, Accuracy: 0.0098
2022-12-06 13:18:49,422 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:18:49,423 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:18:49.424 [ZeusMonitor] Monitor started.
2022-12-06 18:18:49.424 [ZeusMonitor] Running indefinitely. 2022-12-06 18:18:49.424 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:18:49.424 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 13:19:33,687 [ZeusDataLoader(train)] train epoch 10 done: time=44.49 energy=6251.34
2022-12-06 13:19:33,690 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 3.5387
Training Epoch: 9 [2048/50176]	Loss: 3.5426
Training Epoch: 9 [3072/50176]	Loss: 3.5561
Training Epoch: 9 [4096/50176]	Loss: 3.5277
Training Epoch: 9 [5120/50176]	Loss: 3.4988
Training Epoch: 9 [6144/50176]	Loss: 3.5494
Training Epoch: 9 [7168/50176]	Loss: 3.5059
Training Epoch: 9 [8192/50176]	Loss: 3.5016
Training Epoch: 9 [9216/50176]	Loss: 3.4900
Training Epoch: 9 [10240/50176]	Loss: 3.5081
Training Epoch: 9 [11264/50176]	Loss: 3.4330
Training Epoch: 9 [12288/50176]	Loss: 3.4938
Training Epoch: 9 [13312/50176]	Loss: 3.5016
Training Epoch: 9 [14336/50176]	Loss: 3.5695
Training Epoch: 9 [15360/50176]	Loss: 3.5051
Training Epoch: 9 [16384/50176]	Loss: 3.5803
Training Epoch: 9 [17408/50176]	Loss: 3.5431
Training Epoch: 9 [18432/50176]	Loss: 3.4820
Training Epoch: 9 [19456/50176]	Loss: 3.5264
Training Epoch: 9 [20480/50176]	Loss: 3.4985
Training Epoch: 9 [21504/50176]	Loss: 3.4523
Training Epoch: 9 [22528/50176]	Loss: 3.4102
Training Epoch: 9 [23552/50176]	Loss: 3.3959
Training Epoch: 9 [24576/50176]	Loss: 3.4845
Training Epoch: 9 [25600/50176]	Loss: 3.4519
Training Epoch: 9 [26624/50176]	Loss: 3.4942
Training Epoch: 9 [27648/50176]	Loss: 3.4687
Training Epoch: 9 [28672/50176]	Loss: 3.4334
Training Epoch: 9 [29696/50176]	Loss: 3.4277
Training Epoch: 9 [30720/50176]	Loss: 3.4305
Training Epoch: 9 [31744/50176]	Loss: 3.4394
Training Epoch: 9 [32768/50176]	Loss: 3.4515
Training Epoch: 9 [33792/50176]	Loss: 3.4105
Training Epoch: 9 [34816/50176]	Loss: 3.4503
Training Epoch: 9 [35840/50176]	Loss: 3.4052
Training Epoch: 9 [36864/50176]	Loss: 3.4449
Training Epoch: 9 [37888/50176]	Loss: 3.4778
Training Epoch: 9 [38912/50176]	Loss: 3.5320
Training Epoch: 9 [39936/50176]	Loss: 3.4574
Training Epoch: 9 [40960/50176]	Loss: 3.5192
Training Epoch: 9 [41984/50176]	Loss: 3.4055
Training Epoch: 9 [43008/50176]	Loss: 3.4545
Training Epoch: 9 [44032/50176]	Loss: 3.3940
Training Epoch: 9 [45056/50176]	Loss: 3.3888
Training Epoch: 9 [46080/50176]	Loss: 3.4582
Training Epoch: 9 [47104/50176]	Loss: 3.4595
Training Epoch: 9 [48128/50176]	Loss: 3.4585
Training Epoch: 9 [49152/50176]	Loss: 3.3712
Training Epoch: 9 [50176/50176]	Loss: 3.3367
2022-12-06 18:19:37.560 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:19:37,610 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.91 energy=493.28
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Up to epoch 10: time=529.22, energy=68806.77, cost=80709.85
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:19:37,610 [ZeusDataLoader(train)] Expected next epoch: time=576.32, energy=75494.64, cost=88175.35
2022-12-06 13:19:37,611 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0673, Accuracy: 0.0098
2022-12-06 13:19:37,853 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:19:37,854 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:19:37.856 [ZeusMonitor] Monitor started.
2022-12-06 18:19:37.856 [ZeusMonitor] Running indefinitely. 2022-12-06 18:19:37.856 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:19:37.856 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 13:20:22,039 [ZeusDataLoader(train)] train epoch 11 done: time=44.42 energy=6236.57
2022-12-06 13:20:22,043 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 3.4147
Training Epoch: 10 [2048/50176]	Loss: 3.3581
Training Epoch: 10 [3072/50176]	Loss: 3.3155
Training Epoch: 10 [4096/50176]	Loss: 3.3547
Training Epoch: 10 [5120/50176]	Loss: 3.4108
Training Epoch: 10 [6144/50176]	Loss: 3.3885
Training Epoch: 10 [7168/50176]	Loss: 3.3562
Training Epoch: 10 [8192/50176]	Loss: 3.3064
Training Epoch: 10 [9216/50176]	Loss: 3.2513
Training Epoch: 10 [10240/50176]	Loss: 3.2666
Training Epoch: 10 [11264/50176]	Loss: 3.3299
Training Epoch: 10 [12288/50176]	Loss: 3.3535
Training Epoch: 10 [13312/50176]	Loss: 3.4319
Training Epoch: 10 [14336/50176]	Loss: 3.3888
Training Epoch: 10 [15360/50176]	Loss: 3.3118
Training Epoch: 10 [16384/50176]	Loss: 3.4316
Training Epoch: 10 [17408/50176]	Loss: 3.3718
Training Epoch: 10 [18432/50176]	Loss: 3.2991
Training Epoch: 10 [19456/50176]	Loss: 3.3329
Training Epoch: 10 [20480/50176]	Loss: 3.3772
Training Epoch: 10 [21504/50176]	Loss: 3.3842
Training Epoch: 10 [22528/50176]	Loss: 3.3035
Training Epoch: 10 [23552/50176]	Loss: 3.2838
Training Epoch: 10 [24576/50176]	Loss: 3.2922
Training Epoch: 10 [25600/50176]	Loss: 3.3224
Training Epoch: 10 [26624/50176]	Loss: 3.3035
Training Epoch: 10 [27648/50176]	Loss: 3.2957
Training Epoch: 10 [28672/50176]	Loss: 3.2821
Training Epoch: 10 [29696/50176]	Loss: 3.3836
Training Epoch: 10 [30720/50176]	Loss: 3.3171
Training Epoch: 10 [31744/50176]	Loss: 3.4298
Training Epoch: 10 [32768/50176]	Loss: 3.3268
Training Epoch: 10 [33792/50176]	Loss: 3.3105
Training Epoch: 10 [34816/50176]	Loss: 3.3288
Training Epoch: 10 [35840/50176]	Loss: 3.3712
Training Epoch: 10 [36864/50176]	Loss: 3.3304
Training Epoch: 10 [37888/50176]	Loss: 3.2122
Training Epoch: 10 [38912/50176]	Loss: 3.2793
Training Epoch: 10 [39936/50176]	Loss: 3.3663
Training Epoch: 10 [40960/50176]	Loss: 3.2236
Training Epoch: 10 [41984/50176]	Loss: 3.2492
Training Epoch: 10 [43008/50176]	Loss: 3.3328
Training Epoch: 10 [44032/50176]	Loss: 3.2647
Training Epoch: 10 [45056/50176]	Loss: 3.2895
Training Epoch: 10 [46080/50176]	Loss: 3.1991
Training Epoch: 10 [47104/50176]	Loss: 3.2304
Training Epoch: 10 [48128/50176]	Loss: 3.2926
Training Epoch: 10 [49152/50176]	Loss: 3.2884
Training Epoch: 10 [50176/50176]	Loss: 3.2553
2022-12-06 18:20:25.768 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:20:25,787 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.74 energy=469.83
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Up to epoch 11: time=577.37, energy=75513.17, cost=88276.74
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:20:25,787 [ZeusDataLoader(train)] Expected next epoch: time=624.48, energy=82201.05, cost=95742.23
2022-12-06 13:20:25,788 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.1097, Accuracy: 0.0098
2022-12-06 13:20:26,021 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:20:26,021 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:20:26.023 [ZeusMonitor] Monitor started.
2022-12-06 18:20:26.023 [ZeusMonitor] Running indefinitely. 2022-12-06 18:20:26.023 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:20:26.023 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 13:21:10,195 [ZeusDataLoader(train)] train epoch 12 done: time=44.40 energy=6255.34
2022-12-06 13:21:10,199 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 3.1916
Training Epoch: 11 [2048/50176]	Loss: 3.1975
Training Epoch: 11 [3072/50176]	Loss: 3.1710
Training Epoch: 11 [4096/50176]	Loss: 3.2554
Training Epoch: 11 [5120/50176]	Loss: 3.3353
Training Epoch: 11 [6144/50176]	Loss: 3.1413
Training Epoch: 11 [7168/50176]	Loss: 3.2715
Training Epoch: 11 [8192/50176]	Loss: 3.2078
Training Epoch: 11 [9216/50176]	Loss: 3.2155
Training Epoch: 11 [10240/50176]	Loss: 3.3048
Training Epoch: 11 [11264/50176]	Loss: 3.2656
Training Epoch: 11 [12288/50176]	Loss: 3.1847
Training Epoch: 11 [13312/50176]	Loss: 3.3653
Training Epoch: 11 [14336/50176]	Loss: 3.2306
Training Epoch: 11 [15360/50176]	Loss: 3.2507
Training Epoch: 11 [16384/50176]	Loss: 3.1903
Training Epoch: 11 [17408/50176]	Loss: 3.2020
Training Epoch: 11 [18432/50176]	Loss: 3.1738
Training Epoch: 11 [19456/50176]	Loss: 3.1806
Training Epoch: 11 [20480/50176]	Loss: 3.2296
Training Epoch: 11 [21504/50176]	Loss: 3.1704
Training Epoch: 11 [22528/50176]	Loss: 3.1999
Training Epoch: 11 [23552/50176]	Loss: 3.3470
Training Epoch: 11 [24576/50176]	Loss: 3.1717
Training Epoch: 11 [25600/50176]	Loss: 3.2275
Training Epoch: 11 [26624/50176]	Loss: 3.0844
Training Epoch: 11 [27648/50176]	Loss: 3.2539
Training Epoch: 11 [28672/50176]	Loss: 3.2392
Training Epoch: 11 [29696/50176]	Loss: 3.1402
Training Epoch: 11 [30720/50176]	Loss: 3.1781
Training Epoch: 11 [31744/50176]	Loss: 3.1775
Training Epoch: 11 [32768/50176]	Loss: 3.1969
Training Epoch: 11 [33792/50176]	Loss: 3.1047
Training Epoch: 11 [34816/50176]	Loss: 3.2270
Training Epoch: 11 [35840/50176]	Loss: 3.2368
Training Epoch: 11 [36864/50176]	Loss: 3.2464
Training Epoch: 11 [37888/50176]	Loss: 3.1733
Training Epoch: 11 [38912/50176]	Loss: 3.2188
Training Epoch: 11 [39936/50176]	Loss: 3.1699
Training Epoch: 11 [40960/50176]	Loss: 3.2008
Training Epoch: 11 [41984/50176]	Loss: 3.1797
Training Epoch: 11 [43008/50176]	Loss: 3.2759
Training Epoch: 11 [44032/50176]	Loss: 3.1192
Training Epoch: 11 [45056/50176]	Loss: 3.1691
Training Epoch: 11 [46080/50176]	Loss: 3.0474
Training Epoch: 11 [47104/50176]	Loss: 3.2486
Training Epoch: 11 [48128/50176]	Loss: 3.1426
Training Epoch: 11 [49152/50176]	Loss: 3.1231
Training Epoch: 11 [50176/50176]	Loss: 3.1871
2022-12-06 18:21:13.933 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:21:13,946 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.74 energy=476.57
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Up to epoch 12: time=625.51, energy=82245.08, cost=95854.82
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:21:13,946 [ZeusDataLoader(train)] Expected next epoch: time=672.62, energy=88932.95, cost=103320.32
2022-12-06 13:21:13,947 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.2583, Accuracy: 0.0098
2022-12-06 13:21:14,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:21:14,139 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:21:14.142 [ZeusMonitor] Monitor started.
2022-12-06 18:21:14.142 [ZeusMonitor] Running indefinitely. 2022-12-06 18:21:14.142 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:21:14.142 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 13:21:58,181 [ZeusDataLoader(train)] train epoch 13 done: time=44.23 energy=6242.06
2022-12-06 13:21:58,185 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 3.1198
Training Epoch: 12 [2048/50176]	Loss: 3.1591
Training Epoch: 12 [3072/50176]	Loss: 3.1094
Training Epoch: 12 [4096/50176]	Loss: 3.0812
Training Epoch: 12 [5120/50176]	Loss: 2.9681
Training Epoch: 12 [6144/50176]	Loss: 3.1242
Training Epoch: 12 [7168/50176]	Loss: 3.2051
Training Epoch: 12 [8192/50176]	Loss: 3.0395
Training Epoch: 12 [9216/50176]	Loss: 3.0865
Training Epoch: 12 [10240/50176]	Loss: 3.0607
Training Epoch: 12 [11264/50176]	Loss: 3.2161
Training Epoch: 12 [12288/50176]	Loss: 3.0637
Training Epoch: 12 [13312/50176]	Loss: 3.0796
Training Epoch: 12 [14336/50176]	Loss: 3.1137
Training Epoch: 12 [15360/50176]	Loss: 2.9816
Training Epoch: 12 [16384/50176]	Loss: 3.0772
Training Epoch: 12 [17408/50176]	Loss: 3.0685
Training Epoch: 12 [18432/50176]	Loss: 3.0581
Training Epoch: 12 [19456/50176]	Loss: 3.0609
Training Epoch: 12 [20480/50176]	Loss: 3.1079
Training Epoch: 12 [21504/50176]	Loss: 3.0912
Training Epoch: 12 [22528/50176]	Loss: 3.0825
Training Epoch: 12 [23552/50176]	Loss: 3.0972
Training Epoch: 12 [24576/50176]	Loss: 2.9623
Training Epoch: 12 [25600/50176]	Loss: 3.0964
Training Epoch: 12 [26624/50176]	Loss: 3.0817
Training Epoch: 12 [27648/50176]	Loss: 3.0392
Training Epoch: 12 [28672/50176]	Loss: 3.0751
Training Epoch: 12 [29696/50176]	Loss: 3.0463
Training Epoch: 12 [30720/50176]	Loss: 3.0574
Training Epoch: 12 [31744/50176]	Loss: 3.0251
Training Epoch: 12 [32768/50176]	Loss: 3.1301
Training Epoch: 12 [33792/50176]	Loss: 2.9677
Training Epoch: 12 [34816/50176]	Loss: 3.0336
Training Epoch: 12 [35840/50176]	Loss: 3.0472
Training Epoch: 12 [36864/50176]	Loss: 3.0548
Training Epoch: 12 [37888/50176]	Loss: 3.0693
Training Epoch: 12 [38912/50176]	Loss: 3.0422
Training Epoch: 12 [39936/50176]	Loss: 3.1210
Training Epoch: 12 [40960/50176]	Loss: 3.0249
Training Epoch: 12 [41984/50176]	Loss: 3.0330
Training Epoch: 12 [43008/50176]	Loss: 3.0411
Training Epoch: 12 [44032/50176]	Loss: 3.1491
Training Epoch: 12 [45056/50176]	Loss: 2.9713
Training Epoch: 12 [46080/50176]	Loss: 3.0584
Training Epoch: 12 [47104/50176]	Loss: 2.9745
Training Epoch: 12 [48128/50176]	Loss: 2.9471
Training Epoch: 12 [49152/50176]	Loss: 3.0095
Training Epoch: 12 [50176/50176]	Loss: 2.8990
2022-12-06 18:22:02.034 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:22:02,082 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.89 energy=490.96
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Up to epoch 13: time=673.63, energy=88978.09, cost=103431.39
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:22:02,082 [ZeusDataLoader(train)] Expected next epoch: time=720.73, energy=95665.97, cost=110896.89
2022-12-06 13:22:02,083 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0317, Accuracy: 0.0098
2022-12-06 13:22:02,317 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:22:02,318 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:22:02.328 [ZeusMonitor] Monitor started.
2022-12-06 18:22:02.328 [ZeusMonitor] Running indefinitely. 2022-12-06 18:22:02.328 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:22:02.328 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 13:22:46,710 [ZeusDataLoader(train)] train epoch 14 done: time=44.62 energy=6258.68
2022-12-06 13:22:46,714 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 2.9363
Training Epoch: 13 [2048/50176]	Loss: 2.9913
Training Epoch: 13 [3072/50176]	Loss: 2.9883
Training Epoch: 13 [4096/50176]	Loss: 3.0130
Training Epoch: 13 [5120/50176]	Loss: 2.9494
Training Epoch: 13 [6144/50176]	Loss: 2.9849
Training Epoch: 13 [7168/50176]	Loss: 2.9215
Training Epoch: 13 [8192/50176]	Loss: 2.9268
Training Epoch: 13 [9216/50176]	Loss: 2.9655
Training Epoch: 13 [10240/50176]	Loss: 3.0053
Training Epoch: 13 [11264/50176]	Loss: 3.0377
Training Epoch: 13 [12288/50176]	Loss: 2.9488
Training Epoch: 13 [13312/50176]	Loss: 2.9559
Training Epoch: 13 [14336/50176]	Loss: 3.0061
Training Epoch: 13 [15360/50176]	Loss: 2.9723
Training Epoch: 13 [16384/50176]	Loss: 2.9908
Training Epoch: 13 [17408/50176]	Loss: 2.9419
Training Epoch: 13 [18432/50176]	Loss: 2.9467
Training Epoch: 13 [19456/50176]	Loss: 2.9668
Training Epoch: 13 [20480/50176]	Loss: 2.8884
Training Epoch: 13 [21504/50176]	Loss: 3.0027
Training Epoch: 13 [22528/50176]	Loss: 3.0014
Training Epoch: 13 [23552/50176]	Loss: 2.9560
Training Epoch: 13 [24576/50176]	Loss: 2.9070
Training Epoch: 13 [25600/50176]	Loss: 2.9361
Training Epoch: 13 [26624/50176]	Loss: 2.9838
Training Epoch: 13 [27648/50176]	Loss: 2.9429
Training Epoch: 13 [28672/50176]	Loss: 2.9144
Training Epoch: 13 [29696/50176]	Loss: 2.9616
Training Epoch: 13 [30720/50176]	Loss: 2.9551
Training Epoch: 13 [31744/50176]	Loss: 3.0396
Training Epoch: 13 [32768/50176]	Loss: 2.9275
Training Epoch: 13 [33792/50176]	Loss: 2.9917
Training Epoch: 13 [34816/50176]	Loss: 2.9746
Training Epoch: 13 [35840/50176]	Loss: 3.0766
Training Epoch: 13 [36864/50176]	Loss: 3.0009
Training Epoch: 13 [37888/50176]	Loss: 2.9609
Training Epoch: 13 [38912/50176]	Loss: 2.8715
Training Epoch: 13 [39936/50176]	Loss: 2.8311
Training Epoch: 13 [40960/50176]	Loss: 2.8936
Training Epoch: 13 [41984/50176]	Loss: 2.9481
Training Epoch: 13 [43008/50176]	Loss: 2.8452
Training Epoch: 13 [44032/50176]	Loss: 2.9148
Training Epoch: 13 [45056/50176]	Loss: 2.9685
Training Epoch: 13 [46080/50176]	Loss: 2.8854
Training Epoch: 13 [47104/50176]	Loss: 2.9209
Training Epoch: 13 [48128/50176]	Loss: 2.8874
Training Epoch: 13 [49152/50176]	Loss: 2.8172
Training Epoch: 13 [50176/50176]	Loss: 2.8691
2022-12-06 18:22:50.458 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:22:50,511 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.79 energy=471.97
2022-12-06 13:22:50,511 [ZeusDataLoader(train)] Up to epoch 14: time=722.04, energy=95708.74, cost=111032.47
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Expected next epoch: time=769.14, energy=102396.62, cost=118497.97
2022-12-06 13:22:50,512 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0679, Accuracy: 0.0098
2022-12-06 13:22:50,755 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:22:50,756 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:22:50.758 [ZeusMonitor] Monitor started.
2022-12-06 18:22:50.758 [ZeusMonitor] Running indefinitely. 2022-12-06 18:22:50.758 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:22:50.758 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 13:23:34,605 [ZeusDataLoader(train)] train epoch 15 done: time=44.08 energy=6220.13
2022-12-06 13:23:34,608 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 2.8693
Training Epoch: 14 [2048/50176]	Loss: 2.9065
Training Epoch: 14 [3072/50176]	Loss: 2.9251
Training Epoch: 14 [4096/50176]	Loss: 2.9835
Training Epoch: 14 [5120/50176]	Loss: 2.8382
Training Epoch: 14 [6144/50176]	Loss: 2.8396
Training Epoch: 14 [7168/50176]	Loss: 2.7924
Training Epoch: 14 [8192/50176]	Loss: 2.9131
Training Epoch: 14 [9216/50176]	Loss: 2.8666
Training Epoch: 14 [10240/50176]	Loss: 2.8282
Training Epoch: 14 [11264/50176]	Loss: 2.8434
Training Epoch: 14 [12288/50176]	Loss: 2.9130
Training Epoch: 14 [13312/50176]	Loss: 2.8170
Training Epoch: 14 [14336/50176]	Loss: 2.8367
Training Epoch: 14 [15360/50176]	Loss: 2.8085
Training Epoch: 14 [16384/50176]	Loss: 2.7618
Training Epoch: 14 [17408/50176]	Loss: 2.8155
Training Epoch: 14 [18432/50176]	Loss: 2.8510
Training Epoch: 14 [19456/50176]	Loss: 2.7615
Training Epoch: 14 [20480/50176]	Loss: 2.8778
Training Epoch: 14 [21504/50176]	Loss: 2.8236
Training Epoch: 14 [22528/50176]	Loss: 2.8409
Training Epoch: 14 [23552/50176]	Loss: 2.8305
Training Epoch: 14 [24576/50176]	Loss: 2.7840
Training Epoch: 14 [25600/50176]	Loss: 2.8725
Training Epoch: 14 [26624/50176]	Loss: 2.7904
Training Epoch: 14 [27648/50176]	Loss: 2.7450
Training Epoch: 14 [28672/50176]	Loss: 2.7953
Training Epoch: 14 [29696/50176]	Loss: 2.8503
Training Epoch: 14 [30720/50176]	Loss: 2.8700
Training Epoch: 14 [31744/50176]	Loss: 2.8180
Training Epoch: 14 [32768/50176]	Loss: 2.8769
Training Epoch: 14 [33792/50176]	Loss: 2.8771
Training Epoch: 14 [34816/50176]	Loss: 2.9095
Training Epoch: 14 [35840/50176]	Loss: 2.9009
Training Epoch: 14 [36864/50176]	Loss: 2.9538
Training Epoch: 14 [37888/50176]	Loss: 2.7268
Training Epoch: 14 [38912/50176]	Loss: 2.8197
Training Epoch: 14 [39936/50176]	Loss: 2.7596
Training Epoch: 14 [40960/50176]	Loss: 2.8158
Training Epoch: 14 [41984/50176]	Loss: 2.9200
Training Epoch: 14 [43008/50176]	Loss: 2.7906
Training Epoch: 14 [44032/50176]	Loss: 2.7744
Training Epoch: 14 [45056/50176]	Loss: 2.7915
Training Epoch: 14 [46080/50176]	Loss: 2.8891
Training Epoch: 14 [47104/50176]	Loss: 2.7466
Training Epoch: 14 [48128/50176]	Loss: 2.8169
Training Epoch: 14 [49152/50176]	Loss: 2.8233
Training Epoch: 14 [50176/50176]	Loss: 2.8078
2022-12-06 18:23:38.370 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:23:38,421 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.81 energy=487.70
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Up to epoch 15: time=769.93, energy=102416.57, cost=118576.76
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:23:38,422 [ZeusDataLoader(train)] Expected next epoch: time=817.03, energy=109104.45, cost=126042.26
2022-12-06 13:23:38,423 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.5139, Accuracy: 0.0098
2022-12-06 13:23:38,683 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:23:38,684 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:23:38.686 [ZeusMonitor] Monitor started.
2022-12-06 18:23:38.686 [ZeusMonitor] Running indefinitely. 2022-12-06 18:23:38.686 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:23:38.686 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 13:24:23,070 [ZeusDataLoader(train)] train epoch 16 done: time=44.64 energy=6264.23
2022-12-06 13:24:23,074 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 2.8356
Training Epoch: 15 [2048/50176]	Loss: 2.7799
Training Epoch: 15 [3072/50176]	Loss: 2.7233
Training Epoch: 15 [4096/50176]	Loss: 2.7574
Training Epoch: 15 [5120/50176]	Loss: 2.7150
Training Epoch: 15 [6144/50176]	Loss: 2.7261
Training Epoch: 15 [7168/50176]	Loss: 2.7503
Training Epoch: 15 [8192/50176]	Loss: 2.8410
Training Epoch: 15 [9216/50176]	Loss: 2.7380
Training Epoch: 15 [10240/50176]	Loss: 2.7736
Training Epoch: 15 [11264/50176]	Loss: 2.7570
Training Epoch: 15 [12288/50176]	Loss: 2.9031
Training Epoch: 15 [13312/50176]	Loss: 2.6901
Training Epoch: 15 [14336/50176]	Loss: 2.7602
Training Epoch: 15 [15360/50176]	Loss: 2.7565
Training Epoch: 15 [16384/50176]	Loss: 2.8957
Training Epoch: 15 [17408/50176]	Loss: 2.7103
Training Epoch: 15 [18432/50176]	Loss: 2.7478
Training Epoch: 15 [19456/50176]	Loss: 2.6595
Training Epoch: 15 [20480/50176]	Loss: 2.7096
Training Epoch: 15 [21504/50176]	Loss: 2.6953
Training Epoch: 15 [22528/50176]	Loss: 2.8816
Training Epoch: 15 [23552/50176]	Loss: 2.7615
Training Epoch: 15 [24576/50176]	Loss: 2.7095
Training Epoch: 15 [25600/50176]	Loss: 2.7897
Training Epoch: 15 [26624/50176]	Loss: 2.7373
Training Epoch: 15 [27648/50176]	Loss: 2.7749
Training Epoch: 15 [28672/50176]	Loss: 2.6907
Training Epoch: 15 [29696/50176]	Loss: 2.7203
Training Epoch: 15 [30720/50176]	Loss: 2.7692
Training Epoch: 15 [31744/50176]	Loss: 2.7848
Training Epoch: 15 [32768/50176]	Loss: 2.7039
Training Epoch: 15 [33792/50176]	Loss: 2.7148
Training Epoch: 15 [34816/50176]	Loss: 2.7661
Training Epoch: 15 [35840/50176]	Loss: 2.7875
Training Epoch: 15 [36864/50176]	Loss: 2.5907
Training Epoch: 15 [37888/50176]	Loss: 2.7491
Training Epoch: 15 [38912/50176]	Loss: 2.6677
Training Epoch: 15 [39936/50176]	Loss: 2.6762
Training Epoch: 15 [40960/50176]	Loss: 2.7887
Training Epoch: 15 [41984/50176]	Loss: 2.7390
Training Epoch: 15 [43008/50176]	Loss: 2.7858
Training Epoch: 15 [44032/50176]	Loss: 2.7090
Training Epoch: 15 [45056/50176]	Loss: 2.6917
Training Epoch: 15 [46080/50176]	Loss: 2.6854
Training Epoch: 15 [47104/50176]	Loss: 2.7002
Training Epoch: 15 [48128/50176]	Loss: 2.7113
Training Epoch: 15 [49152/50176]	Loss: 2.6765
Training Epoch: 15 [50176/50176]	Loss: 2.6108
2022-12-06 18:24:26.778 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:24:26,788 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.71 energy=468.56
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Up to epoch 16: time=818.27, energy=109149.37, cost=126173.36
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:24:26,788 [ZeusDataLoader(train)] Expected next epoch: time=865.37, energy=115837.25, cost=133638.85
2022-12-06 13:24:26,789 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.1142, Accuracy: 0.0084
2022-12-06 13:24:27,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:24:27,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:24:27.036 [ZeusMonitor] Monitor started.
2022-12-06 18:24:27.036 [ZeusMonitor] Running indefinitely. 2022-12-06 18:24:27.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:24:27.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 13:25:11,191 [ZeusDataLoader(train)] train epoch 17 done: time=44.39 energy=6252.33
2022-12-06 13:25:11,194 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 2.6719
Training Epoch: 16 [2048/50176]	Loss: 2.6244
Training Epoch: 16 [3072/50176]	Loss: 2.5834
Training Epoch: 16 [4096/50176]	Loss: 2.5874
Training Epoch: 16 [5120/50176]	Loss: 2.7244
Training Epoch: 16 [6144/50176]	Loss: 2.6537
Training Epoch: 16 [7168/50176]	Loss: 2.5910
Training Epoch: 16 [8192/50176]	Loss: 2.5344
Training Epoch: 16 [9216/50176]	Loss: 2.6206
Training Epoch: 16 [10240/50176]	Loss: 2.5906
Training Epoch: 16 [11264/50176]	Loss: 2.6626
Training Epoch: 16 [12288/50176]	Loss: 2.6425
Training Epoch: 16 [13312/50176]	Loss: 2.6515
Training Epoch: 16 [14336/50176]	Loss: 2.6229
Training Epoch: 16 [15360/50176]	Loss: 2.7348
Training Epoch: 16 [16384/50176]	Loss: 2.6258
Training Epoch: 16 [17408/50176]	Loss: 2.6552
Training Epoch: 16 [18432/50176]	Loss: 2.7643
Training Epoch: 16 [19456/50176]	Loss: 2.6582
Training Epoch: 16 [20480/50176]	Loss: 2.5817
Training Epoch: 16 [21504/50176]	Loss: 2.6895
Training Epoch: 16 [22528/50176]	Loss: 2.5878
Training Epoch: 16 [23552/50176]	Loss: 2.6856
Training Epoch: 16 [24576/50176]	Loss: 2.6103
Training Epoch: 16 [25600/50176]	Loss: 2.5905
Training Epoch: 16 [26624/50176]	Loss: 2.6143
Training Epoch: 16 [27648/50176]	Loss: 2.7192
Training Epoch: 16 [28672/50176]	Loss: 2.6511
Training Epoch: 16 [29696/50176]	Loss: 2.6089
Training Epoch: 16 [30720/50176]	Loss: 2.6262
Training Epoch: 16 [31744/50176]	Loss: 2.6211
Training Epoch: 16 [32768/50176]	Loss: 2.6520
Training Epoch: 16 [33792/50176]	Loss: 2.6046
Training Epoch: 16 [34816/50176]	Loss: 2.7132
Training Epoch: 16 [35840/50176]	Loss: 2.7565
Training Epoch: 16 [36864/50176]	Loss: 2.6472
Training Epoch: 16 [37888/50176]	Loss: 2.5292
Training Epoch: 16 [38912/50176]	Loss: 2.5609
Training Epoch: 16 [39936/50176]	Loss: 2.7421
Training Epoch: 16 [40960/50176]	Loss: 2.5953
Training Epoch: 16 [41984/50176]	Loss: 2.6450
Training Epoch: 16 [43008/50176]	Loss: 2.6192
Training Epoch: 16 [44032/50176]	Loss: 2.6051
Training Epoch: 16 [45056/50176]	Loss: 2.6076
Training Epoch: 16 [46080/50176]	Loss: 2.6619
Training Epoch: 16 [47104/50176]	Loss: 2.6394
Training Epoch: 16 [48128/50176]	Loss: 2.6579
Training Epoch: 16 [49152/50176]	Loss: 2.6109
Training Epoch: 16 [50176/50176]	Loss: 2.6249
2022-12-06 18:25:14.950 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:25:15,001 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=474.20
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Up to epoch 17: time=866.46, energy=115875.89, cost=133753.53
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:25:15,002 [ZeusDataLoader(train)] Expected next epoch: time=913.57, energy=122563.77, cost=141219.03
2022-12-06 13:25:15,003 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 4.2636, Accuracy: 0.0107
2022-12-06 13:25:15,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:25:15,238 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:25:15.240 [ZeusMonitor] Monitor started.
2022-12-06 18:25:15.240 [ZeusMonitor] Running indefinitely. 2022-12-06 18:25:15.240 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:25:15.240 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 13:25:58,870 [ZeusDataLoader(train)] train epoch 18 done: time=43.86 energy=6211.20
2022-12-06 13:25:58,873 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 2.5583
Training Epoch: 17 [2048/50176]	Loss: 2.5444
Training Epoch: 17 [3072/50176]	Loss: 2.4287
Training Epoch: 17 [4096/50176]	Loss: 2.5388
Training Epoch: 17 [5120/50176]	Loss: 2.6707
Training Epoch: 17 [6144/50176]	Loss: 2.5082
Training Epoch: 17 [7168/50176]	Loss: 2.5658
Training Epoch: 17 [8192/50176]	Loss: 2.4826
Training Epoch: 17 [9216/50176]	Loss: 2.5460
Training Epoch: 17 [10240/50176]	Loss: 2.5146
Training Epoch: 17 [11264/50176]	Loss: 2.4838
Training Epoch: 17 [12288/50176]	Loss: 2.5662
Training Epoch: 17 [13312/50176]	Loss: 2.5906
Training Epoch: 17 [14336/50176]	Loss: 2.5878
Training Epoch: 17 [15360/50176]	Loss: 2.5924
Training Epoch: 17 [16384/50176]	Loss: 2.5646
Training Epoch: 17 [17408/50176]	Loss: 2.6018
Training Epoch: 17 [18432/50176]	Loss: 2.6401
Training Epoch: 17 [19456/50176]	Loss: 2.4757
Training Epoch: 17 [20480/50176]	Loss: 2.5697
Training Epoch: 17 [21504/50176]	Loss: 2.6031
Training Epoch: 17 [22528/50176]	Loss: 2.6460
Training Epoch: 17 [23552/50176]	Loss: 2.5445
Training Epoch: 17 [24576/50176]	Loss: 2.6533
Training Epoch: 17 [25600/50176]	Loss: 2.5663
Training Epoch: 17 [26624/50176]	Loss: 2.5321
Training Epoch: 17 [27648/50176]	Loss: 2.5515
Training Epoch: 17 [28672/50176]	Loss: 2.5158
Training Epoch: 17 [29696/50176]	Loss: 2.5945
Training Epoch: 17 [30720/50176]	Loss: 2.6148
Training Epoch: 17 [31744/50176]	Loss: 2.4940
Training Epoch: 17 [32768/50176]	Loss: 2.5287
Training Epoch: 17 [33792/50176]	Loss: 2.6950
Training Epoch: 17 [34816/50176]	Loss: 2.5467
Training Epoch: 17 [35840/50176]	Loss: 2.4873
Training Epoch: 17 [36864/50176]	Loss: 2.5756
Training Epoch: 17 [37888/50176]	Loss: 2.5146
Training Epoch: 17 [38912/50176]	Loss: 2.5907
Training Epoch: 17 [39936/50176]	Loss: 2.6683
Training Epoch: 17 [40960/50176]	Loss: 2.5523
Training Epoch: 17 [41984/50176]	Loss: 2.5370
Training Epoch: 17 [43008/50176]	Loss: 2.4923
Training Epoch: 17 [44032/50176]	Loss: 2.5591
Training Epoch: 17 [45056/50176]	Loss: 2.5443
Training Epoch: 17 [46080/50176]	Loss: 2.4525
Training Epoch: 17 [47104/50176]	Loss: 2.4882
Training Epoch: 17 [48128/50176]	Loss: 2.5506
Training Epoch: 17 [49152/50176]	Loss: 2.5103
Training Epoch: 17 [50176/50176]	Loss: 2.5528
2022-12-06 18:26:02.597 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:26:02,608 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.73 energy=471.25
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Up to epoch 18: time=914.05, energy=122558.35, cost=141258.54
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:26:02,609 [ZeusDataLoader(train)] Expected next epoch: time=961.15, energy=129246.22, cost=148724.03
2022-12-06 13:26:02,610 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0537, Accuracy: 0.0098
2022-12-06 13:26:02,854 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:26:02,855 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:26:02.856 [ZeusMonitor] Monitor started.
2022-12-06 18:26:02.857 [ZeusMonitor] Running indefinitely. 2022-12-06 18:26:02.857 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:26:02.857 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 13:26:46,877 [ZeusDataLoader(train)] train epoch 19 done: time=44.26 energy=6236.97
2022-12-06 13:26:46,881 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 2.4687
Training Epoch: 18 [2048/50176]	Loss: 2.5182
Training Epoch: 18 [3072/50176]	Loss: 2.4959
Training Epoch: 18 [4096/50176]	Loss: 2.3882
Training Epoch: 18 [5120/50176]	Loss: 2.4640
Training Epoch: 18 [6144/50176]	Loss: 2.4895
Training Epoch: 18 [7168/50176]	Loss: 2.4555
Training Epoch: 18 [8192/50176]	Loss: 2.5092
Training Epoch: 18 [9216/50176]	Loss: 2.4876
Training Epoch: 18 [10240/50176]	Loss: 2.4444
Training Epoch: 18 [11264/50176]	Loss: 2.5029
Training Epoch: 18 [12288/50176]	Loss: 2.4967
Training Epoch: 18 [13312/50176]	Loss: 2.5149
Training Epoch: 18 [14336/50176]	Loss: 2.4708
Training Epoch: 18 [15360/50176]	Loss: 2.4464
Training Epoch: 18 [16384/50176]	Loss: 2.5486
Training Epoch: 18 [17408/50176]	Loss: 2.5349
Training Epoch: 18 [18432/50176]	Loss: 2.5312
Training Epoch: 18 [19456/50176]	Loss: 2.5242
Training Epoch: 18 [20480/50176]	Loss: 2.4571
Training Epoch: 18 [21504/50176]	Loss: 2.5308
Training Epoch: 18 [22528/50176]	Loss: 2.5425
Training Epoch: 18 [23552/50176]	Loss: 2.4670
Training Epoch: 18 [24576/50176]	Loss: 2.4502
Training Epoch: 18 [25600/50176]	Loss: 2.4647
Training Epoch: 18 [26624/50176]	Loss: 2.3465
Training Epoch: 18 [27648/50176]	Loss: 2.5155
Training Epoch: 18 [28672/50176]	Loss: 2.5132
Training Epoch: 18 [29696/50176]	Loss: 2.5120
Training Epoch: 18 [30720/50176]	Loss: 2.5076
Training Epoch: 18 [31744/50176]	Loss: 2.5076
Training Epoch: 18 [32768/50176]	Loss: 2.4129
Training Epoch: 18 [33792/50176]	Loss: 2.4612
Training Epoch: 18 [34816/50176]	Loss: 2.4555
Training Epoch: 18 [35840/50176]	Loss: 2.5346
Training Epoch: 18 [36864/50176]	Loss: 2.4576
Training Epoch: 18 [37888/50176]	Loss: 2.4097
Training Epoch: 18 [38912/50176]	Loss: 2.4363
Training Epoch: 18 [39936/50176]	Loss: 2.4690
Training Epoch: 18 [40960/50176]	Loss: 2.3737
Training Epoch: 18 [41984/50176]	Loss: 2.4018
Training Epoch: 18 [43008/50176]	Loss: 2.4780
Training Epoch: 18 [44032/50176]	Loss: 2.4611
Training Epoch: 18 [45056/50176]	Loss: 2.4337
Training Epoch: 18 [46080/50176]	Loss: 2.4027
Training Epoch: 18 [47104/50176]	Loss: 2.4485
Training Epoch: 18 [48128/50176]	Loss: 2.4754
Training Epoch: 18 [49152/50176]	Loss: 2.4364
Training Epoch: 18 [50176/50176]	Loss: 2.4578
2022-12-06 18:26:50.640 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:26:50,675 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.79 energy=482.60
2022-12-06 13:26:50,675 [ZeusDataLoader(train)] Up to epoch 19: time=962.10, energy=129277.91, cost=148822.30
2022-12-06 13:26:50,675 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:26:50,676 [ZeusDataLoader(train)] Expected next epoch: time=1009.20, energy=135965.79, cost=156287.80
2022-12-06 13:26:50,676 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0318, Accuracy: 0.0099
2022-12-06 13:26:50,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:26:50,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:26:50.925 [ZeusMonitor] Monitor started.
2022-12-06 18:26:50.925 [ZeusMonitor] Running indefinitely. 2022-12-06 18:26:50.925 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:26:50.925 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 13:27:35,077 [ZeusDataLoader(train)] train epoch 20 done: time=44.39 energy=6234.69
2022-12-06 13:27:35,081 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 2.3347
Training Epoch: 19 [2048/50176]	Loss: 2.4669
Training Epoch: 19 [3072/50176]	Loss: 2.3621
Training Epoch: 19 [4096/50176]	Loss: 2.4183
Training Epoch: 19 [5120/50176]	Loss: 2.2826
Training Epoch: 19 [6144/50176]	Loss: 2.3839
Training Epoch: 19 [7168/50176]	Loss: 2.2741
Training Epoch: 19 [8192/50176]	Loss: 2.3651
Training Epoch: 19 [9216/50176]	Loss: 2.4024
Training Epoch: 19 [10240/50176]	Loss: 2.4953
Training Epoch: 19 [11264/50176]	Loss: 2.4452
Training Epoch: 19 [12288/50176]	Loss: 2.3587
Training Epoch: 19 [13312/50176]	Loss: 2.4111
Training Epoch: 19 [14336/50176]	Loss: 2.4398
Training Epoch: 19 [15360/50176]	Loss: 2.4747
Training Epoch: 19 [16384/50176]	Loss: 2.3288
Training Epoch: 19 [17408/50176]	Loss: 2.4522
Training Epoch: 19 [18432/50176]	Loss: 2.3655
Training Epoch: 19 [19456/50176]	Loss: 2.3876
Training Epoch: 19 [20480/50176]	Loss: 2.4343
Training Epoch: 19 [21504/50176]	Loss: 2.4702
Training Epoch: 19 [22528/50176]	Loss: 2.4183
Training Epoch: 19 [23552/50176]	Loss: 2.4865
Training Epoch: 19 [24576/50176]	Loss: 2.4025
Training Epoch: 19 [25600/50176]	Loss: 2.3604
Training Epoch: 19 [26624/50176]	Loss: 2.4173
Training Epoch: 19 [27648/50176]	Loss: 2.3447
Training Epoch: 19 [28672/50176]	Loss: 2.3530
Training Epoch: 19 [29696/50176]	Loss: 2.4356
Training Epoch: 19 [30720/50176]	Loss: 2.3906
Training Epoch: 19 [31744/50176]	Loss: 2.3613
Training Epoch: 19 [32768/50176]	Loss: 2.4544
Training Epoch: 19 [33792/50176]	Loss: 2.3562
Training Epoch: 19 [34816/50176]	Loss: 2.3969
Training Epoch: 19 [35840/50176]	Loss: 2.3095
Training Epoch: 19 [36864/50176]	Loss: 2.3792
Training Epoch: 19 [37888/50176]	Loss: 2.3637
Training Epoch: 19 [38912/50176]	Loss: 2.4043
Training Epoch: 19 [39936/50176]	Loss: 2.3681
Training Epoch: 19 [40960/50176]	Loss: 2.2853
Training Epoch: 19 [41984/50176]	Loss: 2.4435
Training Epoch: 19 [43008/50176]	Loss: 2.4036
Training Epoch: 19 [44032/50176]	Loss: 2.3311
Training Epoch: 19 [45056/50176]	Loss: 2.3800
Training Epoch: 19 [46080/50176]	Loss: 2.3269
Training Epoch: 19 [47104/50176]	Loss: 2.3187
Training Epoch: 19 [48128/50176]	Loss: 2.3740
Training Epoch: 19 [49152/50176]	Loss: 2.4154
Training Epoch: 19 [50176/50176]	Loss: 2.3094
2022-12-06 18:27:38.848 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:27:38,886 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.80 energy=489.54
2022-12-06 13:27:38,886 [ZeusDataLoader(train)] Up to epoch 20: time=1010.29, energy=136002.15, cost=156401.02
2022-12-06 13:27:38,886 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:27:38,887 [ZeusDataLoader(train)] Expected next epoch: time=1057.39, energy=142690.03, cost=163866.51
2022-12-06 13:27:38,888 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0456, Accuracy: 0.0094
2022-12-06 13:27:39,160 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:27:39,161 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:27:39.162 [ZeusMonitor] Monitor started.
2022-12-06 18:27:39.162 [ZeusMonitor] Running indefinitely. 2022-12-06 18:27:39.162 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:27:39.162 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 13:28:23,444 [ZeusDataLoader(train)] train epoch 21 done: time=44.55 energy=6255.65
2022-12-06 13:28:23,447 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 2.2789
Training Epoch: 20 [2048/50176]	Loss: 2.3046
Training Epoch: 20 [3072/50176]	Loss: 2.3468
Training Epoch: 20 [4096/50176]	Loss: 2.2705
Training Epoch: 20 [5120/50176]	Loss: 2.2140
Training Epoch: 20 [6144/50176]	Loss: 2.3541
Training Epoch: 20 [7168/50176]	Loss: 2.2646
Training Epoch: 20 [8192/50176]	Loss: 2.4108
Training Epoch: 20 [9216/50176]	Loss: 2.3353
Training Epoch: 20 [10240/50176]	Loss: 2.2711
Training Epoch: 20 [11264/50176]	Loss: 2.3327
Training Epoch: 20 [12288/50176]	Loss: 2.2848
Training Epoch: 20 [13312/50176]	Loss: 2.2279
Training Epoch: 20 [14336/50176]	Loss: 2.4338
Training Epoch: 20 [15360/50176]	Loss: 2.4173
Training Epoch: 20 [16384/50176]	Loss: 2.3934
Training Epoch: 20 [17408/50176]	Loss: 2.3352
Training Epoch: 20 [18432/50176]	Loss: 2.2770
Training Epoch: 20 [19456/50176]	Loss: 2.3518
Training Epoch: 20 [20480/50176]	Loss: 2.3059
Training Epoch: 20 [21504/50176]	Loss: 2.3891
Training Epoch: 20 [22528/50176]	Loss: 2.3134
Training Epoch: 20 [23552/50176]	Loss: 2.2226
Training Epoch: 20 [24576/50176]	Loss: 2.3568
Training Epoch: 20 [25600/50176]	Loss: 2.4285
Training Epoch: 20 [26624/50176]	Loss: 2.2898
Training Epoch: 20 [27648/50176]	Loss: 2.2624
Training Epoch: 20 [28672/50176]	Loss: 2.3301
Training Epoch: 20 [29696/50176]	Loss: 2.2606
Training Epoch: 20 [30720/50176]	Loss: 2.3356
Training Epoch: 20 [31744/50176]	Loss: 2.3912
Training Epoch: 20 [32768/50176]	Loss: 2.3878
Training Epoch: 20 [33792/50176]	Loss: 2.2754
Training Epoch: 20 [34816/50176]	Loss: 2.4019
Training Epoch: 20 [35840/50176]	Loss: 2.2682
Training Epoch: 20 [36864/50176]	Loss: 2.4060
Training Epoch: 20 [37888/50176]	Loss: 2.2124
Training Epoch: 20 [38912/50176]	Loss: 2.3448
Training Epoch: 20 [39936/50176]	Loss: 2.3431
Training Epoch: 20 [40960/50176]	Loss: 2.3509
Training Epoch: 20 [41984/50176]	Loss: 2.2850
Training Epoch: 20 [43008/50176]	Loss: 2.2921
Training Epoch: 20 [44032/50176]	Loss: 2.2028
Training Epoch: 20 [45056/50176]	Loss: 2.2983
Training Epoch: 20 [46080/50176]	Loss: 2.3058
Training Epoch: 20 [47104/50176]	Loss: 2.3585
Training Epoch: 20 [48128/50176]	Loss: 2.3616
Training Epoch: 20 [49152/50176]	Loss: 2.3164
Training Epoch: 20 [50176/50176]	Loss: 2.2674
2022-12-06 18:28:27.210 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:28:27,263 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.81 energy=492.39
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Up to epoch 21: time=1058.64, energy=142750.18, cost=164006.23
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:28:27,264 [ZeusDataLoader(train)] Expected next epoch: time=1105.75, energy=149438.06, cost=171471.72
2022-12-06 13:28:27,265 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.1832, Accuracy: 0.0098
2022-12-06 13:28:27,510 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:28:27,511 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:28:27.513 [ZeusMonitor] Monitor started.
2022-12-06 18:28:27.513 [ZeusMonitor] Running indefinitely. 2022-12-06 18:28:27.513 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:28:27.513 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 13:29:11,688 [ZeusDataLoader(train)] train epoch 22 done: time=44.42 energy=6244.03
2022-12-06 13:29:11,691 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 2.2492
Training Epoch: 21 [2048/50176]	Loss: 2.2148
Training Epoch: 21 [3072/50176]	Loss: 2.2290
Training Epoch: 21 [4096/50176]	Loss: 2.2914
Training Epoch: 21 [5120/50176]	Loss: 2.3007
Training Epoch: 21 [6144/50176]	Loss: 2.2385
Training Epoch: 21 [7168/50176]	Loss: 2.2189
Training Epoch: 21 [8192/50176]	Loss: 2.2819
Training Epoch: 21 [9216/50176]	Loss: 2.1977
Training Epoch: 21 [10240/50176]	Loss: 2.2003
Training Epoch: 21 [11264/50176]	Loss: 2.2351
Training Epoch: 21 [12288/50176]	Loss: 2.2513
Training Epoch: 21 [13312/50176]	Loss: 2.1895
Training Epoch: 21 [14336/50176]	Loss: 2.2641
Training Epoch: 21 [15360/50176]	Loss: 2.1991
Training Epoch: 21 [16384/50176]	Loss: 2.3187
Training Epoch: 21 [17408/50176]	Loss: 2.1764
Training Epoch: 21 [18432/50176]	Loss: 2.1697
Training Epoch: 21 [19456/50176]	Loss: 2.3302
Training Epoch: 21 [20480/50176]	Loss: 2.2072
Training Epoch: 21 [21504/50176]	Loss: 2.2613
Training Epoch: 21 [22528/50176]	Loss: 2.3176
Training Epoch: 21 [23552/50176]	Loss: 2.2654
Training Epoch: 21 [24576/50176]	Loss: 2.1361
Training Epoch: 21 [25600/50176]	Loss: 2.2576
Training Epoch: 21 [26624/50176]	Loss: 2.2701
Training Epoch: 21 [27648/50176]	Loss: 2.2681
Training Epoch: 21 [28672/50176]	Loss: 2.2378
Training Epoch: 21 [29696/50176]	Loss: 2.3373
Training Epoch: 21 [30720/50176]	Loss: 2.1854
Training Epoch: 21 [31744/50176]	Loss: 2.2095
Training Epoch: 21 [32768/50176]	Loss: 2.2034
Training Epoch: 21 [33792/50176]	Loss: 2.2387
Training Epoch: 21 [34816/50176]	Loss: 2.2216
Training Epoch: 21 [35840/50176]	Loss: 2.2394
Training Epoch: 21 [36864/50176]	Loss: 2.1296
Training Epoch: 21 [37888/50176]	Loss: 2.3355
Training Epoch: 21 [38912/50176]	Loss: 2.2759
Training Epoch: 21 [39936/50176]	Loss: 2.3663
Training Epoch: 21 [40960/50176]	Loss: 2.2109
Training Epoch: 21 [41984/50176]	Loss: 2.2495
Training Epoch: 21 [43008/50176]	Loss: 2.2255
Training Epoch: 21 [44032/50176]	Loss: 2.2700
Training Epoch: 21 [45056/50176]	Loss: 2.2590
Training Epoch: 21 [46080/50176]	Loss: 2.2446
Training Epoch: 21 [47104/50176]	Loss: 2.3132
Training Epoch: 21 [48128/50176]	Loss: 2.2322
Training Epoch: 21 [49152/50176]	Loss: 2.2462
Training Epoch: 21 [50176/50176]	Loss: 2.2756
2022-12-06 18:29:15.445 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:29:15,484 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.78 energy=479.59
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Up to epoch 22: time=1106.84, energy=149473.80, cost=171585.57
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:29:15,484 [ZeusDataLoader(train)] Expected next epoch: time=1153.95, energy=156161.68, cost=179051.07
2022-12-06 13:29:15,485 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.2018, Accuracy: 0.0095
2022-12-06 13:29:15,722 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:29:15,722 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:29:15.724 [ZeusMonitor] Monitor started.
2022-12-06 18:29:15.724 [ZeusMonitor] Running indefinitely. 2022-12-06 18:29:15.724 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:29:15.724 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 13:29:59,579 [ZeusDataLoader(train)] train epoch 23 done: time=44.09 energy=6225.39
2022-12-06 13:29:59,583 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 2.1931
Training Epoch: 22 [2048/50176]	Loss: 2.2197
Training Epoch: 22 [3072/50176]	Loss: 2.2012
Training Epoch: 22 [4096/50176]	Loss: 2.0650
Training Epoch: 22 [5120/50176]	Loss: 2.2094
Training Epoch: 22 [6144/50176]	Loss: 2.1902
Training Epoch: 22 [7168/50176]	Loss: 2.2549
Training Epoch: 22 [8192/50176]	Loss: 2.2434
Training Epoch: 22 [9216/50176]	Loss: 2.1724
Training Epoch: 22 [10240/50176]	Loss: 2.1483
Training Epoch: 22 [11264/50176]	Loss: 2.2499
Training Epoch: 22 [12288/50176]	Loss: 2.2571
Training Epoch: 22 [13312/50176]	Loss: 2.0572
Training Epoch: 22 [14336/50176]	Loss: 2.1845
Training Epoch: 22 [15360/50176]	Loss: 2.1715
Training Epoch: 22 [16384/50176]	Loss: 2.2451
Training Epoch: 22 [17408/50176]	Loss: 2.0843
Training Epoch: 22 [18432/50176]	Loss: 2.1836
Training Epoch: 22 [19456/50176]	Loss: 2.1528
Training Epoch: 22 [20480/50176]	Loss: 2.2455
Training Epoch: 22 [21504/50176]	Loss: 2.2098
Training Epoch: 22 [22528/50176]	Loss: 2.1749
Training Epoch: 22 [23552/50176]	Loss: 2.1905
Training Epoch: 22 [24576/50176]	Loss: 2.2420
Training Epoch: 22 [25600/50176]	Loss: 2.2586
Training Epoch: 22 [26624/50176]	Loss: 2.1653
Training Epoch: 22 [27648/50176]	Loss: 2.1857
Training Epoch: 22 [28672/50176]	Loss: 2.2506
Training Epoch: 22 [29696/50176]	Loss: 2.1968
Training Epoch: 22 [30720/50176]	Loss: 2.0840
Training Epoch: 22 [31744/50176]	Loss: 2.2753
Training Epoch: 22 [32768/50176]	Loss: 2.1747
Training Epoch: 22 [33792/50176]	Loss: 2.1191
Training Epoch: 22 [34816/50176]	Loss: 2.2185
Training Epoch: 22 [35840/50176]	Loss: 2.2643
Training Epoch: 22 [36864/50176]	Loss: 2.1998
Training Epoch: 22 [37888/50176]	Loss: 2.1247
Training Epoch: 22 [38912/50176]	Loss: 2.1761
Training Epoch: 22 [39936/50176]	Loss: 2.1246
Training Epoch: 22 [40960/50176]	Loss: 2.2329
Training Epoch: 22 [41984/50176]	Loss: 2.2346
Training Epoch: 22 [43008/50176]	Loss: 2.1415
Training Epoch: 22 [44032/50176]	Loss: 2.1330
Training Epoch: 22 [45056/50176]	Loss: 2.1915
Training Epoch: 22 [46080/50176]	Loss: 2.1027
Training Epoch: 22 [47104/50176]	Loss: 2.0655
Training Epoch: 22 [48128/50176]	Loss: 2.3634
Training Epoch: 22 [49152/50176]	Loss: 2.2249
Training Epoch: 22 [50176/50176]	Loss: 2.0637
2022-12-06 18:30:03.397 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:30:03,414 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.82 energy=475.31
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Up to epoch 23: time=1154.75, energy=156174.50, cost=179127.90
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:30:03,414 [ZeusDataLoader(train)] Expected next epoch: time=1201.85, energy=162862.38, cost=186593.40
2022-12-06 13:30:03,415 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.2828, Accuracy: 0.0098
2022-12-06 13:30:03,653 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:30:03,653 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:30:03.657 [ZeusMonitor] Monitor started.
2022-12-06 18:30:03.657 [ZeusMonitor] Running indefinitely. 2022-12-06 18:30:03.657 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:30:03.657 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 13:30:47,607 [ZeusDataLoader(train)] train epoch 24 done: time=44.18 energy=6225.80
2022-12-06 13:30:47,610 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 2.1250
Training Epoch: 23 [2048/50176]	Loss: 2.0631
Training Epoch: 23 [3072/50176]	Loss: 2.0986
Training Epoch: 23 [4096/50176]	Loss: 2.1593
Training Epoch: 23 [5120/50176]	Loss: 2.0955
Training Epoch: 23 [6144/50176]	Loss: 2.1507
Training Epoch: 23 [7168/50176]	Loss: 2.1952
Training Epoch: 23 [8192/50176]	Loss: 2.1329
Training Epoch: 23 [9216/50176]	Loss: 2.0663
Training Epoch: 23 [10240/50176]	Loss: 2.1367
Training Epoch: 23 [11264/50176]	Loss: 2.0788
Training Epoch: 23 [12288/50176]	Loss: 2.0717
Training Epoch: 23 [13312/50176]	Loss: 2.2207
Training Epoch: 23 [14336/50176]	Loss: 2.1719
Training Epoch: 23 [15360/50176]	Loss: 2.0176
Training Epoch: 23 [16384/50176]	Loss: 2.1308
Training Epoch: 23 [17408/50176]	Loss: 2.2031
Training Epoch: 23 [18432/50176]	Loss: 2.1154
Training Epoch: 23 [19456/50176]	Loss: 2.1917
Training Epoch: 23 [20480/50176]	Loss: 2.0671
Training Epoch: 23 [21504/50176]	Loss: 2.1081
Training Epoch: 23 [22528/50176]	Loss: 2.1698
Training Epoch: 23 [23552/50176]	Loss: 2.0428
Training Epoch: 23 [24576/50176]	Loss: 2.1523
Training Epoch: 23 [25600/50176]	Loss: 2.1698
Training Epoch: 23 [26624/50176]	Loss: 2.1723
Training Epoch: 23 [27648/50176]	Loss: 2.0708
Training Epoch: 23 [28672/50176]	Loss: 2.1366
Training Epoch: 23 [29696/50176]	Loss: 2.0821
Training Epoch: 23 [30720/50176]	Loss: 2.1795
Training Epoch: 23 [31744/50176]	Loss: 2.1657
Training Epoch: 23 [32768/50176]	Loss: 2.2280
Training Epoch: 23 [33792/50176]	Loss: 2.1502
Training Epoch: 23 [34816/50176]	Loss: 2.1472
Training Epoch: 23 [35840/50176]	Loss: 2.1968
Training Epoch: 23 [36864/50176]	Loss: 2.0794
Training Epoch: 23 [37888/50176]	Loss: 2.0796
Training Epoch: 23 [38912/50176]	Loss: 2.2069
Training Epoch: 23 [39936/50176]	Loss: 2.2064
Training Epoch: 23 [40960/50176]	Loss: 2.1805
Training Epoch: 23 [41984/50176]	Loss: 2.1787
Training Epoch: 23 [43008/50176]	Loss: 2.0684
Training Epoch: 23 [44032/50176]	Loss: 2.1647
Training Epoch: 23 [45056/50176]	Loss: 2.2161
Training Epoch: 23 [46080/50176]	Loss: 2.3027
Training Epoch: 23 [47104/50176]	Loss: 2.0822
Training Epoch: 23 [48128/50176]	Loss: 2.0465
Training Epoch: 23 [49152/50176]	Loss: 2.0802
Training Epoch: 23 [50176/50176]	Loss: 2.0953
2022-12-06 18:30:51.354 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:30:51,404 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.79 energy=487.12
2022-12-06 13:30:51,404 [ZeusDataLoader(train)] Up to epoch 24: time=1202.72, energy=162887.43, cost=186681.68
2022-12-06 13:30:51,405 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:30:51,405 [ZeusDataLoader(train)] Expected next epoch: time=1249.82, energy=169575.31, cost=194147.18
2022-12-06 13:30:51,406 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.1594, Accuracy: 0.0098
2022-12-06 13:30:51,596 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:30:51,597 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:30:51.600 [ZeusMonitor] Monitor started.
2022-12-06 18:30:51.600 [ZeusMonitor] Running indefinitely. 2022-12-06 18:30:51.600 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:30:51.600 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 13:31:35,975 [ZeusDataLoader(train)] train epoch 25 done: time=44.56 energy=6262.58
2022-12-06 13:31:35,979 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 2.0475
Training Epoch: 24 [2048/50176]	Loss: 1.9875
Training Epoch: 24 [3072/50176]	Loss: 2.0181
Training Epoch: 24 [4096/50176]	Loss: 1.9907
Training Epoch: 24 [5120/50176]	Loss: 2.0369
Training Epoch: 24 [6144/50176]	Loss: 1.9776
Training Epoch: 24 [7168/50176]	Loss: 2.0814
Training Epoch: 24 [8192/50176]	Loss: 2.0218
Training Epoch: 24 [9216/50176]	Loss: 2.1321
Training Epoch: 24 [10240/50176]	Loss: 2.0562
Training Epoch: 24 [11264/50176]	Loss: 2.0434
Training Epoch: 24 [12288/50176]	Loss: 2.0512
Training Epoch: 24 [13312/50176]	Loss: 2.0598
Training Epoch: 24 [14336/50176]	Loss: 2.1620
Training Epoch: 24 [15360/50176]	Loss: 1.9508
Training Epoch: 24 [16384/50176]	Loss: 1.9740
Training Epoch: 24 [17408/50176]	Loss: 2.0274
Training Epoch: 24 [18432/50176]	Loss: 2.1257
Training Epoch: 24 [19456/50176]	Loss: 2.0654
Training Epoch: 24 [20480/50176]	Loss: 2.0587
Training Epoch: 24 [21504/50176]	Loss: 2.0144
Training Epoch: 24 [22528/50176]	Loss: 2.0420
Training Epoch: 24 [23552/50176]	Loss: 2.1421
Training Epoch: 24 [24576/50176]	Loss: 1.9771
Training Epoch: 24 [25600/50176]	Loss: 2.0372
Training Epoch: 24 [26624/50176]	Loss: 2.0290
Training Epoch: 24 [27648/50176]	Loss: 2.2114
Training Epoch: 24 [28672/50176]	Loss: 2.0308
Training Epoch: 24 [29696/50176]	Loss: 2.0486
Training Epoch: 24 [30720/50176]	Loss: 2.0925
Training Epoch: 24 [31744/50176]	Loss: 2.1949
Training Epoch: 24 [32768/50176]	Loss: 2.1202
Training Epoch: 24 [33792/50176]	Loss: 2.0171
Training Epoch: 24 [34816/50176]	Loss: 2.1270
Training Epoch: 24 [35840/50176]	Loss: 2.1073
Training Epoch: 24 [36864/50176]	Loss: 2.0278
Training Epoch: 24 [37888/50176]	Loss: 2.1495
Training Epoch: 24 [38912/50176]	Loss: 2.1208
Training Epoch: 24 [39936/50176]	Loss: 1.9824
Training Epoch: 24 [40960/50176]	Loss: 1.9784
Training Epoch: 24 [41984/50176]	Loss: 2.1702
Training Epoch: 24 [43008/50176]	Loss: 2.1015
Training Epoch: 24 [44032/50176]	Loss: 1.9943
Training Epoch: 24 [45056/50176]	Loss: 2.0904
Training Epoch: 24 [46080/50176]	Loss: 2.1371
Training Epoch: 24 [47104/50176]	Loss: 2.1303
Training Epoch: 24 [48128/50176]	Loss: 2.2049
Training Epoch: 24 [49152/50176]	Loss: 2.0796
Training Epoch: 24 [50176/50176]	Loss: 2.0366
2022-12-06 18:31:39.732 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:31:39,744 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.76 energy=467.31
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Up to epoch 25: time=1251.04, energy=169617.32, cost=194274.58
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:31:39,744 [ZeusDataLoader(train)] Expected next epoch: time=1298.14, energy=176305.20, cost=201740.08
2022-12-06 13:31:39,745 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0719, Accuracy: 0.0098
2022-12-06 13:31:39,989 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:31:39,990 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:31:39.992 [ZeusMonitor] Monitor started.
2022-12-06 18:31:39.992 [ZeusMonitor] Running indefinitely. 2022-12-06 18:31:39.992 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:31:39.992 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 13:32:23,841 [ZeusDataLoader(train)] train epoch 26 done: time=44.09 energy=6232.50
2022-12-06 13:32:23,845 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 2.0137
Training Epoch: 25 [2048/50176]	Loss: 2.0112
Training Epoch: 25 [3072/50176]	Loss: 2.0135
Training Epoch: 25 [4096/50176]	Loss: 2.1223
Training Epoch: 25 [5120/50176]	Loss: 2.0002
Training Epoch: 25 [6144/50176]	Loss: 2.0823
Training Epoch: 25 [7168/50176]	Loss: 2.0060
Training Epoch: 25 [8192/50176]	Loss: 2.0607
Training Epoch: 25 [9216/50176]	Loss: 2.0676
Training Epoch: 25 [10240/50176]	Loss: 1.9691
Training Epoch: 25 [11264/50176]	Loss: 2.0310
Training Epoch: 25 [12288/50176]	Loss: 2.0422
Training Epoch: 25 [13312/50176]	Loss: 1.9610
Training Epoch: 25 [14336/50176]	Loss: 1.9427
Training Epoch: 25 [15360/50176]	Loss: 1.9970
Training Epoch: 25 [16384/50176]	Loss: 2.1311
Training Epoch: 25 [17408/50176]	Loss: 2.0422
Training Epoch: 25 [18432/50176]	Loss: 2.0277
Training Epoch: 25 [19456/50176]	Loss: 1.9878
Training Epoch: 25 [20480/50176]	Loss: 2.0182
Training Epoch: 25 [21504/50176]	Loss: 1.9229
Training Epoch: 25 [22528/50176]	Loss: 2.0877
Training Epoch: 25 [23552/50176]	Loss: 1.9761
Training Epoch: 25 [24576/50176]	Loss: 1.9343
Training Epoch: 25 [25600/50176]	Loss: 1.9218
Training Epoch: 25 [26624/50176]	Loss: 2.0544
Training Epoch: 25 [27648/50176]	Loss: 1.9786
Training Epoch: 25 [28672/50176]	Loss: 2.0300
Training Epoch: 25 [29696/50176]	Loss: 2.0973
Training Epoch: 25 [30720/50176]	Loss: 2.0554
Training Epoch: 25 [31744/50176]	Loss: 1.9850
Training Epoch: 25 [32768/50176]	Loss: 1.9864
Training Epoch: 25 [33792/50176]	Loss: 1.9537
Training Epoch: 25 [34816/50176]	Loss: 1.9788
Training Epoch: 25 [35840/50176]	Loss: 1.9827
Training Epoch: 25 [36864/50176]	Loss: 2.0025
Training Epoch: 25 [37888/50176]	Loss: 1.9878
Training Epoch: 25 [38912/50176]	Loss: 2.0310
Training Epoch: 25 [39936/50176]	Loss: 1.9821
Training Epoch: 25 [40960/50176]	Loss: 2.0266
Training Epoch: 25 [41984/50176]	Loss: 2.0155
Training Epoch: 25 [43008/50176]	Loss: 2.0482
Training Epoch: 25 [44032/50176]	Loss: 2.0212
Training Epoch: 25 [45056/50176]	Loss: 2.0782
Training Epoch: 25 [46080/50176]	Loss: 2.0254
Training Epoch: 25 [47104/50176]	Loss: 1.9521
Training Epoch: 25 [48128/50176]	Loss: 2.0144
Training Epoch: 25 [49152/50176]	Loss: 2.0258
Training Epoch: 25 [50176/50176]	Loss: 2.0076
2022-12-06 18:32:27.600 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:32:27,654 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.80 energy=480.50
2022-12-06 13:32:27,654 [ZeusDataLoader(train)] Up to epoch 26: time=1298.93, energy=176330.32, cost=201821.37
2022-12-06 13:32:27,655 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:32:27,655 [ZeusDataLoader(train)] Expected next epoch: time=1346.03, energy=183018.20, cost=209286.87
2022-12-06 13:32:27,656 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.2032, Accuracy: 0.0098
2022-12-06 13:32:27,906 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:32:27,907 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:32:27.908 [ZeusMonitor] Monitor started.
2022-12-06 18:32:27.908 [ZeusMonitor] Running indefinitely. 2022-12-06 18:32:27.908 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:32:27.908 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 13:33:12,064 [ZeusDataLoader(train)] train epoch 27 done: time=44.40 energy=6250.21
2022-12-06 13:33:12,067 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 2.0236
Training Epoch: 26 [2048/50176]	Loss: 2.0283
Training Epoch: 26 [3072/50176]	Loss: 2.0341
Training Epoch: 26 [4096/50176]	Loss: 1.8853
Training Epoch: 26 [5120/50176]	Loss: 1.9645
Training Epoch: 26 [6144/50176]	Loss: 1.9338
Training Epoch: 26 [7168/50176]	Loss: 1.9545
Training Epoch: 26 [8192/50176]	Loss: 1.9452
Training Epoch: 26 [9216/50176]	Loss: 1.8696
Training Epoch: 26 [10240/50176]	Loss: 2.0314
Training Epoch: 26 [11264/50176]	Loss: 1.9021
Training Epoch: 26 [12288/50176]	Loss: 1.9429
Training Epoch: 26 [13312/50176]	Loss: 1.8615
Training Epoch: 26 [14336/50176]	Loss: 1.9606
Training Epoch: 26 [15360/50176]	Loss: 1.8990
Training Epoch: 26 [16384/50176]	Loss: 1.8832
Training Epoch: 26 [17408/50176]	Loss: 1.9411
Training Epoch: 26 [18432/50176]	Loss: 1.9606
Training Epoch: 26 [19456/50176]	Loss: 1.9707
Training Epoch: 26 [20480/50176]	Loss: 1.8992
Training Epoch: 26 [21504/50176]	Loss: 1.9101
Training Epoch: 26 [22528/50176]	Loss: 1.9806
Training Epoch: 26 [23552/50176]	Loss: 2.0272
Training Epoch: 26 [24576/50176]	Loss: 1.9276
Training Epoch: 26 [25600/50176]	Loss: 1.9266
Training Epoch: 26 [26624/50176]	Loss: 1.9826
Training Epoch: 26 [27648/50176]	Loss: 2.0051
Training Epoch: 26 [28672/50176]	Loss: 1.9468
Training Epoch: 26 [29696/50176]	Loss: 1.9619
Training Epoch: 26 [30720/50176]	Loss: 1.9997
Training Epoch: 26 [31744/50176]	Loss: 1.9708
Training Epoch: 26 [32768/50176]	Loss: 2.0630
Training Epoch: 26 [33792/50176]	Loss: 2.0749
Training Epoch: 26 [34816/50176]	Loss: 2.0184
Training Epoch: 26 [35840/50176]	Loss: 1.9443
Training Epoch: 26 [36864/50176]	Loss: 1.9452
Training Epoch: 26 [37888/50176]	Loss: 1.9374
Training Epoch: 26 [38912/50176]	Loss: 1.9412
Training Epoch: 26 [39936/50176]	Loss: 2.0566
Training Epoch: 26 [40960/50176]	Loss: 1.9542
Training Epoch: 26 [41984/50176]	Loss: 1.9850
Training Epoch: 26 [43008/50176]	Loss: 1.9585
Training Epoch: 26 [44032/50176]	Loss: 1.9532
Training Epoch: 26 [45056/50176]	Loss: 1.9529
Training Epoch: 26 [46080/50176]	Loss: 1.9824
Training Epoch: 26 [47104/50176]	Loss: 2.0626
Training Epoch: 26 [48128/50176]	Loss: 2.0524
Training Epoch: 26 [49152/50176]	Loss: 1.8681
Training Epoch: 26 [50176/50176]	Loss: 1.9107
2022-12-06 18:33:15.940 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:33:15,967 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.89 energy=483.93
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Up to epoch 27: time=1347.22, energy=183064.46, cost=209414.02
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:33:15,967 [ZeusDataLoader(train)] Expected next epoch: time=1394.32, energy=189752.34, cost=216879.52
2022-12-06 13:33:15,968 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.1020, Accuracy: 0.0099
2022-12-06 13:33:16,216 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:33:16,217 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:33:16.219 [ZeusMonitor] Monitor started.
2022-12-06 18:33:16.219 [ZeusMonitor] Running indefinitely. 2022-12-06 18:33:16.219 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:33:16.219 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 13:34:00,184 [ZeusDataLoader(train)] train epoch 28 done: time=44.21 energy=6227.24
2022-12-06 13:34:00,189 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 1.8293
Training Epoch: 27 [2048/50176]	Loss: 1.8332
Training Epoch: 27 [3072/50176]	Loss: 1.8837
Training Epoch: 27 [4096/50176]	Loss: 1.8688
Training Epoch: 27 [5120/50176]	Loss: 1.8833
Training Epoch: 27 [6144/50176]	Loss: 1.8196
Training Epoch: 27 [7168/50176]	Loss: 1.7745
Training Epoch: 27 [8192/50176]	Loss: 1.9240
Training Epoch: 27 [9216/50176]	Loss: 1.8069
Training Epoch: 27 [10240/50176]	Loss: 1.9230
Training Epoch: 27 [11264/50176]	Loss: 1.8414
Training Epoch: 27 [12288/50176]	Loss: 1.8468
Training Epoch: 27 [13312/50176]	Loss: 1.8955
Training Epoch: 27 [14336/50176]	Loss: 1.8463
Training Epoch: 27 [15360/50176]	Loss: 1.8932
Training Epoch: 27 [16384/50176]	Loss: 1.9087
Training Epoch: 27 [17408/50176]	Loss: 1.8595
Training Epoch: 27 [18432/50176]	Loss: 2.0149
Training Epoch: 27 [19456/50176]	Loss: 1.8511
Training Epoch: 27 [20480/50176]	Loss: 1.7921
Training Epoch: 27 [21504/50176]	Loss: 2.0097
Training Epoch: 27 [22528/50176]	Loss: 1.8416
Training Epoch: 27 [23552/50176]	Loss: 1.8559
Training Epoch: 27 [24576/50176]	Loss: 1.8989
Training Epoch: 27 [25600/50176]	Loss: 1.9253
Training Epoch: 27 [26624/50176]	Loss: 1.9204
Training Epoch: 27 [27648/50176]	Loss: 1.9563
Training Epoch: 27 [28672/50176]	Loss: 1.9540
Training Epoch: 27 [29696/50176]	Loss: 1.9580
Training Epoch: 27 [30720/50176]	Loss: 1.9533
Training Epoch: 27 [31744/50176]	Loss: 1.9901
Training Epoch: 27 [32768/50176]	Loss: 1.9596
Training Epoch: 27 [33792/50176]	Loss: 1.8931
Training Epoch: 27 [34816/50176]	Loss: 2.0541
Training Epoch: 27 [35840/50176]	Loss: 1.9712
Training Epoch: 27 [36864/50176]	Loss: 1.8952
Training Epoch: 27 [37888/50176]	Loss: 1.8893
Training Epoch: 27 [38912/50176]	Loss: 1.8804
Training Epoch: 27 [39936/50176]	Loss: 1.9754
Training Epoch: 27 [40960/50176]	Loss: 1.8789
Training Epoch: 27 [41984/50176]	Loss: 1.9421
Training Epoch: 27 [43008/50176]	Loss: 1.9229
Training Epoch: 27 [44032/50176]	Loss: 1.9420
Training Epoch: 27 [45056/50176]	Loss: 1.8491
Training Epoch: 27 [46080/50176]	Loss: 1.9328
Training Epoch: 27 [47104/50176]	Loss: 1.9574
Training Epoch: 27 [48128/50176]	Loss: 1.9431
Training Epoch: 27 [49152/50176]	Loss: 2.0153
Training Epoch: 27 [50176/50176]	Loss: 2.0098
2022-12-06 18:34:03.924 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:34:03,938 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.74 energy=469.80
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Up to epoch 28: time=1395.17, energy=189761.49, cost=216958.11
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:34:03,939 [ZeusDataLoader(train)] Expected next epoch: time=1442.27, energy=196449.37, cost=224423.61
2022-12-06 13:34:03,940 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.4401, Accuracy: 0.0098
2022-12-06 13:34:04,178 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:34:04,178 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:34:04.188 [ZeusMonitor] Monitor started.
2022-12-06 18:34:04.189 [ZeusMonitor] Running indefinitely. 2022-12-06 18:34:04.189 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:34:04.189 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 13:34:48,175 [ZeusDataLoader(train)] train epoch 29 done: time=44.23 energy=6228.03
2022-12-06 13:34:48,178 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 1.8378
Training Epoch: 28 [2048/50176]	Loss: 1.9144
Training Epoch: 28 [3072/50176]	Loss: 1.8009
Training Epoch: 28 [4096/50176]	Loss: 1.9294
Training Epoch: 28 [5120/50176]	Loss: 1.8327
Training Epoch: 28 [6144/50176]	Loss: 1.8673
Training Epoch: 28 [7168/50176]	Loss: 1.7964
Training Epoch: 28 [8192/50176]	Loss: 1.7855
Training Epoch: 28 [9216/50176]	Loss: 1.9152
Training Epoch: 28 [10240/50176]	Loss: 1.8676
Training Epoch: 28 [11264/50176]	Loss: 1.8100
Training Epoch: 28 [12288/50176]	Loss: 1.8878
Training Epoch: 28 [13312/50176]	Loss: 1.8834
Training Epoch: 28 [14336/50176]	Loss: 1.9330
Training Epoch: 28 [15360/50176]	Loss: 1.8404
Training Epoch: 28 [16384/50176]	Loss: 1.8586
Training Epoch: 28 [17408/50176]	Loss: 1.9219
Training Epoch: 28 [18432/50176]	Loss: 1.8617
Training Epoch: 28 [19456/50176]	Loss: 1.9352
Training Epoch: 28 [20480/50176]	Loss: 1.7863
Training Epoch: 28 [21504/50176]	Loss: 1.8861
Training Epoch: 28 [22528/50176]	Loss: 1.9303
Training Epoch: 28 [23552/50176]	Loss: 1.9229
Training Epoch: 28 [24576/50176]	Loss: 1.7430
Training Epoch: 28 [25600/50176]	Loss: 1.8868
Training Epoch: 28 [26624/50176]	Loss: 1.8612
Training Epoch: 28 [27648/50176]	Loss: 1.9760
Training Epoch: 28 [28672/50176]	Loss: 1.8812
Training Epoch: 28 [29696/50176]	Loss: 1.8838
Training Epoch: 28 [30720/50176]	Loss: 1.8742
Training Epoch: 28 [31744/50176]	Loss: 1.9266
Training Epoch: 28 [32768/50176]	Loss: 1.8565
Training Epoch: 28 [33792/50176]	Loss: 1.9006
Training Epoch: 28 [34816/50176]	Loss: 1.8357
Training Epoch: 28 [35840/50176]	Loss: 1.8253
Training Epoch: 28 [36864/50176]	Loss: 1.8711
Training Epoch: 28 [37888/50176]	Loss: 1.8600
Training Epoch: 28 [38912/50176]	Loss: 1.8264
Training Epoch: 28 [39936/50176]	Loss: 1.9319
Training Epoch: 28 [40960/50176]	Loss: 2.0001
Training Epoch: 28 [41984/50176]	Loss: 1.8588
Training Epoch: 28 [43008/50176]	Loss: 1.8716
Training Epoch: 28 [44032/50176]	Loss: 1.7927
Training Epoch: 28 [45056/50176]	Loss: 2.0093
Training Epoch: 28 [46080/50176]	Loss: 1.9232
Training Epoch: 28 [47104/50176]	Loss: 1.8586
Training Epoch: 28 [48128/50176]	Loss: 1.8459
Training Epoch: 28 [49152/50176]	Loss: 1.8363
Training Epoch: 28 [50176/50176]	Loss: 1.8912
2022-12-06 18:34:51.872 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:34:51,908 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.72 energy=470.92
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Up to epoch 29: time=1443.12, energy=196460.45, cost=224503.10
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:34:51,908 [ZeusDataLoader(train)] Expected next epoch: time=1490.22, energy=203148.33, cost=231968.60
2022-12-06 13:34:51,909 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.6465, Accuracy: 0.0098
2022-12-06 13:34:52,149 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:34:52,149 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:34:52.151 [ZeusMonitor] Monitor started.
2022-12-06 18:34:52.151 [ZeusMonitor] Running indefinitely. 2022-12-06 18:34:52.151 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:34:52.151 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 13:35:36,269 [ZeusDataLoader(train)] train epoch 30 done: time=44.35 energy=6236.09
2022-12-06 13:35:36,273 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 1.7547
Training Epoch: 29 [2048/50176]	Loss: 1.7895
Training Epoch: 29 [3072/50176]	Loss: 1.7466
Training Epoch: 29 [4096/50176]	Loss: 1.8221
Training Epoch: 29 [5120/50176]	Loss: 1.8557
Training Epoch: 29 [6144/50176]	Loss: 1.8434
Training Epoch: 29 [7168/50176]	Loss: 1.7766
Training Epoch: 29 [8192/50176]	Loss: 1.7287
Training Epoch: 29 [9216/50176]	Loss: 1.8457
Training Epoch: 29 [10240/50176]	Loss: 1.7624
Training Epoch: 29 [11264/50176]	Loss: 1.8064
Training Epoch: 29 [12288/50176]	Loss: 1.8002
Training Epoch: 29 [13312/50176]	Loss: 1.6956
Training Epoch: 29 [14336/50176]	Loss: 1.7162
Training Epoch: 29 [15360/50176]	Loss: 1.8894
Training Epoch: 29 [16384/50176]	Loss: 1.7685
Training Epoch: 29 [17408/50176]	Loss: 1.7219
Training Epoch: 29 [18432/50176]	Loss: 1.9360
Training Epoch: 29 [19456/50176]	Loss: 1.9449
Training Epoch: 29 [20480/50176]	Loss: 1.8249
Training Epoch: 29 [21504/50176]	Loss: 1.8543
Training Epoch: 29 [22528/50176]	Loss: 1.7514
Training Epoch: 29 [23552/50176]	Loss: 1.7999
Training Epoch: 29 [24576/50176]	Loss: 1.7998
Training Epoch: 29 [25600/50176]	Loss: 1.7854
Training Epoch: 29 [26624/50176]	Loss: 1.8370
Training Epoch: 29 [27648/50176]	Loss: 1.8698
Training Epoch: 29 [28672/50176]	Loss: 1.7519
Training Epoch: 29 [29696/50176]	Loss: 1.7714
Training Epoch: 29 [30720/50176]	Loss: 1.9042
Training Epoch: 29 [31744/50176]	Loss: 1.8741
Training Epoch: 29 [32768/50176]	Loss: 1.8607
Training Epoch: 29 [33792/50176]	Loss: 1.8372
Training Epoch: 29 [34816/50176]	Loss: 1.7966
Training Epoch: 29 [35840/50176]	Loss: 1.7405
Training Epoch: 29 [36864/50176]	Loss: 1.8332
Training Epoch: 29 [37888/50176]	Loss: 1.8169
Training Epoch: 29 [38912/50176]	Loss: 1.8598
Training Epoch: 29 [39936/50176]	Loss: 1.8592
Training Epoch: 29 [40960/50176]	Loss: 1.8296
Training Epoch: 29 [41984/50176]	Loss: 1.7986
Training Epoch: 29 [43008/50176]	Loss: 1.8381
Training Epoch: 29 [44032/50176]	Loss: 1.8478
Training Epoch: 29 [45056/50176]	Loss: 1.8681
Training Epoch: 29 [46080/50176]	Loss: 1.8516
Training Epoch: 29 [47104/50176]	Loss: 1.8325
Training Epoch: 29 [48128/50176]	Loss: 1.8976
Training Epoch: 29 [49152/50176]	Loss: 1.8418
Training Epoch: 29 [50176/50176]	Loss: 1.8727
2022-12-06 18:35:40.092 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:35:40,107 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.83 energy=478.75
2022-12-06 13:35:40,107 [ZeusDataLoader(train)] Up to epoch 30: time=1491.30, energy=203175.29, cost=232076.04
2022-12-06 13:35:40,108 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:35:40,108 [ZeusDataLoader(train)] Expected next epoch: time=1538.40, energy=209863.17, cost=239541.54
2022-12-06 13:35:40,109 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.1057, Accuracy: 0.0101
2022-12-06 13:35:40,350 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:35:40,350 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:35:40.352 [ZeusMonitor] Monitor started.
2022-12-06 18:35:40.352 [ZeusMonitor] Running indefinitely. 2022-12-06 18:35:40.352 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:35:40.352 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 13:36:24,429 [ZeusDataLoader(train)] train epoch 31 done: time=44.31 energy=6236.83
2022-12-06 13:36:24,433 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 1.8563
Training Epoch: 30 [2048/50176]	Loss: 1.8101
Training Epoch: 30 [3072/50176]	Loss: 1.8716
Training Epoch: 30 [4096/50176]	Loss: 1.7705
Training Epoch: 30 [5120/50176]	Loss: 1.7146
Training Epoch: 30 [6144/50176]	Loss: 1.7339
Training Epoch: 30 [7168/50176]	Loss: 1.7891
Training Epoch: 30 [8192/50176]	Loss: 1.7695
Training Epoch: 30 [9216/50176]	Loss: 1.7494
Training Epoch: 30 [10240/50176]	Loss: 1.8114
Training Epoch: 30 [11264/50176]	Loss: 1.7326
Training Epoch: 30 [12288/50176]	Loss: 1.8145
Training Epoch: 30 [13312/50176]	Loss: 1.8038
Training Epoch: 30 [14336/50176]	Loss: 1.7786
Training Epoch: 30 [15360/50176]	Loss: 1.8014
Training Epoch: 30 [16384/50176]	Loss: 1.8070
Training Epoch: 30 [17408/50176]	Loss: 1.7626
Training Epoch: 30 [18432/50176]	Loss: 1.7279
Training Epoch: 30 [19456/50176]	Loss: 1.7751
Training Epoch: 30 [20480/50176]	Loss: 1.7790
Training Epoch: 30 [21504/50176]	Loss: 1.7347
Training Epoch: 30 [22528/50176]	Loss: 1.7970
Training Epoch: 30 [23552/50176]	Loss: 1.7225
Training Epoch: 30 [24576/50176]	Loss: 1.7857
Training Epoch: 30 [25600/50176]	Loss: 1.7450
Training Epoch: 30 [26624/50176]	Loss: 1.6944
Training Epoch: 30 [27648/50176]	Loss: 1.7681
Training Epoch: 30 [28672/50176]	Loss: 1.8656
Training Epoch: 30 [29696/50176]	Loss: 1.7314
Training Epoch: 30 [30720/50176]	Loss: 1.7677
Training Epoch: 30 [31744/50176]	Loss: 1.7710
Training Epoch: 30 [32768/50176]	Loss: 1.7658
Training Epoch: 30 [33792/50176]	Loss: 1.8624
Training Epoch: 30 [34816/50176]	Loss: 1.8146
Training Epoch: 30 [35840/50176]	Loss: 1.8607
Training Epoch: 30 [36864/50176]	Loss: 1.7723
Training Epoch: 30 [37888/50176]	Loss: 1.7660
Training Epoch: 30 [38912/50176]	Loss: 1.8308
Training Epoch: 30 [39936/50176]	Loss: 1.7578
Training Epoch: 30 [40960/50176]	Loss: 1.8615
Training Epoch: 30 [41984/50176]	Loss: 1.8284
Training Epoch: 30 [43008/50176]	Loss: 1.8386
Training Epoch: 30 [44032/50176]	Loss: 1.7532
Training Epoch: 30 [45056/50176]	Loss: 1.7441
Training Epoch: 30 [46080/50176]	Loss: 1.7852
Training Epoch: 30 [47104/50176]	Loss: 1.7704
Training Epoch: 30 [48128/50176]	Loss: 1.7573
Training Epoch: 30 [49152/50176]	Loss: 1.9282
Training Epoch: 30 [50176/50176]	Loss: 1.8753
2022-12-06 18:36:28.189 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:36:28,234 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.79 energy=472.95
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Up to epoch 31: time=1539.40, energy=209885.07, cost=239640.19
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:36:28,235 [ZeusDataLoader(train)] Expected next epoch: time=1586.51, energy=216572.95, cost=247105.69
2022-12-06 13:36:28,236 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0501, Accuracy: 0.0122
2022-12-06 13:36:28,477 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:36:28,478 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:36:28.480 [ZeusMonitor] Monitor started.
2022-12-06 18:36:28.480 [ZeusMonitor] Running indefinitely. 2022-12-06 18:36:28.480 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:36:28.480 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 13:37:12,541 [ZeusDataLoader(train)] train epoch 32 done: time=44.30 energy=6233.18
2022-12-06 13:37:12,545 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 1.7322
Training Epoch: 31 [2048/50176]	Loss: 1.6498
Training Epoch: 31 [3072/50176]	Loss: 1.7626
Training Epoch: 31 [4096/50176]	Loss: 1.7719
Training Epoch: 31 [5120/50176]	Loss: 1.7511
Training Epoch: 31 [6144/50176]	Loss: 1.7444
Training Epoch: 31 [7168/50176]	Loss: 1.6678
Training Epoch: 31 [8192/50176]	Loss: 1.7363
Training Epoch: 31 [9216/50176]	Loss: 1.6827
Training Epoch: 31 [10240/50176]	Loss: 1.7787
Training Epoch: 31 [11264/50176]	Loss: 1.7320
Training Epoch: 31 [12288/50176]	Loss: 1.7201
Training Epoch: 31 [13312/50176]	Loss: 1.7828
Training Epoch: 31 [14336/50176]	Loss: 1.6016
Training Epoch: 31 [15360/50176]	Loss: 1.6384
Training Epoch: 31 [16384/50176]	Loss: 1.7558
Training Epoch: 31 [17408/50176]	Loss: 1.7567
Training Epoch: 31 [18432/50176]	Loss: 1.7801
Training Epoch: 31 [19456/50176]	Loss: 1.7960
Training Epoch: 31 [20480/50176]	Loss: 1.8050
Training Epoch: 31 [21504/50176]	Loss: 1.8164
Training Epoch: 31 [22528/50176]	Loss: 1.7576
Training Epoch: 31 [23552/50176]	Loss: 1.7866
Training Epoch: 31 [24576/50176]	Loss: 1.7216
Training Epoch: 31 [25600/50176]	Loss: 1.8123
Training Epoch: 31 [26624/50176]	Loss: 1.7460
Training Epoch: 31 [27648/50176]	Loss: 1.6814
Training Epoch: 31 [28672/50176]	Loss: 1.7144
Training Epoch: 31 [29696/50176]	Loss: 1.7624
Training Epoch: 31 [30720/50176]	Loss: 1.7281
Training Epoch: 31 [31744/50176]	Loss: 1.7751
Training Epoch: 31 [32768/50176]	Loss: 1.8437
Training Epoch: 31 [33792/50176]	Loss: 1.7156
Training Epoch: 31 [34816/50176]	Loss: 1.7505
Training Epoch: 31 [35840/50176]	Loss: 1.7361
Training Epoch: 31 [36864/50176]	Loss: 1.8127
Training Epoch: 31 [37888/50176]	Loss: 1.8280
Training Epoch: 31 [38912/50176]	Loss: 1.8223
Training Epoch: 31 [39936/50176]	Loss: 1.8128
Training Epoch: 31 [40960/50176]	Loss: 1.7767
Training Epoch: 31 [41984/50176]	Loss: 1.7307
Training Epoch: 31 [43008/50176]	Loss: 1.6802
Training Epoch: 31 [44032/50176]	Loss: 1.7814
Training Epoch: 31 [45056/50176]	Loss: 1.7577
Training Epoch: 31 [46080/50176]	Loss: 1.7460
Training Epoch: 31 [47104/50176]	Loss: 1.7638
Training Epoch: 31 [48128/50176]	Loss: 1.7932
Training Epoch: 31 [49152/50176]	Loss: 1.7532
Training Epoch: 31 [50176/50176]	Loss: 1.7055
2022-12-06 18:37:16.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:37:16,465 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.91 energy=488.25
2022-12-06 13:37:16,465 [ZeusDataLoader(train)] Up to epoch 32: time=1587.61, energy=216606.51, cost=247219.20
2022-12-06 13:37:16,466 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:37:16,466 [ZeusDataLoader(train)] Expected next epoch: time=1634.71, energy=223294.39, cost=254684.70
2022-12-06 13:37:16,467 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0154, Accuracy: 0.0104
2022-12-06 13:37:16,655 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:37:16,656 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:37:16.660 [ZeusMonitor] Monitor started.
2022-12-06 18:37:16.660 [ZeusMonitor] Running indefinitely. 2022-12-06 18:37:16.660 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:37:16.660 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 13:38:00,809 [ZeusDataLoader(train)] train epoch 33 done: time=44.33 energy=6235.38
2022-12-06 13:38:00,812 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 1.6645
Training Epoch: 32 [2048/50176]	Loss: 1.5984
Training Epoch: 32 [3072/50176]	Loss: 1.7215
Training Epoch: 32 [4096/50176]	Loss: 1.7256
Training Epoch: 32 [5120/50176]	Loss: 1.7051
Training Epoch: 32 [6144/50176]	Loss: 1.7490
Training Epoch: 32 [7168/50176]	Loss: 1.7631
Training Epoch: 32 [8192/50176]	Loss: 1.6432
Training Epoch: 32 [9216/50176]	Loss: 1.6579
Training Epoch: 32 [10240/50176]	Loss: 1.7222
Training Epoch: 32 [11264/50176]	Loss: 1.7806
Training Epoch: 32 [12288/50176]	Loss: 1.7545
Training Epoch: 32 [13312/50176]	Loss: 1.7143
Training Epoch: 32 [14336/50176]	Loss: 1.7892
Training Epoch: 32 [15360/50176]	Loss: 1.6869
Training Epoch: 32 [16384/50176]	Loss: 1.6869
Training Epoch: 32 [17408/50176]	Loss: 1.7282
Training Epoch: 32 [18432/50176]	Loss: 1.7241
Training Epoch: 32 [19456/50176]	Loss: 1.7216
Training Epoch: 32 [20480/50176]	Loss: 1.7457
Training Epoch: 32 [21504/50176]	Loss: 1.7460
Training Epoch: 32 [22528/50176]	Loss: 1.7992
Training Epoch: 32 [23552/50176]	Loss: 1.8007
Training Epoch: 32 [24576/50176]	Loss: 1.7298
Training Epoch: 32 [25600/50176]	Loss: 1.7522
Training Epoch: 32 [26624/50176]	Loss: 1.6598
Training Epoch: 32 [27648/50176]	Loss: 1.6995
Training Epoch: 32 [28672/50176]	Loss: 1.7099
Training Epoch: 32 [29696/50176]	Loss: 1.7203
Training Epoch: 32 [30720/50176]	Loss: 1.7370
Training Epoch: 32 [31744/50176]	Loss: 1.6753
Training Epoch: 32 [32768/50176]	Loss: 1.6348
Training Epoch: 32 [33792/50176]	Loss: 1.7258
Training Epoch: 32 [34816/50176]	Loss: 1.7198
Training Epoch: 32 [35840/50176]	Loss: 1.6412
Training Epoch: 32 [36864/50176]	Loss: 1.7831
Training Epoch: 32 [37888/50176]	Loss: 1.6951
Training Epoch: 32 [38912/50176]	Loss: 1.7150
Training Epoch: 32 [39936/50176]	Loss: 1.7226
Training Epoch: 32 [40960/50176]	Loss: 1.6814
Training Epoch: 32 [41984/50176]	Loss: 1.6835
Training Epoch: 32 [43008/50176]	Loss: 1.6866
Training Epoch: 32 [44032/50176]	Loss: 1.8406
Training Epoch: 32 [45056/50176]	Loss: 1.7051
Training Epoch: 32 [46080/50176]	Loss: 1.7788
Training Epoch: 32 [47104/50176]	Loss: 1.7615
Training Epoch: 32 [48128/50176]	Loss: 1.7574
Training Epoch: 32 [49152/50176]	Loss: 1.7726
Training Epoch: 32 [50176/50176]	Loss: 1.7373
2022-12-06 18:38:04.505 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:38:04,516 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.70 energy=472.93
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Up to epoch 33: time=1635.64, energy=223314.82, cost=254775.99
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:38:04,516 [ZeusDataLoader(train)] Expected next epoch: time=1682.74, energy=230002.69, cost=262241.49
2022-12-06 13:38:04,517 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0098, Accuracy: 0.0189
2022-12-06 13:38:04,757 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:38:04,758 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:38:04.759 [ZeusMonitor] Monitor started.
2022-12-06 18:38:04.759 [ZeusMonitor] Running indefinitely. 2022-12-06 18:38:04.759 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:38:04.759 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 13:38:48,703 [ZeusDataLoader(train)] train epoch 34 done: time=44.18 energy=6223.27
2022-12-06 13:38:48,706 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 1.5598
Training Epoch: 33 [2048/50176]	Loss: 1.5922
Training Epoch: 33 [3072/50176]	Loss: 1.7017
Training Epoch: 33 [4096/50176]	Loss: 1.6723
Training Epoch: 33 [5120/50176]	Loss: 1.7692
Training Epoch: 33 [6144/50176]	Loss: 1.5703
Training Epoch: 33 [7168/50176]	Loss: 1.7561
Training Epoch: 33 [8192/50176]	Loss: 1.6595
Training Epoch: 33 [9216/50176]	Loss: 1.7048
Training Epoch: 33 [10240/50176]	Loss: 1.6591
Training Epoch: 33 [11264/50176]	Loss: 1.7607
Training Epoch: 33 [12288/50176]	Loss: 1.6691
Training Epoch: 33 [13312/50176]	Loss: 1.7001
Training Epoch: 33 [14336/50176]	Loss: 1.7686
Training Epoch: 33 [15360/50176]	Loss: 1.6473
Training Epoch: 33 [16384/50176]	Loss: 1.6359
Training Epoch: 33 [17408/50176]	Loss: 1.5629
Training Epoch: 33 [18432/50176]	Loss: 1.7119
Training Epoch: 33 [19456/50176]	Loss: 1.7447
Training Epoch: 33 [20480/50176]	Loss: 1.6205
Training Epoch: 33 [21504/50176]	Loss: 1.7690
Training Epoch: 33 [22528/50176]	Loss: 1.6478
Training Epoch: 33 [23552/50176]	Loss: 1.7772
Training Epoch: 33 [24576/50176]	Loss: 1.6961
Training Epoch: 33 [25600/50176]	Loss: 1.6730
Training Epoch: 33 [26624/50176]	Loss: 1.6027
Training Epoch: 33 [27648/50176]	Loss: 1.6589
Training Epoch: 33 [28672/50176]	Loss: 1.7546
Training Epoch: 33 [29696/50176]	Loss: 1.6308
Training Epoch: 33 [30720/50176]	Loss: 1.7062
Training Epoch: 33 [31744/50176]	Loss: 1.6883
Training Epoch: 33 [32768/50176]	Loss: 1.6217
Training Epoch: 33 [33792/50176]	Loss: 1.7600
Training Epoch: 33 [34816/50176]	Loss: 1.7090
Training Epoch: 33 [35840/50176]	Loss: 1.6826
Training Epoch: 33 [36864/50176]	Loss: 1.6502
Training Epoch: 33 [37888/50176]	Loss: 1.7045
Training Epoch: 33 [38912/50176]	Loss: 1.6969
Training Epoch: 33 [39936/50176]	Loss: 1.6721
Training Epoch: 33 [40960/50176]	Loss: 1.7365
Training Epoch: 33 [41984/50176]	Loss: 1.7119
Training Epoch: 33 [43008/50176]	Loss: 1.7252
Training Epoch: 33 [44032/50176]	Loss: 1.6535
Training Epoch: 33 [45056/50176]	Loss: 1.7315
Training Epoch: 33 [46080/50176]	Loss: 1.6185
Training Epoch: 33 [47104/50176]	Loss: 1.6853
Training Epoch: 33 [48128/50176]	Loss: 1.6678
Training Epoch: 33 [49152/50176]	Loss: 1.7151
Training Epoch: 33 [50176/50176]	Loss: 1.7147
2022-12-06 18:38:52.453 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:38:52,482 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.77 energy=473.95
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Up to epoch 34: time=1683.59, energy=230012.04, cost=262319.80
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:38:52,482 [ZeusDataLoader(train)] Expected next epoch: time=1730.69, energy=236699.92, cost=269785.29
2022-12-06 13:38:52,483 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0500, Accuracy: 0.0097
2022-12-06 13:38:52,672 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:38:52,673 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:38:52.676 [ZeusMonitor] Monitor started.
2022-12-06 18:38:52.676 [ZeusMonitor] Running indefinitely. 2022-12-06 18:38:52.676 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:38:52.676 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 13:39:37,062 [ZeusDataLoader(train)] train epoch 35 done: time=44.57 energy=6255.56
2022-12-06 13:39:37,066 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 1.6378
Training Epoch: 34 [2048/50176]	Loss: 1.6353
Training Epoch: 34 [3072/50176]	Loss: 1.6521
Training Epoch: 34 [4096/50176]	Loss: 1.5771
Training Epoch: 34 [5120/50176]	Loss: 1.6339
Training Epoch: 34 [6144/50176]	Loss: 1.7177
Training Epoch: 34 [7168/50176]	Loss: 1.5831
Training Epoch: 34 [8192/50176]	Loss: 1.6664
Training Epoch: 34 [9216/50176]	Loss: 1.6104
Training Epoch: 34 [10240/50176]	Loss: 1.7409
Training Epoch: 34 [11264/50176]	Loss: 1.6142
Training Epoch: 34 [12288/50176]	Loss: 1.6340
Training Epoch: 34 [13312/50176]	Loss: 1.6532
Training Epoch: 34 [14336/50176]	Loss: 1.5636
Training Epoch: 34 [15360/50176]	Loss: 1.6269
Training Epoch: 34 [16384/50176]	Loss: 1.8305
Training Epoch: 34 [17408/50176]	Loss: 1.6431
Training Epoch: 34 [18432/50176]	Loss: 1.6174
Training Epoch: 34 [19456/50176]	Loss: 1.6031
Training Epoch: 34 [20480/50176]	Loss: 1.6928
Training Epoch: 34 [21504/50176]	Loss: 1.7073
Training Epoch: 34 [22528/50176]	Loss: 1.7390
Training Epoch: 34 [23552/50176]	Loss: 1.6634
Training Epoch: 34 [24576/50176]	Loss: 1.6135
Training Epoch: 34 [25600/50176]	Loss: 1.6902
Training Epoch: 34 [26624/50176]	Loss: 1.7757
Training Epoch: 34 [27648/50176]	Loss: 1.6744
Training Epoch: 34 [28672/50176]	Loss: 1.7184
Training Epoch: 34 [29696/50176]	Loss: 1.7279
Training Epoch: 34 [30720/50176]	Loss: 1.7029
Training Epoch: 34 [31744/50176]	Loss: 1.7311
Training Epoch: 34 [32768/50176]	Loss: 1.6756
Training Epoch: 34 [33792/50176]	Loss: 1.6709
Training Epoch: 34 [34816/50176]	Loss: 1.6877
Training Epoch: 34 [35840/50176]	Loss: 1.6302
Training Epoch: 34 [36864/50176]	Loss: 1.7505
Training Epoch: 34 [37888/50176]	Loss: 1.6327
Training Epoch: 34 [38912/50176]	Loss: 1.6022
Training Epoch: 34 [39936/50176]	Loss: 1.6230
Training Epoch: 34 [40960/50176]	Loss: 1.6652
Training Epoch: 34 [41984/50176]	Loss: 1.6279
Training Epoch: 34 [43008/50176]	Loss: 1.5934
Training Epoch: 34 [44032/50176]	Loss: 1.6964
Training Epoch: 34 [45056/50176]	Loss: 1.7242
Training Epoch: 34 [46080/50176]	Loss: 1.6314
Training Epoch: 34 [47104/50176]	Loss: 1.6247
Training Epoch: 34 [48128/50176]	Loss: 1.6960
Training Epoch: 34 [49152/50176]	Loss: 1.6932
Training Epoch: 34 [50176/50176]	Loss: 1.6243
2022-12-06 18:39:40.790 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:39:40,806 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.73 energy=474.70
2022-12-06 13:39:40,806 [ZeusDataLoader(train)] Up to epoch 35: time=1731.89, energy=236742.30, cost=269911.45
2022-12-06 13:39:40,807 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:39:40,807 [ZeusDataLoader(train)] Expected next epoch: time=1778.99, energy=243430.17, cost=277376.95
2022-12-06 13:39:40,808 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0221, Accuracy: 0.0115
2022-12-06 13:39:41,044 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:39:41,044 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:39:41.046 [ZeusMonitor] Monitor started.
2022-12-06 18:39:41.046 [ZeusMonitor] Running indefinitely. 2022-12-06 18:39:41.046 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:39:41.046 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 13:40:25,507 [ZeusDataLoader(train)] train epoch 36 done: time=44.69 energy=6260.80
2022-12-06 13:40:25,511 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 1.6085
Training Epoch: 35 [2048/50176]	Loss: 1.6237
Training Epoch: 35 [3072/50176]	Loss: 1.5881
Training Epoch: 35 [4096/50176]	Loss: 1.5678
Training Epoch: 35 [5120/50176]	Loss: 1.6119
Training Epoch: 35 [6144/50176]	Loss: 1.5139
Training Epoch: 35 [7168/50176]	Loss: 1.6481
Training Epoch: 35 [8192/50176]	Loss: 1.6124
Training Epoch: 35 [9216/50176]	Loss: 1.4761
Training Epoch: 35 [10240/50176]	Loss: 1.6517
Training Epoch: 35 [11264/50176]	Loss: 1.6442
Training Epoch: 35 [12288/50176]	Loss: 1.7255
Training Epoch: 35 [13312/50176]	Loss: 1.6770
Training Epoch: 35 [14336/50176]	Loss: 1.5769
Training Epoch: 35 [15360/50176]	Loss: 1.5333
Training Epoch: 35 [16384/50176]	Loss: 1.6731
Training Epoch: 35 [17408/50176]	Loss: 1.6550
Training Epoch: 35 [18432/50176]	Loss: 1.5248
Training Epoch: 35 [19456/50176]	Loss: 1.6588
Training Epoch: 35 [20480/50176]	Loss: 1.4585
Training Epoch: 35 [21504/50176]	Loss: 1.5609
Training Epoch: 35 [22528/50176]	Loss: 1.6592
Training Epoch: 35 [23552/50176]	Loss: 1.5488
Training Epoch: 35 [24576/50176]	Loss: 1.6554
Training Epoch: 35 [25600/50176]	Loss: 1.6433
Training Epoch: 35 [26624/50176]	Loss: 1.5783
Training Epoch: 35 [27648/50176]	Loss: 1.6153
Training Epoch: 35 [28672/50176]	Loss: 1.6561
Training Epoch: 35 [29696/50176]	Loss: 1.5862
Training Epoch: 35 [30720/50176]	Loss: 1.6246
Training Epoch: 35 [31744/50176]	Loss: 1.5518
Training Epoch: 35 [32768/50176]	Loss: 1.5772
Training Epoch: 35 [33792/50176]	Loss: 1.5970
Training Epoch: 35 [34816/50176]	Loss: 1.5155
Training Epoch: 35 [35840/50176]	Loss: 1.5786
Training Epoch: 35 [36864/50176]	Loss: 1.6222
Training Epoch: 35 [37888/50176]	Loss: 1.6630
Training Epoch: 35 [38912/50176]	Loss: 1.6285
Training Epoch: 35 [39936/50176]	Loss: 1.6797
Training Epoch: 35 [40960/50176]	Loss: 1.5629
Training Epoch: 35 [41984/50176]	Loss: 1.7461
Training Epoch: 35 [43008/50176]	Loss: 1.5434
Training Epoch: 35 [44032/50176]	Loss: 1.6407
Training Epoch: 35 [45056/50176]	Loss: 1.6989
Training Epoch: 35 [46080/50176]	Loss: 1.6335
Training Epoch: 35 [47104/50176]	Loss: 1.7115
Training Epoch: 35 [48128/50176]	Loss: 1.6773
Training Epoch: 35 [49152/50176]	Loss: 1.6345
Training Epoch: 35 [50176/50176]	Loss: 1.6472
2022-12-06 18:40:29.255 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:40:29,279 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.76 energy=467.13
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Up to epoch 36: time=1780.34, energy=243470.23, cost=277514.91
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:40:29,279 [ZeusDataLoader(train)] Expected next epoch: time=1827.44, energy=250158.10, cost=284980.40
2022-12-06 13:40:29,280 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0655, Accuracy: 0.0124
2022-12-06 13:40:29,507 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:40:29,508 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:40:29.509 [ZeusMonitor] Monitor started.
2022-12-06 18:40:29.510 [ZeusMonitor] Running indefinitely. 2022-12-06 18:40:29.510 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:40:29.510 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 13:41:13,546 [ZeusDataLoader(train)] train epoch 37 done: time=44.26 energy=6221.96
2022-12-06 13:41:13,549 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 1.5121
Training Epoch: 36 [2048/50176]	Loss: 1.5035
Training Epoch: 36 [3072/50176]	Loss: 1.5243
Training Epoch: 36 [4096/50176]	Loss: 1.5380
Training Epoch: 36 [5120/50176]	Loss: 1.5938
Training Epoch: 36 [6144/50176]	Loss: 1.5464
Training Epoch: 36 [7168/50176]	Loss: 1.5802
Training Epoch: 36 [8192/50176]	Loss: 1.5528
Training Epoch: 36 [9216/50176]	Loss: 1.5708
Training Epoch: 36 [10240/50176]	Loss: 1.6977
Training Epoch: 36 [11264/50176]	Loss: 1.6333
Training Epoch: 36 [12288/50176]	Loss: 1.6262
Training Epoch: 36 [13312/50176]	Loss: 1.5801
Training Epoch: 36 [14336/50176]	Loss: 1.5377
Training Epoch: 36 [15360/50176]	Loss: 1.5954
Training Epoch: 36 [16384/50176]	Loss: 1.5728
Training Epoch: 36 [17408/50176]	Loss: 1.5150
Training Epoch: 36 [18432/50176]	Loss: 1.6184
Training Epoch: 36 [19456/50176]	Loss: 1.6248
Training Epoch: 36 [20480/50176]	Loss: 1.6011
Training Epoch: 36 [21504/50176]	Loss: 1.5950
Training Epoch: 36 [22528/50176]	Loss: 1.6438
Training Epoch: 36 [23552/50176]	Loss: 1.5748
Training Epoch: 36 [24576/50176]	Loss: 1.5905
Training Epoch: 36 [25600/50176]	Loss: 1.6821
Training Epoch: 36 [26624/50176]	Loss: 1.6349
Training Epoch: 36 [27648/50176]	Loss: 1.5733
Training Epoch: 36 [28672/50176]	Loss: 1.6239
Training Epoch: 36 [29696/50176]	Loss: 1.6375
Training Epoch: 36 [30720/50176]	Loss: 1.5849
Training Epoch: 36 [31744/50176]	Loss: 1.5928
Training Epoch: 36 [32768/50176]	Loss: 1.5926
Training Epoch: 36 [33792/50176]	Loss: 1.5837
Training Epoch: 36 [34816/50176]	Loss: 1.5862
Training Epoch: 36 [35840/50176]	Loss: 1.5282
Training Epoch: 36 [36864/50176]	Loss: 1.6001
Training Epoch: 36 [37888/50176]	Loss: 1.5901
Training Epoch: 36 [38912/50176]	Loss: 1.5175
Training Epoch: 36 [39936/50176]	Loss: 1.5658
Training Epoch: 36 [40960/50176]	Loss: 1.5843
Training Epoch: 36 [41984/50176]	Loss: 1.5848
Training Epoch: 36 [43008/50176]	Loss: 1.6217
Training Epoch: 36 [44032/50176]	Loss: 1.6365
Training Epoch: 36 [45056/50176]	Loss: 1.6668
Training Epoch: 36 [46080/50176]	Loss: 1.5735
Training Epoch: 36 [47104/50176]	Loss: 1.6007
Training Epoch: 36 [48128/50176]	Loss: 1.5419
Training Epoch: 36 [49152/50176]	Loss: 1.5856
Training Epoch: 36 [50176/50176]	Loss: 1.5270
2022-12-06 18:41:17.321 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:41:17,347 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.79 energy=494.05
2022-12-06 13:41:17,347 [ZeusDataLoader(train)] Up to epoch 37: time=1828.39, energy=250186.23, cost=285076.99
2022-12-06 13:41:17,347 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:41:17,348 [ZeusDataLoader(train)] Expected next epoch: time=1875.49, energy=256874.11, cost=292542.48
2022-12-06 13:41:17,348 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0495, Accuracy: 0.0164
2022-12-06 13:41:17,535 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:41:17,535 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:41:17.539 [ZeusMonitor] Monitor started.
2022-12-06 18:41:17.539 [ZeusMonitor] Running indefinitely. 2022-12-06 18:41:17.539 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:41:17.539 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 13:42:01,434 [ZeusDataLoader(train)] train epoch 38 done: time=44.08 energy=6221.68
2022-12-06 13:42:01,438 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 1.4872
Training Epoch: 37 [2048/50176]	Loss: 1.5410
Training Epoch: 37 [3072/50176]	Loss: 1.4828
Training Epoch: 37 [4096/50176]	Loss: 1.5733
Training Epoch: 37 [5120/50176]	Loss: 1.4362
Training Epoch: 37 [6144/50176]	Loss: 1.4338
Training Epoch: 37 [7168/50176]	Loss: 1.4860
Training Epoch: 37 [8192/50176]	Loss: 1.4970
Training Epoch: 37 [9216/50176]	Loss: 1.4805
Training Epoch: 37 [10240/50176]	Loss: 1.5154
Training Epoch: 37 [11264/50176]	Loss: 1.5660
Training Epoch: 37 [12288/50176]	Loss: 1.6284
Training Epoch: 37 [13312/50176]	Loss: 1.5019
Training Epoch: 37 [14336/50176]	Loss: 1.4905
Training Epoch: 37 [15360/50176]	Loss: 1.5985
Training Epoch: 37 [16384/50176]	Loss: 1.5046
Training Epoch: 37 [17408/50176]	Loss: 1.5776
Training Epoch: 37 [18432/50176]	Loss: 1.4884
Training Epoch: 37 [19456/50176]	Loss: 1.5355
Training Epoch: 37 [20480/50176]	Loss: 1.4746
Training Epoch: 37 [21504/50176]	Loss: 1.5991
Training Epoch: 37 [22528/50176]	Loss: 1.5581
Training Epoch: 37 [23552/50176]	Loss: 1.4579
Training Epoch: 37 [24576/50176]	Loss: 1.5061
Training Epoch: 37 [25600/50176]	Loss: 1.5045
Training Epoch: 37 [26624/50176]	Loss: 1.5695
Training Epoch: 37 [27648/50176]	Loss: 1.6364
Training Epoch: 37 [28672/50176]	Loss: 1.6242
Training Epoch: 37 [29696/50176]	Loss: 1.5557
Training Epoch: 37 [30720/50176]	Loss: 1.5433
Training Epoch: 37 [31744/50176]	Loss: 1.4814
Training Epoch: 37 [32768/50176]	Loss: 1.5896
Training Epoch: 37 [33792/50176]	Loss: 1.5897
Training Epoch: 37 [34816/50176]	Loss: 1.6066
Training Epoch: 37 [35840/50176]	Loss: 1.5363
Training Epoch: 37 [36864/50176]	Loss: 1.5874
Training Epoch: 37 [37888/50176]	Loss: 1.6103
Training Epoch: 37 [38912/50176]	Loss: 1.5537
Training Epoch: 37 [39936/50176]	Loss: 1.4723
Training Epoch: 37 [40960/50176]	Loss: 1.5637
Training Epoch: 37 [41984/50176]	Loss: 1.5493
Training Epoch: 37 [43008/50176]	Loss: 1.6678
Training Epoch: 37 [44032/50176]	Loss: 1.6075
Training Epoch: 37 [45056/50176]	Loss: 1.6766
Training Epoch: 37 [46080/50176]	Loss: 1.5541
Training Epoch: 37 [47104/50176]	Loss: 1.6508
Training Epoch: 37 [48128/50176]	Loss: 1.6641
Training Epoch: 37 [49152/50176]	Loss: 1.5705
Training Epoch: 37 [50176/50176]	Loss: 1.6164
2022-12-06 18:42:05.165 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:42:05,190 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.74 energy=470.38
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Up to epoch 38: time=1876.21, energy=256878.28, cost=292607.45
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:42:05,190 [ZeusDataLoader(train)] Expected next epoch: time=1923.31, energy=263566.16, cost=300072.95
2022-12-06 13:42:05,191 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0400, Accuracy: 0.0118
2022-12-06 13:42:05,433 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:42:05,434 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:42:05.436 [ZeusMonitor] Monitor started.
2022-12-06 18:42:05.436 [ZeusMonitor] Running indefinitely. 2022-12-06 18:42:05.436 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:42:05.436 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 13:42:49,231 [ZeusDataLoader(train)] train epoch 39 done: time=44.03 energy=6209.49
2022-12-06 13:42:49,234 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 1.5362
Training Epoch: 38 [2048/50176]	Loss: 1.5031
Training Epoch: 38 [3072/50176]	Loss: 1.4976
Training Epoch: 38 [4096/50176]	Loss: 1.4150
Training Epoch: 38 [5120/50176]	Loss: 1.5650
Training Epoch: 38 [6144/50176]	Loss: 1.4657
Training Epoch: 38 [7168/50176]	Loss: 1.5765
Training Epoch: 38 [8192/50176]	Loss: 1.5344
Training Epoch: 38 [9216/50176]	Loss: 1.5041
Training Epoch: 38 [10240/50176]	Loss: 1.5859
Training Epoch: 38 [11264/50176]	Loss: 1.6042
Training Epoch: 38 [12288/50176]	Loss: 1.4652
Training Epoch: 38 [13312/50176]	Loss: 1.5191
Training Epoch: 38 [14336/50176]	Loss: 1.4672
Training Epoch: 38 [15360/50176]	Loss: 1.5529
Training Epoch: 38 [16384/50176]	Loss: 1.4975
Training Epoch: 38 [17408/50176]	Loss: 1.4944
Training Epoch: 38 [18432/50176]	Loss: 1.6240
Training Epoch: 38 [19456/50176]	Loss: 1.5449
Training Epoch: 38 [20480/50176]	Loss: 1.4871
Training Epoch: 38 [21504/50176]	Loss: 1.5245
Training Epoch: 38 [22528/50176]	Loss: 1.5214
Training Epoch: 38 [23552/50176]	Loss: 1.5852
Training Epoch: 38 [24576/50176]	Loss: 1.5314
Training Epoch: 38 [25600/50176]	Loss: 1.4621
Training Epoch: 38 [26624/50176]	Loss: 1.5637
Training Epoch: 38 [27648/50176]	Loss: 1.5393
Training Epoch: 38 [28672/50176]	Loss: 1.5523
Training Epoch: 38 [29696/50176]	Loss: 1.4491
Training Epoch: 38 [30720/50176]	Loss: 1.5182
Training Epoch: 38 [31744/50176]	Loss: 1.5544
Training Epoch: 38 [32768/50176]	Loss: 1.5690
Training Epoch: 38 [33792/50176]	Loss: 1.6019
Training Epoch: 38 [34816/50176]	Loss: 1.5690
Training Epoch: 38 [35840/50176]	Loss: 1.4381
Training Epoch: 38 [36864/50176]	Loss: 1.5349
Training Epoch: 38 [37888/50176]	Loss: 1.5734
Training Epoch: 38 [38912/50176]	Loss: 1.4513
Training Epoch: 38 [39936/50176]	Loss: 1.5969
Training Epoch: 38 [40960/50176]	Loss: 1.6223
Training Epoch: 38 [41984/50176]	Loss: 1.5784
Training Epoch: 38 [43008/50176]	Loss: 1.7026
Training Epoch: 38 [44032/50176]	Loss: 1.5161
Training Epoch: 38 [45056/50176]	Loss: 1.5264
Training Epoch: 38 [46080/50176]	Loss: 1.4976
Training Epoch: 38 [47104/50176]	Loss: 1.5557
Training Epoch: 38 [48128/50176]	Loss: 1.5815
Training Epoch: 38 [49152/50176]	Loss: 1.6058
Training Epoch: 38 [50176/50176]	Loss: 1.5501
2022-12-06 18:42:53.025 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:42:53,050 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.81 energy=475.54
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Up to epoch 39: time=1924.05, energy=263563.31, cost=300135.88
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:42:53,050 [ZeusDataLoader(train)] Expected next epoch: time=1971.15, energy=270251.19, cost=307601.38
2022-12-06 13:42:53,051 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0429, Accuracy: 0.0099
2022-12-06 13:42:53,328 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:42:53,329 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:42:53.330 [ZeusMonitor] Monitor started.
2022-12-06 18:42:53.331 [ZeusMonitor] Running indefinitely. 2022-12-06 18:42:53.331 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:42:53.331 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 13:43:37,464 [ZeusDataLoader(train)] train epoch 40 done: time=44.40 energy=6238.41
2022-12-06 13:43:37,467 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 1.4511
Training Epoch: 39 [2048/50176]	Loss: 1.4870
Training Epoch: 39 [3072/50176]	Loss: 1.4926
Training Epoch: 39 [4096/50176]	Loss: 1.5809
Training Epoch: 39 [5120/50176]	Loss: 1.6259
Training Epoch: 39 [6144/50176]	Loss: 1.5634
Training Epoch: 39 [7168/50176]	Loss: 1.4176
Training Epoch: 39 [8192/50176]	Loss: 1.4818
Training Epoch: 39 [9216/50176]	Loss: 1.5183
Training Epoch: 39 [10240/50176]	Loss: 1.5319
Training Epoch: 39 [11264/50176]	Loss: 1.5005
Training Epoch: 39 [12288/50176]	Loss: 1.4728
Training Epoch: 39 [13312/50176]	Loss: 1.4914
Training Epoch: 39 [14336/50176]	Loss: 1.4027
Training Epoch: 39 [15360/50176]	Loss: 1.5366
Training Epoch: 39 [16384/50176]	Loss: 1.4030
Training Epoch: 39 [17408/50176]	Loss: 1.4541
Training Epoch: 39 [18432/50176]	Loss: 1.5012
Training Epoch: 39 [19456/50176]	Loss: 1.4854
Training Epoch: 39 [20480/50176]	Loss: 1.5707
Training Epoch: 39 [21504/50176]	Loss: 1.5655
Training Epoch: 39 [22528/50176]	Loss: 1.4420
Training Epoch: 39 [23552/50176]	Loss: 1.4875
Training Epoch: 39 [24576/50176]	Loss: 1.4492
Training Epoch: 39 [25600/50176]	Loss: 1.4811
Training Epoch: 39 [26624/50176]	Loss: 1.5420
Training Epoch: 39 [27648/50176]	Loss: 1.5908
Training Epoch: 39 [28672/50176]	Loss: 1.4151
Training Epoch: 39 [29696/50176]	Loss: 1.5564
Training Epoch: 39 [30720/50176]	Loss: 1.5276
Training Epoch: 39 [31744/50176]	Loss: 1.6015
Training Epoch: 39 [32768/50176]	Loss: 1.4256
Training Epoch: 39 [33792/50176]	Loss: 1.5807
Training Epoch: 39 [34816/50176]	Loss: 1.6445
Training Epoch: 39 [35840/50176]	Loss: 1.4837
Training Epoch: 39 [36864/50176]	Loss: 1.5166
Training Epoch: 39 [37888/50176]	Loss: 1.5257
Training Epoch: 39 [38912/50176]	Loss: 1.5366
Training Epoch: 39 [39936/50176]	Loss: 1.5851
Training Epoch: 39 [40960/50176]	Loss: 1.5895
Training Epoch: 39 [41984/50176]	Loss: 1.5695
Training Epoch: 39 [43008/50176]	Loss: 1.4679
Training Epoch: 39 [44032/50176]	Loss: 1.4472
Training Epoch: 39 [45056/50176]	Loss: 1.6267
Training Epoch: 39 [46080/50176]	Loss: 1.5585
Training Epoch: 39 [47104/50176]	Loss: 1.5937
Training Epoch: 39 [48128/50176]	Loss: 1.4756
Training Epoch: 39 [49152/50176]	Loss: 1.5154
Training Epoch: 39 [50176/50176]	Loss: 1.5411
2022-12-06 18:43:41.219 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:43:41,272 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.80 energy=473.54
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Up to epoch 40: time=1972.25, energy=270275.26, cost=307709.52
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:43:41,272 [ZeusDataLoader(train)] Expected next epoch: time=2019.35, energy=276963.14, cost=315175.01
2022-12-06 13:43:41,273 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0150, Accuracy: 0.0204
2022-12-06 13:43:41,465 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:43:41,466 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:43:41.469 [ZeusMonitor] Monitor started.
2022-12-06 18:43:41.469 [ZeusMonitor] Running indefinitely. 2022-12-06 18:43:41.470 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:43:41.470 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 13:44:25,442 [ZeusDataLoader(train)] train epoch 41 done: time=44.16 energy=6226.46
2022-12-06 13:44:25,446 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 1.4150
Training Epoch: 40 [2048/50176]	Loss: 1.4391
Training Epoch: 40 [3072/50176]	Loss: 1.3935
Training Epoch: 40 [4096/50176]	Loss: 1.4147
Training Epoch: 40 [5120/50176]	Loss: 1.4408
Training Epoch: 40 [6144/50176]	Loss: 1.4300
Training Epoch: 40 [7168/50176]	Loss: 1.4528
Training Epoch: 40 [8192/50176]	Loss: 1.3903
Training Epoch: 40 [9216/50176]	Loss: 1.4172
Training Epoch: 40 [10240/50176]	Loss: 1.4732
Training Epoch: 40 [11264/50176]	Loss: 1.4170
Training Epoch: 40 [12288/50176]	Loss: 1.4522
Training Epoch: 40 [13312/50176]	Loss: 1.4205
Training Epoch: 40 [14336/50176]	Loss: 1.4640
Training Epoch: 40 [15360/50176]	Loss: 1.4268
Training Epoch: 40 [16384/50176]	Loss: 1.4557
Training Epoch: 40 [17408/50176]	Loss: 1.3798
Training Epoch: 40 [18432/50176]	Loss: 1.5047
Training Epoch: 40 [19456/50176]	Loss: 1.4306
Training Epoch: 40 [20480/50176]	Loss: 1.5176
Training Epoch: 40 [21504/50176]	Loss: 1.4275
Training Epoch: 40 [22528/50176]	Loss: 1.4238
Training Epoch: 40 [23552/50176]	Loss: 1.5544
Training Epoch: 40 [24576/50176]	Loss: 1.4647
Training Epoch: 40 [25600/50176]	Loss: 1.4326
Training Epoch: 40 [26624/50176]	Loss: 1.5378
Training Epoch: 40 [27648/50176]	Loss: 1.4803
Training Epoch: 40 [28672/50176]	Loss: 1.4981
Training Epoch: 40 [29696/50176]	Loss: 1.4215
Training Epoch: 40 [30720/50176]	Loss: 1.4043
Training Epoch: 40 [31744/50176]	Loss: 1.4701
Training Epoch: 40 [32768/50176]	Loss: 1.5614
Training Epoch: 40 [33792/50176]	Loss: 1.5709
Training Epoch: 40 [34816/50176]	Loss: 1.3735
Training Epoch: 40 [35840/50176]	Loss: 1.4559
Training Epoch: 40 [36864/50176]	Loss: 1.4498
Training Epoch: 40 [37888/50176]	Loss: 1.4297
Training Epoch: 40 [38912/50176]	Loss: 1.4500
Training Epoch: 40 [39936/50176]	Loss: 1.5214
Training Epoch: 40 [40960/50176]	Loss: 1.5550
Training Epoch: 40 [41984/50176]	Loss: 1.4174
Training Epoch: 40 [43008/50176]	Loss: 1.6328
Training Epoch: 40 [44032/50176]	Loss: 1.5051
Training Epoch: 40 [45056/50176]	Loss: 1.6033
Training Epoch: 40 [46080/50176]	Loss: 1.5366
Training Epoch: 40 [47104/50176]	Loss: 1.4799
Training Epoch: 40 [48128/50176]	Loss: 1.5659
Training Epoch: 40 [49152/50176]	Loss: 1.5175
Training Epoch: 40 [50176/50176]	Loss: 1.5053
2022-12-06 18:44:29.146 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:44:29,156 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.70 energy=471.30
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Up to epoch 41: time=2020.11, energy=276973.02, cost=315246.39
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:44:29,156 [ZeusDataLoader(train)] Expected next epoch: time=2067.22, energy=283660.90, cost=322711.88
2022-12-06 13:44:29,157 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0253, Accuracy: 0.0164
2022-12-06 13:44:29,403 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:44:29,404 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:44:29.406 [ZeusMonitor] Monitor started.
2022-12-06 18:44:29.406 [ZeusMonitor] Running indefinitely. 2022-12-06 18:44:29.406 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:44:29.406 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 13:45:13,669 [ZeusDataLoader(train)] train epoch 42 done: time=44.50 energy=6246.97
2022-12-06 13:45:13,672 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 1.4418
Training Epoch: 41 [2048/50176]	Loss: 1.4356
Training Epoch: 41 [3072/50176]	Loss: 1.4645
Training Epoch: 41 [4096/50176]	Loss: 1.3903
Training Epoch: 41 [5120/50176]	Loss: 1.3821
Training Epoch: 41 [6144/50176]	Loss: 1.4546
Training Epoch: 41 [7168/50176]	Loss: 1.4773
Training Epoch: 41 [8192/50176]	Loss: 1.4560
Training Epoch: 41 [9216/50176]	Loss: 1.4740
Training Epoch: 41 [10240/50176]	Loss: 1.4838
Training Epoch: 41 [11264/50176]	Loss: 1.3910
Training Epoch: 41 [12288/50176]	Loss: 1.4306
Training Epoch: 41 [13312/50176]	Loss: 1.4334
Training Epoch: 41 [14336/50176]	Loss: 1.4935
Training Epoch: 41 [15360/50176]	Loss: 1.5324
Training Epoch: 41 [16384/50176]	Loss: 1.4628
Training Epoch: 41 [17408/50176]	Loss: 1.5494
Training Epoch: 41 [18432/50176]	Loss: 1.4442
Training Epoch: 41 [19456/50176]	Loss: 1.4886
Training Epoch: 41 [20480/50176]	Loss: 1.4597
Training Epoch: 41 [21504/50176]	Loss: 1.4109
Training Epoch: 41 [22528/50176]	Loss: 1.3875
Training Epoch: 41 [23552/50176]	Loss: 1.4550
Training Epoch: 41 [24576/50176]	Loss: 1.4647
Training Epoch: 41 [25600/50176]	Loss: 1.4659
Training Epoch: 41 [26624/50176]	Loss: 1.3614
Training Epoch: 41 [27648/50176]	Loss: 1.4683
Training Epoch: 41 [28672/50176]	Loss: 1.4864
Training Epoch: 41 [29696/50176]	Loss: 1.4622
Training Epoch: 41 [30720/50176]	Loss: 1.4712
Training Epoch: 41 [31744/50176]	Loss: 1.4677
Training Epoch: 41 [32768/50176]	Loss: 1.3983
Training Epoch: 41 [33792/50176]	Loss: 1.3996
Training Epoch: 41 [34816/50176]	Loss: 1.4479
Training Epoch: 41 [35840/50176]	Loss: 1.4737
Training Epoch: 41 [36864/50176]	Loss: 1.4944
Training Epoch: 41 [37888/50176]	Loss: 1.4988
Training Epoch: 41 [38912/50176]	Loss: 1.4128
Training Epoch: 41 [39936/50176]	Loss: 1.4759
Training Epoch: 41 [40960/50176]	Loss: 1.4714
Training Epoch: 41 [41984/50176]	Loss: 1.4161
Training Epoch: 41 [43008/50176]	Loss: 1.4679
Training Epoch: 41 [44032/50176]	Loss: 1.5388
Training Epoch: 41 [45056/50176]	Loss: 1.5355
Training Epoch: 41 [46080/50176]	Loss: 1.4481
Training Epoch: 41 [47104/50176]	Loss: 1.4020
Training Epoch: 41 [48128/50176]	Loss: 1.4898
Training Epoch: 41 [49152/50176]	Loss: 1.4197
Training Epoch: 41 [50176/50176]	Loss: 1.4332
2022-12-06 18:45:17.389 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:45:17,410 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.73 energy=471.17
2022-12-06 13:45:17,410 [ZeusDataLoader(train)] Up to epoch 42: time=2068.35, energy=283691.16, cost=322825.94
2022-12-06 13:45:17,410 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:45:17,411 [ZeusDataLoader(train)] Expected next epoch: time=2115.45, energy=290379.04, cost=330291.44
2022-12-06 13:45:17,412 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 3.1221, Accuracy: 0.0098
2022-12-06 13:45:17,654 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:45:17,654 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:45:17.656 [ZeusMonitor] Monitor started.
2022-12-06 18:45:17.656 [ZeusMonitor] Running indefinitely. 2022-12-06 18:45:17.656 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:45:17.656 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 13:46:01,715 [ZeusDataLoader(train)] train epoch 43 done: time=44.30 energy=6228.50
2022-12-06 13:46:01,719 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 1.3448
Training Epoch: 42 [2048/50176]	Loss: 1.2900
Training Epoch: 42 [3072/50176]	Loss: 1.4060
Training Epoch: 42 [4096/50176]	Loss: 1.4332
Training Epoch: 42 [5120/50176]	Loss: 1.4010
Training Epoch: 42 [6144/50176]	Loss: 1.4554
Training Epoch: 42 [7168/50176]	Loss: 1.3385
Training Epoch: 42 [8192/50176]	Loss: 1.3614
Training Epoch: 42 [9216/50176]	Loss: 1.4054
Training Epoch: 42 [10240/50176]	Loss: 1.4566
Training Epoch: 42 [11264/50176]	Loss: 1.3822
Training Epoch: 42 [12288/50176]	Loss: 1.4535
Training Epoch: 42 [13312/50176]	Loss: 1.3324
Training Epoch: 42 [14336/50176]	Loss: 1.4194
Training Epoch: 42 [15360/50176]	Loss: 1.3638
Training Epoch: 42 [16384/50176]	Loss: 1.3688
Training Epoch: 42 [17408/50176]	Loss: 1.3735
Training Epoch: 42 [18432/50176]	Loss: 1.3656
Training Epoch: 42 [19456/50176]	Loss: 1.3871
Training Epoch: 42 [20480/50176]	Loss: 1.3705
Training Epoch: 42 [21504/50176]	Loss: 1.4101
Training Epoch: 42 [22528/50176]	Loss: 1.4214
Training Epoch: 42 [23552/50176]	Loss: 1.4027
Training Epoch: 42 [24576/50176]	Loss: 1.4535
Training Epoch: 42 [25600/50176]	Loss: 1.5187
Training Epoch: 42 [26624/50176]	Loss: 1.3679
Training Epoch: 42 [27648/50176]	Loss: 1.4027
Training Epoch: 42 [28672/50176]	Loss: 1.3328
Training Epoch: 42 [29696/50176]	Loss: 1.4230
Training Epoch: 42 [30720/50176]	Loss: 1.3697
Training Epoch: 42 [31744/50176]	Loss: 1.4956
Training Epoch: 42 [32768/50176]	Loss: 1.3786
Training Epoch: 42 [33792/50176]	Loss: 1.3842
Training Epoch: 42 [34816/50176]	Loss: 1.4452
Training Epoch: 42 [35840/50176]	Loss: 1.4313
Training Epoch: 42 [36864/50176]	Loss: 1.5037
Training Epoch: 42 [37888/50176]	Loss: 1.5071
Training Epoch: 42 [38912/50176]	Loss: 1.4852
Training Epoch: 42 [39936/50176]	Loss: 1.3604
Training Epoch: 42 [40960/50176]	Loss: 1.4922
Training Epoch: 42 [41984/50176]	Loss: 1.3975
Training Epoch: 42 [43008/50176]	Loss: 1.4984
Training Epoch: 42 [44032/50176]	Loss: 1.4858
Training Epoch: 42 [45056/50176]	Loss: 1.4798
Training Epoch: 42 [46080/50176]	Loss: 1.4175
Training Epoch: 42 [47104/50176]	Loss: 1.4118
Training Epoch: 42 [48128/50176]	Loss: 1.4387
Training Epoch: 42 [49152/50176]	Loss: 1.4480
Training Epoch: 42 [50176/50176]	Loss: 1.5245
2022-12-06 18:46:05.454 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:46:05,512 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.79 energy=485.39
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Up to epoch 43: time=2116.43, energy=290405.05, cost=330390.00
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:46:05,513 [ZeusDataLoader(train)] Expected next epoch: time=2163.53, energy=297092.93, cost=337855.49
2022-12-06 13:46:05,514 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0211, Accuracy: 0.0104
2022-12-06 13:46:05,749 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:46:05,749 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:46:05.763 [ZeusMonitor] Monitor started.
2022-12-06 18:46:05.763 [ZeusMonitor] Running indefinitely. 2022-12-06 18:46:05.763 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:46:05.763 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 13:46:49,640 [ZeusDataLoader(train)] train epoch 44 done: time=44.12 energy=6221.07
2022-12-06 13:46:49,643 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 1.2928
Training Epoch: 43 [2048/50176]	Loss: 1.3129
Training Epoch: 43 [3072/50176]	Loss: 1.3428
Training Epoch: 43 [4096/50176]	Loss: 1.4413
Training Epoch: 43 [5120/50176]	Loss: 1.3704
Training Epoch: 43 [6144/50176]	Loss: 1.3472
Training Epoch: 43 [7168/50176]	Loss: 1.4143
Training Epoch: 43 [8192/50176]	Loss: 1.3285
Training Epoch: 43 [9216/50176]	Loss: 1.4342
Training Epoch: 43 [10240/50176]	Loss: 1.4770
Training Epoch: 43 [11264/50176]	Loss: 1.3935
Training Epoch: 43 [12288/50176]	Loss: 1.3911
Training Epoch: 43 [13312/50176]	Loss: 1.3390
Training Epoch: 43 [14336/50176]	Loss: 1.3317
Training Epoch: 43 [15360/50176]	Loss: 1.3996
Training Epoch: 43 [16384/50176]	Loss: 1.4749
Training Epoch: 43 [17408/50176]	Loss: 1.4163
Training Epoch: 43 [18432/50176]	Loss: 1.4137
Training Epoch: 43 [19456/50176]	Loss: 1.5459
Training Epoch: 43 [20480/50176]	Loss: 1.4452
Training Epoch: 43 [21504/50176]	Loss: 1.5105
Training Epoch: 43 [22528/50176]	Loss: 1.3912
Training Epoch: 43 [23552/50176]	Loss: 1.3557
Training Epoch: 43 [24576/50176]	Loss: 1.3901
Training Epoch: 43 [25600/50176]	Loss: 1.4956
Training Epoch: 43 [26624/50176]	Loss: 1.4189
Training Epoch: 43 [27648/50176]	Loss: 1.3816
Training Epoch: 43 [28672/50176]	Loss: 1.3918
Training Epoch: 43 [29696/50176]	Loss: 1.3028
Training Epoch: 43 [30720/50176]	Loss: 1.3762
Training Epoch: 43 [31744/50176]	Loss: 1.3927
Training Epoch: 43 [32768/50176]	Loss: 1.4235
Training Epoch: 43 [33792/50176]	Loss: 1.3742
Training Epoch: 43 [34816/50176]	Loss: 1.5141
Training Epoch: 43 [35840/50176]	Loss: 1.4811
Training Epoch: 43 [36864/50176]	Loss: 1.4625
Training Epoch: 43 [37888/50176]	Loss: 1.4431
Training Epoch: 43 [38912/50176]	Loss: 1.3260
Training Epoch: 43 [39936/50176]	Loss: 1.3572
Training Epoch: 43 [40960/50176]	Loss: 1.3288
Training Epoch: 43 [41984/50176]	Loss: 1.4494
Training Epoch: 43 [43008/50176]	Loss: 1.3853
Training Epoch: 43 [44032/50176]	Loss: 1.4242
Training Epoch: 43 [45056/50176]	Loss: 1.4222
Training Epoch: 43 [46080/50176]	Loss: 1.4208
Training Epoch: 43 [47104/50176]	Loss: 1.4713
Training Epoch: 43 [48128/50176]	Loss: 1.4158
Training Epoch: 43 [49152/50176]	Loss: 1.3676
Training Epoch: 43 [50176/50176]	Loss: 1.4212
2022-12-06 18:46:53.400 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:46:53,434 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.78 energy=481.71
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Up to epoch 44: time=2164.33, energy=297107.83, cost=337932.72
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:46:53,434 [ZeusDataLoader(train)] Expected next epoch: time=2211.43, energy=303795.71, cost=345398.22
2022-12-06 13:46:53,435 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0402, Accuracy: 0.0087
2022-12-06 13:46:53,671 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:46:53,671 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:46:53.673 [ZeusMonitor] Monitor started.
2022-12-06 18:46:53.673 [ZeusMonitor] Running indefinitely. 2022-12-06 18:46:53.673 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:46:53.673 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 13:47:37,583 [ZeusDataLoader(train)] train epoch 45 done: time=44.14 energy=6221.38
2022-12-06 13:47:37,586 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 1.3066
Training Epoch: 44 [2048/50176]	Loss: 1.4356
Training Epoch: 44 [3072/50176]	Loss: 1.2739
Training Epoch: 44 [4096/50176]	Loss: 1.3183
Training Epoch: 44 [5120/50176]	Loss: 1.3063
Training Epoch: 44 [6144/50176]	Loss: 1.2650
Training Epoch: 44 [7168/50176]	Loss: 1.3521
Training Epoch: 44 [8192/50176]	Loss: 1.2880
Training Epoch: 44 [9216/50176]	Loss: 1.3085
Training Epoch: 44 [10240/50176]	Loss: 1.2637
Training Epoch: 44 [11264/50176]	Loss: 1.3904
Training Epoch: 44 [12288/50176]	Loss: 1.2229
Training Epoch: 44 [13312/50176]	Loss: 1.4262
Training Epoch: 44 [14336/50176]	Loss: 1.4238
Training Epoch: 44 [15360/50176]	Loss: 1.3387
Training Epoch: 44 [16384/50176]	Loss: 1.3578
Training Epoch: 44 [17408/50176]	Loss: 1.3577
Training Epoch: 44 [18432/50176]	Loss: 1.3252
Training Epoch: 44 [19456/50176]	Loss: 1.3791
Training Epoch: 44 [20480/50176]	Loss: 1.3591
Training Epoch: 44 [21504/50176]	Loss: 1.4304
Training Epoch: 44 [22528/50176]	Loss: 1.3398
Training Epoch: 44 [23552/50176]	Loss: 1.3453
Training Epoch: 44 [24576/50176]	Loss: 1.3995
Training Epoch: 44 [25600/50176]	Loss: 1.3963
Training Epoch: 44 [26624/50176]	Loss: 1.4472
Training Epoch: 44 [27648/50176]	Loss: 1.3932
Training Epoch: 44 [28672/50176]	Loss: 1.3842
Training Epoch: 44 [29696/50176]	Loss: 1.3776
Training Epoch: 44 [30720/50176]	Loss: 1.3175
Training Epoch: 44 [31744/50176]	Loss: 1.4021
Training Epoch: 44 [32768/50176]	Loss: 1.3908
Training Epoch: 44 [33792/50176]	Loss: 1.3978
Training Epoch: 44 [34816/50176]	Loss: 1.3499
Training Epoch: 44 [35840/50176]	Loss: 1.3886
Training Epoch: 44 [36864/50176]	Loss: 1.3895
Training Epoch: 44 [37888/50176]	Loss: 1.4464
Training Epoch: 44 [38912/50176]	Loss: 1.4374
Training Epoch: 44 [39936/50176]	Loss: 1.4369
Training Epoch: 44 [40960/50176]	Loss: 1.3704
Training Epoch: 44 [41984/50176]	Loss: 1.2727
Training Epoch: 44 [43008/50176]	Loss: 1.4023
Training Epoch: 44 [44032/50176]	Loss: 1.4812
Training Epoch: 44 [45056/50176]	Loss: 1.4024
Training Epoch: 44 [46080/50176]	Loss: 1.4577
Training Epoch: 44 [47104/50176]	Loss: 1.3923
Training Epoch: 44 [48128/50176]	Loss: 1.3891
Training Epoch: 44 [49152/50176]	Loss: 1.4286
Training Epoch: 44 [50176/50176]	Loss: 1.3846
2022-12-06 18:47:41.336 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:47:41,373 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.78 energy=483.45
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Up to epoch 45: time=2212.25, energy=303812.66, cost=345478.02
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:47:41,373 [ZeusDataLoader(train)] Expected next epoch: time=2259.35, energy=310500.54, cost=352943.51
2022-12-06 13:47:41,374 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0279, Accuracy: 0.0128
2022-12-06 13:47:41,619 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:47:41,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:47:41.621 [ZeusMonitor] Monitor started.
2022-12-06 18:47:41.621 [ZeusMonitor] Running indefinitely. 2022-12-06 18:47:41.621 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:47:41.621 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 13:48:25,434 [ZeusDataLoader(train)] train epoch 46 done: time=44.05 energy=6215.15
2022-12-06 13:48:25,438 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 1.3335
Training Epoch: 45 [2048/50176]	Loss: 1.3298
Training Epoch: 45 [3072/50176]	Loss: 1.2939
Training Epoch: 45 [4096/50176]	Loss: 1.4136
Training Epoch: 45 [5120/50176]	Loss: 1.2413
Training Epoch: 45 [6144/50176]	Loss: 1.3410
Training Epoch: 45 [7168/50176]	Loss: 1.3209
Training Epoch: 45 [8192/50176]	Loss: 1.4199
Training Epoch: 45 [9216/50176]	Loss: 1.2851
Training Epoch: 45 [10240/50176]	Loss: 1.3676
Training Epoch: 45 [11264/50176]	Loss: 1.4051
Training Epoch: 45 [12288/50176]	Loss: 1.3657
Training Epoch: 45 [13312/50176]	Loss: 1.3145
Training Epoch: 45 [14336/50176]	Loss: 1.3491
Training Epoch: 45 [15360/50176]	Loss: 1.2979
Training Epoch: 45 [16384/50176]	Loss: 1.3034
Training Epoch: 45 [17408/50176]	Loss: 1.3085
Training Epoch: 45 [18432/50176]	Loss: 1.4092
Training Epoch: 45 [19456/50176]	Loss: 1.3835
Training Epoch: 45 [20480/50176]	Loss: 1.3175
Training Epoch: 45 [21504/50176]	Loss: 1.3059
Training Epoch: 45 [22528/50176]	Loss: 1.3174
Training Epoch: 45 [23552/50176]	Loss: 1.3071
Training Epoch: 45 [24576/50176]	Loss: 1.2939
Training Epoch: 45 [25600/50176]	Loss: 1.3548
Training Epoch: 45 [26624/50176]	Loss: 1.3429
Training Epoch: 45 [27648/50176]	Loss: 1.3299
Training Epoch: 45 [28672/50176]	Loss: 1.3796
Training Epoch: 45 [29696/50176]	Loss: 1.3930
Training Epoch: 45 [30720/50176]	Loss: 1.3763
Training Epoch: 45 [31744/50176]	Loss: 1.2999
Training Epoch: 45 [32768/50176]	Loss: 1.3443
Training Epoch: 45 [33792/50176]	Loss: 1.3729
Training Epoch: 45 [34816/50176]	Loss: 1.4143
Training Epoch: 45 [35840/50176]	Loss: 1.3459
Training Epoch: 45 [36864/50176]	Loss: 1.3793
Training Epoch: 45 [37888/50176]	Loss: 1.4023
Training Epoch: 45 [38912/50176]	Loss: 1.3285
Training Epoch: 45 [39936/50176]	Loss: 1.3613
Training Epoch: 45 [40960/50176]	Loss: 1.4466
Training Epoch: 45 [41984/50176]	Loss: 1.3409
Training Epoch: 45 [43008/50176]	Loss: 1.4071
Training Epoch: 45 [44032/50176]	Loss: 1.3834
Training Epoch: 45 [45056/50176]	Loss: 1.4735
Training Epoch: 45 [46080/50176]	Loss: 1.3524
Training Epoch: 45 [47104/50176]	Loss: 1.3338
Training Epoch: 45 [48128/50176]	Loss: 1.2996
Training Epoch: 45 [49152/50176]	Loss: 1.3266
Training Epoch: 45 [50176/50176]	Loss: 1.4442
2022-12-06 18:48:29.190 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:48:29,226 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.78 energy=485.27
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Up to epoch 46: time=2260.08, energy=310513.08, cost=353013.54
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:48:29,227 [ZeusDataLoader(train)] Expected next epoch: time=2307.18, energy=317200.95, cost=360479.04
2022-12-06 13:48:29,228 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0456, Accuracy: 0.0138
2022-12-06 13:48:29,424 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:48:29,425 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:48:29.428 [ZeusMonitor] Monitor started.
2022-12-06 18:48:29.429 [ZeusMonitor] Running indefinitely. 2022-12-06 18:48:29.429 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:48:29.429 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 13:49:13,600 [ZeusDataLoader(train)] train epoch 47 done: time=44.36 energy=6241.73
2022-12-06 13:49:13,603 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 1.3085
Training Epoch: 46 [2048/50176]	Loss: 1.3878
Training Epoch: 46 [3072/50176]	Loss: 1.2803
Training Epoch: 46 [4096/50176]	Loss: 1.3137
Training Epoch: 46 [5120/50176]	Loss: 1.2936
Training Epoch: 46 [6144/50176]	Loss: 1.3421
Training Epoch: 46 [7168/50176]	Loss: 1.2254
Training Epoch: 46 [8192/50176]	Loss: 1.2660
Training Epoch: 46 [9216/50176]	Loss: 1.2354
Training Epoch: 46 [10240/50176]	Loss: 1.3189
Training Epoch: 46 [11264/50176]	Loss: 1.3371
Training Epoch: 46 [12288/50176]	Loss: 1.2908
Training Epoch: 46 [13312/50176]	Loss: 1.2877
Training Epoch: 46 [14336/50176]	Loss: 1.3372
Training Epoch: 46 [15360/50176]	Loss: 1.2925
Training Epoch: 46 [16384/50176]	Loss: 1.3600
Training Epoch: 46 [17408/50176]	Loss: 1.3588
Training Epoch: 46 [18432/50176]	Loss: 1.3619
Training Epoch: 46 [19456/50176]	Loss: 1.2924
Training Epoch: 46 [20480/50176]	Loss: 1.3501
Training Epoch: 46 [21504/50176]	Loss: 1.3526
Training Epoch: 46 [22528/50176]	Loss: 1.3576
Training Epoch: 46 [23552/50176]	Loss: 1.4313
Training Epoch: 46 [24576/50176]	Loss: 1.4600
Training Epoch: 46 [25600/50176]	Loss: 1.3313
Training Epoch: 46 [26624/50176]	Loss: 1.3539
Training Epoch: 46 [27648/50176]	Loss: 1.3801
Training Epoch: 46 [28672/50176]	Loss: 1.2807
Training Epoch: 46 [29696/50176]	Loss: 1.2665
Training Epoch: 46 [30720/50176]	Loss: 1.3588
Training Epoch: 46 [31744/50176]	Loss: 1.3368
Training Epoch: 46 [32768/50176]	Loss: 1.3083
Training Epoch: 46 [33792/50176]	Loss: 1.3808
Training Epoch: 46 [34816/50176]	Loss: 1.4109
Training Epoch: 46 [35840/50176]	Loss: 1.3762
Training Epoch: 46 [36864/50176]	Loss: 1.3301
Training Epoch: 46 [37888/50176]	Loss: 1.3535
Training Epoch: 46 [38912/50176]	Loss: 1.3716
Training Epoch: 46 [39936/50176]	Loss: 1.3902
Training Epoch: 46 [40960/50176]	Loss: 1.3468
Training Epoch: 46 [41984/50176]	Loss: 1.3643
Training Epoch: 46 [43008/50176]	Loss: 1.2284
Training Epoch: 46 [44032/50176]	Loss: 1.3113
Training Epoch: 46 [45056/50176]	Loss: 1.3821
Training Epoch: 46 [46080/50176]	Loss: 1.3382
Training Epoch: 46 [47104/50176]	Loss: 1.3580
Training Epoch: 46 [48128/50176]	Loss: 1.3708
Training Epoch: 46 [49152/50176]	Loss: 1.3703
Training Epoch: 46 [50176/50176]	Loss: 1.3353
2022-12-06 18:49:17.370 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:49:17,397 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.79 energy=473.39
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Up to epoch 47: time=2308.23, energy=317228.19, cost=360584.23
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:49:17,398 [ZeusDataLoader(train)] Expected next epoch: time=2355.33, energy=323916.07, cost=368049.72
2022-12-06 13:49:17,399 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0500, Accuracy: 0.0165
2022-12-06 13:49:17,638 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:49:17,638 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:49:17.640 [ZeusMonitor] Monitor started.
2022-12-06 18:49:17.640 [ZeusMonitor] Running indefinitely. 2022-12-06 18:49:17.640 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:49:17.640 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 13:50:01,796 [ZeusDataLoader(train)] train epoch 48 done: time=44.39 energy=6246.24
2022-12-06 13:50:01,800 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 1.2303
Training Epoch: 47 [2048/50176]	Loss: 1.2424
Training Epoch: 47 [3072/50176]	Loss: 1.2734
Training Epoch: 47 [4096/50176]	Loss: 1.3091
Training Epoch: 47 [5120/50176]	Loss: 1.2810
Training Epoch: 47 [6144/50176]	Loss: 1.2881
Training Epoch: 47 [7168/50176]	Loss: 1.2324
Training Epoch: 47 [8192/50176]	Loss: 1.3228
Training Epoch: 47 [9216/50176]	Loss: 1.3109
Training Epoch: 47 [10240/50176]	Loss: 1.3194
Training Epoch: 47 [11264/50176]	Loss: 1.3613
Training Epoch: 47 [12288/50176]	Loss: 1.3383
Training Epoch: 47 [13312/50176]	Loss: 1.2767
Training Epoch: 47 [14336/50176]	Loss: 1.3271
Training Epoch: 47 [15360/50176]	Loss: 1.2437
Training Epoch: 47 [16384/50176]	Loss: 1.2932
Training Epoch: 47 [17408/50176]	Loss: 1.2509
Training Epoch: 47 [18432/50176]	Loss: 1.2123
Training Epoch: 47 [19456/50176]	Loss: 1.3945
Training Epoch: 47 [20480/50176]	Loss: 1.3334
Training Epoch: 47 [21504/50176]	Loss: 1.3328
Training Epoch: 47 [22528/50176]	Loss: 1.2786
Training Epoch: 47 [23552/50176]	Loss: 1.2826
Training Epoch: 47 [24576/50176]	Loss: 1.2633
Training Epoch: 47 [25600/50176]	Loss: 1.3519
Training Epoch: 47 [26624/50176]	Loss: 1.2212
Training Epoch: 47 [27648/50176]	Loss: 1.2608
Training Epoch: 47 [28672/50176]	Loss: 1.2714
Training Epoch: 47 [29696/50176]	Loss: 1.2734
Training Epoch: 47 [30720/50176]	Loss: 1.3931
Training Epoch: 47 [31744/50176]	Loss: 1.2688
Training Epoch: 47 [32768/50176]	Loss: 1.4009
Training Epoch: 47 [33792/50176]	Loss: 1.3892
Training Epoch: 47 [34816/50176]	Loss: 1.2907
Training Epoch: 47 [35840/50176]	Loss: 1.3478
Training Epoch: 47 [36864/50176]	Loss: 1.3133
Training Epoch: 47 [37888/50176]	Loss: 1.3024
Training Epoch: 47 [38912/50176]	Loss: 1.3500
Training Epoch: 47 [39936/50176]	Loss: 1.3414
Training Epoch: 47 [40960/50176]	Loss: 1.2144
Training Epoch: 47 [41984/50176]	Loss: 1.4376
Training Epoch: 47 [43008/50176]	Loss: 1.3718
Training Epoch: 47 [44032/50176]	Loss: 1.2703
Training Epoch: 47 [45056/50176]	Loss: 1.3359
Training Epoch: 47 [46080/50176]	Loss: 1.3696
Training Epoch: 47 [47104/50176]	Loss: 1.2403
Training Epoch: 47 [48128/50176]	Loss: 1.3121
Training Epoch: 47 [49152/50176]	Loss: 1.3170
Training Epoch: 47 [50176/50176]	Loss: 1.3844
2022-12-06 18:50:05.554 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:50:05,565 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.76 energy=466.33
2022-12-06 13:50:05,565 [ZeusDataLoader(train)] Up to epoch 48: time=2356.38, energy=323940.76, cost=368153.35
2022-12-06 13:50:05,566 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:50:05,566 [ZeusDataLoader(train)] Expected next epoch: time=2403.48, energy=330628.64, cost=375618.85
2022-12-06 13:50:05,567 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.9088, Accuracy: 0.0093
2022-12-06 13:50:05,818 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:50:05,819 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:50:05.821 [ZeusMonitor] Monitor started.
2022-12-06 18:50:05.821 [ZeusMonitor] Running indefinitely. 2022-12-06 18:50:05.821 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:50:05.821 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 13:50:49,958 [ZeusDataLoader(train)] train epoch 49 done: time=44.38 energy=6224.26
2022-12-06 13:50:49,962 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 1.2758
Training Epoch: 48 [2048/50176]	Loss: 1.2273
Training Epoch: 48 [3072/50176]	Loss: 1.2165
Training Epoch: 48 [4096/50176]	Loss: 1.2825
Training Epoch: 48 [5120/50176]	Loss: 1.2584
Training Epoch: 48 [6144/50176]	Loss: 1.2374
Training Epoch: 48 [7168/50176]	Loss: 1.1686
Training Epoch: 48 [8192/50176]	Loss: 1.2083
Training Epoch: 48 [9216/50176]	Loss: 1.2426
Training Epoch: 48 [10240/50176]	Loss: 1.2892
Training Epoch: 48 [11264/50176]	Loss: 1.2234
Training Epoch: 48 [12288/50176]	Loss: 1.2655
Training Epoch: 48 [13312/50176]	Loss: 1.2660
Training Epoch: 48 [14336/50176]	Loss: 1.2706
Training Epoch: 48 [15360/50176]	Loss: 1.3671
Training Epoch: 48 [16384/50176]	Loss: 1.2434
Training Epoch: 48 [17408/50176]	Loss: 1.2304
Training Epoch: 48 [18432/50176]	Loss: 1.2624
Training Epoch: 48 [19456/50176]	Loss: 1.2683
Training Epoch: 48 [20480/50176]	Loss: 1.2971
Training Epoch: 48 [21504/50176]	Loss: 1.3209
Training Epoch: 48 [22528/50176]	Loss: 1.2161
Training Epoch: 48 [23552/50176]	Loss: 1.3116
Training Epoch: 48 [24576/50176]	Loss: 1.3006
Training Epoch: 48 [25600/50176]	Loss: 1.2862
Training Epoch: 48 [26624/50176]	Loss: 1.2086
Training Epoch: 48 [27648/50176]	Loss: 1.4320
Training Epoch: 48 [28672/50176]	Loss: 1.2621
Training Epoch: 48 [29696/50176]	Loss: 1.2489
Training Epoch: 48 [30720/50176]	Loss: 1.3093
Training Epoch: 48 [31744/50176]	Loss: 1.2827
Training Epoch: 48 [32768/50176]	Loss: 1.2905
Training Epoch: 48 [33792/50176]	Loss: 1.3884
Training Epoch: 48 [34816/50176]	Loss: 1.2517
Training Epoch: 48 [35840/50176]	Loss: 1.3164
Training Epoch: 48 [36864/50176]	Loss: 1.2886
Training Epoch: 48 [37888/50176]	Loss: 1.2894
Training Epoch: 48 [38912/50176]	Loss: 1.2476
Training Epoch: 48 [39936/50176]	Loss: 1.2054
Training Epoch: 48 [40960/50176]	Loss: 1.3414
Training Epoch: 48 [41984/50176]	Loss: 1.3471
Training Epoch: 48 [43008/50176]	Loss: 1.3320
Training Epoch: 48 [44032/50176]	Loss: 1.3069
Training Epoch: 48 [45056/50176]	Loss: 1.2759
Training Epoch: 48 [46080/50176]	Loss: 1.3778
Training Epoch: 48 [47104/50176]	Loss: 1.3020
Training Epoch: 48 [48128/50176]	Loss: 1.3257
Training Epoch: 48 [49152/50176]	Loss: 1.3086
Training Epoch: 48 [50176/50176]	Loss: 1.3093
2022-12-06 18:50:53.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:50:53,769 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.80 energy=485.67
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Up to epoch 49: time=2404.56, energy=330650.68, cost=375724.32
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:50:53,769 [ZeusDataLoader(train)] Expected next epoch: time=2451.66, energy=337338.56, cost=383189.82
2022-12-06 13:50:53,770 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0481, Accuracy: 0.0116
2022-12-06 13:50:54,011 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:50:54,012 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:50:54.014 [ZeusMonitor] Monitor started.
2022-12-06 18:50:54.014 [ZeusMonitor] Running indefinitely. 2022-12-06 18:50:54.014 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:50:54.014 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 13:51:38,264 [ZeusDataLoader(train)] train epoch 50 done: time=44.49 energy=6251.62
2022-12-06 13:51:38,268 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 1.1842
Training Epoch: 49 [2048/50176]	Loss: 1.2198
Training Epoch: 49 [3072/50176]	Loss: 1.2537
Training Epoch: 49 [4096/50176]	Loss: 1.2967
Training Epoch: 49 [5120/50176]	Loss: 1.2593
Training Epoch: 49 [6144/50176]	Loss: 1.1486
Training Epoch: 49 [7168/50176]	Loss: 1.2104
Training Epoch: 49 [8192/50176]	Loss: 1.2623
Training Epoch: 49 [9216/50176]	Loss: 1.2931
Training Epoch: 49 [10240/50176]	Loss: 1.2644
Training Epoch: 49 [11264/50176]	Loss: 1.3363
Training Epoch: 49 [12288/50176]	Loss: 1.3334
Training Epoch: 49 [13312/50176]	Loss: 1.2528
Training Epoch: 49 [14336/50176]	Loss: 1.2968
Training Epoch: 49 [15360/50176]	Loss: 1.3655
Training Epoch: 49 [16384/50176]	Loss: 1.3728
Training Epoch: 49 [17408/50176]	Loss: 1.1876
Training Epoch: 49 [18432/50176]	Loss: 1.2675
Training Epoch: 49 [19456/50176]	Loss: 1.2388
Training Epoch: 49 [20480/50176]	Loss: 1.2132
Training Epoch: 49 [21504/50176]	Loss: 1.2417
Training Epoch: 49 [22528/50176]	Loss: 1.2804
Training Epoch: 49 [23552/50176]	Loss: 1.2994
Training Epoch: 49 [24576/50176]	Loss: 1.2315
Training Epoch: 49 [25600/50176]	Loss: 1.3087
Training Epoch: 49 [26624/50176]	Loss: 1.3293
Training Epoch: 49 [27648/50176]	Loss: 1.3119
Training Epoch: 49 [28672/50176]	Loss: 1.2274
Training Epoch: 49 [29696/50176]	Loss: 1.2431
Training Epoch: 49 [30720/50176]	Loss: 1.3010
Training Epoch: 49 [31744/50176]	Loss: 1.3181
Training Epoch: 49 [32768/50176]	Loss: 1.2119
Training Epoch: 49 [33792/50176]	Loss: 1.2482
Training Epoch: 49 [34816/50176]	Loss: 1.3386
Training Epoch: 49 [35840/50176]	Loss: 1.3756
Training Epoch: 49 [36864/50176]	Loss: 1.3243
Training Epoch: 49 [37888/50176]	Loss: 1.2357
Training Epoch: 49 [38912/50176]	Loss: 1.2860
Training Epoch: 49 [39936/50176]	Loss: 1.3412
Training Epoch: 49 [40960/50176]	Loss: 1.1872
Training Epoch: 49 [41984/50176]	Loss: 1.4475
Training Epoch: 49 [43008/50176]	Loss: 1.3275
Training Epoch: 49 [44032/50176]	Loss: 1.2425
Training Epoch: 49 [45056/50176]	Loss: 1.3082
Training Epoch: 49 [46080/50176]	Loss: 1.2756
Training Epoch: 49 [47104/50176]	Loss: 1.3165
Training Epoch: 49 [48128/50176]	Loss: 1.2813
Training Epoch: 49 [49152/50176]	Loss: 1.3616
Training Epoch: 49 [50176/50176]	Loss: 1.2845
2022-12-06 18:51:42.037 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:51:42,070 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.79 energy=495.10
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Up to epoch 50: time=2452.84, energy=337397.41, cost=383322.18
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:51:42,070 [ZeusDataLoader(train)] Expected next epoch: time=2499.94, energy=344085.29, cost=390787.68
2022-12-06 13:51:42,071 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.1582, Accuracy: 0.0098
2022-12-06 13:51:42,334 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:51:42,335 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:51:42.336 [ZeusMonitor] Monitor started.
2022-12-06 18:51:42.336 [ZeusMonitor] Running indefinitely. 2022-12-06 18:51:42.337 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:51:42.337 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 13:52:26,743 [ZeusDataLoader(train)] train epoch 51 done: time=44.66 energy=6258.73
2022-12-06 13:52:26,746 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 1.1492
Training Epoch: 50 [2048/50176]	Loss: 1.1802
Training Epoch: 50 [3072/50176]	Loss: 1.3094
Training Epoch: 50 [4096/50176]	Loss: 1.2962
Training Epoch: 50 [5120/50176]	Loss: 1.2871
Training Epoch: 50 [6144/50176]	Loss: 1.2301
Training Epoch: 50 [7168/50176]	Loss: 1.2479
Training Epoch: 50 [8192/50176]	Loss: 1.2523
Training Epoch: 50 [9216/50176]	Loss: 1.2555
Training Epoch: 50 [10240/50176]	Loss: 1.2466
Training Epoch: 50 [11264/50176]	Loss: 1.1604
Training Epoch: 50 [12288/50176]	Loss: 1.2153
Training Epoch: 50 [13312/50176]	Loss: 1.2396
Training Epoch: 50 [14336/50176]	Loss: 1.2108
Training Epoch: 50 [15360/50176]	Loss: 1.2592
Training Epoch: 50 [16384/50176]	Loss: 1.2149
Training Epoch: 50 [17408/50176]	Loss: 1.2238
Training Epoch: 50 [18432/50176]	Loss: 1.3003
Training Epoch: 50 [19456/50176]	Loss: 1.2476
Training Epoch: 50 [20480/50176]	Loss: 1.2794
Training Epoch: 50 [21504/50176]	Loss: 1.1742
Training Epoch: 50 [22528/50176]	Loss: 1.1979
Training Epoch: 50 [23552/50176]	Loss: 1.2136
Training Epoch: 50 [24576/50176]	Loss: 1.2616
Training Epoch: 50 [25600/50176]	Loss: 1.2779
Training Epoch: 50 [26624/50176]	Loss: 1.2485
Training Epoch: 50 [27648/50176]	Loss: 1.2544
Training Epoch: 50 [28672/50176]	Loss: 1.3372
Training Epoch: 50 [29696/50176]	Loss: 1.2231
Training Epoch: 50 [30720/50176]	Loss: 1.2511
Training Epoch: 50 [31744/50176]	Loss: 1.2123
Training Epoch: 50 [32768/50176]	Loss: 1.3136
Training Epoch: 50 [33792/50176]	Loss: 1.2316
Training Epoch: 50 [34816/50176]	Loss: 1.3311
Training Epoch: 50 [35840/50176]	Loss: 1.2154
Training Epoch: 50 [36864/50176]	Loss: 1.3581
Training Epoch: 50 [37888/50176]	Loss: 1.1701
Training Epoch: 50 [38912/50176]	Loss: 1.2564
Training Epoch: 50 [39936/50176]	Loss: 1.2177
Training Epoch: 50 [40960/50176]	Loss: 1.2769
Training Epoch: 50 [41984/50176]	Loss: 1.2630
Training Epoch: 50 [43008/50176]	Loss: 1.2551
Training Epoch: 50 [44032/50176]	Loss: 1.3165
Training Epoch: 50 [45056/50176]	Loss: 1.3362
Training Epoch: 50 [46080/50176]	Loss: 1.3225
Training Epoch: 50 [47104/50176]	Loss: 1.2879
Training Epoch: 50 [48128/50176]	Loss: 1.2497
Training Epoch: 50 [49152/50176]	Loss: 1.2690
Training Epoch: 50 [50176/50176]	Loss: 1.3089
2022-12-06 18:52:30.455 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:52:30,476 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.72 energy=473.27
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Up to epoch 51: time=2501.22, energy=344129.41, cost=390921.89
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:52:30,477 [ZeusDataLoader(train)] Expected next epoch: time=2548.33, energy=350817.29, cost=398387.39
2022-12-06 13:52:30,478 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0189, Accuracy: 0.0135
2022-12-06 13:52:30,720 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:52:30,721 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:52:30.722 [ZeusMonitor] Monitor started.
2022-12-06 18:52:30.722 [ZeusMonitor] Running indefinitely. 2022-12-06 18:52:30.722 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:52:30.723 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 13:53:15,023 [ZeusDataLoader(train)] train epoch 52 done: time=44.54 energy=6239.86
2022-12-06 13:53:15,027 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 1.1018
Training Epoch: 51 [2048/50176]	Loss: 1.2788
Training Epoch: 51 [3072/50176]	Loss: 1.2085
Training Epoch: 51 [4096/50176]	Loss: 1.1910
Training Epoch: 51 [5120/50176]	Loss: 1.1903
Training Epoch: 51 [6144/50176]	Loss: 1.1790
Training Epoch: 51 [7168/50176]	Loss: 1.2170
Training Epoch: 51 [8192/50176]	Loss: 1.2865
Training Epoch: 51 [9216/50176]	Loss: 1.1884
Training Epoch: 51 [10240/50176]	Loss: 1.1753
Training Epoch: 51 [11264/50176]	Loss: 1.2608
Training Epoch: 51 [12288/50176]	Loss: 1.2642
Training Epoch: 51 [13312/50176]	Loss: 1.2405
Training Epoch: 51 [14336/50176]	Loss: 1.1625
Training Epoch: 51 [15360/50176]	Loss: 1.2582
Training Epoch: 51 [16384/50176]	Loss: 1.3080
Training Epoch: 51 [17408/50176]	Loss: 1.2198
Training Epoch: 51 [18432/50176]	Loss: 1.3662
Training Epoch: 51 [19456/50176]	Loss: 1.2223
Training Epoch: 51 [20480/50176]	Loss: 1.2228
Training Epoch: 51 [21504/50176]	Loss: 1.1636
Training Epoch: 51 [22528/50176]	Loss: 1.2145
Training Epoch: 51 [23552/50176]	Loss: 1.2445
Training Epoch: 51 [24576/50176]	Loss: 1.3094
Training Epoch: 51 [25600/50176]	Loss: 1.2437
Training Epoch: 51 [26624/50176]	Loss: 1.2449
Training Epoch: 51 [27648/50176]	Loss: 1.2953
Training Epoch: 51 [28672/50176]	Loss: 1.1849
Training Epoch: 51 [29696/50176]	Loss: 1.3412
Training Epoch: 51 [30720/50176]	Loss: 1.2239
Training Epoch: 51 [31744/50176]	Loss: 1.3006
Training Epoch: 51 [32768/50176]	Loss: 1.2144
Training Epoch: 51 [33792/50176]	Loss: 1.2845
Training Epoch: 51 [34816/50176]	Loss: 1.2257
Training Epoch: 51 [35840/50176]	Loss: 1.2264
Training Epoch: 51 [36864/50176]	Loss: 1.1655
Training Epoch: 51 [37888/50176]	Loss: 1.3241
Training Epoch: 51 [38912/50176]	Loss: 1.2161
Training Epoch: 51 [39936/50176]	Loss: 1.1780
Training Epoch: 51 [40960/50176]	Loss: 1.2511
Training Epoch: 51 [41984/50176]	Loss: 1.3164
Training Epoch: 51 [43008/50176]	Loss: 1.2709
Training Epoch: 51 [44032/50176]	Loss: 1.2135
Training Epoch: 51 [45056/50176]	Loss: 1.3265
Training Epoch: 51 [46080/50176]	Loss: 1.3445
Training Epoch: 51 [47104/50176]	Loss: 1.2971
Training Epoch: 51 [48128/50176]	Loss: 1.1802
Training Epoch: 51 [49152/50176]	Loss: 1.3040
Training Epoch: 51 [50176/50176]	Loss: 1.3197
2022-12-06 18:53:18.915 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:53:18,936 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.90 energy=496.41
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Up to epoch 52: time=2549.66, energy=350865.68, cost=398528.34
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:53:18,936 [ZeusDataLoader(train)] Expected next epoch: time=2596.77, energy=357553.56, cost=405993.84
2022-12-06 13:53:18,937 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0227, Accuracy: 0.0130
2022-12-06 13:53:19,178 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:53:19,179 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:53:19.180 [ZeusMonitor] Monitor started.
2022-12-06 18:53:19.181 [ZeusMonitor] Running indefinitely. 2022-12-06 18:53:19.181 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:53:19.181 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 13:54:03,501 [ZeusDataLoader(train)] train epoch 53 done: time=44.56 energy=6247.85
2022-12-06 13:54:03,504 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 1.1792
Training Epoch: 52 [2048/50176]	Loss: 1.1727
Training Epoch: 52 [3072/50176]	Loss: 1.1579
Training Epoch: 52 [4096/50176]	Loss: 1.1303
Training Epoch: 52 [5120/50176]	Loss: 1.1771
Training Epoch: 52 [6144/50176]	Loss: 1.1917
Training Epoch: 52 [7168/50176]	Loss: 1.1574
Training Epoch: 52 [8192/50176]	Loss: 1.2285
Training Epoch: 52 [9216/50176]	Loss: 1.1317
Training Epoch: 52 [10240/50176]	Loss: 1.1983
Training Epoch: 52 [11264/50176]	Loss: 1.1817
Training Epoch: 52 [12288/50176]	Loss: 1.1599
Training Epoch: 52 [13312/50176]	Loss: 1.1588
Training Epoch: 52 [14336/50176]	Loss: 1.1289
Training Epoch: 52 [15360/50176]	Loss: 1.1273
Training Epoch: 52 [16384/50176]	Loss: 1.2113
Training Epoch: 52 [17408/50176]	Loss: 1.1912
Training Epoch: 52 [18432/50176]	Loss: 1.2387
Training Epoch: 52 [19456/50176]	Loss: 1.1615
Training Epoch: 52 [20480/50176]	Loss: 1.2496
Training Epoch: 52 [21504/50176]	Loss: 1.1873
Training Epoch: 52 [22528/50176]	Loss: 1.3094
Training Epoch: 52 [23552/50176]	Loss: 1.2609
Training Epoch: 52 [24576/50176]	Loss: 1.2725
Training Epoch: 52 [25600/50176]	Loss: 1.2545
Training Epoch: 52 [26624/50176]	Loss: 1.2498
Training Epoch: 52 [27648/50176]	Loss: 1.3175
Training Epoch: 52 [28672/50176]	Loss: 1.2581
Training Epoch: 52 [29696/50176]	Loss: 1.2450
Training Epoch: 52 [30720/50176]	Loss: 1.2843
Training Epoch: 52 [31744/50176]	Loss: 1.2108
Training Epoch: 52 [32768/50176]	Loss: 1.2675
Training Epoch: 52 [33792/50176]	Loss: 1.2598
Training Epoch: 52 [34816/50176]	Loss: 1.1983
Training Epoch: 52 [35840/50176]	Loss: 1.2653
Training Epoch: 52 [36864/50176]	Loss: 1.3654
Training Epoch: 52 [37888/50176]	Loss: 1.2929
Training Epoch: 52 [38912/50176]	Loss: 1.1939
Training Epoch: 52 [39936/50176]	Loss: 1.2310
Training Epoch: 52 [40960/50176]	Loss: 1.2379
Training Epoch: 52 [41984/50176]	Loss: 1.2032
Training Epoch: 52 [43008/50176]	Loss: 1.2487
Training Epoch: 52 [44032/50176]	Loss: 1.3435
Training Epoch: 52 [45056/50176]	Loss: 1.2515
Training Epoch: 52 [46080/50176]	Loss: 1.3057
Training Epoch: 52 [47104/50176]	Loss: 1.2361
Training Epoch: 52 [48128/50176]	Loss: 1.2720
Training Epoch: 52 [49152/50176]	Loss: 1.2548
Training Epoch: 52 [50176/50176]	Loss: 1.4103
2022-12-06 18:54:07.183 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:54:07,203 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.69 energy=459.58
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Up to epoch 53: time=2597.91, energy=357573.12, cost=406103.65
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:54:07,203 [ZeusDataLoader(train)] Expected next epoch: time=2645.01, energy=364260.99, cost=413569.15
2022-12-06 13:54:07,204 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0275, Accuracy: 0.0117
2022-12-06 13:54:07,502 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:54:07,503 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:54:07.516 [ZeusMonitor] Monitor started.
2022-12-06 18:54:07.517 [ZeusMonitor] Running indefinitely. 2022-12-06 18:54:07.517 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:54:07.517 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 13:54:51,701 [ZeusDataLoader(train)] train epoch 54 done: time=44.49 energy=6231.40
2022-12-06 13:54:51,705 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 1.1342
Training Epoch: 53 [2048/50176]	Loss: 1.0997
Training Epoch: 53 [3072/50176]	Loss: 1.1551
Training Epoch: 53 [4096/50176]	Loss: 1.1690
Training Epoch: 53 [5120/50176]	Loss: 1.1771
Training Epoch: 53 [6144/50176]	Loss: 1.1111
Training Epoch: 53 [7168/50176]	Loss: 1.1788
Training Epoch: 53 [8192/50176]	Loss: 1.1702
Training Epoch: 53 [9216/50176]	Loss: 1.1891
Training Epoch: 53 [10240/50176]	Loss: 1.2295
Training Epoch: 53 [11264/50176]	Loss: 1.0520
Training Epoch: 53 [12288/50176]	Loss: 1.1587
Training Epoch: 53 [13312/50176]	Loss: 1.0893
Training Epoch: 53 [14336/50176]	Loss: 1.2022
Training Epoch: 53 [15360/50176]	Loss: 1.1580
Training Epoch: 53 [16384/50176]	Loss: 1.2151
Training Epoch: 53 [17408/50176]	Loss: 1.1289
Training Epoch: 53 [18432/50176]	Loss: 1.1424
Training Epoch: 53 [19456/50176]	Loss: 1.3138
Training Epoch: 53 [20480/50176]	Loss: 1.1673
Training Epoch: 53 [21504/50176]	Loss: 1.1671
Training Epoch: 53 [22528/50176]	Loss: 1.2282
Training Epoch: 53 [23552/50176]	Loss: 1.1246
Training Epoch: 53 [24576/50176]	Loss: 1.1804
Training Epoch: 53 [25600/50176]	Loss: 1.1479
Training Epoch: 53 [26624/50176]	Loss: 1.1563
Training Epoch: 53 [27648/50176]	Loss: 1.2565
Training Epoch: 53 [28672/50176]	Loss: 1.1602
Training Epoch: 53 [29696/50176]	Loss: 1.2186
Training Epoch: 53 [30720/50176]	Loss: 1.2926
Training Epoch: 53 [31744/50176]	Loss: 1.1838
Training Epoch: 53 [32768/50176]	Loss: 1.2437
Training Epoch: 53 [33792/50176]	Loss: 1.1897
Training Epoch: 53 [34816/50176]	Loss: 1.1165
Training Epoch: 53 [35840/50176]	Loss: 1.1696
Training Epoch: 53 [36864/50176]	Loss: 1.2360
Training Epoch: 53 [37888/50176]	Loss: 1.2926
Training Epoch: 53 [38912/50176]	Loss: 1.2581
Training Epoch: 53 [39936/50176]	Loss: 1.2357
Training Epoch: 53 [40960/50176]	Loss: 1.2369
Training Epoch: 53 [41984/50176]	Loss: 1.2430
Training Epoch: 53 [43008/50176]	Loss: 1.2866
Training Epoch: 53 [44032/50176]	Loss: 1.2603
Training Epoch: 53 [45056/50176]	Loss: 1.2539
Training Epoch: 53 [46080/50176]	Loss: 1.2510
Training Epoch: 53 [47104/50176]	Loss: 1.2301
Training Epoch: 53 [48128/50176]	Loss: 1.2423
Training Epoch: 53 [49152/50176]	Loss: 1.2099
Training Epoch: 53 [50176/50176]	Loss: 1.2760
2022-12-06 18:54:55.431 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:54:55,451 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.74 energy=474.25
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Up to epoch 54: time=2646.14, energy=364278.76, cost=413676.39
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:54:55,452 [ZeusDataLoader(train)] Expected next epoch: time=2693.24, energy=370966.64, cost=421141.89
2022-12-06 13:54:55,453 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0276, Accuracy: 0.0177
2022-12-06 13:54:55,693 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:54:55,693 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:54:55.695 [ZeusMonitor] Monitor started.
2022-12-06 18:54:55.695 [ZeusMonitor] Running indefinitely. 2022-12-06 18:54:55.695 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:54:55.695 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 13:55:39,486 [ZeusDataLoader(train)] train epoch 55 done: time=44.03 energy=6209.77
2022-12-06 13:55:39,489 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 1.2580
Training Epoch: 54 [2048/50176]	Loss: 1.2188
Training Epoch: 54 [3072/50176]	Loss: 1.1106
Training Epoch: 54 [4096/50176]	Loss: 1.1063
Training Epoch: 54 [5120/50176]	Loss: 1.0801
Training Epoch: 54 [6144/50176]	Loss: 1.1688
Training Epoch: 54 [7168/50176]	Loss: 1.1086
Training Epoch: 54 [8192/50176]	Loss: 1.1558
Training Epoch: 54 [9216/50176]	Loss: 1.1587
Training Epoch: 54 [10240/50176]	Loss: 1.1621
Training Epoch: 54 [11264/50176]	Loss: 1.1897
Training Epoch: 54 [12288/50176]	Loss: 1.0830
Training Epoch: 54 [13312/50176]	Loss: 1.1927
Training Epoch: 54 [14336/50176]	Loss: 1.1596
Training Epoch: 54 [15360/50176]	Loss: 1.2660
Training Epoch: 54 [16384/50176]	Loss: 1.0909
Training Epoch: 54 [17408/50176]	Loss: 1.1760
Training Epoch: 54 [18432/50176]	Loss: 1.1527
Training Epoch: 54 [19456/50176]	Loss: 1.2486
Training Epoch: 54 [20480/50176]	Loss: 1.1174
Training Epoch: 54 [21504/50176]	Loss: 1.1648
Training Epoch: 54 [22528/50176]	Loss: 1.2283
Training Epoch: 54 [23552/50176]	Loss: 1.1429
Training Epoch: 54 [24576/50176]	Loss: 1.1406
Training Epoch: 54 [25600/50176]	Loss: 1.1821
Training Epoch: 54 [26624/50176]	Loss: 1.1288
Training Epoch: 54 [27648/50176]	Loss: 1.2355
Training Epoch: 54 [28672/50176]	Loss: 1.2012
Training Epoch: 54 [29696/50176]	Loss: 1.0868
Training Epoch: 54 [30720/50176]	Loss: 1.1648
Training Epoch: 54 [31744/50176]	Loss: 1.1979
Training Epoch: 54 [32768/50176]	Loss: 1.1129
Training Epoch: 54 [33792/50176]	Loss: 1.2442
Training Epoch: 54 [34816/50176]	Loss: 1.2127
Training Epoch: 54 [35840/50176]	Loss: 1.3166
Training Epoch: 54 [36864/50176]	Loss: 1.2462
Training Epoch: 54 [37888/50176]	Loss: 1.1483
Training Epoch: 54 [38912/50176]	Loss: 1.1804
Training Epoch: 54 [39936/50176]	Loss: 1.2919
Training Epoch: 54 [40960/50176]	Loss: 1.2236
Training Epoch: 54 [41984/50176]	Loss: 1.1848
Training Epoch: 54 [43008/50176]	Loss: 1.1772
Training Epoch: 54 [44032/50176]	Loss: 1.1357
Training Epoch: 54 [45056/50176]	Loss: 1.2120
Training Epoch: 54 [46080/50176]	Loss: 1.2384
Training Epoch: 54 [47104/50176]	Loss: 1.1986
Training Epoch: 54 [48128/50176]	Loss: 1.1271
Training Epoch: 54 [49152/50176]	Loss: 1.2021
Training Epoch: 54 [50176/50176]	Loss: 1.2454
2022-12-06 18:55:43.297 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:55:43,318 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.82 energy=480.93
2022-12-06 13:55:43,318 [ZeusDataLoader(train)] Up to epoch 55: time=2693.98, energy=370969.47, cost=421208.29
2022-12-06 13:55:43,319 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:55:43,319 [ZeusDataLoader(train)] Expected next epoch: time=2741.09, energy=377657.34, cost=428673.79
2022-12-06 13:55:43,320 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0406, Accuracy: 0.0097
2022-12-06 13:55:43,509 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:55:43,510 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:55:43.513 [ZeusMonitor] Monitor started.
2022-12-06 18:55:43.513 [ZeusMonitor] Running indefinitely. 2022-12-06 18:55:43.513 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:55:43.513 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 13:56:27,258 [ZeusDataLoader(train)] train epoch 56 done: time=43.93 energy=6202.41
2022-12-06 13:56:27,262 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 1.1161
Training Epoch: 55 [2048/50176]	Loss: 1.1735
Training Epoch: 55 [3072/50176]	Loss: 1.1362
Training Epoch: 55 [4096/50176]	Loss: 1.1363
Training Epoch: 55 [5120/50176]	Loss: 1.0866
Training Epoch: 55 [6144/50176]	Loss: 1.1300
Training Epoch: 55 [7168/50176]	Loss: 1.1257
Training Epoch: 55 [8192/50176]	Loss: 1.1934
Training Epoch: 55 [9216/50176]	Loss: 1.1130
Training Epoch: 55 [10240/50176]	Loss: 1.1845
Training Epoch: 55 [11264/50176]	Loss: 1.1698
Training Epoch: 55 [12288/50176]	Loss: 1.0636
Training Epoch: 55 [13312/50176]	Loss: 1.1597
Training Epoch: 55 [14336/50176]	Loss: 1.1821
Training Epoch: 55 [15360/50176]	Loss: 1.1396
Training Epoch: 55 [16384/50176]	Loss: 1.1126
Training Epoch: 55 [17408/50176]	Loss: 1.2024
Training Epoch: 55 [18432/50176]	Loss: 1.2018
Training Epoch: 55 [19456/50176]	Loss: 1.1444
Training Epoch: 55 [20480/50176]	Loss: 1.1894
Training Epoch: 55 [21504/50176]	Loss: 1.1515
Training Epoch: 55 [22528/50176]	Loss: 1.1244
Training Epoch: 55 [23552/50176]	Loss: 1.2395
Training Epoch: 55 [24576/50176]	Loss: 1.1792
Training Epoch: 55 [25600/50176]	Loss: 1.2077
Training Epoch: 55 [26624/50176]	Loss: 1.1427
Training Epoch: 55 [27648/50176]	Loss: 1.1047
Training Epoch: 55 [28672/50176]	Loss: 1.1467
Training Epoch: 55 [29696/50176]	Loss: 1.2074
Training Epoch: 55 [30720/50176]	Loss: 1.1836
Training Epoch: 55 [31744/50176]	Loss: 1.1825
Training Epoch: 55 [32768/50176]	Loss: 1.2901
Training Epoch: 55 [33792/50176]	Loss: 1.1443
Training Epoch: 55 [34816/50176]	Loss: 1.1728
Training Epoch: 55 [35840/50176]	Loss: 1.2223
Training Epoch: 55 [36864/50176]	Loss: 1.2288
Training Epoch: 55 [37888/50176]	Loss: 1.2890
Training Epoch: 55 [38912/50176]	Loss: 1.1763
Training Epoch: 55 [39936/50176]	Loss: 1.2335
Training Epoch: 55 [40960/50176]	Loss: 1.1456
Training Epoch: 55 [41984/50176]	Loss: 1.1888
Training Epoch: 55 [43008/50176]	Loss: 1.2226
Training Epoch: 55 [44032/50176]	Loss: 1.1074
Training Epoch: 55 [45056/50176]	Loss: 1.2245
Training Epoch: 55 [46080/50176]	Loss: 1.1973
Training Epoch: 55 [47104/50176]	Loss: 1.1910
Training Epoch: 55 [48128/50176]	Loss: 1.2826
Training Epoch: 55 [49152/50176]	Loss: 1.2222
Training Epoch: 55 [50176/50176]	Loss: 1.2744
2022-12-06 18:56:31.018 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:56:31,073 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.80 energy=476.65
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Up to epoch 56: time=2741.72, energy=377648.53, cost=428724.59
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:56:31,074 [ZeusDataLoader(train)] Expected next epoch: time=2788.82, energy=384336.40, cost=436190.09
2022-12-06 13:56:31,075 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0562, Accuracy: 0.0160
2022-12-06 13:56:31,314 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:56:31,314 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:56:31.330 [ZeusMonitor] Monitor started.
2022-12-06 18:56:31.330 [ZeusMonitor] Running indefinitely. 2022-12-06 18:56:31.330 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:56:31.330 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 13:57:15,447 [ZeusDataLoader(train)] train epoch 57 done: time=44.36 energy=6245.50
2022-12-06 13:57:15,450 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 1.1175
Training Epoch: 56 [2048/50176]	Loss: 1.1649
Training Epoch: 56 [3072/50176]	Loss: 1.0873
Training Epoch: 56 [4096/50176]	Loss: 1.0613
Training Epoch: 56 [5120/50176]	Loss: 1.0945
Training Epoch: 56 [6144/50176]	Loss: 1.0774
Training Epoch: 56 [7168/50176]	Loss: 1.0950
Training Epoch: 56 [8192/50176]	Loss: 1.0844
Training Epoch: 56 [9216/50176]	Loss: 1.1739
Training Epoch: 56 [10240/50176]	Loss: 1.0974
Training Epoch: 56 [11264/50176]	Loss: 1.0987
Training Epoch: 56 [12288/50176]	Loss: 1.0587
Training Epoch: 56 [13312/50176]	Loss: 1.1588
Training Epoch: 56 [14336/50176]	Loss: 1.1051
Training Epoch: 56 [15360/50176]	Loss: 1.1422
Training Epoch: 56 [16384/50176]	Loss: 1.0836
Training Epoch: 56 [17408/50176]	Loss: 1.0969
Training Epoch: 56 [18432/50176]	Loss: 1.1909
Training Epoch: 56 [19456/50176]	Loss: 1.1188
Training Epoch: 56 [20480/50176]	Loss: 1.1126
Training Epoch: 56 [21504/50176]	Loss: 1.1166
Training Epoch: 56 [22528/50176]	Loss: 1.1722
Training Epoch: 56 [23552/50176]	Loss: 1.1208
Training Epoch: 56 [24576/50176]	Loss: 1.1658
Training Epoch: 56 [25600/50176]	Loss: 1.0826
Training Epoch: 56 [26624/50176]	Loss: 1.1439
Training Epoch: 56 [27648/50176]	Loss: 1.0545
Training Epoch: 56 [28672/50176]	Loss: 1.1630
Training Epoch: 56 [29696/50176]	Loss: 1.0540
Training Epoch: 56 [30720/50176]	Loss: 1.2135
Training Epoch: 56 [31744/50176]	Loss: 1.1803
Training Epoch: 56 [32768/50176]	Loss: 1.1959
Training Epoch: 56 [33792/50176]	Loss: 1.1144
Training Epoch: 56 [34816/50176]	Loss: 1.1140
Training Epoch: 56 [35840/50176]	Loss: 1.1642
Training Epoch: 56 [36864/50176]	Loss: 1.0800
Training Epoch: 56 [37888/50176]	Loss: 1.2397
Training Epoch: 56 [38912/50176]	Loss: 1.1782
Training Epoch: 56 [39936/50176]	Loss: 1.1279
Training Epoch: 56 [40960/50176]	Loss: 1.1720
Training Epoch: 56 [41984/50176]	Loss: 1.1729
Training Epoch: 56 [43008/50176]	Loss: 1.1603
Training Epoch: 56 [44032/50176]	Loss: 1.1783
Training Epoch: 56 [45056/50176]	Loss: 1.1841
Training Epoch: 56 [46080/50176]	Loss: 1.1252
Training Epoch: 56 [47104/50176]	Loss: 1.1968
Training Epoch: 56 [48128/50176]	Loss: 1.1483
Training Epoch: 56 [49152/50176]	Loss: 1.2436
Training Epoch: 56 [50176/50176]	Loss: 1.1468
2022-12-06 18:57:19.209 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:57:19,239 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.78 energy=484.13
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Up to epoch 57: time=2789.86, energy=384378.15, cost=436302.09
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:57:19,240 [ZeusDataLoader(train)] Expected next epoch: time=2836.97, energy=391066.02, cost=443767.59
2022-12-06 13:57:19,241 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0280, Accuracy: 0.0119
2022-12-06 13:57:19,425 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:57:19,426 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:57:19.428 [ZeusMonitor] Monitor started.
2022-12-06 18:57:19.428 [ZeusMonitor] Running indefinitely. 2022-12-06 18:57:19.428 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:57:19.428 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 13:58:03,604 [ZeusDataLoader(train)] train epoch 58 done: time=44.36 energy=6233.64
2022-12-06 13:58:03,607 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 1.1504
Training Epoch: 57 [2048/50176]	Loss: 1.0693
Training Epoch: 57 [3072/50176]	Loss: 1.1106
Training Epoch: 57 [4096/50176]	Loss: 1.0582
Training Epoch: 57 [5120/50176]	Loss: 1.1234
Training Epoch: 57 [6144/50176]	Loss: 1.1608
Training Epoch: 57 [7168/50176]	Loss: 1.1431
Training Epoch: 57 [8192/50176]	Loss: 1.0983
Training Epoch: 57 [9216/50176]	Loss: 1.0259
Training Epoch: 57 [10240/50176]	Loss: 1.0510
Training Epoch: 57 [11264/50176]	Loss: 1.1385
Training Epoch: 57 [12288/50176]	Loss: 1.0631
Training Epoch: 57 [13312/50176]	Loss: 1.0163
Training Epoch: 57 [14336/50176]	Loss: 1.2078
Training Epoch: 57 [15360/50176]	Loss: 1.0363
Training Epoch: 57 [16384/50176]	Loss: 1.0993
Training Epoch: 57 [17408/50176]	Loss: 1.1246
Training Epoch: 57 [18432/50176]	Loss: 1.1000
Training Epoch: 57 [19456/50176]	Loss: 1.0527
Training Epoch: 57 [20480/50176]	Loss: 1.0630
Training Epoch: 57 [21504/50176]	Loss: 1.1657
Training Epoch: 57 [22528/50176]	Loss: 1.0902
Training Epoch: 57 [23552/50176]	Loss: 1.1360
Training Epoch: 57 [24576/50176]	Loss: 1.0759
Training Epoch: 57 [25600/50176]	Loss: 1.0876
Training Epoch: 57 [26624/50176]	Loss: 1.1053
Training Epoch: 57 [27648/50176]	Loss: 1.1578
Training Epoch: 57 [28672/50176]	Loss: 1.1525
Training Epoch: 57 [29696/50176]	Loss: 1.2037
Training Epoch: 57 [30720/50176]	Loss: 1.0753
Training Epoch: 57 [31744/50176]	Loss: 1.0589
Training Epoch: 57 [32768/50176]	Loss: 1.1723
Training Epoch: 57 [33792/50176]	Loss: 1.1819
Training Epoch: 57 [34816/50176]	Loss: 1.2294
Training Epoch: 57 [35840/50176]	Loss: 1.1462
Training Epoch: 57 [36864/50176]	Loss: 1.1198
Training Epoch: 57 [37888/50176]	Loss: 1.1445
Training Epoch: 57 [38912/50176]	Loss: 1.1002
Training Epoch: 57 [39936/50176]	Loss: 1.1219
Training Epoch: 57 [40960/50176]	Loss: 1.1763
Training Epoch: 57 [41984/50176]	Loss: 1.1198
Training Epoch: 57 [43008/50176]	Loss: 1.1043
Training Epoch: 57 [44032/50176]	Loss: 1.1983
Training Epoch: 57 [45056/50176]	Loss: 1.2251
Training Epoch: 57 [46080/50176]	Loss: 1.1714
Training Epoch: 57 [47104/50176]	Loss: 1.1881
Training Epoch: 57 [48128/50176]	Loss: 1.1750
Training Epoch: 57 [49152/50176]	Loss: 1.2182
Training Epoch: 57 [50176/50176]	Loss: 1.2236
2022-12-06 18:58:07.318 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:58:07,336 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.72 energy=474.92
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Up to epoch 58: time=2837.94, energy=391086.71, cost=443863.02
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:58:07,336 [ZeusDataLoader(train)] Expected next epoch: time=2885.04, energy=397774.59, cost=451328.52
2022-12-06 13:58:07,337 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0404, Accuracy: 0.0208
2022-12-06 13:58:07,574 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:58:07,575 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:58:07.585 [ZeusMonitor] Monitor started.
2022-12-06 18:58:07.585 [ZeusMonitor] Running indefinitely. 2022-12-06 18:58:07.585 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:58:07.585 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 13:58:51,842 [ZeusDataLoader(train)] train epoch 59 done: time=44.50 energy=6242.78
2022-12-06 13:58:51,846 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 1.0346
Training Epoch: 58 [2048/50176]	Loss: 1.0107
Training Epoch: 58 [3072/50176]	Loss: 1.0623
Training Epoch: 58 [4096/50176]	Loss: 1.0089
Training Epoch: 58 [5120/50176]	Loss: 1.0043
Training Epoch: 58 [6144/50176]	Loss: 1.0486
Training Epoch: 58 [7168/50176]	Loss: 1.0117
Training Epoch: 58 [8192/50176]	Loss: 1.0715
Training Epoch: 58 [9216/50176]	Loss: 1.1931
Training Epoch: 58 [10240/50176]	Loss: 1.0744
Training Epoch: 58 [11264/50176]	Loss: 1.0875
Training Epoch: 58 [12288/50176]	Loss: 1.1609
Training Epoch: 58 [13312/50176]	Loss: 1.0311
Training Epoch: 58 [14336/50176]	Loss: 1.0565
Training Epoch: 58 [15360/50176]	Loss: 0.9889
Training Epoch: 58 [16384/50176]	Loss: 1.0275
Training Epoch: 58 [17408/50176]	Loss: 1.1068
Training Epoch: 58 [18432/50176]	Loss: 1.0952
Training Epoch: 58 [19456/50176]	Loss: 1.0570
Training Epoch: 58 [20480/50176]	Loss: 1.0430
Training Epoch: 58 [21504/50176]	Loss: 1.1146
Training Epoch: 58 [22528/50176]	Loss: 1.1319
Training Epoch: 58 [23552/50176]	Loss: 1.1557
Training Epoch: 58 [24576/50176]	Loss: 1.0834
Training Epoch: 58 [25600/50176]	Loss: 1.1167
Training Epoch: 58 [26624/50176]	Loss: 1.1289
Training Epoch: 58 [27648/50176]	Loss: 1.1356
Training Epoch: 58 [28672/50176]	Loss: 1.0820
Training Epoch: 58 [29696/50176]	Loss: 1.1419
Training Epoch: 58 [30720/50176]	Loss: 1.1000
Training Epoch: 58 [31744/50176]	Loss: 1.1730
Training Epoch: 58 [32768/50176]	Loss: 1.1269
Training Epoch: 58 [33792/50176]	Loss: 1.1302
Training Epoch: 58 [34816/50176]	Loss: 1.0883
Training Epoch: 58 [35840/50176]	Loss: 1.0813
Training Epoch: 58 [36864/50176]	Loss: 1.1580
Training Epoch: 58 [37888/50176]	Loss: 1.1747
Training Epoch: 58 [38912/50176]	Loss: 1.1731
Training Epoch: 58 [39936/50176]	Loss: 1.1607
Training Epoch: 58 [40960/50176]	Loss: 1.1562
Training Epoch: 58 [41984/50176]	Loss: 1.1164
Training Epoch: 58 [43008/50176]	Loss: 1.2739
Training Epoch: 58 [44032/50176]	Loss: 1.1564
Training Epoch: 58 [45056/50176]	Loss: 1.1888
Training Epoch: 58 [46080/50176]	Loss: 1.1311
Training Epoch: 58 [47104/50176]	Loss: 1.1688
Training Epoch: 58 [48128/50176]	Loss: 1.1899
Training Epoch: 58 [49152/50176]	Loss: 1.1977
Training Epoch: 58 [50176/50176]	Loss: 1.1754
2022-12-06 18:58:55.575 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:58:55,595 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.74 energy=478.71
2022-12-06 13:58:55,595 [ZeusDataLoader(train)] Up to epoch 59: time=2886.18, energy=397808.21, cost=451444.64
2022-12-06 13:58:55,595 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:58:55,596 [ZeusDataLoader(train)] Expected next epoch: time=2933.28, energy=404496.08, cost=458910.13
2022-12-06 13:58:55,596 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0482, Accuracy: 0.0293
2022-12-06 13:58:55,825 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:58:55,826 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:58:55.828 [ZeusMonitor] Monitor started.
2022-12-06 18:58:55.828 [ZeusMonitor] Running indefinitely. 2022-12-06 18:58:55.828 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:58:55.828 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 13:59:39,580 [ZeusDataLoader(train)] train epoch 60 done: time=43.97 energy=6209.32
2022-12-06 13:59:39,583 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 1.0385
Training Epoch: 59 [2048/50176]	Loss: 1.1787
Training Epoch: 59 [3072/50176]	Loss: 1.0963
Training Epoch: 59 [4096/50176]	Loss: 1.0743
Training Epoch: 59 [5120/50176]	Loss: 0.9267
Training Epoch: 59 [6144/50176]	Loss: 1.1174
Training Epoch: 59 [7168/50176]	Loss: 1.1012
Training Epoch: 59 [8192/50176]	Loss: 1.0913
Training Epoch: 59 [9216/50176]	Loss: 1.0595
Training Epoch: 59 [10240/50176]	Loss: 1.1085
Training Epoch: 59 [11264/50176]	Loss: 1.0053
Training Epoch: 59 [12288/50176]	Loss: 1.0780
Training Epoch: 59 [13312/50176]	Loss: 1.0691
Training Epoch: 59 [14336/50176]	Loss: 1.0925
Training Epoch: 59 [15360/50176]	Loss: 1.0501
Training Epoch: 59 [16384/50176]	Loss: 1.0495
Training Epoch: 59 [17408/50176]	Loss: 1.0884
Training Epoch: 59 [18432/50176]	Loss: 1.0543
Training Epoch: 59 [19456/50176]	Loss: 1.0702
Training Epoch: 59 [20480/50176]	Loss: 1.1431
Training Epoch: 59 [21504/50176]	Loss: 1.1453
Training Epoch: 59 [22528/50176]	Loss: 1.1179
Training Epoch: 59 [23552/50176]	Loss: 1.1162
Training Epoch: 59 [24576/50176]	Loss: 1.0724
Training Epoch: 59 [25600/50176]	Loss: 1.1233
Training Epoch: 59 [26624/50176]	Loss: 1.0851
Training Epoch: 59 [27648/50176]	Loss: 1.0990
Training Epoch: 59 [28672/50176]	Loss: 1.1001
Training Epoch: 59 [29696/50176]	Loss: 1.1222
Training Epoch: 59 [30720/50176]	Loss: 1.1803
Training Epoch: 59 [31744/50176]	Loss: 1.0695
Training Epoch: 59 [32768/50176]	Loss: 1.0395
Training Epoch: 59 [33792/50176]	Loss: 1.1666
Training Epoch: 59 [34816/50176]	Loss: 1.1202
Training Epoch: 59 [35840/50176]	Loss: 1.2064
Training Epoch: 59 [36864/50176]	Loss: 1.2289
Training Epoch: 59 [37888/50176]	Loss: 1.2045
Training Epoch: 59 [38912/50176]	Loss: 1.1227
Training Epoch: 59 [39936/50176]	Loss: 1.1209
Training Epoch: 59 [40960/50176]	Loss: 1.1713
Training Epoch: 59 [41984/50176]	Loss: 1.1436
Training Epoch: 59 [43008/50176]	Loss: 1.1474
Training Epoch: 59 [44032/50176]	Loss: 1.1342
Training Epoch: 59 [45056/50176]	Loss: 1.1181
Training Epoch: 59 [46080/50176]	Loss: 1.1698
Training Epoch: 59 [47104/50176]	Loss: 1.1450
Training Epoch: 59 [48128/50176]	Loss: 1.1370
Training Epoch: 59 [49152/50176]	Loss: 1.1340
Training Epoch: 59 [50176/50176]	Loss: 1.1498
2022-12-06 18:59:43.339 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 13:59:43,388 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.80 energy=482.69
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Up to epoch 60: time=2933.95, energy=404500.22, cost=458970.64
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 13:59:43,388 [ZeusDataLoader(train)] Expected next epoch: time=2981.05, energy=411188.10, cost=466436.14
2022-12-06 13:59:43,389 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0458, Accuracy: 0.0282
2022-12-06 13:59:43,630 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 13:59:43,631 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 18:59:43.632 [ZeusMonitor] Monitor started.
2022-12-06 18:59:43.633 [ZeusMonitor] Running indefinitely. 2022-12-06 18:59:43.633 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 18:59:43.633 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 14:00:27,396 [ZeusDataLoader(train)] train epoch 61 done: time=44.00 energy=6211.22
2022-12-06 14:00:27,401 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.9926
Training Epoch: 60 [2048/50176]	Loss: 1.0860
Training Epoch: 60 [3072/50176]	Loss: 1.0454
Training Epoch: 60 [4096/50176]	Loss: 0.9666
Training Epoch: 60 [5120/50176]	Loss: 1.1595
Training Epoch: 60 [6144/50176]	Loss: 1.0380
Training Epoch: 60 [7168/50176]	Loss: 1.0592
Training Epoch: 60 [8192/50176]	Loss: 1.0066
Training Epoch: 60 [9216/50176]	Loss: 1.1188
Training Epoch: 60 [10240/50176]	Loss: 1.0441
Training Epoch: 60 [11264/50176]	Loss: 1.0610
Training Epoch: 60 [12288/50176]	Loss: 1.1789
Training Epoch: 60 [13312/50176]	Loss: 1.1154
Training Epoch: 60 [14336/50176]	Loss: 1.0891
Training Epoch: 60 [15360/50176]	Loss: 1.0017
Training Epoch: 60 [16384/50176]	Loss: 1.0816
Training Epoch: 60 [17408/50176]	Loss: 1.0981
Training Epoch: 60 [18432/50176]	Loss: 1.0974
Training Epoch: 60 [19456/50176]	Loss: 1.0536
Training Epoch: 60 [20480/50176]	Loss: 1.0137
Training Epoch: 60 [21504/50176]	Loss: 1.0453
Training Epoch: 60 [22528/50176]	Loss: 1.0802
Training Epoch: 60 [23552/50176]	Loss: 1.0153
Training Epoch: 60 [24576/50176]	Loss: 1.1071
Training Epoch: 60 [25600/50176]	Loss: 1.2191
Training Epoch: 60 [26624/50176]	Loss: 1.0575
Training Epoch: 60 [27648/50176]	Loss: 1.0837
Training Epoch: 60 [28672/50176]	Loss: 1.0882
Training Epoch: 60 [29696/50176]	Loss: 1.0826
Training Epoch: 60 [30720/50176]	Loss: 1.0803
Training Epoch: 60 [31744/50176]	Loss: 1.1113
Training Epoch: 60 [32768/50176]	Loss: 1.0505
Training Epoch: 60 [33792/50176]	Loss: 1.1531
Training Epoch: 60 [34816/50176]	Loss: 1.0703
Training Epoch: 60 [35840/50176]	Loss: 1.0400
Training Epoch: 60 [36864/50176]	Loss: 1.1777
Training Epoch: 60 [37888/50176]	Loss: 1.1320
Training Epoch: 60 [38912/50176]	Loss: 1.1313
Training Epoch: 60 [39936/50176]	Loss: 1.0850
Training Epoch: 60 [40960/50176]	Loss: 1.0991
Training Epoch: 60 [41984/50176]	Loss: 1.1100
Training Epoch: 60 [43008/50176]	Loss: 1.1362
Training Epoch: 60 [44032/50176]	Loss: 1.1122
Training Epoch: 60 [45056/50176]	Loss: 1.0782
Training Epoch: 60 [46080/50176]	Loss: 1.1014
Training Epoch: 60 [47104/50176]	Loss: 1.0498
Training Epoch: 60 [48128/50176]	Loss: 1.1158
Training Epoch: 60 [49152/50176]	Loss: 1.0590
Training Epoch: 60 [50176/50176]	Loss: 1.1462
2022-12-06 19:00:31.141 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:00:31,156 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.75 energy=473.52
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Up to epoch 61: time=2981.70, energy=411184.96, cost=466490.82
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:00:31,157 [ZeusDataLoader(train)] Expected next epoch: time=3028.80, energy=417872.84, cost=473956.31
2022-12-06 14:00:31,158 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0167, Accuracy: 0.0314
2022-12-06 14:00:31,349 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:00:31,349 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:00:31.351 [ZeusMonitor] Monitor started.
2022-12-06 19:00:31.351 [ZeusMonitor] Running indefinitely. 2022-12-06 19:00:31.351 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:00:31.351 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 14:01:15,316 [ZeusDataLoader(train)] train epoch 62 done: time=44.15 energy=6219.02
2022-12-06 14:01:15,320 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.9914
Training Epoch: 61 [2048/50176]	Loss: 0.9917
Training Epoch: 61 [3072/50176]	Loss: 0.9425
Training Epoch: 61 [4096/50176]	Loss: 1.0903
Training Epoch: 61 [5120/50176]	Loss: 1.0030
Training Epoch: 61 [6144/50176]	Loss: 1.1179
Training Epoch: 61 [7168/50176]	Loss: 1.1143
Training Epoch: 61 [8192/50176]	Loss: 0.9665
Training Epoch: 61 [9216/50176]	Loss: 1.0162
Training Epoch: 61 [10240/50176]	Loss: 0.9429
Training Epoch: 61 [11264/50176]	Loss: 1.0241
Training Epoch: 61 [12288/50176]	Loss: 1.0394
Training Epoch: 61 [13312/50176]	Loss: 1.1281
Training Epoch: 61 [14336/50176]	Loss: 1.1380
Training Epoch: 61 [15360/50176]	Loss: 0.9633
Training Epoch: 61 [16384/50176]	Loss: 1.0660
Training Epoch: 61 [17408/50176]	Loss: 1.0081
Training Epoch: 61 [18432/50176]	Loss: 1.0779
Training Epoch: 61 [19456/50176]	Loss: 0.9652
Training Epoch: 61 [20480/50176]	Loss: 1.0414
Training Epoch: 61 [21504/50176]	Loss: 1.0830
Training Epoch: 61 [22528/50176]	Loss: 1.1028
Training Epoch: 61 [23552/50176]	Loss: 0.9612
Training Epoch: 61 [24576/50176]	Loss: 1.0312
Training Epoch: 61 [25600/50176]	Loss: 1.1178
Training Epoch: 61 [26624/50176]	Loss: 1.1137
Training Epoch: 61 [27648/50176]	Loss: 1.0856
Training Epoch: 61 [28672/50176]	Loss: 1.0739
Training Epoch: 61 [29696/50176]	Loss: 1.0346
Training Epoch: 61 [30720/50176]	Loss: 1.0859
Training Epoch: 61 [31744/50176]	Loss: 1.0025
Training Epoch: 61 [32768/50176]	Loss: 1.0845
Training Epoch: 61 [33792/50176]	Loss: 1.2118
Training Epoch: 61 [34816/50176]	Loss: 1.0499
Training Epoch: 61 [35840/50176]	Loss: 1.0434
Training Epoch: 61 [36864/50176]	Loss: 1.0875
Training Epoch: 61 [37888/50176]	Loss: 1.1183
Training Epoch: 61 [38912/50176]	Loss: 1.1856
Training Epoch: 61 [39936/50176]	Loss: 1.0809
Training Epoch: 61 [40960/50176]	Loss: 1.1480
Training Epoch: 61 [41984/50176]	Loss: 1.1197
Training Epoch: 61 [43008/50176]	Loss: 1.1380
Training Epoch: 61 [44032/50176]	Loss: 1.1432
Training Epoch: 61 [45056/50176]	Loss: 1.1526
Training Epoch: 61 [46080/50176]	Loss: 1.1332
Training Epoch: 61 [47104/50176]	Loss: 1.1347
Training Epoch: 61 [48128/50176]	Loss: 1.0612
Training Epoch: 61 [49152/50176]	Loss: 1.2190
Training Epoch: 61 [50176/50176]	Loss: 1.0842
2022-12-06 19:01:19.079 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:01:19,112 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.78 energy=475.83
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Up to epoch 62: time=3029.63, energy=417879.82, cost=474032.53
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:01:19,113 [ZeusDataLoader(train)] Expected next epoch: time=3076.73, energy=424567.69, cost=481498.03
2022-12-06 14:01:19,114 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0115, Accuracy: 0.0412
2022-12-06 14:01:19,309 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:01:19,310 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:01:19.313 [ZeusMonitor] Monitor started.
2022-12-06 19:01:19.313 [ZeusMonitor] Running indefinitely. 2022-12-06 19:01:19.313 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:01:19.313 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 14:02:03,352 [ZeusDataLoader(train)] train epoch 63 done: time=44.23 energy=6232.87
2022-12-06 14:02:03,355 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.9952
Training Epoch: 62 [2048/50176]	Loss: 0.9914
Training Epoch: 62 [3072/50176]	Loss: 0.9966
Training Epoch: 62 [4096/50176]	Loss: 1.0720
Training Epoch: 62 [5120/50176]	Loss: 1.0388
Training Epoch: 62 [6144/50176]	Loss: 0.9879
Training Epoch: 62 [7168/50176]	Loss: 1.0338
Training Epoch: 62 [8192/50176]	Loss: 1.1398
Training Epoch: 62 [9216/50176]	Loss: 0.9582
Training Epoch: 62 [10240/50176]	Loss: 0.9940
Training Epoch: 62 [11264/50176]	Loss: 1.0338
Training Epoch: 62 [12288/50176]	Loss: 0.9962
Training Epoch: 62 [13312/50176]	Loss: 1.0255
Training Epoch: 62 [14336/50176]	Loss: 1.0374
Training Epoch: 62 [15360/50176]	Loss: 1.0264
Training Epoch: 62 [16384/50176]	Loss: 1.0180
Training Epoch: 62 [17408/50176]	Loss: 1.0256
Training Epoch: 62 [18432/50176]	Loss: 1.1123
Training Epoch: 62 [19456/50176]	Loss: 1.0553
Training Epoch: 62 [20480/50176]	Loss: 1.1286
Training Epoch: 62 [21504/50176]	Loss: 1.0118
Training Epoch: 62 [22528/50176]	Loss: 1.1010
Training Epoch: 62 [23552/50176]	Loss: 1.0512
Training Epoch: 62 [24576/50176]	Loss: 1.1541
Training Epoch: 62 [25600/50176]	Loss: 0.9505
Training Epoch: 62 [26624/50176]	Loss: 0.9928
Training Epoch: 62 [27648/50176]	Loss: 1.1295
Training Epoch: 62 [28672/50176]	Loss: 1.0159
Training Epoch: 62 [29696/50176]	Loss: 1.0322
Training Epoch: 62 [30720/50176]	Loss: 1.0492
Training Epoch: 62 [31744/50176]	Loss: 1.1064
Training Epoch: 62 [32768/50176]	Loss: 1.1508
Training Epoch: 62 [33792/50176]	Loss: 1.0049
Training Epoch: 62 [34816/50176]	Loss: 1.0573
Training Epoch: 62 [35840/50176]	Loss: 1.0461
Training Epoch: 62 [36864/50176]	Loss: 1.1165
Training Epoch: 62 [37888/50176]	Loss: 1.0927
Training Epoch: 62 [38912/50176]	Loss: 1.0592
Training Epoch: 62 [39936/50176]	Loss: 1.0685
Training Epoch: 62 [40960/50176]	Loss: 1.1025
Training Epoch: 62 [41984/50176]	Loss: 1.0679
Training Epoch: 62 [43008/50176]	Loss: 1.1594
Training Epoch: 62 [44032/50176]	Loss: 1.0358
Training Epoch: 62 [45056/50176]	Loss: 1.1613
Training Epoch: 62 [46080/50176]	Loss: 1.0737
Training Epoch: 62 [47104/50176]	Loss: 1.1696
Training Epoch: 62 [48128/50176]	Loss: 1.1805
Training Epoch: 62 [49152/50176]	Loss: 1.1553
Training Epoch: 62 [50176/50176]	Loss: 1.1902
2022-12-06 19:02:07.133 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:02:07,169 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.81 energy=489.18
2022-12-06 14:02:07,169 [ZeusDataLoader(train)] Up to epoch 63: time=3077.67, energy=424601.86, cost=481596.69
2022-12-06 14:02:07,170 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:02:07,170 [ZeusDataLoader(train)] Expected next epoch: time=3124.77, energy=431289.74, cost=489062.19
2022-12-06 14:02:07,171 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0148, Accuracy: 0.0339
2022-12-06 14:02:07,407 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:02:07,407 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:02:07.409 [ZeusMonitor] Monitor started.
2022-12-06 19:02:07.409 [ZeusMonitor] Running indefinitely. 2022-12-06 19:02:07.409 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:02:07.409 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 14:02:51,630 [ZeusDataLoader(train)] train epoch 64 done: time=44.45 energy=6236.69
2022-12-06 14:02:51,634 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 1.0447
Training Epoch: 63 [2048/50176]	Loss: 1.0120
Training Epoch: 63 [3072/50176]	Loss: 1.0635
Training Epoch: 63 [4096/50176]	Loss: 1.0735
Training Epoch: 63 [5120/50176]	Loss: 1.0083
Training Epoch: 63 [6144/50176]	Loss: 0.9827
Training Epoch: 63 [7168/50176]	Loss: 1.0128
Training Epoch: 63 [8192/50176]	Loss: 1.0541
Training Epoch: 63 [9216/50176]	Loss: 0.9929
Training Epoch: 63 [10240/50176]	Loss: 1.0211
Training Epoch: 63 [11264/50176]	Loss: 1.0579
Training Epoch: 63 [12288/50176]	Loss: 1.0056
Training Epoch: 63 [13312/50176]	Loss: 0.9902
Training Epoch: 63 [14336/50176]	Loss: 1.1393
Training Epoch: 63 [15360/50176]	Loss: 1.0195
Training Epoch: 63 [16384/50176]	Loss: 1.0287
Training Epoch: 63 [17408/50176]	Loss: 0.9238
Training Epoch: 63 [18432/50176]	Loss: 1.0193
Training Epoch: 63 [19456/50176]	Loss: 1.0355
Training Epoch: 63 [20480/50176]	Loss: 1.0271
Training Epoch: 63 [21504/50176]	Loss: 1.1465
Training Epoch: 63 [22528/50176]	Loss: 1.0055
Training Epoch: 63 [23552/50176]	Loss: 1.0590
Training Epoch: 63 [24576/50176]	Loss: 0.9713
Training Epoch: 63 [25600/50176]	Loss: 1.0369
Training Epoch: 63 [26624/50176]	Loss: 1.0223
Training Epoch: 63 [27648/50176]	Loss: 1.0098
Training Epoch: 63 [28672/50176]	Loss: 1.0700
Training Epoch: 63 [29696/50176]	Loss: 1.0489
Training Epoch: 63 [30720/50176]	Loss: 1.0429
Training Epoch: 63 [31744/50176]	Loss: 1.0892
Training Epoch: 63 [32768/50176]	Loss: 1.1486
Training Epoch: 63 [33792/50176]	Loss: 1.0858
Training Epoch: 63 [34816/50176]	Loss: 0.9691
Training Epoch: 63 [35840/50176]	Loss: 0.9987
Training Epoch: 63 [36864/50176]	Loss: 1.0665
Training Epoch: 63 [37888/50176]	Loss: 1.0802
Training Epoch: 63 [38912/50176]	Loss: 1.0722
Training Epoch: 63 [39936/50176]	Loss: 1.0371
Training Epoch: 63 [40960/50176]	Loss: 1.0498
Training Epoch: 63 [41984/50176]	Loss: 1.0797
Training Epoch: 63 [43008/50176]	Loss: 1.1317
Training Epoch: 63 [44032/50176]	Loss: 1.0184
Training Epoch: 63 [45056/50176]	Loss: 0.9830
Training Epoch: 63 [46080/50176]	Loss: 1.0299
Training Epoch: 63 [47104/50176]	Loss: 1.0739
Training Epoch: 63 [48128/50176]	Loss: 1.0393
Training Epoch: 63 [49152/50176]	Loss: 1.0843
Training Epoch: 63 [50176/50176]	Loss: 1.0258
2022-12-06 19:02:55.342 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:02:55,380 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.74 energy=473.26
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Up to epoch 64: time=3125.85, energy=431311.81, cost=489168.21
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:02:55,380 [ZeusDataLoader(train)] Expected next epoch: time=3172.96, energy=437999.69, cost=496633.71
2022-12-06 14:02:55,381 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0197, Accuracy: 0.0271
2022-12-06 14:02:55,613 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:02:55,614 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:02:55.632 [ZeusMonitor] Monitor started.
2022-12-06 19:02:55.632 [ZeusMonitor] Running indefinitely. 2022-12-06 19:02:55.632 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:02:55.632 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 14:03:39,832 [ZeusDataLoader(train)] train epoch 65 done: time=44.44 energy=6239.38
2022-12-06 14:03:39,835 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 1.0048
Training Epoch: 64 [2048/50176]	Loss: 0.9348
Training Epoch: 64 [3072/50176]	Loss: 0.9348
Training Epoch: 64 [4096/50176]	Loss: 0.9694
Training Epoch: 64 [5120/50176]	Loss: 1.0026
Training Epoch: 64 [6144/50176]	Loss: 0.9543
Training Epoch: 64 [7168/50176]	Loss: 1.0299
Training Epoch: 64 [8192/50176]	Loss: 0.9063
Training Epoch: 64 [9216/50176]	Loss: 0.9722
Training Epoch: 64 [10240/50176]	Loss: 1.0051
Training Epoch: 64 [11264/50176]	Loss: 0.9458
Training Epoch: 64 [12288/50176]	Loss: 0.9993
Training Epoch: 64 [13312/50176]	Loss: 1.0037
Training Epoch: 64 [14336/50176]	Loss: 0.9843
Training Epoch: 64 [15360/50176]	Loss: 0.9568
Training Epoch: 64 [16384/50176]	Loss: 0.9605
Training Epoch: 64 [17408/50176]	Loss: 0.9465
Training Epoch: 64 [18432/50176]	Loss: 0.9851
Training Epoch: 64 [19456/50176]	Loss: 1.0611
Training Epoch: 64 [20480/50176]	Loss: 1.0299
Training Epoch: 64 [21504/50176]	Loss: 0.9944
Training Epoch: 64 [22528/50176]	Loss: 1.0370
Training Epoch: 64 [23552/50176]	Loss: 1.0890
Training Epoch: 64 [24576/50176]	Loss: 0.9420
Training Epoch: 64 [25600/50176]	Loss: 0.9657
Training Epoch: 64 [26624/50176]	Loss: 1.0208
Training Epoch: 64 [27648/50176]	Loss: 1.0369
Training Epoch: 64 [28672/50176]	Loss: 1.0283
Training Epoch: 64 [29696/50176]	Loss: 1.0247
Training Epoch: 64 [30720/50176]	Loss: 1.0846
Training Epoch: 64 [31744/50176]	Loss: 0.9501
Training Epoch: 64 [32768/50176]	Loss: 1.0794
Training Epoch: 64 [33792/50176]	Loss: 1.1592
Training Epoch: 64 [34816/50176]	Loss: 1.0090
Training Epoch: 64 [35840/50176]	Loss: 1.0515
Training Epoch: 64 [36864/50176]	Loss: 1.0879
Training Epoch: 64 [37888/50176]	Loss: 1.0777
Training Epoch: 64 [38912/50176]	Loss: 1.0715
Training Epoch: 64 [39936/50176]	Loss: 0.9994
Training Epoch: 64 [40960/50176]	Loss: 1.0427
Training Epoch: 64 [41984/50176]	Loss: 1.0185
Training Epoch: 64 [43008/50176]	Loss: 1.0442
Training Epoch: 64 [44032/50176]	Loss: 1.0530
Training Epoch: 64 [45056/50176]	Loss: 1.1019
Training Epoch: 64 [46080/50176]	Loss: 1.1289
Training Epoch: 64 [47104/50176]	Loss: 1.0460
Training Epoch: 64 [48128/50176]	Loss: 1.0262
Training Epoch: 64 [49152/50176]	Loss: 1.0720
Training Epoch: 64 [50176/50176]	Loss: 1.0727
2022-12-06 19:03:43.572 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:03:43,598 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.75 energy=472.29
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Up to epoch 65: time=3174.05, energy=438023.48, cost=496741.31
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:03:43,598 [ZeusDataLoader(train)] Expected next epoch: time=3221.16, energy=444711.36, cost=504206.80
2022-12-06 14:03:43,599 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0232, Accuracy: 0.0222
2022-12-06 14:03:43,845 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:03:43,846 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:03:43.848 [ZeusMonitor] Monitor started.
2022-12-06 19:03:43.848 [ZeusMonitor] Running indefinitely. 2022-12-06 19:03:43.848 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:03:43.848 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 14:04:28,312 [ZeusDataLoader(train)] train epoch 66 done: time=44.71 energy=6262.44
2022-12-06 14:04:28,315 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.9303
Training Epoch: 65 [2048/50176]	Loss: 0.8908
Training Epoch: 65 [3072/50176]	Loss: 0.9718
Training Epoch: 65 [4096/50176]	Loss: 0.9082
Training Epoch: 65 [5120/50176]	Loss: 0.9742
Training Epoch: 65 [6144/50176]	Loss: 1.0175
Training Epoch: 65 [7168/50176]	Loss: 0.9209
Training Epoch: 65 [8192/50176]	Loss: 0.9310
Training Epoch: 65 [9216/50176]	Loss: 0.9363
Training Epoch: 65 [10240/50176]	Loss: 1.0333
Training Epoch: 65 [11264/50176]	Loss: 0.9918
Training Epoch: 65 [12288/50176]	Loss: 0.9453
Training Epoch: 65 [13312/50176]	Loss: 0.9875
Training Epoch: 65 [14336/50176]	Loss: 0.9625
Training Epoch: 65 [15360/50176]	Loss: 0.9581
Training Epoch: 65 [16384/50176]	Loss: 1.0058
Training Epoch: 65 [17408/50176]	Loss: 0.9097
Training Epoch: 65 [18432/50176]	Loss: 1.0570
Training Epoch: 65 [19456/50176]	Loss: 0.9844
Training Epoch: 65 [20480/50176]	Loss: 0.9666
Training Epoch: 65 [21504/50176]	Loss: 1.0511
Training Epoch: 65 [22528/50176]	Loss: 1.0171
Training Epoch: 65 [23552/50176]	Loss: 1.0861
Training Epoch: 65 [24576/50176]	Loss: 0.9204
Training Epoch: 65 [25600/50176]	Loss: 0.9860
Training Epoch: 65 [26624/50176]	Loss: 1.0488
Training Epoch: 65 [27648/50176]	Loss: 1.0494
Training Epoch: 65 [28672/50176]	Loss: 0.9193
Training Epoch: 65 [29696/50176]	Loss: 1.0188
Training Epoch: 65 [30720/50176]	Loss: 1.0301
Training Epoch: 65 [31744/50176]	Loss: 1.0130
Training Epoch: 65 [32768/50176]	Loss: 0.9652
Training Epoch: 65 [33792/50176]	Loss: 1.0358
Training Epoch: 65 [34816/50176]	Loss: 1.0560
Training Epoch: 65 [35840/50176]	Loss: 0.9818
Training Epoch: 65 [36864/50176]	Loss: 1.0525
Training Epoch: 65 [37888/50176]	Loss: 0.9576
Training Epoch: 65 [38912/50176]	Loss: 1.0495
Training Epoch: 65 [39936/50176]	Loss: 1.0239
Training Epoch: 65 [40960/50176]	Loss: 1.0587
Training Epoch: 65 [41984/50176]	Loss: 1.0698
Training Epoch: 65 [43008/50176]	Loss: 1.0394
Training Epoch: 65 [44032/50176]	Loss: 1.0417
Training Epoch: 65 [45056/50176]	Loss: 1.0814
Training Epoch: 65 [46080/50176]	Loss: 1.0558
Training Epoch: 65 [47104/50176]	Loss: 1.0453
Training Epoch: 65 [48128/50176]	Loss: 1.0973
Training Epoch: 65 [49152/50176]	Loss: 1.1397
Training Epoch: 65 [50176/50176]	Loss: 1.1339
2022-12-06 19:04:32.071 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:04:32,114 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.79 energy=482.34
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Up to epoch 66: time=3222.55, energy=444768.26, cost=504357.11
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:04:32,115 [ZeusDataLoader(train)] Expected next epoch: time=3269.65, energy=451456.14, cost=511822.60
2022-12-06 14:04:32,116 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0136, Accuracy: 0.0614
2022-12-06 14:04:32,364 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:04:32,364 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:04:32.366 [ZeusMonitor] Monitor started.
2022-12-06 19:04:32.366 [ZeusMonitor] Running indefinitely. 2022-12-06 19:04:32.366 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:04:32.366 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 14:05:16,974 [ZeusDataLoader(train)] train epoch 67 done: time=44.85 energy=6271.98
2022-12-06 14:05:16,978 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.9098
Training Epoch: 66 [2048/50176]	Loss: 0.9574
Training Epoch: 66 [3072/50176]	Loss: 0.9156
Training Epoch: 66 [4096/50176]	Loss: 1.0043
Training Epoch: 66 [5120/50176]	Loss: 1.0769
Training Epoch: 66 [6144/50176]	Loss: 0.8489
Training Epoch: 66 [7168/50176]	Loss: 1.0042
Training Epoch: 66 [8192/50176]	Loss: 0.9955
Training Epoch: 66 [9216/50176]	Loss: 0.8813
Training Epoch: 66 [10240/50176]	Loss: 0.9815
Training Epoch: 66 [11264/50176]	Loss: 1.0227
Training Epoch: 66 [12288/50176]	Loss: 0.9894
Training Epoch: 66 [13312/50176]	Loss: 0.9377
Training Epoch: 66 [14336/50176]	Loss: 0.9456
Training Epoch: 66 [15360/50176]	Loss: 0.8771
Training Epoch: 66 [16384/50176]	Loss: 1.0656
Training Epoch: 66 [17408/50176]	Loss: 0.9481
Training Epoch: 66 [18432/50176]	Loss: 0.9618
Training Epoch: 66 [19456/50176]	Loss: 0.9863
Training Epoch: 66 [20480/50176]	Loss: 0.9548
Training Epoch: 66 [21504/50176]	Loss: 0.9740
Training Epoch: 66 [22528/50176]	Loss: 0.9232
Training Epoch: 66 [23552/50176]	Loss: 0.9556
Training Epoch: 66 [24576/50176]	Loss: 0.9889
Training Epoch: 66 [25600/50176]	Loss: 1.1094
Training Epoch: 66 [26624/50176]	Loss: 1.0133
Training Epoch: 66 [27648/50176]	Loss: 1.0916
Training Epoch: 66 [28672/50176]	Loss: 1.0939
Training Epoch: 66 [29696/50176]	Loss: 0.9967
Training Epoch: 66 [30720/50176]	Loss: 1.0592
Training Epoch: 66 [31744/50176]	Loss: 0.9358
Training Epoch: 66 [32768/50176]	Loss: 1.0458
Training Epoch: 66 [33792/50176]	Loss: 1.0111
Training Epoch: 66 [34816/50176]	Loss: 1.0412
Training Epoch: 66 [35840/50176]	Loss: 1.0219
Training Epoch: 66 [36864/50176]	Loss: 1.0239
Training Epoch: 66 [37888/50176]	Loss: 1.0330
Training Epoch: 66 [38912/50176]	Loss: 0.9884
Training Epoch: 66 [39936/50176]	Loss: 1.0376
Training Epoch: 66 [40960/50176]	Loss: 1.0464
Training Epoch: 66 [41984/50176]	Loss: 0.9882
Training Epoch: 66 [43008/50176]	Loss: 1.0646
Training Epoch: 66 [44032/50176]	Loss: 1.0204
Training Epoch: 66 [45056/50176]	Loss: 0.9939
Training Epoch: 66 [46080/50176]	Loss: 1.0586
Training Epoch: 66 [47104/50176]	Loss: 1.0554
Training Epoch: 66 [48128/50176]	Loss: 1.0484
Training Epoch: 66 [49152/50176]	Loss: 0.9987
Training Epoch: 66 [50176/50176]	Loss: 1.0816
2022-12-06 19:05:20.728 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:05:20,762 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.78 energy=474.03
2022-12-06 14:05:20,762 [ZeusDataLoader(train)] Up to epoch 67: time=3271.18, energy=451514.27, cost=511984.99
2022-12-06 14:05:20,763 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:05:20,763 [ZeusDataLoader(train)] Expected next epoch: time=3318.28, energy=458202.14, cost=519450.48
2022-12-06 14:05:20,764 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0218, Accuracy: 0.0258
2022-12-06 14:05:21,001 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:05:21,002 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:05:21.003 [ZeusMonitor] Monitor started.
2022-12-06 19:05:21.004 [ZeusMonitor] Running indefinitely. 2022-12-06 19:05:21.004 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:05:21.004 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 14:06:05,365 [ZeusDataLoader(train)] train epoch 68 done: time=44.59 energy=6260.79
2022-12-06 14:06:05,368 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.9295
Training Epoch: 67 [2048/50176]	Loss: 0.9807
Training Epoch: 67 [3072/50176]	Loss: 0.9563
Training Epoch: 67 [4096/50176]	Loss: 0.9693
Training Epoch: 67 [5120/50176]	Loss: 0.9767
Training Epoch: 67 [6144/50176]	Loss: 0.9830
Training Epoch: 67 [7168/50176]	Loss: 0.9440
Training Epoch: 67 [8192/50176]	Loss: 0.9700
Training Epoch: 67 [9216/50176]	Loss: 0.9499
Training Epoch: 67 [10240/50176]	Loss: 0.9532
Training Epoch: 67 [11264/50176]	Loss: 0.9435
Training Epoch: 67 [12288/50176]	Loss: 0.9016
Training Epoch: 67 [13312/50176]	Loss: 0.9989
Training Epoch: 67 [14336/50176]	Loss: 0.9037
Training Epoch: 67 [15360/50176]	Loss: 0.8840
Training Epoch: 67 [16384/50176]	Loss: 0.9797
Training Epoch: 67 [17408/50176]	Loss: 0.9356
Training Epoch: 67 [18432/50176]	Loss: 1.1034
Training Epoch: 67 [19456/50176]	Loss: 1.0201
Training Epoch: 67 [20480/50176]	Loss: 0.9876
Training Epoch: 67 [21504/50176]	Loss: 0.9921
Training Epoch: 67 [22528/50176]	Loss: 0.9795
Training Epoch: 67 [23552/50176]	Loss: 0.9361
Training Epoch: 67 [24576/50176]	Loss: 0.9627
Training Epoch: 67 [25600/50176]	Loss: 1.0250
Training Epoch: 67 [26624/50176]	Loss: 0.9895
Training Epoch: 67 [27648/50176]	Loss: 0.9788
Training Epoch: 67 [28672/50176]	Loss: 1.0111
Training Epoch: 67 [29696/50176]	Loss: 0.9951
Training Epoch: 67 [30720/50176]	Loss: 1.0109
Training Epoch: 67 [31744/50176]	Loss: 1.0245
Training Epoch: 67 [32768/50176]	Loss: 0.9451
Training Epoch: 67 [33792/50176]	Loss: 0.9769
Training Epoch: 67 [34816/50176]	Loss: 0.9843
Training Epoch: 67 [35840/50176]	Loss: 0.9946
Training Epoch: 67 [36864/50176]	Loss: 0.9508
Training Epoch: 67 [37888/50176]	Loss: 1.0413
Training Epoch: 67 [38912/50176]	Loss: 1.0058
Training Epoch: 67 [39936/50176]	Loss: 1.0456
Training Epoch: 67 [40960/50176]	Loss: 1.0704
Training Epoch: 67 [41984/50176]	Loss: 0.9679
Training Epoch: 67 [43008/50176]	Loss: 1.0199
Training Epoch: 67 [44032/50176]	Loss: 1.0289
Training Epoch: 67 [45056/50176]	Loss: 1.0940
Training Epoch: 67 [46080/50176]	Loss: 1.0706
Training Epoch: 67 [47104/50176]	Loss: 0.9919
Training Epoch: 67 [48128/50176]	Loss: 0.9812
Training Epoch: 67 [49152/50176]	Loss: 1.0231
Training Epoch: 67 [50176/50176]	Loss: 0.9545
2022-12-06 19:06:09.036 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:06:09,048 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.67 energy=461.69
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Up to epoch 68: time=3319.44, energy=458236.74, cost=519569.40
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:06:09,048 [ZeusDataLoader(train)] Expected next epoch: time=3366.54, energy=464924.62, cost=527034.90
2022-12-06 14:06:09,049 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0717, Accuracy: 0.0158
2022-12-06 14:06:09,241 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:06:09,242 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:06:09.245 [ZeusMonitor] Monitor started.
2022-12-06 19:06:09.245 [ZeusMonitor] Running indefinitely. 2022-12-06 19:06:09.245 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:06:09.245 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 14:06:53,530 [ZeusDataLoader(train)] train epoch 69 done: time=44.47 energy=6255.08
2022-12-06 14:06:53,533 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.8941
Training Epoch: 68 [2048/50176]	Loss: 0.8841
Training Epoch: 68 [3072/50176]	Loss: 0.9077
Training Epoch: 68 [4096/50176]	Loss: 0.8932
Training Epoch: 68 [5120/50176]	Loss: 0.9385
Training Epoch: 68 [6144/50176]	Loss: 0.9754
Training Epoch: 68 [7168/50176]	Loss: 0.9930
Training Epoch: 68 [8192/50176]	Loss: 0.9432
Training Epoch: 68 [9216/50176]	Loss: 0.9593
Training Epoch: 68 [10240/50176]	Loss: 0.8456
Training Epoch: 68 [11264/50176]	Loss: 0.9112
Training Epoch: 68 [12288/50176]	Loss: 0.9865
Training Epoch: 68 [13312/50176]	Loss: 1.0024
Training Epoch: 68 [14336/50176]	Loss: 0.9287
Training Epoch: 68 [15360/50176]	Loss: 0.9112
Training Epoch: 68 [16384/50176]	Loss: 1.0367
Training Epoch: 68 [17408/50176]	Loss: 0.9498
Training Epoch: 68 [18432/50176]	Loss: 0.9255
Training Epoch: 68 [19456/50176]	Loss: 0.8853
Training Epoch: 68 [20480/50176]	Loss: 0.9516
Training Epoch: 68 [21504/50176]	Loss: 0.9557
Training Epoch: 68 [22528/50176]	Loss: 0.9471
Training Epoch: 68 [23552/50176]	Loss: 0.8478
Training Epoch: 68 [24576/50176]	Loss: 0.9772
Training Epoch: 68 [25600/50176]	Loss: 0.9151
Training Epoch: 68 [26624/50176]	Loss: 0.9491
Training Epoch: 68 [27648/50176]	Loss: 0.9272
Training Epoch: 68 [28672/50176]	Loss: 0.9974
Training Epoch: 68 [29696/50176]	Loss: 1.0693
Training Epoch: 68 [30720/50176]	Loss: 1.0131
Training Epoch: 68 [31744/50176]	Loss: 0.9581
Training Epoch: 68 [32768/50176]	Loss: 0.9901
Training Epoch: 68 [33792/50176]	Loss: 0.9451
Training Epoch: 68 [34816/50176]	Loss: 0.9873
Training Epoch: 68 [35840/50176]	Loss: 1.0187
Training Epoch: 68 [36864/50176]	Loss: 0.9375
Training Epoch: 68 [37888/50176]	Loss: 0.9583
Training Epoch: 68 [38912/50176]	Loss: 0.9801
Training Epoch: 68 [39936/50176]	Loss: 1.0330
Training Epoch: 68 [40960/50176]	Loss: 1.0123
Training Epoch: 68 [41984/50176]	Loss: 1.0120
Training Epoch: 68 [43008/50176]	Loss: 1.0735
Training Epoch: 68 [44032/50176]	Loss: 1.0115
Training Epoch: 68 [45056/50176]	Loss: 1.0136
Training Epoch: 68 [46080/50176]	Loss: 0.9810
Training Epoch: 68 [47104/50176]	Loss: 0.9354
Training Epoch: 68 [48128/50176]	Loss: 1.0041
Training Epoch: 68 [49152/50176]	Loss: 1.0281
Training Epoch: 68 [50176/50176]	Loss: 0.9714
2022-12-06 19:06:57.274 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:06:57,293 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.75 energy=475.26
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Up to epoch 69: time=3367.66, energy=464967.08, cost=527154.19
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:06:57,293 [ZeusDataLoader(train)] Expected next epoch: time=3414.77, energy=471654.96, cost=534619.69
2022-12-06 14:06:57,294 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0175, Accuracy: 0.0446
2022-12-06 14:06:57,534 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:06:57,535 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:06:57.549 [ZeusMonitor] Monitor started.
2022-12-06 19:06:57.549 [ZeusMonitor] Running indefinitely. 2022-12-06 19:06:57.549 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:06:57.549 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 14:07:41,780 [ZeusDataLoader(train)] train epoch 70 done: time=44.48 energy=6237.52
2022-12-06 14:07:41,783 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.8959
Training Epoch: 69 [2048/50176]	Loss: 0.9224
Training Epoch: 69 [3072/50176]	Loss: 0.9015
Training Epoch: 69 [4096/50176]	Loss: 0.9489
Training Epoch: 69 [5120/50176]	Loss: 0.9359
Training Epoch: 69 [6144/50176]	Loss: 0.9326
Training Epoch: 69 [7168/50176]	Loss: 0.8679
Training Epoch: 69 [8192/50176]	Loss: 0.9100
Training Epoch: 69 [9216/50176]	Loss: 0.9293
Training Epoch: 69 [10240/50176]	Loss: 0.8673
Training Epoch: 69 [11264/50176]	Loss: 0.8760
Training Epoch: 69 [12288/50176]	Loss: 0.8755
Training Epoch: 69 [13312/50176]	Loss: 0.8462
Training Epoch: 69 [14336/50176]	Loss: 0.8583
Training Epoch: 69 [15360/50176]	Loss: 0.9318
Training Epoch: 69 [16384/50176]	Loss: 0.8667
Training Epoch: 69 [17408/50176]	Loss: 0.9524
Training Epoch: 69 [18432/50176]	Loss: 0.8225
Training Epoch: 69 [19456/50176]	Loss: 0.9428
Training Epoch: 69 [20480/50176]	Loss: 0.8840
Training Epoch: 69 [21504/50176]	Loss: 0.8733
Training Epoch: 69 [22528/50176]	Loss: 0.9187
Training Epoch: 69 [23552/50176]	Loss: 0.8811
Training Epoch: 69 [24576/50176]	Loss: 0.8140
Training Epoch: 69 [25600/50176]	Loss: 0.9550
Training Epoch: 69 [26624/50176]	Loss: 0.8681
Training Epoch: 69 [27648/50176]	Loss: 0.9458
Training Epoch: 69 [28672/50176]	Loss: 0.8613
Training Epoch: 69 [29696/50176]	Loss: 0.9819
Training Epoch: 69 [30720/50176]	Loss: 0.9543
Training Epoch: 69 [31744/50176]	Loss: 1.0714
Training Epoch: 69 [32768/50176]	Loss: 0.9767
Training Epoch: 69 [33792/50176]	Loss: 1.0782
Training Epoch: 69 [34816/50176]	Loss: 0.9357
Training Epoch: 69 [35840/50176]	Loss: 0.9663
Training Epoch: 69 [36864/50176]	Loss: 1.0093
Training Epoch: 69 [37888/50176]	Loss: 0.9484
Training Epoch: 69 [38912/50176]	Loss: 0.9850
Training Epoch: 69 [39936/50176]	Loss: 1.0630
Training Epoch: 69 [40960/50176]	Loss: 0.9538
Training Epoch: 69 [41984/50176]	Loss: 0.9901
Training Epoch: 69 [43008/50176]	Loss: 0.9804
Training Epoch: 69 [44032/50176]	Loss: 0.9876
Training Epoch: 69 [45056/50176]	Loss: 1.0683
Training Epoch: 69 [46080/50176]	Loss: 1.1024
Training Epoch: 69 [47104/50176]	Loss: 1.0133
Training Epoch: 69 [48128/50176]	Loss: 1.0555
Training Epoch: 69 [49152/50176]	Loss: 0.9551
Training Epoch: 69 [50176/50176]	Loss: 1.0701
2022-12-06 19:07:45.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:07:45,583 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.79 energy=485.62
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Up to epoch 70: time=3415.93, energy=471690.22, cost=534739.35
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:07:45,584 [ZeusDataLoader(train)] Expected next epoch: time=3463.04, energy=478378.09, cost=542204.85
2022-12-06 14:07:45,585 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0546, Accuracy: 0.0135
2022-12-06 14:07:45,778 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:07:45,779 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:07:45.782 [ZeusMonitor] Monitor started.
2022-12-06 19:07:45.783 [ZeusMonitor] Running indefinitely. 2022-12-06 19:07:45.783 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:07:45.783 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 14:08:30,088 [ZeusDataLoader(train)] train epoch 71 done: time=44.50 energy=6254.25
2022-12-06 14:08:30,092 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.9198
Training Epoch: 70 [2048/50176]	Loss: 0.9216
Training Epoch: 70 [3072/50176]	Loss: 0.8660
Training Epoch: 70 [4096/50176]	Loss: 0.8421
Training Epoch: 70 [5120/50176]	Loss: 1.0015
Training Epoch: 70 [6144/50176]	Loss: 0.8967
Training Epoch: 70 [7168/50176]	Loss: 0.9414
Training Epoch: 70 [8192/50176]	Loss: 0.8732
Training Epoch: 70 [9216/50176]	Loss: 0.8931
Training Epoch: 70 [10240/50176]	Loss: 0.9586
Training Epoch: 70 [11264/50176]	Loss: 0.8443
Training Epoch: 70 [12288/50176]	Loss: 0.8638
Training Epoch: 70 [13312/50176]	Loss: 0.9572
Training Epoch: 70 [14336/50176]	Loss: 0.8954
Training Epoch: 70 [15360/50176]	Loss: 0.8570
Training Epoch: 70 [16384/50176]	Loss: 0.9425
Training Epoch: 70 [17408/50176]	Loss: 0.8954
Training Epoch: 70 [18432/50176]	Loss: 0.9127
Training Epoch: 70 [19456/50176]	Loss: 0.9452
Training Epoch: 70 [20480/50176]	Loss: 0.8435
Training Epoch: 70 [21504/50176]	Loss: 0.9355
Training Epoch: 70 [22528/50176]	Loss: 1.0213
Training Epoch: 70 [23552/50176]	Loss: 0.9408
Training Epoch: 70 [24576/50176]	Loss: 0.8873
Training Epoch: 70 [25600/50176]	Loss: 0.8886
Training Epoch: 70 [26624/50176]	Loss: 0.9075
Training Epoch: 70 [27648/50176]	Loss: 0.9407
Training Epoch: 70 [28672/50176]	Loss: 0.9603
Training Epoch: 70 [29696/50176]	Loss: 0.8803
Training Epoch: 70 [30720/50176]	Loss: 0.9621
Training Epoch: 70 [31744/50176]	Loss: 0.9352
Training Epoch: 70 [32768/50176]	Loss: 0.9611
Training Epoch: 70 [33792/50176]	Loss: 0.9492
Training Epoch: 70 [34816/50176]	Loss: 0.8881
Training Epoch: 70 [35840/50176]	Loss: 0.9077
Training Epoch: 70 [36864/50176]	Loss: 0.9589
Training Epoch: 70 [37888/50176]	Loss: 0.9284
Training Epoch: 70 [38912/50176]	Loss: 1.0150
Training Epoch: 70 [39936/50176]	Loss: 1.1335
Training Epoch: 70 [40960/50176]	Loss: 0.9776
Training Epoch: 70 [41984/50176]	Loss: 1.0019
Training Epoch: 70 [43008/50176]	Loss: 0.9947
Training Epoch: 70 [44032/50176]	Loss: 0.9733
Training Epoch: 70 [45056/50176]	Loss: 0.9930
Training Epoch: 70 [46080/50176]	Loss: 0.9987
Training Epoch: 70 [47104/50176]	Loss: 0.9734
Training Epoch: 70 [48128/50176]	Loss: 0.9583
Training Epoch: 70 [49152/50176]	Loss: 0.9414
Training Epoch: 70 [50176/50176]	Loss: 0.9365
2022-12-06 19:08:33.879 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:08:33,895 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.79 energy=480.46
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Up to epoch 71: time=3464.22, energy=478424.92, cost=542332.08
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:08:33,895 [ZeusDataLoader(train)] Expected next epoch: time=3511.33, energy=485112.80, cost=549797.58
2022-12-06 14:08:33,896 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0195, Accuracy: 0.0582
2022-12-06 14:08:34,133 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:08:34,133 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:08:34.135 [ZeusMonitor] Monitor started.
2022-12-06 19:08:34.135 [ZeusMonitor] Running indefinitely. 2022-12-06 19:08:34.135 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:08:34.135 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 14:09:18,643 [ZeusDataLoader(train)] train epoch 72 done: time=44.74 energy=6265.62
2022-12-06 14:09:18,646 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.8752
Training Epoch: 71 [2048/50176]	Loss: 0.9661
Training Epoch: 71 [3072/50176]	Loss: 0.9033
Training Epoch: 71 [4096/50176]	Loss: 0.9200
Training Epoch: 71 [5120/50176]	Loss: 0.8866
Training Epoch: 71 [6144/50176]	Loss: 0.8742
Training Epoch: 71 [7168/50176]	Loss: 0.9479
Training Epoch: 71 [8192/50176]	Loss: 0.8926
Training Epoch: 71 [9216/50176]	Loss: 0.8475
Training Epoch: 71 [10240/50176]	Loss: 0.8844
Training Epoch: 71 [11264/50176]	Loss: 0.8259
Training Epoch: 71 [12288/50176]	Loss: 0.8445
Training Epoch: 71 [13312/50176]	Loss: 0.9258
Training Epoch: 71 [14336/50176]	Loss: 0.8851
Training Epoch: 71 [15360/50176]	Loss: 0.8821
Training Epoch: 71 [16384/50176]	Loss: 0.9544
Training Epoch: 71 [17408/50176]	Loss: 0.9767
Training Epoch: 71 [18432/50176]	Loss: 0.8649
Training Epoch: 71 [19456/50176]	Loss: 0.8818
Training Epoch: 71 [20480/50176]	Loss: 0.9308
Training Epoch: 71 [21504/50176]	Loss: 0.9489
Training Epoch: 71 [22528/50176]	Loss: 0.9038
Training Epoch: 71 [23552/50176]	Loss: 0.8886
Training Epoch: 71 [24576/50176]	Loss: 0.9181
Training Epoch: 71 [25600/50176]	Loss: 0.9031
Training Epoch: 71 [26624/50176]	Loss: 0.9711
Training Epoch: 71 [27648/50176]	Loss: 0.8847
Training Epoch: 71 [28672/50176]	Loss: 0.9159
Training Epoch: 71 [29696/50176]	Loss: 0.9200
Training Epoch: 71 [30720/50176]	Loss: 0.9151
Training Epoch: 71 [31744/50176]	Loss: 0.9350
Training Epoch: 71 [32768/50176]	Loss: 1.0235
Training Epoch: 71 [33792/50176]	Loss: 0.9585
Training Epoch: 71 [34816/50176]	Loss: 1.0059
Training Epoch: 71 [35840/50176]	Loss: 0.9401
Training Epoch: 71 [36864/50176]	Loss: 0.9615
Training Epoch: 71 [37888/50176]	Loss: 0.9112
Training Epoch: 71 [38912/50176]	Loss: 0.9707
Training Epoch: 71 [39936/50176]	Loss: 0.8978
Training Epoch: 71 [40960/50176]	Loss: 0.8800
Training Epoch: 71 [41984/50176]	Loss: 0.9219
Training Epoch: 71 [43008/50176]	Loss: 1.0000
Training Epoch: 71 [44032/50176]	Loss: 0.9346
Training Epoch: 71 [45056/50176]	Loss: 0.9146
Training Epoch: 71 [46080/50176]	Loss: 0.9335
Training Epoch: 71 [47104/50176]	Loss: 0.9821
Training Epoch: 71 [48128/50176]	Loss: 1.0095
Training Epoch: 71 [49152/50176]	Loss: 1.0101
Training Epoch: 71 [50176/50176]	Loss: 0.9851
2022-12-06 19:09:22.523 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:09:22,569 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.92 energy=495.00
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Up to epoch 72: time=3512.88, energy=485185.54, cost=549969.61
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:09:22,570 [ZeusDataLoader(train)] Expected next epoch: time=3559.98, energy=491873.42, cost=557435.11
2022-12-06 14:09:22,571 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0103, Accuracy: 0.0953
2022-12-06 14:09:22,816 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:09:22,817 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:09:22.819 [ZeusMonitor] Monitor started.
2022-12-06 19:09:22.819 [ZeusMonitor] Running indefinitely. 2022-12-06 19:09:22.819 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:09:22.819 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 14:10:06,761 [ZeusDataLoader(train)] train epoch 73 done: time=44.18 energy=6220.32
2022-12-06 14:10:06,765 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.8737
Training Epoch: 72 [2048/50176]	Loss: 0.8957
Training Epoch: 72 [3072/50176]	Loss: 0.8888
Training Epoch: 72 [4096/50176]	Loss: 0.8598
Training Epoch: 72 [5120/50176]	Loss: 0.9178
Training Epoch: 72 [6144/50176]	Loss: 0.8140
Training Epoch: 72 [7168/50176]	Loss: 0.8849
Training Epoch: 72 [8192/50176]	Loss: 0.8155
Training Epoch: 72 [9216/50176]	Loss: 0.9055
Training Epoch: 72 [10240/50176]	Loss: 0.8755
Training Epoch: 72 [11264/50176]	Loss: 0.9117
Training Epoch: 72 [12288/50176]	Loss: 0.9086
Training Epoch: 72 [13312/50176]	Loss: 0.8702
Training Epoch: 72 [14336/50176]	Loss: 0.8211
Training Epoch: 72 [15360/50176]	Loss: 0.8262
Training Epoch: 72 [16384/50176]	Loss: 0.9314
Training Epoch: 72 [17408/50176]	Loss: 0.9927
Training Epoch: 72 [18432/50176]	Loss: 0.9004
Training Epoch: 72 [19456/50176]	Loss: 0.8718
Training Epoch: 72 [20480/50176]	Loss: 0.9065
Training Epoch: 72 [21504/50176]	Loss: 0.9290
Training Epoch: 72 [22528/50176]	Loss: 0.8905
Training Epoch: 72 [23552/50176]	Loss: 0.9051
Training Epoch: 72 [24576/50176]	Loss: 0.9219
Training Epoch: 72 [25600/50176]	Loss: 0.9209
Training Epoch: 72 [26624/50176]	Loss: 0.9226
Training Epoch: 72 [27648/50176]	Loss: 0.8908
Training Epoch: 72 [28672/50176]	Loss: 0.9643
Training Epoch: 72 [29696/50176]	Loss: 0.9048
Training Epoch: 72 [30720/50176]	Loss: 0.9245
Training Epoch: 72 [31744/50176]	Loss: 0.8760
Training Epoch: 72 [32768/50176]	Loss: 0.9126
Training Epoch: 72 [33792/50176]	Loss: 0.8947
Training Epoch: 72 [34816/50176]	Loss: 0.9724
Training Epoch: 72 [35840/50176]	Loss: 0.9153
Training Epoch: 72 [36864/50176]	Loss: 0.9369
Training Epoch: 72 [37888/50176]	Loss: 0.9956
Training Epoch: 72 [38912/50176]	Loss: 0.9991
Training Epoch: 72 [39936/50176]	Loss: 0.9015
Training Epoch: 72 [40960/50176]	Loss: 0.9524
Training Epoch: 72 [41984/50176]	Loss: 0.9867
Training Epoch: 72 [43008/50176]	Loss: 1.0217
Training Epoch: 72 [44032/50176]	Loss: 0.9852
Training Epoch: 72 [45056/50176]	Loss: 0.9931
Training Epoch: 72 [46080/50176]	Loss: 1.0234
Training Epoch: 72 [47104/50176]	Loss: 0.9472
Training Epoch: 72 [48128/50176]	Loss: 0.9493
Training Epoch: 72 [49152/50176]	Loss: 0.9198
Training Epoch: 72 [50176/50176]	Loss: 1.0358
2022-12-06 19:10:10.610 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:10:10,666 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.89 energy=493.97
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Up to epoch 73: time=3560.95, energy=491899.83, cost=557533.36
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:10:10,666 [ZeusDataLoader(train)] Expected next epoch: time=3608.06, energy=498587.71, cost=564998.86
2022-12-06 14:10:10,667 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0235, Accuracy: 0.0511
2022-12-06 14:10:10,913 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:10:10,913 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:10:10.915 [ZeusMonitor] Monitor started.
2022-12-06 19:10:10.915 [ZeusMonitor] Running indefinitely. 2022-12-06 19:10:10.915 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:10:10.915 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 14:10:54,711 [ZeusDataLoader(train)] train epoch 74 done: time=44.04 energy=6209.94
2022-12-06 14:10:54,715 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.8593
Training Epoch: 73 [2048/50176]	Loss: 0.8588
Training Epoch: 73 [3072/50176]	Loss: 0.8718
Training Epoch: 73 [4096/50176]	Loss: 0.9034
Training Epoch: 73 [5120/50176]	Loss: 0.7987
Training Epoch: 73 [6144/50176]	Loss: 0.8936
Training Epoch: 73 [7168/50176]	Loss: 0.8281
Training Epoch: 73 [8192/50176]	Loss: 0.8882
Training Epoch: 73 [9216/50176]	Loss: 0.8248
Training Epoch: 73 [10240/50176]	Loss: 0.9528
Training Epoch: 73 [11264/50176]	Loss: 0.8322
Training Epoch: 73 [12288/50176]	Loss: 0.8406
Training Epoch: 73 [13312/50176]	Loss: 0.8067
Training Epoch: 73 [14336/50176]	Loss: 0.8587
Training Epoch: 73 [15360/50176]	Loss: 0.9056
Training Epoch: 73 [16384/50176]	Loss: 0.8967
Training Epoch: 73 [17408/50176]	Loss: 0.7896
Training Epoch: 73 [18432/50176]	Loss: 0.8387
Training Epoch: 73 [19456/50176]	Loss: 0.8587
Training Epoch: 73 [20480/50176]	Loss: 0.8948
Training Epoch: 73 [21504/50176]	Loss: 0.8528
Training Epoch: 73 [22528/50176]	Loss: 0.9427
Training Epoch: 73 [23552/50176]	Loss: 0.8596
Training Epoch: 73 [24576/50176]	Loss: 0.8257
Training Epoch: 73 [25600/50176]	Loss: 0.8534
Training Epoch: 73 [26624/50176]	Loss: 0.9135
Training Epoch: 73 [27648/50176]	Loss: 0.8475
Training Epoch: 73 [28672/50176]	Loss: 0.9394
Training Epoch: 73 [29696/50176]	Loss: 0.9660
Training Epoch: 73 [30720/50176]	Loss: 0.9006
Training Epoch: 73 [31744/50176]	Loss: 0.9180
Training Epoch: 73 [32768/50176]	Loss: 0.9437
Training Epoch: 73 [33792/50176]	Loss: 0.9484
Training Epoch: 73 [34816/50176]	Loss: 0.9203
Training Epoch: 73 [35840/50176]	Loss: 0.9493
Training Epoch: 73 [36864/50176]	Loss: 0.8669
Training Epoch: 73 [37888/50176]	Loss: 0.8929
Training Epoch: 73 [38912/50176]	Loss: 0.9031
Training Epoch: 73 [39936/50176]	Loss: 0.9451
Training Epoch: 73 [40960/50176]	Loss: 0.8913
Training Epoch: 73 [41984/50176]	Loss: 1.0053
Training Epoch: 73 [43008/50176]	Loss: 0.9633
Training Epoch: 73 [44032/50176]	Loss: 0.8952
Training Epoch: 73 [45056/50176]	Loss: 0.8644
Training Epoch: 73 [46080/50176]	Loss: 0.9262
Training Epoch: 73 [47104/50176]	Loss: 0.9936
Training Epoch: 73 [48128/50176]	Loss: 0.9358
Training Epoch: 73 [49152/50176]	Loss: 0.8928
Training Epoch: 73 [50176/50176]	Loss: 0.9572
2022-12-06 19:10:58.407 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:10:58,418 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.69 energy=471.99
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Up to epoch 74: time=3608.68, energy=498581.75, cost=565050.77
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:10:58,418 [ZeusDataLoader(train)] Expected next epoch: time=3655.79, energy=505269.63, cost=572516.27
2022-12-06 14:10:58,419 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0216, Accuracy: 0.0175
2022-12-06 14:10:58,618 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:10:58,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:10:58.622 [ZeusMonitor] Monitor started.
2022-12-06 19:10:58.622 [ZeusMonitor] Running indefinitely. 2022-12-06 19:10:58.622 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:10:58.623 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 14:11:42,777 [ZeusDataLoader(train)] train epoch 75 done: time=44.35 energy=6246.57
2022-12-06 14:11:42,780 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.8202
Training Epoch: 74 [2048/50176]	Loss: 0.8116
Training Epoch: 74 [3072/50176]	Loss: 0.7397
Training Epoch: 74 [4096/50176]	Loss: 0.8548
Training Epoch: 74 [5120/50176]	Loss: 0.7951
Training Epoch: 74 [6144/50176]	Loss: 0.8159
Training Epoch: 74 [7168/50176]	Loss: 0.8850
Training Epoch: 74 [8192/50176]	Loss: 0.8359
Training Epoch: 74 [9216/50176]	Loss: 0.8710
Training Epoch: 74 [10240/50176]	Loss: 0.8996
Training Epoch: 74 [11264/50176]	Loss: 0.8709
Training Epoch: 74 [12288/50176]	Loss: 0.8135
Training Epoch: 74 [13312/50176]	Loss: 0.8817
Training Epoch: 74 [14336/50176]	Loss: 0.8955
Training Epoch: 74 [15360/50176]	Loss: 0.7942
Training Epoch: 74 [16384/50176]	Loss: 0.8742
Training Epoch: 74 [17408/50176]	Loss: 0.8876
Training Epoch: 74 [18432/50176]	Loss: 0.9061
Training Epoch: 74 [19456/50176]	Loss: 0.8692
Training Epoch: 74 [20480/50176]	Loss: 0.9088
Training Epoch: 74 [21504/50176]	Loss: 0.8276
Training Epoch: 74 [22528/50176]	Loss: 0.8416
Training Epoch: 74 [23552/50176]	Loss: 0.9322
Training Epoch: 74 [24576/50176]	Loss: 0.8762
Training Epoch: 74 [25600/50176]	Loss: 0.8589
Training Epoch: 74 [26624/50176]	Loss: 0.9161
Training Epoch: 74 [27648/50176]	Loss: 0.9491
Training Epoch: 74 [28672/50176]	Loss: 0.8539
Training Epoch: 74 [29696/50176]	Loss: 0.8997
Training Epoch: 74 [30720/50176]	Loss: 0.7772
Training Epoch: 74 [31744/50176]	Loss: 0.9446
Training Epoch: 74 [32768/50176]	Loss: 0.9704
Training Epoch: 74 [33792/50176]	Loss: 0.8862
Training Epoch: 74 [34816/50176]	Loss: 0.9639
Training Epoch: 74 [35840/50176]	Loss: 0.9211
Training Epoch: 74 [36864/50176]	Loss: 0.8796
Training Epoch: 74 [37888/50176]	Loss: 0.8961
Training Epoch: 74 [38912/50176]	Loss: 0.9915
Training Epoch: 74 [39936/50176]	Loss: 0.8830
Training Epoch: 74 [40960/50176]	Loss: 0.9026
Training Epoch: 74 [41984/50176]	Loss: 0.8922
Training Epoch: 74 [43008/50176]	Loss: 0.9393
Training Epoch: 74 [44032/50176]	Loss: 0.9311
Training Epoch: 74 [45056/50176]	Loss: 0.9543
Training Epoch: 74 [46080/50176]	Loss: 0.9417
Training Epoch: 74 [47104/50176]	Loss: 0.9581
Training Epoch: 74 [48128/50176]	Loss: 0.9325
Training Epoch: 74 [49152/50176]	Loss: 1.0464
Training Epoch: 74 [50176/50176]	Loss: 0.9447
2022-12-06 19:11:46.538 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:11:46,586 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.80 energy=485.61
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Up to epoch 75: time=3656.83, energy=505313.94, cost=572629.82
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:11:46,587 [ZeusDataLoader(train)] Expected next epoch: time=3703.94, energy=512001.82, cost=580095.31
2022-12-06 14:11:46,588 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 0.0131, Accuracy: 0.0782
2022-12-06 14:11:46,844 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:11:46,845 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:11:46.847 [ZeusMonitor] Monitor started.
2022-12-06 19:11:46.847 [ZeusMonitor] Running indefinitely. 2022-12-06 19:11:46.847 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:11:46.847 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e76+gpu0.power.log
2022-12-06 14:12:31,205 [ZeusDataLoader(train)] train epoch 76 done: time=44.61 energy=6257.69
2022-12-06 14:12:31,209 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 0.8114
Training Epoch: 75 [2048/50176]	Loss: 0.9027
Training Epoch: 75 [3072/50176]	Loss: 0.7759
Training Epoch: 75 [4096/50176]	Loss: 0.8172
Training Epoch: 75 [5120/50176]	Loss: 0.8230
Training Epoch: 75 [6144/50176]	Loss: 0.9142
Training Epoch: 75 [7168/50176]	Loss: 0.8358
Training Epoch: 75 [8192/50176]	Loss: 0.8202
Training Epoch: 75 [9216/50176]	Loss: 0.7986
Training Epoch: 75 [10240/50176]	Loss: 0.7783
Training Epoch: 75 [11264/50176]	Loss: 0.8638
Training Epoch: 75 [12288/50176]	Loss: 0.8087
Training Epoch: 75 [13312/50176]	Loss: 0.8636
Training Epoch: 75 [14336/50176]	Loss: 0.8845
Training Epoch: 75 [15360/50176]	Loss: 0.7646
Training Epoch: 75 [16384/50176]	Loss: 0.8906
Training Epoch: 75 [17408/50176]	Loss: 0.8280
Training Epoch: 75 [18432/50176]	Loss: 0.8278
Training Epoch: 75 [19456/50176]	Loss: 0.8269
Training Epoch: 75 [20480/50176]	Loss: 0.8407
Training Epoch: 75 [21504/50176]	Loss: 0.8576
Training Epoch: 75 [22528/50176]	Loss: 0.8782
Training Epoch: 75 [23552/50176]	Loss: 0.9103
Training Epoch: 75 [24576/50176]	Loss: 0.7728
Training Epoch: 75 [25600/50176]	Loss: 0.8646
Training Epoch: 75 [26624/50176]	Loss: 0.8772
Training Epoch: 75 [27648/50176]	Loss: 0.8197
Training Epoch: 75 [28672/50176]	Loss: 0.9106
Training Epoch: 75 [29696/50176]	Loss: 1.0075
Training Epoch: 75 [30720/50176]	Loss: 0.8833
Training Epoch: 75 [31744/50176]	Loss: 0.9702
Training Epoch: 75 [32768/50176]	Loss: 0.8861
Training Epoch: 75 [33792/50176]	Loss: 0.8475
Training Epoch: 75 [34816/50176]	Loss: 0.9169
Training Epoch: 75 [35840/50176]	Loss: 0.9198
Training Epoch: 75 [36864/50176]	Loss: 0.9575
Training Epoch: 75 [37888/50176]	Loss: 0.9110
Training Epoch: 75 [38912/50176]	Loss: 1.0080
Training Epoch: 75 [39936/50176]	Loss: 0.9256
Training Epoch: 75 [40960/50176]	Loss: 0.8299
Training Epoch: 75 [41984/50176]	Loss: 0.8563
Training Epoch: 75 [43008/50176]	Loss: 0.9287
Training Epoch: 75 [44032/50176]	Loss: 0.9088
Training Epoch: 75 [45056/50176]	Loss: 0.9435
Training Epoch: 75 [46080/50176]	Loss: 0.8780
Training Epoch: 75 [47104/50176]	Loss: 0.9329
Training Epoch: 75 [48128/50176]	Loss: 0.9070
Training Epoch: 75 [49152/50176]	Loss: 0.8780
Training Epoch: 75 [50176/50176]	Loss: 0.8658
2022-12-06 19:12:35.050 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:12:35,078 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.86 energy=482.88
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Up to epoch 76: time=3705.30, energy=512054.51, cost=580241.27
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:12:35,079 [ZeusDataLoader(train)] Expected next epoch: time=3752.41, energy=518742.39, cost=587706.77
2022-12-06 14:12:35,080 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 0.0107, Accuracy: 0.1086
2022-12-06 14:12:35,269 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:12:35,270 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:12:35.271 [ZeusMonitor] Monitor started.
2022-12-06 19:12:35.272 [ZeusMonitor] Running indefinitely. 2022-12-06 19:12:35.272 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:12:35.272 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e77+gpu0.power.log
2022-12-06 14:13:19,416 [ZeusDataLoader(train)] train epoch 77 done: time=44.33 energy=6237.22
2022-12-06 14:13:19,419 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 0.8227
Training Epoch: 76 [2048/50176]	Loss: 0.8805
Training Epoch: 76 [3072/50176]	Loss: 0.7535
Training Epoch: 76 [4096/50176]	Loss: 0.8079
Training Epoch: 76 [5120/50176]	Loss: 0.8531
Training Epoch: 76 [6144/50176]	Loss: 0.8146
Training Epoch: 76 [7168/50176]	Loss: 0.8198
Training Epoch: 76 [8192/50176]	Loss: 0.7590
Training Epoch: 76 [9216/50176]	Loss: 0.7211
Training Epoch: 76 [10240/50176]	Loss: 0.8033
Training Epoch: 76 [11264/50176]	Loss: 0.8674
Training Epoch: 76 [12288/50176]	Loss: 0.8606
Training Epoch: 76 [13312/50176]	Loss: 0.7751
Training Epoch: 76 [14336/50176]	Loss: 0.8645
Training Epoch: 76 [15360/50176]	Loss: 0.7914
Training Epoch: 76 [16384/50176]	Loss: 0.7745
Training Epoch: 76 [17408/50176]	Loss: 0.8924
Training Epoch: 76 [18432/50176]	Loss: 0.8244
Training Epoch: 76 [19456/50176]	Loss: 0.8409
Training Epoch: 76 [20480/50176]	Loss: 0.8744
Training Epoch: 76 [21504/50176]	Loss: 0.8885
Training Epoch: 76 [22528/50176]	Loss: 0.8365
Training Epoch: 76 [23552/50176]	Loss: 0.8468
Training Epoch: 76 [24576/50176]	Loss: 0.8569
Training Epoch: 76 [25600/50176]	Loss: 0.8212
Training Epoch: 76 [26624/50176]	Loss: 0.9358
Training Epoch: 76 [27648/50176]	Loss: 0.9416
Training Epoch: 76 [28672/50176]	Loss: 0.8594
Training Epoch: 76 [29696/50176]	Loss: 0.9324
Training Epoch: 76 [30720/50176]	Loss: 0.9407
Training Epoch: 76 [31744/50176]	Loss: 0.8635
Training Epoch: 76 [32768/50176]	Loss: 0.8730
Training Epoch: 76 [33792/50176]	Loss: 0.9690
Training Epoch: 76 [34816/50176]	Loss: 0.8888
Training Epoch: 76 [35840/50176]	Loss: 0.9193
Training Epoch: 76 [36864/50176]	Loss: 0.8181
Training Epoch: 76 [37888/50176]	Loss: 0.9001
Training Epoch: 76 [38912/50176]	Loss: 0.8774
Training Epoch: 76 [39936/50176]	Loss: 0.8135
Training Epoch: 76 [40960/50176]	Loss: 0.9446
Training Epoch: 76 [41984/50176]	Loss: 0.8731
Training Epoch: 76 [43008/50176]	Loss: 0.9732
Training Epoch: 76 [44032/50176]	Loss: 0.9105
Training Epoch: 76 [45056/50176]	Loss: 0.8150
Training Epoch: 76 [46080/50176]	Loss: 0.9400
Training Epoch: 76 [47104/50176]	Loss: 0.8544
Training Epoch: 76 [48128/50176]	Loss: 0.8835
Training Epoch: 76 [49152/50176]	Loss: 0.8758
Training Epoch: 76 [50176/50176]	Loss: 0.9386
2022-12-06 19:13:23.156 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:13:23,184 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.76 energy=470.83
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Up to epoch 77: time=3753.39, energy=518762.56, cost=587802.71
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:13:23,184 [ZeusDataLoader(train)] Expected next epoch: time=3800.49, energy=525450.43, cost=595268.21
2022-12-06 14:13:23,185 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0062, Accuracy: 0.1666
2022-12-06 14:13:23,435 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:13:23,436 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:13:23.446 [ZeusMonitor] Monitor started.
2022-12-06 19:13:23.446 [ZeusMonitor] Running indefinitely. 2022-12-06 19:13:23.446 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:13:23.446 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e78+gpu0.power.log
2022-12-06 14:14:07,657 [ZeusDataLoader(train)] train epoch 78 done: time=44.46 energy=6237.17
2022-12-06 14:14:07,660 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 0.7987
Training Epoch: 77 [2048/50176]	Loss: 0.8225
Training Epoch: 77 [3072/50176]	Loss: 0.8029
Training Epoch: 77 [4096/50176]	Loss: 0.7820
Training Epoch: 77 [5120/50176]	Loss: 0.8057
Training Epoch: 77 [6144/50176]	Loss: 0.7652
Training Epoch: 77 [7168/50176]	Loss: 0.7889
Training Epoch: 77 [8192/50176]	Loss: 0.7991
Training Epoch: 77 [9216/50176]	Loss: 0.8475
Training Epoch: 77 [10240/50176]	Loss: 0.8315
Training Epoch: 77 [11264/50176]	Loss: 0.7273
Training Epoch: 77 [12288/50176]	Loss: 0.7744
Training Epoch: 77 [13312/50176]	Loss: 0.8265
Training Epoch: 77 [14336/50176]	Loss: 0.8419
Training Epoch: 77 [15360/50176]	Loss: 0.9028
Training Epoch: 77 [16384/50176]	Loss: 0.8273
Training Epoch: 77 [17408/50176]	Loss: 0.8728
Training Epoch: 77 [18432/50176]	Loss: 0.8375
Training Epoch: 77 [19456/50176]	Loss: 0.8122
Training Epoch: 77 [20480/50176]	Loss: 0.8210
Training Epoch: 77 [21504/50176]	Loss: 0.7881
Training Epoch: 77 [22528/50176]	Loss: 0.8915
Training Epoch: 77 [23552/50176]	Loss: 0.8440
Training Epoch: 77 [24576/50176]	Loss: 0.8691
Training Epoch: 77 [25600/50176]	Loss: 0.8209
Training Epoch: 77 [26624/50176]	Loss: 0.8107
Training Epoch: 77 [27648/50176]	Loss: 0.8664
Training Epoch: 77 [28672/50176]	Loss: 0.9098
Training Epoch: 77 [29696/50176]	Loss: 0.8905
Training Epoch: 77 [30720/50176]	Loss: 0.8289
Training Epoch: 77 [31744/50176]	Loss: 0.7998
Training Epoch: 77 [32768/50176]	Loss: 0.8858
Training Epoch: 77 [33792/50176]	Loss: 0.8306
Training Epoch: 77 [34816/50176]	Loss: 0.9461
Training Epoch: 77 [35840/50176]	Loss: 1.0024
Training Epoch: 77 [36864/50176]	Loss: 0.8935
Training Epoch: 77 [37888/50176]	Loss: 0.9788
Training Epoch: 77 [38912/50176]	Loss: 0.8976
Training Epoch: 77 [39936/50176]	Loss: 0.9343
Training Epoch: 77 [40960/50176]	Loss: 0.8705
Training Epoch: 77 [41984/50176]	Loss: 0.8955
Training Epoch: 77 [43008/50176]	Loss: 0.9084
Training Epoch: 77 [44032/50176]	Loss: 0.8329
Training Epoch: 77 [45056/50176]	Loss: 0.9245
Training Epoch: 77 [46080/50176]	Loss: 0.9041
Training Epoch: 77 [47104/50176]	Loss: 0.8506
Training Epoch: 77 [48128/50176]	Loss: 0.9568
Training Epoch: 77 [49152/50176]	Loss: 0.8838
Training Epoch: 77 [50176/50176]	Loss: 0.8713
2022-12-06 19:14:11.388 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:14:11,400 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.73 energy=474.58
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Up to epoch 78: time=3801.58, energy=525474.30, cost=595375.71
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:14:11,400 [ZeusDataLoader(train)] Expected next epoch: time=3848.69, energy=532162.18, cost=602841.21
2022-12-06 14:14:11,401 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0396, Accuracy: 0.0395
2022-12-06 14:14:11,636 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:14:11,637 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:14:11.639 [ZeusMonitor] Monitor started.
2022-12-06 19:14:11.639 [ZeusMonitor] Running indefinitely. 2022-12-06 19:14:11.639 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:14:11.639 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e79+gpu0.power.log
2022-12-06 14:14:56,101 [ZeusDataLoader(train)] train epoch 79 done: time=44.69 energy=6271.48
2022-12-06 14:14:56,104 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 0.7922
Training Epoch: 78 [2048/50176]	Loss: 0.7499
Training Epoch: 78 [3072/50176]	Loss: 0.7599
Training Epoch: 78 [4096/50176]	Loss: 0.8063
Training Epoch: 78 [5120/50176]	Loss: 0.7944
Training Epoch: 78 [6144/50176]	Loss: 0.8249
Training Epoch: 78 [7168/50176]	Loss: 0.8028
Training Epoch: 78 [8192/50176]	Loss: 0.8715
Training Epoch: 78 [9216/50176]	Loss: 0.7972
Training Epoch: 78 [10240/50176]	Loss: 0.8306
Training Epoch: 78 [11264/50176]	Loss: 0.8107
Training Epoch: 78 [12288/50176]	Loss: 0.8098
Training Epoch: 78 [13312/50176]	Loss: 0.8853
Training Epoch: 78 [14336/50176]	Loss: 0.8125
Training Epoch: 78 [15360/50176]	Loss: 0.7826
Training Epoch: 78 [16384/50176]	Loss: 0.8427
Training Epoch: 78 [17408/50176]	Loss: 0.8321
Training Epoch: 78 [18432/50176]	Loss: 0.8182
Training Epoch: 78 [19456/50176]	Loss: 0.8031
Training Epoch: 78 [20480/50176]	Loss: 0.7813
Training Epoch: 78 [21504/50176]	Loss: 0.8185
Training Epoch: 78 [22528/50176]	Loss: 0.8101
Training Epoch: 78 [23552/50176]	Loss: 0.8843
Training Epoch: 78 [24576/50176]	Loss: 0.8966
Training Epoch: 78 [25600/50176]	Loss: 0.9037
Training Epoch: 78 [26624/50176]	Loss: 0.8824
Training Epoch: 78 [27648/50176]	Loss: 0.7943
Training Epoch: 78 [28672/50176]	Loss: 0.8169
Training Epoch: 78 [29696/50176]	Loss: 0.8806
Training Epoch: 78 [30720/50176]	Loss: 0.8500
Training Epoch: 78 [31744/50176]	Loss: 0.8057
Training Epoch: 78 [32768/50176]	Loss: 0.9540
Training Epoch: 78 [33792/50176]	Loss: 0.8740
Training Epoch: 78 [34816/50176]	Loss: 0.9034
Training Epoch: 78 [35840/50176]	Loss: 0.7519
Training Epoch: 78 [36864/50176]	Loss: 0.9233
Training Epoch: 78 [37888/50176]	Loss: 0.8243
Training Epoch: 78 [38912/50176]	Loss: 0.8672
Training Epoch: 78 [39936/50176]	Loss: 0.8842
Training Epoch: 78 [40960/50176]	Loss: 0.8223
Training Epoch: 78 [41984/50176]	Loss: 0.7813
Training Epoch: 78 [43008/50176]	Loss: 0.9154
Training Epoch: 78 [44032/50176]	Loss: 0.8658
Training Epoch: 78 [45056/50176]	Loss: 0.9148
Training Epoch: 78 [46080/50176]	Loss: 0.8817
Training Epoch: 78 [47104/50176]	Loss: 0.8700
Training Epoch: 78 [48128/50176]	Loss: 0.8214
Training Epoch: 78 [49152/50176]	Loss: 0.8533
Training Epoch: 78 [50176/50176]	Loss: 0.9024
2022-12-06 19:14:59.779 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:14:59,791 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.68 energy=462.25
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Up to epoch 79: time=3849.95, energy=532208.03, cost=602974.96
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:14:59,792 [ZeusDataLoader(train)] Expected next epoch: time=3897.06, energy=538895.91, cost=610440.45
2022-12-06 14:14:59,793 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 0.0115, Accuracy: 0.0953
2022-12-06 14:15:00,054 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:15:00,054 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:15:00.058 [ZeusMonitor] Monitor started.
2022-12-06 19:15:00.058 [ZeusMonitor] Running indefinitely. 2022-12-06 19:15:00.058 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:15:00.058 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e80+gpu0.power.log
2022-12-06 14:15:44,268 [ZeusDataLoader(train)] train epoch 80 done: time=44.47 energy=6240.85
2022-12-06 14:15:44,272 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 0.8145
Training Epoch: 79 [2048/50176]	Loss: 0.7824
Training Epoch: 79 [3072/50176]	Loss: 0.7477
Training Epoch: 79 [4096/50176]	Loss: 0.7842
Training Epoch: 79 [5120/50176]	Loss: 0.7163
Training Epoch: 79 [6144/50176]	Loss: 0.8183
Training Epoch: 79 [7168/50176]	Loss: 0.8397
Training Epoch: 79 [8192/50176]	Loss: 0.7999
Training Epoch: 79 [9216/50176]	Loss: 0.7268
Training Epoch: 79 [10240/50176]	Loss: 0.7907
Training Epoch: 79 [11264/50176]	Loss: 0.8149
Training Epoch: 79 [12288/50176]	Loss: 0.8465
Training Epoch: 79 [13312/50176]	Loss: 0.7865
Training Epoch: 79 [14336/50176]	Loss: 0.7596
Training Epoch: 79 [15360/50176]	Loss: 0.7353
Training Epoch: 79 [16384/50176]	Loss: 0.8724
Training Epoch: 79 [17408/50176]	Loss: 0.7210
Training Epoch: 79 [18432/50176]	Loss: 0.7321
Training Epoch: 79 [19456/50176]	Loss: 0.9101
Training Epoch: 79 [20480/50176]	Loss: 0.7687
Training Epoch: 79 [21504/50176]	Loss: 0.8829
Training Epoch: 79 [22528/50176]	Loss: 0.8026
Training Epoch: 79 [23552/50176]	Loss: 0.8150
Training Epoch: 79 [24576/50176]	Loss: 0.7751
Training Epoch: 79 [25600/50176]	Loss: 0.7249
Training Epoch: 79 [26624/50176]	Loss: 0.9186
Training Epoch: 79 [27648/50176]	Loss: 0.8572
Training Epoch: 79 [28672/50176]	Loss: 0.8371
Training Epoch: 79 [29696/50176]	Loss: 0.8296
Training Epoch: 79 [30720/50176]	Loss: 0.8133
Training Epoch: 79 [31744/50176]	Loss: 0.8027
Training Epoch: 79 [32768/50176]	Loss: 0.8184
Training Epoch: 79 [33792/50176]	Loss: 0.8032
Training Epoch: 79 [34816/50176]	Loss: 0.7837
Training Epoch: 79 [35840/50176]	Loss: 0.8839
Training Epoch: 79 [36864/50176]	Loss: 0.8318
Training Epoch: 79 [37888/50176]	Loss: 0.8396
Training Epoch: 79 [38912/50176]	Loss: 0.8916
Training Epoch: 79 [39936/50176]	Loss: 0.8426
Training Epoch: 79 [40960/50176]	Loss: 0.8547
Training Epoch: 79 [41984/50176]	Loss: 0.7853
Training Epoch: 79 [43008/50176]	Loss: 0.8888
Training Epoch: 79 [44032/50176]	Loss: 0.8971
Training Epoch: 79 [45056/50176]	Loss: 0.7887
Training Epoch: 79 [46080/50176]	Loss: 0.9013
Training Epoch: 79 [47104/50176]	Loss: 0.8269
Training Epoch: 79 [48128/50176]	Loss: 0.8559
Training Epoch: 79 [49152/50176]	Loss: 0.8294
Training Epoch: 79 [50176/50176]	Loss: 0.9025
2022-12-06 19:15:48.207 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:15:48,237 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.96 energy=491.99
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Up to epoch 80: time=3898.38, energy=538940.86, cost=610578.57
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:15:48,238 [ZeusDataLoader(train)] Expected next epoch: time=3945.48, energy=545628.74, cost=618044.07
2022-12-06 14:15:48,239 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 0.0203, Accuracy: 0.0410
2022-12-06 14:15:48,469 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:15:48,470 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:15:48.472 [ZeusMonitor] Monitor started.
2022-12-06 19:15:48.472 [ZeusMonitor] Running indefinitely. 2022-12-06 19:15:48.472 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:15:48.472 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e81+gpu0.power.log
2022-12-06 14:16:32,838 [ZeusDataLoader(train)] train epoch 81 done: time=44.59 energy=6251.47
2022-12-06 14:16:32,842 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 0.7796
Training Epoch: 80 [2048/50176]	Loss: 0.7504
Training Epoch: 80 [3072/50176]	Loss: 0.7273
Training Epoch: 80 [4096/50176]	Loss: 0.7464
Training Epoch: 80 [5120/50176]	Loss: 0.7927
Training Epoch: 80 [6144/50176]	Loss: 0.7247
Training Epoch: 80 [7168/50176]	Loss: 0.8245
Training Epoch: 80 [8192/50176]	Loss: 0.8061
Training Epoch: 80 [9216/50176]	Loss: 0.8037
Training Epoch: 80 [10240/50176]	Loss: 0.7827
Training Epoch: 80 [11264/50176]	Loss: 0.7625
Training Epoch: 80 [12288/50176]	Loss: 0.8128
Training Epoch: 80 [13312/50176]	Loss: 0.7497
Training Epoch: 80 [14336/50176]	Loss: 0.8427
Training Epoch: 80 [15360/50176]	Loss: 0.7338
Training Epoch: 80 [16384/50176]	Loss: 0.8418
Training Epoch: 80 [17408/50176]	Loss: 0.8946
Training Epoch: 80 [18432/50176]	Loss: 0.8161
Training Epoch: 80 [19456/50176]	Loss: 0.7750
Training Epoch: 80 [20480/50176]	Loss: 0.7252
Training Epoch: 80 [21504/50176]	Loss: 0.8285
Training Epoch: 80 [22528/50176]	Loss: 0.8639
Training Epoch: 80 [23552/50176]	Loss: 0.8905
Training Epoch: 80 [24576/50176]	Loss: 0.8173
Training Epoch: 80 [25600/50176]	Loss: 0.7789
Training Epoch: 80 [26624/50176]	Loss: 0.8062
Training Epoch: 80 [27648/50176]	Loss: 0.8796
Training Epoch: 80 [28672/50176]	Loss: 0.8031
Training Epoch: 80 [29696/50176]	Loss: 0.8573
Training Epoch: 80 [30720/50176]	Loss: 0.7765
Training Epoch: 80 [31744/50176]	Loss: 0.8329
Training Epoch: 80 [32768/50176]	Loss: 0.7804
Training Epoch: 80 [33792/50176]	Loss: 0.8658
Training Epoch: 80 [34816/50176]	Loss: 0.8088
Training Epoch: 80 [35840/50176]	Loss: 0.8388
Training Epoch: 80 [36864/50176]	Loss: 0.8128
Training Epoch: 80 [37888/50176]	Loss: 0.7307
Training Epoch: 80 [38912/50176]	Loss: 0.8188
Training Epoch: 80 [39936/50176]	Loss: 0.8820
Training Epoch: 80 [40960/50176]	Loss: 0.8853
Training Epoch: 80 [41984/50176]	Loss: 0.9230
Training Epoch: 80 [43008/50176]	Loss: 0.8567
Training Epoch: 80 [44032/50176]	Loss: 0.9108
Training Epoch: 80 [45056/50176]	Loss: 0.8005
Training Epoch: 80 [46080/50176]	Loss: 0.8629
Training Epoch: 80 [47104/50176]	Loss: 0.8359
Training Epoch: 80 [48128/50176]	Loss: 0.8067
Training Epoch: 80 [49152/50176]	Loss: 0.8325
Training Epoch: 80 [50176/50176]	Loss: 0.9182
2022-12-06 19:16:36.598 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:16:36,626 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.78 energy=478.13
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Up to epoch 81: time=3946.75, energy=545670.46, cost=618175.58
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:16:36,626 [ZeusDataLoader(train)] Expected next epoch: time=3993.85, energy=552358.34, cost=625641.08
2022-12-06 14:16:36,627 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0109, Accuracy: 0.1751
2022-12-06 14:16:36,868 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:16:36,869 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:16:36.871 [ZeusMonitor] Monitor started.
2022-12-06 19:16:36.871 [ZeusMonitor] Running indefinitely. 2022-12-06 19:16:36.871 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:16:36.871 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e82+gpu0.power.log
2022-12-06 14:17:20,837 [ZeusDataLoader(train)] train epoch 82 done: time=44.20 energy=6226.79
2022-12-06 14:17:20,841 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 0.7340
Training Epoch: 81 [2048/50176]	Loss: 0.7783
Training Epoch: 81 [3072/50176]	Loss: 0.7755
Training Epoch: 81 [4096/50176]	Loss: 0.7993
Training Epoch: 81 [5120/50176]	Loss: 0.8403
Training Epoch: 81 [6144/50176]	Loss: 0.7538
Training Epoch: 81 [7168/50176]	Loss: 0.8065
Training Epoch: 81 [8192/50176]	Loss: 0.7852
Training Epoch: 81 [9216/50176]	Loss: 0.8123
Training Epoch: 81 [10240/50176]	Loss: 0.7525
Training Epoch: 81 [11264/50176]	Loss: 0.8242
Training Epoch: 81 [12288/50176]	Loss: 0.7610
Training Epoch: 81 [13312/50176]	Loss: 0.7411
Training Epoch: 81 [14336/50176]	Loss: 0.7934
Training Epoch: 81 [15360/50176]	Loss: 0.7640
Training Epoch: 81 [16384/50176]	Loss: 0.7409
Training Epoch: 81 [17408/50176]	Loss: 0.8234
Training Epoch: 81 [18432/50176]	Loss: 0.7348
Training Epoch: 81 [19456/50176]	Loss: 0.7211
Training Epoch: 81 [20480/50176]	Loss: 0.8479
Training Epoch: 81 [21504/50176]	Loss: 0.7610
Training Epoch: 81 [22528/50176]	Loss: 0.7589
Training Epoch: 81 [23552/50176]	Loss: 0.7813
Training Epoch: 81 [24576/50176]	Loss: 0.7680
Training Epoch: 81 [25600/50176]	Loss: 0.8653
Training Epoch: 81 [26624/50176]	Loss: 0.8301
Training Epoch: 81 [27648/50176]	Loss: 0.7921
Training Epoch: 81 [28672/50176]	Loss: 0.8291
Training Epoch: 81 [29696/50176]	Loss: 0.7829
Training Epoch: 81 [30720/50176]	Loss: 0.7381
Training Epoch: 81 [31744/50176]	Loss: 0.8416
Training Epoch: 81 [32768/50176]	Loss: 0.8797
Training Epoch: 81 [33792/50176]	Loss: 0.7988
Training Epoch: 81 [34816/50176]	Loss: 0.7695
Training Epoch: 81 [35840/50176]	Loss: 0.8632
Training Epoch: 81 [36864/50176]	Loss: 0.8125
Training Epoch: 81 [37888/50176]	Loss: 0.9085
Training Epoch: 81 [38912/50176]	Loss: 0.8351
Training Epoch: 81 [39936/50176]	Loss: 0.7793
Training Epoch: 81 [40960/50176]	Loss: 0.8632
Training Epoch: 81 [41984/50176]	Loss: 0.7904
Training Epoch: 81 [43008/50176]	Loss: 0.8110
Training Epoch: 81 [44032/50176]	Loss: 0.8717
Training Epoch: 81 [45056/50176]	Loss: 0.8884
Training Epoch: 81 [46080/50176]	Loss: 0.8776
Training Epoch: 81 [47104/50176]	Loss: 0.8239
Training Epoch: 81 [48128/50176]	Loss: 0.8548
Training Epoch: 81 [49152/50176]	Loss: 0.7792
Training Epoch: 81 [50176/50176]	Loss: 0.8422
2022-12-06 19:17:24.598 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:17:24,653 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.80 energy=489.03
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Up to epoch 82: time=3994.75, energy=552386.28, cost=625733.98
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:17:24,653 [ZeusDataLoader(train)] Expected next epoch: time=4041.86, energy=559074.15, cost=633199.48
2022-12-06 14:17:24,654 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 0.0106, Accuracy: 0.1024
2022-12-06 14:17:24,903 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:17:24,904 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:17:24.906 [ZeusMonitor] Monitor started.
2022-12-06 19:17:24.906 [ZeusMonitor] Running indefinitely. 2022-12-06 19:17:24.906 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:17:24.906 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e83+gpu0.power.log
2022-12-06 14:18:09,288 [ZeusDataLoader(train)] train epoch 83 done: time=44.63 energy=6256.47
2022-12-06 14:18:09,292 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 0.6953
Training Epoch: 82 [2048/50176]	Loss: 0.7319
Training Epoch: 82 [3072/50176]	Loss: 0.7032
Training Epoch: 82 [4096/50176]	Loss: 0.7144
Training Epoch: 82 [5120/50176]	Loss: 0.7666
Training Epoch: 82 [6144/50176]	Loss: 0.7285
Training Epoch: 82 [7168/50176]	Loss: 0.7811
Training Epoch: 82 [8192/50176]	Loss: 0.7722
Training Epoch: 82 [9216/50176]	Loss: 0.7439
Training Epoch: 82 [10240/50176]	Loss: 0.6942
Training Epoch: 82 [11264/50176]	Loss: 0.7289
Training Epoch: 82 [12288/50176]	Loss: 0.6914
Training Epoch: 82 [13312/50176]	Loss: 0.7662
Training Epoch: 82 [14336/50176]	Loss: 0.7178
Training Epoch: 82 [15360/50176]	Loss: 0.7665
Training Epoch: 82 [16384/50176]	Loss: 0.7666
Training Epoch: 82 [17408/50176]	Loss: 0.6741
Training Epoch: 82 [18432/50176]	Loss: 0.7832
Training Epoch: 82 [19456/50176]	Loss: 0.7462
Training Epoch: 82 [20480/50176]	Loss: 0.8331
Training Epoch: 82 [21504/50176]	Loss: 0.7920
Training Epoch: 82 [22528/50176]	Loss: 0.7608
Training Epoch: 82 [23552/50176]	Loss: 0.8217
Training Epoch: 82 [24576/50176]	Loss: 0.7713
Training Epoch: 82 [25600/50176]	Loss: 0.7729
Training Epoch: 82 [26624/50176]	Loss: 0.8998
Training Epoch: 82 [27648/50176]	Loss: 0.7805
Training Epoch: 82 [28672/50176]	Loss: 0.6931
Training Epoch: 82 [29696/50176]	Loss: 0.7480
Training Epoch: 82 [30720/50176]	Loss: 0.7752
Training Epoch: 82 [31744/50176]	Loss: 0.7993
Training Epoch: 82 [32768/50176]	Loss: 0.7024
Training Epoch: 82 [33792/50176]	Loss: 0.7655
Training Epoch: 82 [34816/50176]	Loss: 0.7760
Training Epoch: 82 [35840/50176]	Loss: 0.8417
Training Epoch: 82 [36864/50176]	Loss: 0.8239
Training Epoch: 82 [37888/50176]	Loss: 0.7561
Training Epoch: 82 [38912/50176]	Loss: 0.8230
Training Epoch: 82 [39936/50176]	Loss: 0.8149
Training Epoch: 82 [40960/50176]	Loss: 0.9296
Training Epoch: 82 [41984/50176]	Loss: 0.7772
Training Epoch: 82 [43008/50176]	Loss: 0.8768
Training Epoch: 82 [44032/50176]	Loss: 0.7777
Training Epoch: 82 [45056/50176]	Loss: 0.8437
Training Epoch: 82 [46080/50176]	Loss: 0.8558
Training Epoch: 82 [47104/50176]	Loss: 0.8681
Training Epoch: 82 [48128/50176]	Loss: 0.8398
Training Epoch: 82 [49152/50176]	Loss: 0.7910
Training Epoch: 82 [50176/50176]	Loss: 0.8530
2022-12-06 19:18:13.014 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:18:13,023 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.72 energy=471.47
2022-12-06 14:18:13,023 [ZeusDataLoader(train)] Up to epoch 83: time=4043.10, energy=559114.21, cost=633328.49
2022-12-06 14:18:13,023 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:18:13,024 [ZeusDataLoader(train)] Expected next epoch: time=4090.21, energy=565802.09, cost=640793.99
2022-12-06 14:18:13,024 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 0.0091, Accuracy: 0.1307
2022-12-06 14:18:13,291 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:18:13,291 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:18:13.293 [ZeusMonitor] Monitor started.
2022-12-06 19:18:13.293 [ZeusMonitor] Running indefinitely. 2022-12-06 19:18:13.293 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:18:13.293 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e84+gpu0.power.log
2022-12-06 14:18:57,926 [ZeusDataLoader(train)] train epoch 84 done: time=44.89 energy=6267.55
2022-12-06 14:18:57,929 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 0.7259
Training Epoch: 83 [2048/50176]	Loss: 0.6962
Training Epoch: 83 [3072/50176]	Loss: 0.7457
Training Epoch: 83 [4096/50176]	Loss: 0.7200
Training Epoch: 83 [5120/50176]	Loss: 0.7698
Training Epoch: 83 [6144/50176]	Loss: 0.6555
Training Epoch: 83 [7168/50176]	Loss: 0.8001
Training Epoch: 83 [8192/50176]	Loss: 0.7480
Training Epoch: 83 [9216/50176]	Loss: 0.7905
Training Epoch: 83 [10240/50176]	Loss: 0.7339
Training Epoch: 83 [11264/50176]	Loss: 0.7841
Training Epoch: 83 [12288/50176]	Loss: 0.8358
Training Epoch: 83 [13312/50176]	Loss: 0.7446
Training Epoch: 83 [14336/50176]	Loss: 0.7804
Training Epoch: 83 [15360/50176]	Loss: 0.7325
Training Epoch: 83 [16384/50176]	Loss: 0.7677
Training Epoch: 83 [17408/50176]	Loss: 0.7421
Training Epoch: 83 [18432/50176]	Loss: 0.7078
Training Epoch: 83 [19456/50176]	Loss: 0.9144
Training Epoch: 83 [20480/50176]	Loss: 0.8672
Training Epoch: 83 [21504/50176]	Loss: 0.8081
Training Epoch: 83 [22528/50176]	Loss: 0.7171
Training Epoch: 83 [23552/50176]	Loss: 0.6587
Training Epoch: 83 [24576/50176]	Loss: 0.7431
Training Epoch: 83 [25600/50176]	Loss: 0.7699
Training Epoch: 83 [26624/50176]	Loss: 0.8045
Training Epoch: 83 [27648/50176]	Loss: 0.7863
Training Epoch: 83 [28672/50176]	Loss: 0.7370
Training Epoch: 83 [29696/50176]	Loss: 0.7634
Training Epoch: 83 [30720/50176]	Loss: 0.7986
Training Epoch: 83 [31744/50176]	Loss: 0.7844
Training Epoch: 83 [32768/50176]	Loss: 0.8665
Training Epoch: 83 [33792/50176]	Loss: 0.8098
Training Epoch: 83 [34816/50176]	Loss: 0.7583
Training Epoch: 83 [35840/50176]	Loss: 0.8043
Training Epoch: 83 [36864/50176]	Loss: 0.7706
Training Epoch: 83 [37888/50176]	Loss: 0.7212
Training Epoch: 83 [38912/50176]	Loss: 0.7570
Training Epoch: 83 [39936/50176]	Loss: 0.8824
Training Epoch: 83 [40960/50176]	Loss: 0.8000
Training Epoch: 83 [41984/50176]	Loss: 0.8403
Training Epoch: 83 [43008/50176]	Loss: 0.7550
Training Epoch: 83 [44032/50176]	Loss: 0.7728
Training Epoch: 83 [45056/50176]	Loss: 0.8909
Training Epoch: 83 [46080/50176]	Loss: 0.7618
Training Epoch: 83 [47104/50176]	Loss: 0.7919
Training Epoch: 83 [48128/50176]	Loss: 0.7664
Training Epoch: 83 [49152/50176]	Loss: 0.8065
Training Epoch: 83 [50176/50176]	Loss: 0.8255
2022-12-06 19:19:01.615 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:19:01,629 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.69 energy=472.23
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Up to epoch 84: time=4091.69, energy=565853.99, cost=640949.63
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:19:01,630 [ZeusDataLoader(train)] Expected next epoch: time=4138.79, energy=572541.86, cost=648415.12
2022-12-06 14:19:01,631 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 0.0106, Accuracy: 0.1046
2022-12-06 14:19:01,872 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:19:01,873 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:19:01.875 [ZeusMonitor] Monitor started.
2022-12-06 19:19:01.875 [ZeusMonitor] Running indefinitely. 2022-12-06 19:19:01.875 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:19:01.875 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e85+gpu0.power.log
2022-12-06 14:19:45,839 [ZeusDataLoader(train)] train epoch 85 done: time=44.20 energy=6237.37
2022-12-06 14:19:45,843 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 0.7269
Training Epoch: 84 [2048/50176]	Loss: 0.7529
Training Epoch: 84 [3072/50176]	Loss: 0.7336
Training Epoch: 84 [4096/50176]	Loss: 0.7187
Training Epoch: 84 [5120/50176]	Loss: 0.8208
Training Epoch: 84 [6144/50176]	Loss: 0.7250
Training Epoch: 84 [7168/50176]	Loss: 0.6824
Training Epoch: 84 [8192/50176]	Loss: 0.7927
Training Epoch: 84 [9216/50176]	Loss: 0.7421
Training Epoch: 84 [10240/50176]	Loss: 0.7303
Training Epoch: 84 [11264/50176]	Loss: 0.6998
Training Epoch: 84 [12288/50176]	Loss: 0.7556
Training Epoch: 84 [13312/50176]	Loss: 0.7796
Training Epoch: 84 [14336/50176]	Loss: 0.7287
Training Epoch: 84 [15360/50176]	Loss: 0.6846
Training Epoch: 84 [16384/50176]	Loss: 0.7844
Training Epoch: 84 [17408/50176]	Loss: 0.7417
Training Epoch: 84 [18432/50176]	Loss: 0.7712
Training Epoch: 84 [19456/50176]	Loss: 0.7555
Training Epoch: 84 [20480/50176]	Loss: 0.7764
Training Epoch: 84 [21504/50176]	Loss: 0.7553
Training Epoch: 84 [22528/50176]	Loss: 0.7584
Training Epoch: 84 [23552/50176]	Loss: 0.7786
Training Epoch: 84 [24576/50176]	Loss: 0.7591
Training Epoch: 84 [25600/50176]	Loss: 0.7515
Training Epoch: 84 [26624/50176]	Loss: 0.8407
Training Epoch: 84 [27648/50176]	Loss: 0.7997
Training Epoch: 84 [28672/50176]	Loss: 0.7578
Training Epoch: 84 [29696/50176]	Loss: 0.8762
Training Epoch: 84 [30720/50176]	Loss: 0.8385
Training Epoch: 84 [31744/50176]	Loss: 0.6895
Training Epoch: 84 [32768/50176]	Loss: 0.7199
Training Epoch: 84 [33792/50176]	Loss: 0.7853
Training Epoch: 84 [34816/50176]	Loss: 0.7577
Training Epoch: 84 [35840/50176]	Loss: 0.7899
Training Epoch: 84 [36864/50176]	Loss: 0.8331
Training Epoch: 84 [37888/50176]	Loss: 0.7577
Training Epoch: 84 [38912/50176]	Loss: 0.7980
Training Epoch: 84 [39936/50176]	Loss: 0.7498
Training Epoch: 84 [40960/50176]	Loss: 0.8055
Training Epoch: 84 [41984/50176]	Loss: 0.8107
Training Epoch: 84 [43008/50176]	Loss: 0.7894
Training Epoch: 84 [44032/50176]	Loss: 0.8856
Training Epoch: 84 [45056/50176]	Loss: 0.7999
Training Epoch: 84 [46080/50176]	Loss: 0.8177
Training Epoch: 84 [47104/50176]	Loss: 0.8240
Training Epoch: 84 [48128/50176]	Loss: 0.9050
Training Epoch: 84 [49152/50176]	Loss: 0.8585
Training Epoch: 84 [50176/50176]	Loss: 0.8175
2022-12-06 19:19:49.610 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:19:49,662 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.81 energy=491.32
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Up to epoch 85: time=4139.70, energy=572582.67, cost=648514.95
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:19:49,662 [ZeusDataLoader(train)] Expected next epoch: time=4186.80, energy=579270.55, cost=655980.45
2022-12-06 14:19:49,663 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 0.0185, Accuracy: 0.0945
2022-12-06 14:19:49,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:19:49,909 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:19:49.911 [ZeusMonitor] Monitor started.
2022-12-06 19:19:49.911 [ZeusMonitor] Running indefinitely. 2022-12-06 19:19:49.911 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:19:49.911 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e86+gpu0.power.log
2022-12-06 14:20:34,131 [ZeusDataLoader(train)] train epoch 86 done: time=44.46 energy=6241.40
2022-12-06 14:20:34,135 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 0.7269
Training Epoch: 85 [2048/50176]	Loss: 0.7339
Training Epoch: 85 [3072/50176]	Loss: 0.7547
Training Epoch: 85 [4096/50176]	Loss: 0.6464
Training Epoch: 85 [5120/50176]	Loss: 0.7393
Training Epoch: 85 [6144/50176]	Loss: 0.7224
Training Epoch: 85 [7168/50176]	Loss: 0.7509
Training Epoch: 85 [8192/50176]	Loss: 0.7160
Training Epoch: 85 [9216/50176]	Loss: 0.7325
Training Epoch: 85 [10240/50176]	Loss: 0.7282
Training Epoch: 85 [11264/50176]	Loss: 0.6844
Training Epoch: 85 [12288/50176]	Loss: 0.7268
Training Epoch: 85 [13312/50176]	Loss: 0.6799
Training Epoch: 85 [14336/50176]	Loss: 0.6968
Training Epoch: 85 [15360/50176]	Loss: 0.7398
Training Epoch: 85 [16384/50176]	Loss: 0.7030
Training Epoch: 85 [17408/50176]	Loss: 0.7419
Training Epoch: 85 [18432/50176]	Loss: 0.7383
Training Epoch: 85 [19456/50176]	Loss: 0.7605
Training Epoch: 85 [20480/50176]	Loss: 0.7555
Training Epoch: 85 [21504/50176]	Loss: 0.7955
Training Epoch: 85 [22528/50176]	Loss: 0.7435
Training Epoch: 85 [23552/50176]	Loss: 0.7404
Training Epoch: 85 [24576/50176]	Loss: 0.7998
Training Epoch: 85 [25600/50176]	Loss: 0.7277
Training Epoch: 85 [26624/50176]	Loss: 0.7537
Training Epoch: 85 [27648/50176]	Loss: 0.7171
Training Epoch: 85 [28672/50176]	Loss: 0.7359
Training Epoch: 85 [29696/50176]	Loss: 0.7985
Training Epoch: 85 [30720/50176]	Loss: 0.7351
Training Epoch: 85 [31744/50176]	Loss: 0.7495
Training Epoch: 85 [32768/50176]	Loss: 0.8377
Training Epoch: 85 [33792/50176]	Loss: 0.8277
Training Epoch: 85 [34816/50176]	Loss: 0.7726
Training Epoch: 85 [35840/50176]	Loss: 0.8320
Training Epoch: 85 [36864/50176]	Loss: 0.8072
Training Epoch: 85 [37888/50176]	Loss: 0.7657
Training Epoch: 85 [38912/50176]	Loss: 0.8194
Training Epoch: 85 [39936/50176]	Loss: 0.8490
Training Epoch: 85 [40960/50176]	Loss: 0.7566
Training Epoch: 85 [41984/50176]	Loss: 0.6735
Training Epoch: 85 [43008/50176]	Loss: 0.8236
Training Epoch: 85 [44032/50176]	Loss: 0.8443
Training Epoch: 85 [45056/50176]	Loss: 0.7971
Training Epoch: 85 [46080/50176]	Loss: 0.8678
Training Epoch: 85 [47104/50176]	Loss: 0.7630
Training Epoch: 85 [48128/50176]	Loss: 0.8007
Training Epoch: 85 [49152/50176]	Loss: 0.7927
Training Epoch: 85 [50176/50176]	Loss: 0.8563
2022-12-06 19:20:38.028 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:20:38,050 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.91 energy=494.85
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Up to epoch 86: time=4188.07, energy=579318.93, cost=656115.17
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:20:38,050 [ZeusDataLoader(train)] Expected next epoch: time=4235.17, energy=586006.80, cost=663580.67
2022-12-06 14:20:38,051 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 0.0062, Accuracy: 0.1580
2022-12-06 14:20:38,284 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:20:38,285 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:20:38.287 [ZeusMonitor] Monitor started.
2022-12-06 19:20:38.287 [ZeusMonitor] Running indefinitely. 2022-12-06 19:20:38.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:20:38.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e87+gpu0.power.log
2022-12-06 14:21:22,564 [ZeusDataLoader(train)] train epoch 87 done: time=44.50 energy=6245.11
2022-12-06 14:21:22,567 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 0.6650
Training Epoch: 86 [2048/50176]	Loss: 0.6881
Training Epoch: 86 [3072/50176]	Loss: 0.7664
Training Epoch: 86 [4096/50176]	Loss: 0.7293
Training Epoch: 86 [5120/50176]	Loss: 0.6985
Training Epoch: 86 [6144/50176]	Loss: 0.7192
Training Epoch: 86 [7168/50176]	Loss: 0.6936
Training Epoch: 86 [8192/50176]	Loss: 0.7766
Training Epoch: 86 [9216/50176]	Loss: 0.7261
Training Epoch: 86 [10240/50176]	Loss: 0.7210
Training Epoch: 86 [11264/50176]	Loss: 0.6881
Training Epoch: 86 [12288/50176]	Loss: 0.7059
Training Epoch: 86 [13312/50176]	Loss: 0.6793
Training Epoch: 86 [14336/50176]	Loss: 0.7129
Training Epoch: 86 [15360/50176]	Loss: 0.8220
Training Epoch: 86 [16384/50176]	Loss: 0.6542
Training Epoch: 86 [17408/50176]	Loss: 0.7141
Training Epoch: 86 [18432/50176]	Loss: 0.6792
Training Epoch: 86 [19456/50176]	Loss: 0.6902
Training Epoch: 86 [20480/50176]	Loss: 0.7728
Training Epoch: 86 [21504/50176]	Loss: 0.7689
Training Epoch: 86 [22528/50176]	Loss: 0.7859
Training Epoch: 86 [23552/50176]	Loss: 0.7439
Training Epoch: 86 [24576/50176]	Loss: 0.7796
Training Epoch: 86 [25600/50176]	Loss: 0.8403
Training Epoch: 86 [26624/50176]	Loss: 0.7266
Training Epoch: 86 [27648/50176]	Loss: 0.7879
Training Epoch: 86 [28672/50176]	Loss: 0.8131
Training Epoch: 86 [29696/50176]	Loss: 0.7516
Training Epoch: 86 [30720/50176]	Loss: 0.7786
Training Epoch: 86 [31744/50176]	Loss: 0.8063
Training Epoch: 86 [32768/50176]	Loss: 0.7810
Training Epoch: 86 [33792/50176]	Loss: 0.7429
Training Epoch: 86 [34816/50176]	Loss: 0.7302
Training Epoch: 86 [35840/50176]	Loss: 0.7548
Training Epoch: 86 [36864/50176]	Loss: 0.7494
Training Epoch: 86 [37888/50176]	Loss: 0.7975
Training Epoch: 86 [38912/50176]	Loss: 0.7510
Training Epoch: 86 [39936/50176]	Loss: 0.7950
Training Epoch: 86 [40960/50176]	Loss: 0.7851
Training Epoch: 86 [41984/50176]	Loss: 0.7431
Training Epoch: 86 [43008/50176]	Loss: 0.7213
Training Epoch: 86 [44032/50176]	Loss: 0.7780
Training Epoch: 86 [45056/50176]	Loss: 0.7840
Training Epoch: 86 [46080/50176]	Loss: 0.7798
Training Epoch: 86 [47104/50176]	Loss: 0.8040
Training Epoch: 86 [48128/50176]	Loss: 0.7539
Training Epoch: 86 [49152/50176]	Loss: 0.7537
Training Epoch: 86 [50176/50176]	Loss: 0.8215
2022-12-06 19:21:26.393 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:21:26,412 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.84 energy=478.82
2022-12-06 14:21:26,412 [ZeusDataLoader(train)] Up to epoch 87: time=4236.41, energy=586042.86, cost=663707.10
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Expected next epoch: time=4283.51, energy=592730.74, cost=671172.60
2022-12-06 14:21:26,413 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 0.0130, Accuracy: 0.1219
2022-12-06 14:21:26,649 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:21:26,649 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:21:26.659 [ZeusMonitor] Monitor started.
2022-12-06 19:21:26.659 [ZeusMonitor] Running indefinitely. 2022-12-06 19:21:26.660 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:21:26.660 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e88+gpu0.power.log
2022-12-06 14:22:10,813 [ZeusDataLoader(train)] train epoch 88 done: time=44.39 energy=6239.37
2022-12-06 14:22:10,817 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 0.6559
Training Epoch: 87 [2048/50176]	Loss: 0.7084
Training Epoch: 87 [3072/50176]	Loss: 0.6907
Training Epoch: 87 [4096/50176]	Loss: 0.6724
Training Epoch: 87 [5120/50176]	Loss: 0.7129
Training Epoch: 87 [6144/50176]	Loss: 0.7108
Training Epoch: 87 [7168/50176]	Loss: 0.6538
Training Epoch: 87 [8192/50176]	Loss: 0.7083
Training Epoch: 87 [9216/50176]	Loss: 0.7284
Training Epoch: 87 [10240/50176]	Loss: 0.6943
Training Epoch: 87 [11264/50176]	Loss: 0.8182
Training Epoch: 87 [12288/50176]	Loss: 0.7075
Training Epoch: 87 [13312/50176]	Loss: 0.6951
Training Epoch: 87 [14336/50176]	Loss: 0.7157
Training Epoch: 87 [15360/50176]	Loss: 0.7516
Training Epoch: 87 [16384/50176]	Loss: 0.7879
Training Epoch: 87 [17408/50176]	Loss: 0.7432
Training Epoch: 87 [18432/50176]	Loss: 0.7199
Training Epoch: 87 [19456/50176]	Loss: 0.7653
Training Epoch: 87 [20480/50176]	Loss: 0.7205
Training Epoch: 87 [21504/50176]	Loss: 0.7636
Training Epoch: 87 [22528/50176]	Loss: 0.7099
Training Epoch: 87 [23552/50176]	Loss: 0.7051
Training Epoch: 87 [24576/50176]	Loss: 0.8037
Training Epoch: 87 [25600/50176]	Loss: 0.8134
Training Epoch: 87 [26624/50176]	Loss: 0.7228
Training Epoch: 87 [27648/50176]	Loss: 0.6925
Training Epoch: 87 [28672/50176]	Loss: 0.7442
Training Epoch: 87 [29696/50176]	Loss: 0.7954
Training Epoch: 87 [30720/50176]	Loss: 0.7539
Training Epoch: 87 [31744/50176]	Loss: 0.6935
Training Epoch: 87 [32768/50176]	Loss: 0.7894
Training Epoch: 87 [33792/50176]	Loss: 0.7539
Training Epoch: 87 [34816/50176]	Loss: 0.7534
Training Epoch: 87 [35840/50176]	Loss: 0.8092
Training Epoch: 87 [36864/50176]	Loss: 0.7160
Training Epoch: 87 [37888/50176]	Loss: 0.8265
Training Epoch: 87 [38912/50176]	Loss: 0.7347
Training Epoch: 87 [39936/50176]	Loss: 0.7385
Training Epoch: 87 [40960/50176]	Loss: 0.7192
Training Epoch: 87 [41984/50176]	Loss: 0.6630
Training Epoch: 87 [43008/50176]	Loss: 0.8222
Training Epoch: 87 [44032/50176]	Loss: 0.7694
Training Epoch: 87 [45056/50176]	Loss: 0.7818
Training Epoch: 87 [46080/50176]	Loss: 0.8125
Training Epoch: 87 [47104/50176]	Loss: 0.7927
Training Epoch: 87 [48128/50176]	Loss: 0.7821
Training Epoch: 87 [49152/50176]	Loss: 0.7772
Training Epoch: 87 [50176/50176]	Loss: 0.7907
2022-12-06 19:22:14.581 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:22:14,624 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.80 energy=485.31
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Up to epoch 88: time=4284.60, energy=592767.54, cost=671286.16
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:22:14,625 [ZeusDataLoader(train)] Expected next epoch: time=4331.70, energy=599455.42, cost=678751.66
2022-12-06 14:22:14,626 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0093, Accuracy: 0.1143
2022-12-06 14:22:14,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:22:14,836 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:22:14.838 [ZeusMonitor] Monitor started.
2022-12-06 19:22:14.838 [ZeusMonitor] Running indefinitely. 2022-12-06 19:22:14.838 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:22:14.838 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e89+gpu0.power.log
2022-12-06 14:22:58,886 [ZeusDataLoader(train)] train epoch 89 done: time=44.25 energy=6236.96
2022-12-06 14:22:58,890 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 0.6965
Training Epoch: 88 [2048/50176]	Loss: 0.6740
Training Epoch: 88 [3072/50176]	Loss: 0.6036
Training Epoch: 88 [4096/50176]	Loss: 0.6634
Training Epoch: 88 [5120/50176]	Loss: 0.6540
Training Epoch: 88 [6144/50176]	Loss: 0.7002
Training Epoch: 88 [7168/50176]	Loss: 0.7137
Training Epoch: 88 [8192/50176]	Loss: 0.6493
Training Epoch: 88 [9216/50176]	Loss: 0.6570
Training Epoch: 88 [10240/50176]	Loss: 0.6700
Training Epoch: 88 [11264/50176]	Loss: 0.6792
Training Epoch: 88 [12288/50176]	Loss: 0.7021
Training Epoch: 88 [13312/50176]	Loss: 0.6286
Training Epoch: 88 [14336/50176]	Loss: 0.6739
Training Epoch: 88 [15360/50176]	Loss: 0.7657
Training Epoch: 88 [16384/50176]	Loss: 0.7331
Training Epoch: 88 [17408/50176]	Loss: 0.7125
Training Epoch: 88 [18432/50176]	Loss: 0.7325
Training Epoch: 88 [19456/50176]	Loss: 0.7351
Training Epoch: 88 [20480/50176]	Loss: 0.6787
Training Epoch: 88 [21504/50176]	Loss: 0.6569
Training Epoch: 88 [22528/50176]	Loss: 0.6456
Training Epoch: 88 [23552/50176]	Loss: 0.7018
Training Epoch: 88 [24576/50176]	Loss: 0.6848
Training Epoch: 88 [25600/50176]	Loss: 0.6563
Training Epoch: 88 [26624/50176]	Loss: 0.7373
Training Epoch: 88 [27648/50176]	Loss: 0.7395
Training Epoch: 88 [28672/50176]	Loss: 0.7202
Training Epoch: 88 [29696/50176]	Loss: 0.6585
Training Epoch: 88 [30720/50176]	Loss: 0.7325
Training Epoch: 88 [31744/50176]	Loss: 0.7258
Training Epoch: 88 [32768/50176]	Loss: 0.7769
Training Epoch: 88 [33792/50176]	Loss: 0.8100
Training Epoch: 88 [34816/50176]	Loss: 0.7647
Training Epoch: 88 [35840/50176]	Loss: 0.7984
Training Epoch: 88 [36864/50176]	Loss: 0.7486
Training Epoch: 88 [37888/50176]	Loss: 0.7200
Training Epoch: 88 [38912/50176]	Loss: 0.7896
Training Epoch: 88 [39936/50176]	Loss: 0.7598
Training Epoch: 88 [40960/50176]	Loss: 0.7556
Training Epoch: 88 [41984/50176]	Loss: 0.7777
Training Epoch: 88 [43008/50176]	Loss: 0.8336
Training Epoch: 88 [44032/50176]	Loss: 0.7915
Training Epoch: 88 [45056/50176]	Loss: 0.7870
Training Epoch: 88 [46080/50176]	Loss: 0.7633
Training Epoch: 88 [47104/50176]	Loss: 0.7459
Training Epoch: 88 [48128/50176]	Loss: 0.7239
Training Epoch: 88 [49152/50176]	Loss: 0.7911
Training Epoch: 88 [50176/50176]	Loss: 0.8256
2022-12-06 19:23:02.641 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:23:02,659 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.76 energy=470.20
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Up to epoch 89: time=4332.61, energy=599474.70, cost=678841.00
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:23:02,659 [ZeusDataLoader(train)] Expected next epoch: time=4379.72, energy=606162.58, cost=686306.50
2022-12-06 14:23:02,660 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 0.0170, Accuracy: 0.0243
2022-12-06 14:23:02,917 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:23:02,917 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:23:02.919 [ZeusMonitor] Monitor started.
2022-12-06 19:23:02.919 [ZeusMonitor] Running indefinitely. 2022-12-06 19:23:02.919 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:23:02.919 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e90+gpu0.power.log
2022-12-06 14:23:46,958 [ZeusDataLoader(train)] train epoch 90 done: time=44.29 energy=6223.77
2022-12-06 14:23:46,962 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 0.6058
Training Epoch: 89 [2048/50176]	Loss: 0.6553
Training Epoch: 89 [3072/50176]	Loss: 0.6678
Training Epoch: 89 [4096/50176]	Loss: 0.6831
Training Epoch: 89 [5120/50176]	Loss: 0.6368
Training Epoch: 89 [6144/50176]	Loss: 0.7060
Training Epoch: 89 [7168/50176]	Loss: 0.6655
Training Epoch: 89 [8192/50176]	Loss: 0.6472
Training Epoch: 89 [9216/50176]	Loss: 0.6889
Training Epoch: 89 [10240/50176]	Loss: 0.7470
Training Epoch: 89 [11264/50176]	Loss: 0.6983
Training Epoch: 89 [12288/50176]	Loss: 0.6820
Training Epoch: 89 [13312/50176]	Loss: 0.7173
Training Epoch: 89 [14336/50176]	Loss: 0.7387
Training Epoch: 89 [15360/50176]	Loss: 0.6934
Training Epoch: 89 [16384/50176]	Loss: 0.6869
Training Epoch: 89 [17408/50176]	Loss: 0.7647
Training Epoch: 89 [18432/50176]	Loss: 0.6526
Training Epoch: 89 [19456/50176]	Loss: 0.6557
Training Epoch: 89 [20480/50176]	Loss: 0.6515
Training Epoch: 89 [21504/50176]	Loss: 0.7544
Training Epoch: 89 [22528/50176]	Loss: 0.6284
Training Epoch: 89 [23552/50176]	Loss: 0.7807
Training Epoch: 89 [24576/50176]	Loss: 0.7237
Training Epoch: 89 [25600/50176]	Loss: 0.6612
Training Epoch: 89 [26624/50176]	Loss: 0.7028
Training Epoch: 89 [27648/50176]	Loss: 0.6516
Training Epoch: 89 [28672/50176]	Loss: 0.6870
Training Epoch: 89 [29696/50176]	Loss: 0.6863
Training Epoch: 89 [30720/50176]	Loss: 0.7477
Training Epoch: 89 [31744/50176]	Loss: 0.7604
Training Epoch: 89 [32768/50176]	Loss: 0.7783
Training Epoch: 89 [33792/50176]	Loss: 0.6714
Training Epoch: 89 [34816/50176]	Loss: 0.7891
Training Epoch: 89 [35840/50176]	Loss: 0.7665
Training Epoch: 89 [36864/50176]	Loss: 0.7621
Training Epoch: 89 [37888/50176]	Loss: 0.7601
Training Epoch: 89 [38912/50176]	Loss: 0.8097
Training Epoch: 89 [39936/50176]	Loss: 0.6931
Training Epoch: 89 [40960/50176]	Loss: 0.7594
Training Epoch: 89 [41984/50176]	Loss: 0.7617
Training Epoch: 89 [43008/50176]	Loss: 0.7986
Training Epoch: 89 [44032/50176]	Loss: 0.7082
Training Epoch: 89 [45056/50176]	Loss: 0.7347
Training Epoch: 89 [46080/50176]	Loss: 0.7396
Training Epoch: 89 [47104/50176]	Loss: 0.7126
Training Epoch: 89 [48128/50176]	Loss: 0.7327
Training Epoch: 89 [49152/50176]	Loss: 0.8621
Training Epoch: 89 [50176/50176]	Loss: 0.7619
2022-12-06 19:23:50.742 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:23:50,779 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.81 energy=484.37
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Up to epoch 90: time=4380.71, energy=606182.84, cost=686403.78
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:23:50,779 [ZeusDataLoader(train)] Expected next epoch: time=4427.82, energy=612870.72, cost=693869.28
2022-12-06 14:23:50,780 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0110, Accuracy: 0.1212
2022-12-06 14:23:51,013 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:23:51,014 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:23:51.036 [ZeusMonitor] Monitor started.
2022-12-06 19:23:51.036 [ZeusMonitor] Running indefinitely. 2022-12-06 19:23:51.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:23:51.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e91+gpu0.power.log
2022-12-06 14:24:35,436 [ZeusDataLoader(train)] train epoch 91 done: time=44.65 energy=6257.02
2022-12-06 14:24:35,440 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 0.6646
Training Epoch: 90 [2048/50176]	Loss: 0.6327
Training Epoch: 90 [3072/50176]	Loss: 0.6310
Training Epoch: 90 [4096/50176]	Loss: 0.6645
Training Epoch: 90 [5120/50176]	Loss: 0.6459
Training Epoch: 90 [6144/50176]	Loss: 0.6466
Training Epoch: 90 [7168/50176]	Loss: 0.6659
Training Epoch: 90 [8192/50176]	Loss: 0.7141
Training Epoch: 90 [9216/50176]	Loss: 0.6767
Training Epoch: 90 [10240/50176]	Loss: 0.6688
Training Epoch: 90 [11264/50176]	Loss: 0.6366
Training Epoch: 90 [12288/50176]	Loss: 0.6928
Training Epoch: 90 [13312/50176]	Loss: 0.6495
Training Epoch: 90 [14336/50176]	Loss: 0.7060
Training Epoch: 90 [15360/50176]	Loss: 0.6755
Training Epoch: 90 [16384/50176]	Loss: 0.6803
Training Epoch: 90 [17408/50176]	Loss: 0.7093
Training Epoch: 90 [18432/50176]	Loss: 0.6574
Training Epoch: 90 [19456/50176]	Loss: 0.7128
Training Epoch: 90 [20480/50176]	Loss: 0.6248
Training Epoch: 90 [21504/50176]	Loss: 0.7302
Training Epoch: 90 [22528/50176]	Loss: 0.6581
Training Epoch: 90 [23552/50176]	Loss: 0.6761
Training Epoch: 90 [24576/50176]	Loss: 0.6559
Training Epoch: 90 [25600/50176]	Loss: 0.7127
Training Epoch: 90 [26624/50176]	Loss: 0.7596
Training Epoch: 90 [27648/50176]	Loss: 0.6869
Training Epoch: 90 [28672/50176]	Loss: 0.7115
Training Epoch: 90 [29696/50176]	Loss: 0.6765
Training Epoch: 90 [30720/50176]	Loss: 0.6832
Training Epoch: 90 [31744/50176]	Loss: 0.7422
Training Epoch: 90 [32768/50176]	Loss: 0.6973
Training Epoch: 90 [33792/50176]	Loss: 0.7178
Training Epoch: 90 [34816/50176]	Loss: 0.7136
Training Epoch: 90 [35840/50176]	Loss: 0.8142
Training Epoch: 90 [36864/50176]	Loss: 0.6378
Training Epoch: 90 [37888/50176]	Loss: 0.7136
Training Epoch: 90 [38912/50176]	Loss: 0.8554
Training Epoch: 90 [39936/50176]	Loss: 0.7751
Training Epoch: 90 [40960/50176]	Loss: 0.7656
Training Epoch: 90 [41984/50176]	Loss: 0.6809
Training Epoch: 90 [43008/50176]	Loss: 0.7070
Training Epoch: 90 [44032/50176]	Loss: 0.7637
Training Epoch: 90 [45056/50176]	Loss: 0.7202
Training Epoch: 90 [46080/50176]	Loss: 0.7365
Training Epoch: 90 [47104/50176]	Loss: 0.7208
Training Epoch: 90 [48128/50176]	Loss: 0.7870
Training Epoch: 90 [49152/50176]	Loss: 0.7701
Training Epoch: 90 [50176/50176]	Loss: 0.7252
2022-12-06 19:24:39.307 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:24:39,346 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.90 energy=494.31
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Up to epoch 91: time=4429.26, energy=612934.17, cost=694027.24
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:24:39,346 [ZeusDataLoader(train)] Expected next epoch: time=4476.36, energy=619622.05, cost=701492.74
2022-12-06 14:24:39,347 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 0.0085, Accuracy: 0.2354
2022-12-06 14:24:39,596 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:24:39,597 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:24:39.599 [ZeusMonitor] Monitor started.
2022-12-06 19:24:39.599 [ZeusMonitor] Running indefinitely. 2022-12-06 19:24:39.599 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:24:39.599 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e92+gpu0.power.log
2022-12-06 14:25:23,883 [ZeusDataLoader(train)] train epoch 92 done: time=44.53 energy=6254.16
2022-12-06 14:25:23,887 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 0.6439
Training Epoch: 91 [2048/50176]	Loss: 0.6367
Training Epoch: 91 [3072/50176]	Loss: 0.7222
Training Epoch: 91 [4096/50176]	Loss: 0.6185
Training Epoch: 91 [5120/50176]	Loss: 0.6928
Training Epoch: 91 [6144/50176]	Loss: 0.6750
Training Epoch: 91 [7168/50176]	Loss: 0.6927
Training Epoch: 91 [8192/50176]	Loss: 0.7536
Training Epoch: 91 [9216/50176]	Loss: 0.7216
Training Epoch: 91 [10240/50176]	Loss: 0.6770
Training Epoch: 91 [11264/50176]	Loss: 0.7166
Training Epoch: 91 [12288/50176]	Loss: 0.6878
Training Epoch: 91 [13312/50176]	Loss: 0.6907
Training Epoch: 91 [14336/50176]	Loss: 0.6466
Training Epoch: 91 [15360/50176]	Loss: 0.6660
Training Epoch: 91 [16384/50176]	Loss: 0.7543
Training Epoch: 91 [17408/50176]	Loss: 0.6855
Training Epoch: 91 [18432/50176]	Loss: 0.6835
Training Epoch: 91 [19456/50176]	Loss: 0.6821
Training Epoch: 91 [20480/50176]	Loss: 0.7449
Training Epoch: 91 [21504/50176]	Loss: 0.6788
Training Epoch: 91 [22528/50176]	Loss: 0.6399
Training Epoch: 91 [23552/50176]	Loss: 0.7424
Training Epoch: 91 [24576/50176]	Loss: 0.6572
Training Epoch: 91 [25600/50176]	Loss: 0.6565
Training Epoch: 91 [26624/50176]	Loss: 0.7252
Training Epoch: 91 [27648/50176]	Loss: 0.5822
Training Epoch: 91 [28672/50176]	Loss: 0.6707
Training Epoch: 91 [29696/50176]	Loss: 0.7445
Training Epoch: 91 [30720/50176]	Loss: 0.7044
Training Epoch: 91 [31744/50176]	Loss: 0.7015
Training Epoch: 91 [32768/50176]	Loss: 0.6928
Training Epoch: 91 [33792/50176]	Loss: 0.6787
Training Epoch: 91 [34816/50176]	Loss: 0.6863
Training Epoch: 91 [35840/50176]	Loss: 0.6988
Training Epoch: 91 [36864/50176]	Loss: 0.7069
Training Epoch: 91 [37888/50176]	Loss: 0.8245
Training Epoch: 91 [38912/50176]	Loss: 0.6856
Training Epoch: 91 [39936/50176]	Loss: 0.7295
Training Epoch: 91 [40960/50176]	Loss: 0.7086
Training Epoch: 91 [41984/50176]	Loss: 0.7092
Training Epoch: 91 [43008/50176]	Loss: 0.7636
Training Epoch: 91 [44032/50176]	Loss: 0.6904
Training Epoch: 91 [45056/50176]	Loss: 0.7681
Training Epoch: 91 [46080/50176]	Loss: 0.7252
Training Epoch: 91 [47104/50176]	Loss: 0.7197
Training Epoch: 91 [48128/50176]	Loss: 0.7294
Training Epoch: 91 [49152/50176]	Loss: 0.6769
Training Epoch: 91 [50176/50176]	Loss: 0.7413
2022-12-06 19:25:27.674 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:25:27,690 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.80 energy=464.18
2022-12-06 14:25:27,690 [ZeusDataLoader(train)] Up to epoch 92: time=4477.58, energy=619652.51, cost=701614.70
2022-12-06 14:25:27,690 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:25:27,691 [ZeusDataLoader(train)] Expected next epoch: time=4524.69, energy=626340.39, cost=709080.20
2022-12-06 14:25:27,691 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 0.0287, Accuracy: 0.0604
2022-12-06 14:25:27,929 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:25:27,930 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:25:27.932 [ZeusMonitor] Monitor started.
2022-12-06 19:25:27.932 [ZeusMonitor] Running indefinitely. 2022-12-06 19:25:27.932 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:25:27.932 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e93+gpu0.power.log
2022-12-06 14:26:12,238 [ZeusDataLoader(train)] train epoch 93 done: time=44.54 energy=6239.11
2022-12-06 14:26:12,241 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 0.7169
Training Epoch: 92 [2048/50176]	Loss: 0.6417
Training Epoch: 92 [3072/50176]	Loss: 0.6469
Training Epoch: 92 [4096/50176]	Loss: 0.6171
Training Epoch: 92 [5120/50176]	Loss: 0.6876
Training Epoch: 92 [6144/50176]	Loss: 0.6485
Training Epoch: 92 [7168/50176]	Loss: 0.6683
Training Epoch: 92 [8192/50176]	Loss: 0.6293
Training Epoch: 92 [9216/50176]	Loss: 0.6456
Training Epoch: 92 [10240/50176]	Loss: 0.6021
Training Epoch: 92 [11264/50176]	Loss: 0.6060
Training Epoch: 92 [12288/50176]	Loss: 0.6770
Training Epoch: 92 [13312/50176]	Loss: 0.6710
Training Epoch: 92 [14336/50176]	Loss: 0.6773
Training Epoch: 92 [15360/50176]	Loss: 0.7008
Training Epoch: 92 [16384/50176]	Loss: 0.6097
Training Epoch: 92 [17408/50176]	Loss: 0.6359
Training Epoch: 92 [18432/50176]	Loss: 0.6715
Training Epoch: 92 [19456/50176]	Loss: 0.7501
Training Epoch: 92 [20480/50176]	Loss: 0.6873
Training Epoch: 92 [21504/50176]	Loss: 0.6750
Training Epoch: 92 [22528/50176]	Loss: 0.6930
Training Epoch: 92 [23552/50176]	Loss: 0.6959
Training Epoch: 92 [24576/50176]	Loss: 0.6257
Training Epoch: 92 [25600/50176]	Loss: 0.6787
Training Epoch: 92 [26624/50176]	Loss: 0.7316
Training Epoch: 92 [27648/50176]	Loss: 0.6929
Training Epoch: 92 [28672/50176]	Loss: 0.6931
Training Epoch: 92 [29696/50176]	Loss: 0.6216
Training Epoch: 92 [30720/50176]	Loss: 0.6576
Training Epoch: 92 [31744/50176]	Loss: 0.6713
Training Epoch: 92 [32768/50176]	Loss: 0.7067
Training Epoch: 92 [33792/50176]	Loss: 0.7006
Training Epoch: 92 [34816/50176]	Loss: 0.7505
Training Epoch: 92 [35840/50176]	Loss: 0.6943
Training Epoch: 92 [36864/50176]	Loss: 0.6393
Training Epoch: 92 [37888/50176]	Loss: 0.7015
Training Epoch: 92 [38912/50176]	Loss: 0.7390
Training Epoch: 92 [39936/50176]	Loss: 0.6876
Training Epoch: 92 [40960/50176]	Loss: 0.6726
Training Epoch: 92 [41984/50176]	Loss: 0.7506
Training Epoch: 92 [43008/50176]	Loss: 0.6441
Training Epoch: 92 [44032/50176]	Loss: 0.7319
Training Epoch: 92 [45056/50176]	Loss: 0.7230
Training Epoch: 92 [46080/50176]	Loss: 0.7017
Training Epoch: 92 [47104/50176]	Loss: 0.7426
Training Epoch: 92 [48128/50176]	Loss: 0.6725
Training Epoch: 92 [49152/50176]	Loss: 0.6818
Training Epoch: 92 [50176/50176]	Loss: 0.6798
2022-12-06 19:26:15.958 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:26:15,976 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.73 energy=472.78
2022-12-06 14:26:15,976 [ZeusDataLoader(train)] Up to epoch 93: time=4525.85, energy=626364.40, cost=709193.88
2022-12-06 14:26:15,977 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:26:15,977 [ZeusDataLoader(train)] Expected next epoch: time=4572.95, energy=633052.27, cost=716659.37
2022-12-06 14:26:15,978 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0073, Accuracy: 0.2205
2022-12-06 14:26:16,226 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:26:16,226 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:26:16.230 [ZeusMonitor] Monitor started.
2022-12-06 19:26:16.230 [ZeusMonitor] Running indefinitely. 2022-12-06 19:26:16.230 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:26:16.230 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e94+gpu0.power.log
2022-12-06 14:27:00,213 [ZeusDataLoader(train)] train epoch 94 done: time=44.23 energy=6227.59
2022-12-06 14:27:00,217 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 0.6070
Training Epoch: 93 [2048/50176]	Loss: 0.5753
Training Epoch: 93 [3072/50176]	Loss: 0.5715
Training Epoch: 93 [4096/50176]	Loss: 0.6394
Training Epoch: 93 [5120/50176]	Loss: 0.7135
Training Epoch: 93 [6144/50176]	Loss: 0.6488
Training Epoch: 93 [7168/50176]	Loss: 0.5658
Training Epoch: 93 [8192/50176]	Loss: 0.5745
Training Epoch: 93 [9216/50176]	Loss: 0.6568
Training Epoch: 93 [10240/50176]	Loss: 0.6026
Training Epoch: 93 [11264/50176]	Loss: 0.6697
Training Epoch: 93 [12288/50176]	Loss: 0.6159
Training Epoch: 93 [13312/50176]	Loss: 0.6692
Training Epoch: 93 [14336/50176]	Loss: 0.7035
Training Epoch: 93 [15360/50176]	Loss: 0.6442
Training Epoch: 93 [16384/50176]	Loss: 0.5884
Training Epoch: 93 [17408/50176]	Loss: 0.6567
Training Epoch: 93 [18432/50176]	Loss: 0.6282
Training Epoch: 93 [19456/50176]	Loss: 0.6777
Training Epoch: 93 [20480/50176]	Loss: 0.6658
Training Epoch: 93 [21504/50176]	Loss: 0.7118
Training Epoch: 93 [22528/50176]	Loss: 0.6085
Training Epoch: 93 [23552/50176]	Loss: 0.6665
Training Epoch: 93 [24576/50176]	Loss: 0.6709
Training Epoch: 93 [25600/50176]	Loss: 0.6919
Training Epoch: 93 [26624/50176]	Loss: 0.6973
Training Epoch: 93 [27648/50176]	Loss: 0.6484
Training Epoch: 93 [28672/50176]	Loss: 0.6444
Training Epoch: 93 [29696/50176]	Loss: 0.6654
Training Epoch: 93 [30720/50176]	Loss: 0.6829
Training Epoch: 93 [31744/50176]	Loss: 0.6750
Training Epoch: 93 [32768/50176]	Loss: 0.6854
Training Epoch: 93 [33792/50176]	Loss: 0.7097
Training Epoch: 93 [34816/50176]	Loss: 0.6770
Training Epoch: 93 [35840/50176]	Loss: 0.5991
Training Epoch: 93 [36864/50176]	Loss: 0.7007
Training Epoch: 93 [37888/50176]	Loss: 0.7307
Training Epoch: 93 [38912/50176]	Loss: 0.7305
Training Epoch: 93 [39936/50176]	Loss: 0.6562
Training Epoch: 93 [40960/50176]	Loss: 0.7287
Training Epoch: 93 [41984/50176]	Loss: 0.7261
Training Epoch: 93 [43008/50176]	Loss: 0.7425
Training Epoch: 93 [44032/50176]	Loss: 0.7544
Training Epoch: 93 [45056/50176]	Loss: 0.7456
Training Epoch: 93 [46080/50176]	Loss: 0.7214
Training Epoch: 93 [47104/50176]	Loss: 0.6572
Training Epoch: 93 [48128/50176]	Loss: 0.6479
Training Epoch: 93 [49152/50176]	Loss: 0.7475
Training Epoch: 93 [50176/50176]	Loss: 0.7547
2022-12-06 19:27:03.969 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:27:04,015 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.79 energy=480.65
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Up to epoch 94: time=4573.87, energy=633072.63, cost=716749.61
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:27:04,015 [ZeusDataLoader(train)] Expected next epoch: time=4620.97, energy=639760.51, cost=724215.11
2022-12-06 14:27:04,016 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 0.0184, Accuracy: 0.0847
2022-12-06 14:27:04,209 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:27:04,210 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:27:04.213 [ZeusMonitor] Monitor started.
2022-12-06 19:27:04.213 [ZeusMonitor] Running indefinitely. 2022-12-06 19:27:04.213 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:27:04.213 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e95+gpu0.power.log
2022-12-06 14:27:48,277 [ZeusDataLoader(train)] train epoch 95 done: time=44.25 energy=6232.27
2022-12-06 14:27:48,280 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 0.5970
Training Epoch: 94 [2048/50176]	Loss: 0.6546
Training Epoch: 94 [3072/50176]	Loss: 0.5799
Training Epoch: 94 [4096/50176]	Loss: 0.6133
Training Epoch: 94 [5120/50176]	Loss: 0.5844
Training Epoch: 94 [6144/50176]	Loss: 0.6076
Training Epoch: 94 [7168/50176]	Loss: 0.6032
Training Epoch: 94 [8192/50176]	Loss: 0.6118
Training Epoch: 94 [9216/50176]	Loss: 0.6218
Training Epoch: 94 [10240/50176]	Loss: 0.6865
Training Epoch: 94 [11264/50176]	Loss: 0.5332
Training Epoch: 94 [12288/50176]	Loss: 0.5679
Training Epoch: 94 [13312/50176]	Loss: 0.6495
Training Epoch: 94 [14336/50176]	Loss: 0.6264
Training Epoch: 94 [15360/50176]	Loss: 0.6596
Training Epoch: 94 [16384/50176]	Loss: 0.6050
Training Epoch: 94 [17408/50176]	Loss: 0.6248
Training Epoch: 94 [18432/50176]	Loss: 0.6791
Training Epoch: 94 [19456/50176]	Loss: 0.6396
Training Epoch: 94 [20480/50176]	Loss: 0.6915
Training Epoch: 94 [21504/50176]	Loss: 0.6084
Training Epoch: 94 [22528/50176]	Loss: 0.7165
Training Epoch: 94 [23552/50176]	Loss: 0.6722
Training Epoch: 94 [24576/50176]	Loss: 0.6545
Training Epoch: 94 [25600/50176]	Loss: 0.6040
Training Epoch: 94 [26624/50176]	Loss: 0.6929
Training Epoch: 94 [27648/50176]	Loss: 0.6666
Training Epoch: 94 [28672/50176]	Loss: 0.6522
Training Epoch: 94 [29696/50176]	Loss: 0.6551
Training Epoch: 94 [30720/50176]	Loss: 0.6480
Training Epoch: 94 [31744/50176]	Loss: 0.7120
Training Epoch: 94 [32768/50176]	Loss: 0.6886
Training Epoch: 94 [33792/50176]	Loss: 0.6324
Training Epoch: 94 [34816/50176]	Loss: 0.7520
Training Epoch: 94 [35840/50176]	Loss: 0.6624
Training Epoch: 94 [36864/50176]	Loss: 0.7290
Training Epoch: 94 [37888/50176]	Loss: 0.6074
Training Epoch: 94 [38912/50176]	Loss: 0.7194
Training Epoch: 94 [39936/50176]	Loss: 0.6665
Training Epoch: 94 [40960/50176]	Loss: 0.7241
Training Epoch: 94 [41984/50176]	Loss: 0.7179
Training Epoch: 94 [43008/50176]	Loss: 0.6791
Training Epoch: 94 [44032/50176]	Loss: 0.7574
Training Epoch: 94 [45056/50176]	Loss: 0.7634
Training Epoch: 94 [46080/50176]	Loss: 0.7387
Training Epoch: 94 [47104/50176]	Loss: 0.6211
Training Epoch: 94 [48128/50176]	Loss: 0.7291
Training Epoch: 94 [49152/50176]	Loss: 0.6651
Training Epoch: 94 [50176/50176]	Loss: 0.7190
2022-12-06 19:27:52.027 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:27:52,076 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.79 energy=476.19
2022-12-06 14:27:52,076 [ZeusDataLoader(train)] Up to epoch 95: time=4621.91, energy=639781.10, cost=724307.36
2022-12-06 14:27:52,076 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:27:52,077 [ZeusDataLoader(train)] Expected next epoch: time=4669.01, energy=646468.98, cost=731772.86
2022-12-06 14:27:52,077 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 0.0155, Accuracy: 0.0940
2022-12-06 14:27:52,308 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:27:52,309 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:27:52.311 [ZeusMonitor] Monitor started.
2022-12-06 19:27:52.311 [ZeusMonitor] Running indefinitely. 2022-12-06 19:27:52.311 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:27:52.311 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e96+gpu0.power.log
2022-12-06 14:28:36,359 [ZeusDataLoader(train)] train epoch 96 done: time=44.27 energy=6226.11
2022-12-06 14:28:36,362 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 0.5591
Training Epoch: 95 [2048/50176]	Loss: 0.5889
Training Epoch: 95 [3072/50176]	Loss: 0.6502
Training Epoch: 95 [4096/50176]	Loss: 0.6051
Training Epoch: 95 [5120/50176]	Loss: 0.6593
Training Epoch: 95 [6144/50176]	Loss: 0.6465
Training Epoch: 95 [7168/50176]	Loss: 0.6058
Training Epoch: 95 [8192/50176]	Loss: 0.6639
Training Epoch: 95 [9216/50176]	Loss: 0.5978
Training Epoch: 95 [10240/50176]	Loss: 0.5944
Training Epoch: 95 [11264/50176]	Loss: 0.6571
Training Epoch: 95 [12288/50176]	Loss: 0.6294
Training Epoch: 95 [13312/50176]	Loss: 0.6969
Training Epoch: 95 [14336/50176]	Loss: 0.5916
Training Epoch: 95 [15360/50176]	Loss: 0.6423
Training Epoch: 95 [16384/50176]	Loss: 0.6257
Training Epoch: 95 [17408/50176]	Loss: 0.6355
Training Epoch: 95 [18432/50176]	Loss: 0.6214
Training Epoch: 95 [19456/50176]	Loss: 0.6956
Training Epoch: 95 [20480/50176]	Loss: 0.6640
Training Epoch: 95 [21504/50176]	Loss: 0.6702
Training Epoch: 95 [22528/50176]	Loss: 0.6310
Training Epoch: 95 [23552/50176]	Loss: 0.6381
Training Epoch: 95 [24576/50176]	Loss: 0.6545
Training Epoch: 95 [25600/50176]	Loss: 0.6881
Training Epoch: 95 [26624/50176]	Loss: 0.7047
Training Epoch: 95 [27648/50176]	Loss: 0.6329
Training Epoch: 95 [28672/50176]	Loss: 0.6224
Training Epoch: 95 [29696/50176]	Loss: 0.7010
Training Epoch: 95 [30720/50176]	Loss: 0.6812
Training Epoch: 95 [31744/50176]	Loss: 0.7132
Training Epoch: 95 [32768/50176]	Loss: 0.7178
Training Epoch: 95 [33792/50176]	Loss: 0.6882
Training Epoch: 95 [34816/50176]	Loss: 0.6631
Training Epoch: 95 [35840/50176]	Loss: 0.7195
Training Epoch: 95 [36864/50176]	Loss: 0.6265
Training Epoch: 95 [37888/50176]	Loss: 0.6832
Training Epoch: 95 [38912/50176]	Loss: 0.6821
Training Epoch: 95 [39936/50176]	Loss: 0.6878
Training Epoch: 95 [40960/50176]	Loss: 0.6483
Training Epoch: 95 [41984/50176]	Loss: 0.7668
Training Epoch: 95 [43008/50176]	Loss: 0.6536
Training Epoch: 95 [44032/50176]	Loss: 0.6736
Training Epoch: 95 [45056/50176]	Loss: 0.6752
Training Epoch: 95 [46080/50176]	Loss: 0.6348
Training Epoch: 95 [47104/50176]	Loss: 0.7291
Training Epoch: 95 [48128/50176]	Loss: 0.6626
Training Epoch: 95 [49152/50176]	Loss: 0.6349
Training Epoch: 95 [50176/50176]	Loss: 0.6450
2022-12-06 19:28:40.045 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:28:40,058 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.69 energy=471.83
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Up to epoch 96: time=4669.87, energy=646479.03, cost=731852.92
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:28:40,058 [ZeusDataLoader(train)] Expected next epoch: time=4716.97, energy=653166.91, cost=739318.41
2022-12-06 14:28:40,059 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 0.0113, Accuracy: 0.0443
2022-12-06 14:28:40,299 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:28:40,299 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:28:40.301 [ZeusMonitor] Monitor started.
2022-12-06 19:28:40.301 [ZeusMonitor] Running indefinitely. 2022-12-06 19:28:40.301 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:28:40.301 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e97+gpu0.power.log
2022-12-06 14:29:24,141 [ZeusDataLoader(train)] train epoch 97 done: time=44.07 energy=6215.18
2022-12-06 14:29:24,145 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 0.5812
Training Epoch: 96 [2048/50176]	Loss: 0.6084
Training Epoch: 96 [3072/50176]	Loss: 0.6263
Training Epoch: 96 [4096/50176]	Loss: 0.5543
Training Epoch: 96 [5120/50176]	Loss: 0.5743
Training Epoch: 96 [6144/50176]	Loss: 0.6084
Training Epoch: 96 [7168/50176]	Loss: 0.6320
Training Epoch: 96 [8192/50176]	Loss: 0.5844
Training Epoch: 96 [9216/50176]	Loss: 0.6284
Training Epoch: 96 [10240/50176]	Loss: 0.5835
Training Epoch: 96 [11264/50176]	Loss: 0.6151
Training Epoch: 96 [12288/50176]	Loss: 0.6111
Training Epoch: 96 [13312/50176]	Loss: 0.5941
Training Epoch: 96 [14336/50176]	Loss: 0.6779
Training Epoch: 96 [15360/50176]	Loss: 0.6502
Training Epoch: 96 [16384/50176]	Loss: 0.6609
Training Epoch: 96 [17408/50176]	Loss: 0.6296
Training Epoch: 96 [18432/50176]	Loss: 0.5960
Training Epoch: 96 [19456/50176]	Loss: 0.6622
Training Epoch: 96 [20480/50176]	Loss: 0.6340
Training Epoch: 96 [21504/50176]	Loss: 0.7045
Training Epoch: 96 [22528/50176]	Loss: 0.6640
Training Epoch: 96 [23552/50176]	Loss: 0.6529
Training Epoch: 96 [24576/50176]	Loss: 0.6422
Training Epoch: 96 [25600/50176]	Loss: 0.6715
Training Epoch: 96 [26624/50176]	Loss: 0.5953
Training Epoch: 96 [27648/50176]	Loss: 0.6506
Training Epoch: 96 [28672/50176]	Loss: 0.7133
Training Epoch: 96 [29696/50176]	Loss: 0.6752
Training Epoch: 96 [30720/50176]	Loss: 0.6776
Training Epoch: 96 [31744/50176]	Loss: 0.6052
Training Epoch: 96 [32768/50176]	Loss: 0.6442
Training Epoch: 96 [33792/50176]	Loss: 0.6269
Training Epoch: 96 [34816/50176]	Loss: 0.7002
Training Epoch: 96 [35840/50176]	Loss: 0.6823
Training Epoch: 96 [36864/50176]	Loss: 0.6702
Training Epoch: 96 [37888/50176]	Loss: 0.7315
Training Epoch: 96 [38912/50176]	Loss: 0.7512
Training Epoch: 96 [39936/50176]	Loss: 0.7056
Training Epoch: 96 [40960/50176]	Loss: 0.6619
Training Epoch: 96 [41984/50176]	Loss: 0.6666
Training Epoch: 96 [43008/50176]	Loss: 0.7296
Training Epoch: 96 [44032/50176]	Loss: 0.6917
Training Epoch: 96 [45056/50176]	Loss: 0.7185
Training Epoch: 96 [46080/50176]	Loss: 0.6978
Training Epoch: 96 [47104/50176]	Loss: 0.6958
Training Epoch: 96 [48128/50176]	Loss: 0.6693
Training Epoch: 96 [49152/50176]	Loss: 0.6428
Training Epoch: 96 [50176/50176]	Loss: 0.7295
2022-12-06 19:29:28.008 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:29:28,064 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.91 energy=490.12
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Up to epoch 97: time=4717.85, energy=653184.33, cost=739404.29
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:29:28,064 [ZeusDataLoader(train)] Expected next epoch: time=4764.96, energy=659872.21, cost=746869.78
2022-12-06 14:29:28,065 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 0.0139, Accuracy: 0.1463
2022-12-06 14:29:28,358 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:29:28,358 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:29:28.360 [ZeusMonitor] Monitor started.
2022-12-06 19:29:28.360 [ZeusMonitor] Running indefinitely. 2022-12-06 19:29:28.360 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:29:28.360 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e98+gpu0.power.log
2022-12-06 14:30:12,163 [ZeusDataLoader(train)] train epoch 98 done: time=44.09 energy=6215.38
2022-12-06 14:30:12,167 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 0.5763
Training Epoch: 97 [2048/50176]	Loss: 0.5667
Training Epoch: 97 [3072/50176]	Loss: 0.6655
Training Epoch: 97 [4096/50176]	Loss: 0.6051
Training Epoch: 97 [5120/50176]	Loss: 0.6232
Training Epoch: 97 [6144/50176]	Loss: 0.6017
Training Epoch: 97 [7168/50176]	Loss: 0.6250
Training Epoch: 97 [8192/50176]	Loss: 0.6186
Training Epoch: 97 [9216/50176]	Loss: 0.6068
Training Epoch: 97 [10240/50176]	Loss: 0.6235
Training Epoch: 97 [11264/50176]	Loss: 0.5829
Training Epoch: 97 [12288/50176]	Loss: 0.5880
Training Epoch: 97 [13312/50176]	Loss: 0.6159
Training Epoch: 97 [14336/50176]	Loss: 0.6457
Training Epoch: 97 [15360/50176]	Loss: 0.6355
Training Epoch: 97 [16384/50176]	Loss: 0.6029
Training Epoch: 97 [17408/50176]	Loss: 0.6038
Training Epoch: 97 [18432/50176]	Loss: 0.5852
Training Epoch: 97 [19456/50176]	Loss: 0.6391
Training Epoch: 97 [20480/50176]	Loss: 0.6503
Training Epoch: 97 [21504/50176]	Loss: 0.6516
Training Epoch: 97 [22528/50176]	Loss: 0.6485
Training Epoch: 97 [23552/50176]	Loss: 0.6319
Training Epoch: 97 [24576/50176]	Loss: 0.6145
Training Epoch: 97 [25600/50176]	Loss: 0.6962
Training Epoch: 97 [26624/50176]	Loss: 0.5972
Training Epoch: 97 [27648/50176]	Loss: 0.6044
Training Epoch: 97 [28672/50176]	Loss: 0.5922
Training Epoch: 97 [29696/50176]	Loss: 0.6963
Training Epoch: 97 [30720/50176]	Loss: 0.6220
Training Epoch: 97 [31744/50176]	Loss: 0.6705
Training Epoch: 97 [32768/50176]	Loss: 0.6225
Training Epoch: 97 [33792/50176]	Loss: 0.6504
Training Epoch: 97 [34816/50176]	Loss: 0.6809
Training Epoch: 97 [35840/50176]	Loss: 0.6741
Training Epoch: 97 [36864/50176]	Loss: 0.6993
Training Epoch: 97 [37888/50176]	Loss: 0.6632
Training Epoch: 97 [38912/50176]	Loss: 0.7134
Training Epoch: 97 [39936/50176]	Loss: 0.6464
Training Epoch: 97 [40960/50176]	Loss: 0.5995
Training Epoch: 97 [41984/50176]	Loss: 0.5877
Training Epoch: 97 [43008/50176]	Loss: 0.6464
Training Epoch: 97 [44032/50176]	Loss: 0.7304
Training Epoch: 97 [45056/50176]	Loss: 0.7282
Training Epoch: 97 [46080/50176]	Loss: 0.6617
Training Epoch: 97 [47104/50176]	Loss: 0.6661
Training Epoch: 97 [48128/50176]	Loss: 0.5900
Training Epoch: 97 [49152/50176]	Loss: 0.6963
Training Epoch: 97 [50176/50176]	Loss: 0.7139
2022-12-06 19:30:16.022 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:30:16,046 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.87 energy=479.89
2022-12-06 14:30:16,046 [ZeusDataLoader(train)] Up to epoch 98: time=4765.82, energy=659879.60, cost=746948.61
2022-12-06 14:30:16,047 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:30:16,047 [ZeusDataLoader(train)] Expected next epoch: time=4812.92, energy=666567.48, cost=754414.11
2022-12-06 14:30:16,048 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0093, Accuracy: 0.2004
2022-12-06 14:30:16,273 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:30:16,274 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:30:16.288 [ZeusMonitor] Monitor started.
2022-12-06 19:30:16.288 [ZeusMonitor] Running indefinitely. 2022-12-06 19:30:16.288 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:30:16.288 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e99+gpu0.power.log
2022-12-06 14:31:00,311 [ZeusDataLoader(train)] train epoch 99 done: time=44.26 energy=6228.17
2022-12-06 14:31:00,314 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 0.5753
Training Epoch: 98 [2048/50176]	Loss: 0.4817
Training Epoch: 98 [3072/50176]	Loss: 0.5622
Training Epoch: 98 [4096/50176]	Loss: 0.5233
Training Epoch: 98 [5120/50176]	Loss: 0.6122
Training Epoch: 98 [6144/50176]	Loss: 0.5838
Training Epoch: 98 [7168/50176]	Loss: 0.5585
Training Epoch: 98 [8192/50176]	Loss: 0.6276
Training Epoch: 98 [9216/50176]	Loss: 0.5573
Training Epoch: 98 [10240/50176]	Loss: 0.5964
Training Epoch: 98 [11264/50176]	Loss: 0.6041
Training Epoch: 98 [12288/50176]	Loss: 0.6077
Training Epoch: 98 [13312/50176]	Loss: 0.5915
Training Epoch: 98 [14336/50176]	Loss: 0.5536
Training Epoch: 98 [15360/50176]	Loss: 0.5702
Training Epoch: 98 [16384/50176]	Loss: 0.6430
Training Epoch: 98 [17408/50176]	Loss: 0.6487
Training Epoch: 98 [18432/50176]	Loss: 0.5856
Training Epoch: 98 [19456/50176]	Loss: 0.6006
Training Epoch: 98 [20480/50176]	Loss: 0.5764
Training Epoch: 98 [21504/50176]	Loss: 0.6261
Training Epoch: 98 [22528/50176]	Loss: 0.6431
Training Epoch: 98 [23552/50176]	Loss: 0.6579
Training Epoch: 98 [24576/50176]	Loss: 0.6259
Training Epoch: 98 [25600/50176]	Loss: 0.6237
Training Epoch: 98 [26624/50176]	Loss: 0.6326
Training Epoch: 98 [27648/50176]	Loss: 0.6560
Training Epoch: 98 [28672/50176]	Loss: 0.6274
Training Epoch: 98 [29696/50176]	Loss: 0.6523
Training Epoch: 98 [30720/50176]	Loss: 0.6841
Training Epoch: 98 [31744/50176]	Loss: 0.7224
Training Epoch: 98 [32768/50176]	Loss: 0.6199
Training Epoch: 98 [33792/50176]	Loss: 0.6675
Training Epoch: 98 [34816/50176]	Loss: 0.6379
Training Epoch: 98 [35840/50176]	Loss: 0.6607
Training Epoch: 98 [36864/50176]	Loss: 0.7056
Training Epoch: 98 [37888/50176]	Loss: 0.6557
Training Epoch: 98 [38912/50176]	Loss: 0.6267
Training Epoch: 98 [39936/50176]	Loss: 0.5814
Training Epoch: 98 [40960/50176]	Loss: 0.6041
Training Epoch: 98 [41984/50176]	Loss: 0.6318
Training Epoch: 98 [43008/50176]	Loss: 0.6632
Training Epoch: 98 [44032/50176]	Loss: 0.6911
Training Epoch: 98 [45056/50176]	Loss: 0.6966
Training Epoch: 98 [46080/50176]	Loss: 0.7140
Training Epoch: 98 [47104/50176]	Loss: 0.6225
Training Epoch: 98 [48128/50176]	Loss: 0.6932
Training Epoch: 98 [49152/50176]	Loss: 0.6443
Training Epoch: 98 [50176/50176]	Loss: 0.6196
2022-12-06 19:31:04.066 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:31:04,114 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.79 energy=495.31
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Up to epoch 99: time=4813.86, energy=666603.08, cost=754514.50
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.10 energy=6687.88
2022-12-06 14:31:04,114 [ZeusDataLoader(train)] Expected next epoch: time=4860.97, energy=673290.96, cost=761979.99
2022-12-06 14:31:04,115 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0223, Accuracy: 0.0962
2022-12-06 14:31:04,304 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:31:04,305 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:31:04.309 [ZeusMonitor] Monitor started.
2022-12-06 19:31:04.309 [ZeusMonitor] Running indefinitely. 2022-12-06 19:31:04.309 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:31:04.309 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e100+gpu0.power.log
2022-12-06 14:31:48,659 [ZeusDataLoader(train)] train epoch 100 done: time=44.54 energy=6246.90
2022-12-06 14:31:48,662 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 0.5675
Training Epoch: 99 [2048/50176]	Loss: 0.5855
Training Epoch: 99 [3072/50176]	Loss: 0.5545
Training Epoch: 99 [4096/50176]	Loss: 0.6313
Training Epoch: 99 [5120/50176]	Loss: 0.5909
Training Epoch: 99 [6144/50176]	Loss: 0.5373
Training Epoch: 99 [7168/50176]	Loss: 0.5761
Training Epoch: 99 [8192/50176]	Loss: 0.5754
Training Epoch: 99 [9216/50176]	Loss: 0.5276
Training Epoch: 99 [10240/50176]	Loss: 0.5933
Training Epoch: 99 [11264/50176]	Loss: 0.5395
Training Epoch: 99 [12288/50176]	Loss: 0.6421
Training Epoch: 99 [13312/50176]	Loss: 0.6092
Training Epoch: 99 [14336/50176]	Loss: 0.5673
Training Epoch: 99 [15360/50176]	Loss: 0.5262
Training Epoch: 99 [16384/50176]	Loss: 0.5515
Training Epoch: 99 [17408/50176]	Loss: 0.6108
Training Epoch: 99 [18432/50176]	Loss: 0.5733
Training Epoch: 99 [19456/50176]	Loss: 0.5832
Training Epoch: 99 [20480/50176]	Loss: 0.6359
Training Epoch: 99 [21504/50176]	Loss: 0.6189
Training Epoch: 99 [22528/50176]	Loss: 0.6002
Training Epoch: 99 [23552/50176]	Loss: 0.6269
Training Epoch: 99 [24576/50176]	Loss: 0.5917
Training Epoch: 99 [25600/50176]	Loss: 0.6372
Training Epoch: 99 [26624/50176]	Loss: 0.6471
Training Epoch: 99 [27648/50176]	Loss: 0.6324
Training Epoch: 99 [28672/50176]	Loss: 0.6225
Training Epoch: 99 [29696/50176]	Loss: 0.5676
Training Epoch: 99 [30720/50176]	Loss: 0.6047
Training Epoch: 99 [31744/50176]	Loss: 0.6343
Training Epoch: 99 [32768/50176]	Loss: 0.5899
Training Epoch: 99 [33792/50176]	Loss: 0.6422
Training Epoch: 99 [34816/50176]	Loss: 0.6361
Training Epoch: 99 [35840/50176]	Loss: 0.6796
Training Epoch: 99 [36864/50176]	Loss: 0.6621
Training Epoch: 99 [37888/50176]	Loss: 0.5907
Training Epoch: 99 [38912/50176]	Loss: 0.6338
Training Epoch: 99 [39936/50176]	Loss: 0.6259
Training Epoch: 99 [40960/50176]	Loss: 0.6003
Training Epoch: 99 [41984/50176]	Loss: 0.6893
Training Epoch: 99 [43008/50176]	Loss: 0.6678
Training Epoch: 99 [44032/50176]	Loss: 0.6645
Training Epoch: 99 [45056/50176]	Loss: 0.6079
Training Epoch: 99 [46080/50176]	Loss: 0.5939
Training Epoch: 99 [47104/50176]	Loss: 0.5896
Training Epoch: 99 [48128/50176]	Loss: 0.7329
Training Epoch: 99 [49152/50176]	Loss: 0.6759
Training Epoch: 99 [50176/50176]	Loss: 0.6956
2022-12-06 19:31:52.333 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:31:52,344 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.67 energy=458.13
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Up to epoch 100: time=4862.07, energy=673308.11, cost=762085.34
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Training done.
2022-12-06 14:31:52,344 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec02+try01+bs1024+lr0.0500000.train.json: {"energy": 673308.1082976655, "time": 4862.071877154984, "cost": 762085.3433998938, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 0.0133, Accuracy: 0.1025

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 673308.1082976655, 'time': 4862.071877154984, 'cost': 762085.3433998938, 'num_epochs': 100, 'reached': False}
[run job; power] power_stats={'job_id': 'rec02+try01', 'train_power': {'175000': 144.47546303251323, '150000': 143.5043538909716, '125000': 122.98543544465625, '100000': 96.15303472348029}, 'train_throughput': {'175000': 1.1271092756166952, '150000': 1.1318246084833394, '125000': 1.049840007140111, '100000': 0.5319577495376839}, 'eval_power': {'175000': 125.11089176100826, '150000': 124.69307695790027, '125000': 113.06620903588392}, 'eval_throughput': {'175000': 2.7278581345566275, '150000': 2.624264534414073, '125000': 2.5546916558312223}, 'optimal_pl': 150000}
[Zeus Master] cost=762085.3433998938

[Zeus Master] Job did not reach the target metric!
