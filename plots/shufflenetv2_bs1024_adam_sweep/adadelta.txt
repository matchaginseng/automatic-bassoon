[Zeus Master] Job(cifar100,shufflenetv2,adadelta,0.6,bs1024~100) x 100
[Zeus Master] Batch sizes: [1024]
[Zeus Master] Learning rates: [0.01]
[run job] Launching job with BS 1024: and LR: 0.01
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734', 'ZEUS_JOB_ID': 'rec00+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.01']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/rec00+try01.train.log'
2022-12-08 10:35:40,303 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-08 10:35:40,303 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-08 10:35:40,303 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-08 10:35:40,355 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-08 10:35:40,355 [ZeusDataLoader(train)] Power profiling: ON
2022-12-08 10:35:50,035 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-08 10:35:50,036 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-08 10:35:50,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 15:35:50.196 [ZeusMonitor] Monitor started.
2022-12-08 15:35:50.196 [ZeusMonitor] Running indefinitely. 2022-12-08 15:35:50.196 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:35:50.196 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e1+gpu0.power.log
2022-12-08 10:35:51,043 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 10:35:51,043 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-08 10:36:01,947 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-08 10:36:35,855 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-08 10:36:37,523 [ZeusDataLoader(train)] train epoch 1 done: time=47.48 energy=6921.57
2022-12-08 10:36:37,527 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 4.7067
Training Epoch: 0 [3072/50176]	Loss: 4.6696
Training Epoch: 0 [4096/50176]	Loss: 4.6389
Training Epoch: 0 [5120/50176]	Loss: 4.6284
Training Epoch: 0 [6144/50176]	Loss: 4.6175
Training Epoch: 0 [7168/50176]	Loss: 4.6438
Training Epoch: 0 [8192/50176]	Loss: 4.5776
Training Epoch: 0 [9216/50176]	Loss: 4.5654
Training Epoch: 0 [10240/50176]	Loss: 4.5786
Training Epoch: 0 [11264/50176]	Loss: 4.5139
Training Epoch: 0 [12288/50176]	Loss: 4.5705
Training Epoch: 0 [13312/50176]	Loss: 4.5700
Training Epoch: 0 [14336/50176]	Loss: 4.4957
Training Epoch: 0 [15360/50176]	Loss: 4.4727
Training Epoch: 0 [16384/50176]	Loss: 4.4819
Training Epoch: 0 [17408/50176]	Loss: 4.4353
Training Epoch: 0 [18432/50176]	Loss: 4.4439
Training Epoch: 0 [19456/50176]	Loss: 4.3244
Training Epoch: 0 [20480/50176]	Loss: 4.3295
Training Epoch: 0 [21504/50176]	Loss: 4.3960
Training Epoch: 0 [22528/50176]	Loss: 4.4685
Training Epoch: 0 [23552/50176]	Loss: 4.5247
Training Epoch: 0 [24576/50176]	Loss: 4.4259
Training Epoch: 0 [25600/50176]	Loss: 4.3279
Training Epoch: 0 [26624/50176]	Loss: 4.3105
Training Epoch: 0 [27648/50176]	Loss: 4.2866
Training Epoch: 0 [28672/50176]	Loss: 4.1894
Training Epoch: 0 [29696/50176]	Loss: 4.2236
Training Epoch: 0 [30720/50176]	Loss: 4.2424
Training Epoch: 0 [31744/50176]	Loss: 4.3283
Training Epoch: 0 [32768/50176]	Loss: 4.3838
Training Epoch: 0 [33792/50176]	Loss: 4.3196
Training Epoch: 0 [34816/50176]	Loss: 4.2220
Training Epoch: 0 [35840/50176]	Loss: 4.2639
Training Epoch: 0 [36864/50176]	Loss: 4.1620
Training Epoch: 0 [37888/50176]	Loss: 4.1353
Training Epoch: 0 [38912/50176]	Loss: 4.0975
Training Epoch: 0 [39936/50176]	Loss: 4.0880
Training Epoch: 0 [40960/50176]	Loss: 4.0153
Training Epoch: 0 [41984/50176]	Loss: 3.9896
Training Epoch: 0 [43008/50176]	Loss: 4.1523
Training Epoch: 0 [44032/50176]	Loss: 4.1683
Training Epoch: 0 [45056/50176]	Loss: 4.2300
Training Epoch: 0 [46080/50176]	Loss: 4.1045
Training Epoch: 0 [47104/50176]	Loss: 4.0612
Training Epoch: 0 [48128/50176]	Loss: 4.0070
Training Epoch: 0 [49152/50176]	Loss: 4.0099
Training Epoch: 0 [50176/50176]	Loss: 3.9532
2022-12-08 15:36:41.241 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:36:41,256 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.72 energy=513.37
2022-12-08 10:36:41,257 [ZeusDataLoader(train)] Up to epoch 1: time=51.20, energy=7434.94, cost=8197.56
2022-12-08 10:36:41,258 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0043, Accuracy: 0.0549
2022-12-08 10:36:41,432 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 15:36:41.434 [ZeusMonitor] Monitor started.
2022-12-08 15:36:41.434 [ZeusMonitor] Running indefinitely. 2022-12-08 15:36:41.434 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:36:41.434 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e2+gpu0.power.log
2022-12-08 10:36:42,199 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-08 10:36:42,200 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-08 10:36:50,571 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-08 10:37:25,425 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-08 10:37:27,148 [ZeusDataLoader(train)] train epoch 2 done: time=45.88 energy=6591.43
2022-12-08 10:37:27,152 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.0165
Training Epoch: 1 [2048/50176]	Loss: 4.0736
Training Epoch: 1 [3072/50176]	Loss: 4.0499
Training Epoch: 1 [4096/50176]	Loss: 3.9407
Training Epoch: 1 [5120/50176]	Loss: 3.8743
Training Epoch: 1 [6144/50176]	Loss: 3.9065
Training Epoch: 1 [7168/50176]	Loss: 3.8893
Training Epoch: 1 [8192/50176]	Loss: 3.9151
Training Epoch: 1 [9216/50176]	Loss: 4.0165
Training Epoch: 1 [10240/50176]	Loss: 3.9415
Training Epoch: 1 [11264/50176]	Loss: 3.9731
Training Epoch: 1 [12288/50176]	Loss: 3.9290
Training Epoch: 1 [13312/50176]	Loss: 3.9125
Training Epoch: 1 [14336/50176]	Loss: 4.0517
Training Epoch: 1 [15360/50176]	Loss: 3.9203
Training Epoch: 1 [16384/50176]	Loss: 3.9248
Training Epoch: 1 [17408/50176]	Loss: 3.9251
Training Epoch: 1 [18432/50176]	Loss: 3.7835
Training Epoch: 1 [19456/50176]	Loss: 3.9237
Training Epoch: 1 [20480/50176]	Loss: 3.8024
Training Epoch: 1 [21504/50176]	Loss: 3.9088
Training Epoch: 1 [22528/50176]	Loss: 3.9229
Training Epoch: 1 [23552/50176]	Loss: 3.8518
Training Epoch: 1 [24576/50176]	Loss: 3.7669
Training Epoch: 1 [25600/50176]	Loss: 3.7506
Training Epoch: 1 [26624/50176]	Loss: 3.8599
Training Epoch: 1 [27648/50176]	Loss: 3.8801
Training Epoch: 1 [28672/50176]	Loss: 3.8803
Training Epoch: 1 [29696/50176]	Loss: 3.9082
Training Epoch: 1 [30720/50176]	Loss: 3.8587
Training Epoch: 1 [31744/50176]	Loss: 3.8397
Training Epoch: 1 [32768/50176]	Loss: 3.7358
Training Epoch: 1 [33792/50176]	Loss: 3.8200
Training Epoch: 1 [34816/50176]	Loss: 3.7748
Training Epoch: 1 [35840/50176]	Loss: 3.7755
Training Epoch: 1 [36864/50176]	Loss: 3.7555
Training Epoch: 1 [37888/50176]	Loss: 3.7443
Training Epoch: 1 [38912/50176]	Loss: 3.8118
Training Epoch: 1 [39936/50176]	Loss: 3.8106
Training Epoch: 1 [40960/50176]	Loss: 3.7693
Training Epoch: 1 [41984/50176]	Loss: 3.7340
Training Epoch: 1 [43008/50176]	Loss: 3.8487
Training Epoch: 1 [44032/50176]	Loss: 3.7100
Training Epoch: 1 [45056/50176]	Loss: 3.7887
Training Epoch: 1 [46080/50176]	Loss: 3.7404
Training Epoch: 1 [47104/50176]	Loss: 3.7998
Training Epoch: 1 [48128/50176]	Loss: 3.8631
Training Epoch: 1 [49152/50176]	Loss: 3.7266
Training Epoch: 1 [50176/50176]	Loss: 3.6699
2022-12-08 15:37:30.905 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:37:30,921 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.76 energy=497.46
2022-12-08 10:37:30,921 [ZeusDataLoader(train)] Up to epoch 2: time=100.84, energy=14523.83, cost=16085.71
2022-12-08 10:37:30,922 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0037, Accuracy: 0.1139
2022-12-08 10:37:31,108 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 15:37:31.111 [ZeusMonitor] Monitor started.
2022-12-08 15:37:31.111 [ZeusMonitor] Running indefinitely. 2022-12-08 15:37:31.111 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:37:31.111 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e3+gpu0.power.log
2022-12-08 10:37:31,877 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-08 10:37:31,877 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-08 10:37:41,320 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-08 10:38:20,824 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-08 10:38:22,775 [ZeusDataLoader(train)] train epoch 3 done: time=51.85 energy=6276.22
2022-12-08 10:38:22,779 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 3.7030
Training Epoch: 2 [2048/50176]	Loss: 3.7077
Training Epoch: 2 [3072/50176]	Loss: 3.6481
Training Epoch: 2 [4096/50176]	Loss: 3.6473
Training Epoch: 2 [5120/50176]	Loss: 3.6660
Training Epoch: 2 [6144/50176]	Loss: 3.7028
Training Epoch: 2 [7168/50176]	Loss: 3.7950
Training Epoch: 2 [8192/50176]	Loss: 3.8524
Training Epoch: 2 [9216/50176]	Loss: 3.6247
Training Epoch: 2 [10240/50176]	Loss: 3.5596
Training Epoch: 2 [11264/50176]	Loss: 3.5553
Training Epoch: 2 [12288/50176]	Loss: 3.6238
Training Epoch: 2 [13312/50176]	Loss: 3.6246
Training Epoch: 2 [14336/50176]	Loss: 3.7071
Training Epoch: 2 [15360/50176]	Loss: 3.6633
Training Epoch: 2 [16384/50176]	Loss: 3.6979
Training Epoch: 2 [17408/50176]	Loss: 3.6259
Training Epoch: 2 [18432/50176]	Loss: 3.5301
Training Epoch: 2 [19456/50176]	Loss: 3.6154
Training Epoch: 2 [20480/50176]	Loss: 3.5273
Training Epoch: 2 [21504/50176]	Loss: 3.6448
Training Epoch: 2 [22528/50176]	Loss: 3.5572
Training Epoch: 2 [23552/50176]	Loss: 3.5567
Training Epoch: 2 [24576/50176]	Loss: 3.6668
Training Epoch: 2 [25600/50176]	Loss: 3.6537
Training Epoch: 2 [26624/50176]	Loss: 3.6621
Training Epoch: 2 [27648/50176]	Loss: 3.6222
Training Epoch: 2 [28672/50176]	Loss: 3.6423
Training Epoch: 2 [29696/50176]	Loss: 3.6341
Training Epoch: 2 [30720/50176]	Loss: 3.6042
Training Epoch: 2 [31744/50176]	Loss: 3.5382
Training Epoch: 2 [32768/50176]	Loss: 3.5425
Training Epoch: 2 [33792/50176]	Loss: 3.6281
Training Epoch: 2 [34816/50176]	Loss: 3.5796
Training Epoch: 2 [35840/50176]	Loss: 3.5863
Training Epoch: 2 [36864/50176]	Loss: 3.5852
Training Epoch: 2 [37888/50176]	Loss: 3.6066
Training Epoch: 2 [38912/50176]	Loss: 3.5032
Training Epoch: 2 [39936/50176]	Loss: 3.5235
Training Epoch: 2 [40960/50176]	Loss: 3.6099
Training Epoch: 2 [41984/50176]	Loss: 3.5555
Training Epoch: 2 [43008/50176]	Loss: 3.5781
Training Epoch: 2 [44032/50176]	Loss: 3.4987
Training Epoch: 2 [45056/50176]	Loss: 3.5942
Training Epoch: 2 [46080/50176]	Loss: 3.6005
Training Epoch: 2 [47104/50176]	Loss: 3.5334
Training Epoch: 2 [48128/50176]	Loss: 3.5939
Training Epoch: 2 [49152/50176]	Loss: 3.5602
Training Epoch: 2 [50176/50176]	Loss: 3.5455
2022-12-08 15:38:27.035 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:38:27,070 [ZeusDataLoader(eval)] eval epoch 3 done: time=4.28 energy=481.70
2022-12-08 10:38:27,070 [ZeusDataLoader(train)] Up to epoch 3: time=156.97, energy=21281.75, cost=24375.81
2022-12-08 10:38:27,071 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0036, Accuracy: 0.1222
2022-12-08 10:38:27,256 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 15:38:27.259 [ZeusMonitor] Monitor started.
2022-12-08 15:38:27.259 [ZeusMonitor] Running indefinitely. 2022-12-08 15:38:27.259 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:38:27.259 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e4+gpu0.power.log
2022-12-08 10:38:28,023 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-08 10:38:28,023 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-08 10:38:52,363 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-08 10:40:36,051 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-08 10:40:36,052 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-08 10:40:36,052 [ZeusDataLoader(train)] Cost-optimal power limit is 175W
2022-12-08 10:40:36,055 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-08 10:40:38,497 [ZeusDataLoader(train)] train epoch 4 done: time=131.42 energy=13398.51
2022-12-08 10:40:38,501 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 3.4961
Training Epoch: 3 [2048/50176]	Loss: 3.5166
Training Epoch: 3 [3072/50176]	Loss: 3.4970
Training Epoch: 3 [4096/50176]	Loss: 3.4786
Training Epoch: 3 [5120/50176]	Loss: 3.4923
Training Epoch: 3 [6144/50176]	Loss: 3.4394
Training Epoch: 3 [7168/50176]	Loss: 3.4166
Training Epoch: 3 [8192/50176]	Loss: 3.4467
Training Epoch: 3 [9216/50176]	Loss: 3.4141
Training Epoch: 3 [10240/50176]	Loss: 3.4374
Training Epoch: 3 [11264/50176]	Loss: 3.5475
Training Epoch: 3 [12288/50176]	Loss: 3.4166
Training Epoch: 3 [13312/50176]	Loss: 3.4240
Training Epoch: 3 [14336/50176]	Loss: 3.3874
Training Epoch: 3 [15360/50176]	Loss: 3.3966
Training Epoch: 3 [16384/50176]	Loss: 3.4952
Training Epoch: 3 [17408/50176]	Loss: 3.4517
Training Epoch: 3 [18432/50176]	Loss: 3.4531
Training Epoch: 3 [19456/50176]	Loss: 3.3864
Training Epoch: 3 [20480/50176]	Loss: 3.3382
Training Epoch: 3 [21504/50176]	Loss: 3.3935
Training Epoch: 3 [22528/50176]	Loss: 3.3228
Training Epoch: 3 [23552/50176]	Loss: 3.4029
Training Epoch: 3 [24576/50176]	Loss: 3.4762
Training Epoch: 3 [25600/50176]	Loss: 3.3784
Training Epoch: 3 [26624/50176]	Loss: 3.4630
Training Epoch: 3 [27648/50176]	Loss: 3.4647
Training Epoch: 3 [28672/50176]	Loss: 3.3654
Training Epoch: 3 [29696/50176]	Loss: 3.3191
Training Epoch: 3 [30720/50176]	Loss: 3.3740
Training Epoch: 3 [31744/50176]	Loss: 3.3399
Training Epoch: 3 [32768/50176]	Loss: 3.3232
Training Epoch: 3 [33792/50176]	Loss: 3.2149
Training Epoch: 3 [34816/50176]	Loss: 3.2827
Training Epoch: 3 [35840/50176]	Loss: 3.2627
Training Epoch: 3 [36864/50176]	Loss: 3.3443
Training Epoch: 3 [37888/50176]	Loss: 3.3752
Training Epoch: 3 [38912/50176]	Loss: 3.4046
Training Epoch: 3 [39936/50176]	Loss: 3.3106
Training Epoch: 3 [40960/50176]	Loss: 3.2083
Training Epoch: 3 [41984/50176]	Loss: 3.2715
Training Epoch: 3 [43008/50176]	Loss: 3.2518
Training Epoch: 3 [44032/50176]	Loss: 3.3393
Training Epoch: 3 [45056/50176]	Loss: 3.3062
Training Epoch: 3 [46080/50176]	Loss: 3.3257
Training Epoch: 3 [47104/50176]	Loss: 3.2619
Training Epoch: 3 [48128/50176]	Loss: 3.4477
Training Epoch: 3 [49152/50176]	Loss: 3.3045
Training Epoch: 3 [50176/50176]	Loss: 3.3604
2022-12-08 15:40:42.243 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:40:42,291 [ZeusDataLoader(eval)] Power profiling done.
2022-12-08 10:40:42,291 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+lr0.0100000.power.json: {"job_id": "rec00+try01", "train_power": {"175000": 154.40443116295992, "150000": 146.53987041988927, "125000": 122.72397225081689, "100000": 102.08045101720573}, "train_throughput": {"175000": 1.122030166276307, "150000": 1.090649724980027, "125000": 0.9622041478454387, "100000": 0.36653964935112676}, "eval_power": {"175000": 135.96811705020852, "150000": 132.2877466725818, "125000": 112.50808699512434}, "eval_throughput": {"175000": 2.6461322114583137, "150000": 2.6592437105036812, "125000": 2.3356564013251946}, "optimal_pl": 175000}
2022-12-08 10:40:42,291 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.78 energy=513.84
2022-12-08 10:40:42,292 [ZeusDataLoader(train)] Up to epoch 4: time=292.17, energy=35194.10, cost=43161.50
2022-12-08 10:40:42,292 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:40:42,292 [ZeusDataLoader(train)] Expected next epoch: time=339.62, energy=42450.90, cost=50941.78
2022-12-08 10:40:42,293 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 0.0035, Accuracy: 0.1578
2022-12-08 10:40:42,438 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:40:42,439 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:40:42.443 [ZeusMonitor] Monitor started.
2022-12-08 15:40:42.443 [ZeusMonitor] Running indefinitely. 2022-12-08 15:40:42.443 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:40:42.443 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e5+gpu0.power.log
2022-12-08 10:41:26,617 [ZeusDataLoader(train)] train epoch 5 done: time=44.32 energy=6734.30
2022-12-08 10:41:26,621 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 3.3257
Training Epoch: 4 [2048/50176]	Loss: 3.2529
Training Epoch: 4 [3072/50176]	Loss: 3.1919
Training Epoch: 4 [4096/50176]	Loss: 3.2136
Training Epoch: 4 [5120/50176]	Loss: 3.2652
Training Epoch: 4 [6144/50176]	Loss: 3.2166
Training Epoch: 4 [7168/50176]	Loss: 3.2399
Training Epoch: 4 [8192/50176]	Loss: 3.2696
Training Epoch: 4 [9216/50176]	Loss: 3.2498
Training Epoch: 4 [10240/50176]	Loss: 3.1613
Training Epoch: 4 [11264/50176]	Loss: 3.2649
Training Epoch: 4 [12288/50176]	Loss: 3.2350
Training Epoch: 4 [13312/50176]	Loss: 3.2289
Training Epoch: 4 [14336/50176]	Loss: 3.2330
Training Epoch: 4 [15360/50176]	Loss: 3.2500
Training Epoch: 4 [16384/50176]	Loss: 3.1853
Training Epoch: 4 [17408/50176]	Loss: 3.3171
Training Epoch: 4 [18432/50176]	Loss: 3.3834
Training Epoch: 4 [19456/50176]	Loss: 3.2790
Training Epoch: 4 [20480/50176]	Loss: 3.2716
Training Epoch: 4 [21504/50176]	Loss: 3.1773
Training Epoch: 4 [22528/50176]	Loss: 3.1361
Training Epoch: 4 [23552/50176]	Loss: 3.1346
Training Epoch: 4 [24576/50176]	Loss: 3.1461
Training Epoch: 4 [25600/50176]	Loss: 3.1317
Training Epoch: 4 [26624/50176]	Loss: 3.1136
Training Epoch: 4 [27648/50176]	Loss: 3.1951
Training Epoch: 4 [28672/50176]	Loss: 3.0921
Training Epoch: 4 [29696/50176]	Loss: 3.2700
Training Epoch: 4 [30720/50176]	Loss: 3.2035
Training Epoch: 4 [31744/50176]	Loss: 3.0820
Training Epoch: 4 [32768/50176]	Loss: 3.2390
Training Epoch: 4 [33792/50176]	Loss: 3.2228
Training Epoch: 4 [34816/50176]	Loss: 3.0914
Training Epoch: 4 [35840/50176]	Loss: 3.1404
Training Epoch: 4 [36864/50176]	Loss: 3.0813
Training Epoch: 4 [37888/50176]	Loss: 3.3118
Training Epoch: 4 [38912/50176]	Loss: 3.1409
Training Epoch: 4 [39936/50176]	Loss: 3.1548
Training Epoch: 4 [40960/50176]	Loss: 3.2147
Training Epoch: 4 [41984/50176]	Loss: 3.0769
Training Epoch: 4 [43008/50176]	Loss: 3.1405
Training Epoch: 4 [44032/50176]	Loss: 3.0777
Training Epoch: 4 [45056/50176]	Loss: 3.1077
Training Epoch: 4 [46080/50176]	Loss: 3.1192
Training Epoch: 4 [47104/50176]	Loss: 3.1434
Training Epoch: 4 [48128/50176]	Loss: 3.1176
Training Epoch: 4 [49152/50176]	Loss: 3.0951
Training Epoch: 4 [50176/50176]	Loss: 3.1621
2022-12-08 15:41:30.355 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:41:30,391 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.76 energy=515.99
2022-12-08 10:41:30,391 [ZeusDataLoader(train)] Up to epoch 5: time=340.24, energy=42444.39, cost=50993.39
2022-12-08 10:41:30,391 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:41:30,391 [ZeusDataLoader(train)] Expected next epoch: time=387.69, energy=49701.20, cost=58773.66
2022-12-08 10:41:30,392 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 0.0032, Accuracy: 0.2092
2022-12-08 10:41:30,539 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:41:30,540 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:41:30.543 [ZeusMonitor] Monitor started.
2022-12-08 15:41:30.543 [ZeusMonitor] Running indefinitely. 2022-12-08 15:41:30.543 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:41:30.543 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e6+gpu0.power.log
2022-12-08 10:42:14,907 [ZeusDataLoader(train)] train epoch 6 done: time=44.51 energy=6751.42
2022-12-08 10:42:14,910 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 2.9513
Training Epoch: 5 [2048/50176]	Loss: 3.0039
Training Epoch: 5 [3072/50176]	Loss: 3.1329
Training Epoch: 5 [4096/50176]	Loss: 2.9758
Training Epoch: 5 [5120/50176]	Loss: 3.0119
Training Epoch: 5 [6144/50176]	Loss: 3.0705
Training Epoch: 5 [7168/50176]	Loss: 2.9985
Training Epoch: 5 [8192/50176]	Loss: 3.1177
Training Epoch: 5 [9216/50176]	Loss: 3.1731
Training Epoch: 5 [10240/50176]	Loss: 3.1436
Training Epoch: 5 [11264/50176]	Loss: 3.0997
Training Epoch: 5 [12288/50176]	Loss: 2.9577
Training Epoch: 5 [13312/50176]	Loss: 3.0286
Training Epoch: 5 [14336/50176]	Loss: 3.0514
Training Epoch: 5 [15360/50176]	Loss: 3.1257
Training Epoch: 5 [16384/50176]	Loss: 3.0173
Training Epoch: 5 [17408/50176]	Loss: 3.0870
Training Epoch: 5 [18432/50176]	Loss: 3.0273
Training Epoch: 5 [19456/50176]	Loss: 3.0185
Training Epoch: 5 [20480/50176]	Loss: 3.0607
Training Epoch: 5 [21504/50176]	Loss: 3.0083
Training Epoch: 5 [22528/50176]	Loss: 3.0976
Training Epoch: 5 [23552/50176]	Loss: 3.0530
Training Epoch: 5 [24576/50176]	Loss: 3.0679
Training Epoch: 5 [25600/50176]	Loss: 2.9932
Training Epoch: 5 [26624/50176]	Loss: 2.9453
Training Epoch: 5 [27648/50176]	Loss: 3.0002
Training Epoch: 5 [28672/50176]	Loss: 2.9692
Training Epoch: 5 [29696/50176]	Loss: 2.9384
Training Epoch: 5 [30720/50176]	Loss: 2.8782
Training Epoch: 5 [31744/50176]	Loss: 2.9483
Training Epoch: 5 [32768/50176]	Loss: 3.0023
Training Epoch: 5 [33792/50176]	Loss: 2.9860
Training Epoch: 5 [34816/50176]	Loss: 2.9807
Training Epoch: 5 [35840/50176]	Loss: 3.0115
Training Epoch: 5 [36864/50176]	Loss: 2.9419
Training Epoch: 5 [37888/50176]	Loss: 2.9790
Training Epoch: 5 [38912/50176]	Loss: 2.9876
Training Epoch: 5 [39936/50176]	Loss: 3.0222
Training Epoch: 5 [40960/50176]	Loss: 2.8699
Training Epoch: 5 [41984/50176]	Loss: 2.9479
Training Epoch: 5 [43008/50176]	Loss: 2.9755
Training Epoch: 5 [44032/50176]	Loss: 3.0807
Training Epoch: 5 [45056/50176]	Loss: 3.0740
Training Epoch: 5 [46080/50176]	Loss: 2.9120
Training Epoch: 5 [47104/50176]	Loss: 2.9448
Training Epoch: 5 [48128/50176]	Loss: 3.0448
Training Epoch: 5 [49152/50176]	Loss: 3.1038
Training Epoch: 5 [50176/50176]	Loss: 2.9639
2022-12-08 15:42:18.724 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:42:18,752 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.83 energy=527.66
2022-12-08 10:42:18,752 [ZeusDataLoader(train)] Up to epoch 6: time=388.58, energy=49723.48, cost=58862.50
2022-12-08 10:42:18,752 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:42:18,752 [ZeusDataLoader(train)] Expected next epoch: time=436.03, energy=56980.28, cost=66642.77
2022-12-08 10:42:18,753 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0031, Accuracy: 0.2338
2022-12-08 10:42:18,942 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:42:18,943 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:42:18.957 [ZeusMonitor] Monitor started.
2022-12-08 15:42:18.957 [ZeusMonitor] Running indefinitely. 2022-12-08 15:42:18.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:42:18.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e7+gpu0.power.log
2022-12-08 10:43:03,197 [ZeusDataLoader(train)] train epoch 7 done: time=44.44 energy=6736.95
2022-12-08 10:43:03,201 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 2.9267
Training Epoch: 6 [2048/50176]	Loss: 2.8679
Training Epoch: 6 [3072/50176]	Loss: 2.9574
Training Epoch: 6 [4096/50176]	Loss: 2.9455
Training Epoch: 6 [5120/50176]	Loss: 2.8262
Training Epoch: 6 [6144/50176]	Loss: 2.9419
Training Epoch: 6 [7168/50176]	Loss: 3.0112
Training Epoch: 6 [8192/50176]	Loss: 2.8809
Training Epoch: 6 [9216/50176]	Loss: 2.9586
Training Epoch: 6 [10240/50176]	Loss: 2.8671
Training Epoch: 6 [11264/50176]	Loss: 2.9106
Training Epoch: 6 [12288/50176]	Loss: 2.9459
Training Epoch: 6 [13312/50176]	Loss: 2.9305
Training Epoch: 6 [14336/50176]	Loss: 2.9298
Training Epoch: 6 [15360/50176]	Loss: 2.8588
Training Epoch: 6 [16384/50176]	Loss: 2.8738
Training Epoch: 6 [17408/50176]	Loss: 2.8643
Training Epoch: 6 [18432/50176]	Loss: 2.8946
Training Epoch: 6 [19456/50176]	Loss: 2.8286
Training Epoch: 6 [20480/50176]	Loss: 2.9736
Training Epoch: 6 [21504/50176]	Loss: 2.9379
Training Epoch: 6 [22528/50176]	Loss: 2.8638
Training Epoch: 6 [23552/50176]	Loss: 2.9090
Training Epoch: 6 [24576/50176]	Loss: 2.8052
Training Epoch: 6 [25600/50176]	Loss: 2.8165
Training Epoch: 6 [26624/50176]	Loss: 2.9227
Training Epoch: 6 [27648/50176]	Loss: 2.8828
Training Epoch: 6 [28672/50176]	Loss: 2.7688
Training Epoch: 6 [29696/50176]	Loss: 2.8112
Training Epoch: 6 [30720/50176]	Loss: 2.9055
Training Epoch: 6 [31744/50176]	Loss: 2.8921
Training Epoch: 6 [32768/50176]	Loss: 2.8075
Training Epoch: 6 [33792/50176]	Loss: 2.8685
Training Epoch: 6 [34816/50176]	Loss: 2.8835
Training Epoch: 6 [35840/50176]	Loss: 2.8105
Training Epoch: 6 [36864/50176]	Loss: 2.8912
Training Epoch: 6 [37888/50176]	Loss: 2.8686
Training Epoch: 6 [38912/50176]	Loss: 2.8269
Training Epoch: 6 [39936/50176]	Loss: 2.7945
Training Epoch: 6 [40960/50176]	Loss: 2.8134
Training Epoch: 6 [41984/50176]	Loss: 2.7389
Training Epoch: 6 [43008/50176]	Loss: 2.7633
Training Epoch: 6 [44032/50176]	Loss: 2.8346
Training Epoch: 6 [45056/50176]	Loss: 2.8021
Training Epoch: 6 [46080/50176]	Loss: 2.8637
Training Epoch: 6 [47104/50176]	Loss: 2.8182
Training Epoch: 6 [48128/50176]	Loss: 2.8648
Training Epoch: 6 [49152/50176]	Loss: 2.8062
Training Epoch: 6 [50176/50176]	Loss: 2.8188
2022-12-08 15:43:06.902 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:43:06,925 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.72 energy=520.34
2022-12-08 10:43:06,926 [ZeusDataLoader(train)] Up to epoch 7: time=436.73, energy=56980.76, cost=66704.39
2022-12-08 10:43:06,926 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:43:06,926 [ZeusDataLoader(train)] Expected next epoch: time=484.18, energy=64237.57, cost=74484.66
2022-12-08 10:43:06,927 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 0.0029, Accuracy: 0.2579
2022-12-08 10:43:07,072 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:43:07,073 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:43:07.077 [ZeusMonitor] Monitor started.
2022-12-08 15:43:07.077 [ZeusMonitor] Running indefinitely. 2022-12-08 15:43:07.077 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:43:07.077 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e8+gpu0.power.log
2022-12-08 10:43:51,433 [ZeusDataLoader(train)] train epoch 8 done: time=44.50 energy=6752.16
2022-12-08 10:43:51,436 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 2.8398
Training Epoch: 7 [2048/50176]	Loss: 2.7282
Training Epoch: 7 [3072/50176]	Loss: 2.7082
Training Epoch: 7 [4096/50176]	Loss: 2.7463
Training Epoch: 7 [5120/50176]	Loss: 2.7384
Training Epoch: 7 [6144/50176]	Loss: 2.7137
Training Epoch: 7 [7168/50176]	Loss: 2.7078
Training Epoch: 7 [8192/50176]	Loss: 2.7331
Training Epoch: 7 [9216/50176]	Loss: 2.6284
Training Epoch: 7 [10240/50176]	Loss: 2.7158
Training Epoch: 7 [11264/50176]	Loss: 2.7369
Training Epoch: 7 [12288/50176]	Loss: 2.7504
Training Epoch: 7 [13312/50176]	Loss: 2.7465
Training Epoch: 7 [14336/50176]	Loss: 2.8095
Training Epoch: 7 [15360/50176]	Loss: 2.7572
Training Epoch: 7 [16384/50176]	Loss: 2.7387
Training Epoch: 7 [17408/50176]	Loss: 2.8228
Training Epoch: 7 [18432/50176]	Loss: 2.7249
Training Epoch: 7 [19456/50176]	Loss: 2.7199
Training Epoch: 7 [20480/50176]	Loss: 2.7323
Training Epoch: 7 [21504/50176]	Loss: 2.6949
Training Epoch: 7 [22528/50176]	Loss: 2.7163
Training Epoch: 7 [23552/50176]	Loss: 2.7753
Training Epoch: 7 [24576/50176]	Loss: 2.7549
Training Epoch: 7 [25600/50176]	Loss: 2.7954
Training Epoch: 7 [26624/50176]	Loss: 2.7949
Training Epoch: 7 [27648/50176]	Loss: 2.8968
Training Epoch: 7 [28672/50176]	Loss: 2.7126
Training Epoch: 7 [29696/50176]	Loss: 2.7661
Training Epoch: 7 [30720/50176]	Loss: 2.7336
Training Epoch: 7 [31744/50176]	Loss: 2.8081
Training Epoch: 7 [32768/50176]	Loss: 2.6568
Training Epoch: 7 [33792/50176]	Loss: 2.7261
Training Epoch: 7 [34816/50176]	Loss: 2.7504
Training Epoch: 7 [35840/50176]	Loss: 2.6764
Training Epoch: 7 [36864/50176]	Loss: 2.6029
Training Epoch: 7 [37888/50176]	Loss: 2.6429
Training Epoch: 7 [38912/50176]	Loss: 2.7387
Training Epoch: 7 [39936/50176]	Loss: 2.7947
Training Epoch: 7 [40960/50176]	Loss: 2.7249
Training Epoch: 7 [41984/50176]	Loss: 2.5866
Training Epoch: 7 [43008/50176]	Loss: 2.6547
Training Epoch: 7 [44032/50176]	Loss: 2.6235
Training Epoch: 7 [45056/50176]	Loss: 2.7226
Training Epoch: 7 [46080/50176]	Loss: 2.7183
Training Epoch: 7 [47104/50176]	Loss: 2.7028
Training Epoch: 7 [48128/50176]	Loss: 2.6725
Training Epoch: 7 [49152/50176]	Loss: 2.7628
Training Epoch: 7 [50176/50176]	Loss: 2.6053
2022-12-08 15:43:55.165 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:43:55,175 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.73 energy=519.77
2022-12-08 10:43:55,175 [ZeusDataLoader(train)] Up to epoch 8: time=484.96, energy=64252.70, cost=74560.18
2022-12-08 10:43:55,175 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:43:55,176 [ZeusDataLoader(train)] Expected next epoch: time=532.41, energy=71509.50, cost=82340.45
2022-12-08 10:43:55,177 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 0.0027, Accuracy: 0.2899
2022-12-08 10:43:55,326 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:43:55,327 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:43:55.330 [ZeusMonitor] Monitor started.
2022-12-08 15:43:55.330 [ZeusMonitor] Running indefinitely. 2022-12-08 15:43:55.330 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:43:55.331 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e9+gpu0.power.log
2022-12-08 10:44:39,798 [ZeusDataLoader(train)] train epoch 9 done: time=44.61 energy=6760.11
2022-12-08 10:44:39,802 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 2.6763
Training Epoch: 8 [2048/50176]	Loss: 2.6623
Training Epoch: 8 [3072/50176]	Loss: 2.6998
Training Epoch: 8 [4096/50176]	Loss: 2.6146
Training Epoch: 8 [5120/50176]	Loss: 2.5012
Training Epoch: 8 [6144/50176]	Loss: 2.5704
Training Epoch: 8 [7168/50176]	Loss: 2.6603
Training Epoch: 8 [8192/50176]	Loss: 2.6519
Training Epoch: 8 [9216/50176]	Loss: 2.6004
Training Epoch: 8 [10240/50176]	Loss: 2.5731
Training Epoch: 8 [11264/50176]	Loss: 2.5811
Training Epoch: 8 [12288/50176]	Loss: 2.5938
Training Epoch: 8 [13312/50176]	Loss: 2.5652
Training Epoch: 8 [14336/50176]	Loss: 2.6411
Training Epoch: 8 [15360/50176]	Loss: 2.7290
Training Epoch: 8 [16384/50176]	Loss: 2.5371
Training Epoch: 8 [17408/50176]	Loss: 2.7346
Training Epoch: 8 [18432/50176]	Loss: 2.7012
Training Epoch: 8 [19456/50176]	Loss: 2.5817
Training Epoch: 8 [20480/50176]	Loss: 2.5567
Training Epoch: 8 [21504/50176]	Loss: 2.5116
Training Epoch: 8 [22528/50176]	Loss: 2.5635
Training Epoch: 8 [23552/50176]	Loss: 2.4877
Training Epoch: 8 [24576/50176]	Loss: 2.6747
Training Epoch: 8 [25600/50176]	Loss: 2.6943
Training Epoch: 8 [26624/50176]	Loss: 2.6338
Training Epoch: 8 [27648/50176]	Loss: 2.5328
Training Epoch: 8 [28672/50176]	Loss: 2.5625
Training Epoch: 8 [29696/50176]	Loss: 2.5851
Training Epoch: 8 [30720/50176]	Loss: 2.5997
Training Epoch: 8 [31744/50176]	Loss: 2.5482
Training Epoch: 8 [32768/50176]	Loss: 2.5867
Training Epoch: 8 [33792/50176]	Loss: 2.6281
Training Epoch: 8 [34816/50176]	Loss: 2.7088
Training Epoch: 8 [35840/50176]	Loss: 2.6274
Training Epoch: 8 [36864/50176]	Loss: 2.5595
Training Epoch: 8 [37888/50176]	Loss: 2.5891
Training Epoch: 8 [38912/50176]	Loss: 2.5469
Training Epoch: 8 [39936/50176]	Loss: 2.6630
Training Epoch: 8 [40960/50176]	Loss: 2.5243
Training Epoch: 8 [41984/50176]	Loss: 2.5961
Training Epoch: 8 [43008/50176]	Loss: 2.6154
Training Epoch: 8 [44032/50176]	Loss: 2.6039
Training Epoch: 8 [45056/50176]	Loss: 2.6706
Training Epoch: 8 [46080/50176]	Loss: 2.5616
Training Epoch: 8 [47104/50176]	Loss: 2.5831
Training Epoch: 8 [48128/50176]	Loss: 2.4940
Training Epoch: 8 [49152/50176]	Loss: 2.6620
Training Epoch: 8 [50176/50176]	Loss: 2.6122
2022-12-08 15:44:43.491 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:44:43,505 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.69 energy=518.88
2022-12-08 10:44:43,505 [ZeusDataLoader(train)] Up to epoch 9: time=533.27, energy=71531.69, cost=82426.55
2022-12-08 10:44:43,505 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:44:43,505 [ZeusDataLoader(train)] Expected next epoch: time=580.72, energy=78788.49, cost=90206.82
2022-12-08 10:44:43,506 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.0027, Accuracy: 0.3037
2022-12-08 10:44:43,692 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:44:43,693 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:44:43.695 [ZeusMonitor] Monitor started.
2022-12-08 15:44:43.695 [ZeusMonitor] Running indefinitely. 2022-12-08 15:44:43.695 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:44:43.695 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e10+gpu0.power.log
2022-12-08 10:45:27,997 [ZeusDataLoader(train)] train epoch 10 done: time=44.48 energy=6747.65
2022-12-08 10:45:28,000 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 2.5750
Training Epoch: 9 [2048/50176]	Loss: 2.5301
Training Epoch: 9 [3072/50176]	Loss: 2.5774
Training Epoch: 9 [4096/50176]	Loss: 2.5116
Training Epoch: 9 [5120/50176]	Loss: 2.6450
Training Epoch: 9 [6144/50176]	Loss: 2.5014
Training Epoch: 9 [7168/50176]	Loss: 2.5395
Training Epoch: 9 [8192/50176]	Loss: 2.5543
Training Epoch: 9 [9216/50176]	Loss: 2.4676
Training Epoch: 9 [10240/50176]	Loss: 2.5086
Training Epoch: 9 [11264/50176]	Loss: 2.5012
Training Epoch: 9 [12288/50176]	Loss: 2.4861
Training Epoch: 9 [13312/50176]	Loss: 2.3908
Training Epoch: 9 [14336/50176]	Loss: 2.4838
Training Epoch: 9 [15360/50176]	Loss: 2.5092
Training Epoch: 9 [16384/50176]	Loss: 2.5713
Training Epoch: 9 [17408/50176]	Loss: 2.4936
Training Epoch: 9 [18432/50176]	Loss: 2.5957
Training Epoch: 9 [19456/50176]	Loss: 2.5130
Training Epoch: 9 [20480/50176]	Loss: 2.5243
Training Epoch: 9 [21504/50176]	Loss: 2.4737
Training Epoch: 9 [22528/50176]	Loss: 2.3887
Training Epoch: 9 [23552/50176]	Loss: 2.3334
Training Epoch: 9 [24576/50176]	Loss: 2.5112
Training Epoch: 9 [25600/50176]	Loss: 2.4409
Training Epoch: 9 [26624/50176]	Loss: 2.4094
Training Epoch: 9 [27648/50176]	Loss: 2.4859
Training Epoch: 9 [28672/50176]	Loss: 2.5541
Training Epoch: 9 [29696/50176]	Loss: 2.5536
Training Epoch: 9 [30720/50176]	Loss: 2.3985
Training Epoch: 9 [31744/50176]	Loss: 2.4069
Training Epoch: 9 [32768/50176]	Loss: 2.3865
Training Epoch: 9 [33792/50176]	Loss: 2.3621
Training Epoch: 9 [34816/50176]	Loss: 2.5001
Training Epoch: 9 [35840/50176]	Loss: 2.4320
Training Epoch: 9 [36864/50176]	Loss: 2.5094
Training Epoch: 9 [37888/50176]	Loss: 2.4361
Training Epoch: 9 [38912/50176]	Loss: 2.5489
Training Epoch: 9 [39936/50176]	Loss: 2.5070
Training Epoch: 9 [40960/50176]	Loss: 2.5220
Training Epoch: 9 [41984/50176]	Loss: 2.4616
Training Epoch: 9 [43008/50176]	Loss: 2.4883
Training Epoch: 9 [44032/50176]	Loss: 2.4569
Training Epoch: 9 [45056/50176]	Loss: 2.3743
Training Epoch: 9 [46080/50176]	Loss: 2.3383
Training Epoch: 9 [47104/50176]	Loss: 2.3645
Training Epoch: 9 [48128/50176]	Loss: 2.4394
Training Epoch: 9 [49152/50176]	Loss: 2.4169
Training Epoch: 9 [50176/50176]	Loss: 2.3600
2022-12-08 15:45:31.730 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:45:31,754 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.74 energy=516.54
2022-12-08 10:45:31,754 [ZeusDataLoader(train)] Up to epoch 10: time=581.49, energy=78795.87, cost=90278.46
2022-12-08 10:45:31,754 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:45:31,755 [ZeusDataLoader(train)] Expected next epoch: time=628.94, energy=86052.68, cost=98058.74
2022-12-08 10:45:31,756 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 0.0025, Accuracy: 0.3487
2022-12-08 10:45:31,942 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:45:31,943 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:45:31.945 [ZeusMonitor] Monitor started.
2022-12-08 15:45:31.945 [ZeusMonitor] Running indefinitely. 2022-12-08 15:45:31.945 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:45:31.945 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e11+gpu0.power.log
2022-12-08 10:46:16,329 [ZeusDataLoader(train)] train epoch 11 done: time=44.56 energy=6751.21
2022-12-08 10:46:16,333 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 2.3860
Training Epoch: 10 [2048/50176]	Loss: 2.3739
Training Epoch: 10 [3072/50176]	Loss: 2.3430
Training Epoch: 10 [4096/50176]	Loss: 2.3983
Training Epoch: 10 [5120/50176]	Loss: 2.3415
Training Epoch: 10 [6144/50176]	Loss: 2.3573
Training Epoch: 10 [7168/50176]	Loss: 2.4122
Training Epoch: 10 [8192/50176]	Loss: 2.3358
Training Epoch: 10 [9216/50176]	Loss: 2.3680
Training Epoch: 10 [10240/50176]	Loss: 2.3048
Training Epoch: 10 [11264/50176]	Loss: 2.4585
Training Epoch: 10 [12288/50176]	Loss: 2.3106
Training Epoch: 10 [13312/50176]	Loss: 2.4576
Training Epoch: 10 [14336/50176]	Loss: 2.4785
Training Epoch: 10 [15360/50176]	Loss: 2.4170
Training Epoch: 10 [16384/50176]	Loss: 2.4574
Training Epoch: 10 [17408/50176]	Loss: 2.4692
Training Epoch: 10 [18432/50176]	Loss: 2.3503
Training Epoch: 10 [19456/50176]	Loss: 2.4264
Training Epoch: 10 [20480/50176]	Loss: 2.4402
Training Epoch: 10 [21504/50176]	Loss: 2.4638
Training Epoch: 10 [22528/50176]	Loss: 2.3302
Training Epoch: 10 [23552/50176]	Loss: 2.3150
Training Epoch: 10 [24576/50176]	Loss: 2.3249
Training Epoch: 10 [25600/50176]	Loss: 2.3934
Training Epoch: 10 [26624/50176]	Loss: 2.3350
Training Epoch: 10 [27648/50176]	Loss: 2.3167
Training Epoch: 10 [28672/50176]	Loss: 2.4212
Training Epoch: 10 [29696/50176]	Loss: 2.4532
Training Epoch: 10 [30720/50176]	Loss: 2.3868
Training Epoch: 10 [31744/50176]	Loss: 2.4677
Training Epoch: 10 [32768/50176]	Loss: 2.4210
Training Epoch: 10 [33792/50176]	Loss: 2.3624
Training Epoch: 10 [34816/50176]	Loss: 2.3652
Training Epoch: 10 [35840/50176]	Loss: 2.4593
Training Epoch: 10 [36864/50176]	Loss: 2.3476
Training Epoch: 10 [37888/50176]	Loss: 2.3409
Training Epoch: 10 [38912/50176]	Loss: 2.3595
Training Epoch: 10 [39936/50176]	Loss: 2.4183
Training Epoch: 10 [40960/50176]	Loss: 2.2284
Training Epoch: 10 [41984/50176]	Loss: 2.3047
Training Epoch: 10 [43008/50176]	Loss: 2.3734
Training Epoch: 10 [44032/50176]	Loss: 2.3526
Training Epoch: 10 [45056/50176]	Loss: 2.2954
Training Epoch: 10 [46080/50176]	Loss: 2.2645
Training Epoch: 10 [47104/50176]	Loss: 2.3613
Training Epoch: 10 [48128/50176]	Loss: 2.3600
Training Epoch: 10 [49152/50176]	Loss: 2.3640
Training Epoch: 10 [50176/50176]	Loss: 2.3571
2022-12-08 15:46:20.217 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:46:20,271 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.91 energy=556.03
2022-12-08 10:46:20,271 [ZeusDataLoader(train)] Up to epoch 11: time=629.96, energy=86103.11, cost=98173.31
2022-12-08 10:46:20,271 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:46:20,271 [ZeusDataLoader(train)] Expected next epoch: time=677.41, energy=93359.92, cost=105953.58
2022-12-08 10:46:20,276 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 0.0025, Accuracy: 0.3475
2022-12-08 10:46:20,856 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:46:20,861 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:46:20.867 [ZeusMonitor] Monitor started.
2022-12-08 15:46:20.867 [ZeusMonitor] Running indefinitely. 2022-12-08 15:46:20.867 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:46:20.867 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e12+gpu0.power.log
2022-12-08 10:47:05,413 [ZeusDataLoader(train)] train epoch 12 done: time=45.13 energy=6767.91
2022-12-08 10:47:05,416 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 2.2786
Training Epoch: 11 [2048/50176]	Loss: 2.2434
Training Epoch: 11 [3072/50176]	Loss: 2.2900
Training Epoch: 11 [4096/50176]	Loss: 2.3581
Training Epoch: 11 [5120/50176]	Loss: 2.4099
Training Epoch: 11 [6144/50176]	Loss: 2.2175
Training Epoch: 11 [7168/50176]	Loss: 2.2623
Training Epoch: 11 [8192/50176]	Loss: 2.2390
Training Epoch: 11 [9216/50176]	Loss: 2.2676
Training Epoch: 11 [10240/50176]	Loss: 2.2939
Training Epoch: 11 [11264/50176]	Loss: 2.1937
Training Epoch: 11 [12288/50176]	Loss: 2.2801
Training Epoch: 11 [13312/50176]	Loss: 2.3599
Training Epoch: 11 [14336/50176]	Loss: 2.2386
Training Epoch: 11 [15360/50176]	Loss: 2.3714
Training Epoch: 11 [16384/50176]	Loss: 2.2510
Training Epoch: 11 [17408/50176]	Loss: 2.2154
Training Epoch: 11 [18432/50176]	Loss: 2.3633
Training Epoch: 11 [19456/50176]	Loss: 2.3098
Training Epoch: 11 [20480/50176]	Loss: 2.3693
Training Epoch: 11 [21504/50176]	Loss: 2.2534
Training Epoch: 11 [22528/50176]	Loss: 2.3655
Training Epoch: 11 [23552/50176]	Loss: 2.3456
Training Epoch: 11 [24576/50176]	Loss: 2.2587
Training Epoch: 11 [25600/50176]	Loss: 2.2174
Training Epoch: 11 [26624/50176]	Loss: 2.1844
Training Epoch: 11 [27648/50176]	Loss: 2.1932
Training Epoch: 11 [28672/50176]	Loss: 2.2360
Training Epoch: 11 [29696/50176]	Loss: 2.3360
Training Epoch: 11 [30720/50176]	Loss: 2.2154
Training Epoch: 11 [31744/50176]	Loss: 2.2262
Training Epoch: 11 [32768/50176]	Loss: 2.2356
Training Epoch: 11 [33792/50176]	Loss: 2.2893
Training Epoch: 11 [34816/50176]	Loss: 2.3821
Training Epoch: 11 [35840/50176]	Loss: 2.3242
Training Epoch: 11 [36864/50176]	Loss: 2.2040
Training Epoch: 11 [37888/50176]	Loss: 2.2716
Training Epoch: 11 [38912/50176]	Loss: 2.3247
Training Epoch: 11 [39936/50176]	Loss: 2.3696
Training Epoch: 11 [40960/50176]	Loss: 2.1353
Training Epoch: 11 [41984/50176]	Loss: 2.2324
Training Epoch: 11 [43008/50176]	Loss: 2.3510
Training Epoch: 11 [44032/50176]	Loss: 2.2205
Training Epoch: 11 [45056/50176]	Loss: 2.3199
Training Epoch: 11 [46080/50176]	Loss: 2.1405
Training Epoch: 11 [47104/50176]	Loss: 2.2731
Training Epoch: 11 [48128/50176]	Loss: 2.2003
Training Epoch: 11 [49152/50176]	Loss: 2.2351
Training Epoch: 11 [50176/50176]	Loss: 2.3115
2022-12-08 15:47:09.156 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:47:09,168 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.74 energy=517.02
2022-12-08 10:47:09,168 [ZeusDataLoader(train)] Up to epoch 12: time=678.83, energy=93388.04, cost=106091.95
2022-12-08 10:47:09,169 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:47:09,169 [ZeusDataLoader(train)] Expected next epoch: time=726.28, energy=100644.85, cost=113872.22
2022-12-08 10:47:09,170 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 0.0023, Accuracy: 0.3729
2022-12-08 10:47:09,356 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:47:09,357 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:47:09.359 [ZeusMonitor] Monitor started.
2022-12-08 15:47:09.359 [ZeusMonitor] Running indefinitely. 2022-12-08 15:47:09.359 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:47:09.359 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e13+gpu0.power.log
2022-12-08 10:47:53,698 [ZeusDataLoader(train)] train epoch 13 done: time=44.52 energy=6766.75
2022-12-08 10:47:53,702 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 2.1970
Training Epoch: 12 [2048/50176]	Loss: 2.1202
Training Epoch: 12 [3072/50176]	Loss: 2.1714
Training Epoch: 12 [4096/50176]	Loss: 2.1464
Training Epoch: 12 [5120/50176]	Loss: 2.0352
Training Epoch: 12 [6144/50176]	Loss: 2.1704
Training Epoch: 12 [7168/50176]	Loss: 2.2578
Training Epoch: 12 [8192/50176]	Loss: 2.0545
Training Epoch: 12 [9216/50176]	Loss: 2.2105
Training Epoch: 12 [10240/50176]	Loss: 2.1225
Training Epoch: 12 [11264/50176]	Loss: 2.2446
Training Epoch: 12 [12288/50176]	Loss: 2.1864
Training Epoch: 12 [13312/50176]	Loss: 2.1110
Training Epoch: 12 [14336/50176]	Loss: 2.2362
Training Epoch: 12 [15360/50176]	Loss: 2.0849
Training Epoch: 12 [16384/50176]	Loss: 2.1741
Training Epoch: 12 [17408/50176]	Loss: 2.1631
Training Epoch: 12 [18432/50176]	Loss: 2.1932
Training Epoch: 12 [19456/50176]	Loss: 2.1305
Training Epoch: 12 [20480/50176]	Loss: 2.1570
Training Epoch: 12 [21504/50176]	Loss: 2.2251
Training Epoch: 12 [22528/50176]	Loss: 2.1637
Training Epoch: 12 [23552/50176]	Loss: 2.2488
Training Epoch: 12 [24576/50176]	Loss: 2.1257
Training Epoch: 12 [25600/50176]	Loss: 2.2389
Training Epoch: 12 [26624/50176]	Loss: 2.2315
Training Epoch: 12 [27648/50176]	Loss: 2.1129
Training Epoch: 12 [28672/50176]	Loss: 2.1347
Training Epoch: 12 [29696/50176]	Loss: 2.1218
Training Epoch: 12 [30720/50176]	Loss: 2.0978
Training Epoch: 12 [31744/50176]	Loss: 2.1629
Training Epoch: 12 [32768/50176]	Loss: 2.2501
Training Epoch: 12 [33792/50176]	Loss: 2.0676
Training Epoch: 12 [34816/50176]	Loss: 2.0994
Training Epoch: 12 [35840/50176]	Loss: 2.1233
Training Epoch: 12 [36864/50176]	Loss: 2.1579
Training Epoch: 12 [37888/50176]	Loss: 2.1323
Training Epoch: 12 [38912/50176]	Loss: 2.0722
Training Epoch: 12 [39936/50176]	Loss: 2.2038
Training Epoch: 12 [40960/50176]	Loss: 2.0816
Training Epoch: 12 [41984/50176]	Loss: 2.1787
Training Epoch: 12 [43008/50176]	Loss: 2.1749
Training Epoch: 12 [44032/50176]	Loss: 2.2569
Training Epoch: 12 [45056/50176]	Loss: 2.1288
Training Epoch: 12 [46080/50176]	Loss: 2.1823
Training Epoch: 12 [47104/50176]	Loss: 2.0885
Training Epoch: 12 [48128/50176]	Loss: 2.0871
Training Epoch: 12 [49152/50176]	Loss: 2.1128
Training Epoch: 12 [50176/50176]	Loss: 2.1025
2022-12-08 15:47:57.428 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:47:57,453 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.74 energy=515.20
2022-12-08 10:47:57,453 [ZeusDataLoader(train)] Up to epoch 13: time=727.09, energy=100669.99, cost=113955.75
2022-12-08 10:47:57,453 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:47:57,453 [ZeusDataLoader(train)] Expected next epoch: time=774.54, energy=107926.80, cost=121736.03
2022-12-08 10:47:57,454 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0023, Accuracy: 0.3860
2022-12-08 10:47:57,632 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:47:57,633 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:47:57.635 [ZeusMonitor] Monitor started.
2022-12-08 15:47:57.635 [ZeusMonitor] Running indefinitely. 2022-12-08 15:47:57.635 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:47:57.635 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e14+gpu0.power.log
2022-12-08 10:48:42,117 [ZeusDataLoader(train)] train epoch 14 done: time=44.65 energy=6764.33
2022-12-08 10:48:42,120 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 2.0511
Training Epoch: 13 [2048/50176]	Loss: 2.0644
Training Epoch: 13 [3072/50176]	Loss: 2.1295
Training Epoch: 13 [4096/50176]	Loss: 2.0682
Training Epoch: 13 [5120/50176]	Loss: 2.0156
Training Epoch: 13 [6144/50176]	Loss: 2.0623
Training Epoch: 13 [7168/50176]	Loss: 2.0220
Training Epoch: 13 [8192/50176]	Loss: 2.0576
Training Epoch: 13 [9216/50176]	Loss: 2.0619
Training Epoch: 13 [10240/50176]	Loss: 2.1384
Training Epoch: 13 [11264/50176]	Loss: 2.0283
Training Epoch: 13 [12288/50176]	Loss: 2.0523
Training Epoch: 13 [13312/50176]	Loss: 2.0646
Training Epoch: 13 [14336/50176]	Loss: 2.0816
Training Epoch: 13 [15360/50176]	Loss: 2.0638
Training Epoch: 13 [16384/50176]	Loss: 2.1222
Training Epoch: 13 [17408/50176]	Loss: 2.0990
Training Epoch: 13 [18432/50176]	Loss: 2.0202
Training Epoch: 13 [19456/50176]	Loss: 2.0609
Training Epoch: 13 [20480/50176]	Loss: 1.9801
Training Epoch: 13 [21504/50176]	Loss: 2.1145
Training Epoch: 13 [22528/50176]	Loss: 2.0347
Training Epoch: 13 [23552/50176]	Loss: 2.0981
Training Epoch: 13 [24576/50176]	Loss: 2.0597
Training Epoch: 13 [25600/50176]	Loss: 2.1016
Training Epoch: 13 [26624/50176]	Loss: 2.0675
Training Epoch: 13 [27648/50176]	Loss: 2.0694
Training Epoch: 13 [28672/50176]	Loss: 2.0501
Training Epoch: 13 [29696/50176]	Loss: 2.0559
Training Epoch: 13 [30720/50176]	Loss: 2.1245
Training Epoch: 13 [31744/50176]	Loss: 2.0739
Training Epoch: 13 [32768/50176]	Loss: 2.0228
Training Epoch: 13 [33792/50176]	Loss: 2.1239
Training Epoch: 13 [34816/50176]	Loss: 2.1306
Training Epoch: 13 [35840/50176]	Loss: 2.1961
Training Epoch: 13 [36864/50176]	Loss: 2.1278
Training Epoch: 13 [37888/50176]	Loss: 2.2166
Training Epoch: 13 [38912/50176]	Loss: 2.0419
Training Epoch: 13 [39936/50176]	Loss: 2.0418
Training Epoch: 13 [40960/50176]	Loss: 2.0702
Training Epoch: 13 [41984/50176]	Loss: 2.1314
Training Epoch: 13 [43008/50176]	Loss: 2.0778
Training Epoch: 13 [44032/50176]	Loss: 2.1770
Training Epoch: 13 [45056/50176]	Loss: 2.0999
Training Epoch: 13 [46080/50176]	Loss: 1.9886
Training Epoch: 13 [47104/50176]	Loss: 1.9903
Training Epoch: 13 [48128/50176]	Loss: 2.1272
Training Epoch: 13 [49152/50176]	Loss: 2.0554
Training Epoch: 13 [50176/50176]	Loss: 2.1137
2022-12-08 15:48:45.912 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:48:45,932 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.80 energy=542.30
2022-12-08 10:48:45,933 [ZeusDataLoader(train)] Up to epoch 14: time=775.55, energy=107976.62, cost=121849.00
2022-12-08 10:48:45,933 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:48:45,933 [ZeusDataLoader(train)] Expected next epoch: time=823.00, energy=115233.43, cost=129629.27
2022-12-08 10:48:45,934 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 0.0022, Accuracy: 0.4025
2022-12-08 10:48:46,081 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:48:46,082 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:48:46.086 [ZeusMonitor] Monitor started.
2022-12-08 15:48:46.086 [ZeusMonitor] Running indefinitely. 2022-12-08 15:48:46.086 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:48:46.086 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e15+gpu0.power.log
2022-12-08 10:49:30,464 [ZeusDataLoader(train)] train epoch 15 done: time=44.52 energy=6752.21
2022-12-08 10:49:30,467 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 1.9763
Training Epoch: 14 [2048/50176]	Loss: 2.0671
Training Epoch: 14 [3072/50176]	Loss: 2.0828
Training Epoch: 14 [4096/50176]	Loss: 2.1721
Training Epoch: 14 [5120/50176]	Loss: 1.9223
Training Epoch: 14 [6144/50176]	Loss: 2.0553
Training Epoch: 14 [7168/50176]	Loss: 1.9431
Training Epoch: 14 [8192/50176]	Loss: 2.0432
Training Epoch: 14 [9216/50176]	Loss: 1.9666
Training Epoch: 14 [10240/50176]	Loss: 2.0218
Training Epoch: 14 [11264/50176]	Loss: 1.9296
Training Epoch: 14 [12288/50176]	Loss: 2.0425
Training Epoch: 14 [13312/50176]	Loss: 2.0224
Training Epoch: 14 [14336/50176]	Loss: 2.0125
Training Epoch: 14 [15360/50176]	Loss: 1.9734
Training Epoch: 14 [16384/50176]	Loss: 1.8918
Training Epoch: 14 [17408/50176]	Loss: 1.9840
Training Epoch: 14 [18432/50176]	Loss: 1.9681
Training Epoch: 14 [19456/50176]	Loss: 1.9356
Training Epoch: 14 [20480/50176]	Loss: 1.9806
Training Epoch: 14 [21504/50176]	Loss: 1.9476
Training Epoch: 14 [22528/50176]	Loss: 1.9554
Training Epoch: 14 [23552/50176]	Loss: 1.9510
Training Epoch: 14 [24576/50176]	Loss: 1.9961
Training Epoch: 14 [25600/50176]	Loss: 2.1307
Training Epoch: 14 [26624/50176]	Loss: 1.9637
Training Epoch: 14 [27648/50176]	Loss: 1.9023
Training Epoch: 14 [28672/50176]	Loss: 2.0678
Training Epoch: 14 [29696/50176]	Loss: 1.9949
Training Epoch: 14 [30720/50176]	Loss: 1.9468
Training Epoch: 14 [31744/50176]	Loss: 1.9445
Training Epoch: 14 [32768/50176]	Loss: 2.0630
Training Epoch: 14 [33792/50176]	Loss: 2.0018
Training Epoch: 14 [34816/50176]	Loss: 2.0106
Training Epoch: 14 [35840/50176]	Loss: 1.9670
Training Epoch: 14 [36864/50176]	Loss: 2.0666
Training Epoch: 14 [37888/50176]	Loss: 1.9199
Training Epoch: 14 [38912/50176]	Loss: 1.9691
Training Epoch: 14 [39936/50176]	Loss: 1.9724
Training Epoch: 14 [40960/50176]	Loss: 1.9413
Training Epoch: 14 [41984/50176]	Loss: 2.0461
Training Epoch: 14 [43008/50176]	Loss: 2.0222
Training Epoch: 14 [44032/50176]	Loss: 1.9737
Training Epoch: 14 [45056/50176]	Loss: 1.9766
Training Epoch: 14 [46080/50176]	Loss: 1.9802
Training Epoch: 14 [47104/50176]	Loss: 1.9634
Training Epoch: 14 [48128/50176]	Loss: 1.9943
Training Epoch: 14 [49152/50176]	Loss: 2.0125
Training Epoch: 14 [50176/50176]	Loss: 1.9976
2022-12-08 15:49:34.188 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:49:34,204 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.73 energy=515.25
2022-12-08 10:49:34,204 [ZeusDataLoader(train)] Up to epoch 15: time=823.80, energy=115244.08, cost=129704.57
2022-12-08 10:49:34,204 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:49:34,204 [ZeusDataLoader(train)] Expected next epoch: time=871.25, energy=122500.89, cost=137484.85
2022-12-08 10:49:34,205 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 0.0021, Accuracy: 0.4177
2022-12-08 10:49:34,390 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:49:34,391 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:49:34.410 [ZeusMonitor] Monitor started.
2022-12-08 15:49:34.410 [ZeusMonitor] Running indefinitely. 2022-12-08 15:49:34.410 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:49:34.410 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e16+gpu0.power.log
2022-12-08 10:50:18,692 [ZeusDataLoader(train)] train epoch 16 done: time=44.48 energy=6747.35
2022-12-08 10:50:18,696 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 1.9915
Training Epoch: 15 [2048/50176]	Loss: 1.8391
Training Epoch: 15 [3072/50176]	Loss: 1.8592
Training Epoch: 15 [4096/50176]	Loss: 1.9109
Training Epoch: 15 [5120/50176]	Loss: 1.8827
Training Epoch: 15 [6144/50176]	Loss: 1.9145
Training Epoch: 15 [7168/50176]	Loss: 1.8962
Training Epoch: 15 [8192/50176]	Loss: 1.9223
Training Epoch: 15 [9216/50176]	Loss: 1.8928
Training Epoch: 15 [10240/50176]	Loss: 1.9166
Training Epoch: 15 [11264/50176]	Loss: 1.8947
Training Epoch: 15 [12288/50176]	Loss: 2.0286
Training Epoch: 15 [13312/50176]	Loss: 1.8128
Training Epoch: 15 [14336/50176]	Loss: 1.8927
Training Epoch: 15 [15360/50176]	Loss: 1.9787
Training Epoch: 15 [16384/50176]	Loss: 1.9774
Training Epoch: 15 [17408/50176]	Loss: 1.9046
Training Epoch: 15 [18432/50176]	Loss: 1.9211
Training Epoch: 15 [19456/50176]	Loss: 1.8812
Training Epoch: 15 [20480/50176]	Loss: 1.8463
Training Epoch: 15 [21504/50176]	Loss: 1.8453
Training Epoch: 15 [22528/50176]	Loss: 1.9888
Training Epoch: 15 [23552/50176]	Loss: 1.9448
Training Epoch: 15 [24576/50176]	Loss: 1.8957
Training Epoch: 15 [25600/50176]	Loss: 1.9902
Training Epoch: 15 [26624/50176]	Loss: 1.9201
Training Epoch: 15 [27648/50176]	Loss: 1.9493
Training Epoch: 15 [28672/50176]	Loss: 1.7732
Training Epoch: 15 [29696/50176]	Loss: 1.9149
Training Epoch: 15 [30720/50176]	Loss: 1.8998
Training Epoch: 15 [31744/50176]	Loss: 1.9516
Training Epoch: 15 [32768/50176]	Loss: 1.9131
Training Epoch: 15 [33792/50176]	Loss: 1.8663
Training Epoch: 15 [34816/50176]	Loss: 1.9877
Training Epoch: 15 [35840/50176]	Loss: 1.9337
Training Epoch: 15 [36864/50176]	Loss: 1.8311
Training Epoch: 15 [37888/50176]	Loss: 1.9304
Training Epoch: 15 [38912/50176]	Loss: 1.8705
Training Epoch: 15 [39936/50176]	Loss: 1.8162
Training Epoch: 15 [40960/50176]	Loss: 1.9428
Training Epoch: 15 [41984/50176]	Loss: 1.9293
Training Epoch: 15 [43008/50176]	Loss: 1.9246
Training Epoch: 15 [44032/50176]	Loss: 1.8695
Training Epoch: 15 [45056/50176]	Loss: 1.8754
Training Epoch: 15 [46080/50176]	Loss: 1.9262
Training Epoch: 15 [47104/50176]	Loss: 1.8718
Training Epoch: 15 [48128/50176]	Loss: 1.9884
Training Epoch: 15 [49152/50176]	Loss: 1.8144
Training Epoch: 15 [50176/50176]	Loss: 1.8422
2022-12-08 15:50:22.492 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:50:22,539 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.83 energy=534.34
2022-12-08 10:50:22,540 [ZeusDataLoader(train)] Up to epoch 16: time=872.11, energy=122525.77, cost=137572.64
2022-12-08 10:50:22,540 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:50:22,540 [ZeusDataLoader(train)] Expected next epoch: time=919.56, energy=129782.58, cost=145352.92
2022-12-08 10:50:22,541 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0021, Accuracy: 0.4281
2022-12-08 10:50:22,686 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:50:22,686 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:50:22.690 [ZeusMonitor] Monitor started.
2022-12-08 15:50:22.690 [ZeusMonitor] Running indefinitely. 2022-12-08 15:50:22.690 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:50:22.690 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e17+gpu0.power.log
2022-12-08 10:51:07,310 [ZeusDataLoader(train)] train epoch 17 done: time=44.76 energy=6798.10
2022-12-08 10:51:07,315 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 1.8465
Training Epoch: 16 [2048/50176]	Loss: 1.7772
Training Epoch: 16 [3072/50176]	Loss: 1.8651
Training Epoch: 16 [4096/50176]	Loss: 1.8237
Training Epoch: 16 [5120/50176]	Loss: 1.8783
Training Epoch: 16 [6144/50176]	Loss: 1.7972
Training Epoch: 16 [7168/50176]	Loss: 1.8100
Training Epoch: 16 [8192/50176]	Loss: 1.7169
Training Epoch: 16 [9216/50176]	Loss: 1.8255
Training Epoch: 16 [10240/50176]	Loss: 1.7718
Training Epoch: 16 [11264/50176]	Loss: 1.9056
Training Epoch: 16 [12288/50176]	Loss: 1.8867
Training Epoch: 16 [13312/50176]	Loss: 1.8095
Training Epoch: 16 [14336/50176]	Loss: 1.8568
Training Epoch: 16 [15360/50176]	Loss: 1.9631
Training Epoch: 16 [16384/50176]	Loss: 1.8318
Training Epoch: 16 [17408/50176]	Loss: 1.8189
Training Epoch: 16 [18432/50176]	Loss: 1.9082
Training Epoch: 16 [19456/50176]	Loss: 1.9293
Training Epoch: 16 [20480/50176]	Loss: 1.7753
Training Epoch: 16 [21504/50176]	Loss: 1.8173
Training Epoch: 16 [22528/50176]	Loss: 1.8034
Training Epoch: 16 [23552/50176]	Loss: 1.8401
Training Epoch: 16 [24576/50176]	Loss: 1.8717
Training Epoch: 16 [25600/50176]	Loss: 1.8459
Training Epoch: 16 [26624/50176]	Loss: 1.7662
Training Epoch: 16 [27648/50176]	Loss: 1.9198
Training Epoch: 16 [28672/50176]	Loss: 1.8228
Training Epoch: 16 [29696/50176]	Loss: 1.8625
Training Epoch: 16 [30720/50176]	Loss: 1.7829
Training Epoch: 16 [31744/50176]	Loss: 1.8041
Training Epoch: 16 [32768/50176]	Loss: 1.8095
Training Epoch: 16 [33792/50176]	Loss: 1.8086
Training Epoch: 16 [34816/50176]	Loss: 1.7914
Training Epoch: 16 [35840/50176]	Loss: 1.9224
Training Epoch: 16 [36864/50176]	Loss: 1.8103
Training Epoch: 16 [37888/50176]	Loss: 1.6941
Training Epoch: 16 [38912/50176]	Loss: 1.8087
Training Epoch: 16 [39936/50176]	Loss: 1.9193
Training Epoch: 16 [40960/50176]	Loss: 1.8484
Training Epoch: 16 [41984/50176]	Loss: 1.8069
Training Epoch: 16 [43008/50176]	Loss: 1.8283
Training Epoch: 16 [44032/50176]	Loss: 1.8216
Training Epoch: 16 [45056/50176]	Loss: 1.8939
Training Epoch: 16 [46080/50176]	Loss: 1.8549
Training Epoch: 16 [47104/50176]	Loss: 1.9146
Training Epoch: 16 [48128/50176]	Loss: 1.8370
Training Epoch: 16 [49152/50176]	Loss: 1.8215
Training Epoch: 16 [50176/50176]	Loss: 1.7966
2022-12-08 15:51:11.067 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:51:11,114 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.79 energy=534.97
2022-12-08 10:51:11,114 [ZeusDataLoader(train)] Up to epoch 17: time=920.66, energy=129858.85, cost=145487.28
2022-12-08 10:51:11,114 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:51:11,114 [ZeusDataLoader(train)] Expected next epoch: time=968.11, energy=137115.65, cost=153267.56
2022-12-08 10:51:11,115 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 0.0020, Accuracy: 0.4505
2022-12-08 10:51:11,292 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:51:11,293 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:51:11.295 [ZeusMonitor] Monitor started.
2022-12-08 15:51:11.295 [ZeusMonitor] Running indefinitely. 2022-12-08 15:51:11.295 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:51:11.295 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e18+gpu0.power.log
2022-12-08 10:51:55,629 [ZeusDataLoader(train)] train epoch 18 done: time=44.51 energy=6762.37
2022-12-08 10:51:55,633 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 1.7773
Training Epoch: 17 [2048/50176]	Loss: 1.7933
Training Epoch: 17 [3072/50176]	Loss: 1.6585
Training Epoch: 17 [4096/50176]	Loss: 1.7269
Training Epoch: 17 [5120/50176]	Loss: 1.8973
Training Epoch: 17 [6144/50176]	Loss: 1.7972
Training Epoch: 17 [7168/50176]	Loss: 1.7924
Training Epoch: 17 [8192/50176]	Loss: 1.7344
Training Epoch: 17 [9216/50176]	Loss: 1.7193
Training Epoch: 17 [10240/50176]	Loss: 1.7494
Training Epoch: 17 [11264/50176]	Loss: 1.6926
Training Epoch: 17 [12288/50176]	Loss: 1.7268
Training Epoch: 17 [13312/50176]	Loss: 1.7905
Training Epoch: 17 [14336/50176]	Loss: 1.8314
Training Epoch: 17 [15360/50176]	Loss: 1.7290
Training Epoch: 17 [16384/50176]	Loss: 1.8460
Training Epoch: 17 [17408/50176]	Loss: 1.8421
Training Epoch: 17 [18432/50176]	Loss: 1.8363
Training Epoch: 17 [19456/50176]	Loss: 1.6793
Training Epoch: 17 [20480/50176]	Loss: 1.7602
Training Epoch: 17 [21504/50176]	Loss: 1.7952
Training Epoch: 17 [22528/50176]	Loss: 1.8643
Training Epoch: 17 [23552/50176]	Loss: 1.8311
Training Epoch: 17 [24576/50176]	Loss: 1.8145
Training Epoch: 17 [25600/50176]	Loss: 1.7977
Training Epoch: 17 [26624/50176]	Loss: 1.7977
Training Epoch: 17 [27648/50176]	Loss: 1.7636
Training Epoch: 17 [28672/50176]	Loss: 1.7794
Training Epoch: 17 [29696/50176]	Loss: 1.7981
Training Epoch: 17 [30720/50176]	Loss: 1.8277
Training Epoch: 17 [31744/50176]	Loss: 1.7395
Training Epoch: 17 [32768/50176]	Loss: 1.7358
Training Epoch: 17 [33792/50176]	Loss: 1.7874
Training Epoch: 17 [34816/50176]	Loss: 1.7763
Training Epoch: 17 [35840/50176]	Loss: 1.7289
Training Epoch: 17 [36864/50176]	Loss: 1.8427
Training Epoch: 17 [37888/50176]	Loss: 1.7109
Training Epoch: 17 [38912/50176]	Loss: 1.8548
Training Epoch: 17 [39936/50176]	Loss: 1.8095
Training Epoch: 17 [40960/50176]	Loss: 1.7372
Training Epoch: 17 [41984/50176]	Loss: 1.7858
Training Epoch: 17 [43008/50176]	Loss: 1.7743
Training Epoch: 17 [44032/50176]	Loss: 1.8167
Training Epoch: 17 [45056/50176]	Loss: 1.7618
Training Epoch: 17 [46080/50176]	Loss: 1.6964
Training Epoch: 17 [47104/50176]	Loss: 1.7013
Training Epoch: 17 [48128/50176]	Loss: 1.7830
Training Epoch: 17 [49152/50176]	Loss: 1.8177
Training Epoch: 17 [50176/50176]	Loss: 1.7595
2022-12-08 15:51:59.391 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:51:59,436 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.79 energy=532.26
2022-12-08 10:51:59,437 [ZeusDataLoader(train)] Up to epoch 18: time=968.96, energy=137153.47, cost=153360.88
2022-12-08 10:51:59,437 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:51:59,437 [ZeusDataLoader(train)] Expected next epoch: time=1016.41, energy=144410.28, cost=161141.15
2022-12-08 10:51:59,438 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 0.0019, Accuracy: 0.4633
2022-12-08 10:51:59,614 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:51:59,615 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:51:59.629 [ZeusMonitor] Monitor started.
2022-12-08 15:51:59.629 [ZeusMonitor] Running indefinitely. 2022-12-08 15:51:59.629 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:51:59.629 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e19+gpu0.power.log
2022-12-08 10:52:43,884 [ZeusDataLoader(train)] train epoch 19 done: time=44.44 energy=6740.54
2022-12-08 10:52:43,887 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 1.6891
Training Epoch: 18 [2048/50176]	Loss: 1.7990
Training Epoch: 18 [3072/50176]	Loss: 1.7542
Training Epoch: 18 [4096/50176]	Loss: 1.7336
Training Epoch: 18 [5120/50176]	Loss: 1.7459
Training Epoch: 18 [6144/50176]	Loss: 1.7481
Training Epoch: 18 [7168/50176]	Loss: 1.6610
Training Epoch: 18 [8192/50176]	Loss: 1.7460
Training Epoch: 18 [9216/50176]	Loss: 1.6988
Training Epoch: 18 [10240/50176]	Loss: 1.6920
Training Epoch: 18 [11264/50176]	Loss: 1.7324
Training Epoch: 18 [12288/50176]	Loss: 1.6741
Training Epoch: 18 [13312/50176]	Loss: 1.7072
Training Epoch: 18 [14336/50176]	Loss: 1.7216
Training Epoch: 18 [15360/50176]	Loss: 1.7623
Training Epoch: 18 [16384/50176]	Loss: 1.7387
Training Epoch: 18 [17408/50176]	Loss: 1.7040
Training Epoch: 18 [18432/50176]	Loss: 1.7398
Training Epoch: 18 [19456/50176]	Loss: 1.7223
Training Epoch: 18 [20480/50176]	Loss: 1.7063
Training Epoch: 18 [21504/50176]	Loss: 1.7497
Training Epoch: 18 [22528/50176]	Loss: 1.7795
Training Epoch: 18 [23552/50176]	Loss: 1.6780
Training Epoch: 18 [24576/50176]	Loss: 1.6984
Training Epoch: 18 [25600/50176]	Loss: 1.7086
Training Epoch: 18 [26624/50176]	Loss: 1.5479
Training Epoch: 18 [27648/50176]	Loss: 1.7038
Training Epoch: 18 [28672/50176]	Loss: 1.6811
Training Epoch: 18 [29696/50176]	Loss: 1.7348
Training Epoch: 18 [30720/50176]	Loss: 1.7596
Training Epoch: 18 [31744/50176]	Loss: 1.7618
Training Epoch: 18 [32768/50176]	Loss: 1.6753
Training Epoch: 18 [33792/50176]	Loss: 1.6867
Training Epoch: 18 [34816/50176]	Loss: 1.7069
Training Epoch: 18 [35840/50176]	Loss: 1.7531
Training Epoch: 18 [36864/50176]	Loss: 1.7079
Training Epoch: 18 [37888/50176]	Loss: 1.7139
Training Epoch: 18 [38912/50176]	Loss: 1.6879
Training Epoch: 18 [39936/50176]	Loss: 1.6988
Training Epoch: 18 [40960/50176]	Loss: 1.6799
Training Epoch: 18 [41984/50176]	Loss: 1.7017
Training Epoch: 18 [43008/50176]	Loss: 1.7165
Training Epoch: 18 [44032/50176]	Loss: 1.7785
Training Epoch: 18 [45056/50176]	Loss: 1.7613
Training Epoch: 18 [46080/50176]	Loss: 1.7208
Training Epoch: 18 [47104/50176]	Loss: 1.6709
Training Epoch: 18 [48128/50176]	Loss: 1.6712
Training Epoch: 18 [49152/50176]	Loss: 1.7037
Training Epoch: 18 [50176/50176]	Loss: 1.7186
2022-12-08 15:52:47.622 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:52:47,660 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.76 energy=522.86
2022-12-08 10:52:47,660 [ZeusDataLoader(train)] Up to epoch 19: time=1017.16, energy=144416.88, cost=161210.13
2022-12-08 10:52:47,660 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:52:47,660 [ZeusDataLoader(train)] Expected next epoch: time=1064.61, energy=151673.68, cost=168990.41
2022-12-08 10:52:47,661 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 0.0020, Accuracy: 0.4557
2022-12-08 10:52:47,857 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:52:47,858 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:52:47.860 [ZeusMonitor] Monitor started.
2022-12-08 15:52:47.860 [ZeusMonitor] Running indefinitely. 2022-12-08 15:52:47.860 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:52:47.860 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e20+gpu0.power.log
2022-12-08 10:53:32,189 [ZeusDataLoader(train)] train epoch 20 done: time=44.52 energy=6769.13
2022-12-08 10:53:32,192 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 1.6485
Training Epoch: 19 [2048/50176]	Loss: 1.6931
Training Epoch: 19 [3072/50176]	Loss: 1.6455
Training Epoch: 19 [4096/50176]	Loss: 1.6735
Training Epoch: 19 [5120/50176]	Loss: 1.6583
Training Epoch: 19 [6144/50176]	Loss: 1.6601
Training Epoch: 19 [7168/50176]	Loss: 1.5947
Training Epoch: 19 [8192/50176]	Loss: 1.5552
Training Epoch: 19 [9216/50176]	Loss: 1.6102
Training Epoch: 19 [10240/50176]	Loss: 1.6858
Training Epoch: 19 [11264/50176]	Loss: 1.7129
Training Epoch: 19 [12288/50176]	Loss: 1.6255
Training Epoch: 19 [13312/50176]	Loss: 1.6071
Training Epoch: 19 [14336/50176]	Loss: 1.6625
Training Epoch: 19 [15360/50176]	Loss: 1.6775
Training Epoch: 19 [16384/50176]	Loss: 1.6610
Training Epoch: 19 [17408/50176]	Loss: 1.6801
Training Epoch: 19 [18432/50176]	Loss: 1.5855
Training Epoch: 19 [19456/50176]	Loss: 1.5994
Training Epoch: 19 [20480/50176]	Loss: 1.6741
Training Epoch: 19 [21504/50176]	Loss: 1.6614
Training Epoch: 19 [22528/50176]	Loss: 1.7208
Training Epoch: 19 [23552/50176]	Loss: 1.7156
Training Epoch: 19 [24576/50176]	Loss: 1.5718
Training Epoch: 19 [25600/50176]	Loss: 1.6068
Training Epoch: 19 [26624/50176]	Loss: 1.6877
Training Epoch: 19 [27648/50176]	Loss: 1.5556
Training Epoch: 19 [28672/50176]	Loss: 1.6507
Training Epoch: 19 [29696/50176]	Loss: 1.7567
Training Epoch: 19 [30720/50176]	Loss: 1.6817
Training Epoch: 19 [31744/50176]	Loss: 1.6283
Training Epoch: 19 [32768/50176]	Loss: 1.7436
Training Epoch: 19 [33792/50176]	Loss: 1.6526
Training Epoch: 19 [34816/50176]	Loss: 1.6522
Training Epoch: 19 [35840/50176]	Loss: 1.6186
Training Epoch: 19 [36864/50176]	Loss: 1.6735
Training Epoch: 19 [37888/50176]	Loss: 1.5741
Training Epoch: 19 [38912/50176]	Loss: 1.6822
Training Epoch: 19 [39936/50176]	Loss: 1.6106
Training Epoch: 19 [40960/50176]	Loss: 1.6251
Training Epoch: 19 [41984/50176]	Loss: 1.6500
Training Epoch: 19 [43008/50176]	Loss: 1.6789
Training Epoch: 19 [44032/50176]	Loss: 1.6711
Training Epoch: 19 [45056/50176]	Loss: 1.7181
Training Epoch: 19 [46080/50176]	Loss: 1.6150
Training Epoch: 19 [47104/50176]	Loss: 1.6503
Training Epoch: 19 [48128/50176]	Loss: 1.6712
Training Epoch: 19 [49152/50176]	Loss: 1.7434
Training Epoch: 19 [50176/50176]	Loss: 1.6682
2022-12-08 15:53:35.957 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:53:35,984 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.78 energy=523.90
2022-12-08 10:53:35,984 [ZeusDataLoader(train)] Up to epoch 20: time=1065.46, energy=151709.91, cost=169083.09
2022-12-08 10:53:35,984 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:53:35,985 [ZeusDataLoader(train)] Expected next epoch: time=1112.91, energy=158966.71, cost=176863.36
2022-12-08 10:53:35,986 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 0.0020, Accuracy: 0.4578
2022-12-08 10:53:36,172 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:53:36,173 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:53:36.180 [ZeusMonitor] Monitor started.
2022-12-08 15:53:36.180 [ZeusMonitor] Running indefinitely. 2022-12-08 15:53:36.180 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:53:36.180 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e21+gpu0.power.log
2022-12-08 10:54:20,520 [ZeusDataLoader(train)] train epoch 21 done: time=44.53 energy=6757.70
2022-12-08 10:54:20,523 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 1.5979
Training Epoch: 20 [2048/50176]	Loss: 1.6128
Training Epoch: 20 [3072/50176]	Loss: 1.6256
Training Epoch: 20 [4096/50176]	Loss: 1.4947
Training Epoch: 20 [5120/50176]	Loss: 1.5621
Training Epoch: 20 [6144/50176]	Loss: 1.5682
Training Epoch: 20 [7168/50176]	Loss: 1.5938
Training Epoch: 20 [8192/50176]	Loss: 1.5820
Training Epoch: 20 [9216/50176]	Loss: 1.5580
Training Epoch: 20 [10240/50176]	Loss: 1.5526
Training Epoch: 20 [11264/50176]	Loss: 1.6039
Training Epoch: 20 [12288/50176]	Loss: 1.5466
Training Epoch: 20 [13312/50176]	Loss: 1.5181
Training Epoch: 20 [14336/50176]	Loss: 1.6399
Training Epoch: 20 [15360/50176]	Loss: 1.6195
Training Epoch: 20 [16384/50176]	Loss: 1.6529
Training Epoch: 20 [17408/50176]	Loss: 1.6510
Training Epoch: 20 [18432/50176]	Loss: 1.6651
Training Epoch: 20 [19456/50176]	Loss: 1.6589
Training Epoch: 20 [20480/50176]	Loss: 1.5430
Training Epoch: 20 [21504/50176]	Loss: 1.6964
Training Epoch: 20 [22528/50176]	Loss: 1.5971
Training Epoch: 20 [23552/50176]	Loss: 1.4947
Training Epoch: 20 [24576/50176]	Loss: 1.6736
Training Epoch: 20 [25600/50176]	Loss: 1.6773
Training Epoch: 20 [26624/50176]	Loss: 1.6263
Training Epoch: 20 [27648/50176]	Loss: 1.5685
Training Epoch: 20 [28672/50176]	Loss: 1.6095
Training Epoch: 20 [29696/50176]	Loss: 1.5312
Training Epoch: 20 [30720/50176]	Loss: 1.5656
Training Epoch: 20 [31744/50176]	Loss: 1.5719
Training Epoch: 20 [32768/50176]	Loss: 1.6175
Training Epoch: 20 [33792/50176]	Loss: 1.6193
Training Epoch: 20 [34816/50176]	Loss: 1.6413
Training Epoch: 20 [35840/50176]	Loss: 1.5822
Training Epoch: 20 [36864/50176]	Loss: 1.6351
Training Epoch: 20 [37888/50176]	Loss: 1.6010
Training Epoch: 20 [38912/50176]	Loss: 1.5909
Training Epoch: 20 [39936/50176]	Loss: 1.6186
Training Epoch: 20 [40960/50176]	Loss: 1.6761
Training Epoch: 20 [41984/50176]	Loss: 1.5321
Training Epoch: 20 [43008/50176]	Loss: 1.5835
Training Epoch: 20 [44032/50176]	Loss: 1.5077
Training Epoch: 20 [45056/50176]	Loss: 1.6165
Training Epoch: 20 [46080/50176]	Loss: 1.6126
Training Epoch: 20 [47104/50176]	Loss: 1.6216
Training Epoch: 20 [48128/50176]	Loss: 1.5941
Training Epoch: 20 [49152/50176]	Loss: 1.6035
Training Epoch: 20 [50176/50176]	Loss: 1.6237
2022-12-08 15:54:24.239 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:54:24,261 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.73 energy=514.24
2022-12-08 10:54:24,261 [ZeusDataLoader(train)] Up to epoch 21: time=1113.72, energy=158981.85, cost=176941.30
2022-12-08 10:54:24,261 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:54:24,261 [ZeusDataLoader(train)] Expected next epoch: time=1161.17, energy=166238.66, cost=184721.57
2022-12-08 10:54:24,262 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 0.0019, Accuracy: 0.4711
2022-12-08 10:54:24,410 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:54:24,411 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:54:24.414 [ZeusMonitor] Monitor started.
2022-12-08 15:54:24.415 [ZeusMonitor] Running indefinitely. 2022-12-08 15:54:24.415 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:54:24.415 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e22+gpu0.power.log
2022-12-08 10:55:08,995 [ZeusDataLoader(train)] train epoch 22 done: time=44.72 energy=6790.59
2022-12-08 10:55:08,999 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 1.5058
Training Epoch: 21 [2048/50176]	Loss: 1.4433
Training Epoch: 21 [3072/50176]	Loss: 1.5771
Training Epoch: 21 [4096/50176]	Loss: 1.5217
Training Epoch: 21 [5120/50176]	Loss: 1.5009
Training Epoch: 21 [6144/50176]	Loss: 1.4119
Training Epoch: 21 [7168/50176]	Loss: 1.4119
Training Epoch: 21 [8192/50176]	Loss: 1.5186
Training Epoch: 21 [9216/50176]	Loss: 1.5302
Training Epoch: 21 [10240/50176]	Loss: 1.5105
Training Epoch: 21 [11264/50176]	Loss: 1.5239
Training Epoch: 21 [12288/50176]	Loss: 1.5361
Training Epoch: 21 [13312/50176]	Loss: 1.5314
Training Epoch: 21 [14336/50176]	Loss: 1.5838
Training Epoch: 21 [15360/50176]	Loss: 1.4721
Training Epoch: 21 [16384/50176]	Loss: 1.5454
Training Epoch: 21 [17408/50176]	Loss: 1.5180
Training Epoch: 21 [18432/50176]	Loss: 1.4659
Training Epoch: 21 [19456/50176]	Loss: 1.5375
Training Epoch: 21 [20480/50176]	Loss: 1.4926
Training Epoch: 21 [21504/50176]	Loss: 1.5457
Training Epoch: 21 [22528/50176]	Loss: 1.5631
Training Epoch: 21 [23552/50176]	Loss: 1.6190
Training Epoch: 21 [24576/50176]	Loss: 1.5693
Training Epoch: 21 [25600/50176]	Loss: 1.5644
Training Epoch: 21 [26624/50176]	Loss: 1.6172
Training Epoch: 21 [27648/50176]	Loss: 1.5588
Training Epoch: 21 [28672/50176]	Loss: 1.5083
Training Epoch: 21 [29696/50176]	Loss: 1.6169
Training Epoch: 21 [30720/50176]	Loss: 1.4977
Training Epoch: 21 [31744/50176]	Loss: 1.5200
Training Epoch: 21 [32768/50176]	Loss: 1.5495
Training Epoch: 21 [33792/50176]	Loss: 1.5158
Training Epoch: 21 [34816/50176]	Loss: 1.5018
Training Epoch: 21 [35840/50176]	Loss: 1.5498
Training Epoch: 21 [36864/50176]	Loss: 1.4490
Training Epoch: 21 [37888/50176]	Loss: 1.6029
Training Epoch: 21 [38912/50176]	Loss: 1.5475
Training Epoch: 21 [39936/50176]	Loss: 1.5304
Training Epoch: 21 [40960/50176]	Loss: 1.4766
Training Epoch: 21 [41984/50176]	Loss: 1.4933
Training Epoch: 21 [43008/50176]	Loss: 1.6229
Training Epoch: 21 [44032/50176]	Loss: 1.5906
Training Epoch: 21 [45056/50176]	Loss: 1.6005
Training Epoch: 21 [46080/50176]	Loss: 1.5524
Training Epoch: 21 [47104/50176]	Loss: 1.5936
Training Epoch: 21 [48128/50176]	Loss: 1.5680
Training Epoch: 21 [49152/50176]	Loss: 1.6248
Training Epoch: 21 [50176/50176]	Loss: 1.6373
2022-12-08 15:55:12.687 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:55:12,703 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.70 energy=505.94
2022-12-08 10:55:12,703 [ZeusDataLoader(train)] Up to epoch 22: time=1162.14, energy=166278.38, cost=184826.33
2022-12-08 10:55:12,704 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:55:12,704 [ZeusDataLoader(train)] Expected next epoch: time=1209.59, energy=173535.18, cost=192606.60
2022-12-08 10:55:12,705 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0019, Accuracy: 0.4808
2022-12-08 10:55:12,884 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:55:12,885 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:55:12.887 [ZeusMonitor] Monitor started.
2022-12-08 15:55:12.887 [ZeusMonitor] Running indefinitely. 2022-12-08 15:55:12.887 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:55:12.887 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e23+gpu0.power.log
2022-12-08 10:55:57,357 [ZeusDataLoader(train)] train epoch 23 done: time=44.64 energy=6761.33
2022-12-08 10:55:57,361 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 1.5990
Training Epoch: 22 [2048/50176]	Loss: 1.5242
Training Epoch: 22 [3072/50176]	Loss: 1.5137
Training Epoch: 22 [4096/50176]	Loss: 1.3535
Training Epoch: 22 [5120/50176]	Loss: 1.4621
Training Epoch: 22 [6144/50176]	Loss: 1.4436
Training Epoch: 22 [7168/50176]	Loss: 1.5008
Training Epoch: 22 [8192/50176]	Loss: 1.5533
Training Epoch: 22 [9216/50176]	Loss: 1.4541
Training Epoch: 22 [10240/50176]	Loss: 1.3922
Training Epoch: 22 [11264/50176]	Loss: 1.5470
Training Epoch: 22 [12288/50176]	Loss: 1.6086
Training Epoch: 22 [13312/50176]	Loss: 1.4057
Training Epoch: 22 [14336/50176]	Loss: 1.4860
Training Epoch: 22 [15360/50176]	Loss: 1.4527
Training Epoch: 22 [16384/50176]	Loss: 1.4715
Training Epoch: 22 [17408/50176]	Loss: 1.4710
Training Epoch: 22 [18432/50176]	Loss: 1.4972
Training Epoch: 22 [19456/50176]	Loss: 1.5430
Training Epoch: 22 [20480/50176]	Loss: 1.5257
Training Epoch: 22 [21504/50176]	Loss: 1.5022
Training Epoch: 22 [22528/50176]	Loss: 1.5267
Training Epoch: 22 [23552/50176]	Loss: 1.5612
Training Epoch: 22 [24576/50176]	Loss: 1.5754
Training Epoch: 22 [25600/50176]	Loss: 1.5408
Training Epoch: 22 [26624/50176]	Loss: 1.5727
Training Epoch: 22 [27648/50176]	Loss: 1.4938
Training Epoch: 22 [28672/50176]	Loss: 1.5443
Training Epoch: 22 [29696/50176]	Loss: 1.5055
Training Epoch: 22 [30720/50176]	Loss: 1.4273
Training Epoch: 22 [31744/50176]	Loss: 1.5715
Training Epoch: 22 [32768/50176]	Loss: 1.5601
Training Epoch: 22 [33792/50176]	Loss: 1.5373
Training Epoch: 22 [34816/50176]	Loss: 1.5057
Training Epoch: 22 [35840/50176]	Loss: 1.5591
Training Epoch: 22 [36864/50176]	Loss: 1.5172
Training Epoch: 22 [37888/50176]	Loss: 1.5356
Training Epoch: 22 [38912/50176]	Loss: 1.4572
Training Epoch: 22 [39936/50176]	Loss: 1.4392
Training Epoch: 22 [40960/50176]	Loss: 1.4691
Training Epoch: 22 [41984/50176]	Loss: 1.5884
Training Epoch: 22 [43008/50176]	Loss: 1.4899
Training Epoch: 22 [44032/50176]	Loss: 1.4005
Training Epoch: 22 [45056/50176]	Loss: 1.5275
Training Epoch: 22 [46080/50176]	Loss: 1.4187
Training Epoch: 22 [47104/50176]	Loss: 1.4633
Training Epoch: 22 [48128/50176]	Loss: 1.6477
Training Epoch: 22 [49152/50176]	Loss: 1.6024
Training Epoch: 22 [50176/50176]	Loss: 1.3305
2022-12-08 15:56:01.040 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:56:01,056 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.69 energy=519.35
2022-12-08 10:56:01,057 [ZeusDataLoader(train)] Up to epoch 23: time=1210.47, energy=173559.05, cost=192695.54
2022-12-08 10:56:01,057 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:56:01,057 [ZeusDataLoader(train)] Expected next epoch: time=1257.92, energy=180815.86, cost=200475.82
2022-12-08 10:56:01,058 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 0.0018, Accuracy: 0.4971
2022-12-08 10:56:01,240 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:56:01,241 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:56:01.243 [ZeusMonitor] Monitor started.
2022-12-08 15:56:01.243 [ZeusMonitor] Running indefinitely. 2022-12-08 15:56:01.243 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:56:01.243 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e24+gpu0.power.log
2022-12-08 10:56:45,508 [ZeusDataLoader(train)] train epoch 24 done: time=44.44 energy=6753.35
2022-12-08 10:56:45,511 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 1.4682
Training Epoch: 23 [2048/50176]	Loss: 1.3382
Training Epoch: 23 [3072/50176]	Loss: 1.3733
Training Epoch: 23 [4096/50176]	Loss: 1.4732
Training Epoch: 23 [5120/50176]	Loss: 1.4017
Training Epoch: 23 [6144/50176]	Loss: 1.4212
Training Epoch: 23 [7168/50176]	Loss: 1.5004
Training Epoch: 23 [8192/50176]	Loss: 1.4194
Training Epoch: 23 [9216/50176]	Loss: 1.4102
Training Epoch: 23 [10240/50176]	Loss: 1.3562
Training Epoch: 23 [11264/50176]	Loss: 1.4254
Training Epoch: 23 [12288/50176]	Loss: 1.3538
Training Epoch: 23 [13312/50176]	Loss: 1.4835
Training Epoch: 23 [14336/50176]	Loss: 1.3623
Training Epoch: 23 [15360/50176]	Loss: 1.3805
Training Epoch: 23 [16384/50176]	Loss: 1.3940
Training Epoch: 23 [17408/50176]	Loss: 1.4734
Training Epoch: 23 [18432/50176]	Loss: 1.4041
Training Epoch: 23 [19456/50176]	Loss: 1.4333
Training Epoch: 23 [20480/50176]	Loss: 1.4167
Training Epoch: 23 [21504/50176]	Loss: 1.4620
Training Epoch: 23 [22528/50176]	Loss: 1.4475
Training Epoch: 23 [23552/50176]	Loss: 1.3990
Training Epoch: 23 [24576/50176]	Loss: 1.4338
Training Epoch: 23 [25600/50176]	Loss: 1.4452
Training Epoch: 23 [26624/50176]	Loss: 1.5029
Training Epoch: 23 [27648/50176]	Loss: 1.4408
Training Epoch: 23 [28672/50176]	Loss: 1.4316
Training Epoch: 23 [29696/50176]	Loss: 1.4471
Training Epoch: 23 [30720/50176]	Loss: 1.4783
Training Epoch: 23 [31744/50176]	Loss: 1.5002
Training Epoch: 23 [32768/50176]	Loss: 1.5070
Training Epoch: 23 [33792/50176]	Loss: 1.4424
Training Epoch: 23 [34816/50176]	Loss: 1.5055
Training Epoch: 23 [35840/50176]	Loss: 1.4403
Training Epoch: 23 [36864/50176]	Loss: 1.4132
Training Epoch: 23 [37888/50176]	Loss: 1.4237
Training Epoch: 23 [38912/50176]	Loss: 1.4836
Training Epoch: 23 [39936/50176]	Loss: 1.4820
Training Epoch: 23 [40960/50176]	Loss: 1.5108
Training Epoch: 23 [41984/50176]	Loss: 1.4854
Training Epoch: 23 [43008/50176]	Loss: 1.4587
Training Epoch: 23 [44032/50176]	Loss: 1.4227
Training Epoch: 23 [45056/50176]	Loss: 1.4760
Training Epoch: 23 [46080/50176]	Loss: 1.4855
Training Epoch: 23 [47104/50176]	Loss: 1.4816
Training Epoch: 23 [48128/50176]	Loss: 1.4383
Training Epoch: 23 [49152/50176]	Loss: 1.4986
Training Epoch: 23 [50176/50176]	Loss: 1.4125
2022-12-08 15:56:49.264 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:56:49,306 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.79 energy=519.36
2022-12-08 10:56:49,306 [ZeusDataLoader(train)] Up to epoch 24: time=1258.70, energy=180831.76, cost=200551.75
2022-12-08 10:56:49,306 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:56:49,306 [ZeusDataLoader(train)] Expected next epoch: time=1306.15, energy=188088.57, cost=208332.02
2022-12-08 10:56:49,307 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 0.0018, Accuracy: 0.4996
2022-12-08 10:56:49,458 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:56:49,459 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:56:49.463 [ZeusMonitor] Monitor started.
2022-12-08 15:56:49.463 [ZeusMonitor] Running indefinitely. 2022-12-08 15:56:49.463 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:56:49.463 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e25+gpu0.power.log
2022-12-08 10:57:33,862 [ZeusDataLoader(train)] train epoch 25 done: time=44.55 energy=6760.95
2022-12-08 10:57:33,865 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 1.3213
Training Epoch: 24 [2048/50176]	Loss: 1.2791
Training Epoch: 24 [3072/50176]	Loss: 1.3771
Training Epoch: 24 [4096/50176]	Loss: 1.3003
Training Epoch: 24 [5120/50176]	Loss: 1.3670
Training Epoch: 24 [6144/50176]	Loss: 1.3699
Training Epoch: 24 [7168/50176]	Loss: 1.4368
Training Epoch: 24 [8192/50176]	Loss: 1.3872
Training Epoch: 24 [9216/50176]	Loss: 1.4527
Training Epoch: 24 [10240/50176]	Loss: 1.4123
Training Epoch: 24 [11264/50176]	Loss: 1.3786
Training Epoch: 24 [12288/50176]	Loss: 1.3993
Training Epoch: 24 [13312/50176]	Loss: 1.4498
Training Epoch: 24 [14336/50176]	Loss: 1.4414
Training Epoch: 24 [15360/50176]	Loss: 1.3157
Training Epoch: 24 [16384/50176]	Loss: 1.3203
Training Epoch: 24 [17408/50176]	Loss: 1.4490
Training Epoch: 24 [18432/50176]	Loss: 1.4903
Training Epoch: 24 [19456/50176]	Loss: 1.3870
Training Epoch: 24 [20480/50176]	Loss: 1.4142
Training Epoch: 24 [21504/50176]	Loss: 1.4352
Training Epoch: 24 [22528/50176]	Loss: 1.3693
Training Epoch: 24 [23552/50176]	Loss: 1.3980
Training Epoch: 24 [24576/50176]	Loss: 1.3052
Training Epoch: 24 [25600/50176]	Loss: 1.4084
Training Epoch: 24 [26624/50176]	Loss: 1.3390
Training Epoch: 24 [27648/50176]	Loss: 1.4705
Training Epoch: 24 [28672/50176]	Loss: 1.3980
Training Epoch: 24 [29696/50176]	Loss: 1.3339
Training Epoch: 24 [30720/50176]	Loss: 1.3798
Training Epoch: 24 [31744/50176]	Loss: 1.4674
Training Epoch: 24 [32768/50176]	Loss: 1.4003
Training Epoch: 24 [33792/50176]	Loss: 1.3613
Training Epoch: 24 [34816/50176]	Loss: 1.4663
Training Epoch: 24 [35840/50176]	Loss: 1.4859
Training Epoch: 24 [36864/50176]	Loss: 1.4644
Training Epoch: 24 [37888/50176]	Loss: 1.4058
Training Epoch: 24 [38912/50176]	Loss: 1.4095
Training Epoch: 24 [39936/50176]	Loss: 1.3404
Training Epoch: 24 [40960/50176]	Loss: 1.3881
Training Epoch: 24 [41984/50176]	Loss: 1.4865
Training Epoch: 24 [43008/50176]	Loss: 1.5008
Training Epoch: 24 [44032/50176]	Loss: 1.3280
Training Epoch: 24 [45056/50176]	Loss: 1.3576
Training Epoch: 24 [46080/50176]	Loss: 1.4298
Training Epoch: 24 [47104/50176]	Loss: 1.5206
Training Epoch: 24 [48128/50176]	Loss: 1.5560
Training Epoch: 24 [49152/50176]	Loss: 1.3932
Training Epoch: 24 [50176/50176]	Loss: 1.4027
2022-12-08 15:57:37.651 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:57:37,693 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.82 energy=539.80
2022-12-08 10:57:37,694 [ZeusDataLoader(train)] Up to epoch 25: time=1307.06, energy=188132.51, cost=208434.08
2022-12-08 10:57:37,694 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:57:37,694 [ZeusDataLoader(train)] Expected next epoch: time=1354.51, energy=195389.32, cost=216214.35
2022-12-08 10:57:37,695 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 0.0019, Accuracy: 0.4952
2022-12-08 10:57:37,876 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:57:37,877 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:57:37.879 [ZeusMonitor] Monitor started.
2022-12-08 15:57:37.879 [ZeusMonitor] Running indefinitely. 2022-12-08 15:57:37.879 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:57:37.879 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e26+gpu0.power.log
2022-12-08 10:58:22,198 [ZeusDataLoader(train)] train epoch 26 done: time=44.49 energy=6762.28
2022-12-08 10:58:22,201 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 1.3470
Training Epoch: 25 [2048/50176]	Loss: 1.3274
Training Epoch: 25 [3072/50176]	Loss: 1.3229
Training Epoch: 25 [4096/50176]	Loss: 1.3282
Training Epoch: 25 [5120/50176]	Loss: 1.3275
Training Epoch: 25 [6144/50176]	Loss: 1.3598
Training Epoch: 25 [7168/50176]	Loss: 1.3345
Training Epoch: 25 [8192/50176]	Loss: 1.4080
Training Epoch: 25 [9216/50176]	Loss: 1.4443
Training Epoch: 25 [10240/50176]	Loss: 1.3260
Training Epoch: 25 [11264/50176]	Loss: 1.3839
Training Epoch: 25 [12288/50176]	Loss: 1.3373
Training Epoch: 25 [13312/50176]	Loss: 1.3215
Training Epoch: 25 [14336/50176]	Loss: 1.3432
Training Epoch: 25 [15360/50176]	Loss: 1.3755
Training Epoch: 25 [16384/50176]	Loss: 1.3948
Training Epoch: 25 [17408/50176]	Loss: 1.3343
Training Epoch: 25 [18432/50176]	Loss: 1.3532
Training Epoch: 25 [19456/50176]	Loss: 1.2505
Training Epoch: 25 [20480/50176]	Loss: 1.3351
Training Epoch: 25 [21504/50176]	Loss: 1.3140
Training Epoch: 25 [22528/50176]	Loss: 1.4173
Training Epoch: 25 [23552/50176]	Loss: 1.3513
Training Epoch: 25 [24576/50176]	Loss: 1.2599
Training Epoch: 25 [25600/50176]	Loss: 1.2787
Training Epoch: 25 [26624/50176]	Loss: 1.4162
Training Epoch: 25 [27648/50176]	Loss: 1.3688
Training Epoch: 25 [28672/50176]	Loss: 1.3989
Training Epoch: 25 [29696/50176]	Loss: 1.3631
Training Epoch: 25 [30720/50176]	Loss: 1.4343
Training Epoch: 25 [31744/50176]	Loss: 1.3920
Training Epoch: 25 [32768/50176]	Loss: 1.4488
Training Epoch: 25 [33792/50176]	Loss: 1.3052
Training Epoch: 25 [34816/50176]	Loss: 1.3814
Training Epoch: 25 [35840/50176]	Loss: 1.3726
Training Epoch: 25 [36864/50176]	Loss: 1.3498
Training Epoch: 25 [37888/50176]	Loss: 1.3237
Training Epoch: 25 [38912/50176]	Loss: 1.3085
Training Epoch: 25 [39936/50176]	Loss: 1.2860
Training Epoch: 25 [40960/50176]	Loss: 1.3390
Training Epoch: 25 [41984/50176]	Loss: 1.3493
Training Epoch: 25 [43008/50176]	Loss: 1.4318
Training Epoch: 25 [44032/50176]	Loss: 1.4214
Training Epoch: 25 [45056/50176]	Loss: 1.4203
Training Epoch: 25 [46080/50176]	Loss: 1.3868
Training Epoch: 25 [47104/50176]	Loss: 1.3778
Training Epoch: 25 [48128/50176]	Loss: 1.3764
Training Epoch: 25 [49152/50176]	Loss: 1.3251
Training Epoch: 25 [50176/50176]	Loss: 1.4330
2022-12-08 15:58:25.947 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:58:25,988 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.78 energy=519.71
2022-12-08 10:58:25,989 [ZeusDataLoader(train)] Up to epoch 26: time=1355.33, energy=195414.51, cost=216298.97
2022-12-08 10:58:25,989 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:58:25,989 [ZeusDataLoader(train)] Expected next epoch: time=1402.78, energy=202671.32, cost=224079.24
2022-12-08 10:58:25,990 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 0.0018, Accuracy: 0.5042
2022-12-08 10:58:26,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:58:26,139 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:58:26.143 [ZeusMonitor] Monitor started.
2022-12-08 15:58:26.143 [ZeusMonitor] Running indefinitely. 2022-12-08 15:58:26.143 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:58:26.143 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e27+gpu0.power.log
2022-12-08 10:59:10,492 [ZeusDataLoader(train)] train epoch 27 done: time=44.49 energy=6761.80
2022-12-08 10:59:10,495 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 1.3156
Training Epoch: 26 [2048/50176]	Loss: 1.2703
Training Epoch: 26 [3072/50176]	Loss: 1.2765
Training Epoch: 26 [4096/50176]	Loss: 1.2479
Training Epoch: 26 [5120/50176]	Loss: 1.2369
Training Epoch: 26 [6144/50176]	Loss: 1.3000
Training Epoch: 26 [7168/50176]	Loss: 1.2617
Training Epoch: 26 [8192/50176]	Loss: 1.1924
Training Epoch: 26 [9216/50176]	Loss: 1.1934
Training Epoch: 26 [10240/50176]	Loss: 1.3515
Training Epoch: 26 [11264/50176]	Loss: 1.3274
Training Epoch: 26 [12288/50176]	Loss: 1.2772
Training Epoch: 26 [13312/50176]	Loss: 1.1807
Training Epoch: 26 [14336/50176]	Loss: 1.3089
Training Epoch: 26 [15360/50176]	Loss: 1.2894
Training Epoch: 26 [16384/50176]	Loss: 1.2332
Training Epoch: 26 [17408/50176]	Loss: 1.3058
Training Epoch: 26 [18432/50176]	Loss: 1.2695
Training Epoch: 26 [19456/50176]	Loss: 1.2946
Training Epoch: 26 [20480/50176]	Loss: 1.2997
Training Epoch: 26 [21504/50176]	Loss: 1.3228
Training Epoch: 26 [22528/50176]	Loss: 1.2546
Training Epoch: 26 [23552/50176]	Loss: 1.3565
Training Epoch: 26 [24576/50176]	Loss: 1.3116
Training Epoch: 26 [25600/50176]	Loss: 1.3355
Training Epoch: 26 [26624/50176]	Loss: 1.2685
Training Epoch: 26 [27648/50176]	Loss: 1.3100
Training Epoch: 26 [28672/50176]	Loss: 1.2976
Training Epoch: 26 [29696/50176]	Loss: 1.2711
Training Epoch: 26 [30720/50176]	Loss: 1.4283
Training Epoch: 26 [31744/50176]	Loss: 1.3302
Training Epoch: 26 [32768/50176]	Loss: 1.4102
Training Epoch: 26 [33792/50176]	Loss: 1.4184
Training Epoch: 26 [34816/50176]	Loss: 1.3456
Training Epoch: 26 [35840/50176]	Loss: 1.2787
Training Epoch: 26 [36864/50176]	Loss: 1.3173
Training Epoch: 26 [37888/50176]	Loss: 1.3485
Training Epoch: 26 [38912/50176]	Loss: 1.2884
Training Epoch: 26 [39936/50176]	Loss: 1.4192
Training Epoch: 26 [40960/50176]	Loss: 1.3658
Training Epoch: 26 [41984/50176]	Loss: 1.4300
Training Epoch: 26 [43008/50176]	Loss: 1.3676
Training Epoch: 26 [44032/50176]	Loss: 1.3081
Training Epoch: 26 [45056/50176]	Loss: 1.3112
Training Epoch: 26 [46080/50176]	Loss: 1.3982
Training Epoch: 26 [47104/50176]	Loss: 1.3404
Training Epoch: 26 [48128/50176]	Loss: 1.3848
Training Epoch: 26 [49152/50176]	Loss: 1.2634
Training Epoch: 26 [50176/50176]	Loss: 1.3408
2022-12-08 15:59:14.242 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 10:59:14,251 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.75 energy=521.13
2022-12-08 10:59:14,252 [ZeusDataLoader(train)] Up to epoch 27: time=1403.57, energy=202697.44, cost=224161.50
2022-12-08 10:59:14,252 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 10:59:14,252 [ZeusDataLoader(train)] Expected next epoch: time=1451.02, energy=209954.25, cost=231941.77
2022-12-08 10:59:14,253 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 0.0018, Accuracy: 0.5168
2022-12-08 10:59:14,436 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 10:59:14,437 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 15:59:14.439 [ZeusMonitor] Monitor started.
2022-12-08 15:59:14.439 [ZeusMonitor] Running indefinitely. 2022-12-08 15:59:14.439 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 15:59:14.439 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e28+gpu0.power.log
2022-12-08 10:59:58,882 [ZeusDataLoader(train)] train epoch 28 done: time=44.62 energy=6765.69
2022-12-08 10:59:58,886 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 1.2812
Training Epoch: 27 [2048/50176]	Loss: 1.2556
Training Epoch: 27 [3072/50176]	Loss: 1.2169
Training Epoch: 27 [4096/50176]	Loss: 1.2932
Training Epoch: 27 [5120/50176]	Loss: 1.2138
Training Epoch: 27 [6144/50176]	Loss: 1.2558
Training Epoch: 27 [7168/50176]	Loss: 1.1922
Training Epoch: 27 [8192/50176]	Loss: 1.2559
Training Epoch: 27 [9216/50176]	Loss: 1.2484
Training Epoch: 27 [10240/50176]	Loss: 1.2827
Training Epoch: 27 [11264/50176]	Loss: 1.2476
Training Epoch: 27 [12288/50176]	Loss: 1.2587
Training Epoch: 27 [13312/50176]	Loss: 1.2298
Training Epoch: 27 [14336/50176]	Loss: 1.2264
Training Epoch: 27 [15360/50176]	Loss: 1.2647
Training Epoch: 27 [16384/50176]	Loss: 1.2965
Training Epoch: 27 [17408/50176]	Loss: 1.2585
Training Epoch: 27 [18432/50176]	Loss: 1.3291
Training Epoch: 27 [19456/50176]	Loss: 1.3234
Training Epoch: 27 [20480/50176]	Loss: 1.1902
Training Epoch: 27 [21504/50176]	Loss: 1.3220
Training Epoch: 27 [22528/50176]	Loss: 1.2415
Training Epoch: 27 [23552/50176]	Loss: 1.2258
Training Epoch: 27 [24576/50176]	Loss: 1.2098
Training Epoch: 27 [25600/50176]	Loss: 1.2369
Training Epoch: 27 [26624/50176]	Loss: 1.3618
Training Epoch: 27 [27648/50176]	Loss: 1.3237
Training Epoch: 27 [28672/50176]	Loss: 1.3259
Training Epoch: 27 [29696/50176]	Loss: 1.2836
Training Epoch: 27 [30720/50176]	Loss: 1.2675
Training Epoch: 27 [31744/50176]	Loss: 1.3129
Training Epoch: 27 [32768/50176]	Loss: 1.3035
Training Epoch: 27 [33792/50176]	Loss: 1.2105
Training Epoch: 27 [34816/50176]	Loss: 1.3458
Training Epoch: 27 [35840/50176]	Loss: 1.3198
Training Epoch: 27 [36864/50176]	Loss: 1.2676
Training Epoch: 27 [37888/50176]	Loss: 1.2591
Training Epoch: 27 [38912/50176]	Loss: 1.2818
Training Epoch: 27 [39936/50176]	Loss: 1.3068
Training Epoch: 27 [40960/50176]	Loss: 1.2813
Training Epoch: 27 [41984/50176]	Loss: 1.2422
Training Epoch: 27 [43008/50176]	Loss: 1.2691
Training Epoch: 27 [44032/50176]	Loss: 1.3366
Training Epoch: 27 [45056/50176]	Loss: 1.1838
Training Epoch: 27 [46080/50176]	Loss: 1.2711
Training Epoch: 27 [47104/50176]	Loss: 1.3916
Training Epoch: 27 [48128/50176]	Loss: 1.2820
Training Epoch: 27 [49152/50176]	Loss: 1.3702
Training Epoch: 27 [50176/50176]	Loss: 1.3905
2022-12-08 16:00:02.671 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:00:02,684 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.79 energy=525.42
2022-12-08 11:00:02,685 [ZeusDataLoader(train)] Up to epoch 28: time=1451.98, energy=209988.55, cost=232042.94
2022-12-08 11:00:02,685 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:00:02,685 [ZeusDataLoader(train)] Expected next epoch: time=1499.43, energy=217245.36, cost=239823.21
2022-12-08 11:00:02,686 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0017, Accuracy: 0.5229
2022-12-08 11:00:02,871 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:00:02,872 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:00:02.882 [ZeusMonitor] Monitor started.
2022-12-08 16:00:02.882 [ZeusMonitor] Running indefinitely. 2022-12-08 16:00:02.882 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:00:02.882 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e29+gpu0.power.log
2022-12-08 11:00:47,251 [ZeusDataLoader(train)] train epoch 29 done: time=44.56 energy=6754.73
2022-12-08 11:00:47,255 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 1.1704
Training Epoch: 28 [2048/50176]	Loss: 1.2277
Training Epoch: 28 [3072/50176]	Loss: 1.1549
Training Epoch: 28 [4096/50176]	Loss: 1.2452
Training Epoch: 28 [5120/50176]	Loss: 1.1583
Training Epoch: 28 [6144/50176]	Loss: 1.1753
Training Epoch: 28 [7168/50176]	Loss: 1.1827
Training Epoch: 28 [8192/50176]	Loss: 1.1740
Training Epoch: 28 [9216/50176]	Loss: 1.2341
Training Epoch: 28 [10240/50176]	Loss: 1.2351
Training Epoch: 28 [11264/50176]	Loss: 1.1347
Training Epoch: 28 [12288/50176]	Loss: 1.2556
Training Epoch: 28 [13312/50176]	Loss: 1.2229
Training Epoch: 28 [14336/50176]	Loss: 1.2650
Training Epoch: 28 [15360/50176]	Loss: 1.2159
Training Epoch: 28 [16384/50176]	Loss: 1.2730
Training Epoch: 28 [17408/50176]	Loss: 1.2776
Training Epoch: 28 [18432/50176]	Loss: 1.1397
Training Epoch: 28 [19456/50176]	Loss: 1.2639
Training Epoch: 28 [20480/50176]	Loss: 1.1492
Training Epoch: 28 [21504/50176]	Loss: 1.2670
Training Epoch: 28 [22528/50176]	Loss: 1.3126
Training Epoch: 28 [23552/50176]	Loss: 1.2820
Training Epoch: 28 [24576/50176]	Loss: 1.1501
Training Epoch: 28 [25600/50176]	Loss: 1.1778
Training Epoch: 28 [26624/50176]	Loss: 1.2026
Training Epoch: 28 [27648/50176]	Loss: 1.3265
Training Epoch: 28 [28672/50176]	Loss: 1.2636
Training Epoch: 28 [29696/50176]	Loss: 1.2004
Training Epoch: 28 [30720/50176]	Loss: 1.2102
Training Epoch: 28 [31744/50176]	Loss: 1.2951
Training Epoch: 28 [32768/50176]	Loss: 1.2297
Training Epoch: 28 [33792/50176]	Loss: 1.1886
Training Epoch: 28 [34816/50176]	Loss: 1.2407
Training Epoch: 28 [35840/50176]	Loss: 1.2091
Training Epoch: 28 [36864/50176]	Loss: 1.2683
Training Epoch: 28 [37888/50176]	Loss: 1.2636
Training Epoch: 28 [38912/50176]	Loss: 1.2761
Training Epoch: 28 [39936/50176]	Loss: 1.2931
Training Epoch: 28 [40960/50176]	Loss: 1.3040
Training Epoch: 28 [41984/50176]	Loss: 1.2693
Training Epoch: 28 [43008/50176]	Loss: 1.2388
Training Epoch: 28 [44032/50176]	Loss: 1.2041
Training Epoch: 28 [45056/50176]	Loss: 1.3458
Training Epoch: 28 [46080/50176]	Loss: 1.2715
Training Epoch: 28 [47104/50176]	Loss: 1.2863
Training Epoch: 28 [48128/50176]	Loss: 1.2678
Training Epoch: 28 [49152/50176]	Loss: 1.2623
Training Epoch: 28 [50176/50176]	Loss: 1.2354
2022-12-08 16:00:51.249 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:00:51,265 [ZeusDataLoader(eval)] eval epoch 29 done: time=4.00 energy=525.87
2022-12-08 11:00:51,266 [ZeusDataLoader(train)] Up to epoch 29: time=1500.54, energy=217269.15, cost=239931.69
2022-12-08 11:00:51,266 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:00:51,266 [ZeusDataLoader(train)] Expected next epoch: time=1547.99, energy=224525.96, cost=247711.96
2022-12-08 11:00:51,268 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0017, Accuracy: 0.5259
2022-12-08 11:00:51,504 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:00:51,505 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:00:51.507 [ZeusMonitor] Monitor started.
2022-12-08 16:00:51.507 [ZeusMonitor] Running indefinitely. 2022-12-08 16:00:51.507 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:00:51.507 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e30+gpu0.power.log
2022-12-08 11:01:36,284 [ZeusDataLoader(train)] train epoch 30 done: time=45.01 energy=6789.07
2022-12-08 11:01:36,287 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 1.1857
Training Epoch: 29 [2048/50176]	Loss: 1.1131
Training Epoch: 29 [3072/50176]	Loss: 1.1985
Training Epoch: 29 [4096/50176]	Loss: 1.1997
Training Epoch: 29 [5120/50176]	Loss: 1.2050
Training Epoch: 29 [6144/50176]	Loss: 1.2038
Training Epoch: 29 [7168/50176]	Loss: 1.1981
Training Epoch: 29 [8192/50176]	Loss: 1.1678
Training Epoch: 29 [9216/50176]	Loss: 1.1830
Training Epoch: 29 [10240/50176]	Loss: 1.1535
Training Epoch: 29 [11264/50176]	Loss: 1.2050
Training Epoch: 29 [12288/50176]	Loss: 1.2031
Training Epoch: 29 [13312/50176]	Loss: 1.1062
Training Epoch: 29 [14336/50176]	Loss: 1.1301
Training Epoch: 29 [15360/50176]	Loss: 1.2903
Training Epoch: 29 [16384/50176]	Loss: 1.1468
Training Epoch: 29 [17408/50176]	Loss: 1.1597
Training Epoch: 29 [18432/50176]	Loss: 1.2062
Training Epoch: 29 [19456/50176]	Loss: 1.2185
Training Epoch: 29 [20480/50176]	Loss: 1.1627
Training Epoch: 29 [21504/50176]	Loss: 1.2361
Training Epoch: 29 [22528/50176]	Loss: 1.1245
Training Epoch: 29 [23552/50176]	Loss: 1.2095
Training Epoch: 29 [24576/50176]	Loss: 1.1794
Training Epoch: 29 [25600/50176]	Loss: 1.1444
Training Epoch: 29 [26624/50176]	Loss: 1.1533
Training Epoch: 29 [27648/50176]	Loss: 1.2318
Training Epoch: 29 [28672/50176]	Loss: 1.1392
Training Epoch: 29 [29696/50176]	Loss: 1.0955
Training Epoch: 29 [30720/50176]	Loss: 1.2173
Training Epoch: 29 [31744/50176]	Loss: 1.2682
Training Epoch: 29 [32768/50176]	Loss: 1.1948
Training Epoch: 29 [33792/50176]	Loss: 1.1441
Training Epoch: 29 [34816/50176]	Loss: 1.2408
Training Epoch: 29 [35840/50176]	Loss: 1.1008
Training Epoch: 29 [36864/50176]	Loss: 1.1786
Training Epoch: 29 [37888/50176]	Loss: 1.1346
Training Epoch: 29 [38912/50176]	Loss: 1.2329
Training Epoch: 29 [39936/50176]	Loss: 1.2670
Training Epoch: 29 [40960/50176]	Loss: 1.2186
Training Epoch: 29 [41984/50176]	Loss: 1.1857
Training Epoch: 29 [43008/50176]	Loss: 1.2297
Training Epoch: 29 [44032/50176]	Loss: 1.1606
Training Epoch: 29 [45056/50176]	Loss: 1.2023
Training Epoch: 29 [46080/50176]	Loss: 1.2282
Training Epoch: 29 [47104/50176]	Loss: 1.1836
Training Epoch: 29 [48128/50176]	Loss: 1.2411
Training Epoch: 29 [49152/50176]	Loss: 1.2410
Training Epoch: 29 [50176/50176]	Loss: 1.3450
2022-12-08 16:01:39.991 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:01:40,030 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.73 energy=521.56
2022-12-08 11:01:40,030 [ZeusDataLoader(train)] Up to epoch 30: time=1549.28, energy=224579.78, cost=247851.75
2022-12-08 11:01:40,030 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:01:40,030 [ZeusDataLoader(train)] Expected next epoch: time=1596.73, energy=231836.59, cost=255632.02
2022-12-08 11:01:40,031 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0018, Accuracy: 0.5230
2022-12-08 11:01:40,178 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:01:40,179 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:01:40.182 [ZeusMonitor] Monitor started.
2022-12-08 16:01:40.183 [ZeusMonitor] Running indefinitely. 2022-12-08 16:01:40.183 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:01:40.183 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e31+gpu0.power.log
2022-12-08 11:02:24,525 [ZeusDataLoader(train)] train epoch 31 done: time=44.48 energy=6745.92
2022-12-08 11:02:24,529 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 1.2761
Training Epoch: 30 [2048/50176]	Loss: 1.2069
Training Epoch: 30 [3072/50176]	Loss: 1.1023
Training Epoch: 30 [4096/50176]	Loss: 1.1509
Training Epoch: 30 [5120/50176]	Loss: 1.1552
Training Epoch: 30 [6144/50176]	Loss: 1.1016
Training Epoch: 30 [7168/50176]	Loss: 1.1349
Training Epoch: 30 [8192/50176]	Loss: 1.1410
Training Epoch: 30 [9216/50176]	Loss: 1.1773
Training Epoch: 30 [10240/50176]	Loss: 1.1817
Training Epoch: 30 [11264/50176]	Loss: 1.1529
Training Epoch: 30 [12288/50176]	Loss: 1.1889
Training Epoch: 30 [13312/50176]	Loss: 1.2061
Training Epoch: 30 [14336/50176]	Loss: 1.1675
Training Epoch: 30 [15360/50176]	Loss: 1.1020
Training Epoch: 30 [16384/50176]	Loss: 1.1703
Training Epoch: 30 [17408/50176]	Loss: 1.1324
Training Epoch: 30 [18432/50176]	Loss: 1.1138
Training Epoch: 30 [19456/50176]	Loss: 1.1106
Training Epoch: 30 [20480/50176]	Loss: 1.1019
Training Epoch: 30 [21504/50176]	Loss: 1.1163
Training Epoch: 30 [22528/50176]	Loss: 1.1469
Training Epoch: 30 [23552/50176]	Loss: 1.0650
Training Epoch: 30 [24576/50176]	Loss: 1.1348
Training Epoch: 30 [25600/50176]	Loss: 1.1323
Training Epoch: 30 [26624/50176]	Loss: 1.1678
Training Epoch: 30 [27648/50176]	Loss: 1.2284
Training Epoch: 30 [28672/50176]	Loss: 1.1888
Training Epoch: 30 [29696/50176]	Loss: 1.1592
Training Epoch: 30 [30720/50176]	Loss: 1.1941
Training Epoch: 30 [31744/50176]	Loss: 1.1089
Training Epoch: 30 [32768/50176]	Loss: 1.1321
Training Epoch: 30 [33792/50176]	Loss: 1.1992
Training Epoch: 30 [34816/50176]	Loss: 1.2082
Training Epoch: 30 [35840/50176]	Loss: 1.2415
Training Epoch: 30 [36864/50176]	Loss: 1.2193
Training Epoch: 30 [37888/50176]	Loss: 1.1432
Training Epoch: 30 [38912/50176]	Loss: 1.2133
Training Epoch: 30 [39936/50176]	Loss: 1.1603
Training Epoch: 30 [40960/50176]	Loss: 1.2184
Training Epoch: 30 [41984/50176]	Loss: 1.1821
Training Epoch: 30 [43008/50176]	Loss: 1.2342
Training Epoch: 30 [44032/50176]	Loss: 1.1156
Training Epoch: 30 [45056/50176]	Loss: 1.1608
Training Epoch: 30 [46080/50176]	Loss: 1.1797
Training Epoch: 30 [47104/50176]	Loss: 1.1415
Training Epoch: 30 [48128/50176]	Loss: 1.1928
Training Epoch: 30 [49152/50176]	Loss: 1.2891
Training Epoch: 30 [50176/50176]	Loss: 1.2873
2022-12-08 16:02:28.234 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:02:28,249 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.71 energy=515.66
2022-12-08 11:02:28,249 [ZeusDataLoader(train)] Up to epoch 31: time=1597.47, energy=231841.36, cost=255699.73
2022-12-08 11:02:28,250 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:02:28,250 [ZeusDataLoader(train)] Expected next epoch: time=1644.92, energy=239098.17, cost=263480.01
2022-12-08 11:02:28,251 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.0018, Accuracy: 0.5136
2022-12-08 11:02:28,437 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:02:28,438 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:02:28.440 [ZeusMonitor] Monitor started.
2022-12-08 16:02:28.440 [ZeusMonitor] Running indefinitely. 2022-12-08 16:02:28.440 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:02:28.440 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e32+gpu0.power.log
2022-12-08 11:03:12,947 [ZeusDataLoader(train)] train epoch 32 done: time=44.69 energy=6783.49
2022-12-08 11:03:12,950 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 1.1461
Training Epoch: 31 [2048/50176]	Loss: 1.0213
Training Epoch: 31 [3072/50176]	Loss: 1.1433
Training Epoch: 31 [4096/50176]	Loss: 1.0331
Training Epoch: 31 [5120/50176]	Loss: 1.0444
Training Epoch: 31 [6144/50176]	Loss: 1.0797
Training Epoch: 31 [7168/50176]	Loss: 1.1062
Training Epoch: 31 [8192/50176]	Loss: 1.0984
Training Epoch: 31 [9216/50176]	Loss: 1.0735
Training Epoch: 31 [10240/50176]	Loss: 1.1497
Training Epoch: 31 [11264/50176]	Loss: 1.0990
Training Epoch: 31 [12288/50176]	Loss: 1.1493
Training Epoch: 31 [13312/50176]	Loss: 1.2192
Training Epoch: 31 [14336/50176]	Loss: 1.0793
Training Epoch: 31 [15360/50176]	Loss: 1.0601
Training Epoch: 31 [16384/50176]	Loss: 1.1400
Training Epoch: 31 [17408/50176]	Loss: 1.0974
Training Epoch: 31 [18432/50176]	Loss: 1.2367
Training Epoch: 31 [19456/50176]	Loss: 1.2146
Training Epoch: 31 [20480/50176]	Loss: 1.1383
Training Epoch: 31 [21504/50176]	Loss: 1.1786
Training Epoch: 31 [22528/50176]	Loss: 1.1383
Training Epoch: 31 [23552/50176]	Loss: 1.1293
Training Epoch: 31 [24576/50176]	Loss: 1.0721
Training Epoch: 31 [25600/50176]	Loss: 1.1178
Training Epoch: 31 [26624/50176]	Loss: 1.2008
Training Epoch: 31 [27648/50176]	Loss: 1.0816
Training Epoch: 31 [28672/50176]	Loss: 1.1543
Training Epoch: 31 [29696/50176]	Loss: 1.1956
Training Epoch: 31 [30720/50176]	Loss: 1.0832
Training Epoch: 31 [31744/50176]	Loss: 1.1225
Training Epoch: 31 [32768/50176]	Loss: 1.1523
Training Epoch: 31 [33792/50176]	Loss: 1.0798
Training Epoch: 31 [34816/50176]	Loss: 1.1739
Training Epoch: 31 [35840/50176]	Loss: 1.1512
Training Epoch: 31 [36864/50176]	Loss: 1.1992
Training Epoch: 31 [37888/50176]	Loss: 1.1670
Training Epoch: 31 [38912/50176]	Loss: 1.1328
Training Epoch: 31 [39936/50176]	Loss: 1.1903
Training Epoch: 31 [40960/50176]	Loss: 1.1534
Training Epoch: 31 [41984/50176]	Loss: 1.1042
Training Epoch: 31 [43008/50176]	Loss: 0.9873
Training Epoch: 31 [44032/50176]	Loss: 1.0683
Training Epoch: 31 [45056/50176]	Loss: 1.1882
Training Epoch: 31 [46080/50176]	Loss: 1.1111
Training Epoch: 31 [47104/50176]	Loss: 1.1114
Training Epoch: 31 [48128/50176]	Loss: 1.2256
Training Epoch: 31 [49152/50176]	Loss: 1.1512
Training Epoch: 31 [50176/50176]	Loss: 1.0948
2022-12-08 16:03:16.719 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:03:16,750 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.79 energy=535.95
2022-12-08 11:03:16,751 [ZeusDataLoader(train)] Up to epoch 32: time=1645.95, energy=239160.79, cost=263601.35
2022-12-08 11:03:16,751 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:03:16,751 [ZeusDataLoader(train)] Expected next epoch: time=1693.40, energy=246417.60, cost=271381.62
2022-12-08 11:03:16,752 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.0017, Accuracy: 0.5365
2022-12-08 11:03:16,932 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:03:16,933 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:03:16.935 [ZeusMonitor] Monitor started.
2022-12-08 16:03:16.935 [ZeusMonitor] Running indefinitely. 2022-12-08 16:03:16.935 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:03:16.935 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e33+gpu0.power.log
2022-12-08 11:04:01,280 [ZeusDataLoader(train)] train epoch 33 done: time=44.52 energy=6759.32
2022-12-08 11:04:01,284 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 1.0703
Training Epoch: 32 [2048/50176]	Loss: 0.9747
Training Epoch: 32 [3072/50176]	Loss: 1.0373
Training Epoch: 32 [4096/50176]	Loss: 1.0469
Training Epoch: 32 [5120/50176]	Loss: 1.0504
Training Epoch: 32 [6144/50176]	Loss: 1.1249
Training Epoch: 32 [7168/50176]	Loss: 1.1023
Training Epoch: 32 [8192/50176]	Loss: 1.1410
Training Epoch: 32 [9216/50176]	Loss: 1.0394
Training Epoch: 32 [10240/50176]	Loss: 1.0409
Training Epoch: 32 [11264/50176]	Loss: 1.0559
Training Epoch: 32 [12288/50176]	Loss: 1.1030
Training Epoch: 32 [13312/50176]	Loss: 1.0097
Training Epoch: 32 [14336/50176]	Loss: 1.1454
Training Epoch: 32 [15360/50176]	Loss: 1.0395
Training Epoch: 32 [16384/50176]	Loss: 1.0610
Training Epoch: 32 [17408/50176]	Loss: 1.0855
Training Epoch: 32 [18432/50176]	Loss: 1.0358
Training Epoch: 32 [19456/50176]	Loss: 1.0329
Training Epoch: 32 [20480/50176]	Loss: 1.0885
Training Epoch: 32 [21504/50176]	Loss: 1.1115
Training Epoch: 32 [22528/50176]	Loss: 1.1855
Training Epoch: 32 [23552/50176]	Loss: 1.1438
Training Epoch: 32 [24576/50176]	Loss: 1.0198
Training Epoch: 32 [25600/50176]	Loss: 1.1665
Training Epoch: 32 [26624/50176]	Loss: 1.1128
Training Epoch: 32 [27648/50176]	Loss: 1.0126
Training Epoch: 32 [28672/50176]	Loss: 1.0676
Training Epoch: 32 [29696/50176]	Loss: 1.0963
Training Epoch: 32 [30720/50176]	Loss: 1.0911
Training Epoch: 32 [31744/50176]	Loss: 1.1269
Training Epoch: 32 [32768/50176]	Loss: 1.0397
Training Epoch: 32 [33792/50176]	Loss: 1.1090
Training Epoch: 32 [34816/50176]	Loss: 1.1224
Training Epoch: 32 [35840/50176]	Loss: 1.0711
Training Epoch: 32 [36864/50176]	Loss: 1.1160
Training Epoch: 32 [37888/50176]	Loss: 1.0906
Training Epoch: 32 [38912/50176]	Loss: 1.0678
Training Epoch: 32 [39936/50176]	Loss: 1.0869
Training Epoch: 32 [40960/50176]	Loss: 1.0853
Training Epoch: 32 [41984/50176]	Loss: 1.0584
Training Epoch: 32 [43008/50176]	Loss: 1.0970
Training Epoch: 32 [44032/50176]	Loss: 1.1851
Training Epoch: 32 [45056/50176]	Loss: 1.1742
Training Epoch: 32 [46080/50176]	Loss: 1.2008
Training Epoch: 32 [47104/50176]	Loss: 1.1189
Training Epoch: 32 [48128/50176]	Loss: 1.1241
Training Epoch: 32 [49152/50176]	Loss: 1.1734
Training Epoch: 32 [50176/50176]	Loss: 1.1368
2022-12-08 16:04:05.010 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:04:05,044 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.75 energy=518.18
2022-12-08 11:04:05,045 [ZeusDataLoader(train)] Up to epoch 33: time=1694.22, energy=246438.29, cost=271463.78
2022-12-08 11:04:05,045 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:04:05,045 [ZeusDataLoader(train)] Expected next epoch: time=1741.67, energy=253695.10, cost=279244.05
2022-12-08 11:04:05,046 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 0.0017, Accuracy: 0.5312
2022-12-08 11:04:05,245 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:04:05,245 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:04:05.247 [ZeusMonitor] Monitor started.
2022-12-08 16:04:05.247 [ZeusMonitor] Running indefinitely. 2022-12-08 16:04:05.247 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:04:05.247 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e34+gpu0.power.log
2022-12-08 11:04:49,641 [ZeusDataLoader(train)] train epoch 34 done: time=44.59 energy=6753.57
2022-12-08 11:04:49,646 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 0.9971
Training Epoch: 33 [2048/50176]	Loss: 0.9446
Training Epoch: 33 [3072/50176]	Loss: 1.0726
Training Epoch: 33 [4096/50176]	Loss: 1.0812
Training Epoch: 33 [5120/50176]	Loss: 1.0943
Training Epoch: 33 [6144/50176]	Loss: 1.0064
Training Epoch: 33 [7168/50176]	Loss: 1.1019
Training Epoch: 33 [8192/50176]	Loss: 0.9769
Training Epoch: 33 [9216/50176]	Loss: 1.0331
Training Epoch: 33 [10240/50176]	Loss: 1.0409
Training Epoch: 33 [11264/50176]	Loss: 1.0526
Training Epoch: 33 [12288/50176]	Loss: 1.0681
Training Epoch: 33 [13312/50176]	Loss: 1.0998
Training Epoch: 33 [14336/50176]	Loss: 1.0251
Training Epoch: 33 [15360/50176]	Loss: 1.0481
Training Epoch: 33 [16384/50176]	Loss: 1.0235
Training Epoch: 33 [17408/50176]	Loss: 1.0216
Training Epoch: 33 [18432/50176]	Loss: 1.0458
Training Epoch: 33 [19456/50176]	Loss: 1.0996
Training Epoch: 33 [20480/50176]	Loss: 1.0352
Training Epoch: 33 [21504/50176]	Loss: 1.1606
Training Epoch: 33 [22528/50176]	Loss: 1.0320
Training Epoch: 33 [23552/50176]	Loss: 1.0840
Training Epoch: 33 [24576/50176]	Loss: 1.0514
Training Epoch: 33 [25600/50176]	Loss: 1.1124
Training Epoch: 33 [26624/50176]	Loss: 1.0260
Training Epoch: 33 [27648/50176]	Loss: 1.0543
Training Epoch: 33 [28672/50176]	Loss: 1.0387
Training Epoch: 33 [29696/50176]	Loss: 1.0762
Training Epoch: 33 [30720/50176]	Loss: 1.0737
Training Epoch: 33 [31744/50176]	Loss: 1.1442
Training Epoch: 33 [32768/50176]	Loss: 1.0828
Training Epoch: 33 [33792/50176]	Loss: 1.1423
Training Epoch: 33 [34816/50176]	Loss: 1.0336
Training Epoch: 33 [35840/50176]	Loss: 1.0385
Training Epoch: 33 [36864/50176]	Loss: 1.0296
Training Epoch: 33 [37888/50176]	Loss: 1.0510
Training Epoch: 33 [38912/50176]	Loss: 1.1355
Training Epoch: 33 [39936/50176]	Loss: 1.0757
Training Epoch: 33 [40960/50176]	Loss: 1.1020
Training Epoch: 33 [41984/50176]	Loss: 1.1178
Training Epoch: 33 [43008/50176]	Loss: 1.0971
Training Epoch: 33 [44032/50176]	Loss: 1.0749
Training Epoch: 33 [45056/50176]	Loss: 1.1128
Training Epoch: 33 [46080/50176]	Loss: 1.0586
Training Epoch: 33 [47104/50176]	Loss: 1.1245
Training Epoch: 33 [48128/50176]	Loss: 1.0950
Training Epoch: 33 [49152/50176]	Loss: 1.0346
Training Epoch: 33 [50176/50176]	Loss: 1.0873
2022-12-08 16:04:53.434 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:04:53,457 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.80 energy=533.64
2022-12-08 11:04:53,457 [ZeusDataLoader(train)] Up to epoch 34: time=1742.61, energy=253725.50, cost=279341.40
2022-12-08 11:04:53,457 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:04:53,457 [ZeusDataLoader(train)] Expected next epoch: time=1790.06, energy=260982.31, cost=287121.67
2022-12-08 11:04:53,458 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 0.0017, Accuracy: 0.5369
2022-12-08 11:04:53,648 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:04:53,649 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:04:53.651 [ZeusMonitor] Monitor started.
2022-12-08 16:04:53.651 [ZeusMonitor] Running indefinitely. 2022-12-08 16:04:53.651 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:04:53.651 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e35+gpu0.power.log
2022-12-08 11:05:37,954 [ZeusDataLoader(train)] train epoch 35 done: time=44.49 energy=6765.34
2022-12-08 11:05:37,958 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 0.9834
Training Epoch: 34 [2048/50176]	Loss: 0.9742
Training Epoch: 34 [3072/50176]	Loss: 0.9379
Training Epoch: 34 [4096/50176]	Loss: 0.9360
Training Epoch: 34 [5120/50176]	Loss: 1.0122
Training Epoch: 34 [6144/50176]	Loss: 1.0262
Training Epoch: 34 [7168/50176]	Loss: 0.9767
Training Epoch: 34 [8192/50176]	Loss: 1.0041
Training Epoch: 34 [9216/50176]	Loss: 0.9947
Training Epoch: 34 [10240/50176]	Loss: 1.0344
Training Epoch: 34 [11264/50176]	Loss: 0.9579
Training Epoch: 34 [12288/50176]	Loss: 0.9912
Training Epoch: 34 [13312/50176]	Loss: 1.0404
Training Epoch: 34 [14336/50176]	Loss: 0.9630
Training Epoch: 34 [15360/50176]	Loss: 0.9773
Training Epoch: 34 [16384/50176]	Loss: 1.1347
Training Epoch: 34 [17408/50176]	Loss: 1.0184
Training Epoch: 34 [18432/50176]	Loss: 1.0308
Training Epoch: 34 [19456/50176]	Loss: 0.8904
Training Epoch: 34 [20480/50176]	Loss: 1.0041
Training Epoch: 34 [21504/50176]	Loss: 1.0510
Training Epoch: 34 [22528/50176]	Loss: 1.0436
Training Epoch: 34 [23552/50176]	Loss: 0.9960
Training Epoch: 34 [24576/50176]	Loss: 1.0203
Training Epoch: 34 [25600/50176]	Loss: 1.0716
Training Epoch: 34 [26624/50176]	Loss: 1.0830
Training Epoch: 34 [27648/50176]	Loss: 1.0681
Training Epoch: 34 [28672/50176]	Loss: 1.0412
Training Epoch: 34 [29696/50176]	Loss: 1.0908
Training Epoch: 34 [30720/50176]	Loss: 1.1340
Training Epoch: 34 [31744/50176]	Loss: 1.0458
Training Epoch: 34 [32768/50176]	Loss: 1.0561
Training Epoch: 34 [33792/50176]	Loss: 1.0414
Training Epoch: 34 [34816/50176]	Loss: 1.0138
Training Epoch: 34 [35840/50176]	Loss: 1.0642
Training Epoch: 34 [36864/50176]	Loss: 1.0507
Training Epoch: 34 [37888/50176]	Loss: 1.0115
Training Epoch: 34 [38912/50176]	Loss: 0.9857
Training Epoch: 34 [39936/50176]	Loss: 1.1112
Training Epoch: 34 [40960/50176]	Loss: 1.0848
Training Epoch: 34 [41984/50176]	Loss: 1.0518
Training Epoch: 34 [43008/50176]	Loss: 0.9802
Training Epoch: 34 [44032/50176]	Loss: 1.0350
Training Epoch: 34 [45056/50176]	Loss: 1.0466
Training Epoch: 34 [46080/50176]	Loss: 0.9914
Training Epoch: 34 [47104/50176]	Loss: 1.0446
Training Epoch: 34 [48128/50176]	Loss: 1.0732
Training Epoch: 34 [49152/50176]	Loss: 1.1026
Training Epoch: 34 [50176/50176]	Loss: 1.0539
2022-12-08 16:05:41.615 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:05:41,629 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.66 energy=504.35
2022-12-08 11:05:41,630 [ZeusDataLoader(train)] Up to epoch 35: time=1790.76, energy=260995.19, cost=287189.26
2022-12-08 11:05:41,630 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:05:41,630 [ZeusDataLoader(train)] Expected next epoch: time=1838.21, energy=268251.99, cost=294969.53
2022-12-08 11:05:41,631 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 0.0017, Accuracy: 0.5482
2022-12-08 11:05:41,816 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:05:41,817 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:05:41.818 [ZeusMonitor] Monitor started.
2022-12-08 16:05:41.818 [ZeusMonitor] Running indefinitely. 2022-12-08 16:05:41.819 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:05:41.819 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e36+gpu0.power.log
2022-12-08 11:06:26,142 [ZeusDataLoader(train)] train epoch 36 done: time=44.50 energy=6753.09
2022-12-08 11:06:26,145 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 0.9996
Training Epoch: 35 [2048/50176]	Loss: 1.0253
Training Epoch: 35 [3072/50176]	Loss: 0.9862
Training Epoch: 35 [4096/50176]	Loss: 0.9720
Training Epoch: 35 [5120/50176]	Loss: 0.9955
Training Epoch: 35 [6144/50176]	Loss: 0.9505
Training Epoch: 35 [7168/50176]	Loss: 0.9726
Training Epoch: 35 [8192/50176]	Loss: 0.9286
Training Epoch: 35 [9216/50176]	Loss: 0.8900
Training Epoch: 35 [10240/50176]	Loss: 0.9447
Training Epoch: 35 [11264/50176]	Loss: 0.9823
Training Epoch: 35 [12288/50176]	Loss: 1.0427
Training Epoch: 35 [13312/50176]	Loss: 1.0331
Training Epoch: 35 [14336/50176]	Loss: 0.9555
Training Epoch: 35 [15360/50176]	Loss: 0.9022
Training Epoch: 35 [16384/50176]	Loss: 1.0494
Training Epoch: 35 [17408/50176]	Loss: 1.0747
Training Epoch: 35 [18432/50176]	Loss: 1.0820
Training Epoch: 35 [19456/50176]	Loss: 1.0317
Training Epoch: 35 [20480/50176]	Loss: 0.9078
Training Epoch: 35 [21504/50176]	Loss: 0.9958
Training Epoch: 35 [22528/50176]	Loss: 0.9827
Training Epoch: 35 [23552/50176]	Loss: 0.9817
Training Epoch: 35 [24576/50176]	Loss: 1.0206
Training Epoch: 35 [25600/50176]	Loss: 1.0288
Training Epoch: 35 [26624/50176]	Loss: 0.9842
Training Epoch: 35 [27648/50176]	Loss: 0.9345
Training Epoch: 35 [28672/50176]	Loss: 1.0244
Training Epoch: 35 [29696/50176]	Loss: 1.0457
Training Epoch: 35 [30720/50176]	Loss: 1.0259
Training Epoch: 35 [31744/50176]	Loss: 0.9784
Training Epoch: 35 [32768/50176]	Loss: 0.9621
Training Epoch: 35 [33792/50176]	Loss: 0.9509
Training Epoch: 35 [34816/50176]	Loss: 0.9893
Training Epoch: 35 [35840/50176]	Loss: 1.0310
Training Epoch: 35 [36864/50176]	Loss: 1.0381
Training Epoch: 35 [37888/50176]	Loss: 0.9944
Training Epoch: 35 [38912/50176]	Loss: 1.0342
Training Epoch: 35 [39936/50176]	Loss: 1.1270
Training Epoch: 35 [40960/50176]	Loss: 1.0006
Training Epoch: 35 [41984/50176]	Loss: 1.0737
Training Epoch: 35 [43008/50176]	Loss: 0.9907
Training Epoch: 35 [44032/50176]	Loss: 0.9992
Training Epoch: 35 [45056/50176]	Loss: 1.0390
Training Epoch: 35 [46080/50176]	Loss: 0.9850
Training Epoch: 35 [47104/50176]	Loss: 0.9954
Training Epoch: 35 [48128/50176]	Loss: 0.9792
Training Epoch: 35 [49152/50176]	Loss: 0.9889
Training Epoch: 35 [50176/50176]	Loss: 1.0294
2022-12-08 16:06:29.889 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:06:29,931 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.78 energy=533.28
2022-12-08 11:06:29,931 [ZeusDataLoader(train)] Up to epoch 36: time=1839.04, energy=268281.55, cost=295056.89
2022-12-08 11:06:29,932 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:06:29,932 [ZeusDataLoader(train)] Expected next epoch: time=1886.49, energy=275538.36, cost=302837.17
2022-12-08 11:06:29,933 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 0.0017, Accuracy: 0.5442
2022-12-08 11:06:30,124 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:06:30,125 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:06:30.127 [ZeusMonitor] Monitor started.
2022-12-08 16:06:30.127 [ZeusMonitor] Running indefinitely. 2022-12-08 16:06:30.127 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:06:30.127 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e37+gpu0.power.log
2022-12-08 11:07:14,429 [ZeusDataLoader(train)] train epoch 37 done: time=44.49 energy=6753.50
2022-12-08 11:07:14,433 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 0.8955
Training Epoch: 36 [2048/50176]	Loss: 0.8777
Training Epoch: 36 [3072/50176]	Loss: 0.8656
Training Epoch: 36 [4096/50176]	Loss: 0.9159
Training Epoch: 36 [5120/50176]	Loss: 0.9286
Training Epoch: 36 [6144/50176]	Loss: 0.8764
Training Epoch: 36 [7168/50176]	Loss: 0.9445
Training Epoch: 36 [8192/50176]	Loss: 0.9244
Training Epoch: 36 [9216/50176]	Loss: 0.9184
Training Epoch: 36 [10240/50176]	Loss: 1.0062
Training Epoch: 36 [11264/50176]	Loss: 0.9758
Training Epoch: 36 [12288/50176]	Loss: 0.9570
Training Epoch: 36 [13312/50176]	Loss: 0.9311
Training Epoch: 36 [14336/50176]	Loss: 0.9323
Training Epoch: 36 [15360/50176]	Loss: 0.9350
Training Epoch: 36 [16384/50176]	Loss: 0.9774
Training Epoch: 36 [17408/50176]	Loss: 0.9587
Training Epoch: 36 [18432/50176]	Loss: 0.9668
Training Epoch: 36 [19456/50176]	Loss: 0.9669
Training Epoch: 36 [20480/50176]	Loss: 0.9704
Training Epoch: 36 [21504/50176]	Loss: 0.9698
Training Epoch: 36 [22528/50176]	Loss: 1.0034
Training Epoch: 36 [23552/50176]	Loss: 0.8789
Training Epoch: 36 [24576/50176]	Loss: 0.9893
Training Epoch: 36 [25600/50176]	Loss: 1.0103
Training Epoch: 36 [26624/50176]	Loss: 1.0238
Training Epoch: 36 [27648/50176]	Loss: 0.9893
Training Epoch: 36 [28672/50176]	Loss: 0.9806
Training Epoch: 36 [29696/50176]	Loss: 0.9588
Training Epoch: 36 [30720/50176]	Loss: 0.9816
Training Epoch: 36 [31744/50176]	Loss: 1.0143
Training Epoch: 36 [32768/50176]	Loss: 1.0204
Training Epoch: 36 [33792/50176]	Loss: 0.9531
Training Epoch: 36 [34816/50176]	Loss: 0.9820
Training Epoch: 36 [35840/50176]	Loss: 0.9274
Training Epoch: 36 [36864/50176]	Loss: 0.9682
Training Epoch: 36 [37888/50176]	Loss: 1.0196
Training Epoch: 36 [38912/50176]	Loss: 0.9564
Training Epoch: 36 [39936/50176]	Loss: 0.9894
Training Epoch: 36 [40960/50176]	Loss: 0.9427
Training Epoch: 36 [41984/50176]	Loss: 1.0225
Training Epoch: 36 [43008/50176]	Loss: 0.9700
Training Epoch: 36 [44032/50176]	Loss: 0.9758
Training Epoch: 36 [45056/50176]	Loss: 1.0224
Training Epoch: 36 [46080/50176]	Loss: 1.0176
Training Epoch: 36 [47104/50176]	Loss: 1.0522
Training Epoch: 36 [48128/50176]	Loss: 0.9793
Training Epoch: 36 [49152/50176]	Loss: 0.9480
Training Epoch: 36 [50176/50176]	Loss: 0.9256
2022-12-08 16:07:18.201 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:07:18,225 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.78 energy=535.12
2022-12-08 11:07:18,226 [ZeusDataLoader(train)] Up to epoch 37: time=1887.31, energy=275570.16, cost=302924.94
2022-12-08 11:07:18,226 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:07:18,226 [ZeusDataLoader(train)] Expected next epoch: time=1934.76, energy=282826.97, cost=310705.21
2022-12-08 11:07:18,227 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 0.0018, Accuracy: 0.5386
2022-12-08 11:07:18,420 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:07:18,421 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:07:18.422 [ZeusMonitor] Monitor started.
2022-12-08 16:07:18.423 [ZeusMonitor] Running indefinitely. 2022-12-08 16:07:18.423 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:07:18.423 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e38+gpu0.power.log
2022-12-08 11:08:03,048 [ZeusDataLoader(train)] train epoch 38 done: time=44.81 energy=6798.27
2022-12-08 11:08:03,052 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 0.9069
Training Epoch: 37 [2048/50176]	Loss: 0.8594
Training Epoch: 37 [3072/50176]	Loss: 0.8586
Training Epoch: 37 [4096/50176]	Loss: 0.8955
Training Epoch: 37 [5120/50176]	Loss: 0.8528
Training Epoch: 37 [6144/50176]	Loss: 0.8713
Training Epoch: 37 [7168/50176]	Loss: 0.8464
Training Epoch: 37 [8192/50176]	Loss: 0.8953
Training Epoch: 37 [9216/50176]	Loss: 0.9277
Training Epoch: 37 [10240/50176]	Loss: 0.8710
Training Epoch: 37 [11264/50176]	Loss: 0.9087
Training Epoch: 37 [12288/50176]	Loss: 1.0110
Training Epoch: 37 [13312/50176]	Loss: 0.8974
Training Epoch: 37 [14336/50176]	Loss: 0.8987
Training Epoch: 37 [15360/50176]	Loss: 0.9031
Training Epoch: 37 [16384/50176]	Loss: 0.9093
Training Epoch: 37 [17408/50176]	Loss: 0.9510
Training Epoch: 37 [18432/50176]	Loss: 0.8437
Training Epoch: 37 [19456/50176]	Loss: 0.9221
Training Epoch: 37 [20480/50176]	Loss: 0.9307
Training Epoch: 37 [21504/50176]	Loss: 0.9494
Training Epoch: 37 [22528/50176]	Loss: 0.8992
Training Epoch: 37 [23552/50176]	Loss: 0.9092
Training Epoch: 37 [24576/50176]	Loss: 0.9418
Training Epoch: 37 [25600/50176]	Loss: 0.9366
Training Epoch: 37 [26624/50176]	Loss: 0.9914
Training Epoch: 37 [27648/50176]	Loss: 0.9709
Training Epoch: 37 [28672/50176]	Loss: 1.0207
Training Epoch: 37 [29696/50176]	Loss: 0.9764
Training Epoch: 37 [30720/50176]	Loss: 0.8975
Training Epoch: 37 [31744/50176]	Loss: 0.8888
Training Epoch: 37 [32768/50176]	Loss: 1.0178
Training Epoch: 37 [33792/50176]	Loss: 0.9954
Training Epoch: 37 [34816/50176]	Loss: 1.0205
Training Epoch: 37 [35840/50176]	Loss: 0.9452
Training Epoch: 37 [36864/50176]	Loss: 0.8617
Training Epoch: 37 [37888/50176]	Loss: 1.0116
Training Epoch: 37 [38912/50176]	Loss: 0.9631
Training Epoch: 37 [39936/50176]	Loss: 0.9340
Training Epoch: 37 [40960/50176]	Loss: 0.9224
Training Epoch: 37 [41984/50176]	Loss: 0.9440
Training Epoch: 37 [43008/50176]	Loss: 1.0056
Training Epoch: 37 [44032/50176]	Loss: 1.0467
Training Epoch: 37 [45056/50176]	Loss: 0.9607
Training Epoch: 37 [46080/50176]	Loss: 0.9258
Training Epoch: 37 [47104/50176]	Loss: 0.9822
Training Epoch: 37 [48128/50176]	Loss: 1.0367
Training Epoch: 37 [49152/50176]	Loss: 0.8938
Training Epoch: 37 [50176/50176]	Loss: 1.0245
2022-12-08 16:08:06.821 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:08:06,862 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.80 energy=523.45
2022-12-08 11:08:06,862 [ZeusDataLoader(train)] Up to epoch 38: time=1935.92, energy=282891.88, cost=310839.38
2022-12-08 11:08:06,862 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:08:06,862 [ZeusDataLoader(train)] Expected next epoch: time=1983.37, energy=290148.69, cost=318619.65
2022-12-08 11:08:06,863 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0018, Accuracy: 0.5443
2022-12-08 11:08:07,057 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:08:07,058 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:08:07.060 [ZeusMonitor] Monitor started.
2022-12-08 16:08:07.060 [ZeusMonitor] Running indefinitely. 2022-12-08 16:08:07.060 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:08:07.060 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e39+gpu0.power.log
2022-12-08 11:08:51,377 [ZeusDataLoader(train)] train epoch 39 done: time=44.51 energy=6752.59
2022-12-08 11:08:51,381 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 0.9522
Training Epoch: 38 [2048/50176]	Loss: 0.9072
Training Epoch: 38 [3072/50176]	Loss: 0.8061
Training Epoch: 38 [4096/50176]	Loss: 0.8009
Training Epoch: 38 [5120/50176]	Loss: 0.8615
Training Epoch: 38 [6144/50176]	Loss: 0.8192
Training Epoch: 38 [7168/50176]	Loss: 0.8437
Training Epoch: 38 [8192/50176]	Loss: 0.8666
Training Epoch: 38 [9216/50176]	Loss: 0.8528
Training Epoch: 38 [10240/50176]	Loss: 0.9574
Training Epoch: 38 [11264/50176]	Loss: 1.0170
Training Epoch: 38 [12288/50176]	Loss: 0.9195
Training Epoch: 38 [13312/50176]	Loss: 0.9060
Training Epoch: 38 [14336/50176]	Loss: 0.9284
Training Epoch: 38 [15360/50176]	Loss: 0.9447
Training Epoch: 38 [16384/50176]	Loss: 0.8979
Training Epoch: 38 [17408/50176]	Loss: 0.8949
Training Epoch: 38 [18432/50176]	Loss: 0.9070
Training Epoch: 38 [19456/50176]	Loss: 0.9498
Training Epoch: 38 [20480/50176]	Loss: 0.9434
Training Epoch: 38 [21504/50176]	Loss: 0.8593
Training Epoch: 38 [22528/50176]	Loss: 0.9112
Training Epoch: 38 [23552/50176]	Loss: 0.9437
Training Epoch: 38 [24576/50176]	Loss: 0.8760
Training Epoch: 38 [25600/50176]	Loss: 0.8434
Training Epoch: 38 [26624/50176]	Loss: 0.9225
Training Epoch: 38 [27648/50176]	Loss: 0.9368
Training Epoch: 38 [28672/50176]	Loss: 0.9755
Training Epoch: 38 [29696/50176]	Loss: 0.8484
Training Epoch: 38 [30720/50176]	Loss: 0.9042
Training Epoch: 38 [31744/50176]	Loss: 0.8904
Training Epoch: 38 [32768/50176]	Loss: 0.8878
Training Epoch: 38 [33792/50176]	Loss: 0.8878
Training Epoch: 38 [34816/50176]	Loss: 0.9500
Training Epoch: 38 [35840/50176]	Loss: 0.8810
Training Epoch: 38 [36864/50176]	Loss: 0.9464
Training Epoch: 38 [37888/50176]	Loss: 0.9418
Training Epoch: 38 [38912/50176]	Loss: 0.8846
Training Epoch: 38 [39936/50176]	Loss: 0.9480
Training Epoch: 38 [40960/50176]	Loss: 0.9478
Training Epoch: 38 [41984/50176]	Loss: 0.9044
Training Epoch: 38 [43008/50176]	Loss: 0.9085
Training Epoch: 38 [44032/50176]	Loss: 0.9127
Training Epoch: 38 [45056/50176]	Loss: 0.9026
Training Epoch: 38 [46080/50176]	Loss: 0.9045
Training Epoch: 38 [47104/50176]	Loss: 0.9263
Training Epoch: 38 [48128/50176]	Loss: 0.9328
Training Epoch: 38 [49152/50176]	Loss: 0.9757
Training Epoch: 38 [50176/50176]	Loss: 0.8841
2022-12-08 16:08:55.089 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:08:55,105 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.71 energy=525.61
2022-12-08 11:08:55,105 [ZeusDataLoader(train)] Up to epoch 39: time=1984.15, energy=290170.08, cost=318697.74
2022-12-08 11:08:55,105 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:08:55,106 [ZeusDataLoader(train)] Expected next epoch: time=2031.60, energy=297426.89, cost=326478.02
2022-12-08 11:08:55,107 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0017, Accuracy: 0.5535
2022-12-08 11:08:55,296 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:08:55,297 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:08:55.299 [ZeusMonitor] Monitor started.
2022-12-08 16:08:55.299 [ZeusMonitor] Running indefinitely. 2022-12-08 16:08:55.299 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:08:55.299 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e40+gpu0.power.log
2022-12-08 11:09:39,599 [ZeusDataLoader(train)] train epoch 40 done: time=44.48 energy=6758.97
2022-12-08 11:09:39,603 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 0.8200
Training Epoch: 39 [2048/50176]	Loss: 0.8660
Training Epoch: 39 [3072/50176]	Loss: 0.8783
Training Epoch: 39 [4096/50176]	Loss: 0.8755
Training Epoch: 39 [5120/50176]	Loss: 0.8897
Training Epoch: 39 [6144/50176]	Loss: 0.8520
Training Epoch: 39 [7168/50176]	Loss: 0.7697
Training Epoch: 39 [8192/50176]	Loss: 0.8775
Training Epoch: 39 [9216/50176]	Loss: 0.8818
Training Epoch: 39 [10240/50176]	Loss: 0.8620
Training Epoch: 39 [11264/50176]	Loss: 0.8582
Training Epoch: 39 [12288/50176]	Loss: 0.8655
Training Epoch: 39 [13312/50176]	Loss: 0.8412
Training Epoch: 39 [14336/50176]	Loss: 0.8491
Training Epoch: 39 [15360/50176]	Loss: 0.8894
Training Epoch: 39 [16384/50176]	Loss: 0.7907
Training Epoch: 39 [17408/50176]	Loss: 0.8482
Training Epoch: 39 [18432/50176]	Loss: 0.8016
Training Epoch: 39 [19456/50176]	Loss: 0.8387
Training Epoch: 39 [20480/50176]	Loss: 0.9164
Training Epoch: 39 [21504/50176]	Loss: 0.9578
Training Epoch: 39 [22528/50176]	Loss: 0.8811
Training Epoch: 39 [23552/50176]	Loss: 0.8463
Training Epoch: 39 [24576/50176]	Loss: 0.8325
Training Epoch: 39 [25600/50176]	Loss: 0.8900
Training Epoch: 39 [26624/50176]	Loss: 0.9263
Training Epoch: 39 [27648/50176]	Loss: 0.8673
Training Epoch: 39 [28672/50176]	Loss: 0.8765
Training Epoch: 39 [29696/50176]	Loss: 0.9574
Training Epoch: 39 [30720/50176]	Loss: 0.9718
Training Epoch: 39 [31744/50176]	Loss: 1.0164
Training Epoch: 39 [32768/50176]	Loss: 0.8327
Training Epoch: 39 [33792/50176]	Loss: 0.8774
Training Epoch: 39 [34816/50176]	Loss: 0.9566
Training Epoch: 39 [35840/50176]	Loss: 0.8494
Training Epoch: 39 [36864/50176]	Loss: 0.8538
Training Epoch: 39 [37888/50176]	Loss: 0.8943
Training Epoch: 39 [38912/50176]	Loss: 0.9045
Training Epoch: 39 [39936/50176]	Loss: 0.9421
Training Epoch: 39 [40960/50176]	Loss: 0.9567
Training Epoch: 39 [41984/50176]	Loss: 0.9541
Training Epoch: 39 [43008/50176]	Loss: 0.8884
Training Epoch: 39 [44032/50176]	Loss: 0.9163
Training Epoch: 39 [45056/50176]	Loss: 0.9284
Training Epoch: 39 [46080/50176]	Loss: 0.9394
Training Epoch: 39 [47104/50176]	Loss: 0.9282
Training Epoch: 39 [48128/50176]	Loss: 0.9152
Training Epoch: 39 [49152/50176]	Loss: 0.9268
Training Epoch: 39 [50176/50176]	Loss: 0.9333
2022-12-08 16:09:43.367 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:09:43,406 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.79 energy=534.66
2022-12-08 11:09:43,406 [ZeusDataLoader(train)] Up to epoch 40: time=2032.42, energy=297463.71, cost=326568.87
2022-12-08 11:09:43,406 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:09:43,407 [ZeusDataLoader(train)] Expected next epoch: time=2079.87, energy=304720.52, cost=334349.14
2022-12-08 11:09:43,408 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0018, Accuracy: 0.5457
2022-12-08 11:09:43,565 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:09:43,566 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:09:43.568 [ZeusMonitor] Monitor started.
2022-12-08 16:09:43.568 [ZeusMonitor] Running indefinitely. 2022-12-08 16:09:43.568 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:09:43.568 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e41+gpu0.power.log
2022-12-08 11:10:27,997 [ZeusDataLoader(train)] train epoch 41 done: time=44.58 energy=6781.50
2022-12-08 11:10:28,000 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 0.7937
Training Epoch: 40 [2048/50176]	Loss: 0.7936
Training Epoch: 40 [3072/50176]	Loss: 0.7701
Training Epoch: 40 [4096/50176]	Loss: 0.8139
Training Epoch: 40 [5120/50176]	Loss: 0.8537
Training Epoch: 40 [6144/50176]	Loss: 0.8309
Training Epoch: 40 [7168/50176]	Loss: 0.7762
Training Epoch: 40 [8192/50176]	Loss: 0.7647
Training Epoch: 40 [9216/50176]	Loss: 0.7743
Training Epoch: 40 [10240/50176]	Loss: 0.8980
Training Epoch: 40 [11264/50176]	Loss: 0.9405
Training Epoch: 40 [12288/50176]	Loss: 0.8249
Training Epoch: 40 [13312/50176]	Loss: 0.8117
Training Epoch: 40 [14336/50176]	Loss: 0.8897
Training Epoch: 40 [15360/50176]	Loss: 0.7942
Training Epoch: 40 [16384/50176]	Loss: 0.8243
Training Epoch: 40 [17408/50176]	Loss: 0.7764
Training Epoch: 40 [18432/50176]	Loss: 0.8833
Training Epoch: 40 [19456/50176]	Loss: 0.8589
Training Epoch: 40 [20480/50176]	Loss: 0.8532
Training Epoch: 40 [21504/50176]	Loss: 0.8829
Training Epoch: 40 [22528/50176]	Loss: 0.8114
Training Epoch: 40 [23552/50176]	Loss: 0.8955
Training Epoch: 40 [24576/50176]	Loss: 0.9615
Training Epoch: 40 [25600/50176]	Loss: 0.8395
Training Epoch: 40 [26624/50176]	Loss: 0.9165
Training Epoch: 40 [27648/50176]	Loss: 0.8753
Training Epoch: 40 [28672/50176]	Loss: 0.8856
Training Epoch: 40 [29696/50176]	Loss: 0.8236
Training Epoch: 40 [30720/50176]	Loss: 0.8367
Training Epoch: 40 [31744/50176]	Loss: 0.8472
Training Epoch: 40 [32768/50176]	Loss: 0.9414
Training Epoch: 40 [33792/50176]	Loss: 0.9145
Training Epoch: 40 [34816/50176]	Loss: 0.8167
Training Epoch: 40 [35840/50176]	Loss: 0.8217
Training Epoch: 40 [36864/50176]	Loss: 0.8390
Training Epoch: 40 [37888/50176]	Loss: 0.8246
Training Epoch: 40 [38912/50176]	Loss: 0.8785
Training Epoch: 40 [39936/50176]	Loss: 0.9282
Training Epoch: 40 [40960/50176]	Loss: 0.9437
Training Epoch: 40 [41984/50176]	Loss: 0.8942
Training Epoch: 40 [43008/50176]	Loss: 0.9545
Training Epoch: 40 [44032/50176]	Loss: 0.9102
Training Epoch: 40 [45056/50176]	Loss: 0.8553
Training Epoch: 40 [46080/50176]	Loss: 0.9254
Training Epoch: 40 [47104/50176]	Loss: 0.8567
Training Epoch: 40 [48128/50176]	Loss: 0.8817
Training Epoch: 40 [49152/50176]	Loss: 0.8339
Training Epoch: 40 [50176/50176]	Loss: 0.8301
2022-12-08 16:10:31.724 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:10:31,742 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.73 energy=518.29
2022-12-08 11:10:31,742 [ZeusDataLoader(train)] Up to epoch 41: time=2080.73, energy=304763.50, cost=334446.06
2022-12-08 11:10:31,742 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:10:31,742 [ZeusDataLoader(train)] Expected next epoch: time=2128.18, energy=312020.30, cost=342226.33
2022-12-08 11:10:31,743 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0018, Accuracy: 0.5553
2022-12-08 11:10:31,902 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:10:31,903 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:10:31.907 [ZeusMonitor] Monitor started.
2022-12-08 16:10:31.907 [ZeusMonitor] Running indefinitely. 2022-12-08 16:10:31.907 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:10:31.907 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e42+gpu0.power.log
2022-12-08 11:11:16,319 [ZeusDataLoader(train)] train epoch 42 done: time=44.57 energy=6776.02
2022-12-08 11:11:16,324 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 0.7613
Training Epoch: 41 [2048/50176]	Loss: 0.7773
Training Epoch: 41 [3072/50176]	Loss: 0.8256
Training Epoch: 41 [4096/50176]	Loss: 0.7800
Training Epoch: 41 [5120/50176]	Loss: 0.7433
Training Epoch: 41 [6144/50176]	Loss: 0.8035
Training Epoch: 41 [7168/50176]	Loss: 0.8122
Training Epoch: 41 [8192/50176]	Loss: 0.8558
Training Epoch: 41 [9216/50176]	Loss: 0.8908
Training Epoch: 41 [10240/50176]	Loss: 0.7908
Training Epoch: 41 [11264/50176]	Loss: 0.8006
Training Epoch: 41 [12288/50176]	Loss: 0.8328
Training Epoch: 41 [13312/50176]	Loss: 0.7887
Training Epoch: 41 [14336/50176]	Loss: 0.8302
Training Epoch: 41 [15360/50176]	Loss: 0.8094
Training Epoch: 41 [16384/50176]	Loss: 0.7813
Training Epoch: 41 [17408/50176]	Loss: 0.8476
Training Epoch: 41 [18432/50176]	Loss: 0.8418
Training Epoch: 41 [19456/50176]	Loss: 0.8888
Training Epoch: 41 [20480/50176]	Loss: 0.8217
Training Epoch: 41 [21504/50176]	Loss: 0.7964
Training Epoch: 41 [22528/50176]	Loss: 0.8266
Training Epoch: 41 [23552/50176]	Loss: 0.8872
Training Epoch: 41 [24576/50176]	Loss: 0.8436
Training Epoch: 41 [25600/50176]	Loss: 0.7691
Training Epoch: 41 [26624/50176]	Loss: 0.7779
Training Epoch: 41 [27648/50176]	Loss: 0.8252
Training Epoch: 41 [28672/50176]	Loss: 0.8682
Training Epoch: 41 [29696/50176]	Loss: 0.7823
Training Epoch: 41 [30720/50176]	Loss: 0.8131
Training Epoch: 41 [31744/50176]	Loss: 0.8752
Training Epoch: 41 [32768/50176]	Loss: 0.7718
Training Epoch: 41 [33792/50176]	Loss: 0.8250
Training Epoch: 41 [34816/50176]	Loss: 0.7983
Training Epoch: 41 [35840/50176]	Loss: 0.8231
Training Epoch: 41 [36864/50176]	Loss: 0.8525
Training Epoch: 41 [37888/50176]	Loss: 0.8369
Training Epoch: 41 [38912/50176]	Loss: 0.8242
Training Epoch: 41 [39936/50176]	Loss: 0.8370
Training Epoch: 41 [40960/50176]	Loss: 0.8832
Training Epoch: 41 [41984/50176]	Loss: 0.8282
Training Epoch: 41 [43008/50176]	Loss: 0.8128
Training Epoch: 41 [44032/50176]	Loss: 0.8687
Training Epoch: 41 [45056/50176]	Loss: 0.8501
Training Epoch: 41 [46080/50176]	Loss: 0.8371
Training Epoch: 41 [47104/50176]	Loss: 0.8526
Training Epoch: 41 [48128/50176]	Loss: 0.8435
Training Epoch: 41 [49152/50176]	Loss: 0.8822
Training Epoch: 41 [50176/50176]	Loss: 0.8542
2022-12-08 16:11:20.094 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:11:20,123 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.79 energy=519.76
2022-12-08 11:11:20,123 [ZeusDataLoader(train)] Up to epoch 42: time=2129.09, energy=312059.28, cost=342325.11
2022-12-08 11:11:20,124 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:11:20,124 [ZeusDataLoader(train)] Expected next epoch: time=2176.54, energy=319316.08, cost=350105.38
2022-12-08 11:11:20,125 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 0.0018, Accuracy: 0.5499
2022-12-08 11:11:20,321 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:11:20,321 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:11:20.323 [ZeusMonitor] Monitor started.
2022-12-08 16:11:20.323 [ZeusMonitor] Running indefinitely. 2022-12-08 16:11:20.323 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:11:20.323 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e43+gpu0.power.log
2022-12-08 11:12:04,709 [ZeusDataLoader(train)] train epoch 43 done: time=44.58 energy=6771.78
2022-12-08 11:12:04,713 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 0.7698
Training Epoch: 42 [2048/50176]	Loss: 0.6817
Training Epoch: 42 [3072/50176]	Loss: 0.7250
Training Epoch: 42 [4096/50176]	Loss: 0.7905
Training Epoch: 42 [5120/50176]	Loss: 0.7254
Training Epoch: 42 [6144/50176]	Loss: 0.8175
Training Epoch: 42 [7168/50176]	Loss: 0.7069
Training Epoch: 42 [8192/50176]	Loss: 0.7305
Training Epoch: 42 [9216/50176]	Loss: 0.7717
Training Epoch: 42 [10240/50176]	Loss: 0.8451
Training Epoch: 42 [11264/50176]	Loss: 0.7321
Training Epoch: 42 [12288/50176]	Loss: 0.8098
Training Epoch: 42 [13312/50176]	Loss: 0.8113
Training Epoch: 42 [14336/50176]	Loss: 0.7283
Training Epoch: 42 [15360/50176]	Loss: 0.7296
Training Epoch: 42 [16384/50176]	Loss: 0.7032
Training Epoch: 42 [17408/50176]	Loss: 0.7070
Training Epoch: 42 [18432/50176]	Loss: 0.7651
Training Epoch: 42 [19456/50176]	Loss: 0.7756
Training Epoch: 42 [20480/50176]	Loss: 0.7832
Training Epoch: 42 [21504/50176]	Loss: 0.7989
Training Epoch: 42 [22528/50176]	Loss: 0.7862
Training Epoch: 42 [23552/50176]	Loss: 0.7980
Training Epoch: 42 [24576/50176]	Loss: 0.7672
Training Epoch: 42 [25600/50176]	Loss: 0.8898
Training Epoch: 42 [26624/50176]	Loss: 0.7526
Training Epoch: 42 [27648/50176]	Loss: 0.7638
Training Epoch: 42 [28672/50176]	Loss: 0.7672
Training Epoch: 42 [29696/50176]	Loss: 0.8525
Training Epoch: 42 [30720/50176]	Loss: 0.8350
Training Epoch: 42 [31744/50176]	Loss: 0.8425
Training Epoch: 42 [32768/50176]	Loss: 0.8412
Training Epoch: 42 [33792/50176]	Loss: 0.8032
Training Epoch: 42 [34816/50176]	Loss: 0.7965
Training Epoch: 42 [35840/50176]	Loss: 0.8247
Training Epoch: 42 [36864/50176]	Loss: 0.9056
Training Epoch: 42 [37888/50176]	Loss: 0.8426
Training Epoch: 42 [38912/50176]	Loss: 0.8589
Training Epoch: 42 [39936/50176]	Loss: 0.8291
Training Epoch: 42 [40960/50176]	Loss: 0.8543
Training Epoch: 42 [41984/50176]	Loss: 0.7729
Training Epoch: 42 [43008/50176]	Loss: 0.8165
Training Epoch: 42 [44032/50176]	Loss: 0.8334
Training Epoch: 42 [45056/50176]	Loss: 0.8688
Training Epoch: 42 [46080/50176]	Loss: 0.8197
Training Epoch: 42 [47104/50176]	Loss: 0.8386
Training Epoch: 42 [48128/50176]	Loss: 0.8424
Training Epoch: 42 [49152/50176]	Loss: 0.9174
Training Epoch: 42 [50176/50176]	Loss: 0.8524
2022-12-08 16:12:08.409 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:12:08,434 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.71 energy=521.15
2022-12-08 11:12:08,435 [ZeusDataLoader(train)] Up to epoch 43: time=2177.38, energy=319352.21, cost=350196.78
2022-12-08 11:12:08,435 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:12:08,435 [ZeusDataLoader(train)] Expected next epoch: time=2224.83, energy=326609.02, cost=357977.05
2022-12-08 11:12:08,436 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 0.0018, Accuracy: 0.5610
2022-12-08 11:12:08,590 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:12:08,591 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:12:08.593 [ZeusMonitor] Monitor started.
2022-12-08 16:12:08.593 [ZeusMonitor] Running indefinitely. 2022-12-08 16:12:08.593 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:12:08.593 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e44+gpu0.power.log
2022-12-08 11:12:53,022 [ZeusDataLoader(train)] train epoch 44 done: time=44.58 energy=6782.21
2022-12-08 11:12:53,025 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 0.7344
Training Epoch: 43 [2048/50176]	Loss: 0.7632
Training Epoch: 43 [3072/50176]	Loss: 0.7211
Training Epoch: 43 [4096/50176]	Loss: 0.7310
Training Epoch: 43 [5120/50176]	Loss: 0.6672
Training Epoch: 43 [6144/50176]	Loss: 0.7513
Training Epoch: 43 [7168/50176]	Loss: 0.7713
Training Epoch: 43 [8192/50176]	Loss: 0.7495
Training Epoch: 43 [9216/50176]	Loss: 0.8070
Training Epoch: 43 [10240/50176]	Loss: 0.8154
Training Epoch: 43 [11264/50176]	Loss: 0.7241
Training Epoch: 43 [12288/50176]	Loss: 0.7837
Training Epoch: 43 [13312/50176]	Loss: 0.7647
Training Epoch: 43 [14336/50176]	Loss: 0.7074
Training Epoch: 43 [15360/50176]	Loss: 0.7194
Training Epoch: 43 [16384/50176]	Loss: 0.7493
Training Epoch: 43 [17408/50176]	Loss: 0.7993
Training Epoch: 43 [18432/50176]	Loss: 0.8088
Training Epoch: 43 [19456/50176]	Loss: 0.8677
Training Epoch: 43 [20480/50176]	Loss: 0.7334
Training Epoch: 43 [21504/50176]	Loss: 0.7943
Training Epoch: 43 [22528/50176]	Loss: 0.7496
Training Epoch: 43 [23552/50176]	Loss: 0.7321
Training Epoch: 43 [24576/50176]	Loss: 0.7407
Training Epoch: 43 [25600/50176]	Loss: 0.8400
Training Epoch: 43 [26624/50176]	Loss: 0.7382
Training Epoch: 43 [27648/50176]	Loss: 0.7984
Training Epoch: 43 [28672/50176]	Loss: 0.7123
Training Epoch: 43 [29696/50176]	Loss: 0.7563
Training Epoch: 43 [30720/50176]	Loss: 0.7027
Training Epoch: 43 [31744/50176]	Loss: 0.7910
Training Epoch: 43 [32768/50176]	Loss: 0.7897
Training Epoch: 43 [33792/50176]	Loss: 0.6937
Training Epoch: 43 [34816/50176]	Loss: 0.8452
Training Epoch: 43 [35840/50176]	Loss: 0.8387
Training Epoch: 43 [36864/50176]	Loss: 0.8391
Training Epoch: 43 [37888/50176]	Loss: 0.8220
Training Epoch: 43 [38912/50176]	Loss: 0.8186
Training Epoch: 43 [39936/50176]	Loss: 0.7942
Training Epoch: 43 [40960/50176]	Loss: 0.7295
Training Epoch: 43 [41984/50176]	Loss: 0.7655
Training Epoch: 43 [43008/50176]	Loss: 0.7248
Training Epoch: 43 [44032/50176]	Loss: 0.8113
Training Epoch: 43 [45056/50176]	Loss: 0.8469
Training Epoch: 43 [46080/50176]	Loss: 0.8415
Training Epoch: 43 [47104/50176]	Loss: 0.7907
Training Epoch: 43 [48128/50176]	Loss: 0.8031
Training Epoch: 43 [49152/50176]	Loss: 0.7345
Training Epoch: 43 [50176/50176]	Loss: 0.7768
2022-12-08 16:12:56.821 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:12:56,845 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.81 energy=543.79
2022-12-08 11:12:56,845 [ZeusDataLoader(train)] Up to epoch 44: time=2225.77, energy=326678.21, cost=358093.65
2022-12-08 11:12:56,845 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:12:56,845 [ZeusDataLoader(train)] Expected next epoch: time=2273.22, energy=333935.02, cost=365873.93
2022-12-08 11:12:56,847 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0018, Accuracy: 0.5566
2022-12-08 11:12:57,045 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:12:57,046 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:12:57.048 [ZeusMonitor] Monitor started.
2022-12-08 16:12:57.048 [ZeusMonitor] Running indefinitely. 2022-12-08 16:12:57.048 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:12:57.048 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e45+gpu0.power.log
2022-12-08 11:13:41,570 [ZeusDataLoader(train)] train epoch 45 done: time=44.71 energy=6797.05
2022-12-08 11:13:41,574 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 0.6707
Training Epoch: 44 [2048/50176]	Loss: 0.7726
Training Epoch: 44 [3072/50176]	Loss: 0.7076
Training Epoch: 44 [4096/50176]	Loss: 0.6959
Training Epoch: 44 [5120/50176]	Loss: 0.6802
Training Epoch: 44 [6144/50176]	Loss: 0.7072
Training Epoch: 44 [7168/50176]	Loss: 0.6647
Training Epoch: 44 [8192/50176]	Loss: 0.6716
Training Epoch: 44 [9216/50176]	Loss: 0.6966
Training Epoch: 44 [10240/50176]	Loss: 0.6533
Training Epoch: 44 [11264/50176]	Loss: 0.7567
Training Epoch: 44 [12288/50176]	Loss: 0.6479
Training Epoch: 44 [13312/50176]	Loss: 0.7780
Training Epoch: 44 [14336/50176]	Loss: 0.7670
Training Epoch: 44 [15360/50176]	Loss: 0.7124
Training Epoch: 44 [16384/50176]	Loss: 0.7550
Training Epoch: 44 [17408/50176]	Loss: 0.7047
Training Epoch: 44 [18432/50176]	Loss: 0.6837
Training Epoch: 44 [19456/50176]	Loss: 0.7538
Training Epoch: 44 [20480/50176]	Loss: 0.7558
Training Epoch: 44 [21504/50176]	Loss: 0.7990
Training Epoch: 44 [22528/50176]	Loss: 0.7063
Training Epoch: 44 [23552/50176]	Loss: 0.6923
Training Epoch: 44 [24576/50176]	Loss: 0.8052
Training Epoch: 44 [25600/50176]	Loss: 0.7583
Training Epoch: 44 [26624/50176]	Loss: 0.7830
Training Epoch: 44 [27648/50176]	Loss: 0.7310
Training Epoch: 44 [28672/50176]	Loss: 0.7378
Training Epoch: 44 [29696/50176]	Loss: 0.7143
Training Epoch: 44 [30720/50176]	Loss: 0.7417
Training Epoch: 44 [31744/50176]	Loss: 0.7939
Training Epoch: 44 [32768/50176]	Loss: 0.7817
Training Epoch: 44 [33792/50176]	Loss: 0.7478
Training Epoch: 44 [34816/50176]	Loss: 0.7067
Training Epoch: 44 [35840/50176]	Loss: 0.7463
Training Epoch: 44 [36864/50176]	Loss: 0.8044
Training Epoch: 44 [37888/50176]	Loss: 0.7952
Training Epoch: 44 [38912/50176]	Loss: 0.7430
Training Epoch: 44 [39936/50176]	Loss: 0.8234
Training Epoch: 44 [40960/50176]	Loss: 0.7697
Training Epoch: 44 [41984/50176]	Loss: 0.7609
Training Epoch: 44 [43008/50176]	Loss: 0.7056
Training Epoch: 44 [44032/50176]	Loss: 0.7909
Training Epoch: 44 [45056/50176]	Loss: 0.7934
Training Epoch: 44 [46080/50176]	Loss: 0.8183
Training Epoch: 44 [47104/50176]	Loss: 0.7808
Training Epoch: 44 [48128/50176]	Loss: 0.7547
Training Epoch: 44 [49152/50176]	Loss: 0.7639
Training Epoch: 44 [50176/50176]	Loss: 0.7408
2022-12-08 16:13:45.354 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:13:45,370 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.79 energy=531.23
2022-12-08 11:13:45,370 [ZeusDataLoader(train)] Up to epoch 45: time=2274.27, energy=334006.50, cost=366001.70
2022-12-08 11:13:45,370 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:13:45,370 [ZeusDataLoader(train)] Expected next epoch: time=2321.72, energy=341263.31, cost=373781.97
2022-12-08 11:13:45,371 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 0.0019, Accuracy: 0.5417
2022-12-08 11:13:45,561 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:13:45,562 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:13:45.564 [ZeusMonitor] Monitor started.
2022-12-08 16:13:45.564 [ZeusMonitor] Running indefinitely. 2022-12-08 16:13:45.564 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:13:45.564 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e46+gpu0.power.log
2022-12-08 11:14:30,092 [ZeusDataLoader(train)] train epoch 46 done: time=44.71 energy=6799.01
2022-12-08 11:14:30,096 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 0.7378
Training Epoch: 45 [2048/50176]	Loss: 0.6604
Training Epoch: 45 [3072/50176]	Loss: 0.5996
Training Epoch: 45 [4096/50176]	Loss: 0.7049
Training Epoch: 45 [5120/50176]	Loss: 0.6257
Training Epoch: 45 [6144/50176]	Loss: 0.6548
Training Epoch: 45 [7168/50176]	Loss: 0.7095
Training Epoch: 45 [8192/50176]	Loss: 0.7331
Training Epoch: 45 [9216/50176]	Loss: 0.6683
Training Epoch: 45 [10240/50176]	Loss: 0.6995
Training Epoch: 45 [11264/50176]	Loss: 0.7482
Training Epoch: 45 [12288/50176]	Loss: 0.7482
Training Epoch: 45 [13312/50176]	Loss: 0.6987
Training Epoch: 45 [14336/50176]	Loss: 0.7128
Training Epoch: 45 [15360/50176]	Loss: 0.6940
Training Epoch: 45 [16384/50176]	Loss: 0.6840
Training Epoch: 45 [17408/50176]	Loss: 0.6386
Training Epoch: 45 [18432/50176]	Loss: 0.7637
Training Epoch: 45 [19456/50176]	Loss: 0.7379
Training Epoch: 45 [20480/50176]	Loss: 0.7012
Training Epoch: 45 [21504/50176]	Loss: 0.7385
Training Epoch: 45 [22528/50176]	Loss: 0.7136
Training Epoch: 45 [23552/50176]	Loss: 0.7196
Training Epoch: 45 [24576/50176]	Loss: 0.6656
Training Epoch: 45 [25600/50176]	Loss: 0.6800
Training Epoch: 45 [26624/50176]	Loss: 0.7174
Training Epoch: 45 [27648/50176]	Loss: 0.6977
Training Epoch: 45 [28672/50176]	Loss: 0.7468
Training Epoch: 45 [29696/50176]	Loss: 0.7118
Training Epoch: 45 [30720/50176]	Loss: 0.7184
Training Epoch: 45 [31744/50176]	Loss: 0.6955
Training Epoch: 45 [32768/50176]	Loss: 0.6953
Training Epoch: 45 [33792/50176]	Loss: 0.7536
Training Epoch: 45 [34816/50176]	Loss: 0.8171
Training Epoch: 45 [35840/50176]	Loss: 0.7701
Training Epoch: 45 [36864/50176]	Loss: 0.7519
Training Epoch: 45 [37888/50176]	Loss: 0.7753
Training Epoch: 45 [38912/50176]	Loss: 0.7486
Training Epoch: 45 [39936/50176]	Loss: 0.7629
Training Epoch: 45 [40960/50176]	Loss: 0.6869
Training Epoch: 45 [41984/50176]	Loss: 0.7168
Training Epoch: 45 [43008/50176]	Loss: 0.7935
Training Epoch: 45 [44032/50176]	Loss: 0.7440
Training Epoch: 45 [45056/50176]	Loss: 0.7794
Training Epoch: 45 [46080/50176]	Loss: 0.7681
Training Epoch: 45 [47104/50176]	Loss: 0.7384
Training Epoch: 45 [48128/50176]	Loss: 0.6994
Training Epoch: 45 [49152/50176]	Loss: 0.6806
Training Epoch: 45 [50176/50176]	Loss: 0.7474
2022-12-08 16:14:33.871 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:14:33,907 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.80 energy=542.90
2022-12-08 11:14:33,907 [ZeusDataLoader(train)] Up to epoch 46: time=2322.78, energy=341348.41, cost=373917.65
2022-12-08 11:14:33,908 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:14:33,908 [ZeusDataLoader(train)] Expected next epoch: time=2370.23, energy=348605.22, cost=381697.92
2022-12-08 11:14:33,909 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 0.0018, Accuracy: 0.5574
2022-12-08 11:14:34,059 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:14:34,060 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:14:34.064 [ZeusMonitor] Monitor started.
2022-12-08 16:14:34.064 [ZeusMonitor] Running indefinitely. 2022-12-08 16:14:34.064 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:14:34.064 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e47+gpu0.power.log
2022-12-08 11:15:18,452 [ZeusDataLoader(train)] train epoch 47 done: time=44.53 energy=6797.11
2022-12-08 11:15:18,455 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 0.6858
Training Epoch: 46 [2048/50176]	Loss: 0.7190
Training Epoch: 46 [3072/50176]	Loss: 0.7137
Training Epoch: 46 [4096/50176]	Loss: 0.6346
Training Epoch: 46 [5120/50176]	Loss: 0.6555
Training Epoch: 46 [6144/50176]	Loss: 0.6561
Training Epoch: 46 [7168/50176]	Loss: 0.6455
Training Epoch: 46 [8192/50176]	Loss: 0.6021
Training Epoch: 46 [9216/50176]	Loss: 0.6409
Training Epoch: 46 [10240/50176]	Loss: 0.6782
Training Epoch: 46 [11264/50176]	Loss: 0.6801
Training Epoch: 46 [12288/50176]	Loss: 0.6857
Training Epoch: 46 [13312/50176]	Loss: 0.6950
Training Epoch: 46 [14336/50176]	Loss: 0.6685
Training Epoch: 46 [15360/50176]	Loss: 0.6753
Training Epoch: 46 [16384/50176]	Loss: 0.6340
Training Epoch: 46 [17408/50176]	Loss: 0.6611
Training Epoch: 46 [18432/50176]	Loss: 0.6803
Training Epoch: 46 [19456/50176]	Loss: 0.6639
Training Epoch: 46 [20480/50176]	Loss: 0.6438
Training Epoch: 46 [21504/50176]	Loss: 0.7151
Training Epoch: 46 [22528/50176]	Loss: 0.7168
Training Epoch: 46 [23552/50176]	Loss: 0.7752
Training Epoch: 46 [24576/50176]	Loss: 0.7798
Training Epoch: 46 [25600/50176]	Loss: 0.7216
Training Epoch: 46 [26624/50176]	Loss: 0.7140
Training Epoch: 46 [27648/50176]	Loss: 0.7450
Training Epoch: 46 [28672/50176]	Loss: 0.6777
Training Epoch: 46 [29696/50176]	Loss: 0.6402
Training Epoch: 46 [30720/50176]	Loss: 0.6936
Training Epoch: 46 [31744/50176]	Loss: 0.7307
Training Epoch: 46 [32768/50176]	Loss: 0.6410
Training Epoch: 46 [33792/50176]	Loss: 0.7446
Training Epoch: 46 [34816/50176]	Loss: 0.7168
Training Epoch: 46 [35840/50176]	Loss: 0.6776
Training Epoch: 46 [36864/50176]	Loss: 0.6715
Training Epoch: 46 [37888/50176]	Loss: 0.6859
Training Epoch: 46 [38912/50176]	Loss: 0.7052
Training Epoch: 46 [39936/50176]	Loss: 0.7558
Training Epoch: 46 [40960/50176]	Loss: 0.7235
Training Epoch: 46 [41984/50176]	Loss: 0.7161
Training Epoch: 46 [43008/50176]	Loss: 0.6869
Training Epoch: 46 [44032/50176]	Loss: 0.6996
Training Epoch: 46 [45056/50176]	Loss: 0.7364
Training Epoch: 46 [46080/50176]	Loss: 0.6981
Training Epoch: 46 [47104/50176]	Loss: 0.7428
Training Epoch: 46 [48128/50176]	Loss: 0.7210
Training Epoch: 46 [49152/50176]	Loss: 0.7193
Training Epoch: 46 [50176/50176]	Loss: 0.7795
2022-12-08 16:15:22.197 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:15:22,216 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.75 energy=519.93
2022-12-08 11:15:22,217 [ZeusDataLoader(train)] Up to epoch 47: time=2371.07, energy=348665.45, cost=381801.30
2022-12-08 11:15:22,217 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:15:22,217 [ZeusDataLoader(train)] Expected next epoch: time=2418.52, energy=355922.25, cost=389581.58
2022-12-08 11:15:22,218 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 0.0020, Accuracy: 0.5337
2022-12-08 11:15:22,409 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:15:22,410 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:15:22.412 [ZeusMonitor] Monitor started.
2022-12-08 16:15:22.412 [ZeusMonitor] Running indefinitely. 2022-12-08 16:15:22.412 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:15:22.412 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e48+gpu0.power.log
2022-12-08 11:16:06,944 [ZeusDataLoader(train)] train epoch 48 done: time=44.72 energy=6817.29
2022-12-08 11:16:06,948 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 0.6713
Training Epoch: 47 [2048/50176]	Loss: 0.6235
Training Epoch: 47 [3072/50176]	Loss: 0.6471
Training Epoch: 47 [4096/50176]	Loss: 0.6265
Training Epoch: 47 [5120/50176]	Loss: 0.6060
Training Epoch: 47 [6144/50176]	Loss: 0.6344
Training Epoch: 47 [7168/50176]	Loss: 0.6487
Training Epoch: 47 [8192/50176]	Loss: 0.7177
Training Epoch: 47 [9216/50176]	Loss: 0.6505
Training Epoch: 47 [10240/50176]	Loss: 0.6549
Training Epoch: 47 [11264/50176]	Loss: 0.6253
Training Epoch: 47 [12288/50176]	Loss: 0.6633
Training Epoch: 47 [13312/50176]	Loss: 0.6426
Training Epoch: 47 [14336/50176]	Loss: 0.6912
Training Epoch: 47 [15360/50176]	Loss: 0.6703
Training Epoch: 47 [16384/50176]	Loss: 0.6281
Training Epoch: 47 [17408/50176]	Loss: 0.6149
Training Epoch: 47 [18432/50176]	Loss: 0.6386
Training Epoch: 47 [19456/50176]	Loss: 0.6986
Training Epoch: 47 [20480/50176]	Loss: 0.6648
Training Epoch: 47 [21504/50176]	Loss: 0.6655
Training Epoch: 47 [22528/50176]	Loss: 0.6093
Training Epoch: 47 [23552/50176]	Loss: 0.6207
Training Epoch: 47 [24576/50176]	Loss: 0.6516
Training Epoch: 47 [25600/50176]	Loss: 0.7191
Training Epoch: 47 [26624/50176]	Loss: 0.6756
Training Epoch: 47 [27648/50176]	Loss: 0.6669
Training Epoch: 47 [28672/50176]	Loss: 0.6756
Training Epoch: 47 [29696/50176]	Loss: 0.6616
Training Epoch: 47 [30720/50176]	Loss: 0.7007
Training Epoch: 47 [31744/50176]	Loss: 0.6923
Training Epoch: 47 [32768/50176]	Loss: 0.6682
Training Epoch: 47 [33792/50176]	Loss: 0.6952
Training Epoch: 47 [34816/50176]	Loss: 0.6747
Training Epoch: 47 [35840/50176]	Loss: 0.6813
Training Epoch: 47 [36864/50176]	Loss: 0.6133
Training Epoch: 47 [37888/50176]	Loss: 0.6412
Training Epoch: 47 [38912/50176]	Loss: 0.7120
Training Epoch: 47 [39936/50176]	Loss: 0.6939
Training Epoch: 47 [40960/50176]	Loss: 0.6613
Training Epoch: 47 [41984/50176]	Loss: 0.7075
Training Epoch: 47 [43008/50176]	Loss: 0.7219
Training Epoch: 47 [44032/50176]	Loss: 0.7323
Training Epoch: 47 [45056/50176]	Loss: 0.7148
Training Epoch: 47 [46080/50176]	Loss: 0.7194
Training Epoch: 47 [47104/50176]	Loss: 0.6405
Training Epoch: 47 [48128/50176]	Loss: 0.6689
Training Epoch: 47 [49152/50176]	Loss: 0.7383
Training Epoch: 47 [50176/50176]	Loss: 0.7598
2022-12-08 16:16:10.709 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:16:10,753 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.80 energy=539.00
2022-12-08 11:16:10,754 [ZeusDataLoader(train)] Up to epoch 48: time=2419.58, energy=356021.74, cost=389724.44
2022-12-08 11:16:10,754 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:16:10,754 [ZeusDataLoader(train)] Expected next epoch: time=2467.03, energy=363278.55, cost=397504.71
2022-12-08 11:16:10,755 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 0.0018, Accuracy: 0.5623
2022-12-08 11:16:10,940 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:16:10,941 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:16:10.943 [ZeusMonitor] Monitor started.
2022-12-08 16:16:10.943 [ZeusMonitor] Running indefinitely. 2022-12-08 16:16:10.943 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:16:10.943 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e49+gpu0.power.log
2022-12-08 11:16:55,399 [ZeusDataLoader(train)] train epoch 49 done: time=44.64 energy=6780.95
2022-12-08 11:16:55,402 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 0.6206
Training Epoch: 48 [2048/50176]	Loss: 0.5777
Training Epoch: 48 [3072/50176]	Loss: 0.5365
Training Epoch: 48 [4096/50176]	Loss: 0.5821
Training Epoch: 48 [5120/50176]	Loss: 0.5591
Training Epoch: 48 [6144/50176]	Loss: 0.6048
Training Epoch: 48 [7168/50176]	Loss: 0.5869
Training Epoch: 48 [8192/50176]	Loss: 0.6176
Training Epoch: 48 [9216/50176]	Loss: 0.6026
Training Epoch: 48 [10240/50176]	Loss: 0.6615
Training Epoch: 48 [11264/50176]	Loss: 0.6113
Training Epoch: 48 [12288/50176]	Loss: 0.6502
Training Epoch: 48 [13312/50176]	Loss: 0.6490
Training Epoch: 48 [14336/50176]	Loss: 0.7316
Training Epoch: 48 [15360/50176]	Loss: 0.6984
Training Epoch: 48 [16384/50176]	Loss: 0.5957
Training Epoch: 48 [17408/50176]	Loss: 0.6232
Training Epoch: 48 [18432/50176]	Loss: 0.6542
Training Epoch: 48 [19456/50176]	Loss: 0.6736
Training Epoch: 48 [20480/50176]	Loss: 0.6424
Training Epoch: 48 [21504/50176]	Loss: 0.6381
Training Epoch: 48 [22528/50176]	Loss: 0.6435
Training Epoch: 48 [23552/50176]	Loss: 0.6496
Training Epoch: 48 [24576/50176]	Loss: 0.6346
Training Epoch: 48 [25600/50176]	Loss: 0.6378
Training Epoch: 48 [26624/50176]	Loss: 0.6492
Training Epoch: 48 [27648/50176]	Loss: 0.6809
Training Epoch: 48 [28672/50176]	Loss: 0.6377
Training Epoch: 48 [29696/50176]	Loss: 0.6496
Training Epoch: 48 [30720/50176]	Loss: 0.6807
Training Epoch: 48 [31744/50176]	Loss: 0.6545
Training Epoch: 48 [32768/50176]	Loss: 0.6870
Training Epoch: 48 [33792/50176]	Loss: 0.7436
Training Epoch: 48 [34816/50176]	Loss: 0.6459
Training Epoch: 48 [35840/50176]	Loss: 0.6403
Training Epoch: 48 [36864/50176]	Loss: 0.6484
Training Epoch: 48 [37888/50176]	Loss: 0.6460
Training Epoch: 48 [38912/50176]	Loss: 0.6294
Training Epoch: 48 [39936/50176]	Loss: 0.6329
Training Epoch: 48 [40960/50176]	Loss: 0.6593
Training Epoch: 48 [41984/50176]	Loss: 0.6690
Training Epoch: 48 [43008/50176]	Loss: 0.7726
Training Epoch: 48 [44032/50176]	Loss: 0.6651
Training Epoch: 48 [45056/50176]	Loss: 0.6889
Training Epoch: 48 [46080/50176]	Loss: 0.6799
Training Epoch: 48 [47104/50176]	Loss: 0.6694
Training Epoch: 48 [48128/50176]	Loss: 0.6440
Training Epoch: 48 [49152/50176]	Loss: 0.6638
Training Epoch: 48 [50176/50176]	Loss: 0.6502
2022-12-08 16:16:59.184 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:16:59,228 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.82 energy=533.62
2022-12-08 11:16:59,228 [ZeusDataLoader(train)] Up to epoch 49: time=2468.04, energy=363336.31, cost=397621.31
2022-12-08 11:16:59,228 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:16:59,228 [ZeusDataLoader(train)] Expected next epoch: time=2515.49, energy=370593.12, cost=405401.58
2022-12-08 11:16:59,229 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 0.0018, Accuracy: 0.5702
2022-12-08 11:16:59,416 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:16:59,417 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:16:59.419 [ZeusMonitor] Monitor started.
2022-12-08 16:16:59.419 [ZeusMonitor] Running indefinitely. 2022-12-08 16:16:59.419 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:16:59.419 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e50+gpu0.power.log
2022-12-08 11:17:43,917 [ZeusDataLoader(train)] train epoch 50 done: time=44.68 energy=6801.18
2022-12-08 11:17:43,920 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 0.5257
Training Epoch: 49 [2048/50176]	Loss: 0.5554
Training Epoch: 49 [3072/50176]	Loss: 0.5564
Training Epoch: 49 [4096/50176]	Loss: 0.5500
Training Epoch: 49 [5120/50176]	Loss: 0.6148
Training Epoch: 49 [6144/50176]	Loss: 0.5499
Training Epoch: 49 [7168/50176]	Loss: 0.5296
Training Epoch: 49 [8192/50176]	Loss: 0.5366
Training Epoch: 49 [9216/50176]	Loss: 0.5841
Training Epoch: 49 [10240/50176]	Loss: 0.5542
Training Epoch: 49 [11264/50176]	Loss: 0.6324
Training Epoch: 49 [12288/50176]	Loss: 0.6149
Training Epoch: 49 [13312/50176]	Loss: 0.6092
Training Epoch: 49 [14336/50176]	Loss: 0.6010
Training Epoch: 49 [15360/50176]	Loss: 0.6278
Training Epoch: 49 [16384/50176]	Loss: 0.6074
Training Epoch: 49 [17408/50176]	Loss: 0.5731
Training Epoch: 49 [18432/50176]	Loss: 0.6418
Training Epoch: 49 [19456/50176]	Loss: 0.6189
Training Epoch: 49 [20480/50176]	Loss: 0.6036
Training Epoch: 49 [21504/50176]	Loss: 0.5852
Training Epoch: 49 [22528/50176]	Loss: 0.6090
Training Epoch: 49 [23552/50176]	Loss: 0.5956
Training Epoch: 49 [24576/50176]	Loss: 0.6158
Training Epoch: 49 [25600/50176]	Loss: 0.6657
Training Epoch: 49 [26624/50176]	Loss: 0.6458
Training Epoch: 49 [27648/50176]	Loss: 0.6756
Training Epoch: 49 [28672/50176]	Loss: 0.6129
Training Epoch: 49 [29696/50176]	Loss: 0.6170
Training Epoch: 49 [30720/50176]	Loss: 0.6262
Training Epoch: 49 [31744/50176]	Loss: 0.6612
Training Epoch: 49 [32768/50176]	Loss: 0.6298
Training Epoch: 49 [33792/50176]	Loss: 0.6132
Training Epoch: 49 [34816/50176]	Loss: 0.6483
Training Epoch: 49 [35840/50176]	Loss: 0.6727
Training Epoch: 49 [36864/50176]	Loss: 0.6697
Training Epoch: 49 [37888/50176]	Loss: 0.6658
Training Epoch: 49 [38912/50176]	Loss: 0.7278
Training Epoch: 49 [39936/50176]	Loss: 0.6605
Training Epoch: 49 [40960/50176]	Loss: 0.5884
Training Epoch: 49 [41984/50176]	Loss: 0.7473
Training Epoch: 49 [43008/50176]	Loss: 0.6780
Training Epoch: 49 [44032/50176]	Loss: 0.6380
Training Epoch: 49 [45056/50176]	Loss: 0.6951
Training Epoch: 49 [46080/50176]	Loss: 0.6655
Training Epoch: 49 [47104/50176]	Loss: 0.6549
Training Epoch: 49 [48128/50176]	Loss: 0.6312
Training Epoch: 49 [49152/50176]	Loss: 0.6787
Training Epoch: 49 [50176/50176]	Loss: 0.6557
2022-12-08 16:17:47.686 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:17:47,719 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.79 energy=523.87
2022-12-08 11:17:47,719 [ZeusDataLoader(train)] Up to epoch 50: time=2516.51, energy=370661.35, cost=405524.87
2022-12-08 11:17:47,719 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:17:47,719 [ZeusDataLoader(train)] Expected next epoch: time=2563.95, energy=377918.16, cost=413305.14
2022-12-08 11:17:47,720 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 0.0018, Accuracy: 0.5587
2022-12-08 11:17:47,868 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:17:47,869 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:17:47.871 [ZeusMonitor] Monitor started.
2022-12-08 16:17:47.871 [ZeusMonitor] Running indefinitely. 2022-12-08 16:17:47.871 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:17:47.871 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e51+gpu0.power.log
2022-12-08 11:18:32,278 [ZeusDataLoader(train)] train epoch 51 done: time=44.55 energy=6799.27
2022-12-08 11:18:32,282 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 0.5682
Training Epoch: 50 [2048/50176]	Loss: 0.5351
Training Epoch: 50 [3072/50176]	Loss: 0.6155
Training Epoch: 50 [4096/50176]	Loss: 0.6190
Training Epoch: 50 [5120/50176]	Loss: 0.6336
Training Epoch: 50 [6144/50176]	Loss: 0.6427
Training Epoch: 50 [7168/50176]	Loss: 0.5920
Training Epoch: 50 [8192/50176]	Loss: 0.6126
Training Epoch: 50 [9216/50176]	Loss: 0.5372
Training Epoch: 50 [10240/50176]	Loss: 0.5535
Training Epoch: 50 [11264/50176]	Loss: 0.5492
Training Epoch: 50 [12288/50176]	Loss: 0.5969
Training Epoch: 50 [13312/50176]	Loss: 0.5805
Training Epoch: 50 [14336/50176]	Loss: 0.5647
Training Epoch: 50 [15360/50176]	Loss: 0.5671
Training Epoch: 50 [16384/50176]	Loss: 0.5763
Training Epoch: 50 [17408/50176]	Loss: 0.5953
Training Epoch: 50 [18432/50176]	Loss: 0.6000
Training Epoch: 50 [19456/50176]	Loss: 0.5908
Training Epoch: 50 [20480/50176]	Loss: 0.6146
Training Epoch: 50 [21504/50176]	Loss: 0.5833
Training Epoch: 50 [22528/50176]	Loss: 0.5925
Training Epoch: 50 [23552/50176]	Loss: 0.5783
Training Epoch: 50 [24576/50176]	Loss: 0.5729
Training Epoch: 50 [25600/50176]	Loss: 0.5964
Training Epoch: 50 [26624/50176]	Loss: 0.6260
Training Epoch: 50 [27648/50176]	Loss: 0.6282
Training Epoch: 50 [28672/50176]	Loss: 0.6524
Training Epoch: 50 [29696/50176]	Loss: 0.6161
Training Epoch: 50 [30720/50176]	Loss: 0.6532
Training Epoch: 50 [31744/50176]	Loss: 0.5223
Training Epoch: 50 [32768/50176]	Loss: 0.5931
Training Epoch: 50 [33792/50176]	Loss: 0.5347
Training Epoch: 50 [34816/50176]	Loss: 0.5962
Training Epoch: 50 [35840/50176]	Loss: 0.6385
Training Epoch: 50 [36864/50176]	Loss: 0.6816
Training Epoch: 50 [37888/50176]	Loss: 0.6231
Training Epoch: 50 [38912/50176]	Loss: 0.6028
Training Epoch: 50 [39936/50176]	Loss: 0.6519
Training Epoch: 50 [40960/50176]	Loss: 0.6820
Training Epoch: 50 [41984/50176]	Loss: 0.5690
Training Epoch: 50 [43008/50176]	Loss: 0.6347
Training Epoch: 50 [44032/50176]	Loss: 0.6625
Training Epoch: 50 [45056/50176]	Loss: 0.6667
Training Epoch: 50 [46080/50176]	Loss: 0.6275
Training Epoch: 50 [47104/50176]	Loss: 0.6459
Training Epoch: 50 [48128/50176]	Loss: 0.6423
Training Epoch: 50 [49152/50176]	Loss: 0.5599
Training Epoch: 50 [50176/50176]	Loss: 0.6122
2022-12-08 16:18:36.030 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:18:36,043 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.75 energy=518.54
2022-12-08 11:18:36,043 [ZeusDataLoader(train)] Up to epoch 51: time=2564.81, energy=377979.17, cost=413410.17
2022-12-08 11:18:36,044 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:18:36,044 [ZeusDataLoader(train)] Expected next epoch: time=2612.26, energy=385235.98, cost=421190.44
2022-12-08 11:18:36,045 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 0.0018, Accuracy: 0.5704
2022-12-08 11:18:36,237 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:18:36,238 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:18:36.240 [ZeusMonitor] Monitor started.
2022-12-08 16:18:36.240 [ZeusMonitor] Running indefinitely. 2022-12-08 16:18:36.252 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:18:36.252 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e52+gpu0.power.log
2022-12-08 11:19:20,723 [ZeusDataLoader(train)] train epoch 52 done: time=44.67 energy=6789.67
2022-12-08 11:19:20,726 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 0.5378
Training Epoch: 51 [2048/50176]	Loss: 0.5651
Training Epoch: 51 [3072/50176]	Loss: 0.5280
Training Epoch: 51 [4096/50176]	Loss: 0.5361
Training Epoch: 51 [5120/50176]	Loss: 0.5119
Training Epoch: 51 [6144/50176]	Loss: 0.5264
Training Epoch: 51 [7168/50176]	Loss: 0.5612
Training Epoch: 51 [8192/50176]	Loss: 0.5396
Training Epoch: 51 [9216/50176]	Loss: 0.5347
Training Epoch: 51 [10240/50176]	Loss: 0.5218
Training Epoch: 51 [11264/50176]	Loss: 0.5361
Training Epoch: 51 [12288/50176]	Loss: 0.6029
Training Epoch: 51 [13312/50176]	Loss: 0.5082
Training Epoch: 51 [14336/50176]	Loss: 0.4658
Training Epoch: 51 [15360/50176]	Loss: 0.5312
Training Epoch: 51 [16384/50176]	Loss: 0.5959
Training Epoch: 51 [17408/50176]	Loss: 0.6101
Training Epoch: 51 [18432/50176]	Loss: 0.6040
Training Epoch: 51 [19456/50176]	Loss: 0.5587
Training Epoch: 51 [20480/50176]	Loss: 0.5704
Training Epoch: 51 [21504/50176]	Loss: 0.5403
Training Epoch: 51 [22528/50176]	Loss: 0.5695
Training Epoch: 51 [23552/50176]	Loss: 0.5819
Training Epoch: 51 [24576/50176]	Loss: 0.5886
Training Epoch: 51 [25600/50176]	Loss: 0.6073
Training Epoch: 51 [26624/50176]	Loss: 0.6250
Training Epoch: 51 [27648/50176]	Loss: 0.6165
Training Epoch: 51 [28672/50176]	Loss: 0.6014
Training Epoch: 51 [29696/50176]	Loss: 0.6208
Training Epoch: 51 [30720/50176]	Loss: 0.5662
Training Epoch: 51 [31744/50176]	Loss: 0.5877
Training Epoch: 51 [32768/50176]	Loss: 0.6048
Training Epoch: 51 [33792/50176]	Loss: 0.6441
Training Epoch: 51 [34816/50176]	Loss: 0.5578
Training Epoch: 51 [35840/50176]	Loss: 0.5764
Training Epoch: 51 [36864/50176]	Loss: 0.5289
Training Epoch: 51 [37888/50176]	Loss: 0.6002
Training Epoch: 51 [38912/50176]	Loss: 0.5973
Training Epoch: 51 [39936/50176]	Loss: 0.5783
Training Epoch: 51 [40960/50176]	Loss: 0.6408
Training Epoch: 51 [41984/50176]	Loss: 0.6373
Training Epoch: 51 [43008/50176]	Loss: 0.6097
Training Epoch: 51 [44032/50176]	Loss: 0.6029
Training Epoch: 51 [45056/50176]	Loss: 0.6361
Training Epoch: 51 [46080/50176]	Loss: 0.6606
Training Epoch: 51 [47104/50176]	Loss: 0.6865
Training Epoch: 51 [48128/50176]	Loss: 0.6455
Training Epoch: 51 [49152/50176]	Loss: 0.5850
Training Epoch: 51 [50176/50176]	Loss: 0.6311
2022-12-08 16:19:24.433 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:19:24,469 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.73 energy=520.92
2022-12-08 11:19:24,469 [ZeusDataLoader(train)] Up to epoch 52: time=2613.21, energy=385289.75, cost=421300.74
2022-12-08 11:19:24,469 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:19:24,469 [ZeusDataLoader(train)] Expected next epoch: time=2660.66, energy=392546.56, cost=429081.01
2022-12-08 11:19:24,470 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 0.0019, Accuracy: 0.5598
2022-12-08 11:19:24,652 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:19:24,653 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:19:24.655 [ZeusMonitor] Monitor started.
2022-12-08 16:19:24.655 [ZeusMonitor] Running indefinitely. 2022-12-08 16:19:24.655 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:19:24.655 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e53+gpu0.power.log
2022-12-08 11:20:09,130 [ZeusDataLoader(train)] train epoch 53 done: time=44.65 energy=6801.51
2022-12-08 11:20:09,133 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 0.4882
Training Epoch: 52 [2048/50176]	Loss: 0.4695
Training Epoch: 52 [3072/50176]	Loss: 0.4936
Training Epoch: 52 [4096/50176]	Loss: 0.4954
Training Epoch: 52 [5120/50176]	Loss: 0.5107
Training Epoch: 52 [6144/50176]	Loss: 0.4523
Training Epoch: 52 [7168/50176]	Loss: 0.4621
Training Epoch: 52 [8192/50176]	Loss: 0.5353
Training Epoch: 52 [9216/50176]	Loss: 0.5497
Training Epoch: 52 [10240/50176]	Loss: 0.5401
Training Epoch: 52 [11264/50176]	Loss: 0.5306
Training Epoch: 52 [12288/50176]	Loss: 0.5326
Training Epoch: 52 [13312/50176]	Loss: 0.5292
Training Epoch: 52 [14336/50176]	Loss: 0.5093
Training Epoch: 52 [15360/50176]	Loss: 0.4903
Training Epoch: 52 [16384/50176]	Loss: 0.5642
Training Epoch: 52 [17408/50176]	Loss: 0.5027
Training Epoch: 52 [18432/50176]	Loss: 0.5865
Training Epoch: 52 [19456/50176]	Loss: 0.4588
Training Epoch: 52 [20480/50176]	Loss: 0.5336
Training Epoch: 52 [21504/50176]	Loss: 0.5341
Training Epoch: 52 [22528/50176]	Loss: 0.5774
Training Epoch: 52 [23552/50176]	Loss: 0.5703
Training Epoch: 52 [24576/50176]	Loss: 0.5800
Training Epoch: 52 [25600/50176]	Loss: 0.5597
Training Epoch: 52 [26624/50176]	Loss: 0.5737
Training Epoch: 52 [27648/50176]	Loss: 0.6177
Training Epoch: 52 [28672/50176]	Loss: 0.5854
Training Epoch: 52 [29696/50176]	Loss: 0.5532
Training Epoch: 52 [30720/50176]	Loss: 0.4959
Training Epoch: 52 [31744/50176]	Loss: 0.5106
Training Epoch: 52 [32768/50176]	Loss: 0.5349
Training Epoch: 52 [33792/50176]	Loss: 0.5497
Training Epoch: 52 [34816/50176]	Loss: 0.5531
Training Epoch: 52 [35840/50176]	Loss: 0.5705
Training Epoch: 52 [36864/50176]	Loss: 0.5868
Training Epoch: 52 [37888/50176]	Loss: 0.5958
Training Epoch: 52 [38912/50176]	Loss: 0.5717
Training Epoch: 52 [39936/50176]	Loss: 0.5556
Training Epoch: 52 [40960/50176]	Loss: 0.5947
Training Epoch: 52 [41984/50176]	Loss: 0.5918
Training Epoch: 52 [43008/50176]	Loss: 0.5306
Training Epoch: 52 [44032/50176]	Loss: 0.5902
Training Epoch: 52 [45056/50176]	Loss: 0.6044
Training Epoch: 52 [46080/50176]	Loss: 0.6219
Training Epoch: 52 [47104/50176]	Loss: 0.6352
Training Epoch: 52 [48128/50176]	Loss: 0.6532
Training Epoch: 52 [49152/50176]	Loss: 0.5806
Training Epoch: 52 [50176/50176]	Loss: 0.6155
2022-12-08 16:20:12.910 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:20:12,936 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.79 energy=522.31
2022-12-08 11:20:12,937 [ZeusDataLoader(train)] Up to epoch 53: time=2661.66, energy=392613.58, cost=429201.62
2022-12-08 11:20:12,937 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:20:12,937 [ZeusDataLoader(train)] Expected next epoch: time=2709.11, energy=399870.39, cost=436981.89
2022-12-08 11:20:12,938 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0019, Accuracy: 0.5656
2022-12-08 11:20:13,125 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:20:13,126 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:20:13.128 [ZeusMonitor] Monitor started.
2022-12-08 16:20:13.140 [ZeusMonitor] Running indefinitely. 2022-12-08 16:20:13.140 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:20:13.140 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e54+gpu0.power.log
2022-12-08 11:20:57,554 [ZeusDataLoader(train)] train epoch 54 done: time=44.61 energy=6785.70
2022-12-08 11:20:57,557 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 0.4814
Training Epoch: 53 [2048/50176]	Loss: 0.4737
Training Epoch: 53 [3072/50176]	Loss: 0.4488
Training Epoch: 53 [4096/50176]	Loss: 0.4805
Training Epoch: 53 [5120/50176]	Loss: 0.5117
Training Epoch: 53 [6144/50176]	Loss: 0.5020
Training Epoch: 53 [7168/50176]	Loss: 0.5526
Training Epoch: 53 [8192/50176]	Loss: 0.5508
Training Epoch: 53 [9216/50176]	Loss: 0.5181
Training Epoch: 53 [10240/50176]	Loss: 0.5666
Training Epoch: 53 [11264/50176]	Loss: 0.5030
Training Epoch: 53 [12288/50176]	Loss: 0.4773
Training Epoch: 53 [13312/50176]	Loss: 0.5062
Training Epoch: 53 [14336/50176]	Loss: 0.5270
Training Epoch: 53 [15360/50176]	Loss: 0.4839
Training Epoch: 53 [16384/50176]	Loss: 0.5280
Training Epoch: 53 [17408/50176]	Loss: 0.5337
Training Epoch: 53 [18432/50176]	Loss: 0.4990
Training Epoch: 53 [19456/50176]	Loss: 0.5586
Training Epoch: 53 [20480/50176]	Loss: 0.4643
Training Epoch: 53 [21504/50176]	Loss: 0.5328
Training Epoch: 53 [22528/50176]	Loss: 0.5014
Training Epoch: 53 [23552/50176]	Loss: 0.4614
Training Epoch: 53 [24576/50176]	Loss: 0.5440
Training Epoch: 53 [25600/50176]	Loss: 0.4808
Training Epoch: 53 [26624/50176]	Loss: 0.4758
Training Epoch: 53 [27648/50176]	Loss: 0.5663
Training Epoch: 53 [28672/50176]	Loss: 0.5261
Training Epoch: 53 [29696/50176]	Loss: 0.5930
Training Epoch: 53 [30720/50176]	Loss: 0.6028
Training Epoch: 53 [31744/50176]	Loss: 0.5743
Training Epoch: 53 [32768/50176]	Loss: 0.5664
Training Epoch: 53 [33792/50176]	Loss: 0.4871
Training Epoch: 53 [34816/50176]	Loss: 0.5388
Training Epoch: 53 [35840/50176]	Loss: 0.5227
Training Epoch: 53 [36864/50176]	Loss: 0.5668
Training Epoch: 53 [37888/50176]	Loss: 0.6005
Training Epoch: 53 [38912/50176]	Loss: 0.5960
Training Epoch: 53 [39936/50176]	Loss: 0.5663
Training Epoch: 53 [40960/50176]	Loss: 0.5616
Training Epoch: 53 [41984/50176]	Loss: 0.5387
Training Epoch: 53 [43008/50176]	Loss: 0.5887
Training Epoch: 53 [44032/50176]	Loss: 0.5781
Training Epoch: 53 [45056/50176]	Loss: 0.6058
Training Epoch: 53 [46080/50176]	Loss: 0.6003
Training Epoch: 53 [47104/50176]	Loss: 0.5425
Training Epoch: 53 [48128/50176]	Loss: 0.5496
Training Epoch: 53 [49152/50176]	Loss: 0.5547
Training Epoch: 53 [50176/50176]	Loss: 0.6419
2022-12-08 16:21:01.335 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:21:01,377 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.81 energy=540.27
2022-12-08 11:21:01,378 [ZeusDataLoader(train)] Up to epoch 54: time=2710.07, energy=399939.55, cost=437101.24
2022-12-08 11:21:01,378 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:21:01,378 [ZeusDataLoader(train)] Expected next epoch: time=2757.52, energy=407196.36, cost=444881.51
2022-12-08 11:21:01,379 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 0.0020, Accuracy: 0.5460
2022-12-08 11:21:01,569 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:21:01,570 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:21:01.572 [ZeusMonitor] Monitor started.
2022-12-08 16:21:01.572 [ZeusMonitor] Running indefinitely. 2022-12-08 16:21:01.572 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:21:01.572 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e55+gpu0.power.log
2022-12-08 11:21:46,030 [ZeusDataLoader(train)] train epoch 55 done: time=44.64 energy=6775.70
2022-12-08 11:21:46,034 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 0.5468
Training Epoch: 54 [2048/50176]	Loss: 0.5413
Training Epoch: 54 [3072/50176]	Loss: 0.4730
Training Epoch: 54 [4096/50176]	Loss: 0.4532
Training Epoch: 54 [5120/50176]	Loss: 0.4390
Training Epoch: 54 [6144/50176]	Loss: 0.4635
Training Epoch: 54 [7168/50176]	Loss: 0.4336
Training Epoch: 54 [8192/50176]	Loss: 0.4910
Training Epoch: 54 [9216/50176]	Loss: 0.4503
Training Epoch: 54 [10240/50176]	Loss: 0.4895
Training Epoch: 54 [11264/50176]	Loss: 0.5445
Training Epoch: 54 [12288/50176]	Loss: 0.5086
Training Epoch: 54 [13312/50176]	Loss: 0.5134
Training Epoch: 54 [14336/50176]	Loss: 0.4962
Training Epoch: 54 [15360/50176]	Loss: 0.5269
Training Epoch: 54 [16384/50176]	Loss: 0.4565
Training Epoch: 54 [17408/50176]	Loss: 0.5429
Training Epoch: 54 [18432/50176]	Loss: 0.4909
Training Epoch: 54 [19456/50176]	Loss: 0.5440
Training Epoch: 54 [20480/50176]	Loss: 0.5147
Training Epoch: 54 [21504/50176]	Loss: 0.5411
Training Epoch: 54 [22528/50176]	Loss: 0.5488
Training Epoch: 54 [23552/50176]	Loss: 0.4638
Training Epoch: 54 [24576/50176]	Loss: 0.5047
Training Epoch: 54 [25600/50176]	Loss: 0.5339
Training Epoch: 54 [26624/50176]	Loss: 0.5307
Training Epoch: 54 [27648/50176]	Loss: 0.5511
Training Epoch: 54 [28672/50176]	Loss: 0.5576
Training Epoch: 54 [29696/50176]	Loss: 0.4995
Training Epoch: 54 [30720/50176]	Loss: 0.4879
Training Epoch: 54 [31744/50176]	Loss: 0.5750
Training Epoch: 54 [32768/50176]	Loss: 0.5160
Training Epoch: 54 [33792/50176]	Loss: 0.5653
Training Epoch: 54 [34816/50176]	Loss: 0.5854
Training Epoch: 54 [35840/50176]	Loss: 0.6521
Training Epoch: 54 [36864/50176]	Loss: 0.5267
Training Epoch: 54 [37888/50176]	Loss: 0.6125
Training Epoch: 54 [38912/50176]	Loss: 0.5698
Training Epoch: 54 [39936/50176]	Loss: 0.5576
Training Epoch: 54 [40960/50176]	Loss: 0.5879
Training Epoch: 54 [41984/50176]	Loss: 0.5974
Training Epoch: 54 [43008/50176]	Loss: 0.6334
Training Epoch: 54 [44032/50176]	Loss: 0.5906
Training Epoch: 54 [45056/50176]	Loss: 0.5662
Training Epoch: 54 [46080/50176]	Loss: 0.5812
Training Epoch: 54 [47104/50176]	Loss: 0.5563
Training Epoch: 54 [48128/50176]	Loss: 0.5232
Training Epoch: 54 [49152/50176]	Loss: 0.5232
Training Epoch: 54 [50176/50176]	Loss: 0.5478
2022-12-08 16:21:49.824 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:21:49,856 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.81 energy=541.23
2022-12-08 11:21:49,856 [ZeusDataLoader(train)] Up to epoch 55: time=2758.53, energy=407256.48, cost=444999.51
2022-12-08 11:21:49,856 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:21:49,856 [ZeusDataLoader(train)] Expected next epoch: time=2805.98, energy=414513.29, cost=452779.78
2022-12-08 11:21:49,857 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 0.0019, Accuracy: 0.5684
2022-12-08 11:21:50,036 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:21:50,037 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:21:50.039 [ZeusMonitor] Monitor started.
2022-12-08 16:21:50.039 [ZeusMonitor] Running indefinitely. 2022-12-08 16:21:50.039 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:21:50.039 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e56+gpu0.power.log
2022-12-08 11:22:34,698 [ZeusDataLoader(train)] train epoch 56 done: time=44.83 energy=6809.76
2022-12-08 11:22:34,702 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 0.4361
Training Epoch: 55 [2048/50176]	Loss: 0.4494
Training Epoch: 55 [3072/50176]	Loss: 0.4545
Training Epoch: 55 [4096/50176]	Loss: 0.4231
Training Epoch: 55 [5120/50176]	Loss: 0.4281
Training Epoch: 55 [6144/50176]	Loss: 0.4108
Training Epoch: 55 [7168/50176]	Loss: 0.5063
Training Epoch: 55 [8192/50176]	Loss: 0.4354
Training Epoch: 55 [9216/50176]	Loss: 0.4460
Training Epoch: 55 [10240/50176]	Loss: 0.4513
Training Epoch: 55 [11264/50176]	Loss: 0.5091
Training Epoch: 55 [12288/50176]	Loss: 0.4426
Training Epoch: 55 [13312/50176]	Loss: 0.4035
Training Epoch: 55 [14336/50176]	Loss: 0.5133
Training Epoch: 55 [15360/50176]	Loss: 0.4543
Training Epoch: 55 [16384/50176]	Loss: 0.4790
Training Epoch: 55 [17408/50176]	Loss: 0.4491
Training Epoch: 55 [18432/50176]	Loss: 0.4350
Training Epoch: 55 [19456/50176]	Loss: 0.4878
Training Epoch: 55 [20480/50176]	Loss: 0.4978
Training Epoch: 55 [21504/50176]	Loss: 0.5005
Training Epoch: 55 [22528/50176]	Loss: 0.4946
Training Epoch: 55 [23552/50176]	Loss: 0.5182
Training Epoch: 55 [24576/50176]	Loss: 0.5439
Training Epoch: 55 [25600/50176]	Loss: 0.4570
Training Epoch: 55 [26624/50176]	Loss: 0.5106
Training Epoch: 55 [27648/50176]	Loss: 0.5022
Training Epoch: 55 [28672/50176]	Loss: 0.4936
Training Epoch: 55 [29696/50176]	Loss: 0.5608
Training Epoch: 55 [30720/50176]	Loss: 0.5156
Training Epoch: 55 [31744/50176]	Loss: 0.5039
Training Epoch: 55 [32768/50176]	Loss: 0.5360
Training Epoch: 55 [33792/50176]	Loss: 0.5413
Training Epoch: 55 [34816/50176]	Loss: 0.5035
Training Epoch: 55 [35840/50176]	Loss: 0.5219
Training Epoch: 55 [36864/50176]	Loss: 0.5741
Training Epoch: 55 [37888/50176]	Loss: 0.6011
Training Epoch: 55 [38912/50176]	Loss: 0.5384
Training Epoch: 55 [39936/50176]	Loss: 0.5299
Training Epoch: 55 [40960/50176]	Loss: 0.4997
Training Epoch: 55 [41984/50176]	Loss: 0.5742
Training Epoch: 55 [43008/50176]	Loss: 0.5046
Training Epoch: 55 [44032/50176]	Loss: 0.5546
Training Epoch: 55 [45056/50176]	Loss: 0.5834
Training Epoch: 55 [46080/50176]	Loss: 0.5381
Training Epoch: 55 [47104/50176]	Loss: 0.5190
Training Epoch: 55 [48128/50176]	Loss: 0.5119
Training Epoch: 55 [49152/50176]	Loss: 0.5546
Training Epoch: 55 [50176/50176]	Loss: 0.5224
2022-12-08 16:22:38.491 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:22:38,518 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.81 energy=537.77
2022-12-08 11:22:38,518 [ZeusDataLoader(train)] Up to epoch 56: time=2807.17, energy=414604.00, cost=452929.17
2022-12-08 11:22:38,519 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:22:38,519 [ZeusDataLoader(train)] Expected next epoch: time=2854.62, energy=421860.81, cost=460709.45
2022-12-08 11:22:38,520 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0019, Accuracy: 0.5735
2022-12-08 11:22:38,708 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:22:38,709 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:22:38.714 [ZeusMonitor] Monitor started.
2022-12-08 16:22:38.714 [ZeusMonitor] Running indefinitely. 2022-12-08 16:22:38.714 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:22:38.714 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e57+gpu0.power.log
2022-12-08 11:23:23,134 [ZeusDataLoader(train)] train epoch 57 done: time=44.61 energy=6794.34
2022-12-08 11:23:23,138 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 0.4522
Training Epoch: 56 [2048/50176]	Loss: 0.3855
Training Epoch: 56 [3072/50176]	Loss: 0.3962
Training Epoch: 56 [4096/50176]	Loss: 0.4202
Training Epoch: 56 [5120/50176]	Loss: 0.4467
Training Epoch: 56 [6144/50176]	Loss: 0.3894
Training Epoch: 56 [7168/50176]	Loss: 0.4381
Training Epoch: 56 [8192/50176]	Loss: 0.4135
Training Epoch: 56 [9216/50176]	Loss: 0.4059
Training Epoch: 56 [10240/50176]	Loss: 0.4486
Training Epoch: 56 [11264/50176]	Loss: 0.4178
Training Epoch: 56 [12288/50176]	Loss: 0.4488
Training Epoch: 56 [13312/50176]	Loss: 0.5167
Training Epoch: 56 [14336/50176]	Loss: 0.4526
Training Epoch: 56 [15360/50176]	Loss: 0.4625
Training Epoch: 56 [16384/50176]	Loss: 0.4655
Training Epoch: 56 [17408/50176]	Loss: 0.4840
Training Epoch: 56 [18432/50176]	Loss: 0.5123
Training Epoch: 56 [19456/50176]	Loss: 0.4733
Training Epoch: 56 [20480/50176]	Loss: 0.4777
Training Epoch: 56 [21504/50176]	Loss: 0.4901
Training Epoch: 56 [22528/50176]	Loss: 0.5714
Training Epoch: 56 [23552/50176]	Loss: 0.5104
Training Epoch: 56 [24576/50176]	Loss: 0.5136
Training Epoch: 56 [25600/50176]	Loss: 0.4658
Training Epoch: 56 [26624/50176]	Loss: 0.5034
Training Epoch: 56 [27648/50176]	Loss: 0.4618
Training Epoch: 56 [28672/50176]	Loss: 0.5160
Training Epoch: 56 [29696/50176]	Loss: 0.4517
Training Epoch: 56 [30720/50176]	Loss: 0.5527
Training Epoch: 56 [31744/50176]	Loss: 0.5001
Training Epoch: 56 [32768/50176]	Loss: 0.5069
Training Epoch: 56 [33792/50176]	Loss: 0.5002
Training Epoch: 56 [34816/50176]	Loss: 0.5720
Training Epoch: 56 [35840/50176]	Loss: 0.5426
Training Epoch: 56 [36864/50176]	Loss: 0.4617
Training Epoch: 56 [37888/50176]	Loss: 0.4929
Training Epoch: 56 [38912/50176]	Loss: 0.5518
Training Epoch: 56 [39936/50176]	Loss: 0.4695
Training Epoch: 56 [40960/50176]	Loss: 0.5021
Training Epoch: 56 [41984/50176]	Loss: 0.4495
Training Epoch: 56 [43008/50176]	Loss: 0.5495
Training Epoch: 56 [44032/50176]	Loss: 0.5429
Training Epoch: 56 [45056/50176]	Loss: 0.5332
Training Epoch: 56 [46080/50176]	Loss: 0.5302
Training Epoch: 56 [47104/50176]	Loss: 0.5190
Training Epoch: 56 [48128/50176]	Loss: 0.5135
Training Epoch: 56 [49152/50176]	Loss: 0.4967
Training Epoch: 56 [50176/50176]	Loss: 0.4776
2022-12-08 16:23:26.895 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:23:26,940 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.79 energy=523.23
2022-12-08 11:23:26,940 [ZeusDataLoader(train)] Up to epoch 57: time=2855.57, energy=421921.58, cost=460822.88
2022-12-08 11:23:26,940 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:23:26,940 [ZeusDataLoader(train)] Expected next epoch: time=2903.02, energy=429178.39, cost=468603.16
2022-12-08 11:23:26,941 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 0.0019, Accuracy: 0.5699
2022-12-08 11:23:27,139 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:23:27,140 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:23:27.142 [ZeusMonitor] Monitor started.
2022-12-08 16:23:27.142 [ZeusMonitor] Running indefinitely. 2022-12-08 16:23:27.142 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:23:27.142 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e58+gpu0.power.log
2022-12-08 11:24:11,608 [ZeusDataLoader(train)] train epoch 58 done: time=44.66 energy=6802.91
2022-12-08 11:24:11,612 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 0.4606
Training Epoch: 57 [2048/50176]	Loss: 0.4475
Training Epoch: 57 [3072/50176]	Loss: 0.4067
Training Epoch: 57 [4096/50176]	Loss: 0.3953
Training Epoch: 57 [5120/50176]	Loss: 0.4540
Training Epoch: 57 [6144/50176]	Loss: 0.4494
Training Epoch: 57 [7168/50176]	Loss: 0.4408
Training Epoch: 57 [8192/50176]	Loss: 0.4359
Training Epoch: 57 [9216/50176]	Loss: 0.3829
Training Epoch: 57 [10240/50176]	Loss: 0.3962
Training Epoch: 57 [11264/50176]	Loss: 0.4411
Training Epoch: 57 [12288/50176]	Loss: 0.3786
Training Epoch: 57 [13312/50176]	Loss: 0.3913
Training Epoch: 57 [14336/50176]	Loss: 0.4432
Training Epoch: 57 [15360/50176]	Loss: 0.4204
Training Epoch: 57 [16384/50176]	Loss: 0.4591
Training Epoch: 57 [17408/50176]	Loss: 0.4741
Training Epoch: 57 [18432/50176]	Loss: 0.4688
Training Epoch: 57 [19456/50176]	Loss: 0.5326
Training Epoch: 57 [20480/50176]	Loss: 0.4306
Training Epoch: 57 [21504/50176]	Loss: 0.4794
Training Epoch: 57 [22528/50176]	Loss: 0.4214
Training Epoch: 57 [23552/50176]	Loss: 0.4048
Training Epoch: 57 [24576/50176]	Loss: 0.4294
Training Epoch: 57 [25600/50176]	Loss: 0.4797
Training Epoch: 57 [26624/50176]	Loss: 0.4486
Training Epoch: 57 [27648/50176]	Loss: 0.4690
Training Epoch: 57 [28672/50176]	Loss: 0.4882
Training Epoch: 57 [29696/50176]	Loss: 0.4858
Training Epoch: 57 [30720/50176]	Loss: 0.4722
Training Epoch: 57 [31744/50176]	Loss: 0.4286
Training Epoch: 57 [32768/50176]	Loss: 0.4630
Training Epoch: 57 [33792/50176]	Loss: 0.4697
Training Epoch: 57 [34816/50176]	Loss: 0.5236
Training Epoch: 57 [35840/50176]	Loss: 0.4903
Training Epoch: 57 [36864/50176]	Loss: 0.4699
Training Epoch: 57 [37888/50176]	Loss: 0.4794
Training Epoch: 57 [38912/50176]	Loss: 0.4404
Training Epoch: 57 [39936/50176]	Loss: 0.4338
Training Epoch: 57 [40960/50176]	Loss: 0.4892
Training Epoch: 57 [41984/50176]	Loss: 0.5036
Training Epoch: 57 [43008/50176]	Loss: 0.4906
Training Epoch: 57 [44032/50176]	Loss: 0.4926
Training Epoch: 57 [45056/50176]	Loss: 0.5338
Training Epoch: 57 [46080/50176]	Loss: 0.4831
Training Epoch: 57 [47104/50176]	Loss: 0.5332
Training Epoch: 57 [48128/50176]	Loss: 0.5294
Training Epoch: 57 [49152/50176]	Loss: 0.5291
Training Epoch: 57 [50176/50176]	Loss: 0.5110
2022-12-08 16:24:15.349 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:24:15,370 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.75 energy=526.42
2022-12-08 11:24:15,371 [ZeusDataLoader(train)] Up to epoch 58: time=2903.97, energy=429250.91, cost=468723.20
2022-12-08 11:24:15,371 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:24:15,371 [ZeusDataLoader(train)] Expected next epoch: time=2951.42, energy=436507.72, cost=476503.47
2022-12-08 11:24:15,372 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0020, Accuracy: 0.5663
2022-12-08 11:24:15,550 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:24:15,550 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:24:15.564 [ZeusMonitor] Monitor started.
2022-12-08 16:24:15.565 [ZeusMonitor] Running indefinitely. 2022-12-08 16:24:15.565 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:24:15.565 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e59+gpu0.power.log
2022-12-08 11:25:00,139 [ZeusDataLoader(train)] train epoch 59 done: time=44.76 energy=6801.86
2022-12-08 11:25:00,143 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 0.4157
Training Epoch: 58 [2048/50176]	Loss: 0.4031
Training Epoch: 58 [3072/50176]	Loss: 0.4042
Training Epoch: 58 [4096/50176]	Loss: 0.4089
Training Epoch: 58 [5120/50176]	Loss: 0.3556
Training Epoch: 58 [6144/50176]	Loss: 0.3976
Training Epoch: 58 [7168/50176]	Loss: 0.3812
Training Epoch: 58 [8192/50176]	Loss: 0.4387
Training Epoch: 58 [9216/50176]	Loss: 0.4063
Training Epoch: 58 [10240/50176]	Loss: 0.4283
Training Epoch: 58 [11264/50176]	Loss: 0.3966
Training Epoch: 58 [12288/50176]	Loss: 0.4709
Training Epoch: 58 [13312/50176]	Loss: 0.4323
Training Epoch: 58 [14336/50176]	Loss: 0.4112
Training Epoch: 58 [15360/50176]	Loss: 0.4223
Training Epoch: 58 [16384/50176]	Loss: 0.4389
Training Epoch: 58 [17408/50176]	Loss: 0.4621
Training Epoch: 58 [18432/50176]	Loss: 0.4217
Training Epoch: 58 [19456/50176]	Loss: 0.4102
Training Epoch: 58 [20480/50176]	Loss: 0.4018
Training Epoch: 58 [21504/50176]	Loss: 0.3991
Training Epoch: 58 [22528/50176]	Loss: 0.4360
Training Epoch: 58 [23552/50176]	Loss: 0.4797
Training Epoch: 58 [24576/50176]	Loss: 0.4934
Training Epoch: 58 [25600/50176]	Loss: 0.5154
Training Epoch: 58 [26624/50176]	Loss: 0.4339
Training Epoch: 58 [27648/50176]	Loss: 0.4732
Training Epoch: 58 [28672/50176]	Loss: 0.4810
Training Epoch: 58 [29696/50176]	Loss: 0.4703
Training Epoch: 58 [30720/50176]	Loss: 0.5526
Training Epoch: 58 [31744/50176]	Loss: 0.4995
Training Epoch: 58 [32768/50176]	Loss: 0.4491
Training Epoch: 58 [33792/50176]	Loss: 0.4754
Training Epoch: 58 [34816/50176]	Loss: 0.4688
Training Epoch: 58 [35840/50176]	Loss: 0.4668
Training Epoch: 58 [36864/50176]	Loss: 0.5071
Training Epoch: 58 [37888/50176]	Loss: 0.4784
Training Epoch: 58 [38912/50176]	Loss: 0.4684
Training Epoch: 58 [39936/50176]	Loss: 0.4914
Training Epoch: 58 [40960/50176]	Loss: 0.4556
Training Epoch: 58 [41984/50176]	Loss: 0.4494
Training Epoch: 58 [43008/50176]	Loss: 0.4859
Training Epoch: 58 [44032/50176]	Loss: 0.4697
Training Epoch: 58 [45056/50176]	Loss: 0.5366
Training Epoch: 58 [46080/50176]	Loss: 0.5071
Training Epoch: 58 [47104/50176]	Loss: 0.5220
Training Epoch: 58 [48128/50176]	Loss: 0.4825
Training Epoch: 58 [49152/50176]	Loss: 0.5050
Training Epoch: 58 [50176/50176]	Loss: 0.4963
2022-12-08 16:25:03.833 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:25:03,873 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.72 energy=526.43
2022-12-08 11:25:03,873 [ZeusDataLoader(train)] Up to epoch 59: time=2952.45, energy=436579.20, cost=476629.35
2022-12-08 11:25:03,873 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:25:03,873 [ZeusDataLoader(train)] Expected next epoch: time=2999.90, energy=443836.01, cost=484409.62
2022-12-08 11:25:03,874 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 0.0020, Accuracy: 0.5576
2022-12-08 11:25:04,056 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:25:04,057 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:25:04.059 [ZeusMonitor] Monitor started.
2022-12-08 16:25:04.059 [ZeusMonitor] Running indefinitely. 2022-12-08 16:25:04.059 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:25:04.059 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e60+gpu0.power.log
2022-12-08 11:25:48,601 [ZeusDataLoader(train)] train epoch 60 done: time=44.72 energy=6805.05
2022-12-08 11:25:48,605 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 0.4482
Training Epoch: 59 [2048/50176]	Loss: 0.4240
Training Epoch: 59 [3072/50176]	Loss: 0.4116
Training Epoch: 59 [4096/50176]	Loss: 0.3739
Training Epoch: 59 [5120/50176]	Loss: 0.3329
Training Epoch: 59 [6144/50176]	Loss: 0.4134
Training Epoch: 59 [7168/50176]	Loss: 0.3998
Training Epoch: 59 [8192/50176]	Loss: 0.4204
Training Epoch: 59 [9216/50176]	Loss: 0.4311
Training Epoch: 59 [10240/50176]	Loss: 0.3917
Training Epoch: 59 [11264/50176]	Loss: 0.3908
Training Epoch: 59 [12288/50176]	Loss: 0.4465
Training Epoch: 59 [13312/50176]	Loss: 0.4522
Training Epoch: 59 [14336/50176]	Loss: 0.4503
Training Epoch: 59 [15360/50176]	Loss: 0.4486
Training Epoch: 59 [16384/50176]	Loss: 0.4004
Training Epoch: 59 [17408/50176]	Loss: 0.4164
Training Epoch: 59 [18432/50176]	Loss: 0.4083
Training Epoch: 59 [19456/50176]	Loss: 0.4124
Training Epoch: 59 [20480/50176]	Loss: 0.4361
Training Epoch: 59 [21504/50176]	Loss: 0.4255
Training Epoch: 59 [22528/50176]	Loss: 0.4389
Training Epoch: 59 [23552/50176]	Loss: 0.4341
Training Epoch: 59 [24576/50176]	Loss: 0.4042
Training Epoch: 59 [25600/50176]	Loss: 0.4498
Training Epoch: 59 [26624/50176]	Loss: 0.4059
Training Epoch: 59 [27648/50176]	Loss: 0.4426
Training Epoch: 59 [28672/50176]	Loss: 0.4473
Training Epoch: 59 [29696/50176]	Loss: 0.4554
Training Epoch: 59 [30720/50176]	Loss: 0.4354
Training Epoch: 59 [31744/50176]	Loss: 0.3972
Training Epoch: 59 [32768/50176]	Loss: 0.4199
Training Epoch: 59 [33792/50176]	Loss: 0.4427
Training Epoch: 59 [34816/50176]	Loss: 0.4546
Training Epoch: 59 [35840/50176]	Loss: 0.4566
Training Epoch: 59 [36864/50176]	Loss: 0.4823
Training Epoch: 59 [37888/50176]	Loss: 0.4481
Training Epoch: 59 [38912/50176]	Loss: 0.4218
Training Epoch: 59 [39936/50176]	Loss: 0.4169
Training Epoch: 59 [40960/50176]	Loss: 0.4428
Training Epoch: 59 [41984/50176]	Loss: 0.4545
Training Epoch: 59 [43008/50176]	Loss: 0.4743
Training Epoch: 59 [44032/50176]	Loss: 0.4704
Training Epoch: 59 [45056/50176]	Loss: 0.3955
Training Epoch: 59 [46080/50176]	Loss: 0.4523
Training Epoch: 59 [47104/50176]	Loss: 0.4498
Training Epoch: 59 [48128/50176]	Loss: 0.4614
Training Epoch: 59 [49152/50176]	Loss: 0.4274
Training Epoch: 59 [50176/50176]	Loss: 0.4713
2022-12-08 16:25:52.330 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:25:52,344 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.73 energy=524.50
2022-12-08 11:25:52,345 [ZeusDataLoader(train)] Up to epoch 60: time=3000.90, energy=443908.75, cost=484533.28
2022-12-08 11:25:52,345 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:25:52,345 [ZeusDataLoader(train)] Expected next epoch: time=3048.35, energy=451165.55, cost=492313.56
2022-12-08 11:25:52,346 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0020, Accuracy: 0.5614
2022-12-08 11:25:52,533 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:25:52,534 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:25:52.536 [ZeusMonitor] Monitor started.
2022-12-08 16:25:52.536 [ZeusMonitor] Running indefinitely. 2022-12-08 16:25:52.536 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:25:52.536 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e61+gpu0.power.log
2022-12-08 11:26:36,945 [ZeusDataLoader(train)] train epoch 61 done: time=44.59 energy=6799.33
2022-12-08 11:26:36,948 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 0.3936
Training Epoch: 60 [2048/50176]	Loss: 0.3682
Training Epoch: 60 [3072/50176]	Loss: 0.3444
Training Epoch: 60 [4096/50176]	Loss: 0.3515
Training Epoch: 60 [5120/50176]	Loss: 0.3926
Training Epoch: 60 [6144/50176]	Loss: 0.3611
Training Epoch: 60 [7168/50176]	Loss: 0.3816
Training Epoch: 60 [8192/50176]	Loss: 0.3742
Training Epoch: 60 [9216/50176]	Loss: 0.4103
Training Epoch: 60 [10240/50176]	Loss: 0.3814
Training Epoch: 60 [11264/50176]	Loss: 0.3804
Training Epoch: 60 [12288/50176]	Loss: 0.4135
Training Epoch: 60 [13312/50176]	Loss: 0.4444
Training Epoch: 60 [14336/50176]	Loss: 0.3991
Training Epoch: 60 [15360/50176]	Loss: 0.3950
Training Epoch: 60 [16384/50176]	Loss: 0.4117
Training Epoch: 60 [17408/50176]	Loss: 0.3993
Training Epoch: 60 [18432/50176]	Loss: 0.3947
Training Epoch: 60 [19456/50176]	Loss: 0.3846
Training Epoch: 60 [20480/50176]	Loss: 0.3736
Training Epoch: 60 [21504/50176]	Loss: 0.3652
Training Epoch: 60 [22528/50176]	Loss: 0.3751
Training Epoch: 60 [23552/50176]	Loss: 0.3966
Training Epoch: 60 [24576/50176]	Loss: 0.4033
Training Epoch: 60 [25600/50176]	Loss: 0.4283
Training Epoch: 60 [26624/50176]	Loss: 0.4282
Training Epoch: 60 [27648/50176]	Loss: 0.4177
Training Epoch: 60 [28672/50176]	Loss: 0.3841
Training Epoch: 60 [29696/50176]	Loss: 0.4181
Training Epoch: 60 [30720/50176]	Loss: 0.3698
Training Epoch: 60 [31744/50176]	Loss: 0.4356
Training Epoch: 60 [32768/50176]	Loss: 0.3921
Training Epoch: 60 [33792/50176]	Loss: 0.4863
Training Epoch: 60 [34816/50176]	Loss: 0.4351
Training Epoch: 60 [35840/50176]	Loss: 0.4321
Training Epoch: 60 [36864/50176]	Loss: 0.5407
Training Epoch: 60 [37888/50176]	Loss: 0.4487
Training Epoch: 60 [38912/50176]	Loss: 0.4212
Training Epoch: 60 [39936/50176]	Loss: 0.3645
Training Epoch: 60 [40960/50176]	Loss: 0.4591
Training Epoch: 60 [41984/50176]	Loss: 0.3958
Training Epoch: 60 [43008/50176]	Loss: 0.4526
Training Epoch: 60 [44032/50176]	Loss: 0.4252
Training Epoch: 60 [45056/50176]	Loss: 0.3933
Training Epoch: 60 [46080/50176]	Loss: 0.4258
Training Epoch: 60 [47104/50176]	Loss: 0.4227
Training Epoch: 60 [48128/50176]	Loss: 0.4566
Training Epoch: 60 [49152/50176]	Loss: 0.4383
Training Epoch: 60 [50176/50176]	Loss: 0.4609
2022-12-08 16:26:40.705 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:26:40,746 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.79 energy=523.83
2022-12-08 11:26:40,747 [ZeusDataLoader(train)] Up to epoch 61: time=3049.28, energy=451231.90, cost=492428.13
2022-12-08 11:26:40,747 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:26:40,747 [ZeusDataLoader(train)] Expected next epoch: time=3096.73, energy=458488.71, cost=500208.41
2022-12-08 11:26:40,748 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0021, Accuracy: 0.5566
2022-12-08 11:26:40,893 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:26:40,894 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:26:40.895 [ZeusMonitor] Monitor started.
2022-12-08 16:26:40.896 [ZeusMonitor] Running indefinitely. 2022-12-08 16:26:40.896 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:26:40.896 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e62+gpu0.power.log
2022-12-08 11:27:25,468 [ZeusDataLoader(train)] train epoch 62 done: time=44.71 energy=6810.11
2022-12-08 11:27:25,472 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 0.4035
Training Epoch: 61 [2048/50176]	Loss: 0.3525
Training Epoch: 61 [3072/50176]	Loss: 0.3259
Training Epoch: 61 [4096/50176]	Loss: 0.3530
Training Epoch: 61 [5120/50176]	Loss: 0.3817
Training Epoch: 61 [6144/50176]	Loss: 0.3910
Training Epoch: 61 [7168/50176]	Loss: 0.3701
Training Epoch: 61 [8192/50176]	Loss: 0.3008
Training Epoch: 61 [9216/50176]	Loss: 0.3812
Training Epoch: 61 [10240/50176]	Loss: 0.3213
Training Epoch: 61 [11264/50176]	Loss: 0.3881
Training Epoch: 61 [12288/50176]	Loss: 0.3557
Training Epoch: 61 [13312/50176]	Loss: 0.3618
Training Epoch: 61 [14336/50176]	Loss: 0.4278
Training Epoch: 61 [15360/50176]	Loss: 0.3930
Training Epoch: 61 [16384/50176]	Loss: 0.3906
Training Epoch: 61 [17408/50176]	Loss: 0.3785
Training Epoch: 61 [18432/50176]	Loss: 0.3913
Training Epoch: 61 [19456/50176]	Loss: 0.3738
Training Epoch: 61 [20480/50176]	Loss: 0.3943
Training Epoch: 61 [21504/50176]	Loss: 0.3986
Training Epoch: 61 [22528/50176]	Loss: 0.4200
Training Epoch: 61 [23552/50176]	Loss: 0.3965
Training Epoch: 61 [24576/50176]	Loss: 0.3850
Training Epoch: 61 [25600/50176]	Loss: 0.3895
Training Epoch: 61 [26624/50176]	Loss: 0.3739
Training Epoch: 61 [27648/50176]	Loss: 0.4502
Training Epoch: 61 [28672/50176]	Loss: 0.3938
Training Epoch: 61 [29696/50176]	Loss: 0.3819
Training Epoch: 61 [30720/50176]	Loss: 0.4162
Training Epoch: 61 [31744/50176]	Loss: 0.3961
Training Epoch: 61 [32768/50176]	Loss: 0.4289
Training Epoch: 61 [33792/50176]	Loss: 0.4520
Training Epoch: 61 [34816/50176]	Loss: 0.4009
Training Epoch: 61 [35840/50176]	Loss: 0.3805
Training Epoch: 61 [36864/50176]	Loss: 0.4313
Training Epoch: 61 [37888/50176]	Loss: 0.3916
Training Epoch: 61 [38912/50176]	Loss: 0.3968
Training Epoch: 61 [39936/50176]	Loss: 0.4196
Training Epoch: 61 [40960/50176]	Loss: 0.4385
Training Epoch: 61 [41984/50176]	Loss: 0.4257
Training Epoch: 61 [43008/50176]	Loss: 0.4722
Training Epoch: 61 [44032/50176]	Loss: 0.4623
Training Epoch: 61 [45056/50176]	Loss: 0.4266
Training Epoch: 61 [46080/50176]	Loss: 0.4551
Training Epoch: 61 [47104/50176]	Loss: 0.4240
Training Epoch: 61 [48128/50176]	Loss: 0.4315
Training Epoch: 61 [49152/50176]	Loss: 0.4662
Training Epoch: 61 [50176/50176]	Loss: 0.4249
2022-12-08 16:27:29.229 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:27:29,262 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.78 energy=535.11
2022-12-08 11:27:29,262 [ZeusDataLoader(train)] Up to epoch 62: time=3097.77, energy=458577.12, cost=500343.76
2022-12-08 11:27:29,262 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:27:29,262 [ZeusDataLoader(train)] Expected next epoch: time=3145.22, energy=465833.93, cost=508124.03
2022-12-08 11:27:29,263 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 0.0020, Accuracy: 0.5767
2022-12-08 11:27:29,457 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:27:29,458 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:27:29.460 [ZeusMonitor] Monitor started.
2022-12-08 16:27:29.460 [ZeusMonitor] Running indefinitely. 2022-12-08 16:27:29.460 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:27:29.460 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e63+gpu0.power.log
2022-12-08 11:28:13,960 [ZeusDataLoader(train)] train epoch 63 done: time=44.69 energy=6812.63
2022-12-08 11:28:13,963 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 0.3256
Training Epoch: 62 [2048/50176]	Loss: 0.3354
Training Epoch: 62 [3072/50176]	Loss: 0.3218
Training Epoch: 62 [4096/50176]	Loss: 0.3476
Training Epoch: 62 [5120/50176]	Loss: 0.3540
Training Epoch: 62 [6144/50176]	Loss: 0.3783
Training Epoch: 62 [7168/50176]	Loss: 0.3528
Training Epoch: 62 [8192/50176]	Loss: 0.3617
Training Epoch: 62 [9216/50176]	Loss: 0.3295
Training Epoch: 62 [10240/50176]	Loss: 0.3430
Training Epoch: 62 [11264/50176]	Loss: 0.3561
Training Epoch: 62 [12288/50176]	Loss: 0.3562
Training Epoch: 62 [13312/50176]	Loss: 0.3391
Training Epoch: 62 [14336/50176]	Loss: 0.3450
Training Epoch: 62 [15360/50176]	Loss: 0.3638
Training Epoch: 62 [16384/50176]	Loss: 0.3525
Training Epoch: 62 [17408/50176]	Loss: 0.3936
Training Epoch: 62 [18432/50176]	Loss: 0.3994
Training Epoch: 62 [19456/50176]	Loss: 0.3531
Training Epoch: 62 [20480/50176]	Loss: 0.3652
Training Epoch: 62 [21504/50176]	Loss: 0.3610
Training Epoch: 62 [22528/50176]	Loss: 0.3741
Training Epoch: 62 [23552/50176]	Loss: 0.3332
Training Epoch: 62 [24576/50176]	Loss: 0.3958
Training Epoch: 62 [25600/50176]	Loss: 0.3523
Training Epoch: 62 [26624/50176]	Loss: 0.3614
Training Epoch: 62 [27648/50176]	Loss: 0.3844
Training Epoch: 62 [28672/50176]	Loss: 0.3721
Training Epoch: 62 [29696/50176]	Loss: 0.3836
Training Epoch: 62 [30720/50176]	Loss: 0.3960
Training Epoch: 62 [31744/50176]	Loss: 0.4199
Training Epoch: 62 [32768/50176]	Loss: 0.3494
Training Epoch: 62 [33792/50176]	Loss: 0.3634
Training Epoch: 62 [34816/50176]	Loss: 0.3935
Training Epoch: 62 [35840/50176]	Loss: 0.3766
Training Epoch: 62 [36864/50176]	Loss: 0.4100
Training Epoch: 62 [37888/50176]	Loss: 0.4048
Training Epoch: 62 [38912/50176]	Loss: 0.4337
Training Epoch: 62 [39936/50176]	Loss: 0.4225
Training Epoch: 62 [40960/50176]	Loss: 0.4366
Training Epoch: 62 [41984/50176]	Loss: 0.3802
Training Epoch: 62 [43008/50176]	Loss: 0.4314
Training Epoch: 62 [44032/50176]	Loss: 0.4185
Training Epoch: 62 [45056/50176]	Loss: 0.4222
Training Epoch: 62 [46080/50176]	Loss: 0.4351
Training Epoch: 62 [47104/50176]	Loss: 0.4616
Training Epoch: 62 [48128/50176]	Loss: 0.4777
Training Epoch: 62 [49152/50176]	Loss: 0.5122
Training Epoch: 62 [50176/50176]	Loss: 0.4743
2022-12-08 16:28:17.728 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:28:17,760 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.79 energy=539.54
2022-12-08 11:28:17,760 [ZeusDataLoader(train)] Up to epoch 63: time=3146.25, energy=465929.29, cost=508261.52
2022-12-08 11:28:17,760 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:28:17,760 [ZeusDataLoader(train)] Expected next epoch: time=3193.70, energy=473186.10, cost=516041.80
2022-12-08 11:28:17,761 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 0.0021, Accuracy: 0.5597
2022-12-08 11:28:17,908 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:28:17,909 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:28:17.913 [ZeusMonitor] Monitor started.
2022-12-08 16:28:17.913 [ZeusMonitor] Running indefinitely. 2022-12-08 16:28:17.913 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:28:17.913 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e64+gpu0.power.log
2022-12-08 11:29:02,399 [ZeusDataLoader(train)] train epoch 64 done: time=44.63 energy=6795.09
2022-12-08 11:29:02,402 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 0.4157
Training Epoch: 63 [2048/50176]	Loss: 0.3602
Training Epoch: 63 [3072/50176]	Loss: 0.3381
Training Epoch: 63 [4096/50176]	Loss: 0.3779
Training Epoch: 63 [5120/50176]	Loss: 0.3944
Training Epoch: 63 [6144/50176]	Loss: 0.3533
Training Epoch: 63 [7168/50176]	Loss: 0.3597
Training Epoch: 63 [8192/50176]	Loss: 0.3493
Training Epoch: 63 [9216/50176]	Loss: 0.3407
Training Epoch: 63 [10240/50176]	Loss: 0.3338
Training Epoch: 63 [11264/50176]	Loss: 0.3681
Training Epoch: 63 [12288/50176]	Loss: 0.3503
Training Epoch: 63 [13312/50176]	Loss: 0.3347
Training Epoch: 63 [14336/50176]	Loss: 0.3894
Training Epoch: 63 [15360/50176]	Loss: 0.3862
Training Epoch: 63 [16384/50176]	Loss: 0.3732
Training Epoch: 63 [17408/50176]	Loss: 0.3462
Training Epoch: 63 [18432/50176]	Loss: 0.3793
Training Epoch: 63 [19456/50176]	Loss: 0.3653
Training Epoch: 63 [20480/50176]	Loss: 0.3658
Training Epoch: 63 [21504/50176]	Loss: 0.3940
Training Epoch: 63 [22528/50176]	Loss: 0.3581
Training Epoch: 63 [23552/50176]	Loss: 0.3531
Training Epoch: 63 [24576/50176]	Loss: 0.3413
Training Epoch: 63 [25600/50176]	Loss: 0.3717
Training Epoch: 63 [26624/50176]	Loss: 0.3457
Training Epoch: 63 [27648/50176]	Loss: 0.3756
Training Epoch: 63 [28672/50176]	Loss: 0.3795
Training Epoch: 63 [29696/50176]	Loss: 0.3721
Training Epoch: 63 [30720/50176]	Loss: 0.3692
Training Epoch: 63 [31744/50176]	Loss: 0.3965
Training Epoch: 63 [32768/50176]	Loss: 0.4518
Training Epoch: 63 [33792/50176]	Loss: 0.3796
Training Epoch: 63 [34816/50176]	Loss: 0.3761
Training Epoch: 63 [35840/50176]	Loss: 0.3743
Training Epoch: 63 [36864/50176]	Loss: 0.3812
Training Epoch: 63 [37888/50176]	Loss: 0.4242
Training Epoch: 63 [38912/50176]	Loss: 0.4307
Training Epoch: 63 [39936/50176]	Loss: 0.4063
Training Epoch: 63 [40960/50176]	Loss: 0.4367
Training Epoch: 63 [41984/50176]	Loss: 0.3524
Training Epoch: 63 [43008/50176]	Loss: 0.4502
Training Epoch: 63 [44032/50176]	Loss: 0.4269
Training Epoch: 63 [45056/50176]	Loss: 0.3584
Training Epoch: 63 [46080/50176]	Loss: 0.3616
Training Epoch: 63 [47104/50176]	Loss: 0.4205
Training Epoch: 63 [48128/50176]	Loss: 0.4176
Training Epoch: 63 [49152/50176]	Loss: 0.5041
Training Epoch: 63 [50176/50176]	Loss: 0.4335
2022-12-08 16:29:06.115 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:29:06,138 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.73 energy=528.73
2022-12-08 11:29:06,138 [ZeusDataLoader(train)] Up to epoch 64: time=3194.61, energy=473253.11, cost=516154.53
2022-12-08 11:29:06,139 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:29:06,139 [ZeusDataLoader(train)] Expected next epoch: time=3242.06, energy=480509.92, cost=523934.81
2022-12-08 11:29:06,140 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 0.0020, Accuracy: 0.5609
2022-12-08 11:29:06,325 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:29:06,326 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:29:06.328 [ZeusMonitor] Monitor started.
2022-12-08 16:29:06.328 [ZeusMonitor] Running indefinitely. 2022-12-08 16:29:06.328 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:29:06.328 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e65+gpu0.power.log
2022-12-08 11:29:50,804 [ZeusDataLoader(train)] train epoch 65 done: time=44.66 energy=6814.62
2022-12-08 11:29:50,807 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 0.4265
Training Epoch: 64 [2048/50176]	Loss: 0.3554
Training Epoch: 64 [3072/50176]	Loss: 0.3420
Training Epoch: 64 [4096/50176]	Loss: 0.3180
Training Epoch: 64 [5120/50176]	Loss: 0.2885
Training Epoch: 64 [6144/50176]	Loss: 0.3046
Training Epoch: 64 [7168/50176]	Loss: 0.3777
Training Epoch: 64 [8192/50176]	Loss: 0.3248
Training Epoch: 64 [9216/50176]	Loss: 0.3418
Training Epoch: 64 [10240/50176]	Loss: 0.3531
Training Epoch: 64 [11264/50176]	Loss: 0.3587
Training Epoch: 64 [12288/50176]	Loss: 0.3178
Training Epoch: 64 [13312/50176]	Loss: 0.3334
Training Epoch: 64 [14336/50176]	Loss: 0.3600
Training Epoch: 64 [15360/50176]	Loss: 0.3260
Training Epoch: 64 [16384/50176]	Loss: 0.3313
Training Epoch: 64 [17408/50176]	Loss: 0.3494
Training Epoch: 64 [18432/50176]	Loss: 0.3415
Training Epoch: 64 [19456/50176]	Loss: 0.3182
Training Epoch: 64 [20480/50176]	Loss: 0.3216
Training Epoch: 64 [21504/50176]	Loss: 0.3812
Training Epoch: 64 [22528/50176]	Loss: 0.3763
Training Epoch: 64 [23552/50176]	Loss: 0.3650
Training Epoch: 64 [24576/50176]	Loss: 0.3506
Training Epoch: 64 [25600/50176]	Loss: 0.3058
Training Epoch: 64 [26624/50176]	Loss: 0.3302
Training Epoch: 64 [27648/50176]	Loss: 0.3386
Training Epoch: 64 [28672/50176]	Loss: 0.3379
Training Epoch: 64 [29696/50176]	Loss: 0.3582
Training Epoch: 64 [30720/50176]	Loss: 0.3758
Training Epoch: 64 [31744/50176]	Loss: 0.4164
Training Epoch: 64 [32768/50176]	Loss: 0.3909
Training Epoch: 64 [33792/50176]	Loss: 0.4003
Training Epoch: 64 [34816/50176]	Loss: 0.3264
Training Epoch: 64 [35840/50176]	Loss: 0.4004
Training Epoch: 64 [36864/50176]	Loss: 0.3922
Training Epoch: 64 [37888/50176]	Loss: 0.4052
Training Epoch: 64 [38912/50176]	Loss: 0.3845
Training Epoch: 64 [39936/50176]	Loss: 0.3986
Training Epoch: 64 [40960/50176]	Loss: 0.4279
Training Epoch: 64 [41984/50176]	Loss: 0.4257
Training Epoch: 64 [43008/50176]	Loss: 0.3679
Training Epoch: 64 [44032/50176]	Loss: 0.4041
Training Epoch: 64 [45056/50176]	Loss: 0.3817
Training Epoch: 64 [46080/50176]	Loss: 0.3950
Training Epoch: 64 [47104/50176]	Loss: 0.3620
Training Epoch: 64 [48128/50176]	Loss: 0.3689
Training Epoch: 64 [49152/50176]	Loss: 0.3558
Training Epoch: 64 [50176/50176]	Loss: 0.3094
2022-12-08 16:29:54.594 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:29:54,624 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.81 energy=539.76
2022-12-08 11:29:54,624 [ZeusDataLoader(train)] Up to epoch 65: time=3243.07, energy=480607.49, cost=524072.25
2022-12-08 11:29:54,624 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:29:54,624 [ZeusDataLoader(train)] Expected next epoch: time=3290.52, energy=487864.30, cost=531852.52
2022-12-08 11:29:54,625 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 0.0020, Accuracy: 0.5764
2022-12-08 11:29:54,803 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:29:54,804 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:29:54.818 [ZeusMonitor] Monitor started.
2022-12-08 16:29:54.818 [ZeusMonitor] Running indefinitely. 2022-12-08 16:29:54.818 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:29:54.818 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e66+gpu0.power.log
2022-12-08 11:30:39,290 [ZeusDataLoader(train)] train epoch 66 done: time=44.66 energy=6789.63
2022-12-08 11:30:39,294 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 0.3333
Training Epoch: 65 [2048/50176]	Loss: 0.2911
Training Epoch: 65 [3072/50176]	Loss: 0.3272
Training Epoch: 65 [4096/50176]	Loss: 0.2792
Training Epoch: 65 [5120/50176]	Loss: 0.3183
Training Epoch: 65 [6144/50176]	Loss: 0.3313
Training Epoch: 65 [7168/50176]	Loss: 0.3476
Training Epoch: 65 [8192/50176]	Loss: 0.3245
Training Epoch: 65 [9216/50176]	Loss: 0.3051
Training Epoch: 65 [10240/50176]	Loss: 0.3036
Training Epoch: 65 [11264/50176]	Loss: 0.3242
Training Epoch: 65 [12288/50176]	Loss: 0.2933
Training Epoch: 65 [13312/50176]	Loss: 0.3219
Training Epoch: 65 [14336/50176]	Loss: 0.3065
Training Epoch: 65 [15360/50176]	Loss: 0.3102
Training Epoch: 65 [16384/50176]	Loss: 0.3120
Training Epoch: 65 [17408/50176]	Loss: 0.2735
Training Epoch: 65 [18432/50176]	Loss: 0.3101
Training Epoch: 65 [19456/50176]	Loss: 0.3437
Training Epoch: 65 [20480/50176]	Loss: 0.3304
Training Epoch: 65 [21504/50176]	Loss: 0.3439
Training Epoch: 65 [22528/50176]	Loss: 0.3553
Training Epoch: 65 [23552/50176]	Loss: 0.3585
Training Epoch: 65 [24576/50176]	Loss: 0.3147
Training Epoch: 65 [25600/50176]	Loss: 0.3042
Training Epoch: 65 [26624/50176]	Loss: 0.3024
Training Epoch: 65 [27648/50176]	Loss: 0.3884
Training Epoch: 65 [28672/50176]	Loss: 0.3334
Training Epoch: 65 [29696/50176]	Loss: 0.3019
Training Epoch: 65 [30720/50176]	Loss: 0.3912
Training Epoch: 65 [31744/50176]	Loss: 0.3028
Training Epoch: 65 [32768/50176]	Loss: 0.3544
Training Epoch: 65 [33792/50176]	Loss: 0.3479
Training Epoch: 65 [34816/50176]	Loss: 0.3530
Training Epoch: 65 [35840/50176]	Loss: 0.3757
Training Epoch: 65 [36864/50176]	Loss: 0.3877
Training Epoch: 65 [37888/50176]	Loss: 0.3192
Training Epoch: 65 [38912/50176]	Loss: 0.3703
Training Epoch: 65 [39936/50176]	Loss: 0.3672
Training Epoch: 65 [40960/50176]	Loss: 0.3726
Training Epoch: 65 [41984/50176]	Loss: 0.3866
Training Epoch: 65 [43008/50176]	Loss: 0.3627
Training Epoch: 65 [44032/50176]	Loss: 0.3740
Training Epoch: 65 [45056/50176]	Loss: 0.4056
Training Epoch: 65 [46080/50176]	Loss: 0.4437
Training Epoch: 65 [47104/50176]	Loss: 0.3629
Training Epoch: 65 [48128/50176]	Loss: 0.3540
Training Epoch: 65 [49152/50176]	Loss: 0.4134
Training Epoch: 65 [50176/50176]	Loss: 0.3870
2022-12-08 16:30:42.973 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:30:42,982 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.68 energy=513.59
2022-12-08 11:30:42,983 [ZeusDataLoader(train)] Up to epoch 66: time=3291.40, energy=487910.71, cost=531953.27
2022-12-08 11:30:42,983 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:30:42,983 [ZeusDataLoader(train)] Expected next epoch: time=3338.85, energy=495167.51, cost=539733.54
2022-12-08 11:30:42,984 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 0.0021, Accuracy: 0.5646
2022-12-08 11:30:43,177 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:30:43,178 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:30:43.180 [ZeusMonitor] Monitor started.
2022-12-08 16:30:43.180 [ZeusMonitor] Running indefinitely. 2022-12-08 16:30:43.180 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:30:43.180 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e67+gpu0.power.log
2022-12-08 11:31:27,617 [ZeusDataLoader(train)] train epoch 67 done: time=44.62 energy=6795.75
2022-12-08 11:31:27,621 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 0.3350
Training Epoch: 66 [2048/50176]	Loss: 0.2958
Training Epoch: 66 [3072/50176]	Loss: 0.3123
Training Epoch: 66 [4096/50176]	Loss: 0.3388
Training Epoch: 66 [5120/50176]	Loss: 0.3217
Training Epoch: 66 [6144/50176]	Loss: 0.2910
Training Epoch: 66 [7168/50176]	Loss: 0.3302
Training Epoch: 66 [8192/50176]	Loss: 0.2988
Training Epoch: 66 [9216/50176]	Loss: 0.2857
Training Epoch: 66 [10240/50176]	Loss: 0.2865
Training Epoch: 66 [11264/50176]	Loss: 0.2896
Training Epoch: 66 [12288/50176]	Loss: 0.3072
Training Epoch: 66 [13312/50176]	Loss: 0.2905
Training Epoch: 66 [14336/50176]	Loss: 0.3050
Training Epoch: 66 [15360/50176]	Loss: 0.2848
Training Epoch: 66 [16384/50176]	Loss: 0.3454
Training Epoch: 66 [17408/50176]	Loss: 0.3577
Training Epoch: 66 [18432/50176]	Loss: 0.3167
Training Epoch: 66 [19456/50176]	Loss: 0.2857
Training Epoch: 66 [20480/50176]	Loss: 0.3392
Training Epoch: 66 [21504/50176]	Loss: 0.2978
Training Epoch: 66 [22528/50176]	Loss: 0.3184
Training Epoch: 66 [23552/50176]	Loss: 0.3233
Training Epoch: 66 [24576/50176]	Loss: 0.3270
Training Epoch: 66 [25600/50176]	Loss: 0.3138
Training Epoch: 66 [26624/50176]	Loss: 0.3844
Training Epoch: 66 [27648/50176]	Loss: 0.3492
Training Epoch: 66 [28672/50176]	Loss: 0.3863
Training Epoch: 66 [29696/50176]	Loss: 0.3570
Training Epoch: 66 [30720/50176]	Loss: 0.3604
Training Epoch: 66 [31744/50176]	Loss: 0.3553
Training Epoch: 66 [32768/50176]	Loss: 0.3325
Training Epoch: 66 [33792/50176]	Loss: 0.3546
Training Epoch: 66 [34816/50176]	Loss: 0.3359
Training Epoch: 66 [35840/50176]	Loss: 0.3282
Training Epoch: 66 [36864/50176]	Loss: 0.3603
Training Epoch: 66 [37888/50176]	Loss: 0.3687
Training Epoch: 66 [38912/50176]	Loss: 0.3794
Training Epoch: 66 [39936/50176]	Loss: 0.3440
Training Epoch: 66 [40960/50176]	Loss: 0.3613
Training Epoch: 66 [41984/50176]	Loss: 0.3462
Training Epoch: 66 [43008/50176]	Loss: 0.3391
Training Epoch: 66 [44032/50176]	Loss: 0.3366
Training Epoch: 66 [45056/50176]	Loss: 0.3372
Training Epoch: 66 [46080/50176]	Loss: 0.3423
Training Epoch: 66 [47104/50176]	Loss: 0.3499
Training Epoch: 66 [48128/50176]	Loss: 0.3472
Training Epoch: 66 [49152/50176]	Loss: 0.3493
Training Epoch: 66 [50176/50176]	Loss: 0.3730
2022-12-08 16:31:31.377 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:31:31,428 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.80 energy=535.58
2022-12-08 11:31:31,429 [ZeusDataLoader(train)] Up to epoch 67: time=3339.83, energy=495242.03, cost=539855.91
2022-12-08 11:31:31,429 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:31:31,429 [ZeusDataLoader(train)] Expected next epoch: time=3387.28, energy=502498.84, cost=547636.19
2022-12-08 11:31:31,430 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 0.0021, Accuracy: 0.5677
2022-12-08 11:31:31,659 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:31:31,659 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:31:31.661 [ZeusMonitor] Monitor started.
2022-12-08 16:31:31.661 [ZeusMonitor] Running indefinitely. 2022-12-08 16:31:31.661 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:31:31.661 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e68+gpu0.power.log
2022-12-08 11:32:16,105 [ZeusDataLoader(train)] train epoch 68 done: time=44.67 energy=6789.45
2022-12-08 11:32:16,110 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 0.3248
Training Epoch: 67 [2048/50176]	Loss: 0.2650
Training Epoch: 67 [3072/50176]	Loss: 0.3015
Training Epoch: 67 [4096/50176]	Loss: 0.2706
Training Epoch: 67 [5120/50176]	Loss: 0.3007
Training Epoch: 67 [6144/50176]	Loss: 0.3081
Training Epoch: 67 [7168/50176]	Loss: 0.2794
Training Epoch: 67 [8192/50176]	Loss: 0.2576
Training Epoch: 67 [9216/50176]	Loss: 0.2495
Training Epoch: 67 [10240/50176]	Loss: 0.3195
Training Epoch: 67 [11264/50176]	Loss: 0.2940
Training Epoch: 67 [12288/50176]	Loss: 0.2906
Training Epoch: 67 [13312/50176]	Loss: 0.2931
Training Epoch: 67 [14336/50176]	Loss: 0.2730
Training Epoch: 67 [15360/50176]	Loss: 0.3052
Training Epoch: 67 [16384/50176]	Loss: 0.2971
Training Epoch: 67 [17408/50176]	Loss: 0.2845
Training Epoch: 67 [18432/50176]	Loss: 0.3093
Training Epoch: 67 [19456/50176]	Loss: 0.3389
Training Epoch: 67 [20480/50176]	Loss: 0.2890
Training Epoch: 67 [21504/50176]	Loss: 0.3099
Training Epoch: 67 [22528/50176]	Loss: 0.2965
Training Epoch: 67 [23552/50176]	Loss: 0.3425
Training Epoch: 67 [24576/50176]	Loss: 0.3186
Training Epoch: 67 [25600/50176]	Loss: 0.3334
Training Epoch: 67 [26624/50176]	Loss: 0.3122
Training Epoch: 67 [27648/50176]	Loss: 0.3395
Training Epoch: 67 [28672/50176]	Loss: 0.3129
Training Epoch: 67 [29696/50176]	Loss: 0.3099
Training Epoch: 67 [30720/50176]	Loss: 0.3120
Training Epoch: 67 [31744/50176]	Loss: 0.3124
Training Epoch: 67 [32768/50176]	Loss: 0.3712
Training Epoch: 67 [33792/50176]	Loss: 0.3157
Training Epoch: 67 [34816/50176]	Loss: 0.2995
Training Epoch: 67 [35840/50176]	Loss: 0.3095
Training Epoch: 67 [36864/50176]	Loss: 0.3121
Training Epoch: 67 [37888/50176]	Loss: 0.3394
Training Epoch: 67 [38912/50176]	Loss: 0.3398
Training Epoch: 67 [39936/50176]	Loss: 0.3507
Training Epoch: 67 [40960/50176]	Loss: 0.3594
Training Epoch: 67 [41984/50176]	Loss: 0.3534
Training Epoch: 67 [43008/50176]	Loss: 0.2812
Training Epoch: 67 [44032/50176]	Loss: 0.3435
Training Epoch: 67 [45056/50176]	Loss: 0.3338
Training Epoch: 67 [46080/50176]	Loss: 0.4087
Training Epoch: 67 [47104/50176]	Loss: 0.3190
Training Epoch: 67 [48128/50176]	Loss: 0.3139
Training Epoch: 67 [49152/50176]	Loss: 0.3293
Training Epoch: 67 [50176/50176]	Loss: 0.3573
2022-12-08 16:32:19.922 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:32:19,949 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.83 energy=538.66
2022-12-08 11:32:19,950 [ZeusDataLoader(train)] Up to epoch 68: time=3388.33, energy=502570.15, cost=547763.53
2022-12-08 11:32:19,950 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:32:19,950 [ZeusDataLoader(train)] Expected next epoch: time=3435.78, energy=509826.96, cost=555543.81
2022-12-08 11:32:19,951 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 0.0021, Accuracy: 0.5709
2022-12-08 11:32:20,138 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:32:20,139 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:32:20.141 [ZeusMonitor] Monitor started.
2022-12-08 16:32:20.141 [ZeusMonitor] Running indefinitely. 2022-12-08 16:32:20.141 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:32:20.141 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e69+gpu0.power.log
2022-12-08 11:33:04,652 [ZeusDataLoader(train)] train epoch 69 done: time=44.69 energy=6793.33
2022-12-08 11:33:04,656 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 0.2937
Training Epoch: 68 [2048/50176]	Loss: 0.2483
Training Epoch: 68 [3072/50176]	Loss: 0.2778
Training Epoch: 68 [4096/50176]	Loss: 0.2912
Training Epoch: 68 [5120/50176]	Loss: 0.3251
Training Epoch: 68 [6144/50176]	Loss: 0.2881
Training Epoch: 68 [7168/50176]	Loss: 0.2925
Training Epoch: 68 [8192/50176]	Loss: 0.3043
Training Epoch: 68 [9216/50176]	Loss: 0.3301
Training Epoch: 68 [10240/50176]	Loss: 0.3329
Training Epoch: 68 [11264/50176]	Loss: 0.3169
Training Epoch: 68 [12288/50176]	Loss: 0.2913
Training Epoch: 68 [13312/50176]	Loss: 0.2776
Training Epoch: 68 [14336/50176]	Loss: 0.3132
Training Epoch: 68 [15360/50176]	Loss: 0.3258
Training Epoch: 68 [16384/50176]	Loss: 0.3344
Training Epoch: 68 [17408/50176]	Loss: 0.3050
Training Epoch: 68 [18432/50176]	Loss: 0.2625
Training Epoch: 68 [19456/50176]	Loss: 0.2573
Training Epoch: 68 [20480/50176]	Loss: 0.2888
Training Epoch: 68 [21504/50176]	Loss: 0.2892
Training Epoch: 68 [22528/50176]	Loss: 0.2961
Training Epoch: 68 [23552/50176]	Loss: 0.2745
Training Epoch: 68 [24576/50176]	Loss: 0.2816
Training Epoch: 68 [25600/50176]	Loss: 0.3151
Training Epoch: 68 [26624/50176]	Loss: 0.3156
Training Epoch: 68 [27648/50176]	Loss: 0.2891
Training Epoch: 68 [28672/50176]	Loss: 0.2816
Training Epoch: 68 [29696/50176]	Loss: 0.3105
Training Epoch: 68 [30720/50176]	Loss: 0.3394
Training Epoch: 68 [31744/50176]	Loss: 0.2700
Training Epoch: 68 [32768/50176]	Loss: 0.3064
Training Epoch: 68 [33792/50176]	Loss: 0.3107
Training Epoch: 68 [34816/50176]	Loss: 0.3141
Training Epoch: 68 [35840/50176]	Loss: 0.3060
Training Epoch: 68 [36864/50176]	Loss: 0.3059
Training Epoch: 68 [37888/50176]	Loss: 0.3131
Training Epoch: 68 [38912/50176]	Loss: 0.3324
Training Epoch: 68 [39936/50176]	Loss: 0.3350
Training Epoch: 68 [40960/50176]	Loss: 0.3337
Training Epoch: 68 [41984/50176]	Loss: 0.3140
Training Epoch: 68 [43008/50176]	Loss: 0.3089
Training Epoch: 68 [44032/50176]	Loss: 0.3233
Training Epoch: 68 [45056/50176]	Loss: 0.2440
Training Epoch: 68 [46080/50176]	Loss: 0.2731
Training Epoch: 68 [47104/50176]	Loss: 0.3470
Training Epoch: 68 [48128/50176]	Loss: 0.3757
Training Epoch: 68 [49152/50176]	Loss: 0.3682
Training Epoch: 68 [50176/50176]	Loss: 0.3537
2022-12-08 16:33:08.378 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:33:08,403 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.74 energy=525.80
2022-12-08 11:33:08,403 [ZeusDataLoader(train)] Up to epoch 69: time=3436.76, energy=509889.27, cost=555660.77
2022-12-08 11:33:08,403 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:33:08,403 [ZeusDataLoader(train)] Expected next epoch: time=3484.21, energy=517146.08, cost=563441.04
2022-12-08 11:33:08,404 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 0.0022, Accuracy: 0.5634
2022-12-08 11:33:08,592 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:33:08,593 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:33:08.595 [ZeusMonitor] Monitor started.
2022-12-08 16:33:08.595 [ZeusMonitor] Running indefinitely. 2022-12-08 16:33:08.595 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:33:08.595 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e70+gpu0.power.log
2022-12-08 11:33:53,010 [ZeusDataLoader(train)] train epoch 70 done: time=44.60 energy=6795.33
2022-12-08 11:33:53,014 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 0.2730
Training Epoch: 69 [2048/50176]	Loss: 0.2796
Training Epoch: 69 [3072/50176]	Loss: 0.2709
Training Epoch: 69 [4096/50176]	Loss: 0.2473
Training Epoch: 69 [5120/50176]	Loss: 0.2186
Training Epoch: 69 [6144/50176]	Loss: 0.2926
Training Epoch: 69 [7168/50176]	Loss: 0.2655
Training Epoch: 69 [8192/50176]	Loss: 0.2522
Training Epoch: 69 [9216/50176]	Loss: 0.2815
Training Epoch: 69 [10240/50176]	Loss: 0.2930
Training Epoch: 69 [11264/50176]	Loss: 0.2535
Training Epoch: 69 [12288/50176]	Loss: 0.2303
Training Epoch: 69 [13312/50176]	Loss: 0.2555
Training Epoch: 69 [14336/50176]	Loss: 0.2360
Training Epoch: 69 [15360/50176]	Loss: 0.2924
Training Epoch: 69 [16384/50176]	Loss: 0.2634
Training Epoch: 69 [17408/50176]	Loss: 0.3178
Training Epoch: 69 [18432/50176]	Loss: 0.2877
Training Epoch: 69 [19456/50176]	Loss: 0.2845
Training Epoch: 69 [20480/50176]	Loss: 0.2387
Training Epoch: 69 [21504/50176]	Loss: 0.2808
Training Epoch: 69 [22528/50176]	Loss: 0.3604
Training Epoch: 69 [23552/50176]	Loss: 0.3257
Training Epoch: 69 [24576/50176]	Loss: 0.3224
Training Epoch: 69 [25600/50176]	Loss: 0.3211
Training Epoch: 69 [26624/50176]	Loss: 0.2881
Training Epoch: 69 [27648/50176]	Loss: 0.3039
Training Epoch: 69 [28672/50176]	Loss: 0.2853
Training Epoch: 69 [29696/50176]	Loss: 0.2872
Training Epoch: 69 [30720/50176]	Loss: 0.2771
Training Epoch: 69 [31744/50176]	Loss: 0.3535
Training Epoch: 69 [32768/50176]	Loss: 0.3265
Training Epoch: 69 [33792/50176]	Loss: 0.3300
Training Epoch: 69 [34816/50176]	Loss: 0.2861
Training Epoch: 69 [35840/50176]	Loss: 0.3112
Training Epoch: 69 [36864/50176]	Loss: 0.2934
Training Epoch: 69 [37888/50176]	Loss: 0.2919
Training Epoch: 69 [38912/50176]	Loss: 0.3306
Training Epoch: 69 [39936/50176]	Loss: 0.3237
Training Epoch: 69 [40960/50176]	Loss: 0.2997
Training Epoch: 69 [41984/50176]	Loss: 0.3410
Training Epoch: 69 [43008/50176]	Loss: 0.3208
Training Epoch: 69 [44032/50176]	Loss: 0.3371
Training Epoch: 69 [45056/50176]	Loss: 0.3493
Training Epoch: 69 [46080/50176]	Loss: 0.3344
Training Epoch: 69 [47104/50176]	Loss: 0.3467
Training Epoch: 69 [48128/50176]	Loss: 0.3912
Training Epoch: 69 [49152/50176]	Loss: 0.3227
Training Epoch: 69 [50176/50176]	Loss: 0.3418
2022-12-08 16:33:56.758 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:33:56,796 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.77 energy=519.27
2022-12-08 11:33:56,797 [ZeusDataLoader(train)] Up to epoch 70: time=3485.13, energy=517203.88, cost=563550.48
2022-12-08 11:33:56,797 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:33:56,797 [ZeusDataLoader(train)] Expected next epoch: time=3532.58, energy=524460.69, cost=571330.76
2022-12-08 11:33:56,798 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0021, Accuracy: 0.5755
2022-12-08 11:33:56,976 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:33:56,976 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:33:56.986 [ZeusMonitor] Monitor started.
2022-12-08 16:33:56.986 [ZeusMonitor] Running indefinitely. 2022-12-08 16:33:56.986 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:33:56.987 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e71+gpu0.power.log
2022-12-08 11:34:41,733 [ZeusDataLoader(train)] train epoch 71 done: time=44.93 energy=6830.11
2022-12-08 11:34:41,737 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 0.3114
Training Epoch: 70 [2048/50176]	Loss: 0.2977
Training Epoch: 70 [3072/50176]	Loss: 0.2572
Training Epoch: 70 [4096/50176]	Loss: 0.2540
Training Epoch: 70 [5120/50176]	Loss: 0.2590
Training Epoch: 70 [6144/50176]	Loss: 0.2469
Training Epoch: 70 [7168/50176]	Loss: 0.2723
Training Epoch: 70 [8192/50176]	Loss: 0.2450
Training Epoch: 70 [9216/50176]	Loss: 0.2709
Training Epoch: 70 [10240/50176]	Loss: 0.2920
Training Epoch: 70 [11264/50176]	Loss: 0.2313
Training Epoch: 70 [12288/50176]	Loss: 0.2329
Training Epoch: 70 [13312/50176]	Loss: 0.2835
Training Epoch: 70 [14336/50176]	Loss: 0.3011
Training Epoch: 70 [15360/50176]	Loss: 0.2366
Training Epoch: 70 [16384/50176]	Loss: 0.2804
Training Epoch: 70 [17408/50176]	Loss: 0.2240
Training Epoch: 70 [18432/50176]	Loss: 0.2583
Training Epoch: 70 [19456/50176]	Loss: 0.2804
Training Epoch: 70 [20480/50176]	Loss: 0.2950
Training Epoch: 70 [21504/50176]	Loss: 0.2532
Training Epoch: 70 [22528/50176]	Loss: 0.2880
Training Epoch: 70 [23552/50176]	Loss: 0.2764
Training Epoch: 70 [24576/50176]	Loss: 0.2913
Training Epoch: 70 [25600/50176]	Loss: 0.2537
Training Epoch: 70 [26624/50176]	Loss: 0.2917
Training Epoch: 70 [27648/50176]	Loss: 0.2895
Training Epoch: 70 [28672/50176]	Loss: 0.3030
Training Epoch: 70 [29696/50176]	Loss: 0.2601
Training Epoch: 70 [30720/50176]	Loss: 0.2590
Training Epoch: 70 [31744/50176]	Loss: 0.2784
Training Epoch: 70 [32768/50176]	Loss: 0.2764
Training Epoch: 70 [33792/50176]	Loss: 0.2938
Training Epoch: 70 [34816/50176]	Loss: 0.2592
Training Epoch: 70 [35840/50176]	Loss: 0.3311
Training Epoch: 70 [36864/50176]	Loss: 0.3049
Training Epoch: 70 [37888/50176]	Loss: 0.2746
Training Epoch: 70 [38912/50176]	Loss: 0.3096
Training Epoch: 70 [39936/50176]	Loss: 0.3458
Training Epoch: 70 [40960/50176]	Loss: 0.3230
Training Epoch: 70 [41984/50176]	Loss: 0.2563
Training Epoch: 70 [43008/50176]	Loss: 0.3025
Training Epoch: 70 [44032/50176]	Loss: 0.3266
Training Epoch: 70 [45056/50176]	Loss: 0.3005
Training Epoch: 70 [46080/50176]	Loss: 0.2711
Training Epoch: 70 [47104/50176]	Loss: 0.3038
Training Epoch: 70 [48128/50176]	Loss: 0.3259
Training Epoch: 70 [49152/50176]	Loss: 0.3037
Training Epoch: 70 [50176/50176]	Loss: 0.3291
2022-12-08 16:34:46.397 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:34:46,427 [ZeusDataLoader(eval)] eval epoch 71 done: time=4.68 energy=591.83
2022-12-08 11:34:46,427 [ZeusDataLoader(train)] Up to epoch 71: time=3534.73, energy=524625.82, cost=571602.11
2022-12-08 11:34:46,427 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:34:46,428 [ZeusDataLoader(train)] Expected next epoch: time=3582.18, energy=531882.63, cost=579382.38
2022-12-08 11:34:46,429 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 0.0021, Accuracy: 0.5733
2022-12-08 11:34:46,608 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:34:46,609 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:34:46.611 [ZeusMonitor] Monitor started.
2022-12-08 16:34:46.611 [ZeusMonitor] Running indefinitely. 2022-12-08 16:34:46.611 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:34:46.611 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e72+gpu0.power.log
2022-12-08 11:35:31,112 [ZeusDataLoader(train)] train epoch 72 done: time=44.68 energy=6810.73
2022-12-08 11:35:31,116 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 0.2738
Training Epoch: 71 [2048/50176]	Loss: 0.2600
Training Epoch: 71 [3072/50176]	Loss: 0.2818
Training Epoch: 71 [4096/50176]	Loss: 0.2723
Training Epoch: 71 [5120/50176]	Loss: 0.2248
Training Epoch: 71 [6144/50176]	Loss: 0.2387
Training Epoch: 71 [7168/50176]	Loss: 0.2436
Training Epoch: 71 [8192/50176]	Loss: 0.2743
Training Epoch: 71 [9216/50176]	Loss: 0.2439
Training Epoch: 71 [10240/50176]	Loss: 0.2569
Training Epoch: 71 [11264/50176]	Loss: 0.2501
Training Epoch: 71 [12288/50176]	Loss: 0.1997
Training Epoch: 71 [13312/50176]	Loss: 0.2750
Training Epoch: 71 [14336/50176]	Loss: 0.2444
Training Epoch: 71 [15360/50176]	Loss: 0.2538
Training Epoch: 71 [16384/50176]	Loss: 0.2487
Training Epoch: 71 [17408/50176]	Loss: 0.2408
Training Epoch: 71 [18432/50176]	Loss: 0.2330
Training Epoch: 71 [19456/50176]	Loss: 0.2060
Training Epoch: 71 [20480/50176]	Loss: 0.2569
Training Epoch: 71 [21504/50176]	Loss: 0.2291
Training Epoch: 71 [22528/50176]	Loss: 0.2139
Training Epoch: 71 [23552/50176]	Loss: 0.2783
Training Epoch: 71 [24576/50176]	Loss: 0.2576
Training Epoch: 71 [25600/50176]	Loss: 0.2451
Training Epoch: 71 [26624/50176]	Loss: 0.2634
Training Epoch: 71 [27648/50176]	Loss: 0.2825
Training Epoch: 71 [28672/50176]	Loss: 0.2355
Training Epoch: 71 [29696/50176]	Loss: 0.2535
Training Epoch: 71 [30720/50176]	Loss: 0.2239
Training Epoch: 71 [31744/50176]	Loss: 0.2797
Training Epoch: 71 [32768/50176]	Loss: 0.2636
Training Epoch: 71 [33792/50176]	Loss: 0.2760
Training Epoch: 71 [34816/50176]	Loss: 0.2961
Training Epoch: 71 [35840/50176]	Loss: 0.2742
Training Epoch: 71 [36864/50176]	Loss: 0.2744
Training Epoch: 71 [37888/50176]	Loss: 0.2545
Training Epoch: 71 [38912/50176]	Loss: 0.2978
Training Epoch: 71 [39936/50176]	Loss: 0.2858
Training Epoch: 71 [40960/50176]	Loss: 0.2475
Training Epoch: 71 [41984/50176]	Loss: 0.2708
Training Epoch: 71 [43008/50176]	Loss: 0.3117
Training Epoch: 71 [44032/50176]	Loss: 0.3331
Training Epoch: 71 [45056/50176]	Loss: 0.2820
Training Epoch: 71 [46080/50176]	Loss: 0.2874
Training Epoch: 71 [47104/50176]	Loss: 0.2965
Training Epoch: 71 [48128/50176]	Loss: 0.2929
Training Epoch: 71 [49152/50176]	Loss: 0.2984
Training Epoch: 71 [50176/50176]	Loss: 0.2885
2022-12-08 16:35:34.901 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:35:34,945 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.82 energy=541.51
2022-12-08 11:35:34,945 [ZeusDataLoader(train)] Up to epoch 72: time=3583.23, energy=531978.06, cost=579521.55
2022-12-08 11:35:34,945 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:35:34,945 [ZeusDataLoader(train)] Expected next epoch: time=3630.68, energy=539234.87, cost=587301.83
2022-12-08 11:35:34,946 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 0.0021, Accuracy: 0.5827
2022-12-08 11:35:35,132 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:35:35,133 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:35:35.135 [ZeusMonitor] Monitor started.
2022-12-08 16:35:35.135 [ZeusMonitor] Running indefinitely. 2022-12-08 16:35:35.135 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:35:35.135 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e73+gpu0.power.log
2022-12-08 11:36:19,590 [ZeusDataLoader(train)] train epoch 73 done: time=44.64 energy=6790.44
2022-12-08 11:36:19,594 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 0.3115
Training Epoch: 72 [2048/50176]	Loss: 0.2554
Training Epoch: 72 [3072/50176]	Loss: 0.2299
Training Epoch: 72 [4096/50176]	Loss: 0.2510
Training Epoch: 72 [5120/50176]	Loss: 0.2038
Training Epoch: 72 [6144/50176]	Loss: 0.2274
Training Epoch: 72 [7168/50176]	Loss: 0.2284
Training Epoch: 72 [8192/50176]	Loss: 0.2410
Training Epoch: 72 [9216/50176]	Loss: 0.2093
Training Epoch: 72 [10240/50176]	Loss: 0.2401
Training Epoch: 72 [11264/50176]	Loss: 0.2709
Training Epoch: 72 [12288/50176]	Loss: 0.2636
Training Epoch: 72 [13312/50176]	Loss: 0.2362
Training Epoch: 72 [14336/50176]	Loss: 0.2084
Training Epoch: 72 [15360/50176]	Loss: 0.2197
Training Epoch: 72 [16384/50176]	Loss: 0.2790
Training Epoch: 72 [17408/50176]	Loss: 0.2690
Training Epoch: 72 [18432/50176]	Loss: 0.2599
Training Epoch: 72 [19456/50176]	Loss: 0.2573
Training Epoch: 72 [20480/50176]	Loss: 0.2777
Training Epoch: 72 [21504/50176]	Loss: 0.2598
Training Epoch: 72 [22528/50176]	Loss: 0.2996
Training Epoch: 72 [23552/50176]	Loss: 0.2838
Training Epoch: 72 [24576/50176]	Loss: 0.2687
Training Epoch: 72 [25600/50176]	Loss: 0.2726
Training Epoch: 72 [26624/50176]	Loss: 0.3070
Training Epoch: 72 [27648/50176]	Loss: 0.2836
Training Epoch: 72 [28672/50176]	Loss: 0.2614
Training Epoch: 72 [29696/50176]	Loss: 0.2701
Training Epoch: 72 [30720/50176]	Loss: 0.2615
Training Epoch: 72 [31744/50176]	Loss: 0.2528
Training Epoch: 72 [32768/50176]	Loss: 0.2499
Training Epoch: 72 [33792/50176]	Loss: 0.2460
Training Epoch: 72 [34816/50176]	Loss: 0.2182
Training Epoch: 72 [35840/50176]	Loss: 0.2584
Training Epoch: 72 [36864/50176]	Loss: 0.2889
Training Epoch: 72 [37888/50176]	Loss: 0.2969
Training Epoch: 72 [38912/50176]	Loss: 0.3047
Training Epoch: 72 [39936/50176]	Loss: 0.2530
Training Epoch: 72 [40960/50176]	Loss: 0.2765
Training Epoch: 72 [41984/50176]	Loss: 0.2511
Training Epoch: 72 [43008/50176]	Loss: 0.2996
Training Epoch: 72 [44032/50176]	Loss: 0.2619
Training Epoch: 72 [45056/50176]	Loss: 0.2893
Training Epoch: 72 [46080/50176]	Loss: 0.2853
Training Epoch: 72 [47104/50176]	Loss: 0.3106
Training Epoch: 72 [48128/50176]	Loss: 0.3172
Training Epoch: 72 [49152/50176]	Loss: 0.3036
Training Epoch: 72 [50176/50176]	Loss: 0.2999
2022-12-08 16:36:23.292 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:36:23,334 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.73 energy=523.39
2022-12-08 11:36:23,335 [ZeusDataLoader(train)] Up to epoch 73: time=3631.60, energy=539291.89, cost=587410.60
2022-12-08 11:36:23,335 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:36:23,335 [ZeusDataLoader(train)] Expected next epoch: time=3679.05, energy=546548.70, cost=595190.87
2022-12-08 11:36:23,336 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 0.0021, Accuracy: 0.5779
2022-12-08 11:36:23,521 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:36:23,521 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:36:23.523 [ZeusMonitor] Monitor started.
2022-12-08 16:36:23.523 [ZeusMonitor] Running indefinitely. 2022-12-08 16:36:23.523 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:36:23.523 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e74+gpu0.power.log
2022-12-08 11:37:08,073 [ZeusDataLoader(train)] train epoch 74 done: time=44.73 energy=6808.88
2022-12-08 11:37:08,076 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 0.2360
Training Epoch: 73 [2048/50176]	Loss: 0.2132
Training Epoch: 73 [3072/50176]	Loss: 0.2152
Training Epoch: 73 [4096/50176]	Loss: 0.1898
Training Epoch: 73 [5120/50176]	Loss: 0.2305
Training Epoch: 73 [6144/50176]	Loss: 0.2235
Training Epoch: 73 [7168/50176]	Loss: 0.2340
Training Epoch: 73 [8192/50176]	Loss: 0.2131
Training Epoch: 73 [9216/50176]	Loss: 0.2018
Training Epoch: 73 [10240/50176]	Loss: 0.2225
Training Epoch: 73 [11264/50176]	Loss: 0.2038
Training Epoch: 73 [12288/50176]	Loss: 0.2328
Training Epoch: 73 [13312/50176]	Loss: 0.2277
Training Epoch: 73 [14336/50176]	Loss: 0.2270
Training Epoch: 73 [15360/50176]	Loss: 0.2449
Training Epoch: 73 [16384/50176]	Loss: 0.2544
Training Epoch: 73 [17408/50176]	Loss: 0.2291
Training Epoch: 73 [18432/50176]	Loss: 0.2107
Training Epoch: 73 [19456/50176]	Loss: 0.2361
Training Epoch: 73 [20480/50176]	Loss: 0.2688
Training Epoch: 73 [21504/50176]	Loss: 0.2830
Training Epoch: 73 [22528/50176]	Loss: 0.2520
Training Epoch: 73 [23552/50176]	Loss: 0.2424
Training Epoch: 73 [24576/50176]	Loss: 0.2268
Training Epoch: 73 [25600/50176]	Loss: 0.2414
Training Epoch: 73 [26624/50176]	Loss: 0.2325
Training Epoch: 73 [27648/50176]	Loss: 0.2515
Training Epoch: 73 [28672/50176]	Loss: 0.2709
Training Epoch: 73 [29696/50176]	Loss: 0.3005
Training Epoch: 73 [30720/50176]	Loss: 0.2773
Training Epoch: 73 [31744/50176]	Loss: 0.2655
Training Epoch: 73 [32768/50176]	Loss: 0.2436
Training Epoch: 73 [33792/50176]	Loss: 0.2698
Training Epoch: 73 [34816/50176]	Loss: 0.2727
Training Epoch: 73 [35840/50176]	Loss: 0.2667
Training Epoch: 73 [36864/50176]	Loss: 0.2244
Training Epoch: 73 [37888/50176]	Loss: 0.2716
Training Epoch: 73 [38912/50176]	Loss: 0.2687
Training Epoch: 73 [39936/50176]	Loss: 0.2451
Training Epoch: 73 [40960/50176]	Loss: 0.2323
Training Epoch: 73 [41984/50176]	Loss: 0.2849
Training Epoch: 73 [43008/50176]	Loss: 0.2668
Training Epoch: 73 [44032/50176]	Loss: 0.2798
Training Epoch: 73 [45056/50176]	Loss: 0.2506
Training Epoch: 73 [46080/50176]	Loss: 0.3122
Training Epoch: 73 [47104/50176]	Loss: 0.3014
Training Epoch: 73 [48128/50176]	Loss: 0.2579
Training Epoch: 73 [49152/50176]	Loss: 0.2911
Training Epoch: 73 [50176/50176]	Loss: 0.3086
2022-12-08 16:37:11.861 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:37:11,897 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.81 energy=537.05
2022-12-08 11:37:11,898 [ZeusDataLoader(train)] Up to epoch 74: time=3680.14, energy=546637.82, cost=595330.84
2022-12-08 11:37:11,898 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:37:11,898 [ZeusDataLoader(train)] Expected next epoch: time=3727.59, energy=553894.63, cost=603111.12
2022-12-08 11:37:11,899 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 0.0023, Accuracy: 0.5597
2022-12-08 11:37:12,086 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:37:12,087 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:37:12.101 [ZeusMonitor] Monitor started.
2022-12-08 16:37:12.101 [ZeusMonitor] Running indefinitely. 2022-12-08 16:37:12.101 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:37:12.101 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e75+gpu0.power.log
2022-12-08 11:37:56,528 [ZeusDataLoader(train)] train epoch 75 done: time=44.62 energy=6794.45
2022-12-08 11:37:56,531 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 0.2573
Training Epoch: 74 [2048/50176]	Loss: 0.2374
Training Epoch: 74 [3072/50176]	Loss: 0.2920
Training Epoch: 74 [4096/50176]	Loss: 0.2123
Training Epoch: 74 [5120/50176]	Loss: 0.2325
Training Epoch: 74 [6144/50176]	Loss: 0.2137
Training Epoch: 74 [7168/50176]	Loss: 0.2687
Training Epoch: 74 [8192/50176]	Loss: 0.2393
Training Epoch: 74 [9216/50176]	Loss: 0.2427
Training Epoch: 74 [10240/50176]	Loss: 0.2427
Training Epoch: 74 [11264/50176]	Loss: 0.2251
Training Epoch: 74 [12288/50176]	Loss: 0.2314
Training Epoch: 74 [13312/50176]	Loss: 0.2301
Training Epoch: 74 [14336/50176]	Loss: 0.2265
Training Epoch: 74 [15360/50176]	Loss: 0.2192
Training Epoch: 74 [16384/50176]	Loss: 0.2206
Training Epoch: 74 [17408/50176]	Loss: 0.2310
Training Epoch: 74 [18432/50176]	Loss: 0.2490
Training Epoch: 74 [19456/50176]	Loss: 0.1789
Training Epoch: 74 [20480/50176]	Loss: 0.2189
Training Epoch: 74 [21504/50176]	Loss: 0.2219
Training Epoch: 74 [22528/50176]	Loss: 0.2558
Training Epoch: 74 [23552/50176]	Loss: 0.2669
Training Epoch: 74 [24576/50176]	Loss: 0.2355
Training Epoch: 74 [25600/50176]	Loss: 0.2629
Training Epoch: 74 [26624/50176]	Loss: 0.2447
Training Epoch: 74 [27648/50176]	Loss: 0.2273
Training Epoch: 74 [28672/50176]	Loss: 0.2495
Training Epoch: 74 [29696/50176]	Loss: 0.2569
Training Epoch: 74 [30720/50176]	Loss: 0.2154
Training Epoch: 74 [31744/50176]	Loss: 0.2490
Training Epoch: 74 [32768/50176]	Loss: 0.3094
Training Epoch: 74 [33792/50176]	Loss: 0.2877
Training Epoch: 74 [34816/50176]	Loss: 0.2775
Training Epoch: 74 [35840/50176]	Loss: 0.2413
Training Epoch: 74 [36864/50176]	Loss: 0.2218
Training Epoch: 74 [37888/50176]	Loss: 0.2202
Training Epoch: 74 [38912/50176]	Loss: 0.2679
Training Epoch: 74 [39936/50176]	Loss: 0.2921
Training Epoch: 74 [40960/50176]	Loss: 0.2206
Training Epoch: 74 [41984/50176]	Loss: 0.2326
Training Epoch: 74 [43008/50176]	Loss: 0.2690
Training Epoch: 74 [44032/50176]	Loss: 0.2657
Training Epoch: 74 [45056/50176]	Loss: 0.2458
Training Epoch: 74 [46080/50176]	Loss: 0.2624
Training Epoch: 74 [47104/50176]	Loss: 0.2640
Training Epoch: 74 [48128/50176]	Loss: 0.2584
Training Epoch: 74 [49152/50176]	Loss: 0.2562
Training Epoch: 74 [50176/50176]	Loss: 0.2565
2022-12-08 16:38:00.261 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:38:00,299 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.76 energy=519.68
2022-12-08 11:38:00,300 [ZeusDataLoader(train)] Up to epoch 75: time=3728.52, energy=553951.95, cost=603221.18
2022-12-08 11:38:00,300 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:38:00,300 [ZeusDataLoader(train)] Expected next epoch: time=3775.97, energy=561208.76, cost=611001.45
2022-12-08 11:38:00,301 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 0.0023, Accuracy: 0.5800
2022-12-08 11:38:00,455 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:38:00,456 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:38:00.460 [ZeusMonitor] Monitor started.
2022-12-08 16:38:00.460 [ZeusMonitor] Running indefinitely. 2022-12-08 16:38:00.460 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:38:00.460 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e76+gpu0.power.log
2022-12-08 11:38:44,951 [ZeusDataLoader(train)] train epoch 76 done: time=44.64 energy=6809.05
2022-12-08 11:38:44,955 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 0.2136
Training Epoch: 75 [2048/50176]	Loss: 0.1734
Training Epoch: 75 [3072/50176]	Loss: 0.1934
Training Epoch: 75 [4096/50176]	Loss: 0.2014
Training Epoch: 75 [5120/50176]	Loss: 0.1892
Training Epoch: 75 [6144/50176]	Loss: 0.2218
Training Epoch: 75 [7168/50176]	Loss: 0.1950
Training Epoch: 75 [8192/50176]	Loss: 0.1984
Training Epoch: 75 [9216/50176]	Loss: 0.1878
Training Epoch: 75 [10240/50176]	Loss: 0.2122
Training Epoch: 75 [11264/50176]	Loss: 0.2135
Training Epoch: 75 [12288/50176]	Loss: 0.2200
Training Epoch: 75 [13312/50176]	Loss: 0.1964
Training Epoch: 75 [14336/50176]	Loss: 0.2180
Training Epoch: 75 [15360/50176]	Loss: 0.1992
Training Epoch: 75 [16384/50176]	Loss: 0.2326
Training Epoch: 75 [17408/50176]	Loss: 0.2458
Training Epoch: 75 [18432/50176]	Loss: 0.2547
Training Epoch: 75 [19456/50176]	Loss: 0.2257
Training Epoch: 75 [20480/50176]	Loss: 0.2470
Training Epoch: 75 [21504/50176]	Loss: 0.2219
Training Epoch: 75 [22528/50176]	Loss: 0.2195
Training Epoch: 75 [23552/50176]	Loss: 0.2524
Training Epoch: 75 [24576/50176]	Loss: 0.1987
Training Epoch: 75 [25600/50176]	Loss: 0.2541
Training Epoch: 75 [26624/50176]	Loss: 0.2541
Training Epoch: 75 [27648/50176]	Loss: 0.2348
Training Epoch: 75 [28672/50176]	Loss: 0.2483
Training Epoch: 75 [29696/50176]	Loss: 0.2349
Training Epoch: 75 [30720/50176]	Loss: 0.2137
Training Epoch: 75 [31744/50176]	Loss: 0.2245
Training Epoch: 75 [32768/50176]	Loss: 0.2727
Training Epoch: 75 [33792/50176]	Loss: 0.2160
Training Epoch: 75 [34816/50176]	Loss: 0.2348
Training Epoch: 75 [35840/50176]	Loss: 0.2330
Training Epoch: 75 [36864/50176]	Loss: 0.2838
Training Epoch: 75 [37888/50176]	Loss: 0.2646
Training Epoch: 75 [38912/50176]	Loss: 0.2528
Training Epoch: 75 [39936/50176]	Loss: 0.2671
Training Epoch: 75 [40960/50176]	Loss: 0.2279
Training Epoch: 75 [41984/50176]	Loss: 0.2774
Training Epoch: 75 [43008/50176]	Loss: 0.2590
Training Epoch: 75 [44032/50176]	Loss: 0.2626
Training Epoch: 75 [45056/50176]	Loss: 0.2536
Training Epoch: 75 [46080/50176]	Loss: 0.2692
Training Epoch: 75 [47104/50176]	Loss: 0.2126
Training Epoch: 75 [48128/50176]	Loss: 0.2623
Training Epoch: 75 [49152/50176]	Loss: 0.2323
Training Epoch: 75 [50176/50176]	Loss: 0.2542
2022-12-08 16:38:48.689 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:38:48,720 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.76 energy=533.68
2022-12-08 11:38:48,721 [ZeusDataLoader(train)] Up to epoch 76: time=3776.91, energy=561294.68, cost=611127.28
2022-12-08 11:38:48,721 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:38:48,721 [ZeusDataLoader(train)] Expected next epoch: time=3824.36, energy=568551.49, cost=618907.55
2022-12-08 11:38:48,722 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 0.0023, Accuracy: 0.5766
2022-12-08 11:38:48,925 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:38:48,926 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:38:48.928 [ZeusMonitor] Monitor started.
2022-12-08 16:38:48.928 [ZeusMonitor] Running indefinitely. 2022-12-08 16:38:48.928 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:38:48.928 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e77+gpu0.power.log
2022-12-08 11:39:33,411 [ZeusDataLoader(train)] train epoch 77 done: time=44.68 energy=6807.53
2022-12-08 11:39:33,414 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 0.2211
Training Epoch: 76 [2048/50176]	Loss: 0.2080
Training Epoch: 76 [3072/50176]	Loss: 0.2148
Training Epoch: 76 [4096/50176]	Loss: 0.1676
Training Epoch: 76 [5120/50176]	Loss: 0.2197
Training Epoch: 76 [6144/50176]	Loss: 0.1800
Training Epoch: 76 [7168/50176]	Loss: 0.1914
Training Epoch: 76 [8192/50176]	Loss: 0.1815
Training Epoch: 76 [9216/50176]	Loss: 0.1672
Training Epoch: 76 [10240/50176]	Loss: 0.1941
Training Epoch: 76 [11264/50176]	Loss: 0.2000
Training Epoch: 76 [12288/50176]	Loss: 0.2242
Training Epoch: 76 [13312/50176]	Loss: 0.2300
Training Epoch: 76 [14336/50176]	Loss: 0.2241
Training Epoch: 76 [15360/50176]	Loss: 0.2314
Training Epoch: 76 [16384/50176]	Loss: 0.2423
Training Epoch: 76 [17408/50176]	Loss: 0.2412
Training Epoch: 76 [18432/50176]	Loss: 0.2058
Training Epoch: 76 [19456/50176]	Loss: 0.2088
Training Epoch: 76 [20480/50176]	Loss: 0.2368
Training Epoch: 76 [21504/50176]	Loss: 0.2158
Training Epoch: 76 [22528/50176]	Loss: 0.2163
Training Epoch: 76 [23552/50176]	Loss: 0.2254
Training Epoch: 76 [24576/50176]	Loss: 0.2275
Training Epoch: 76 [25600/50176]	Loss: 0.2315
Training Epoch: 76 [26624/50176]	Loss: 0.1997
Training Epoch: 76 [27648/50176]	Loss: 0.2202
Training Epoch: 76 [28672/50176]	Loss: 0.2274
Training Epoch: 76 [29696/50176]	Loss: 0.2144
Training Epoch: 76 [30720/50176]	Loss: 0.2465
Training Epoch: 76 [31744/50176]	Loss: 0.2620
Training Epoch: 76 [32768/50176]	Loss: 0.2438
Training Epoch: 76 [33792/50176]	Loss: 0.2330
Training Epoch: 76 [34816/50176]	Loss: 0.2429
Training Epoch: 76 [35840/50176]	Loss: 0.2758
Training Epoch: 76 [36864/50176]	Loss: 0.2186
Training Epoch: 76 [37888/50176]	Loss: 0.2145
Training Epoch: 76 [38912/50176]	Loss: 0.2631
Training Epoch: 76 [39936/50176]	Loss: 0.2798
Training Epoch: 76 [40960/50176]	Loss: 0.2569
Training Epoch: 76 [41984/50176]	Loss: 0.2517
Training Epoch: 76 [43008/50176]	Loss: 0.2876
Training Epoch: 76 [44032/50176]	Loss: 0.2594
Training Epoch: 76 [45056/50176]	Loss: 0.2681
Training Epoch: 76 [46080/50176]	Loss: 0.2626
Training Epoch: 76 [47104/50176]	Loss: 0.2279
Training Epoch: 76 [48128/50176]	Loss: 0.2394
Training Epoch: 76 [49152/50176]	Loss: 0.2650
Training Epoch: 76 [50176/50176]	Loss: 0.2660
2022-12-08 16:39:37.179 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:39:37,221 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.80 energy=524.43
2022-12-08 11:39:37,222 [ZeusDataLoader(train)] Up to epoch 77: time=3825.39, energy=568626.64, cost=619035.14
2022-12-08 11:39:37,222 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:39:37,222 [ZeusDataLoader(train)] Expected next epoch: time=3872.84, energy=575883.45, cost=626815.41
2022-12-08 11:39:37,223 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0023, Accuracy: 0.5730
2022-12-08 11:39:37,413 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:39:37,414 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:39:37.416 [ZeusMonitor] Monitor started.
2022-12-08 16:39:37.416 [ZeusMonitor] Running indefinitely. 2022-12-08 16:39:37.416 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:39:37.416 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e78+gpu0.power.log
2022-12-08 11:40:21,830 [ZeusDataLoader(train)] train epoch 78 done: time=44.60 energy=6798.79
2022-12-08 11:40:21,834 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 0.2076
Training Epoch: 77 [2048/50176]	Loss: 0.1983
Training Epoch: 77 [3072/50176]	Loss: 0.2030
Training Epoch: 77 [4096/50176]	Loss: 0.2007
Training Epoch: 77 [5120/50176]	Loss: 0.1991
Training Epoch: 77 [6144/50176]	Loss: 0.1985
Training Epoch: 77 [7168/50176]	Loss: 0.1775
Training Epoch: 77 [8192/50176]	Loss: 0.1951
Training Epoch: 77 [9216/50176]	Loss: 0.2149
Training Epoch: 77 [10240/50176]	Loss: 0.2041
Training Epoch: 77 [11264/50176]	Loss: 0.1788
Training Epoch: 77 [12288/50176]	Loss: 0.1623
Training Epoch: 77 [13312/50176]	Loss: 0.1803
Training Epoch: 77 [14336/50176]	Loss: 0.2002
Training Epoch: 77 [15360/50176]	Loss: 0.1924
Training Epoch: 77 [16384/50176]	Loss: 0.1971
Training Epoch: 77 [17408/50176]	Loss: 0.2148
Training Epoch: 77 [18432/50176]	Loss: 0.1967
Training Epoch: 77 [19456/50176]	Loss: 0.2103
Training Epoch: 77 [20480/50176]	Loss: 0.1901
Training Epoch: 77 [21504/50176]	Loss: 0.1948
Training Epoch: 77 [22528/50176]	Loss: 0.2064
Training Epoch: 77 [23552/50176]	Loss: 0.1891
Training Epoch: 77 [24576/50176]	Loss: 0.2149
Training Epoch: 77 [25600/50176]	Loss: 0.1991
Training Epoch: 77 [26624/50176]	Loss: 0.2034
Training Epoch: 77 [27648/50176]	Loss: 0.2195
Training Epoch: 77 [28672/50176]	Loss: 0.2416
Training Epoch: 77 [29696/50176]	Loss: 0.2180
Training Epoch: 77 [30720/50176]	Loss: 0.2347
Training Epoch: 77 [31744/50176]	Loss: 0.2044
Training Epoch: 77 [32768/50176]	Loss: 0.1982
Training Epoch: 77 [33792/50176]	Loss: 0.2522
Training Epoch: 77 [34816/50176]	Loss: 0.2491
Training Epoch: 77 [35840/50176]	Loss: 0.2575
Training Epoch: 77 [36864/50176]	Loss: 0.2393
Training Epoch: 77 [37888/50176]	Loss: 0.2427
Training Epoch: 77 [38912/50176]	Loss: 0.1803
Training Epoch: 77 [39936/50176]	Loss: 0.2231
Training Epoch: 77 [40960/50176]	Loss: 0.2053
Training Epoch: 77 [41984/50176]	Loss: 0.2244
Training Epoch: 77 [43008/50176]	Loss: 0.2473
Training Epoch: 77 [44032/50176]	Loss: 0.2584
Training Epoch: 77 [45056/50176]	Loss: 0.2161
Training Epoch: 77 [46080/50176]	Loss: 0.2322
Training Epoch: 77 [47104/50176]	Loss: 0.2272
Training Epoch: 77 [48128/50176]	Loss: 0.2116
Training Epoch: 77 [49152/50176]	Loss: 0.2347
Training Epoch: 77 [50176/50176]	Loss: 0.2395
2022-12-08 16:40:25.553 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:40:25,577 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.73 energy=524.62
2022-12-08 11:40:25,578 [ZeusDataLoader(train)] Up to epoch 78: time=3873.73, energy=575950.04, cost=626926.01
2022-12-08 11:40:25,578 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:40:25,578 [ZeusDataLoader(train)] Expected next epoch: time=3921.18, energy=583206.85, cost=634706.29
2022-12-08 11:40:25,579 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0022, Accuracy: 0.5796
2022-12-08 11:40:25,745 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:40:25,746 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:40:25.748 [ZeusMonitor] Monitor started.
2022-12-08 16:40:25.748 [ZeusMonitor] Running indefinitely. 2022-12-08 16:40:25.748 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:40:25.748 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e79+gpu0.power.log
2022-12-08 11:41:10,235 [ZeusDataLoader(train)] train epoch 79 done: time=44.65 energy=6797.64
2022-12-08 11:41:10,238 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 0.1772
Training Epoch: 78 [2048/50176]	Loss: 0.1722
Training Epoch: 78 [3072/50176]	Loss: 0.1717
Training Epoch: 78 [4096/50176]	Loss: 0.1913
Training Epoch: 78 [5120/50176]	Loss: 0.1895
Training Epoch: 78 [6144/50176]	Loss: 0.1410
Training Epoch: 78 [7168/50176]	Loss: 0.1569
Training Epoch: 78 [8192/50176]	Loss: 0.1904
Training Epoch: 78 [9216/50176]	Loss: 0.2127
Training Epoch: 78 [10240/50176]	Loss: 0.1965
Training Epoch: 78 [11264/50176]	Loss: 0.1935
Training Epoch: 78 [12288/50176]	Loss: 0.1938
Training Epoch: 78 [13312/50176]	Loss: 0.2178
Training Epoch: 78 [14336/50176]	Loss: 0.2089
Training Epoch: 78 [15360/50176]	Loss: 0.2325
Training Epoch: 78 [16384/50176]	Loss: 0.2247
Training Epoch: 78 [17408/50176]	Loss: 0.1973
Training Epoch: 78 [18432/50176]	Loss: 0.2236
Training Epoch: 78 [19456/50176]	Loss: 0.2102
Training Epoch: 78 [20480/50176]	Loss: 0.2242
Training Epoch: 78 [21504/50176]	Loss: 0.2402
Training Epoch: 78 [22528/50176]	Loss: 0.2004
Training Epoch: 78 [23552/50176]	Loss: 0.1850
Training Epoch: 78 [24576/50176]	Loss: 0.2129
Training Epoch: 78 [25600/50176]	Loss: 0.2021
Training Epoch: 78 [26624/50176]	Loss: 0.2205
Training Epoch: 78 [27648/50176]	Loss: 0.2153
Training Epoch: 78 [28672/50176]	Loss: 0.2137
Training Epoch: 78 [29696/50176]	Loss: 0.2271
Training Epoch: 78 [30720/50176]	Loss: 0.2367
Training Epoch: 78 [31744/50176]	Loss: 0.2409
Training Epoch: 78 [32768/50176]	Loss: 0.2525
Training Epoch: 78 [33792/50176]	Loss: 0.2075
Training Epoch: 78 [34816/50176]	Loss: 0.2301
Training Epoch: 78 [35840/50176]	Loss: 0.2260
Training Epoch: 78 [36864/50176]	Loss: 0.2155
Training Epoch: 78 [37888/50176]	Loss: 0.2149
Training Epoch: 78 [38912/50176]	Loss: 0.2047
Training Epoch: 78 [39936/50176]	Loss: 0.2083
Training Epoch: 78 [40960/50176]	Loss: 0.1878
Training Epoch: 78 [41984/50176]	Loss: 0.1805
Training Epoch: 78 [43008/50176]	Loss: 0.2353
Training Epoch: 78 [44032/50176]	Loss: 0.2068
Training Epoch: 78 [45056/50176]	Loss: 0.2648
Training Epoch: 78 [46080/50176]	Loss: 0.2011
Training Epoch: 78 [47104/50176]	Loss: 0.2085
Training Epoch: 78 [48128/50176]	Loss: 0.2166
Training Epoch: 78 [49152/50176]	Loss: 0.2136
Training Epoch: 78 [50176/50176]	Loss: 0.1905
2022-12-08 16:41:13.983 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:41:14,015 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.77 energy=521.74
2022-12-08 11:41:14,015 [ZeusDataLoader(train)] Up to epoch 79: time=3922.14, energy=583269.42, cost=634822.03
2022-12-08 11:41:14,015 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:41:14,015 [ZeusDataLoader(train)] Expected next epoch: time=3969.59, energy=590526.23, cost=642602.30
2022-12-08 11:41:14,016 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 0.0022, Accuracy: 0.5830
2022-12-08 11:41:14,196 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:41:14,197 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:41:14.215 [ZeusMonitor] Monitor started.
2022-12-08 16:41:14.215 [ZeusMonitor] Running indefinitely. 2022-12-08 16:41:14.215 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:41:14.215 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e80+gpu0.power.log
2022-12-08 11:41:58,592 [ZeusDataLoader(train)] train epoch 80 done: time=44.57 energy=6787.62
2022-12-08 11:41:58,596 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 0.1989
Training Epoch: 79 [2048/50176]	Loss: 0.2018
Training Epoch: 79 [3072/50176]	Loss: 0.1865
Training Epoch: 79 [4096/50176]	Loss: 0.1840
Training Epoch: 79 [5120/50176]	Loss: 0.1673
Training Epoch: 79 [6144/50176]	Loss: 0.1569
Training Epoch: 79 [7168/50176]	Loss: 0.1733
Training Epoch: 79 [8192/50176]	Loss: 0.1789
Training Epoch: 79 [9216/50176]	Loss: 0.1670
Training Epoch: 79 [10240/50176]	Loss: 0.1730
Training Epoch: 79 [11264/50176]	Loss: 0.1703
Training Epoch: 79 [12288/50176]	Loss: 0.1968
Training Epoch: 79 [13312/50176]	Loss: 0.1870
Training Epoch: 79 [14336/50176]	Loss: 0.1616
Training Epoch: 79 [15360/50176]	Loss: 0.1612
Training Epoch: 79 [16384/50176]	Loss: 0.1759
Training Epoch: 79 [17408/50176]	Loss: 0.1965
Training Epoch: 79 [18432/50176]	Loss: 0.1724
Training Epoch: 79 [19456/50176]	Loss: 0.2073
Training Epoch: 79 [20480/50176]	Loss: 0.1834
Training Epoch: 79 [21504/50176]	Loss: 0.2042
Training Epoch: 79 [22528/50176]	Loss: 0.2073
Training Epoch: 79 [23552/50176]	Loss: 0.1937
Training Epoch: 79 [24576/50176]	Loss: 0.2005
Training Epoch: 79 [25600/50176]	Loss: 0.2005
Training Epoch: 79 [26624/50176]	Loss: 0.2161
Training Epoch: 79 [27648/50176]	Loss: 0.1950
Training Epoch: 79 [28672/50176]	Loss: 0.2143
Training Epoch: 79 [29696/50176]	Loss: 0.2438
Training Epoch: 79 [30720/50176]	Loss: 0.1966
Training Epoch: 79 [31744/50176]	Loss: 0.2048
Training Epoch: 79 [32768/50176]	Loss: 0.2287
Training Epoch: 79 [33792/50176]	Loss: 0.1956
Training Epoch: 79 [34816/50176]	Loss: 0.2168
Training Epoch: 79 [35840/50176]	Loss: 0.2023
Training Epoch: 79 [36864/50176]	Loss: 0.1957
Training Epoch: 79 [37888/50176]	Loss: 0.2047
Training Epoch: 79 [38912/50176]	Loss: 0.2308
Training Epoch: 79 [39936/50176]	Loss: 0.2051
Training Epoch: 79 [40960/50176]	Loss: 0.2344
Training Epoch: 79 [41984/50176]	Loss: 0.1847
Training Epoch: 79 [43008/50176]	Loss: 0.2240
Training Epoch: 79 [44032/50176]	Loss: 0.2360
Training Epoch: 79 [45056/50176]	Loss: 0.2010
Training Epoch: 79 [46080/50176]	Loss: 0.2286
Training Epoch: 79 [47104/50176]	Loss: 0.2414
Training Epoch: 79 [48128/50176]	Loss: 0.2163
Training Epoch: 79 [49152/50176]	Loss: 0.2053
Training Epoch: 79 [50176/50176]	Loss: 0.2278
2022-12-08 16:42:02.337 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:42:02,368 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.76 energy=525.01
2022-12-08 11:42:02,368 [ZeusDataLoader(train)] Up to epoch 80: time=3970.47, energy=590582.05, cost=642707.22
2022-12-08 11:42:02,368 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:42:02,368 [ZeusDataLoader(train)] Expected next epoch: time=4017.92, energy=597838.86, cost=650487.49
2022-12-08 11:42:02,369 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 0.0023, Accuracy: 0.5803
2022-12-08 11:42:02,564 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:42:02,565 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:42:02.567 [ZeusMonitor] Monitor started.
2022-12-08 16:42:02.567 [ZeusMonitor] Running indefinitely. 2022-12-08 16:42:02.567 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:42:02.567 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e81+gpu0.power.log
2022-12-08 11:42:47,171 [ZeusDataLoader(train)] train epoch 81 done: time=44.79 energy=6808.94
2022-12-08 11:42:47,174 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 0.1817
Training Epoch: 80 [2048/50176]	Loss: 0.1787
Training Epoch: 80 [3072/50176]	Loss: 0.1866
Training Epoch: 80 [4096/50176]	Loss: 0.1671
Training Epoch: 80 [5120/50176]	Loss: 0.1762
Training Epoch: 80 [6144/50176]	Loss: 0.1458
Training Epoch: 80 [7168/50176]	Loss: 0.1794
Training Epoch: 80 [8192/50176]	Loss: 0.1679
Training Epoch: 80 [9216/50176]	Loss: 0.1499
Training Epoch: 80 [10240/50176]	Loss: 0.1685
Training Epoch: 80 [11264/50176]	Loss: 0.1526
Training Epoch: 80 [12288/50176]	Loss: 0.1648
Training Epoch: 80 [13312/50176]	Loss: 0.2069
Training Epoch: 80 [14336/50176]	Loss: 0.1921
Training Epoch: 80 [15360/50176]	Loss: 0.1805
Training Epoch: 80 [16384/50176]	Loss: 0.1713
Training Epoch: 80 [17408/50176]	Loss: 0.1865
Training Epoch: 80 [18432/50176]	Loss: 0.1630
Training Epoch: 80 [19456/50176]	Loss: 0.1959
Training Epoch: 80 [20480/50176]	Loss: 0.1774
Training Epoch: 80 [21504/50176]	Loss: 0.1929
Training Epoch: 80 [22528/50176]	Loss: 0.2070
Training Epoch: 80 [23552/50176]	Loss: 0.2125
Training Epoch: 80 [24576/50176]	Loss: 0.2263
Training Epoch: 80 [25600/50176]	Loss: 0.1807
Training Epoch: 80 [26624/50176]	Loss: 0.1938
Training Epoch: 80 [27648/50176]	Loss: 0.2105
Training Epoch: 80 [28672/50176]	Loss: 0.2039
Training Epoch: 80 [29696/50176]	Loss: 0.2205
Training Epoch: 80 [30720/50176]	Loss: 0.1991
Training Epoch: 80 [31744/50176]	Loss: 0.1949
Training Epoch: 80 [32768/50176]	Loss: 0.1969
Training Epoch: 80 [33792/50176]	Loss: 0.2312
Training Epoch: 80 [34816/50176]	Loss: 0.2067
Training Epoch: 80 [35840/50176]	Loss: 0.1895
Training Epoch: 80 [36864/50176]	Loss: 0.2272
Training Epoch: 80 [37888/50176]	Loss: 0.1843
Training Epoch: 80 [38912/50176]	Loss: 0.2137
Training Epoch: 80 [39936/50176]	Loss: 0.2439
Training Epoch: 80 [40960/50176]	Loss: 0.1947
Training Epoch: 80 [41984/50176]	Loss: 0.2093
Training Epoch: 80 [43008/50176]	Loss: 0.1984
Training Epoch: 80 [44032/50176]	Loss: 0.2481
Training Epoch: 80 [45056/50176]	Loss: 0.2403
Training Epoch: 80 [46080/50176]	Loss: 0.2207
Training Epoch: 80 [47104/50176]	Loss: 0.2121
Training Epoch: 80 [48128/50176]	Loss: 0.2165
Training Epoch: 80 [49152/50176]	Loss: 0.2188
Training Epoch: 80 [50176/50176]	Loss: 0.2568
2022-12-08 16:42:50.870 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:42:50,886 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.70 energy=524.82
2022-12-08 11:42:50,887 [ZeusDataLoader(train)] Up to epoch 81: time=4018.97, energy=597915.81, cost=650617.51
2022-12-08 11:42:50,887 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:42:50,887 [ZeusDataLoader(train)] Expected next epoch: time=4066.42, energy=605172.62, cost=658397.79
2022-12-08 11:42:50,888 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0023, Accuracy: 0.5695
2022-12-08 11:42:51,038 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:42:51,039 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:42:51.040 [ZeusMonitor] Monitor started.
2022-12-08 16:42:51.041 [ZeusMonitor] Running indefinitely. 2022-12-08 16:42:51.041 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:42:51.041 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e82+gpu0.power.log
2022-12-08 11:43:35,480 [ZeusDataLoader(train)] train epoch 82 done: time=44.58 energy=6794.87
2022-12-08 11:43:35,484 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 0.1889
Training Epoch: 81 [2048/50176]	Loss: 0.1592
Training Epoch: 81 [3072/50176]	Loss: 0.1629
Training Epoch: 81 [4096/50176]	Loss: 0.2042
Training Epoch: 81 [5120/50176]	Loss: 0.1840
Training Epoch: 81 [6144/50176]	Loss: 0.1964
Training Epoch: 81 [7168/50176]	Loss: 0.1762
Training Epoch: 81 [8192/50176]	Loss: 0.1985
Training Epoch: 81 [9216/50176]	Loss: 0.1919
Training Epoch: 81 [10240/50176]	Loss: 0.1782
Training Epoch: 81 [11264/50176]	Loss: 0.1818
Training Epoch: 81 [12288/50176]	Loss: 0.1859
Training Epoch: 81 [13312/50176]	Loss: 0.1574
Training Epoch: 81 [14336/50176]	Loss: 0.1676
Training Epoch: 81 [15360/50176]	Loss: 0.1736
Training Epoch: 81 [16384/50176]	Loss: 0.1545
Training Epoch: 81 [17408/50176]	Loss: 0.1968
Training Epoch: 81 [18432/50176]	Loss: 0.1910
Training Epoch: 81 [19456/50176]	Loss: 0.1523
Training Epoch: 81 [20480/50176]	Loss: 0.1807
Training Epoch: 81 [21504/50176]	Loss: 0.1760
Training Epoch: 81 [22528/50176]	Loss: 0.1775
Training Epoch: 81 [23552/50176]	Loss: 0.1554
Training Epoch: 81 [24576/50176]	Loss: 0.1599
Training Epoch: 81 [25600/50176]	Loss: 0.1726
Training Epoch: 81 [26624/50176]	Loss: 0.2112
Training Epoch: 81 [27648/50176]	Loss: 0.2077
Training Epoch: 81 [28672/50176]	Loss: 0.1987
Training Epoch: 81 [29696/50176]	Loss: 0.2100
Training Epoch: 81 [30720/50176]	Loss: 0.1562
Training Epoch: 81 [31744/50176]	Loss: 0.1829
Training Epoch: 81 [32768/50176]	Loss: 0.2012
Training Epoch: 81 [33792/50176]	Loss: 0.1922
Training Epoch: 81 [34816/50176]	Loss: 0.1661
Training Epoch: 81 [35840/50176]	Loss: 0.1748
Training Epoch: 81 [36864/50176]	Loss: 0.1889
Training Epoch: 81 [37888/50176]	Loss: 0.2054
Training Epoch: 81 [38912/50176]	Loss: 0.2141
Training Epoch: 81 [39936/50176]	Loss: 0.2022
Training Epoch: 81 [40960/50176]	Loss: 0.2166
Training Epoch: 81 [41984/50176]	Loss: 0.1919
Training Epoch: 81 [43008/50176]	Loss: 0.2124
Training Epoch: 81 [44032/50176]	Loss: 0.2270
Training Epoch: 81 [45056/50176]	Loss: 0.2241
Training Epoch: 81 [46080/50176]	Loss: 0.2211
Training Epoch: 81 [47104/50176]	Loss: 0.2208
Training Epoch: 81 [48128/50176]	Loss: 0.2119
Training Epoch: 81 [49152/50176]	Loss: 0.2329
Training Epoch: 81 [50176/50176]	Loss: 0.2180
2022-12-08 16:43:39.246 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:43:39,292 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.80 energy=535.40
2022-12-08 11:43:39,292 [ZeusDataLoader(train)] Up to epoch 82: time=4067.35, energy=605246.07, cost=658516.11
2022-12-08 11:43:39,292 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:43:39,292 [ZeusDataLoader(train)] Expected next epoch: time=4114.80, energy=612502.88, cost=666296.39
2022-12-08 11:43:39,293 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 0.0023, Accuracy: 0.5765
2022-12-08 11:43:39,484 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:43:39,485 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:43:39.487 [ZeusMonitor] Monitor started.
2022-12-08 16:43:39.487 [ZeusMonitor] Running indefinitely. 2022-12-08 16:43:39.487 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:43:39.487 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e83+gpu0.power.log
2022-12-08 11:44:23,991 [ZeusDataLoader(train)] train epoch 83 done: time=44.69 energy=6797.62
2022-12-08 11:44:23,994 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 0.1820
Training Epoch: 82 [2048/50176]	Loss: 0.1668
Training Epoch: 82 [3072/50176]	Loss: 0.1517
Training Epoch: 82 [4096/50176]	Loss: 0.1646
Training Epoch: 82 [5120/50176]	Loss: 0.1741
Training Epoch: 82 [6144/50176]	Loss: 0.1795
Training Epoch: 82 [7168/50176]	Loss: 0.1705
Training Epoch: 82 [8192/50176]	Loss: 0.1610
Training Epoch: 82 [9216/50176]	Loss: 0.1675
Training Epoch: 82 [10240/50176]	Loss: 0.1717
Training Epoch: 82 [11264/50176]	Loss: 0.1876
Training Epoch: 82 [12288/50176]	Loss: 0.1497
Training Epoch: 82 [13312/50176]	Loss: 0.1703
Training Epoch: 82 [14336/50176]	Loss: 0.1890
Training Epoch: 82 [15360/50176]	Loss: 0.1833
Training Epoch: 82 [16384/50176]	Loss: 0.1637
Training Epoch: 82 [17408/50176]	Loss: 0.1801
Training Epoch: 82 [18432/50176]	Loss: 0.1953
Training Epoch: 82 [19456/50176]	Loss: 0.1638
Training Epoch: 82 [20480/50176]	Loss: 0.2044
Training Epoch: 82 [21504/50176]	Loss: 0.1690
Training Epoch: 82 [22528/50176]	Loss: 0.1585
Training Epoch: 82 [23552/50176]	Loss: 0.1820
Training Epoch: 82 [24576/50176]	Loss: 0.1814
Training Epoch: 82 [25600/50176]	Loss: 0.1733
Training Epoch: 82 [26624/50176]	Loss: 0.1919
Training Epoch: 82 [27648/50176]	Loss: 0.1590
Training Epoch: 82 [28672/50176]	Loss: 0.1706
Training Epoch: 82 [29696/50176]	Loss: 0.1757
Training Epoch: 82 [30720/50176]	Loss: 0.2170
Training Epoch: 82 [31744/50176]	Loss: 0.1722
Training Epoch: 82 [32768/50176]	Loss: 0.1967
Training Epoch: 82 [33792/50176]	Loss: 0.1774
Training Epoch: 82 [34816/50176]	Loss: 0.1901
Training Epoch: 82 [35840/50176]	Loss: 0.2030
Training Epoch: 82 [36864/50176]	Loss: 0.1993
Training Epoch: 82 [37888/50176]	Loss: 0.2026
Training Epoch: 82 [38912/50176]	Loss: 0.1662
Training Epoch: 82 [39936/50176]	Loss: 0.1870
Training Epoch: 82 [40960/50176]	Loss: 0.1932
Training Epoch: 82 [41984/50176]	Loss: 0.1885
Training Epoch: 82 [43008/50176]	Loss: 0.1908
Training Epoch: 82 [44032/50176]	Loss: 0.2089
Training Epoch: 82 [45056/50176]	Loss: 0.2017
Training Epoch: 82 [46080/50176]	Loss: 0.2053
Training Epoch: 82 [47104/50176]	Loss: 0.2292
Training Epoch: 82 [48128/50176]	Loss: 0.2534
Training Epoch: 82 [49152/50176]	Loss: 0.2041
Training Epoch: 82 [50176/50176]	Loss: 0.2004
2022-12-08 16:44:27.715 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:44:27,746 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.74 energy=520.00
2022-12-08 11:44:27,746 [ZeusDataLoader(train)] Up to epoch 83: time=4115.78, energy=612563.69, cost=666412.68
2022-12-08 11:44:27,746 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:44:27,746 [ZeusDataLoader(train)] Expected next epoch: time=4163.23, energy=619820.50, cost=674192.96
2022-12-08 11:44:27,747 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 0.0023, Accuracy: 0.5809
2022-12-08 11:44:27,904 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:44:27,905 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:44:27.908 [ZeusMonitor] Monitor started.
2022-12-08 16:44:27.909 [ZeusMonitor] Running indefinitely. 2022-12-08 16:44:27.909 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:44:27.909 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e84+gpu0.power.log
2022-12-08 11:45:12,466 [ZeusDataLoader(train)] train epoch 84 done: time=44.71 energy=6805.32
2022-12-08 11:45:12,470 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 0.1758
Training Epoch: 83 [2048/50176]	Loss: 0.1424
Training Epoch: 83 [3072/50176]	Loss: 0.1305
Training Epoch: 83 [4096/50176]	Loss: 0.1669
Training Epoch: 83 [5120/50176]	Loss: 0.1797
Training Epoch: 83 [6144/50176]	Loss: 0.1373
Training Epoch: 83 [7168/50176]	Loss: 0.1653
Training Epoch: 83 [8192/50176]	Loss: 0.1743
Training Epoch: 83 [9216/50176]	Loss: 0.1616
Training Epoch: 83 [10240/50176]	Loss: 0.1532
Training Epoch: 83 [11264/50176]	Loss: 0.1427
Training Epoch: 83 [12288/50176]	Loss: 0.1666
Training Epoch: 83 [13312/50176]	Loss: 0.1597
Training Epoch: 83 [14336/50176]	Loss: 0.1756
Training Epoch: 83 [15360/50176]	Loss: 0.1668
Training Epoch: 83 [16384/50176]	Loss: 0.1529
Training Epoch: 83 [17408/50176]	Loss: 0.2036
Training Epoch: 83 [18432/50176]	Loss: 0.1583
Training Epoch: 83 [19456/50176]	Loss: 0.1885
Training Epoch: 83 [20480/50176]	Loss: 0.2008
Training Epoch: 83 [21504/50176]	Loss: 0.2203
Training Epoch: 83 [22528/50176]	Loss: 0.1695
Training Epoch: 83 [23552/50176]	Loss: 0.1900
Training Epoch: 83 [24576/50176]	Loss: 0.1883
Training Epoch: 83 [25600/50176]	Loss: 0.2004
Training Epoch: 83 [26624/50176]	Loss: 0.2049
Training Epoch: 83 [27648/50176]	Loss: 0.1812
Training Epoch: 83 [28672/50176]	Loss: 0.1810
Training Epoch: 83 [29696/50176]	Loss: 0.1992
Training Epoch: 83 [30720/50176]	Loss: 0.1694
Training Epoch: 83 [31744/50176]	Loss: 0.1574
Training Epoch: 83 [32768/50176]	Loss: 0.1870
Training Epoch: 83 [33792/50176]	Loss: 0.1927
Training Epoch: 83 [34816/50176]	Loss: 0.2043
Training Epoch: 83 [35840/50176]	Loss: 0.1826
Training Epoch: 83 [36864/50176]	Loss: 0.2187
Training Epoch: 83 [37888/50176]	Loss: 0.2012
Training Epoch: 83 [38912/50176]	Loss: 0.1852
Training Epoch: 83 [39936/50176]	Loss: 0.2123
Training Epoch: 83 [40960/50176]	Loss: 0.2016
Training Epoch: 83 [41984/50176]	Loss: 0.2424
Training Epoch: 83 [43008/50176]	Loss: 0.2014
Training Epoch: 83 [44032/50176]	Loss: 0.2054
Training Epoch: 83 [45056/50176]	Loss: 0.2206
Training Epoch: 83 [46080/50176]	Loss: 0.2314
Training Epoch: 83 [47104/50176]	Loss: 0.1825
Training Epoch: 83 [48128/50176]	Loss: 0.2420
Training Epoch: 83 [49152/50176]	Loss: 0.2215
Training Epoch: 83 [50176/50176]	Loss: 0.1898
2022-12-08 16:45:16.260 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:45:16,287 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.81 energy=535.69
2022-12-08 11:45:16,288 [ZeusDataLoader(train)] Up to epoch 84: time=4164.30, energy=619904.71, cost=674328.54
2022-12-08 11:45:16,288 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:45:16,288 [ZeusDataLoader(train)] Expected next epoch: time=4211.75, energy=627161.52, cost=682108.81
2022-12-08 11:45:16,289 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 0.0023, Accuracy: 0.5740
2022-12-08 11:45:16,432 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:45:16,433 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:45:16.436 [ZeusMonitor] Monitor started.
2022-12-08 16:45:16.437 [ZeusMonitor] Running indefinitely. 2022-12-08 16:45:16.437 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:45:16.437 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e85+gpu0.power.log
2022-12-08 11:46:00,993 [ZeusDataLoader(train)] train epoch 85 done: time=44.70 energy=6811.95
2022-12-08 11:46:00,997 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 0.1825
Training Epoch: 84 [2048/50176]	Loss: 0.1668
Training Epoch: 84 [3072/50176]	Loss: 0.1981
Training Epoch: 84 [4096/50176]	Loss: 0.1766
Training Epoch: 84 [5120/50176]	Loss: 0.1723
Training Epoch: 84 [6144/50176]	Loss: 0.1471
Training Epoch: 84 [7168/50176]	Loss: 0.1420
Training Epoch: 84 [8192/50176]	Loss: 0.1655
Training Epoch: 84 [9216/50176]	Loss: 0.1518
Training Epoch: 84 [10240/50176]	Loss: 0.1620
Training Epoch: 84 [11264/50176]	Loss: 0.1555
Training Epoch: 84 [12288/50176]	Loss: 0.1608
Training Epoch: 84 [13312/50176]	Loss: 0.1835
Training Epoch: 84 [14336/50176]	Loss: 0.1614
Training Epoch: 84 [15360/50176]	Loss: 0.1703
Training Epoch: 84 [16384/50176]	Loss: 0.1889
Training Epoch: 84 [17408/50176]	Loss: 0.1615
Training Epoch: 84 [18432/50176]	Loss: 0.1614
Training Epoch: 84 [19456/50176]	Loss: 0.1668
Training Epoch: 84 [20480/50176]	Loss: 0.1943
Training Epoch: 84 [21504/50176]	Loss: 0.1819
Training Epoch: 84 [22528/50176]	Loss: 0.1599
Training Epoch: 84 [23552/50176]	Loss: 0.1825
Training Epoch: 84 [24576/50176]	Loss: 0.1855
Training Epoch: 84 [25600/50176]	Loss: 0.1736
Training Epoch: 84 [26624/50176]	Loss: 0.1722
Training Epoch: 84 [27648/50176]	Loss: 0.1905
Training Epoch: 84 [28672/50176]	Loss: 0.1699
Training Epoch: 84 [29696/50176]	Loss: 0.1692
Training Epoch: 84 [30720/50176]	Loss: 0.1564
Training Epoch: 84 [31744/50176]	Loss: 0.1802
Training Epoch: 84 [32768/50176]	Loss: 0.1777
Training Epoch: 84 [33792/50176]	Loss: 0.1884
Training Epoch: 84 [34816/50176]	Loss: 0.1667
Training Epoch: 84 [35840/50176]	Loss: 0.1861
Training Epoch: 84 [36864/50176]	Loss: 0.1866
Training Epoch: 84 [37888/50176]	Loss: 0.1944
Training Epoch: 84 [38912/50176]	Loss: 0.1553
Training Epoch: 84 [39936/50176]	Loss: 0.1750
Training Epoch: 84 [40960/50176]	Loss: 0.1552
Training Epoch: 84 [41984/50176]	Loss: 0.1864
Training Epoch: 84 [43008/50176]	Loss: 0.1780
Training Epoch: 84 [44032/50176]	Loss: 0.2044
Training Epoch: 84 [45056/50176]	Loss: 0.2078
Training Epoch: 84 [46080/50176]	Loss: 0.1748
Training Epoch: 84 [47104/50176]	Loss: 0.2025
Training Epoch: 84 [48128/50176]	Loss: 0.1797
Training Epoch: 84 [49152/50176]	Loss: 0.1791
Training Epoch: 84 [50176/50176]	Loss: 0.1817
2022-12-08 16:46:04.751 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:46:04,784 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.78 energy=521.68
2022-12-08 11:46:04,784 [ZeusDataLoader(train)] Up to epoch 85: time=4212.77, energy=627238.34, cost=682236.78
2022-12-08 11:46:04,784 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:46:04,784 [ZeusDataLoader(train)] Expected next epoch: time=4260.22, energy=634495.15, cost=690017.06
2022-12-08 11:46:04,785 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 0.0022, Accuracy: 0.5882
2022-12-08 11:46:04,977 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:46:04,978 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:46:04.980 [ZeusMonitor] Monitor started.
2022-12-08 16:46:04.980 [ZeusMonitor] Running indefinitely. 2022-12-08 16:46:04.980 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:46:04.980 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e86+gpu0.power.log
2022-12-08 11:46:49,637 [ZeusDataLoader(train)] train epoch 86 done: time=44.84 energy=6806.26
2022-12-08 11:46:49,640 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 0.1740
Training Epoch: 85 [2048/50176]	Loss: 0.1628
Training Epoch: 85 [3072/50176]	Loss: 0.1414
Training Epoch: 85 [4096/50176]	Loss: 0.1241
Training Epoch: 85 [5120/50176]	Loss: 0.1565
Training Epoch: 85 [6144/50176]	Loss: 0.1558
Training Epoch: 85 [7168/50176]	Loss: 0.1546
Training Epoch: 85 [8192/50176]	Loss: 0.1401
Training Epoch: 85 [9216/50176]	Loss: 0.1579
Training Epoch: 85 [10240/50176]	Loss: 0.1508
Training Epoch: 85 [11264/50176]	Loss: 0.1474
Training Epoch: 85 [12288/50176]	Loss: 0.1725
Training Epoch: 85 [13312/50176]	Loss: 0.1595
Training Epoch: 85 [14336/50176]	Loss: 0.1256
Training Epoch: 85 [15360/50176]	Loss: 0.1443
Training Epoch: 85 [16384/50176]	Loss: 0.1522
Training Epoch: 85 [17408/50176]	Loss: 0.1500
Training Epoch: 85 [18432/50176]	Loss: 0.1791
Training Epoch: 85 [19456/50176]	Loss: 0.1407
Training Epoch: 85 [20480/50176]	Loss: 0.1812
Training Epoch: 85 [21504/50176]	Loss: 0.1572
Training Epoch: 85 [22528/50176]	Loss: 0.1807
Training Epoch: 85 [23552/50176]	Loss: 0.1638
Training Epoch: 85 [24576/50176]	Loss: 0.1436
Training Epoch: 85 [25600/50176]	Loss: 0.1448
Training Epoch: 85 [26624/50176]	Loss: 0.1809
Training Epoch: 85 [27648/50176]	Loss: 0.1682
Training Epoch: 85 [28672/50176]	Loss: 0.1712
Training Epoch: 85 [29696/50176]	Loss: 0.1874
Training Epoch: 85 [30720/50176]	Loss: 0.1541
Training Epoch: 85 [31744/50176]	Loss: 0.1631
Training Epoch: 85 [32768/50176]	Loss: 0.1654
Training Epoch: 85 [33792/50176]	Loss: 0.1681
Training Epoch: 85 [34816/50176]	Loss: 0.1713
Training Epoch: 85 [35840/50176]	Loss: 0.1737
Training Epoch: 85 [36864/50176]	Loss: 0.1655
Training Epoch: 85 [37888/50176]	Loss: 0.1687
Training Epoch: 85 [38912/50176]	Loss: 0.2008
Training Epoch: 85 [39936/50176]	Loss: 0.1924
Training Epoch: 85 [40960/50176]	Loss: 0.1807
Training Epoch: 85 [41984/50176]	Loss: 0.1329
Training Epoch: 85 [43008/50176]	Loss: 0.1681
Training Epoch: 85 [44032/50176]	Loss: 0.1967
Training Epoch: 85 [45056/50176]	Loss: 0.1847
Training Epoch: 85 [46080/50176]	Loss: 0.1752
Training Epoch: 85 [47104/50176]	Loss: 0.1779
Training Epoch: 85 [48128/50176]	Loss: 0.2266
Training Epoch: 85 [49152/50176]	Loss: 0.2693
Training Epoch: 85 [50176/50176]	Loss: 0.2127
2022-12-08 16:46:53.334 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:46:53,350 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.70 energy=522.89
2022-12-08 11:46:53,350 [ZeusDataLoader(train)] Up to epoch 86: time=4261.32, energy=634567.49, cost=690148.95
2022-12-08 11:46:53,350 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:46:53,350 [ZeusDataLoader(train)] Expected next epoch: time=4308.77, energy=641824.30, cost=697929.22
2022-12-08 11:46:53,351 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 0.0023, Accuracy: 0.5805
2022-12-08 11:46:53,541 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:46:53,542 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:46:53.544 [ZeusMonitor] Monitor started.
2022-12-08 16:46:53.544 [ZeusMonitor] Running indefinitely. 2022-12-08 16:46:53.544 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:46:53.544 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e87+gpu0.power.log
2022-12-08 11:47:38,086 [ZeusDataLoader(train)] train epoch 87 done: time=44.73 energy=6806.27
2022-12-08 11:47:38,090 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 0.1064
Training Epoch: 86 [2048/50176]	Loss: 0.1269
Training Epoch: 86 [3072/50176]	Loss: 0.1545
Training Epoch: 86 [4096/50176]	Loss: 0.1375
Training Epoch: 86 [5120/50176]	Loss: 0.1271
Training Epoch: 86 [6144/50176]	Loss: 0.1155
Training Epoch: 86 [7168/50176]	Loss: 0.1270
Training Epoch: 86 [8192/50176]	Loss: 0.1515
Training Epoch: 86 [9216/50176]	Loss: 0.1649
Training Epoch: 86 [10240/50176]	Loss: 0.1538
Training Epoch: 86 [11264/50176]	Loss: 0.1557
Training Epoch: 86 [12288/50176]	Loss: 0.1329
Training Epoch: 86 [13312/50176]	Loss: 0.1420
Training Epoch: 86 [14336/50176]	Loss: 0.1401
Training Epoch: 86 [15360/50176]	Loss: 0.1251
Training Epoch: 86 [16384/50176]	Loss: 0.1011
Training Epoch: 86 [17408/50176]	Loss: 0.1567
Training Epoch: 86 [18432/50176]	Loss: 0.1289
Training Epoch: 86 [19456/50176]	Loss: 0.1528
Training Epoch: 86 [20480/50176]	Loss: 0.1591
Training Epoch: 86 [21504/50176]	Loss: 0.1692
Training Epoch: 86 [22528/50176]	Loss: 0.2040
Training Epoch: 86 [23552/50176]	Loss: 0.2028
Training Epoch: 86 [24576/50176]	Loss: 0.1705
Training Epoch: 86 [25600/50176]	Loss: 0.1722
Training Epoch: 86 [26624/50176]	Loss: 0.1645
Training Epoch: 86 [27648/50176]	Loss: 0.1538
Training Epoch: 86 [28672/50176]	Loss: 0.1826
Training Epoch: 86 [29696/50176]	Loss: 0.1431
Training Epoch: 86 [30720/50176]	Loss: 0.1549
Training Epoch: 86 [31744/50176]	Loss: 0.1757
Training Epoch: 86 [32768/50176]	Loss: 0.1580
Training Epoch: 86 [33792/50176]	Loss: 0.1587
Training Epoch: 86 [34816/50176]	Loss: 0.1520
Training Epoch: 86 [35840/50176]	Loss: 0.1729
Training Epoch: 86 [36864/50176]	Loss: 0.1540
Training Epoch: 86 [37888/50176]	Loss: 0.1805
Training Epoch: 86 [38912/50176]	Loss: 0.1727
Training Epoch: 86 [39936/50176]	Loss: 0.1964
Training Epoch: 86 [40960/50176]	Loss: 0.1710
Training Epoch: 86 [41984/50176]	Loss: 0.1712
Training Epoch: 86 [43008/50176]	Loss: 0.1586
Training Epoch: 86 [44032/50176]	Loss: 0.1579
Training Epoch: 86 [45056/50176]	Loss: 0.1678
Training Epoch: 86 [46080/50176]	Loss: 0.1624
Training Epoch: 86 [47104/50176]	Loss: 0.1617
Training Epoch: 86 [48128/50176]	Loss: 0.1801
Training Epoch: 86 [49152/50176]	Loss: 0.2038
Training Epoch: 86 [50176/50176]	Loss: 0.1828
2022-12-08 16:47:41.814 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:47:41,828 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.73 energy=532.87
2022-12-08 11:47:41,829 [ZeusDataLoader(train)] Up to epoch 87: time=4309.77, energy=641906.63, cost=698058.39
2022-12-08 11:47:41,829 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:47:41,829 [ZeusDataLoader(train)] Expected next epoch: time=4357.22, energy=649163.44, cost=705838.67
2022-12-08 11:47:41,830 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 0.0023, Accuracy: 0.5780
2022-12-08 11:47:42,017 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:47:42,018 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:47:42.020 [ZeusMonitor] Monitor started.
2022-12-08 16:47:42.020 [ZeusMonitor] Running indefinitely. 2022-12-08 16:47:42.020 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:47:42.020 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e88+gpu0.power.log
2022-12-08 11:48:26,787 [ZeusDataLoader(train)] train epoch 88 done: time=44.95 energy=6833.41
2022-12-08 11:48:26,790 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 0.1748
Training Epoch: 87 [2048/50176]	Loss: 0.1486
Training Epoch: 87 [3072/50176]	Loss: 0.1508
Training Epoch: 87 [4096/50176]	Loss: 0.1378
Training Epoch: 87 [5120/50176]	Loss: 0.1751
Training Epoch: 87 [6144/50176]	Loss: 0.1418
Training Epoch: 87 [7168/50176]	Loss: 0.1456
Training Epoch: 87 [8192/50176]	Loss: 0.1393
Training Epoch: 87 [9216/50176]	Loss: 0.1612
Training Epoch: 87 [10240/50176]	Loss: 0.1354
Training Epoch: 87 [11264/50176]	Loss: 0.1610
Training Epoch: 87 [12288/50176]	Loss: 0.1495
Training Epoch: 87 [13312/50176]	Loss: 0.1229
Training Epoch: 87 [14336/50176]	Loss: 0.1414
Training Epoch: 87 [15360/50176]	Loss: 0.1501
Training Epoch: 87 [16384/50176]	Loss: 0.1636
Training Epoch: 87 [17408/50176]	Loss: 0.1537
Training Epoch: 87 [18432/50176]	Loss: 0.1466
Training Epoch: 87 [19456/50176]	Loss: 0.1539
Training Epoch: 87 [20480/50176]	Loss: 0.1295
Training Epoch: 87 [21504/50176]	Loss: 0.1367
Training Epoch: 87 [22528/50176]	Loss: 0.1418
Training Epoch: 87 [23552/50176]	Loss: 0.1547
Training Epoch: 87 [24576/50176]	Loss: 0.1595
Training Epoch: 87 [25600/50176]	Loss: 0.1944
Training Epoch: 87 [26624/50176]	Loss: 0.1582
Training Epoch: 87 [27648/50176]	Loss: 0.1471
Training Epoch: 87 [28672/50176]	Loss: 0.1509
Training Epoch: 87 [29696/50176]	Loss: 0.1633
Training Epoch: 87 [30720/50176]	Loss: 0.1922
Training Epoch: 87 [31744/50176]	Loss: 0.1345
Training Epoch: 87 [32768/50176]	Loss: 0.1732
Training Epoch: 87 [33792/50176]	Loss: 0.1660
Training Epoch: 87 [34816/50176]	Loss: 0.1798
Training Epoch: 87 [35840/50176]	Loss: 0.1979
Training Epoch: 87 [36864/50176]	Loss: 0.1746
Training Epoch: 87 [37888/50176]	Loss: 0.1890
Training Epoch: 87 [38912/50176]	Loss: 0.1730
Training Epoch: 87 [39936/50176]	Loss: 0.1579
Training Epoch: 87 [40960/50176]	Loss: 0.1591
Training Epoch: 87 [41984/50176]	Loss: 0.1493
Training Epoch: 87 [43008/50176]	Loss: 0.1636
Training Epoch: 87 [44032/50176]	Loss: 0.1705
Training Epoch: 87 [45056/50176]	Loss: 0.1613
Training Epoch: 87 [46080/50176]	Loss: 0.1851
Training Epoch: 87 [47104/50176]	Loss: 0.1787
Training Epoch: 87 [48128/50176]	Loss: 0.1906
Training Epoch: 87 [49152/50176]	Loss: 0.1686
Training Epoch: 87 [50176/50176]	Loss: 0.1747
2022-12-08 16:48:30.595 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:48:30,643 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.84 energy=536.77
2022-12-08 11:48:30,643 [ZeusDataLoader(train)] Up to epoch 88: time=4358.56, energy=649276.81, cost=706012.73
2022-12-08 11:48:30,643 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:48:30,643 [ZeusDataLoader(train)] Expected next epoch: time=4406.01, energy=656533.62, cost=713793.01
2022-12-08 11:48:30,644 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0023, Accuracy: 0.5816
2022-12-08 11:48:30,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:48:30,836 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:48:30.838 [ZeusMonitor] Monitor started.
2022-12-08 16:48:30.838 [ZeusMonitor] Running indefinitely. 2022-12-08 16:48:30.838 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:48:30.838 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e89+gpu0.power.log
2022-12-08 11:49:15,338 [ZeusDataLoader(train)] train epoch 89 done: time=44.68 energy=6801.73
2022-12-08 11:49:15,341 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 0.1283
Training Epoch: 88 [2048/50176]	Loss: 0.1315
Training Epoch: 88 [3072/50176]	Loss: 0.1149
Training Epoch: 88 [4096/50176]	Loss: 0.1176
Training Epoch: 88 [5120/50176]	Loss: 0.1310
Training Epoch: 88 [6144/50176]	Loss: 0.1609
Training Epoch: 88 [7168/50176]	Loss: 0.1365
Training Epoch: 88 [8192/50176]	Loss: 0.1404
Training Epoch: 88 [9216/50176]	Loss: 0.1358
Training Epoch: 88 [10240/50176]	Loss: 0.1245
Training Epoch: 88 [11264/50176]	Loss: 0.1416
Training Epoch: 88 [12288/50176]	Loss: 0.1631
Training Epoch: 88 [13312/50176]	Loss: 0.1380
Training Epoch: 88 [14336/50176]	Loss: 0.1872
Training Epoch: 88 [15360/50176]	Loss: 0.1558
Training Epoch: 88 [16384/50176]	Loss: 0.1316
Training Epoch: 88 [17408/50176]	Loss: 0.1246
Training Epoch: 88 [18432/50176]	Loss: 0.1289
Training Epoch: 88 [19456/50176]	Loss: 0.1322
Training Epoch: 88 [20480/50176]	Loss: 0.1501
Training Epoch: 88 [21504/50176]	Loss: 0.1185
Training Epoch: 88 [22528/50176]	Loss: 0.1602
Training Epoch: 88 [23552/50176]	Loss: 0.1648
Training Epoch: 88 [24576/50176]	Loss: 0.1522
Training Epoch: 88 [25600/50176]	Loss: 0.1443
Training Epoch: 88 [26624/50176]	Loss: 0.1498
Training Epoch: 88 [27648/50176]	Loss: 0.1378
Training Epoch: 88 [28672/50176]	Loss: 0.1472
Training Epoch: 88 [29696/50176]	Loss: 0.1527
Training Epoch: 88 [30720/50176]	Loss: 0.1605
Training Epoch: 88 [31744/50176]	Loss: 0.1578
Training Epoch: 88 [32768/50176]	Loss: 0.1746
Training Epoch: 88 [33792/50176]	Loss: 0.1763
Training Epoch: 88 [34816/50176]	Loss: 0.2140
Training Epoch: 88 [35840/50176]	Loss: 0.1817
Training Epoch: 88 [36864/50176]	Loss: 0.1599
Training Epoch: 88 [37888/50176]	Loss: 0.1552
Training Epoch: 88 [38912/50176]	Loss: 0.1850
Training Epoch: 88 [39936/50176]	Loss: 0.1957
Training Epoch: 88 [40960/50176]	Loss: 0.1428
Training Epoch: 88 [41984/50176]	Loss: 0.1827
Training Epoch: 88 [43008/50176]	Loss: 0.1802
Training Epoch: 88 [44032/50176]	Loss: 0.1611
Training Epoch: 88 [45056/50176]	Loss: 0.1568
Training Epoch: 88 [46080/50176]	Loss: 0.1654
Training Epoch: 88 [47104/50176]	Loss: 0.1839
Training Epoch: 88 [48128/50176]	Loss: 0.1631
Training Epoch: 88 [49152/50176]	Loss: 0.1711
Training Epoch: 88 [50176/50176]	Loss: 0.1770
2022-12-08 16:49:19.063 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:49:19,085 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.74 energy=520.52
2022-12-08 11:49:19,086 [ZeusDataLoader(train)] Up to epoch 89: time=4406.98, energy=656599.07, cost=713910.63
2022-12-08 11:49:19,086 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:49:19,086 [ZeusDataLoader(train)] Expected next epoch: time=4454.43, energy=663855.88, cost=721690.90
2022-12-08 11:49:19,087 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 0.0024, Accuracy: 0.5761
2022-12-08 11:49:19,265 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:49:19,266 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:49:19.268 [ZeusMonitor] Monitor started.
2022-12-08 16:49:19.268 [ZeusMonitor] Running indefinitely. 2022-12-08 16:49:19.268 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:49:19.268 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e90+gpu0.power.log
2022-12-08 11:50:03,698 [ZeusDataLoader(train)] train epoch 90 done: time=44.60 energy=6791.96
2022-12-08 11:50:03,702 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 0.1798
Training Epoch: 89 [2048/50176]	Loss: 0.1246
Training Epoch: 89 [3072/50176]	Loss: 0.1275
Training Epoch: 89 [4096/50176]	Loss: 0.1358
Training Epoch: 89 [5120/50176]	Loss: 0.1182
Training Epoch: 89 [6144/50176]	Loss: 0.1110
Training Epoch: 89 [7168/50176]	Loss: 0.1400
Training Epoch: 89 [8192/50176]	Loss: 0.1347
Training Epoch: 89 [9216/50176]	Loss: 0.1352
Training Epoch: 89 [10240/50176]	Loss: 0.1535
Training Epoch: 89 [11264/50176]	Loss: 0.1523
Training Epoch: 89 [12288/50176]	Loss: 0.1674
Training Epoch: 89 [13312/50176]	Loss: 0.1102
Training Epoch: 89 [14336/50176]	Loss: 0.1465
Training Epoch: 89 [15360/50176]	Loss: 0.1427
Training Epoch: 89 [16384/50176]	Loss: 0.1667
Training Epoch: 89 [17408/50176]	Loss: 0.1461
Training Epoch: 89 [18432/50176]	Loss: 0.1434
Training Epoch: 89 [19456/50176]	Loss: 0.1670
Training Epoch: 89 [20480/50176]	Loss: 0.1299
Training Epoch: 89 [21504/50176]	Loss: 0.1570
Training Epoch: 89 [22528/50176]	Loss: 0.1406
Training Epoch: 89 [23552/50176]	Loss: 0.1626
Training Epoch: 89 [24576/50176]	Loss: 0.1503
Training Epoch: 89 [25600/50176]	Loss: 0.1537
Training Epoch: 89 [26624/50176]	Loss: 0.1635
Training Epoch: 89 [27648/50176]	Loss: 0.1455
Training Epoch: 89 [28672/50176]	Loss: 0.1493
Training Epoch: 89 [29696/50176]	Loss: 0.1713
Training Epoch: 89 [30720/50176]	Loss: 0.1474
Training Epoch: 89 [31744/50176]	Loss: 0.1401
Training Epoch: 89 [32768/50176]	Loss: 0.1578
Training Epoch: 89 [33792/50176]	Loss: 0.1653
Training Epoch: 89 [34816/50176]	Loss: 0.1302
Training Epoch: 89 [35840/50176]	Loss: 0.1670
Training Epoch: 89 [36864/50176]	Loss: 0.1392
Training Epoch: 89 [37888/50176]	Loss: 0.1598
Training Epoch: 89 [38912/50176]	Loss: 0.1552
Training Epoch: 89 [39936/50176]	Loss: 0.1523
Training Epoch: 89 [40960/50176]	Loss: 0.1615
Training Epoch: 89 [41984/50176]	Loss: 0.1309
Training Epoch: 89 [43008/50176]	Loss: 0.1611
Training Epoch: 89 [44032/50176]	Loss: 0.1700
Training Epoch: 89 [45056/50176]	Loss: 0.1397
Training Epoch: 89 [46080/50176]	Loss: 0.1600
Training Epoch: 89 [47104/50176]	Loss: 0.1434
Training Epoch: 89 [48128/50176]	Loss: 0.1369
Training Epoch: 89 [49152/50176]	Loss: 0.1620
Training Epoch: 89 [50176/50176]	Loss: 0.1707
2022-12-08 16:50:07.487 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:50:07,507 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.80 energy=524.09
2022-12-08 11:50:07,507 [ZeusDataLoader(train)] Up to epoch 90: time=4455.38, energy=663915.12, cost=721803.53
2022-12-08 11:50:07,507 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:50:07,508 [ZeusDataLoader(train)] Expected next epoch: time=4502.83, energy=671171.93, cost=729583.80
2022-12-08 11:50:07,509 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0023, Accuracy: 0.5827
2022-12-08 11:50:07,707 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:50:07,708 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:50:07.710 [ZeusMonitor] Monitor started.
2022-12-08 16:50:07.710 [ZeusMonitor] Running indefinitely. 2022-12-08 16:50:07.710 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:50:07.710 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e91+gpu0.power.log
2022-12-08 11:50:52,229 [ZeusDataLoader(train)] train epoch 91 done: time=44.71 energy=6800.95
2022-12-08 11:50:52,233 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 0.1476
Training Epoch: 90 [2048/50176]	Loss: 0.1146
Training Epoch: 90 [3072/50176]	Loss: 0.1320
Training Epoch: 90 [4096/50176]	Loss: 0.1472
Training Epoch: 90 [5120/50176]	Loss: 0.1289
Training Epoch: 90 [6144/50176]	Loss: 0.1427
Training Epoch: 90 [7168/50176]	Loss: 0.1497
Training Epoch: 90 [8192/50176]	Loss: 0.1366
Training Epoch: 90 [9216/50176]	Loss: 0.1404
Training Epoch: 90 [10240/50176]	Loss: 0.1577
Training Epoch: 90 [11264/50176]	Loss: 0.1522
Training Epoch: 90 [12288/50176]	Loss: 0.1509
Training Epoch: 90 [13312/50176]	Loss: 0.1113
Training Epoch: 90 [14336/50176]	Loss: 0.1192
Training Epoch: 90 [15360/50176]	Loss: 0.1113
Training Epoch: 90 [16384/50176]	Loss: 0.1206
Training Epoch: 90 [17408/50176]	Loss: 0.1360
Training Epoch: 90 [18432/50176]	Loss: 0.1402
Training Epoch: 90 [19456/50176]	Loss: 0.1392
Training Epoch: 90 [20480/50176]	Loss: 0.1615
Training Epoch: 90 [21504/50176]	Loss: 0.1180
Training Epoch: 90 [22528/50176]	Loss: 0.1396
Training Epoch: 90 [23552/50176]	Loss: 0.1279
Training Epoch: 90 [24576/50176]	Loss: 0.1609
Training Epoch: 90 [25600/50176]	Loss: 0.1567
Training Epoch: 90 [26624/50176]	Loss: 0.1738
Training Epoch: 90 [27648/50176]	Loss: 0.1386
Training Epoch: 90 [28672/50176]	Loss: 0.1602
Training Epoch: 90 [29696/50176]	Loss: 0.1616
Training Epoch: 90 [30720/50176]	Loss: 0.1550
Training Epoch: 90 [31744/50176]	Loss: 0.1738
Training Epoch: 90 [32768/50176]	Loss: 0.1398
Training Epoch: 90 [33792/50176]	Loss: 0.1329
Training Epoch: 90 [34816/50176]	Loss: 0.1646
Training Epoch: 90 [35840/50176]	Loss: 0.1573
Training Epoch: 90 [36864/50176]	Loss: 0.1359
Training Epoch: 90 [37888/50176]	Loss: 0.1525
Training Epoch: 90 [38912/50176]	Loss: 0.1662
Training Epoch: 90 [39936/50176]	Loss: 0.1393
Training Epoch: 90 [40960/50176]	Loss: 0.1452
Training Epoch: 90 [41984/50176]	Loss: 0.1418
Training Epoch: 90 [43008/50176]	Loss: 0.1423
Training Epoch: 90 [44032/50176]	Loss: 0.1405
Training Epoch: 90 [45056/50176]	Loss: 0.1320
Training Epoch: 90 [46080/50176]	Loss: 0.1687
Training Epoch: 90 [47104/50176]	Loss: 0.1679
Training Epoch: 90 [48128/50176]	Loss: 0.1367
Training Epoch: 90 [49152/50176]	Loss: 0.1365
Training Epoch: 90 [50176/50176]	Loss: 0.1634
2022-12-08 16:50:55.918 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:50:55,929 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.69 energy=507.82
2022-12-08 11:50:55,929 [ZeusDataLoader(train)] Up to epoch 91: time=4503.78, energy=671223.89, cost=729692.87
2022-12-08 11:50:55,929 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:50:55,930 [ZeusDataLoader(train)] Expected next epoch: time=4551.23, energy=678480.70, cost=737473.14
2022-12-08 11:50:55,931 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 0.0023, Accuracy: 0.5786
2022-12-08 11:50:56,080 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:50:56,081 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:50:56.083 [ZeusMonitor] Monitor started.
2022-12-08 16:50:56.083 [ZeusMonitor] Running indefinitely. 2022-12-08 16:50:56.083 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:50:56.083 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e92+gpu0.power.log
2022-12-08 11:51:40,567 [ZeusDataLoader(train)] train epoch 92 done: time=44.63 energy=6792.96
2022-12-08 11:51:40,571 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 0.1452
Training Epoch: 91 [2048/50176]	Loss: 0.1435
Training Epoch: 91 [3072/50176]	Loss: 0.1486
Training Epoch: 91 [4096/50176]	Loss: 0.1110
Training Epoch: 91 [5120/50176]	Loss: 0.1243
Training Epoch: 91 [6144/50176]	Loss: 0.1316
Training Epoch: 91 [7168/50176]	Loss: 0.1284
Training Epoch: 91 [8192/50176]	Loss: 0.1289
Training Epoch: 91 [9216/50176]	Loss: 0.1218
Training Epoch: 91 [10240/50176]	Loss: 0.1142
Training Epoch: 91 [11264/50176]	Loss: 0.1523
Training Epoch: 91 [12288/50176]	Loss: 0.1214
Training Epoch: 91 [13312/50176]	Loss: 0.1069
Training Epoch: 91 [14336/50176]	Loss: 0.1211
Training Epoch: 91 [15360/50176]	Loss: 0.1283
Training Epoch: 91 [16384/50176]	Loss: 0.1322
Training Epoch: 91 [17408/50176]	Loss: 0.1227
Training Epoch: 91 [18432/50176]	Loss: 0.1303
Training Epoch: 91 [19456/50176]	Loss: 0.1468
Training Epoch: 91 [20480/50176]	Loss: 0.1540
Training Epoch: 91 [21504/50176]	Loss: 0.1466
Training Epoch: 91 [22528/50176]	Loss: 0.1194
Training Epoch: 91 [23552/50176]	Loss: 0.1481
Training Epoch: 91 [24576/50176]	Loss: 0.1207
Training Epoch: 91 [25600/50176]	Loss: 0.1283
Training Epoch: 91 [26624/50176]	Loss: 0.1305
Training Epoch: 91 [27648/50176]	Loss: 0.1173
Training Epoch: 91 [28672/50176]	Loss: 0.1285
Training Epoch: 91 [29696/50176]	Loss: 0.1333
Training Epoch: 91 [30720/50176]	Loss: 0.1283
Training Epoch: 91 [31744/50176]	Loss: 0.1250
Training Epoch: 91 [32768/50176]	Loss: 0.1279
Training Epoch: 91 [33792/50176]	Loss: 0.1115
Training Epoch: 91 [34816/50176]	Loss: 0.1360
Training Epoch: 91 [35840/50176]	Loss: 0.1176
Training Epoch: 91 [36864/50176]	Loss: 0.1582
Training Epoch: 91 [37888/50176]	Loss: 0.1373
Training Epoch: 91 [38912/50176]	Loss: 0.1608
Training Epoch: 91 [39936/50176]	Loss: 0.1364
Training Epoch: 91 [40960/50176]	Loss: 0.1210
Training Epoch: 91 [41984/50176]	Loss: 0.1439
Training Epoch: 91 [43008/50176]	Loss: 0.1224
Training Epoch: 91 [44032/50176]	Loss: 0.1369
Training Epoch: 91 [45056/50176]	Loss: 0.1401
Training Epoch: 91 [46080/50176]	Loss: 0.1490
Training Epoch: 91 [47104/50176]	Loss: 0.1389
Training Epoch: 91 [48128/50176]	Loss: 0.1637
Training Epoch: 91 [49152/50176]	Loss: 0.1348
Training Epoch: 91 [50176/50176]	Loss: 0.1716
2022-12-08 16:51:44.381 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:51:44,416 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.84 energy=538.55
2022-12-08 11:51:44,416 [ZeusDataLoader(train)] Up to epoch 92: time=4552.24, energy=678555.40, cost=737599.05
2022-12-08 11:51:44,416 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:51:44,416 [ZeusDataLoader(train)] Expected next epoch: time=4599.69, energy=685812.21, cost=745379.32
2022-12-08 11:51:44,417 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 0.0023, Accuracy: 0.5895
2022-12-08 11:51:44,613 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:51:44,613 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:51:44.615 [ZeusMonitor] Monitor started.
2022-12-08 16:51:44.615 [ZeusMonitor] Running indefinitely. 2022-12-08 16:51:44.615 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:51:44.615 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e93+gpu0.power.log
2022-12-08 11:52:29,307 [ZeusDataLoader(train)] train epoch 93 done: time=44.88 energy=6843.16
2022-12-08 11:52:29,311 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 0.1025
Training Epoch: 92 [2048/50176]	Loss: 0.1099
Training Epoch: 92 [3072/50176]	Loss: 0.1400
Training Epoch: 92 [4096/50176]	Loss: 0.1161
Training Epoch: 92 [5120/50176]	Loss: 0.1342
Training Epoch: 92 [6144/50176]	Loss: 0.1155
Training Epoch: 92 [7168/50176]	Loss: 0.1215
Training Epoch: 92 [8192/50176]	Loss: 0.1344
Training Epoch: 92 [9216/50176]	Loss: 0.1219
Training Epoch: 92 [10240/50176]	Loss: 0.0993
Training Epoch: 92 [11264/50176]	Loss: 0.1113
Training Epoch: 92 [12288/50176]	Loss: 0.1359
Training Epoch: 92 [13312/50176]	Loss: 0.1341
Training Epoch: 92 [14336/50176]	Loss: 0.1328
Training Epoch: 92 [15360/50176]	Loss: 0.1200
Training Epoch: 92 [16384/50176]	Loss: 0.1218
Training Epoch: 92 [17408/50176]	Loss: 0.1189
Training Epoch: 92 [18432/50176]	Loss: 0.1225
Training Epoch: 92 [19456/50176]	Loss: 0.1344
Training Epoch: 92 [20480/50176]	Loss: 0.1217
Training Epoch: 92 [21504/50176]	Loss: 0.1145
Training Epoch: 92 [22528/50176]	Loss: 0.1126
Training Epoch: 92 [23552/50176]	Loss: 0.1499
Training Epoch: 92 [24576/50176]	Loss: 0.1225
Training Epoch: 92 [25600/50176]	Loss: 0.1461
Training Epoch: 92 [26624/50176]	Loss: 0.1304
Training Epoch: 92 [27648/50176]	Loss: 0.1259
Training Epoch: 92 [28672/50176]	Loss: 0.1330
Training Epoch: 92 [29696/50176]	Loss: 0.0979
Training Epoch: 92 [30720/50176]	Loss: 0.1253
Training Epoch: 92 [31744/50176]	Loss: 0.1082
Training Epoch: 92 [32768/50176]	Loss: 0.1406
Training Epoch: 92 [33792/50176]	Loss: 0.1268
Training Epoch: 92 [34816/50176]	Loss: 0.1585
Training Epoch: 92 [35840/50176]	Loss: 0.1550
Training Epoch: 92 [36864/50176]	Loss: 0.1294
Training Epoch: 92 [37888/50176]	Loss: 0.1393
Training Epoch: 92 [38912/50176]	Loss: 0.1522
Training Epoch: 92 [39936/50176]	Loss: 0.1359
Training Epoch: 92 [40960/50176]	Loss: 0.1434
Training Epoch: 92 [41984/50176]	Loss: 0.1229
Training Epoch: 92 [43008/50176]	Loss: 0.1310
Training Epoch: 92 [44032/50176]	Loss: 0.1509
Training Epoch: 92 [45056/50176]	Loss: 0.1406
Training Epoch: 92 [46080/50176]	Loss: 0.1315
Training Epoch: 92 [47104/50176]	Loss: 0.1669
Training Epoch: 92 [48128/50176]	Loss: 0.1287
Training Epoch: 92 [49152/50176]	Loss: 0.1279
Training Epoch: 92 [50176/50176]	Loss: 0.1237
2022-12-08 16:52:33.061 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:52:33,071 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.75 energy=524.81
2022-12-08 11:52:33,072 [ZeusDataLoader(train)] Up to epoch 93: time=4600.88, energy=685923.36, cost=745538.34
2022-12-08 11:52:33,072 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:52:33,072 [ZeusDataLoader(train)] Expected next epoch: time=4648.33, energy=693180.17, cost=753318.61
2022-12-08 11:52:33,073 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0023, Accuracy: 0.5902
2022-12-08 11:52:33,256 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:52:33,257 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:52:33.271 [ZeusMonitor] Monitor started.
2022-12-08 16:52:33.271 [ZeusMonitor] Running indefinitely. 2022-12-08 16:52:33.271 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:52:33.271 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e94+gpu0.power.log
2022-12-08 11:53:17,734 [ZeusDataLoader(train)] train epoch 94 done: time=44.65 energy=6802.86
2022-12-08 11:53:17,737 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 0.1190
Training Epoch: 93 [2048/50176]	Loss: 0.1161
Training Epoch: 93 [3072/50176]	Loss: 0.1065
Training Epoch: 93 [4096/50176]	Loss: 0.1238
Training Epoch: 93 [5120/50176]	Loss: 0.1358
Training Epoch: 93 [6144/50176]	Loss: 0.1238
Training Epoch: 93 [7168/50176]	Loss: 0.1116
Training Epoch: 93 [8192/50176]	Loss: 0.1176
Training Epoch: 93 [9216/50176]	Loss: 0.1198
Training Epoch: 93 [10240/50176]	Loss: 0.0994
Training Epoch: 93 [11264/50176]	Loss: 0.1013
Training Epoch: 93 [12288/50176]	Loss: 0.1102
Training Epoch: 93 [13312/50176]	Loss: 0.1400
Training Epoch: 93 [14336/50176]	Loss: 0.1429
Training Epoch: 93 [15360/50176]	Loss: 0.1267
Training Epoch: 93 [16384/50176]	Loss: 0.1214
Training Epoch: 93 [17408/50176]	Loss: 0.1080
Training Epoch: 93 [18432/50176]	Loss: 0.1193
Training Epoch: 93 [19456/50176]	Loss: 0.1570
Training Epoch: 93 [20480/50176]	Loss: 0.1165
Training Epoch: 93 [21504/50176]	Loss: 0.1184
Training Epoch: 93 [22528/50176]	Loss: 0.1164
Training Epoch: 93 [23552/50176]	Loss: 0.1231
Training Epoch: 93 [24576/50176]	Loss: 0.1118
Training Epoch: 93 [25600/50176]	Loss: 0.1326
Training Epoch: 93 [26624/50176]	Loss: 0.1472
Training Epoch: 93 [27648/50176]	Loss: 0.1347
Training Epoch: 93 [28672/50176]	Loss: 0.1181
Training Epoch: 93 [29696/50176]	Loss: 0.1167
Training Epoch: 93 [30720/50176]	Loss: 0.1279
Training Epoch: 93 [31744/50176]	Loss: 0.1080
Training Epoch: 93 [32768/50176]	Loss: 0.1424
Training Epoch: 93 [33792/50176]	Loss: 0.1251
Training Epoch: 93 [34816/50176]	Loss: 0.1393
Training Epoch: 93 [35840/50176]	Loss: 0.1273
Training Epoch: 93 [36864/50176]	Loss: 0.1220
Training Epoch: 93 [37888/50176]	Loss: 0.1224
Training Epoch: 93 [38912/50176]	Loss: 0.1334
Training Epoch: 93 [39936/50176]	Loss: 0.1468
Training Epoch: 93 [40960/50176]	Loss: 0.1173
Training Epoch: 93 [41984/50176]	Loss: 0.1138
Training Epoch: 93 [43008/50176]	Loss: 0.1435
Training Epoch: 93 [44032/50176]	Loss: 0.1387
Training Epoch: 93 [45056/50176]	Loss: 0.1478
Training Epoch: 93 [46080/50176]	Loss: 0.1639
Training Epoch: 93 [47104/50176]	Loss: 0.1432
Training Epoch: 93 [48128/50176]	Loss: 0.1325
Training Epoch: 93 [49152/50176]	Loss: 0.1668
Training Epoch: 93 [50176/50176]	Loss: 0.1621
2022-12-08 16:53:21.511 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:53:21,525 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.78 energy=532.83
2022-12-08 11:53:21,525 [ZeusDataLoader(train)] Up to epoch 94: time=4649.31, energy=693259.06, cost=753443.86
2022-12-08 11:53:21,525 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:53:21,525 [ZeusDataLoader(train)] Expected next epoch: time=4696.76, energy=700515.87, cost=761224.14
2022-12-08 11:53:21,526 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 0.0024, Accuracy: 0.5750
2022-12-08 11:53:21,674 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:53:21,675 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:53:21.679 [ZeusMonitor] Monitor started.
2022-12-08 16:53:21.679 [ZeusMonitor] Running indefinitely. 2022-12-08 16:53:21.679 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:53:21.679 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e95+gpu0.power.log
2022-12-08 11:54:06,229 [ZeusDataLoader(train)] train epoch 95 done: time=44.69 energy=6799.85
2022-12-08 11:54:06,233 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 0.1630
Training Epoch: 94 [2048/50176]	Loss: 0.1474
Training Epoch: 94 [3072/50176]	Loss: 0.1085
Training Epoch: 94 [4096/50176]	Loss: 0.1055
Training Epoch: 94 [5120/50176]	Loss: 0.1097
Training Epoch: 94 [6144/50176]	Loss: 0.1219
Training Epoch: 94 [7168/50176]	Loss: 0.1157
Training Epoch: 94 [8192/50176]	Loss: 0.0939
Training Epoch: 94 [9216/50176]	Loss: 0.1289
Training Epoch: 94 [10240/50176]	Loss: 0.1118
Training Epoch: 94 [11264/50176]	Loss: 0.1088
Training Epoch: 94 [12288/50176]	Loss: 0.0992
Training Epoch: 94 [13312/50176]	Loss: 0.1102
Training Epoch: 94 [14336/50176]	Loss: 0.1449
Training Epoch: 94 [15360/50176]	Loss: 0.1212
Training Epoch: 94 [16384/50176]	Loss: 0.1183
Training Epoch: 94 [17408/50176]	Loss: 0.1006
Training Epoch: 94 [18432/50176]	Loss: 0.1116
Training Epoch: 94 [19456/50176]	Loss: 0.1236
Training Epoch: 94 [20480/50176]	Loss: 0.1276
Training Epoch: 94 [21504/50176]	Loss: 0.1027
Training Epoch: 94 [22528/50176]	Loss: 0.1269
Training Epoch: 94 [23552/50176]	Loss: 0.1220
Training Epoch: 94 [24576/50176]	Loss: 0.1124
Training Epoch: 94 [25600/50176]	Loss: 0.1137
Training Epoch: 94 [26624/50176]	Loss: 0.0998
Training Epoch: 94 [27648/50176]	Loss: 0.1404
Training Epoch: 94 [28672/50176]	Loss: 0.1266
Training Epoch: 94 [29696/50176]	Loss: 0.1518
Training Epoch: 94 [30720/50176]	Loss: 0.1247
Training Epoch: 94 [31744/50176]	Loss: 0.1249
Training Epoch: 94 [32768/50176]	Loss: 0.1222
Training Epoch: 94 [33792/50176]	Loss: 0.1226
Training Epoch: 94 [34816/50176]	Loss: 0.1128
Training Epoch: 94 [35840/50176]	Loss: 0.1164
Training Epoch: 94 [36864/50176]	Loss: 0.1120
Training Epoch: 94 [37888/50176]	Loss: 0.1301
Training Epoch: 94 [38912/50176]	Loss: 0.1287
Training Epoch: 94 [39936/50176]	Loss: 0.1364
Training Epoch: 94 [40960/50176]	Loss: 0.1199
Training Epoch: 94 [41984/50176]	Loss: 0.1320
Training Epoch: 94 [43008/50176]	Loss: 0.1236
Training Epoch: 94 [44032/50176]	Loss: 0.1429
Training Epoch: 94 [45056/50176]	Loss: 0.1436
Training Epoch: 94 [46080/50176]	Loss: 0.1441
Training Epoch: 94 [47104/50176]	Loss: 0.1240
Training Epoch: 94 [48128/50176]	Loss: 0.1518
Training Epoch: 94 [49152/50176]	Loss: 0.1489
Training Epoch: 94 [50176/50176]	Loss: 0.1397
2022-12-08 16:54:09.973 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:54:09,993 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.75 energy=522.98
2022-12-08 11:54:09,993 [ZeusDataLoader(train)] Up to epoch 95: time=4697.75, energy=700581.89, cost=761344.16
2022-12-08 11:54:09,993 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:54:09,993 [ZeusDataLoader(train)] Expected next epoch: time=4745.20, energy=707838.70, cost=769124.43
2022-12-08 11:54:09,994 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 0.0024, Accuracy: 0.5791
2022-12-08 11:54:10,174 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:54:10,175 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:54:10.189 [ZeusMonitor] Monitor started.
2022-12-08 16:54:10.190 [ZeusMonitor] Running indefinitely. 2022-12-08 16:54:10.190 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:54:10.190 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e96+gpu0.power.log
2022-12-08 11:54:54,614 [ZeusDataLoader(train)] train epoch 96 done: time=44.61 energy=6788.98
2022-12-08 11:54:54,618 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 0.1157
Training Epoch: 95 [2048/50176]	Loss: 0.1013
Training Epoch: 95 [3072/50176]	Loss: 0.1104
Training Epoch: 95 [4096/50176]	Loss: 0.1068
Training Epoch: 95 [5120/50176]	Loss: 0.1016
Training Epoch: 95 [6144/50176]	Loss: 0.0962
Training Epoch: 95 [7168/50176]	Loss: 0.1087
Training Epoch: 95 [8192/50176]	Loss: 0.0968
Training Epoch: 95 [9216/50176]	Loss: 0.1090
Training Epoch: 95 [10240/50176]	Loss: 0.1066
Training Epoch: 95 [11264/50176]	Loss: 0.0955
Training Epoch: 95 [12288/50176]	Loss: 0.1018
Training Epoch: 95 [13312/50176]	Loss: 0.1057
Training Epoch: 95 [14336/50176]	Loss: 0.1058
Training Epoch: 95 [15360/50176]	Loss: 0.1163
Training Epoch: 95 [16384/50176]	Loss: 0.1142
Training Epoch: 95 [17408/50176]	Loss: 0.1089
Training Epoch: 95 [18432/50176]	Loss: 0.1292
Training Epoch: 95 [19456/50176]	Loss: 0.1298
Training Epoch: 95 [20480/50176]	Loss: 0.1366
Training Epoch: 95 [21504/50176]	Loss: 0.1321
Training Epoch: 95 [22528/50176]	Loss: 0.1120
Training Epoch: 95 [23552/50176]	Loss: 0.1112
Training Epoch: 95 [24576/50176]	Loss: 0.1232
Training Epoch: 95 [25600/50176]	Loss: 0.1347
Training Epoch: 95 [26624/50176]	Loss: 0.1382
Training Epoch: 95 [27648/50176]	Loss: 0.1076
Training Epoch: 95 [28672/50176]	Loss: 0.1229
Training Epoch: 95 [29696/50176]	Loss: 0.1392
Training Epoch: 95 [30720/50176]	Loss: 0.1191
Training Epoch: 95 [31744/50176]	Loss: 0.1268
Training Epoch: 95 [32768/50176]	Loss: 0.1286
Training Epoch: 95 [33792/50176]	Loss: 0.1193
Training Epoch: 95 [34816/50176]	Loss: 0.1131
Training Epoch: 95 [35840/50176]	Loss: 0.1244
Training Epoch: 95 [36864/50176]	Loss: 0.1158
Training Epoch: 95 [37888/50176]	Loss: 0.1193
Training Epoch: 95 [38912/50176]	Loss: 0.1245
Training Epoch: 95 [39936/50176]	Loss: 0.1400
Training Epoch: 95 [40960/50176]	Loss: 0.1361
Training Epoch: 95 [41984/50176]	Loss: 0.1743
Training Epoch: 95 [43008/50176]	Loss: 0.1498
Training Epoch: 95 [44032/50176]	Loss: 0.1316
Training Epoch: 95 [45056/50176]	Loss: 0.1327
Training Epoch: 95 [46080/50176]	Loss: 0.1270
Training Epoch: 95 [47104/50176]	Loss: 0.1243
Training Epoch: 95 [48128/50176]	Loss: 0.1149
Training Epoch: 95 [49152/50176]	Loss: 0.1195
Training Epoch: 95 [50176/50176]	Loss: 0.1398
2022-12-08 16:54:58.407 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:54:58,439 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.81 energy=535.11
2022-12-08 11:54:58,440 [ZeusDataLoader(train)] Up to epoch 96: time=4746.17, energy=707905.98, cost=769243.25
2022-12-08 11:54:58,440 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:54:58,440 [ZeusDataLoader(train)] Expected next epoch: time=4793.62, energy=715162.79, cost=777023.52
2022-12-08 11:54:58,441 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 0.0025, Accuracy: 0.5751
2022-12-08 11:54:58,589 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:54:58,590 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:54:58.594 [ZeusMonitor] Monitor started.
2022-12-08 16:54:58.594 [ZeusMonitor] Running indefinitely. 2022-12-08 16:54:58.594 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:54:58.594 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e97+gpu0.power.log
2022-12-08 11:55:43,096 [ZeusDataLoader(train)] train epoch 97 done: time=44.65 energy=6811.17
2022-12-08 11:55:43,100 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 0.1296
Training Epoch: 96 [2048/50176]	Loss: 0.1285
Training Epoch: 96 [3072/50176]	Loss: 0.1036
Training Epoch: 96 [4096/50176]	Loss: 0.1154
Training Epoch: 96 [5120/50176]	Loss: 0.0983
Training Epoch: 96 [6144/50176]	Loss: 0.1209
Training Epoch: 96 [7168/50176]	Loss: 0.1221
Training Epoch: 96 [8192/50176]	Loss: 0.0952
Training Epoch: 96 [9216/50176]	Loss: 0.1032
Training Epoch: 96 [10240/50176]	Loss: 0.0872
Training Epoch: 96 [11264/50176]	Loss: 0.0910
Training Epoch: 96 [12288/50176]	Loss: 0.1156
Training Epoch: 96 [13312/50176]	Loss: 0.1166
Training Epoch: 96 [14336/50176]	Loss: 0.1401
Training Epoch: 96 [15360/50176]	Loss: 0.1165
Training Epoch: 96 [16384/50176]	Loss: 0.0987
Training Epoch: 96 [17408/50176]	Loss: 0.1302
Training Epoch: 96 [18432/50176]	Loss: 0.1134
Training Epoch: 96 [19456/50176]	Loss: 0.1116
Training Epoch: 96 [20480/50176]	Loss: 0.1218
Training Epoch: 96 [21504/50176]	Loss: 0.1107
Training Epoch: 96 [22528/50176]	Loss: 0.1077
Training Epoch: 96 [23552/50176]	Loss: 0.1300
Training Epoch: 96 [24576/50176]	Loss: 0.1148
Training Epoch: 96 [25600/50176]	Loss: 0.1071
Training Epoch: 96 [26624/50176]	Loss: 0.1097
Training Epoch: 96 [27648/50176]	Loss: 0.1246
Training Epoch: 96 [28672/50176]	Loss: 0.1208
Training Epoch: 96 [29696/50176]	Loss: 0.1191
Training Epoch: 96 [30720/50176]	Loss: 0.1005
Training Epoch: 96 [31744/50176]	Loss: 0.1146
Training Epoch: 96 [32768/50176]	Loss: 0.1176
Training Epoch: 96 [33792/50176]	Loss: 0.1180
Training Epoch: 96 [34816/50176]	Loss: 0.1160
Training Epoch: 96 [35840/50176]	Loss: 0.1149
Training Epoch: 96 [36864/50176]	Loss: 0.1306
Training Epoch: 96 [37888/50176]	Loss: 0.1448
Training Epoch: 96 [38912/50176]	Loss: 0.1098
Training Epoch: 96 [39936/50176]	Loss: 0.1177
Training Epoch: 96 [40960/50176]	Loss: 0.1229
Training Epoch: 96 [41984/50176]	Loss: 0.1238
Training Epoch: 96 [43008/50176]	Loss: 0.1211
Training Epoch: 96 [44032/50176]	Loss: 0.1209
Training Epoch: 96 [45056/50176]	Loss: 0.1486
Training Epoch: 96 [46080/50176]	Loss: 0.1422
Training Epoch: 96 [47104/50176]	Loss: 0.1550
Training Epoch: 96 [48128/50176]	Loss: 0.1229
Training Epoch: 96 [49152/50176]	Loss: 0.1164
Training Epoch: 96 [50176/50176]	Loss: 0.1618
2022-12-08 16:55:46.863 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:55:46,873 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.76 energy=516.67
2022-12-08 11:55:46,874 [ZeusDataLoader(train)] Up to epoch 97: time=4794.59, energy=715233.82, cost=777143.17
2022-12-08 11:55:46,874 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:55:46,874 [ZeusDataLoader(train)] Expected next epoch: time=4842.04, energy=722490.63, cost=784923.44
2022-12-08 11:55:46,875 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 0.0024, Accuracy: 0.5857
2022-12-08 11:55:47,069 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:55:47,070 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:55:47.072 [ZeusMonitor] Monitor started.
2022-12-08 16:55:47.072 [ZeusMonitor] Running indefinitely. 2022-12-08 16:55:47.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:55:47.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e98+gpu0.power.log
2022-12-08 11:56:31,692 [ZeusDataLoader(train)] train epoch 98 done: time=44.81 energy=6816.99
2022-12-08 11:56:31,696 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 0.1106
Training Epoch: 97 [2048/50176]	Loss: 0.0947
Training Epoch: 97 [3072/50176]	Loss: 0.1254
Training Epoch: 97 [4096/50176]	Loss: 0.1235
Training Epoch: 97 [5120/50176]	Loss: 0.1363
Training Epoch: 97 [6144/50176]	Loss: 0.1087
Training Epoch: 97 [7168/50176]	Loss: 0.1161
Training Epoch: 97 [8192/50176]	Loss: 0.1149
Training Epoch: 97 [9216/50176]	Loss: 0.1362
Training Epoch: 97 [10240/50176]	Loss: 0.1305
Training Epoch: 97 [11264/50176]	Loss: 0.1282
Training Epoch: 97 [12288/50176]	Loss: 0.1138
Training Epoch: 97 [13312/50176]	Loss: 0.1136
Training Epoch: 97 [14336/50176]	Loss: 0.0902
Training Epoch: 97 [15360/50176]	Loss: 0.1141
Training Epoch: 97 [16384/50176]	Loss: 0.1184
Training Epoch: 97 [17408/50176]	Loss: 0.1069
Training Epoch: 97 [18432/50176]	Loss: 0.1178
Training Epoch: 97 [19456/50176]	Loss: 0.1015
Training Epoch: 97 [20480/50176]	Loss: 0.1237
Training Epoch: 97 [21504/50176]	Loss: 0.1147
Training Epoch: 97 [22528/50176]	Loss: 0.1234
Training Epoch: 97 [23552/50176]	Loss: 0.1081
Training Epoch: 97 [24576/50176]	Loss: 0.1163
Training Epoch: 97 [25600/50176]	Loss: 0.1078
Training Epoch: 97 [26624/50176]	Loss: 0.1013
Training Epoch: 97 [27648/50176]	Loss: 0.1241
Training Epoch: 97 [28672/50176]	Loss: 0.1297
Training Epoch: 97 [29696/50176]	Loss: 0.1097
Training Epoch: 97 [30720/50176]	Loss: 0.1402
Training Epoch: 97 [31744/50176]	Loss: 0.1069
Training Epoch: 97 [32768/50176]	Loss: 0.1226
Training Epoch: 97 [33792/50176]	Loss: 0.1421
Training Epoch: 97 [34816/50176]	Loss: 0.1535
Training Epoch: 97 [35840/50176]	Loss: 0.1367
Training Epoch: 97 [36864/50176]	Loss: 0.1198
Training Epoch: 97 [37888/50176]	Loss: 0.1047
Training Epoch: 97 [38912/50176]	Loss: 0.1248
Training Epoch: 97 [39936/50176]	Loss: 0.1085
Training Epoch: 97 [40960/50176]	Loss: 0.1250
Training Epoch: 97 [41984/50176]	Loss: 0.1172
Training Epoch: 97 [43008/50176]	Loss: 0.1325
Training Epoch: 97 [44032/50176]	Loss: 0.1320
Training Epoch: 97 [45056/50176]	Loss: 0.1614
Training Epoch: 97 [46080/50176]	Loss: 0.1321
Training Epoch: 97 [47104/50176]	Loss: 0.1337
Training Epoch: 97 [48128/50176]	Loss: 0.1523
Training Epoch: 97 [49152/50176]	Loss: 0.1211
Training Epoch: 97 [50176/50176]	Loss: 0.1396
2022-12-08 16:56:35.481 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:56:35,505 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.80 energy=536.64
2022-12-08 11:56:35,506 [ZeusDataLoader(train)] Up to epoch 98: time=4843.19, energy=722587.44, cost=785073.25
2022-12-08 11:56:35,506 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:56:35,506 [ZeusDataLoader(train)] Expected next epoch: time=4890.64, energy=729844.25, cost=792853.53
2022-12-08 11:56:35,507 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0024, Accuracy: 0.5828
2022-12-08 11:56:35,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:56:35,702 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:56:35.704 [ZeusMonitor] Monitor started.
2022-12-08 16:56:35.704 [ZeusMonitor] Running indefinitely. 2022-12-08 16:56:35.704 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:56:35.704 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e99+gpu0.power.log
2022-12-08 11:57:20,175 [ZeusDataLoader(train)] train epoch 99 done: time=44.66 energy=6805.49
2022-12-08 11:57:20,180 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 0.1144
Training Epoch: 98 [2048/50176]	Loss: 0.0909
Training Epoch: 98 [3072/50176]	Loss: 0.1022
Training Epoch: 98 [4096/50176]	Loss: 0.1151
Training Epoch: 98 [5120/50176]	Loss: 0.0952
Training Epoch: 98 [6144/50176]	Loss: 0.1169
Training Epoch: 98 [7168/50176]	Loss: 0.1284
Training Epoch: 98 [8192/50176]	Loss: 0.1393
Training Epoch: 98 [9216/50176]	Loss: 0.1217
Training Epoch: 98 [10240/50176]	Loss: 0.1273
Training Epoch: 98 [11264/50176]	Loss: 0.1073
Training Epoch: 98 [12288/50176]	Loss: 0.1012
Training Epoch: 98 [13312/50176]	Loss: 0.1158
Training Epoch: 98 [14336/50176]	Loss: 0.0832
Training Epoch: 98 [15360/50176]	Loss: 0.0944
Training Epoch: 98 [16384/50176]	Loss: 0.1070
Training Epoch: 98 [17408/50176]	Loss: 0.1076
Training Epoch: 98 [18432/50176]	Loss: 0.0998
Training Epoch: 98 [19456/50176]	Loss: 0.0969
Training Epoch: 98 [20480/50176]	Loss: 0.0922
Training Epoch: 98 [21504/50176]	Loss: 0.1010
Training Epoch: 98 [22528/50176]	Loss: 0.1154
Training Epoch: 98 [23552/50176]	Loss: 0.1315
Training Epoch: 98 [24576/50176]	Loss: 0.1244
Training Epoch: 98 [25600/50176]	Loss: 0.1198
Training Epoch: 98 [26624/50176]	Loss: 0.1090
Training Epoch: 98 [27648/50176]	Loss: 0.1156
Training Epoch: 98 [28672/50176]	Loss: 0.1104
Training Epoch: 98 [29696/50176]	Loss: 0.0874
Training Epoch: 98 [30720/50176]	Loss: 0.1076
Training Epoch: 98 [31744/50176]	Loss: 0.1285
Training Epoch: 98 [32768/50176]	Loss: 0.1043
Training Epoch: 98 [33792/50176]	Loss: 0.1229
Training Epoch: 98 [34816/50176]	Loss: 0.1371
Training Epoch: 98 [35840/50176]	Loss: 0.1099
Training Epoch: 98 [36864/50176]	Loss: 0.1477
Training Epoch: 98 [37888/50176]	Loss: 0.1143
Training Epoch: 98 [38912/50176]	Loss: 0.1210
Training Epoch: 98 [39936/50176]	Loss: 0.1235
Training Epoch: 98 [40960/50176]	Loss: 0.1094
Training Epoch: 98 [41984/50176]	Loss: 0.1232
Training Epoch: 98 [43008/50176]	Loss: 0.1320
Training Epoch: 98 [44032/50176]	Loss: 0.1184
Training Epoch: 98 [45056/50176]	Loss: 0.1327
Training Epoch: 98 [46080/50176]	Loss: 0.1293
Training Epoch: 98 [47104/50176]	Loss: 0.1164
Training Epoch: 98 [48128/50176]	Loss: 0.1189
Training Epoch: 98 [49152/50176]	Loss: 0.1346
Training Epoch: 98 [50176/50176]	Loss: 0.1139
2022-12-08 16:57:23.973 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:57:24,003 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.81 energy=522.02
2022-12-08 11:57:24,003 [ZeusDataLoader(train)] Up to epoch 99: time=4891.67, energy=729914.95, cost=792978.42
2022-12-08 11:57:24,004 [ZeusDataLoader(train)] Optimal PL train & eval expected time=47.45 energy=7256.81
2022-12-08 11:57:24,004 [ZeusDataLoader(train)] Expected next epoch: time=4939.12, energy=737171.76, cost=800758.69
2022-12-08 11:57:24,005 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0024, Accuracy: 0.5866
2022-12-08 11:57:24,197 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-08 11:57:24,198 [ZeusDataLoader(train)] Steady state power limit: OPT 175W
2022-12-08 16:57:24.199 [ZeusMonitor] Monitor started.
2022-12-08 16:57:24.200 [ZeusMonitor] Running indefinitely. 2022-12-08 16:57:24.200 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-08 16:57:24.200 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/bs1024+e100+gpu0.power.log
2022-12-08 11:58:08,585 [ZeusDataLoader(train)] train epoch 100 done: time=44.57 energy=6774.32
2022-12-08 11:58:08,589 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 0.1194
Training Epoch: 99 [2048/50176]	Loss: 0.1148
Training Epoch: 99 [3072/50176]	Loss: 0.0918
Training Epoch: 99 [4096/50176]	Loss: 0.1153
Training Epoch: 99 [5120/50176]	Loss: 0.1007
Training Epoch: 99 [6144/50176]	Loss: 0.0979
Training Epoch: 99 [7168/50176]	Loss: 0.1289
Training Epoch: 99 [8192/50176]	Loss: 0.1143
Training Epoch: 99 [9216/50176]	Loss: 0.1070
Training Epoch: 99 [10240/50176]	Loss: 0.0875
Training Epoch: 99 [11264/50176]	Loss: 0.1016
Training Epoch: 99 [12288/50176]	Loss: 0.0913
Training Epoch: 99 [13312/50176]	Loss: 0.1026
Training Epoch: 99 [14336/50176]	Loss: 0.0896
Training Epoch: 99 [15360/50176]	Loss: 0.0894
Training Epoch: 99 [16384/50176]	Loss: 0.1035
Training Epoch: 99 [17408/50176]	Loss: 0.1156
Training Epoch: 99 [18432/50176]	Loss: 0.1118
Training Epoch: 99 [19456/50176]	Loss: 0.0966
Training Epoch: 99 [20480/50176]	Loss: 0.0998
Training Epoch: 99 [21504/50176]	Loss: 0.1044
Training Epoch: 99 [22528/50176]	Loss: 0.1000
Training Epoch: 99 [23552/50176]	Loss: 0.1000
Training Epoch: 99 [24576/50176]	Loss: 0.1086
Training Epoch: 99 [25600/50176]	Loss: 0.1002
Training Epoch: 99 [26624/50176]	Loss: 0.1269
Training Epoch: 99 [27648/50176]	Loss: 0.0880
Training Epoch: 99 [28672/50176]	Loss: 0.1218
Training Epoch: 99 [29696/50176]	Loss: 0.0841
Training Epoch: 99 [30720/50176]	Loss: 0.0986
Training Epoch: 99 [31744/50176]	Loss: 0.1042
Training Epoch: 99 [32768/50176]	Loss: 0.1047
Training Epoch: 99 [33792/50176]	Loss: 0.1135
Training Epoch: 99 [34816/50176]	Loss: 0.1296
Training Epoch: 99 [35840/50176]	Loss: 0.1372
Training Epoch: 99 [36864/50176]	Loss: 0.1497
Training Epoch: 99 [37888/50176]	Loss: 0.1157
Training Epoch: 99 [38912/50176]	Loss: 0.1199
Training Epoch: 99 [39936/50176]	Loss: 0.1264
Training Epoch: 99 [40960/50176]	Loss: 0.1060
Training Epoch: 99 [41984/50176]	Loss: 0.1341
Training Epoch: 99 [43008/50176]	Loss: 0.1161
Training Epoch: 99 [44032/50176]	Loss: 0.1259
Training Epoch: 99 [45056/50176]	Loss: 0.1491
Training Epoch: 99 [46080/50176]	Loss: 0.1084
Training Epoch: 99 [47104/50176]	Loss: 0.1102
Training Epoch: 99 [48128/50176]	Loss: 0.1329
Training Epoch: 99 [49152/50176]	Loss: 0.1387
Training Epoch: 99 [50176/50176]	Loss: 0.1227
2022-12-08 16:58:12.380 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-08 11:58:12,406 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.81 energy=536.58
2022-12-08 11:58:12,406 [ZeusDataLoader(train)] Up to epoch 100: time=4940.05, energy=737225.85, cost=800867.08
2022-12-08 11:58:12,406 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-08 11:58:12,407 [ZeusDataLoader(train)] Training done.
2022-12-08 11:58:12,407 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adadelta+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120810351670513734/rec00+try01+bs1024+lr0.0100000.train.json: {"energy": 737225.8546364072, "time": 4940.047461004, "cost": 800867.0801560536, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 0.0024, Accuracy: 0.5882

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 737225.8546364072, 'time': 4940.047461004, 'cost': 800867.0801560536, 'num_epochs': 100, 'reached': False}
[run job; power] power_stats={'job_id': 'rec00+try01', 'train_power': {'175000': 154.40443116295992, '150000': 146.53987041988927, '125000': 122.72397225081689, '100000': 102.08045101720573}, 'train_throughput': {'175000': 1.122030166276307, '150000': 1.090649724980027, '125000': 0.9622041478454387, '100000': 0.36653964935112676}, 'eval_power': {'175000': 135.96811705020852, '150000': 132.2877466725818, '125000': 112.50808699512434}, 'eval_throughput': {'175000': 2.6461322114583137, '150000': 2.6592437105036812, '125000': 2.3356564013251946}, 'optimal_pl': 175000}
[Zeus Master] cost=800867.0801560536

[Zeus Master] Job did not reach the target metric!
[Zeus Master]
[HistoryEntry(bs=1024, pl=175.0, lr=0.01, energy=737225.8546364072, reached=False, time=4940.047461004)]
