[run job] Launching job with BS 1024: and LR: 0.5
[run job] zeus_env={'ZEUS_LOG_DIR': '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805', 'ZEUS_JOB_ID': 'rec03+try01', 'ZEUS_COST_THRESH': 'inf', 'ZEUS_ETA_KNOB': '0.5', 'ZEUS_TARGET_METRIC': '0.6', 'ZEUS_MONITOR_PATH': '/workspace/zeus/zeus_monitor/zeus_monitor', 'ZEUS_PROFILE_PARAMS': '10,40', 'ZEUS_USE_OPTIMAL_PL': 'True'}
[run job] cwd=/workspace/zeus/examples/cifar100
[run job] command=['python', 'train_lr.py', '--zeus', '--arch', 'shufflenetv2', '--batch_size', '1024', '--epochs', '100', '--seed', '1', '--learning_rate', '0.5']
[run job] cost_ub=inf
[run job] Job output logged to '/workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec03+try01.train.log'
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] Distributed data parallel: OFF
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] The profile window takes 50 iterations (10 for warmup + 40 for profile) and exceeds the number of iterations (49) in one epoch. Scaling the profile window to fit in one epoch...
2022-12-06 14:31:56,793 [ZeusDataLoader(train)] Scaling done! New profile window takes 47 iterations (9 for warmup + 38 for profile).
2022-12-06 14:31:56,836 [ZeusDataLoader(train)] Power limit range: [175000, 150000, 125000, 100000]
2022-12-06 14:31:56,836 [ZeusDataLoader(train)] Power profiling: ON
2022-12-06 14:31:58,997 [ZeusDataLoader(train)] Up to epoch 0: time=0.00, energy=0.00, cost=0.00
2022-12-06 14:31:58,998 [ZeusDataLoader(train)] Epoch 1 begin.
Files already downloaded and verified
Files already downloaded and verified
2022-12-06 14:31:59,187 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:31:59.191 [ZeusMonitor] Monitor started.
2022-12-06 19:31:59.191 [ZeusMonitor] Running indefinitely. 2022-12-06 19:31:59.191 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:31:59.191 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e1+gpu0.power.log
2022-12-06 14:31:59,888 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 175W.
2022-12-06 14:31:59,889 [ZeusDataLoader(train)] Warm-up started with power limit 175W
2022-12-06 14:32:08,655 [ZeusDataLoader(train)] Profile started with power limit 175W
2022-12-06 14:32:42,805 [ZeusDataLoader(train)] Profile done with power limit 175W
2022-12-06 14:32:44,455 [ZeusDataLoader(train)] train epoch 1 done: time=45.45 energy=6246.86
2022-12-06 14:32:44,458 [ZeusDataLoader(eval)] Epoch 1 begin.
Training Epoch: 0 [1024/50176]	Loss: 4.6235
Training Epoch: 0 [2048/50176]	Loss: 182.1425
Training Epoch: 0 [3072/50176]	Loss: 48.1428
Training Epoch: 0 [4096/50176]	Loss: 12.7722
Training Epoch: 0 [5120/50176]	Loss: 17.6722
Training Epoch: 0 [6144/50176]	Loss: 4.9360
Training Epoch: 0 [7168/50176]	Loss: 5.6275
Training Epoch: 0 [8192/50176]	Loss: 8.5320
Training Epoch: 0 [9216/50176]	Loss: 5.1642
Training Epoch: 0 [10240/50176]	Loss: 6.1835
Training Epoch: 0 [11264/50176]	Loss: 4.9697
Training Epoch: 0 [12288/50176]	Loss: 4.7855
Training Epoch: 0 [13312/50176]	Loss: 4.8630
Training Epoch: 0 [14336/50176]	Loss: 4.7613
Training Epoch: 0 [15360/50176]	Loss: 4.6853
Training Epoch: 0 [16384/50176]	Loss: 4.6704
Training Epoch: 0 [17408/50176]	Loss: 4.7377
Training Epoch: 0 [18432/50176]	Loss: 4.6797
Training Epoch: 0 [19456/50176]	Loss: 4.6488
Training Epoch: 0 [20480/50176]	Loss: 4.6987
Training Epoch: 0 [21504/50176]	Loss: 4.6691
Training Epoch: 0 [22528/50176]	Loss: 4.6910
Training Epoch: 0 [23552/50176]	Loss: 4.6831
Training Epoch: 0 [24576/50176]	Loss: 4.6858
Training Epoch: 0 [25600/50176]	Loss: 4.6520
Training Epoch: 0 [26624/50176]	Loss: 4.6496
Training Epoch: 0 [27648/50176]	Loss: 4.6470
Training Epoch: 0 [28672/50176]	Loss: 4.6366
Training Epoch: 0 [29696/50176]	Loss: 4.6378
Training Epoch: 0 [30720/50176]	Loss: 4.6450
Training Epoch: 0 [31744/50176]	Loss: 4.6867
Training Epoch: 0 [32768/50176]	Loss: 4.6452
Training Epoch: 0 [33792/50176]	Loss: 4.6546
Training Epoch: 0 [34816/50176]	Loss: 4.6552
Training Epoch: 0 [35840/50176]	Loss: 4.6530
Training Epoch: 0 [36864/50176]	Loss: 4.6351
Training Epoch: 0 [37888/50176]	Loss: 4.6331
Training Epoch: 0 [38912/50176]	Loss: 4.6310
Training Epoch: 0 [39936/50176]	Loss: 4.6494
Training Epoch: 0 [40960/50176]	Loss: 4.6435
Training Epoch: 0 [41984/50176]	Loss: 4.6470
Training Epoch: 0 [43008/50176]	Loss: 4.6597
Training Epoch: 0 [44032/50176]	Loss: 4.6391
Training Epoch: 0 [45056/50176]	Loss: 4.6448
Training Epoch: 0 [46080/50176]	Loss: 4.6392
Training Epoch: 0 [47104/50176]	Loss: 4.6307
Training Epoch: 0 [48128/50176]	Loss: 4.6309
Training Epoch: 0 [49152/50176]	Loss: 4.6326
Training Epoch: 0 [50176/50176]	Loss: 4.6314
2022-12-06 19:32:48.202 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:32:48,222 [ZeusDataLoader(eval)] eval epoch 1 done: time=3.76 energy=472.02
2022-12-06 14:32:48,222 [ZeusDataLoader(train)] Up to epoch 1: time=49.21, energy=6718.87, cost=7664.98
2022-12-06 14:32:48,223 [ZeusDataLoader(train)] Epoch 2 begin.
Validation Epoch: 0, Average loss: 0.0046, Accuracy: 0.0101
2022-12-06 14:32:48,479 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:32:48.481 [ZeusMonitor] Monitor started.
2022-12-06 19:32:48.481 [ZeusMonitor] Running indefinitely. 2022-12-06 19:32:48.482 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:32:48.482 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e2+gpu0.power.log
2022-12-06 14:32:49,168 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 14:32:49,169 [ZeusDataLoader(train)] Warm-up started with power limit 150W
2022-12-06 14:32:57,275 [ZeusDataLoader(train)] Profile started with power limit 150W
2022-12-06 14:33:30,475 [ZeusDataLoader(train)] Profile done with power limit 150W
2022-12-06 14:33:32,125 [ZeusDataLoader(train)] train epoch 2 done: time=43.90 energy=5915.11
2022-12-06 14:33:32,128 [ZeusDataLoader(eval)] Epoch 2 begin.
Training Epoch: 1 [1024/50176]	Loss: 4.6400
Training Epoch: 1 [2048/50176]	Loss: 4.6316
Training Epoch: 1 [3072/50176]	Loss: 4.6408
Training Epoch: 1 [4096/50176]	Loss: 4.6283
Training Epoch: 1 [5120/50176]	Loss: 4.6458
Training Epoch: 1 [6144/50176]	Loss: 4.6296
Training Epoch: 1 [7168/50176]	Loss: 4.6313
Training Epoch: 1 [8192/50176]	Loss: 4.6324
Training Epoch: 1 [9216/50176]	Loss: 4.6340
Training Epoch: 1 [10240/50176]	Loss: 4.6399
Training Epoch: 1 [11264/50176]	Loss: 4.6301
Training Epoch: 1 [12288/50176]	Loss: 4.6290
Training Epoch: 1 [13312/50176]	Loss: 4.6348
Training Epoch: 1 [14336/50176]	Loss: 4.6360
Training Epoch: 1 [15360/50176]	Loss: 4.6303
Training Epoch: 1 [16384/50176]	Loss: 4.6395
Training Epoch: 1 [17408/50176]	Loss: 4.6394
Training Epoch: 1 [18432/50176]	Loss: 4.6387
Training Epoch: 1 [19456/50176]	Loss: 4.6254
Training Epoch: 1 [20480/50176]	Loss: 4.6237
Training Epoch: 1 [21504/50176]	Loss: 4.6362
Training Epoch: 1 [22528/50176]	Loss: 4.6342
Training Epoch: 1 [23552/50176]	Loss: 4.6335
Training Epoch: 1 [24576/50176]	Loss: 4.6499
Training Epoch: 1 [25600/50176]	Loss: 4.6361
Training Epoch: 1 [26624/50176]	Loss: 4.6254
Training Epoch: 1 [27648/50176]	Loss: 4.6316
Training Epoch: 1 [28672/50176]	Loss: 4.6289
Training Epoch: 1 [29696/50176]	Loss: 4.6251
Training Epoch: 1 [30720/50176]	Loss: 4.6519
Training Epoch: 1 [31744/50176]	Loss: 4.6309
Training Epoch: 1 [32768/50176]	Loss: 4.6348
Training Epoch: 1 [33792/50176]	Loss: 4.6348
Training Epoch: 1 [34816/50176]	Loss: 4.6366
Training Epoch: 1 [35840/50176]	Loss: 4.6399
Training Epoch: 1 [36864/50176]	Loss: 4.6418
Training Epoch: 1 [37888/50176]	Loss: 4.6373
Training Epoch: 1 [38912/50176]	Loss: 4.6189
Training Epoch: 1 [39936/50176]	Loss: 4.6395
Training Epoch: 1 [40960/50176]	Loss: 4.6364
Training Epoch: 1 [41984/50176]	Loss: 4.6400
Training Epoch: 1 [43008/50176]	Loss: 4.6315
Training Epoch: 1 [44032/50176]	Loss: 4.6488
Training Epoch: 1 [45056/50176]	Loss: 4.6275
Training Epoch: 1 [46080/50176]	Loss: 4.6090
Training Epoch: 1 [47104/50176]	Loss: 4.6334
Training Epoch: 1 [48128/50176]	Loss: 4.6315
Training Epoch: 1 [49152/50176]	Loss: 4.6354
Training Epoch: 1 [50176/50176]	Loss: 4.6294
2022-12-06 19:33:35.864 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:33:35,894 [ZeusDataLoader(eval)] eval epoch 2 done: time=3.76 energy=466.13
2022-12-06 14:33:35,895 [ZeusDataLoader(train)] Up to epoch 2: time=96.86, energy=13100.11, cost=15025.30
2022-12-06 14:33:35,896 [ZeusDataLoader(train)] Epoch 3 begin.
Validation Epoch: 1, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:33:36,090 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:33:36.094 [ZeusMonitor] Monitor started.
2022-12-06 19:33:36.094 [ZeusMonitor] Running indefinitely. 2022-12-06 19:33:36.094 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:33:36.094 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e3+gpu0.power.log
2022-12-06 14:33:36,782 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 125W.
2022-12-06 14:33:36,782 [ZeusDataLoader(train)] Warm-up started with power limit 125W
2022-12-06 14:33:45,211 [ZeusDataLoader(train)] Profile started with power limit 125W
2022-12-06 14:34:20,183 [ZeusDataLoader(train)] Profile done with power limit 125W
2022-12-06 14:34:21,918 [ZeusDataLoader(train)] train epoch 3 done: time=46.02 energy=5527.60
2022-12-06 14:34:21,921 [ZeusDataLoader(eval)] Epoch 3 begin.
Training Epoch: 2 [1024/50176]	Loss: 4.6320
Training Epoch: 2 [2048/50176]	Loss: 4.6556
Training Epoch: 2 [3072/50176]	Loss: 4.6322
Training Epoch: 2 [4096/50176]	Loss: 4.6298
Training Epoch: 2 [5120/50176]	Loss: 4.6395
Training Epoch: 2 [6144/50176]	Loss: 4.6272
Training Epoch: 2 [7168/50176]	Loss: 4.6517
Training Epoch: 2 [8192/50176]	Loss: 4.6330
Training Epoch: 2 [9216/50176]	Loss: 4.6292
Training Epoch: 2 [10240/50176]	Loss: 4.6335
Training Epoch: 2 [11264/50176]	Loss: 4.6309
Training Epoch: 2 [12288/50176]	Loss: 4.6384
Training Epoch: 2 [13312/50176]	Loss: 4.6331
Training Epoch: 2 [14336/50176]	Loss: 4.6429
Training Epoch: 2 [15360/50176]	Loss: 4.6290
Training Epoch: 2 [16384/50176]	Loss: 4.6423
Training Epoch: 2 [17408/50176]	Loss: 4.6357
Training Epoch: 2 [18432/50176]	Loss: 4.6397
Training Epoch: 2 [19456/50176]	Loss: 4.6405
Training Epoch: 2 [20480/50176]	Loss: 4.6352
Training Epoch: 2 [21504/50176]	Loss: 4.6367
Training Epoch: 2 [22528/50176]	Loss: 4.6241
Training Epoch: 2 [23552/50176]	Loss: 4.6295
Training Epoch: 2 [24576/50176]	Loss: 4.6418
Training Epoch: 2 [25600/50176]	Loss: 4.6436
Training Epoch: 2 [26624/50176]	Loss: 4.6333
Training Epoch: 2 [27648/50176]	Loss: 4.6367
Training Epoch: 2 [28672/50176]	Loss: 4.6313
Training Epoch: 2 [29696/50176]	Loss: 4.6267
Training Epoch: 2 [30720/50176]	Loss: 4.6367
Training Epoch: 2 [31744/50176]	Loss: 4.6288
Training Epoch: 2 [32768/50176]	Loss: 4.6288
Training Epoch: 2 [33792/50176]	Loss: 4.6420
Training Epoch: 2 [34816/50176]	Loss: 4.6168
Training Epoch: 2 [35840/50176]	Loss: 4.6311
Training Epoch: 2 [36864/50176]	Loss: 4.6307
Training Epoch: 2 [37888/50176]	Loss: 4.6388
Training Epoch: 2 [38912/50176]	Loss: 4.6388
Training Epoch: 2 [39936/50176]	Loss: 4.6316
Training Epoch: 2 [40960/50176]	Loss: 4.6385
Training Epoch: 2 [41984/50176]	Loss: 4.6293
Training Epoch: 2 [43008/50176]	Loss: 4.6224
Training Epoch: 2 [44032/50176]	Loss: 4.6302
Training Epoch: 2 [45056/50176]	Loss: 4.6388
Training Epoch: 2 [46080/50176]	Loss: 4.6456
Training Epoch: 2 [47104/50176]	Loss: 4.6324
Training Epoch: 2 [48128/50176]	Loss: 4.6443
Training Epoch: 2 [49152/50176]	Loss: 4.6440
Training Epoch: 2 [50176/50176]	Loss: 4.6193
2022-12-06 19:34:25.854 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:34:25,880 [ZeusDataLoader(eval)] eval epoch 3 done: time=3.95 energy=442.33
2022-12-06 14:34:25,881 [ZeusDataLoader(train)] Up to epoch 3: time=146.83, energy=19070.04, cost=22382.38
2022-12-06 14:34:25,882 [ZeusDataLoader(train)] Epoch 4 begin.
Validation Epoch: 2, Average loss: 0.0066, Accuracy: 0.0099
2022-12-06 14:34:26,144 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 19:34:26.147 [ZeusMonitor] Monitor started.
2022-12-06 19:34:26.147 [ZeusMonitor] Running indefinitely. 2022-12-06 19:34:26.147 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:34:26.147 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e4+gpu0.power.log
2022-12-06 14:34:26,818 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 100W.
2022-12-06 14:34:26,819 [ZeusDataLoader(train)] Warm-up started with power limit 100W
2022-12-06 14:34:36,816 [ZeusDataLoader(train)] Profile started with power limit 100W
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] Profile done with power limit 100W
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] This was the last power limit to explore.
2022-12-06 14:35:19,050 [ZeusDataLoader(train)] Cost-optimal power limit is 150W
2022-12-06 14:35:19,053 [ZeusDataLoader(train)] [GPU_0] Set GPU power limit to 150W.
2022-12-06 14:35:20,835 [ZeusDataLoader(train)] train epoch 4 done: time=54.95 energy=5362.67
2022-12-06 14:35:20,838 [ZeusDataLoader(eval)] Epoch 4 begin.
Training Epoch: 3 [1024/50176]	Loss: 4.6282
Training Epoch: 3 [2048/50176]	Loss: 4.6226
Training Epoch: 3 [3072/50176]	Loss: 4.6413
Training Epoch: 3 [4096/50176]	Loss: 4.6407
Training Epoch: 3 [5120/50176]	Loss: 4.6382
Training Epoch: 3 [6144/50176]	Loss: 4.6322
Training Epoch: 3 [7168/50176]	Loss: 4.6378
Training Epoch: 3 [8192/50176]	Loss: 4.6235
Training Epoch: 3 [9216/50176]	Loss: 4.6321
Training Epoch: 3 [10240/50176]	Loss: 4.6297
Training Epoch: 3 [11264/50176]	Loss: 4.6396
Training Epoch: 3 [12288/50176]	Loss: 4.6367
Training Epoch: 3 [13312/50176]	Loss: 4.6275
Training Epoch: 3 [14336/50176]	Loss: 4.6403
Training Epoch: 3 [15360/50176]	Loss: 4.6481
Training Epoch: 3 [16384/50176]	Loss: 4.6263
Training Epoch: 3 [17408/50176]	Loss: 4.6331
Training Epoch: 3 [18432/50176]	Loss: 4.6184
Training Epoch: 3 [19456/50176]	Loss: 4.6249
Training Epoch: 3 [20480/50176]	Loss: 4.6338
Training Epoch: 3 [21504/50176]	Loss: 4.6353
Training Epoch: 3 [22528/50176]	Loss: 4.6242
Training Epoch: 3 [23552/50176]	Loss: 4.6491
Training Epoch: 3 [24576/50176]	Loss: 4.6414
Training Epoch: 3 [25600/50176]	Loss: 4.6340
Training Epoch: 3 [26624/50176]	Loss: 4.6243
Training Epoch: 3 [27648/50176]	Loss: 4.6356
Training Epoch: 3 [28672/50176]	Loss: 4.6255
Training Epoch: 3 [29696/50176]	Loss: 4.6374
Training Epoch: 3 [30720/50176]	Loss: 4.6301
Training Epoch: 3 [31744/50176]	Loss: 4.6434
Training Epoch: 3 [32768/50176]	Loss: 4.6414
Training Epoch: 3 [33792/50176]	Loss: 4.6327
Training Epoch: 3 [34816/50176]	Loss: 4.6293
Training Epoch: 3 [35840/50176]	Loss: 4.6245
Training Epoch: 3 [36864/50176]	Loss: 4.6267
Training Epoch: 3 [37888/50176]	Loss: 4.6430
Training Epoch: 3 [38912/50176]	Loss: 4.6246
Training Epoch: 3 [39936/50176]	Loss: 4.6478
Training Epoch: 3 [40960/50176]	Loss: 4.6282
Training Epoch: 3 [41984/50176]	Loss: 4.6379
Training Epoch: 3 [43008/50176]	Loss: 4.6204
Training Epoch: 3 [44032/50176]	Loss: 4.6244
Training Epoch: 3 [45056/50176]	Loss: 4.6314
Training Epoch: 3 [46080/50176]	Loss: 4.6210
Training Epoch: 3 [47104/50176]	Loss: 4.6185
Training Epoch: 3 [48128/50176]	Loss: 4.6407
Training Epoch: 3 [49152/50176]	Loss: 4.6422
Training Epoch: 3 [50176/50176]	Loss: 4.6297
2022-12-06 19:35:24.602 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:35:24,656 [ZeusDataLoader(eval)] Power profiling done.
2022-12-06 14:35:24,656 [ZeusDataLoader(eval)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+lr0.5000000.power.json: {"job_id": "rec03+try01", "train_power": {"175000": 141.93837297518056, "150000": 137.5711933424961, "125000": 122.45263058940533, "100000": 98.39104404902801}, "train_throughput": {"175000": 1.1131630264555321, "150000": 1.1449147533158621, "125000": 1.086906289817731, "100000": 0.8999782655864567}, "eval_power": {"175000": 125.66587303669519, "150000": 125.63847713019706, "125000": 111.94785245414742}, "eval_throughput": {"175000": 2.662326664559453, "150000": 2.6255096010426673, "125000": 2.5308668007617996}, "optimal_pl": 150000}
2022-12-06 14:35:24,657 [ZeusDataLoader(eval)] eval epoch 4 done: time=3.81 energy=478.53
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Up to epoch 4: time=205.58, energy=24911.24, cost=30444.05
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:35:24,657 [ZeusDataLoader(train)] Expected next epoch: time=252.19, energy=31277.54, cost=37705.28
2022-12-06 14:35:24,658 [ZeusDataLoader(train)] Epoch 5 begin.
Validation Epoch: 3, Average loss: 20987.3145, Accuracy: 0.0098
2022-12-06 14:35:24,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:35:24,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:35:24.911 [ZeusMonitor] Monitor started.
2022-12-06 19:35:24.912 [ZeusMonitor] Running indefinitely. 2022-12-06 19:35:24.912 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:35:24.912 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e5+gpu0.power.log
2022-12-06 14:36:08,631 [ZeusDataLoader(train)] train epoch 5 done: time=43.96 energy=5847.50
2022-12-06 14:36:08,634 [ZeusDataLoader(eval)] Epoch 5 begin.
Training Epoch: 4 [1024/50176]	Loss: 4.6281
Training Epoch: 4 [2048/50176]	Loss: 4.6492
Training Epoch: 4 [3072/50176]	Loss: 4.6327
Training Epoch: 4 [4096/50176]	Loss: 4.6265
Training Epoch: 4 [5120/50176]	Loss: 4.6373
Training Epoch: 4 [6144/50176]	Loss: 4.6380
Training Epoch: 4 [7168/50176]	Loss: 4.6348
Training Epoch: 4 [8192/50176]	Loss: 4.6372
Training Epoch: 4 [9216/50176]	Loss: 4.6323
Training Epoch: 4 [10240/50176]	Loss: 4.6243
Training Epoch: 4 [11264/50176]	Loss: 4.6291
Training Epoch: 4 [12288/50176]	Loss: 4.6226
Training Epoch: 4 [13312/50176]	Loss: 4.6279
Training Epoch: 4 [14336/50176]	Loss: 4.6355
Training Epoch: 4 [15360/50176]	Loss: 4.6262
Training Epoch: 4 [16384/50176]	Loss: 4.6288
Training Epoch: 4 [17408/50176]	Loss: 4.6436
Training Epoch: 4 [18432/50176]	Loss: 4.6282
Training Epoch: 4 [19456/50176]	Loss: 4.6191
Training Epoch: 4 [20480/50176]	Loss: 4.6379
Training Epoch: 4 [21504/50176]	Loss: 4.6429
Training Epoch: 4 [22528/50176]	Loss: 4.6320
Training Epoch: 4 [23552/50176]	Loss: 4.6368
Training Epoch: 4 [24576/50176]	Loss: 4.6353
Training Epoch: 4 [25600/50176]	Loss: 4.6235
Training Epoch: 4 [26624/50176]	Loss: 4.6278
Training Epoch: 4 [27648/50176]	Loss: 4.6413
Training Epoch: 4 [28672/50176]	Loss: 4.6475
Training Epoch: 4 [29696/50176]	Loss: 4.6554
Training Epoch: 4 [30720/50176]	Loss: 4.6401
Training Epoch: 4 [31744/50176]	Loss: 4.6567
Training Epoch: 4 [32768/50176]	Loss: 4.6294
Training Epoch: 4 [33792/50176]	Loss: 4.6276
Training Epoch: 4 [34816/50176]	Loss: 4.6403
Training Epoch: 4 [35840/50176]	Loss: 4.6384
Training Epoch: 4 [36864/50176]	Loss: 4.6431
Training Epoch: 4 [37888/50176]	Loss: 4.6204
Training Epoch: 4 [38912/50176]	Loss: 4.6335
Training Epoch: 4 [39936/50176]	Loss: 4.6268
Training Epoch: 4 [40960/50176]	Loss: 4.6175
Training Epoch: 4 [41984/50176]	Loss: 4.6348
Training Epoch: 4 [43008/50176]	Loss: 4.6313
Training Epoch: 4 [44032/50176]	Loss: 4.6301
Training Epoch: 4 [45056/50176]	Loss: 4.6323
Training Epoch: 4 [46080/50176]	Loss: 4.6282
Training Epoch: 4 [47104/50176]	Loss: 4.6267
Training Epoch: 4 [48128/50176]	Loss: 4.6353
Training Epoch: 4 [49152/50176]	Loss: 4.6430
Training Epoch: 4 [50176/50176]	Loss: 4.6257
2022-12-06 19:36:12.349 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:36:12,358 [ZeusDataLoader(eval)] eval epoch 5 done: time=3.72 energy=464.10
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Up to epoch 5: time=253.26, energy=31222.85, cost=37771.90
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:36:12,358 [ZeusDataLoader(train)] Expected next epoch: time=299.87, energy=37589.14, cost=45033.14
2022-12-06 14:36:12,359 [ZeusDataLoader(train)] Epoch 6 begin.
Validation Epoch: 4, Average loss: 7844883877121229.0000, Accuracy: 0.0100
2022-12-06 14:36:12,607 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:36:12,608 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:36:12.609 [ZeusMonitor] Monitor started.
2022-12-06 19:36:12.609 [ZeusMonitor] Running indefinitely. 2022-12-06 19:36:12.609 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:36:12.609 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e6+gpu0.power.log
2022-12-06 14:36:56,182 [ZeusDataLoader(train)] train epoch 6 done: time=43.81 energy=5828.14
2022-12-06 14:36:56,185 [ZeusDataLoader(eval)] Epoch 6 begin.
Training Epoch: 5 [1024/50176]	Loss: 4.6232
Training Epoch: 5 [2048/50176]	Loss: 4.6379
Training Epoch: 5 [3072/50176]	Loss: 4.6217
Training Epoch: 5 [4096/50176]	Loss: 4.6306
Training Epoch: 5 [5120/50176]	Loss: 4.6304
Training Epoch: 5 [6144/50176]	Loss: 4.6243
Training Epoch: 5 [7168/50176]	Loss: 4.6429
Training Epoch: 5 [8192/50176]	Loss: 4.6286
Training Epoch: 5 [9216/50176]	Loss: 4.6350
Training Epoch: 5 [10240/50176]	Loss: 4.6381
Training Epoch: 5 [11264/50176]	Loss: 4.6396
Training Epoch: 5 [12288/50176]	Loss: 4.6285
Training Epoch: 5 [13312/50176]	Loss: 4.6297
Training Epoch: 5 [14336/50176]	Loss: 4.6229
Training Epoch: 5 [15360/50176]	Loss: 4.6376
Training Epoch: 5 [16384/50176]	Loss: 4.6444
Training Epoch: 5 [17408/50176]	Loss: 4.6533
Training Epoch: 5 [18432/50176]	Loss: 4.6365
Training Epoch: 5 [19456/50176]	Loss: 4.6465
Training Epoch: 5 [20480/50176]	Loss: 4.6386
Training Epoch: 5 [21504/50176]	Loss: 4.6277
Training Epoch: 5 [22528/50176]	Loss: 4.6314
Training Epoch: 5 [23552/50176]	Loss: 4.6323
Training Epoch: 5 [24576/50176]	Loss: 4.6322
Training Epoch: 5 [25600/50176]	Loss: 4.6447
Training Epoch: 5 [26624/50176]	Loss: 4.6380
Training Epoch: 5 [27648/50176]	Loss: 4.6360
Training Epoch: 5 [28672/50176]	Loss: 4.6423
Training Epoch: 5 [29696/50176]	Loss: 4.6308
Training Epoch: 5 [30720/50176]	Loss: 4.6392
Training Epoch: 5 [31744/50176]	Loss: 4.6403
Training Epoch: 5 [32768/50176]	Loss: 4.6409
Training Epoch: 5 [33792/50176]	Loss: 4.6397
Training Epoch: 5 [34816/50176]	Loss: 4.6490
Training Epoch: 5 [35840/50176]	Loss: 4.6558
Training Epoch: 5 [36864/50176]	Loss: 4.6408
Training Epoch: 5 [37888/50176]	Loss: 4.6519
Training Epoch: 5 [38912/50176]	Loss: 4.6424
Training Epoch: 5 [39936/50176]	Loss: 4.6299
Training Epoch: 5 [40960/50176]	Loss: 4.6291
Training Epoch: 5 [41984/50176]	Loss: 4.6398
Training Epoch: 5 [43008/50176]	Loss: 4.6303
Training Epoch: 5 [44032/50176]	Loss: 4.6301
Training Epoch: 5 [45056/50176]	Loss: 4.6457
Training Epoch: 5 [46080/50176]	Loss: 4.6335
Training Epoch: 5 [47104/50176]	Loss: 4.6348
Training Epoch: 5 [48128/50176]	Loss: 4.6282
Training Epoch: 5 [49152/50176]	Loss: 4.6313
Training Epoch: 5 [50176/50176]	Loss: 4.6344
2022-12-06 19:36:59.983 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:37:00,018 [ZeusDataLoader(eval)] eval epoch 6 done: time=3.83 energy=476.45
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Up to epoch 6: time=300.90, energy=37527.43, cost=45092.66
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:37:00,018 [ZeusDataLoader(train)] Expected next epoch: time=347.51, energy=43893.73, cost=52353.90
2022-12-06 14:37:00,019 [ZeusDataLoader(train)] Epoch 7 begin.
Validation Epoch: 5, Average loss: 0.0049, Accuracy: 0.0098
2022-12-06 14:37:00,254 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:37:00,255 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:37:00.257 [ZeusMonitor] Monitor started.
2022-12-06 19:37:00.257 [ZeusMonitor] Running indefinitely. 2022-12-06 19:37:00.257 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:37:00.257 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e7+gpu0.power.log
2022-12-06 14:37:43,616 [ZeusDataLoader(train)] train epoch 7 done: time=43.59 energy=5815.69
2022-12-06 14:37:43,619 [ZeusDataLoader(eval)] Epoch 7 begin.
Training Epoch: 6 [1024/50176]	Loss: 4.6237
Training Epoch: 6 [2048/50176]	Loss: 4.6439
Training Epoch: 6 [3072/50176]	Loss: 4.6323
Training Epoch: 6 [4096/50176]	Loss: 4.6345
Training Epoch: 6 [5120/50176]	Loss: 4.6316
Training Epoch: 6 [6144/50176]	Loss: 4.6334
Training Epoch: 6 [7168/50176]	Loss: 4.6252
Training Epoch: 6 [8192/50176]	Loss: 4.6488
Training Epoch: 6 [9216/50176]	Loss: 4.6352
Training Epoch: 6 [10240/50176]	Loss: 4.6317
Training Epoch: 6 [11264/50176]	Loss: 4.6259
Training Epoch: 6 [12288/50176]	Loss: 4.6260
Training Epoch: 6 [13312/50176]	Loss: 4.6274
Training Epoch: 6 [14336/50176]	Loss: 4.6289
Training Epoch: 6 [15360/50176]	Loss: 4.6374
Training Epoch: 6 [16384/50176]	Loss: 4.6415
Training Epoch: 6 [17408/50176]	Loss: 4.6236
Training Epoch: 6 [18432/50176]	Loss: 4.6403
Training Epoch: 6 [19456/50176]	Loss: 4.6337
Training Epoch: 6 [20480/50176]	Loss: 4.6357
Training Epoch: 6 [21504/50176]	Loss: 4.6308
Training Epoch: 6 [22528/50176]	Loss: 4.6388
Training Epoch: 6 [23552/50176]	Loss: 4.6356
Training Epoch: 6 [24576/50176]	Loss: 4.6259
Training Epoch: 6 [25600/50176]	Loss: 4.6383
Training Epoch: 6 [26624/50176]	Loss: 4.6249
Training Epoch: 6 [27648/50176]	Loss: 4.6298
Training Epoch: 6 [28672/50176]	Loss: 4.6389
Training Epoch: 6 [29696/50176]	Loss: 4.6307
Training Epoch: 6 [30720/50176]	Loss: 4.6521
Training Epoch: 6 [31744/50176]	Loss: 4.6252
Training Epoch: 6 [32768/50176]	Loss: 4.6337
Training Epoch: 6 [33792/50176]	Loss: 4.6415
Training Epoch: 6 [34816/50176]	Loss: 4.6380
Training Epoch: 6 [35840/50176]	Loss: 4.6389
Training Epoch: 6 [36864/50176]	Loss: 4.6327
Training Epoch: 6 [37888/50176]	Loss: 4.6321
Training Epoch: 6 [38912/50176]	Loss: 4.6291
Training Epoch: 6 [39936/50176]	Loss: 4.6324
Training Epoch: 6 [40960/50176]	Loss: 4.6408
Training Epoch: 6 [41984/50176]	Loss: 4.6466
Training Epoch: 6 [43008/50176]	Loss: 4.6268
Training Epoch: 6 [44032/50176]	Loss: 4.6311
Training Epoch: 6 [45056/50176]	Loss: 4.6203
Training Epoch: 6 [46080/50176]	Loss: 4.6287
Training Epoch: 6 [47104/50176]	Loss: 4.6421
Training Epoch: 6 [48128/50176]	Loss: 4.6441
Training Epoch: 6 [49152/50176]	Loss: 4.6402
Training Epoch: 6 [50176/50176]	Loss: 4.6300
2022-12-06 19:37:47.318 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:37:47,341 [ZeusDataLoader(eval)] eval epoch 7 done: time=3.71 energy=464.21
2022-12-06 14:37:47,341 [ZeusDataLoader(train)] Up to epoch 7: time=348.20, energy=43807.34, cost=52371.53
2022-12-06 14:37:47,342 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:37:47,342 [ZeusDataLoader(train)] Expected next epoch: time=394.81, energy=50173.63, cost=59632.76
2022-12-06 14:37:47,343 [ZeusDataLoader(train)] Epoch 8 begin.
Validation Epoch: 6, Average loss: 2.1486, Accuracy: 0.0097
2022-12-06 14:37:47,587 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:37:47,588 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:37:47.590 [ZeusMonitor] Monitor started.
2022-12-06 19:37:47.590 [ZeusMonitor] Running indefinitely. 2022-12-06 19:37:47.590 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:37:47.590 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e8+gpu0.power.log
2022-12-06 14:38:30,970 [ZeusDataLoader(train)] train epoch 8 done: time=43.62 energy=5824.02
2022-12-06 14:38:30,974 [ZeusDataLoader(eval)] Epoch 8 begin.
Training Epoch: 7 [1024/50176]	Loss: 4.6265
Training Epoch: 7 [2048/50176]	Loss: 4.6358
Training Epoch: 7 [3072/50176]	Loss: 4.6284
Training Epoch: 7 [4096/50176]	Loss: 4.6192
Training Epoch: 7 [5120/50176]	Loss: 4.6257
Training Epoch: 7 [6144/50176]	Loss: 4.6388
Training Epoch: 7 [7168/50176]	Loss: 4.6282
Training Epoch: 7 [8192/50176]	Loss: 4.6321
Training Epoch: 7 [9216/50176]	Loss: 4.6185
Training Epoch: 7 [10240/50176]	Loss: 4.6311
Training Epoch: 7 [11264/50176]	Loss: 4.6277
Training Epoch: 7 [12288/50176]	Loss: 4.6519
Training Epoch: 7 [13312/50176]	Loss: 4.6240
Training Epoch: 7 [14336/50176]	Loss: 4.6286
Training Epoch: 7 [15360/50176]	Loss: 4.6311
Training Epoch: 7 [16384/50176]	Loss: 4.6259
Training Epoch: 7 [17408/50176]	Loss: 4.6359
Training Epoch: 7 [18432/50176]	Loss: 4.6344
Training Epoch: 7 [19456/50176]	Loss: 4.6263
Training Epoch: 7 [20480/50176]	Loss: 4.6336
Training Epoch: 7 [21504/50176]	Loss: 4.6240
Training Epoch: 7 [22528/50176]	Loss: 4.6311
Training Epoch: 7 [23552/50176]	Loss: 4.6315
Training Epoch: 7 [24576/50176]	Loss: 4.6223
Training Epoch: 7 [25600/50176]	Loss: 4.6319
Training Epoch: 7 [26624/50176]	Loss: 4.6366
Training Epoch: 7 [27648/50176]	Loss: 4.6328
Training Epoch: 7 [28672/50176]	Loss: 4.6223
Training Epoch: 7 [29696/50176]	Loss: 4.6172
Training Epoch: 7 [30720/50176]	Loss: 4.6337
Training Epoch: 7 [31744/50176]	Loss: 4.6313
Training Epoch: 7 [32768/50176]	Loss: 4.6282
Training Epoch: 7 [33792/50176]	Loss: 4.6371
Training Epoch: 7 [34816/50176]	Loss: 4.6334
Training Epoch: 7 [35840/50176]	Loss: 4.6285
Training Epoch: 7 [36864/50176]	Loss: 4.6443
Training Epoch: 7 [37888/50176]	Loss: 4.6246
Training Epoch: 7 [38912/50176]	Loss: 4.6290
Training Epoch: 7 [39936/50176]	Loss: 4.6289
Training Epoch: 7 [40960/50176]	Loss: 4.6221
Training Epoch: 7 [41984/50176]	Loss: 4.6442
Training Epoch: 7 [43008/50176]	Loss: 4.6305
Training Epoch: 7 [44032/50176]	Loss: 4.6309
Training Epoch: 7 [45056/50176]	Loss: 4.6222
Training Epoch: 7 [46080/50176]	Loss: 4.6262
Training Epoch: 7 [47104/50176]	Loss: 4.6289
Training Epoch: 7 [48128/50176]	Loss: 4.6378
Training Epoch: 7 [49152/50176]	Loss: 4.6282
Training Epoch: 7 [50176/50176]	Loss: 4.6578
2022-12-06 19:38:34.732 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:38:34,772 [ZeusDataLoader(eval)] eval epoch 8 done: time=3.79 energy=463.35
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Up to epoch 8: time=395.61, energy=50094.71, cost=59663.53
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:38:34,773 [ZeusDataLoader(train)] Expected next epoch: time=442.22, energy=56461.00, cost=66924.76
2022-12-06 14:38:34,774 [ZeusDataLoader(train)] Epoch 9 begin.
Validation Epoch: 7, Average loss: 1.7477, Accuracy: 0.0098
2022-12-06 14:38:35,033 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:38:35,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:38:35.036 [ZeusMonitor] Monitor started.
2022-12-06 19:38:35.036 [ZeusMonitor] Running indefinitely. 2022-12-06 19:38:35.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:38:35.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e9+gpu0.power.log
2022-12-06 14:39:18,454 [ZeusDataLoader(train)] train epoch 9 done: time=43.67 energy=5817.13
2022-12-06 14:39:18,457 [ZeusDataLoader(eval)] Epoch 9 begin.
Training Epoch: 8 [1024/50176]	Loss: 4.6326
Training Epoch: 8 [2048/50176]	Loss: 4.6422
Training Epoch: 8 [3072/50176]	Loss: 4.6167
Training Epoch: 8 [4096/50176]	Loss: 4.6450
Training Epoch: 8 [5120/50176]	Loss: 4.6375
Training Epoch: 8 [6144/50176]	Loss: 4.6378
Training Epoch: 8 [7168/50176]	Loss: 4.6368
Training Epoch: 8 [8192/50176]	Loss: 4.6400
Training Epoch: 8 [9216/50176]	Loss: 4.6440
Training Epoch: 8 [10240/50176]	Loss: 4.6299
Training Epoch: 8 [11264/50176]	Loss: 4.6391
Training Epoch: 8 [12288/50176]	Loss: 4.6192
Training Epoch: 8 [13312/50176]	Loss: 4.6290
Training Epoch: 8 [14336/50176]	Loss: 4.6408
Training Epoch: 8 [15360/50176]	Loss: 4.6411
Training Epoch: 8 [16384/50176]	Loss: 4.6403
Training Epoch: 8 [17408/50176]	Loss: 4.6453
Training Epoch: 8 [18432/50176]	Loss: 4.6454
Training Epoch: 8 [19456/50176]	Loss: 4.6348
Training Epoch: 8 [20480/50176]	Loss: 4.6297
Training Epoch: 8 [21504/50176]	Loss: 4.6327
Training Epoch: 8 [22528/50176]	Loss: 4.6382
Training Epoch: 8 [23552/50176]	Loss: 4.6257
Training Epoch: 8 [24576/50176]	Loss: 4.6298
Training Epoch: 8 [25600/50176]	Loss: 4.6391
Training Epoch: 8 [26624/50176]	Loss: 4.6544
Training Epoch: 8 [27648/50176]	Loss: 4.6345
Training Epoch: 8 [28672/50176]	Loss: 4.6301
Training Epoch: 8 [29696/50176]	Loss: 4.6247
Training Epoch: 8 [30720/50176]	Loss: 4.6452
Training Epoch: 8 [31744/50176]	Loss: 4.6477
Training Epoch: 8 [32768/50176]	Loss: 4.6370
Training Epoch: 8 [33792/50176]	Loss: 4.6231
Training Epoch: 8 [34816/50176]	Loss: 4.6480
Training Epoch: 8 [35840/50176]	Loss: 4.6438
Training Epoch: 8 [36864/50176]	Loss: 4.6366
Training Epoch: 8 [37888/50176]	Loss: 4.6393
Training Epoch: 8 [38912/50176]	Loss: 4.6230
Training Epoch: 8 [39936/50176]	Loss: 4.6328
Training Epoch: 8 [40960/50176]	Loss: 4.6342
Training Epoch: 8 [41984/50176]	Loss: 4.6403
Training Epoch: 8 [43008/50176]	Loss: 4.6259
Training Epoch: 8 [44032/50176]	Loss: 4.6409
Training Epoch: 8 [45056/50176]	Loss: 4.6333
Training Epoch: 8 [46080/50176]	Loss: 4.6378
Training Epoch: 8 [47104/50176]	Loss: 4.6212
Training Epoch: 8 [48128/50176]	Loss: 4.6343
Training Epoch: 8 [49152/50176]	Loss: 4.6229
Training Epoch: 8 [50176/50176]	Loss: 4.6495
2022-12-06 19:39:22.222 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:39:22,265 [ZeusDataLoader(eval)] eval epoch 9 done: time=3.80 energy=479.63
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Up to epoch 9: time=443.09, energy=56391.47, cost=66965.70
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:39:22,265 [ZeusDataLoader(train)] Expected next epoch: time=489.69, energy=62757.77, cost=74226.93
2022-12-06 14:39:22,266 [ZeusDataLoader(train)] Epoch 10 begin.
Validation Epoch: 8, Average loss: 0.2182, Accuracy: 0.0099
2022-12-06 14:39:22,480 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:39:22,481 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:39:22.484 [ZeusMonitor] Monitor started.
2022-12-06 19:39:22.484 [ZeusMonitor] Running indefinitely. 2022-12-06 19:39:22.484 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:39:22.484 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e10+gpu0.power.log
2022-12-06 14:40:05,890 [ZeusDataLoader(train)] train epoch 10 done: time=43.62 energy=5831.72
2022-12-06 14:40:05,893 [ZeusDataLoader(eval)] Epoch 10 begin.
Training Epoch: 9 [1024/50176]	Loss: 4.6233
Training Epoch: 9 [2048/50176]	Loss: 4.6330
Training Epoch: 9 [3072/50176]	Loss: 4.6495
Training Epoch: 9 [4096/50176]	Loss: 4.6369
Training Epoch: 9 [5120/50176]	Loss: 4.6288
Training Epoch: 9 [6144/50176]	Loss: 4.6314
Training Epoch: 9 [7168/50176]	Loss: 4.6331
Training Epoch: 9 [8192/50176]	Loss: 4.6333
Training Epoch: 9 [9216/50176]	Loss: 4.6439
Training Epoch: 9 [10240/50176]	Loss: 4.6390
Training Epoch: 9 [11264/50176]	Loss: 4.6364
Training Epoch: 9 [12288/50176]	Loss: 4.6248
Training Epoch: 9 [13312/50176]	Loss: 4.6320
Training Epoch: 9 [14336/50176]	Loss: 4.6639
Training Epoch: 9 [15360/50176]	Loss: 4.6399
Training Epoch: 9 [16384/50176]	Loss: 4.6300
Training Epoch: 9 [17408/50176]	Loss: 4.6363
Training Epoch: 9 [18432/50176]	Loss: 4.6272
Training Epoch: 9 [19456/50176]	Loss: 4.6324
Training Epoch: 9 [20480/50176]	Loss: 4.6344
Training Epoch: 9 [21504/50176]	Loss: 4.6222
Training Epoch: 9 [22528/50176]	Loss: 4.6326
Training Epoch: 9 [23552/50176]	Loss: 4.6442
Training Epoch: 9 [24576/50176]	Loss: 4.6387
Training Epoch: 9 [25600/50176]	Loss: 4.6574
Training Epoch: 9 [26624/50176]	Loss: 4.6405
Training Epoch: 9 [27648/50176]	Loss: 4.6311
Training Epoch: 9 [28672/50176]	Loss: 4.6371
Training Epoch: 9 [29696/50176]	Loss: 4.6310
Training Epoch: 9 [30720/50176]	Loss: 4.6439
Training Epoch: 9 [31744/50176]	Loss: 4.6417
Training Epoch: 9 [32768/50176]	Loss: 4.6339
Training Epoch: 9 [33792/50176]	Loss: 4.6453
Training Epoch: 9 [34816/50176]	Loss: 4.6392
Training Epoch: 9 [35840/50176]	Loss: 4.6349
Training Epoch: 9 [36864/50176]	Loss: 4.6453
Training Epoch: 9 [37888/50176]	Loss: 4.6399
Training Epoch: 9 [38912/50176]	Loss: 4.6339
Training Epoch: 9 [39936/50176]	Loss: 4.6250
Training Epoch: 9 [40960/50176]	Loss: 4.6437
Training Epoch: 9 [41984/50176]	Loss: 4.6445
Training Epoch: 9 [43008/50176]	Loss: 4.6462
Training Epoch: 9 [44032/50176]	Loss: 4.6478
Training Epoch: 9 [45056/50176]	Loss: 4.6459
Training Epoch: 9 [46080/50176]	Loss: 4.6421
Training Epoch: 9 [47104/50176]	Loss: 4.6369
Training Epoch: 9 [48128/50176]	Loss: 4.6498
Training Epoch: 9 [49152/50176]	Loss: 4.6258
Training Epoch: 9 [50176/50176]	Loss: 4.6368
2022-12-06 19:40:09.681 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:40:09,704 [ZeusDataLoader(eval)] eval epoch 10 done: time=3.80 energy=483.26
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Up to epoch 10: time=490.50, energy=62706.44, cost=74272.21
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:40:09,704 [ZeusDataLoader(train)] Expected next epoch: time=537.11, energy=69072.74, cost=81533.45
2022-12-06 14:40:09,705 [ZeusDataLoader(train)] Epoch 11 begin.
Validation Epoch: 9, Average loss: 7544442700641075.0000, Accuracy: 0.0095
2022-12-06 14:40:10,001 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:40:10,002 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:40:10.013 [ZeusMonitor] Monitor started.
2022-12-06 19:40:10.014 [ZeusMonitor] Running indefinitely. 2022-12-06 19:40:10.014 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:40:10.014 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e11+gpu0.power.log
2022-12-06 14:40:53,602 [ZeusDataLoader(train)] train epoch 11 done: time=43.89 energy=5827.85
2022-12-06 14:40:53,606 [ZeusDataLoader(eval)] Epoch 11 begin.
Training Epoch: 10 [1024/50176]	Loss: 4.6460
Training Epoch: 10 [2048/50176]	Loss: 4.6240
Training Epoch: 10 [3072/50176]	Loss: 4.6331
Training Epoch: 10 [4096/50176]	Loss: 4.6280
Training Epoch: 10 [5120/50176]	Loss: 4.6534
Training Epoch: 10 [6144/50176]	Loss: 4.6488
Training Epoch: 10 [7168/50176]	Loss: 4.6277
Training Epoch: 10 [8192/50176]	Loss: 4.6496
Training Epoch: 10 [9216/50176]	Loss: 4.6331
Training Epoch: 10 [10240/50176]	Loss: 4.6356
Training Epoch: 10 [11264/50176]	Loss: 4.6390
Training Epoch: 10 [12288/50176]	Loss: 4.6465
Training Epoch: 10 [13312/50176]	Loss: 4.6449
Training Epoch: 10 [14336/50176]	Loss: 4.6476
Training Epoch: 10 [15360/50176]	Loss: 4.6251
Training Epoch: 10 [16384/50176]	Loss: 4.6314
Training Epoch: 10 [17408/50176]	Loss: 4.6234
Training Epoch: 10 [18432/50176]	Loss: 4.6322
Training Epoch: 10 [19456/50176]	Loss: 4.6274
Training Epoch: 10 [20480/50176]	Loss: 4.6349
Training Epoch: 10 [21504/50176]	Loss: 4.6409
Training Epoch: 10 [22528/50176]	Loss: 4.6459
Training Epoch: 10 [23552/50176]	Loss: 4.6176
Training Epoch: 10 [24576/50176]	Loss: 4.6380
Training Epoch: 10 [25600/50176]	Loss: 4.6491
Training Epoch: 10 [26624/50176]	Loss: 4.6311
Training Epoch: 10 [27648/50176]	Loss: 4.6457
Training Epoch: 10 [28672/50176]	Loss: 4.6382
Training Epoch: 10 [29696/50176]	Loss: 4.6570
Training Epoch: 10 [30720/50176]	Loss: 4.6346
Training Epoch: 10 [31744/50176]	Loss: 4.6339
Training Epoch: 10 [32768/50176]	Loss: 4.6300
Training Epoch: 10 [33792/50176]	Loss: 4.6439
Training Epoch: 10 [34816/50176]	Loss: 4.6510
Training Epoch: 10 [35840/50176]	Loss: 4.6420
Training Epoch: 10 [36864/50176]	Loss: 4.6441
Training Epoch: 10 [37888/50176]	Loss: 4.6286
Training Epoch: 10 [38912/50176]	Loss: 4.6341
Training Epoch: 10 [39936/50176]	Loss: 4.6115
Training Epoch: 10 [40960/50176]	Loss: 4.6331
Training Epoch: 10 [41984/50176]	Loss: 4.6377
Training Epoch: 10 [43008/50176]	Loss: 4.6472
Training Epoch: 10 [44032/50176]	Loss: 4.6286
Training Epoch: 10 [45056/50176]	Loss: 4.6198
Training Epoch: 10 [46080/50176]	Loss: 4.6396
Training Epoch: 10 [47104/50176]	Loss: 4.6382
Training Epoch: 10 [48128/50176]	Loss: 4.6313
Training Epoch: 10 [49152/50176]	Loss: 4.6386
Training Epoch: 10 [50176/50176]	Loss: 4.6315
2022-12-06 19:40:57.395 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:40:57,423 [ZeusDataLoader(eval)] eval epoch 11 done: time=3.81 energy=477.08
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Up to epoch 11: time=538.20, energy=69011.38, cost=81598.31
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:40:57,423 [ZeusDataLoader(train)] Expected next epoch: time=584.81, energy=75377.67, cost=88859.54
2022-12-06 14:40:57,424 [ZeusDataLoader(train)] Epoch 12 begin.
Validation Epoch: 10, Average loss: 6.1862, Accuracy: 0.0098
2022-12-06 14:40:57,661 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:40:57,662 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:40:57.663 [ZeusMonitor] Monitor started.
2022-12-06 19:40:57.664 [ZeusMonitor] Running indefinitely. 2022-12-06 19:40:57.664 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:40:57.664 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e12+gpu0.power.log
2022-12-06 14:41:41,051 [ZeusDataLoader(train)] train epoch 12 done: time=43.62 energy=5818.89
2022-12-06 14:41:41,054 [ZeusDataLoader(eval)] Epoch 12 begin.
Training Epoch: 11 [1024/50176]	Loss: 4.6443
Training Epoch: 11 [2048/50176]	Loss: 4.6477
Training Epoch: 11 [3072/50176]	Loss: 4.6215
Training Epoch: 11 [4096/50176]	Loss: 4.6537
Training Epoch: 11 [5120/50176]	Loss: 4.6385
Training Epoch: 11 [6144/50176]	Loss: 4.6232
Training Epoch: 11 [7168/50176]	Loss: 4.6417
Training Epoch: 11 [8192/50176]	Loss: 4.6455
Training Epoch: 11 [9216/50176]	Loss: 4.6495
Training Epoch: 11 [10240/50176]	Loss: 4.6382
Training Epoch: 11 [11264/50176]	Loss: 4.6277
Training Epoch: 11 [12288/50176]	Loss: 4.6335
Training Epoch: 11 [13312/50176]	Loss: 4.6381
Training Epoch: 11 [14336/50176]	Loss: 4.6370
Training Epoch: 11 [15360/50176]	Loss: 4.6289
Training Epoch: 11 [16384/50176]	Loss: 4.6259
Training Epoch: 11 [17408/50176]	Loss: 4.6211
Training Epoch: 11 [18432/50176]	Loss: 4.6447
Training Epoch: 11 [19456/50176]	Loss: 4.6393
Training Epoch: 11 [20480/50176]	Loss: 4.6291
Training Epoch: 11 [21504/50176]	Loss: 4.6405
Training Epoch: 11 [22528/50176]	Loss: 4.6237
Training Epoch: 11 [23552/50176]	Loss: 4.6359
Training Epoch: 11 [24576/50176]	Loss: 4.6435
Training Epoch: 11 [25600/50176]	Loss: 4.6255
Training Epoch: 11 [26624/50176]	Loss: 4.6361
Training Epoch: 11 [27648/50176]	Loss: 4.6346
Training Epoch: 11 [28672/50176]	Loss: 4.6305
Training Epoch: 11 [29696/50176]	Loss: 4.6205
Training Epoch: 11 [30720/50176]	Loss: 4.6380
Training Epoch: 11 [31744/50176]	Loss: 4.6419
Training Epoch: 11 [32768/50176]	Loss: 4.6486
Training Epoch: 11 [33792/50176]	Loss: 4.6379
Training Epoch: 11 [34816/50176]	Loss: 4.6364
Training Epoch: 11 [35840/50176]	Loss: 4.6346
Training Epoch: 11 [36864/50176]	Loss: 4.6452
Training Epoch: 11 [37888/50176]	Loss: 4.6607
Training Epoch: 11 [38912/50176]	Loss: 4.6340
Training Epoch: 11 [39936/50176]	Loss: 4.6415
Training Epoch: 11 [40960/50176]	Loss: 4.6547
Training Epoch: 11 [41984/50176]	Loss: 4.6534
Training Epoch: 11 [43008/50176]	Loss: 4.6399
Training Epoch: 11 [44032/50176]	Loss: 4.6648
Training Epoch: 11 [45056/50176]	Loss: 4.6404
Training Epoch: 11 [46080/50176]	Loss: 4.6306
Training Epoch: 11 [47104/50176]	Loss: 4.6419
Training Epoch: 11 [48128/50176]	Loss: 4.6478
Training Epoch: 11 [49152/50176]	Loss: 4.6528
Training Epoch: 11 [50176/50176]	Loss: 4.6364
2022-12-06 19:41:44.818 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:41:44,870 [ZeusDataLoader(eval)] eval epoch 12 done: time=3.81 energy=476.94
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Up to epoch 12: time=585.63, energy=75307.21, cost=88896.08
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:41:44,871 [ZeusDataLoader(train)] Expected next epoch: time=632.23, energy=81673.50, cost=96157.31
2022-12-06 14:41:44,872 [ZeusDataLoader(train)] Epoch 13 begin.
Validation Epoch: 11, Average loss: 1.1281, Accuracy: 0.0098
2022-12-06 14:41:45,121 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:41:45,122 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:41:45.123 [ZeusMonitor] Monitor started.
2022-12-06 19:41:45.124 [ZeusMonitor] Running indefinitely. 2022-12-06 19:41:45.124 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:41:45.124 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e13+gpu0.power.log
2022-12-06 14:42:28,658 [ZeusDataLoader(train)] train epoch 13 done: time=43.78 energy=5819.24
2022-12-06 14:42:28,661 [ZeusDataLoader(eval)] Epoch 13 begin.
Training Epoch: 12 [1024/50176]	Loss: 4.6331
Training Epoch: 12 [2048/50176]	Loss: 4.6369
Training Epoch: 12 [3072/50176]	Loss: 4.6544
Training Epoch: 12 [4096/50176]	Loss: 4.6383
Training Epoch: 12 [5120/50176]	Loss: 4.6315
Training Epoch: 12 [6144/50176]	Loss: 4.6406
Training Epoch: 12 [7168/50176]	Loss: 4.6337
Training Epoch: 12 [8192/50176]	Loss: 4.6380
Training Epoch: 12 [9216/50176]	Loss: 4.6248
Training Epoch: 12 [10240/50176]	Loss: 4.6413
Training Epoch: 12 [11264/50176]	Loss: 4.6264
Training Epoch: 12 [12288/50176]	Loss: 4.6327
Training Epoch: 12 [13312/50176]	Loss: 4.6286
Training Epoch: 12 [14336/50176]	Loss: 4.6284
Training Epoch: 12 [15360/50176]	Loss: 4.6242
Training Epoch: 12 [16384/50176]	Loss: 4.6318
Training Epoch: 12 [17408/50176]	Loss: 4.6387
Training Epoch: 12 [18432/50176]	Loss: 4.6393
Training Epoch: 12 [19456/50176]	Loss: 4.6293
Training Epoch: 12 [20480/50176]	Loss: 4.6297
Training Epoch: 12 [21504/50176]	Loss: 4.6347
Training Epoch: 12 [22528/50176]	Loss: 4.6297
Training Epoch: 12 [23552/50176]	Loss: 4.6294
Training Epoch: 12 [24576/50176]	Loss: 4.6353
Training Epoch: 12 [25600/50176]	Loss: 4.6162
Training Epoch: 12 [26624/50176]	Loss: 4.6300
Training Epoch: 12 [27648/50176]	Loss: 4.6360
Training Epoch: 12 [28672/50176]	Loss: 4.6406
Training Epoch: 12 [29696/50176]	Loss: 4.6452
Training Epoch: 12 [30720/50176]	Loss: 4.6242
Training Epoch: 12 [31744/50176]	Loss: 4.6380
Training Epoch: 12 [32768/50176]	Loss: 4.6297
Training Epoch: 12 [33792/50176]	Loss: 4.6362
Training Epoch: 12 [34816/50176]	Loss: 4.6440
Training Epoch: 12 [35840/50176]	Loss: 4.6324
Training Epoch: 12 [36864/50176]	Loss: 4.6327
Training Epoch: 12 [37888/50176]	Loss: 4.6318
Training Epoch: 12 [38912/50176]	Loss: 4.6208
Training Epoch: 12 [39936/50176]	Loss: 4.6237
Training Epoch: 12 [40960/50176]	Loss: 4.6507
Training Epoch: 12 [41984/50176]	Loss: 4.6451
Training Epoch: 12 [43008/50176]	Loss: 4.6501
Training Epoch: 12 [44032/50176]	Loss: 4.6565
Training Epoch: 12 [45056/50176]	Loss: 4.6469
Training Epoch: 12 [46080/50176]	Loss: 4.6333
Training Epoch: 12 [47104/50176]	Loss: 4.6275
Training Epoch: 12 [48128/50176]	Loss: 4.6445
Training Epoch: 12 [49152/50176]	Loss: 4.6376
Training Epoch: 12 [50176/50176]	Loss: 4.6289
2022-12-06 19:42:32.447 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:42:32,480 [ZeusDataLoader(eval)] eval epoch 13 done: time=3.81 energy=476.56
2022-12-06 14:42:32,480 [ZeusDataLoader(train)] Up to epoch 13: time=633.22, energy=81603.01, cost=96208.02
2022-12-06 14:42:32,481 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:42:32,481 [ZeusDataLoader(train)] Expected next epoch: time=679.82, energy=87969.31, cost=103469.25
2022-12-06 14:42:32,482 [ZeusDataLoader(train)] Epoch 14 begin.
Validation Epoch: 12, Average loss: 0.0421, Accuracy: 0.0098
2022-12-06 14:42:32,730 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:42:32,731 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:42:32.733 [ZeusMonitor] Monitor started.
2022-12-06 19:42:32.733 [ZeusMonitor] Running indefinitely. 2022-12-06 19:42:32.733 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:42:32.733 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e14+gpu0.power.log
2022-12-06 14:43:16,468 [ZeusDataLoader(train)] train epoch 14 done: time=43.98 energy=5869.77
2022-12-06 14:43:16,472 [ZeusDataLoader(eval)] Epoch 14 begin.
Training Epoch: 13 [1024/50176]	Loss: 4.6281
Training Epoch: 13 [2048/50176]	Loss: 4.6233
Training Epoch: 13 [3072/50176]	Loss: 4.6380
Training Epoch: 13 [4096/50176]	Loss: 4.6396
Training Epoch: 13 [5120/50176]	Loss: 4.6322
Training Epoch: 13 [6144/50176]	Loss: 4.6335
Training Epoch: 13 [7168/50176]	Loss: 4.6470
Training Epoch: 13 [8192/50176]	Loss: 4.6238
Training Epoch: 13 [9216/50176]	Loss: 4.6529
Training Epoch: 13 [10240/50176]	Loss: 4.6477
Training Epoch: 13 [11264/50176]	Loss: 4.6322
Training Epoch: 13 [12288/50176]	Loss: 4.6465
Training Epoch: 13 [13312/50176]	Loss: 4.6525
Training Epoch: 13 [14336/50176]	Loss: 4.6286
Training Epoch: 13 [15360/50176]	Loss: 4.6340
Training Epoch: 13 [16384/50176]	Loss: 4.6187
Training Epoch: 13 [17408/50176]	Loss: 4.6309
Training Epoch: 13 [18432/50176]	Loss: 4.6371
Training Epoch: 13 [19456/50176]	Loss: 4.6407
Training Epoch: 13 [20480/50176]	Loss: 4.6433
Training Epoch: 13 [21504/50176]	Loss: 4.6244
Training Epoch: 13 [22528/50176]	Loss: 4.6233
Training Epoch: 13 [23552/50176]	Loss: 4.6324
Training Epoch: 13 [24576/50176]	Loss: 4.6296
Training Epoch: 13 [25600/50176]	Loss: 4.6333
Training Epoch: 13 [26624/50176]	Loss: 4.6398
Training Epoch: 13 [27648/50176]	Loss: 4.6240
Training Epoch: 13 [28672/50176]	Loss: 4.6306
Training Epoch: 13 [29696/50176]	Loss: 4.6320
Training Epoch: 13 [30720/50176]	Loss: 4.6379
Training Epoch: 13 [31744/50176]	Loss: 4.6457
Training Epoch: 13 [32768/50176]	Loss: 4.6403
Training Epoch: 13 [33792/50176]	Loss: 4.6451
Training Epoch: 13 [34816/50176]	Loss: 4.6316
Training Epoch: 13 [35840/50176]	Loss: 4.6152
Training Epoch: 13 [36864/50176]	Loss: 4.6370
Training Epoch: 13 [37888/50176]	Loss: 4.6298
Training Epoch: 13 [38912/50176]	Loss: 4.6334
Training Epoch: 13 [39936/50176]	Loss: 4.6311
Training Epoch: 13 [40960/50176]	Loss: 4.6474
Training Epoch: 13 [41984/50176]	Loss: 4.6352
Training Epoch: 13 [43008/50176]	Loss: 4.6370
Training Epoch: 13 [44032/50176]	Loss: 4.6402
Training Epoch: 13 [45056/50176]	Loss: 4.6344
Training Epoch: 13 [46080/50176]	Loss: 4.6337
Training Epoch: 13 [47104/50176]	Loss: 4.6558
Training Epoch: 13 [48128/50176]	Loss: 4.6373
Training Epoch: 13 [49152/50176]	Loss: 4.6448
Training Epoch: 13 [50176/50176]	Loss: 4.6451
2022-12-06 19:43:20.231 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:43:20,270 [ZeusDataLoader(eval)] eval epoch 14 done: time=3.79 energy=485.93
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Up to epoch 14: time=680.99, energy=87958.71, cost=103565.64
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:43:20,270 [ZeusDataLoader(train)] Expected next epoch: time=727.59, energy=94325.01, cost=110826.88
2022-12-06 14:43:20,271 [ZeusDataLoader(train)] Epoch 15 begin.
Validation Epoch: 13, Average loss: 493841416401715.1875, Accuracy: 0.0091
2022-12-06 14:43:20,522 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:43:20,523 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:43:20.525 [ZeusMonitor] Monitor started.
2022-12-06 19:43:20.525 [ZeusMonitor] Running indefinitely. 2022-12-06 19:43:20.525 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:43:20.525 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e15+gpu0.power.log
2022-12-06 14:44:04,056 [ZeusDataLoader(train)] train epoch 15 done: time=43.78 energy=5876.40
2022-12-06 14:44:04,060 [ZeusDataLoader(eval)] Epoch 15 begin.
Training Epoch: 14 [1024/50176]	Loss: 4.6334
Training Epoch: 14 [2048/50176]	Loss: 4.6414
Training Epoch: 14 [3072/50176]	Loss: 4.6352
Training Epoch: 14 [4096/50176]	Loss: 4.6331
Training Epoch: 14 [5120/50176]	Loss: 4.6501
Training Epoch: 14 [6144/50176]	Loss: 4.6317
Training Epoch: 14 [7168/50176]	Loss: 4.6338
Training Epoch: 14 [8192/50176]	Loss: 4.6211
Training Epoch: 14 [9216/50176]	Loss: 4.6321
Training Epoch: 14 [10240/50176]	Loss: 4.6389
Training Epoch: 14 [11264/50176]	Loss: 4.6303
Training Epoch: 14 [12288/50176]	Loss: 4.6385
Training Epoch: 14 [13312/50176]	Loss: 4.6444
Training Epoch: 14 [14336/50176]	Loss: 4.6392
Training Epoch: 14 [15360/50176]	Loss: 4.6379
Training Epoch: 14 [16384/50176]	Loss: 4.6317
Training Epoch: 14 [17408/50176]	Loss: 4.6332
Training Epoch: 14 [18432/50176]	Loss: 4.6247
Training Epoch: 14 [19456/50176]	Loss: 4.6225
Training Epoch: 14 [20480/50176]	Loss: 4.6404
Training Epoch: 14 [21504/50176]	Loss: 4.6371
Training Epoch: 14 [22528/50176]	Loss: 4.6394
Training Epoch: 14 [23552/50176]	Loss: 4.6533
Training Epoch: 14 [24576/50176]	Loss: 4.6429
Training Epoch: 14 [25600/50176]	Loss: 4.6531
Training Epoch: 14 [26624/50176]	Loss: 4.6328
Training Epoch: 14 [27648/50176]	Loss: 4.6312
Training Epoch: 14 [28672/50176]	Loss: 4.6318
Training Epoch: 14 [29696/50176]	Loss: 4.6388
Training Epoch: 14 [30720/50176]	Loss: 4.6452
Training Epoch: 14 [31744/50176]	Loss: 4.6488
Training Epoch: 14 [32768/50176]	Loss: 4.6409
Training Epoch: 14 [33792/50176]	Loss: 4.6484
Training Epoch: 14 [34816/50176]	Loss: 4.6297
Training Epoch: 14 [35840/50176]	Loss: 4.6380
Training Epoch: 14 [36864/50176]	Loss: 4.6390
Training Epoch: 14 [37888/50176]	Loss: 4.6307
Training Epoch: 14 [38912/50176]	Loss: 4.6367
Training Epoch: 14 [39936/50176]	Loss: 4.6254
Training Epoch: 14 [40960/50176]	Loss: 4.6267
Training Epoch: 14 [41984/50176]	Loss: 4.6452
Training Epoch: 14 [43008/50176]	Loss: 4.6332
Training Epoch: 14 [44032/50176]	Loss: 4.6265
Training Epoch: 14 [45056/50176]	Loss: 4.6291
Training Epoch: 14 [46080/50176]	Loss: 4.6375
Training Epoch: 14 [47104/50176]	Loss: 4.6325
Training Epoch: 14 [48128/50176]	Loss: 4.6410
Training Epoch: 14 [49152/50176]	Loss: 4.6412
Training Epoch: 14 [50176/50176]	Loss: 4.6270
2022-12-06 19:44:07.757 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:44:07,772 [ZeusDataLoader(eval)] eval epoch 15 done: time=3.70 energy=466.94
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Up to epoch 15: time=728.47, energy=94302.06, cost=110891.80
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:44:07,772 [ZeusDataLoader(train)] Expected next epoch: time=775.07, energy=100668.35, cost=118153.04
2022-12-06 14:44:07,773 [ZeusDataLoader(train)] Epoch 16 begin.
Validation Epoch: 14, Average loss: 165129022.2422, Accuracy: 0.0106
2022-12-06 14:44:08,019 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:44:08,020 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:44:08.022 [ZeusMonitor] Monitor started.
2022-12-06 19:44:08.022 [ZeusMonitor] Running indefinitely. 2022-12-06 19:44:08.022 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:44:08.022 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e16+gpu0.power.log
2022-12-06 14:44:51,619 [ZeusDataLoader(train)] train epoch 16 done: time=43.84 energy=5837.39
2022-12-06 14:44:51,622 [ZeusDataLoader(eval)] Epoch 16 begin.
Training Epoch: 15 [1024/50176]	Loss: 4.6472
Training Epoch: 15 [2048/50176]	Loss: 4.6323
Training Epoch: 15 [3072/50176]	Loss: 4.6343
Training Epoch: 15 [4096/50176]	Loss: 4.6373
Training Epoch: 15 [5120/50176]	Loss: 4.6437
Training Epoch: 15 [6144/50176]	Loss: 4.6332
Training Epoch: 15 [7168/50176]	Loss: 4.6333
Training Epoch: 15 [8192/50176]	Loss: 4.6388
Training Epoch: 15 [9216/50176]	Loss: 4.6213
Training Epoch: 15 [10240/50176]	Loss: 4.6397
Training Epoch: 15 [11264/50176]	Loss: 4.6428
Training Epoch: 15 [12288/50176]	Loss: 4.6346
Training Epoch: 15 [13312/50176]	Loss: 4.6281
Training Epoch: 15 [14336/50176]	Loss: 4.6328
Training Epoch: 15 [15360/50176]	Loss: 4.6374
Training Epoch: 15 [16384/50176]	Loss: 4.6513
Training Epoch: 15 [17408/50176]	Loss: 4.6360
Training Epoch: 15 [18432/50176]	Loss: 4.6393
Training Epoch: 15 [19456/50176]	Loss: 4.6404
Training Epoch: 15 [20480/50176]	Loss: 4.6408
Training Epoch: 15 [21504/50176]	Loss: 4.6227
Training Epoch: 15 [22528/50176]	Loss: 4.6304
Training Epoch: 15 [23552/50176]	Loss: 4.6306
Training Epoch: 15 [24576/50176]	Loss: 4.6330
Training Epoch: 15 [25600/50176]	Loss: 4.6387
Training Epoch: 15 [26624/50176]	Loss: 4.6254
Training Epoch: 15 [27648/50176]	Loss: 4.6358
Training Epoch: 15 [28672/50176]	Loss: 4.6285
Training Epoch: 15 [29696/50176]	Loss: 4.6354
Training Epoch: 15 [30720/50176]	Loss: 4.6300
Training Epoch: 15 [31744/50176]	Loss: 4.6291
Training Epoch: 15 [32768/50176]	Loss: 4.6388
Training Epoch: 15 [33792/50176]	Loss: 4.6587
Training Epoch: 15 [34816/50176]	Loss: 4.6457
Training Epoch: 15 [35840/50176]	Loss: 4.6547
Training Epoch: 15 [36864/50176]	Loss: 4.6289
Training Epoch: 15 [37888/50176]	Loss: 4.6383
Training Epoch: 15 [38912/50176]	Loss: 4.6216
Training Epoch: 15 [39936/50176]	Loss: 4.6222
Training Epoch: 15 [40960/50176]	Loss: 4.6330
Training Epoch: 15 [41984/50176]	Loss: 4.6310
Training Epoch: 15 [43008/50176]	Loss: 4.6515
Training Epoch: 15 [44032/50176]	Loss: 4.6396
Training Epoch: 15 [45056/50176]	Loss: 4.6324
Training Epoch: 15 [46080/50176]	Loss: 4.6246
Training Epoch: 15 [47104/50176]	Loss: 4.6357
Training Epoch: 15 [48128/50176]	Loss: 4.6291
Training Epoch: 15 [49152/50176]	Loss: 4.6285
Training Epoch: 15 [50176/50176]	Loss: 4.6316
2022-12-06 19:44:55.433 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:44:55,445 [ZeusDataLoader(eval)] eval epoch 16 done: time=3.81 energy=470.07
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Up to epoch 16: time=776.12, energy=100609.52, cost=118215.02
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:44:55,445 [ZeusDataLoader(train)] Expected next epoch: time=822.72, energy=106975.81, cost=125476.25
2022-12-06 14:44:55,446 [ZeusDataLoader(train)] Epoch 17 begin.
Validation Epoch: 15, Average loss: 0.0045, Accuracy: 0.0100
2022-12-06 14:44:55,649 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:44:55,650 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:44:55.653 [ZeusMonitor] Monitor started.
2022-12-06 19:44:55.654 [ZeusMonitor] Running indefinitely. 2022-12-06 19:44:55.654 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:44:55.654 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e17+gpu0.power.log
2022-12-06 14:45:39,205 [ZeusDataLoader(train)] train epoch 17 done: time=43.75 energy=5915.61
2022-12-06 14:45:39,209 [ZeusDataLoader(eval)] Epoch 17 begin.
Training Epoch: 16 [1024/50176]	Loss: 4.6444
Training Epoch: 16 [2048/50176]	Loss: 4.6440
Training Epoch: 16 [3072/50176]	Loss: 4.6343
Training Epoch: 16 [4096/50176]	Loss: 4.6378
Training Epoch: 16 [5120/50176]	Loss: 4.6464
Training Epoch: 16 [6144/50176]	Loss: 4.6375
Training Epoch: 16 [7168/50176]	Loss: 4.6304
Training Epoch: 16 [8192/50176]	Loss: 4.6295
Training Epoch: 16 [9216/50176]	Loss: 4.6369
Training Epoch: 16 [10240/50176]	Loss: 4.6426
Training Epoch: 16 [11264/50176]	Loss: 4.6547
Training Epoch: 16 [12288/50176]	Loss: 4.6458
Training Epoch: 16 [13312/50176]	Loss: 4.6390
Training Epoch: 16 [14336/50176]	Loss: 4.6386
Training Epoch: 16 [15360/50176]	Loss: 4.6442
Training Epoch: 16 [16384/50176]	Loss: 4.6438
Training Epoch: 16 [17408/50176]	Loss: 4.6294
Training Epoch: 16 [18432/50176]	Loss: 4.6299
Training Epoch: 16 [19456/50176]	Loss: 4.6294
Training Epoch: 16 [20480/50176]	Loss: 4.6266
Training Epoch: 16 [21504/50176]	Loss: 4.6446
Training Epoch: 16 [22528/50176]	Loss: 4.6251
Training Epoch: 16 [23552/50176]	Loss: 4.6316
Training Epoch: 16 [24576/50176]	Loss: 4.6328
Training Epoch: 16 [25600/50176]	Loss: 4.6226
Training Epoch: 16 [26624/50176]	Loss: 4.6409
Training Epoch: 16 [27648/50176]	Loss: 4.6372
Training Epoch: 16 [28672/50176]	Loss: 4.6434
Training Epoch: 16 [29696/50176]	Loss: 4.6282
Training Epoch: 16 [30720/50176]	Loss: 4.6291
Training Epoch: 16 [31744/50176]	Loss: 4.6471
Training Epoch: 16 [32768/50176]	Loss: 4.8911
Training Epoch: 16 [33792/50176]	Loss: 4.6268
Training Epoch: 16 [34816/50176]	Loss: 4.6416
Training Epoch: 16 [35840/50176]	Loss: 4.6812
Training Epoch: 16 [36864/50176]	Loss: 4.6288
Training Epoch: 16 [37888/50176]	Loss: 4.6359
Training Epoch: 16 [38912/50176]	Loss: 4.7113
Training Epoch: 16 [39936/50176]	Loss: 4.6393
Training Epoch: 16 [40960/50176]	Loss: 4.6443
Training Epoch: 16 [41984/50176]	Loss: 4.6955
Training Epoch: 16 [43008/50176]	Loss: 4.6309
Training Epoch: 16 [44032/50176]	Loss: 4.6220
Training Epoch: 16 [45056/50176]	Loss: 4.6171
Training Epoch: 16 [46080/50176]	Loss: 4.6417
Training Epoch: 16 [47104/50176]	Loss: 4.6511
Training Epoch: 16 [48128/50176]	Loss: 4.6359
Training Epoch: 16 [49152/50176]	Loss: 4.6555
Training Epoch: 16 [50176/50176]	Loss: 4.6498
2022-12-06 19:45:42.966 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:45:43,020 [ZeusDataLoader(eval)] eval epoch 17 done: time=3.80 energy=480.63
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Up to epoch 17: time=823.67, energy=107005.76, cost=125574.16
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:45:43,021 [ZeusDataLoader(train)] Expected next epoch: time=870.28, energy=113372.05, cost=132835.39
2022-12-06 14:45:43,022 [ZeusDataLoader(train)] Epoch 18 begin.
Validation Epoch: 16, Average loss: 37787832995020.7969, Accuracy: 0.0102
2022-12-06 14:45:43,271 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:45:43,271 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:45:43.273 [ZeusMonitor] Monitor started.
2022-12-06 19:45:43.273 [ZeusMonitor] Running indefinitely. 2022-12-06 19:45:43.273 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:45:43.273 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e18+gpu0.power.log
2022-12-06 14:46:27,035 [ZeusDataLoader(train)] train epoch 18 done: time=44.01 energy=5981.57
2022-12-06 14:46:27,039 [ZeusDataLoader(eval)] Epoch 18 begin.
Training Epoch: 17 [1024/50176]	Loss: 4.7553
Training Epoch: 17 [2048/50176]	Loss: 4.6324
Training Epoch: 17 [3072/50176]	Loss: 4.6286
Training Epoch: 17 [4096/50176]	Loss: 4.6579
Training Epoch: 17 [5120/50176]	Loss: 4.6308
Training Epoch: 17 [6144/50176]	Loss: 4.6253
Training Epoch: 17 [7168/50176]	Loss: 4.6717
Training Epoch: 17 [8192/50176]	Loss: 4.6279
Training Epoch: 17 [9216/50176]	Loss: 4.6900
Training Epoch: 17 [10240/50176]	Loss: 4.6274
Training Epoch: 17 [11264/50176]	Loss: 4.6384
Training Epoch: 17 [12288/50176]	Loss: 4.6359
Training Epoch: 17 [13312/50176]	Loss: 4.6352
Training Epoch: 17 [14336/50176]	Loss: 4.6385
Training Epoch: 17 [15360/50176]	Loss: 4.7151
Training Epoch: 17 [16384/50176]	Loss: 4.6355
Training Epoch: 17 [17408/50176]	Loss: 4.6340
Training Epoch: 17 [18432/50176]	Loss: 4.6721
Training Epoch: 17 [19456/50176]	Loss: 4.7020
Training Epoch: 17 [20480/50176]	Loss: 4.6473
Training Epoch: 17 [21504/50176]	Loss: 4.7838
Training Epoch: 17 [22528/50176]	Loss: 4.7014
Training Epoch: 17 [23552/50176]	Loss: 4.6956
Training Epoch: 17 [24576/50176]	Loss: 4.6379
Training Epoch: 17 [25600/50176]	Loss: 4.6347
Training Epoch: 17 [26624/50176]	Loss: 4.6394
Training Epoch: 17 [27648/50176]	Loss: 4.6483
Training Epoch: 17 [28672/50176]	Loss: 4.6549
Training Epoch: 17 [29696/50176]	Loss: 4.6408
Training Epoch: 17 [30720/50176]	Loss: 4.6305
Training Epoch: 17 [31744/50176]	Loss: 4.6317
Training Epoch: 17 [32768/50176]	Loss: 4.6477
Training Epoch: 17 [33792/50176]	Loss: 4.6355
Training Epoch: 17 [34816/50176]	Loss: 4.6274
Training Epoch: 17 [35840/50176]	Loss: 4.6286
Training Epoch: 17 [36864/50176]	Loss: 4.6291
Training Epoch: 17 [37888/50176]	Loss: 4.6355
Training Epoch: 17 [38912/50176]	Loss: 4.6520
Training Epoch: 17 [39936/50176]	Loss: 4.6353
Training Epoch: 17 [40960/50176]	Loss: 4.6288
Training Epoch: 17 [41984/50176]	Loss: 4.6411
Training Epoch: 17 [43008/50176]	Loss: 4.6459
Training Epoch: 17 [44032/50176]	Loss: 4.6273
Training Epoch: 17 [45056/50176]	Loss: 4.6202
Training Epoch: 17 [46080/50176]	Loss: 4.6410
Training Epoch: 17 [47104/50176]	Loss: 4.6417
Training Epoch: 17 [48128/50176]	Loss: 4.6537
Training Epoch: 17 [49152/50176]	Loss: 4.6355
Training Epoch: 17 [50176/50176]	Loss: 4.6352
2022-12-06 19:46:30.793 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:46:30,804 [ZeusDataLoader(eval)] eval epoch 18 done: time=3.76 energy=467.85
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Up to epoch 18: time=871.43, energy=113455.18, cost=132978.13
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:46:30,805 [ZeusDataLoader(train)] Expected next epoch: time=918.04, energy=119821.47, cost=140239.37
2022-12-06 14:46:30,806 [ZeusDataLoader(train)] Epoch 19 begin.
Validation Epoch: 17, Average loss: 316454054395904.0000, Accuracy: 0.0096
2022-12-06 14:46:31,053 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:46:31,054 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:46:31.056 [ZeusMonitor] Monitor started.
2022-12-06 19:46:31.056 [ZeusMonitor] Running indefinitely. 2022-12-06 19:46:31.056 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:46:31.056 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e19+gpu0.power.log
2022-12-06 14:47:14,687 [ZeusDataLoader(train)] train epoch 19 done: time=43.87 energy=5868.23
2022-12-06 14:47:14,690 [ZeusDataLoader(eval)] Epoch 19 begin.
Training Epoch: 18 [1024/50176]	Loss: 4.6149
Training Epoch: 18 [2048/50176]	Loss: 4.6300
Training Epoch: 18 [3072/50176]	Loss: 4.6421
Training Epoch: 18 [4096/50176]	Loss: 4.6549
Training Epoch: 18 [5120/50176]	Loss: 4.6402
Training Epoch: 18 [6144/50176]	Loss: 4.6384
Training Epoch: 18 [7168/50176]	Loss: 4.6301
Training Epoch: 18 [8192/50176]	Loss: 4.6244
Training Epoch: 18 [9216/50176]	Loss: 4.6434
Training Epoch: 18 [10240/50176]	Loss: 4.6408
Training Epoch: 18 [11264/50176]	Loss: 4.6409
Training Epoch: 18 [12288/50176]	Loss: 4.6309
Training Epoch: 18 [13312/50176]	Loss: 4.6340
Training Epoch: 18 [14336/50176]	Loss: 4.6498
Training Epoch: 18 [15360/50176]	Loss: 4.6435
Training Epoch: 18 [16384/50176]	Loss: 4.6308
Training Epoch: 18 [17408/50176]	Loss: 4.6229
Training Epoch: 18 [18432/50176]	Loss: 4.6354
Training Epoch: 18 [19456/50176]	Loss: 4.6167
Training Epoch: 18 [20480/50176]	Loss: 4.6422
Training Epoch: 18 [21504/50176]	Loss: 4.6329
Training Epoch: 18 [22528/50176]	Loss: 4.6321
Training Epoch: 18 [23552/50176]	Loss: 4.6319
Training Epoch: 18 [24576/50176]	Loss: 4.6408
Training Epoch: 18 [25600/50176]	Loss: 4.6317
Training Epoch: 18 [26624/50176]	Loss: 4.6306
Training Epoch: 18 [27648/50176]	Loss: 4.6264
Training Epoch: 18 [28672/50176]	Loss: 4.6412
Training Epoch: 18 [29696/50176]	Loss: 4.6472
Training Epoch: 18 [30720/50176]	Loss: 4.6378
Training Epoch: 18 [31744/50176]	Loss: 4.6381
Training Epoch: 18 [32768/50176]	Loss: 4.6302
Training Epoch: 18 [33792/50176]	Loss: 4.6361
Training Epoch: 18 [34816/50176]	Loss: 4.6298
Training Epoch: 18 [35840/50176]	Loss: 4.6251
Training Epoch: 18 [36864/50176]	Loss: 4.6334
Training Epoch: 18 [37888/50176]	Loss: 4.6382
Training Epoch: 18 [38912/50176]	Loss: 4.6293
Training Epoch: 18 [39936/50176]	Loss: 4.6325
Training Epoch: 18 [40960/50176]	Loss: 4.6501
Training Epoch: 18 [41984/50176]	Loss: 4.6420
Training Epoch: 18 [43008/50176]	Loss: 4.6291
Training Epoch: 18 [44032/50176]	Loss: 4.6373
Training Epoch: 18 [45056/50176]	Loss: 4.6215
Training Epoch: 18 [46080/50176]	Loss: 4.6292
Training Epoch: 18 [47104/50176]	Loss: 4.6429
Training Epoch: 18 [48128/50176]	Loss: 4.6427
Training Epoch: 18 [49152/50176]	Loss: 4.6378
Training Epoch: 18 [50176/50176]	Loss: 4.6339
2022-12-06 19:47:18.452 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:47:18,467 [ZeusDataLoader(eval)] eval epoch 19 done: time=3.77 energy=463.94
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Up to epoch 19: time=919.08, energy=119787.35, cost=140312.77
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:47:18,467 [ZeusDataLoader(train)] Expected next epoch: time=965.68, energy=126153.64, cost=147574.00
2022-12-06 14:47:18,468 [ZeusDataLoader(train)] Epoch 20 begin.
Validation Epoch: 18, Average loss: 202628612441.6000, Accuracy: 0.0090
2022-12-06 14:47:18,724 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:47:18,725 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:47:18.726 [ZeusMonitor] Monitor started.
2022-12-06 19:47:18.727 [ZeusMonitor] Running indefinitely. 2022-12-06 19:47:18.727 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:47:18.727 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e20+gpu0.power.log
2022-12-06 14:48:02,483 [ZeusDataLoader(train)] train epoch 20 done: time=44.01 energy=5847.68
2022-12-06 14:48:02,487 [ZeusDataLoader(eval)] Epoch 20 begin.
Training Epoch: 19 [1024/50176]	Loss: 4.6266
Training Epoch: 19 [2048/50176]	Loss: 4.6415
Training Epoch: 19 [3072/50176]	Loss: 4.6222
Training Epoch: 19 [4096/50176]	Loss: 4.6367
Training Epoch: 19 [5120/50176]	Loss: 4.6368
Training Epoch: 19 [6144/50176]	Loss: 4.6319
Training Epoch: 19 [7168/50176]	Loss: 4.6573
Training Epoch: 19 [8192/50176]	Loss: 4.6293
Training Epoch: 19 [9216/50176]	Loss: 4.6392
Training Epoch: 19 [10240/50176]	Loss: 4.6407
Training Epoch: 19 [11264/50176]	Loss: 4.6452
Training Epoch: 19 [12288/50176]	Loss: 4.6384
Training Epoch: 19 [13312/50176]	Loss: 4.6195
Training Epoch: 19 [14336/50176]	Loss: 4.6256
Training Epoch: 19 [15360/50176]	Loss: 4.6318
Training Epoch: 19 [16384/50176]	Loss: 4.6334
Training Epoch: 19 [17408/50176]	Loss: 4.6350
Training Epoch: 19 [18432/50176]	Loss: 4.6471
Training Epoch: 19 [19456/50176]	Loss: 4.6379
Training Epoch: 19 [20480/50176]	Loss: 4.6322
Training Epoch: 19 [21504/50176]	Loss: 4.6257
Training Epoch: 19 [22528/50176]	Loss: 4.6335
Training Epoch: 19 [23552/50176]	Loss: 4.6342
Training Epoch: 19 [24576/50176]	Loss: 4.6370
Training Epoch: 19 [25600/50176]	Loss: 4.6201
Training Epoch: 19 [26624/50176]	Loss: 4.6412
Training Epoch: 19 [27648/50176]	Loss: 4.6377
Training Epoch: 19 [28672/50176]	Loss: 4.6311
Training Epoch: 19 [29696/50176]	Loss: 4.6420
Training Epoch: 19 [30720/50176]	Loss: 4.6395
Training Epoch: 19 [31744/50176]	Loss: 4.6290
Training Epoch: 19 [32768/50176]	Loss: 4.6385
Training Epoch: 19 [33792/50176]	Loss: 4.6445
Training Epoch: 19 [34816/50176]	Loss: 4.6310
Training Epoch: 19 [35840/50176]	Loss: 4.6275
Training Epoch: 19 [36864/50176]	Loss: 4.6432
Training Epoch: 19 [37888/50176]	Loss: 4.6374
Training Epoch: 19 [38912/50176]	Loss: 4.6465
Training Epoch: 19 [39936/50176]	Loss: 4.6234
Training Epoch: 19 [40960/50176]	Loss: 4.6396
Training Epoch: 19 [41984/50176]	Loss: 4.6407
Training Epoch: 19 [43008/50176]	Loss: 4.6359
Training Epoch: 19 [44032/50176]	Loss: 4.6324
Training Epoch: 19 [45056/50176]	Loss: 4.6376
Training Epoch: 19 [46080/50176]	Loss: 4.6220
Training Epoch: 19 [47104/50176]	Loss: 4.6514
Training Epoch: 19 [48128/50176]	Loss: 4.6292
Training Epoch: 19 [49152/50176]	Loss: 4.6437
Training Epoch: 19 [50176/50176]	Loss: 4.6291
2022-12-06 19:48:06.232 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:48:06,261 [ZeusDataLoader(eval)] eval epoch 20 done: time=3.77 energy=463.24
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Up to epoch 20: time=966.85, energy=126098.27, cost=147648.45
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:48:06,262 [ZeusDataLoader(train)] Expected next epoch: time=1013.46, energy=132464.56, cost=154909.69
2022-12-06 14:48:06,263 [ZeusDataLoader(train)] Epoch 21 begin.
Validation Epoch: 19, Average loss: 11548.6541, Accuracy: 0.0098
2022-12-06 14:48:06,519 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:48:06,520 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:48:06.522 [ZeusMonitor] Monitor started.
2022-12-06 19:48:06.522 [ZeusMonitor] Running indefinitely. 2022-12-06 19:48:06.522 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:48:06.522 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e21+gpu0.power.log
2022-12-06 14:48:50,059 [ZeusDataLoader(train)] train epoch 21 done: time=43.79 energy=5819.91
2022-12-06 14:48:50,062 [ZeusDataLoader(eval)] Epoch 21 begin.
Training Epoch: 20 [1024/50176]	Loss: 4.6322
Training Epoch: 20 [2048/50176]	Loss: 4.6415
Training Epoch: 20 [3072/50176]	Loss: 4.6476
Training Epoch: 20 [4096/50176]	Loss: 4.6416
Training Epoch: 20 [5120/50176]	Loss: 4.6520
Training Epoch: 20 [6144/50176]	Loss: 4.6182
Training Epoch: 20 [7168/50176]	Loss: 4.6279
Training Epoch: 20 [8192/50176]	Loss: 4.6597
Training Epoch: 20 [9216/50176]	Loss: 4.6475
Training Epoch: 20 [10240/50176]	Loss: 4.6460
Training Epoch: 20 [11264/50176]	Loss: 4.6363
Training Epoch: 20 [12288/50176]	Loss: 4.6393
Training Epoch: 20 [13312/50176]	Loss: 4.6354
Training Epoch: 20 [14336/50176]	Loss: 4.6424
Training Epoch: 20 [15360/50176]	Loss: 4.6462
Training Epoch: 20 [16384/50176]	Loss: 4.6421
Training Epoch: 20 [17408/50176]	Loss: 4.6516
Training Epoch: 20 [18432/50176]	Loss: 4.6518
Training Epoch: 20 [19456/50176]	Loss: 4.6265
Training Epoch: 20 [20480/50176]	Loss: 4.6417
Training Epoch: 20 [21504/50176]	Loss: 4.6183
Training Epoch: 20 [22528/50176]	Loss: 4.6411
Training Epoch: 20 [23552/50176]	Loss: 4.6199
Training Epoch: 20 [24576/50176]	Loss: 4.6363
Training Epoch: 20 [25600/50176]	Loss: 4.6413
Training Epoch: 20 [26624/50176]	Loss: 4.6244
Training Epoch: 20 [27648/50176]	Loss: 4.6283
Training Epoch: 20 [28672/50176]	Loss: 4.6420
Training Epoch: 20 [29696/50176]	Loss: 4.6374
Training Epoch: 20 [30720/50176]	Loss: 4.6525
Training Epoch: 20 [31744/50176]	Loss: 4.6479
Training Epoch: 20 [32768/50176]	Loss: 4.6453
Training Epoch: 20 [33792/50176]	Loss: 4.6260
Training Epoch: 20 [34816/50176]	Loss: 4.6294
Training Epoch: 20 [35840/50176]	Loss: 4.6327
Training Epoch: 20 [36864/50176]	Loss: 4.6393
Training Epoch: 20 [37888/50176]	Loss: 4.6414
Training Epoch: 20 [38912/50176]	Loss: 4.6415
Training Epoch: 20 [39936/50176]	Loss: 4.6387
Training Epoch: 20 [40960/50176]	Loss: 4.6323
Training Epoch: 20 [41984/50176]	Loss: 4.6450
Training Epoch: 20 [43008/50176]	Loss: 4.6392
Training Epoch: 20 [44032/50176]	Loss: 4.6291
Training Epoch: 20 [45056/50176]	Loss: 4.6458
Training Epoch: 20 [46080/50176]	Loss: 4.6395
Training Epoch: 20 [47104/50176]	Loss: 4.6433
Training Epoch: 20 [48128/50176]	Loss: 4.6340
Training Epoch: 20 [49152/50176]	Loss: 4.6374
Training Epoch: 20 [50176/50176]	Loss: 4.6291
2022-12-06 19:48:53.855 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:48:53,882 [ZeusDataLoader(eval)] eval epoch 21 done: time=3.81 energy=476.91
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Up to epoch 21: time=1014.45, energy=132395.09, cost=154961.82
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:48:53,882 [ZeusDataLoader(train)] Expected next epoch: time=1061.06, energy=138761.38, cost=162223.05
2022-12-06 14:48:53,883 [ZeusDataLoader(train)] Epoch 22 begin.
Validation Epoch: 20, Average loss: 7359.5478, Accuracy: 0.0098
2022-12-06 14:48:54,131 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:48:54,132 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:48:54.134 [ZeusMonitor] Monitor started.
2022-12-06 19:48:54.134 [ZeusMonitor] Running indefinitely. 2022-12-06 19:48:54.134 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:48:54.134 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e22+gpu0.power.log
2022-12-06 14:49:37,538 [ZeusDataLoader(train)] train epoch 22 done: time=43.65 energy=5821.03
2022-12-06 14:49:37,541 [ZeusDataLoader(eval)] Epoch 22 begin.
Training Epoch: 21 [1024/50176]	Loss: 4.6512
Training Epoch: 21 [2048/50176]	Loss: 4.6429
Training Epoch: 21 [3072/50176]	Loss: 4.6292
Training Epoch: 21 [4096/50176]	Loss: 4.6510
Training Epoch: 21 [5120/50176]	Loss: 4.6296
Training Epoch: 21 [6144/50176]	Loss: 4.6475
Training Epoch: 21 [7168/50176]	Loss: 4.6344
Training Epoch: 21 [8192/50176]	Loss: 4.6396
Training Epoch: 21 [9216/50176]	Loss: 4.6457
Training Epoch: 21 [10240/50176]	Loss: 4.6347
Training Epoch: 21 [11264/50176]	Loss: 4.6309
Training Epoch: 21 [12288/50176]	Loss: 4.6414
Training Epoch: 21 [13312/50176]	Loss: 4.6483
Training Epoch: 21 [14336/50176]	Loss: 4.6312
Training Epoch: 21 [15360/50176]	Loss: 4.6260
Training Epoch: 21 [16384/50176]	Loss: 4.6462
Training Epoch: 21 [17408/50176]	Loss: 4.6493
Training Epoch: 21 [18432/50176]	Loss: 4.6502
Training Epoch: 21 [19456/50176]	Loss: 4.6426
Training Epoch: 21 [20480/50176]	Loss: 4.6291
Training Epoch: 21 [21504/50176]	Loss: 4.6294
Training Epoch: 21 [22528/50176]	Loss: 4.6473
Training Epoch: 21 [23552/50176]	Loss: 4.6333
Training Epoch: 21 [24576/50176]	Loss: 4.6328
Training Epoch: 21 [25600/50176]	Loss: 4.6476
Training Epoch: 21 [26624/50176]	Loss: 4.6366
Training Epoch: 21 [27648/50176]	Loss: 4.6362
Training Epoch: 21 [28672/50176]	Loss: 4.6372
Training Epoch: 21 [29696/50176]	Loss: 4.6401
Training Epoch: 21 [30720/50176]	Loss: 4.6346
Training Epoch: 21 [31744/50176]	Loss: 4.6355
Training Epoch: 21 [32768/50176]	Loss: 4.6281
Training Epoch: 21 [33792/50176]	Loss: 4.6325
Training Epoch: 21 [34816/50176]	Loss: 4.6318
Training Epoch: 21 [35840/50176]	Loss: 4.6388
Training Epoch: 21 [36864/50176]	Loss: 4.6291
Training Epoch: 21 [37888/50176]	Loss: 4.6225
Training Epoch: 21 [38912/50176]	Loss: 4.6312
Training Epoch: 21 [39936/50176]	Loss: 4.6361
Training Epoch: 21 [40960/50176]	Loss: 4.6315
Training Epoch: 21 [41984/50176]	Loss: 4.6461
Training Epoch: 21 [43008/50176]	Loss: 4.6362
Training Epoch: 21 [44032/50176]	Loss: 4.6326
Training Epoch: 21 [45056/50176]	Loss: 4.6384
Training Epoch: 21 [46080/50176]	Loss: 4.6373
Training Epoch: 21 [47104/50176]	Loss: 4.6314
Training Epoch: 21 [48128/50176]	Loss: 4.6362
Training Epoch: 21 [49152/50176]	Loss: 4.6292
Training Epoch: 21 [50176/50176]	Loss: 4.6429
2022-12-06 19:49:41.302 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:49:41,360 [ZeusDataLoader(eval)] eval epoch 22 done: time=3.81 energy=478.00
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Up to epoch 22: time=1061.91, energy=138694.12, cost=162263.78
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:49:41,360 [ZeusDataLoader(train)] Expected next epoch: time=1108.51, energy=145060.41, cost=169525.01
2022-12-06 14:49:41,361 [ZeusDataLoader(train)] Epoch 23 begin.
Validation Epoch: 21, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:49:41,603 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:49:41,603 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:49:41.617 [ZeusMonitor] Monitor started.
2022-12-06 19:49:41.617 [ZeusMonitor] Running indefinitely. 2022-12-06 19:49:41.617 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:49:41.617 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e23+gpu0.power.log
2022-12-06 14:50:25,263 [ZeusDataLoader(train)] train epoch 23 done: time=43.89 energy=5826.14
2022-12-06 14:50:25,267 [ZeusDataLoader(eval)] Epoch 23 begin.
Training Epoch: 22 [1024/50176]	Loss: 4.6312
Training Epoch: 22 [2048/50176]	Loss: 4.6266
Training Epoch: 22 [3072/50176]	Loss: 4.6320
Training Epoch: 22 [4096/50176]	Loss: 4.6302
Training Epoch: 22 [5120/50176]	Loss: 4.6298
Training Epoch: 22 [6144/50176]	Loss: 4.6329
Training Epoch: 22 [7168/50176]	Loss: 4.6455
Training Epoch: 22 [8192/50176]	Loss: 4.6367
Training Epoch: 22 [9216/50176]	Loss: 4.6468
Training Epoch: 22 [10240/50176]	Loss: 4.6479
Training Epoch: 22 [11264/50176]	Loss: 4.6228
Training Epoch: 22 [12288/50176]	Loss: 4.6334
Training Epoch: 22 [13312/50176]	Loss: 4.6317
Training Epoch: 22 [14336/50176]	Loss: 4.6508
Training Epoch: 22 [15360/50176]	Loss: 4.6478
Training Epoch: 22 [16384/50176]	Loss: 4.6419
Training Epoch: 22 [17408/50176]	Loss: 4.6266
Training Epoch: 22 [18432/50176]	Loss: 4.6340
Training Epoch: 22 [19456/50176]	Loss: 4.6370
Training Epoch: 22 [20480/50176]	Loss: 4.6364
Training Epoch: 22 [21504/50176]	Loss: 4.6221
Training Epoch: 22 [22528/50176]	Loss: 4.6330
Training Epoch: 22 [23552/50176]	Loss: 4.6368
Training Epoch: 22 [24576/50176]	Loss: 4.6433
Training Epoch: 22 [25600/50176]	Loss: 4.6383
Training Epoch: 22 [26624/50176]	Loss: 4.6308
Training Epoch: 22 [27648/50176]	Loss: 4.6407
Training Epoch: 22 [28672/50176]	Loss: 4.6387
Training Epoch: 22 [29696/50176]	Loss: 4.6334
Training Epoch: 22 [30720/50176]	Loss: 4.6396
Training Epoch: 22 [31744/50176]	Loss: 4.6253
Training Epoch: 22 [32768/50176]	Loss: 4.6400
Training Epoch: 22 [33792/50176]	Loss: 4.6389
Training Epoch: 22 [34816/50176]	Loss: 4.6356
Training Epoch: 22 [35840/50176]	Loss: 4.6387
Training Epoch: 22 [36864/50176]	Loss: 4.6431
Training Epoch: 22 [37888/50176]	Loss: 4.6295
Training Epoch: 22 [38912/50176]	Loss: 4.6369
Training Epoch: 22 [39936/50176]	Loss: 4.6425
Training Epoch: 22 [40960/50176]	Loss: 4.6450
Training Epoch: 22 [41984/50176]	Loss: 4.6412
Training Epoch: 22 [43008/50176]	Loss: 4.6353
Training Epoch: 22 [44032/50176]	Loss: 4.6411
Training Epoch: 22 [45056/50176]	Loss: 4.6274
Training Epoch: 22 [46080/50176]	Loss: 4.6415
Training Epoch: 22 [47104/50176]	Loss: 4.6315
Training Epoch: 22 [48128/50176]	Loss: 4.6380
Training Epoch: 22 [49152/50176]	Loss: 4.6290
Training Epoch: 22 [50176/50176]	Loss: 4.6331
2022-12-06 19:50:29.034 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:50:29,088 [ZeusDataLoader(eval)] eval epoch 23 done: time=3.81 energy=476.94
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Up to epoch 23: time=1109.61, energy=144997.20, cost=169589.66
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:50:29,089 [ZeusDataLoader(train)] Expected next epoch: time=1156.22, energy=151363.50, cost=176850.89
2022-12-06 14:50:29,090 [ZeusDataLoader(train)] Epoch 24 begin.
Validation Epoch: 22, Average loss: 4158.7793, Accuracy: 0.0098
2022-12-06 14:50:29,297 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:50:29,298 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:50:29.302 [ZeusMonitor] Monitor started.
2022-12-06 19:50:29.302 [ZeusMonitor] Running indefinitely. 2022-12-06 19:50:29.302 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:50:29.302 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e24+gpu0.power.log
2022-12-06 14:51:12,800 [ZeusDataLoader(train)] train epoch 24 done: time=43.70 energy=5825.36
2022-12-06 14:51:12,803 [ZeusDataLoader(eval)] Epoch 24 begin.
Training Epoch: 23 [1024/50176]	Loss: 4.6389
Training Epoch: 23 [2048/50176]	Loss: 4.6192
Training Epoch: 23 [3072/50176]	Loss: 4.6261
Training Epoch: 23 [4096/50176]	Loss: 4.6411
Training Epoch: 23 [5120/50176]	Loss: 4.6234
Training Epoch: 23 [6144/50176]	Loss: 4.6277
Training Epoch: 23 [7168/50176]	Loss: 4.6505
Training Epoch: 23 [8192/50176]	Loss: 4.6444
Training Epoch: 23 [9216/50176]	Loss: 4.6186
Training Epoch: 23 [10240/50176]	Loss: 4.6337
Training Epoch: 23 [11264/50176]	Loss: 4.6320
Training Epoch: 23 [12288/50176]	Loss: 4.6297
Training Epoch: 23 [13312/50176]	Loss: 4.6387
Training Epoch: 23 [14336/50176]	Loss: 4.6518
Training Epoch: 23 [15360/50176]	Loss: 4.6505
Training Epoch: 23 [16384/50176]	Loss: 4.6545
Training Epoch: 23 [17408/50176]	Loss: 4.6272
Training Epoch: 23 [18432/50176]	Loss: 4.6278
Training Epoch: 23 [19456/50176]	Loss: 4.6410
Training Epoch: 23 [20480/50176]	Loss: 4.6342
Training Epoch: 23 [21504/50176]	Loss: 4.6401
Training Epoch: 23 [22528/50176]	Loss: 4.6365
Training Epoch: 23 [23552/50176]	Loss: 4.6450
Training Epoch: 23 [24576/50176]	Loss: 4.6489
Training Epoch: 23 [25600/50176]	Loss: 4.6302
Training Epoch: 23 [26624/50176]	Loss: 4.6262
Training Epoch: 23 [27648/50176]	Loss: 4.6359
Training Epoch: 23 [28672/50176]	Loss: 4.6436
Training Epoch: 23 [29696/50176]	Loss: 4.6424
Training Epoch: 23 [30720/50176]	Loss: 4.6548
Training Epoch: 23 [31744/50176]	Loss: 4.6490
Training Epoch: 23 [32768/50176]	Loss: 4.6494
Training Epoch: 23 [33792/50176]	Loss: 4.6498
Training Epoch: 23 [34816/50176]	Loss: 4.6345
Training Epoch: 23 [35840/50176]	Loss: 4.6369
Training Epoch: 23 [36864/50176]	Loss: 4.6454
Training Epoch: 23 [37888/50176]	Loss: 4.6326
Training Epoch: 23 [38912/50176]	Loss: 4.6446
Training Epoch: 23 [39936/50176]	Loss: 4.6360
Training Epoch: 23 [40960/50176]	Loss: 4.6374
Training Epoch: 23 [41984/50176]	Loss: 4.6345
Training Epoch: 23 [43008/50176]	Loss: 4.6338
Training Epoch: 23 [44032/50176]	Loss: 4.6230
Training Epoch: 23 [45056/50176]	Loss: 4.6457
Training Epoch: 23 [46080/50176]	Loss: 4.6428
Training Epoch: 23 [47104/50176]	Loss: 4.6329
Training Epoch: 23 [48128/50176]	Loss: 4.6324
Training Epoch: 23 [49152/50176]	Loss: 4.6329
Training Epoch: 23 [50176/50176]	Loss: 4.6312
2022-12-06 19:51:16.536 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:51:16,576 [ZeusDataLoader(eval)] eval epoch 24 done: time=3.76 energy=464.83
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Up to epoch 24: time=1157.08, energy=151287.39, cost=176888.09
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:51:16,576 [ZeusDataLoader(train)] Expected next epoch: time=1203.69, energy=157653.69, cost=184149.33
2022-12-06 14:51:16,577 [ZeusDataLoader(train)] Epoch 25 begin.
Validation Epoch: 23, Average loss: 147.0823, Accuracy: 0.0098
2022-12-06 14:51:16,818 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:51:16,819 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:51:16.820 [ZeusMonitor] Monitor started.
2022-12-06 19:51:16.821 [ZeusMonitor] Running indefinitely. 2022-12-06 19:51:16.821 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:51:16.821 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e25+gpu0.power.log
2022-12-06 14:52:00,480 [ZeusDataLoader(train)] train epoch 25 done: time=43.89 energy=5834.70
2022-12-06 14:52:00,483 [ZeusDataLoader(eval)] Epoch 25 begin.
Training Epoch: 24 [1024/50176]	Loss: 4.6235
Training Epoch: 24 [2048/50176]	Loss: 4.6368
Training Epoch: 24 [3072/50176]	Loss: 4.6344
Training Epoch: 24 [4096/50176]	Loss: 4.6339
Training Epoch: 24 [5120/50176]	Loss: 4.6331
Training Epoch: 24 [6144/50176]	Loss: 4.6356
Training Epoch: 24 [7168/50176]	Loss: 4.6426
Training Epoch: 24 [8192/50176]	Loss: 4.6404
Training Epoch: 24 [9216/50176]	Loss: 4.6396
Training Epoch: 24 [10240/50176]	Loss: 4.6299
Training Epoch: 24 [11264/50176]	Loss: 4.6202
Training Epoch: 24 [12288/50176]	Loss: 4.6419
Training Epoch: 24 [13312/50176]	Loss: 4.6400
Training Epoch: 24 [14336/50176]	Loss: 4.6485
Training Epoch: 24 [15360/50176]	Loss: 4.6519
Training Epoch: 24 [16384/50176]	Loss: 4.6271
Training Epoch: 24 [17408/50176]	Loss: 4.6132
Training Epoch: 24 [18432/50176]	Loss: 4.6366
Training Epoch: 24 [19456/50176]	Loss: 4.6365
Training Epoch: 24 [20480/50176]	Loss: 4.6353
Training Epoch: 24 [21504/50176]	Loss: 4.6460
Training Epoch: 24 [22528/50176]	Loss: 4.6423
Training Epoch: 24 [23552/50176]	Loss: 4.6361
Training Epoch: 24 [24576/50176]	Loss: 4.6429
Training Epoch: 24 [25600/50176]	Loss: 4.6330
Training Epoch: 24 [26624/50176]	Loss: 4.6501
Training Epoch: 24 [27648/50176]	Loss: 4.6462
Training Epoch: 24 [28672/50176]	Loss: 4.6458
Training Epoch: 24 [29696/50176]	Loss: 4.6381
Training Epoch: 24 [30720/50176]	Loss: 4.6418
Training Epoch: 24 [31744/50176]	Loss: 4.6390
Training Epoch: 24 [32768/50176]	Loss: 4.6566
Training Epoch: 24 [33792/50176]	Loss: 4.6306
Training Epoch: 24 [34816/50176]	Loss: 4.6513
Training Epoch: 24 [35840/50176]	Loss: 4.6227
Training Epoch: 24 [36864/50176]	Loss: 4.6463
Training Epoch: 24 [37888/50176]	Loss: 4.6488
Training Epoch: 24 [38912/50176]	Loss: 4.6520
Training Epoch: 24 [39936/50176]	Loss: 4.6269
Training Epoch: 24 [40960/50176]	Loss: 4.6266
Training Epoch: 24 [41984/50176]	Loss: 4.6510
Training Epoch: 24 [43008/50176]	Loss: 4.6332
Training Epoch: 24 [44032/50176]	Loss: 4.6442
Training Epoch: 24 [45056/50176]	Loss: 4.6395
Training Epoch: 24 [46080/50176]	Loss: 4.6433
Training Epoch: 24 [47104/50176]	Loss: 4.6425
Training Epoch: 24 [48128/50176]	Loss: 4.6498
Training Epoch: 24 [49152/50176]	Loss: 4.6357
Training Epoch: 24 [50176/50176]	Loss: 4.6292
2022-12-06 19:52:04.214 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:52:04,252 [ZeusDataLoader(eval)] eval epoch 25 done: time=3.76 energy=462.26
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Up to epoch 25: time=1204.73, energy=157584.34, cost=184206.46
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:52:04,253 [ZeusDataLoader(train)] Expected next epoch: time=1251.34, energy=163950.64, cost=191467.69
2022-12-06 14:52:04,254 [ZeusDataLoader(train)] Epoch 26 begin.
Validation Epoch: 24, Average loss: 67.7428, Accuracy: 0.0098
2022-12-06 14:52:04,501 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:52:04,502 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:52:04.511 [ZeusMonitor] Monitor started.
2022-12-06 19:52:04.512 [ZeusMonitor] Running indefinitely. 2022-12-06 19:52:04.512 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:52:04.512 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e26+gpu0.power.log
2022-12-06 14:52:48,031 [ZeusDataLoader(train)] train epoch 26 done: time=43.77 energy=5827.48
2022-12-06 14:52:48,034 [ZeusDataLoader(eval)] Epoch 26 begin.
Training Epoch: 25 [1024/50176]	Loss: 4.6410
Training Epoch: 25 [2048/50176]	Loss: 4.6341
Training Epoch: 25 [3072/50176]	Loss: 4.6388
Training Epoch: 25 [4096/50176]	Loss: 4.6327
Training Epoch: 25 [5120/50176]	Loss: 4.6366
Training Epoch: 25 [6144/50176]	Loss: 4.6328
Training Epoch: 25 [7168/50176]	Loss: 4.6290
Training Epoch: 25 [8192/50176]	Loss: 4.6245
Training Epoch: 25 [9216/50176]	Loss: 4.6470
Training Epoch: 25 [10240/50176]	Loss: 4.6225
Training Epoch: 25 [11264/50176]	Loss: 4.6318
Training Epoch: 25 [12288/50176]	Loss: 4.6313
Training Epoch: 25 [13312/50176]	Loss: 4.6273
Training Epoch: 25 [14336/50176]	Loss: 4.6330
Training Epoch: 25 [15360/50176]	Loss: 4.6388
Training Epoch: 25 [16384/50176]	Loss: 4.6267
Training Epoch: 25 [17408/50176]	Loss: 4.6381
Training Epoch: 25 [18432/50176]	Loss: 4.6549
Training Epoch: 25 [19456/50176]	Loss: 4.6409
Training Epoch: 25 [20480/50176]	Loss: 4.6400
Training Epoch: 25 [21504/50176]	Loss: 4.6362
Training Epoch: 25 [22528/50176]	Loss: 4.6393
Training Epoch: 25 [23552/50176]	Loss: 4.6407
Training Epoch: 25 [24576/50176]	Loss: 4.6302
Training Epoch: 25 [25600/50176]	Loss: 4.6461
Training Epoch: 25 [26624/50176]	Loss: 4.6285
Training Epoch: 25 [27648/50176]	Loss: 4.6306
Training Epoch: 25 [28672/50176]	Loss: 4.6329
Training Epoch: 25 [29696/50176]	Loss: 4.6371
Training Epoch: 25 [30720/50176]	Loss: 4.6330
Training Epoch: 25 [31744/50176]	Loss: 4.6569
Training Epoch: 25 [32768/50176]	Loss: 4.6542
Training Epoch: 25 [33792/50176]	Loss: 4.6359
Training Epoch: 25 [34816/50176]	Loss: 4.6359
Training Epoch: 25 [35840/50176]	Loss: 4.6370
Training Epoch: 25 [36864/50176]	Loss: 4.6428
Training Epoch: 25 [37888/50176]	Loss: 4.6403
Training Epoch: 25 [38912/50176]	Loss: 4.6287
Training Epoch: 25 [39936/50176]	Loss: 4.6279
Training Epoch: 25 [40960/50176]	Loss: 4.6457
Training Epoch: 25 [41984/50176]	Loss: 4.6480
Training Epoch: 25 [43008/50176]	Loss: 4.6355
Training Epoch: 25 [44032/50176]	Loss: 4.6435
Training Epoch: 25 [45056/50176]	Loss: 4.6409
Training Epoch: 25 [46080/50176]	Loss: 4.6410
Training Epoch: 25 [47104/50176]	Loss: 4.6376
Training Epoch: 25 [48128/50176]	Loss: 4.6440
Training Epoch: 25 [49152/50176]	Loss: 4.6433
Training Epoch: 25 [50176/50176]	Loss: 4.6272
2022-12-06 19:52:51.790 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:52:51,821 [ZeusDataLoader(eval)] eval epoch 26 done: time=3.78 energy=483.69
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Up to epoch 26: time=1252.28, energy=163895.51, cost=191522.59
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:52:51,822 [ZeusDataLoader(train)] Expected next epoch: time=1298.89, energy=170261.81, cost=198783.82
2022-12-06 14:52:51,823 [ZeusDataLoader(train)] Epoch 27 begin.
Validation Epoch: 25, Average loss: 10796.0790, Accuracy: 0.0099
2022-12-06 14:52:52,071 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:52:52,072 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:52:52.073 [ZeusMonitor] Monitor started.
2022-12-06 19:52:52.073 [ZeusMonitor] Running indefinitely. 2022-12-06 19:52:52.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:52:52.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e27+gpu0.power.log
2022-12-06 14:53:35,704 [ZeusDataLoader(train)] train epoch 27 done: time=43.87 energy=5825.93
2022-12-06 14:53:35,707 [ZeusDataLoader(eval)] Epoch 27 begin.
Training Epoch: 26 [1024/50176]	Loss: 4.6369
Training Epoch: 26 [2048/50176]	Loss: 4.6321
Training Epoch: 26 [3072/50176]	Loss: 4.6512
Training Epoch: 26 [4096/50176]	Loss: 4.6407
Training Epoch: 26 [5120/50176]	Loss: 4.6402
Training Epoch: 26 [6144/50176]	Loss: 4.6465
Training Epoch: 26 [7168/50176]	Loss: 4.6390
Training Epoch: 26 [8192/50176]	Loss: 4.6495
Training Epoch: 26 [9216/50176]	Loss: 4.6460
Training Epoch: 26 [10240/50176]	Loss: 4.6374
Training Epoch: 26 [11264/50176]	Loss: 4.6275
Training Epoch: 26 [12288/50176]	Loss: 4.6449
Training Epoch: 26 [13312/50176]	Loss: 4.6492
Training Epoch: 26 [14336/50176]	Loss: 4.6321
Training Epoch: 26 [15360/50176]	Loss: 4.6466
Training Epoch: 26 [16384/50176]	Loss: 4.6402
Training Epoch: 26 [17408/50176]	Loss: 4.6281
Training Epoch: 26 [18432/50176]	Loss: 4.6268
Training Epoch: 26 [19456/50176]	Loss: 4.6342
Training Epoch: 26 [20480/50176]	Loss: 4.6416
Training Epoch: 26 [21504/50176]	Loss: 4.6396
Training Epoch: 26 [22528/50176]	Loss: 4.6312
Training Epoch: 26 [23552/50176]	Loss: 4.6377
Training Epoch: 26 [24576/50176]	Loss: 4.6345
Training Epoch: 26 [25600/50176]	Loss: 4.6460
Training Epoch: 26 [26624/50176]	Loss: 4.6378
Training Epoch: 26 [27648/50176]	Loss: 4.6512
Training Epoch: 26 [28672/50176]	Loss: 4.6570
Training Epoch: 26 [29696/50176]	Loss: 4.6387
Training Epoch: 26 [30720/50176]	Loss: 4.6492
Training Epoch: 26 [31744/50176]	Loss: 4.6322
Training Epoch: 26 [32768/50176]	Loss: 4.6364
Training Epoch: 26 [33792/50176]	Loss: 4.6424
Training Epoch: 26 [34816/50176]	Loss: 4.6484
Training Epoch: 26 [35840/50176]	Loss: 4.6469
Training Epoch: 26 [36864/50176]	Loss: 4.6297
Training Epoch: 26 [37888/50176]	Loss: 4.6512
Training Epoch: 26 [38912/50176]	Loss: 4.6385
Training Epoch: 26 [39936/50176]	Loss: 4.6315
Training Epoch: 26 [40960/50176]	Loss: 4.6460
Training Epoch: 26 [41984/50176]	Loss: 4.6461
Training Epoch: 26 [43008/50176]	Loss: 4.6380
Training Epoch: 26 [44032/50176]	Loss: 4.6301
Training Epoch: 26 [45056/50176]	Loss: 4.6303
Training Epoch: 26 [46080/50176]	Loss: 4.6395
Training Epoch: 26 [47104/50176]	Loss: 4.6347
Training Epoch: 26 [48128/50176]	Loss: 4.6292
Training Epoch: 26 [49152/50176]	Loss: 4.6448
Training Epoch: 26 [50176/50176]	Loss: 4.6420
2022-12-06 19:53:39.435 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:53:39,458 [ZeusDataLoader(eval)] eval epoch 27 done: time=3.74 energy=466.08
2022-12-06 14:53:39,458 [ZeusDataLoader(train)] Up to epoch 27: time=1299.90, energy=170187.52, cost=198835.03
2022-12-06 14:53:39,458 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:53:39,459 [ZeusDataLoader(train)] Expected next epoch: time=1346.51, energy=176553.82, cost=206096.27
2022-12-06 14:53:39,459 [ZeusDataLoader(train)] Epoch 28 begin.
Validation Epoch: 26, Average loss: 31.0042, Accuracy: 0.0098
2022-12-06 14:53:39,711 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:53:39,712 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:53:39.714 [ZeusMonitor] Monitor started.
2022-12-06 19:53:39.714 [ZeusMonitor] Running indefinitely. 2022-12-06 19:53:39.714 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:53:39.714 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e28+gpu0.power.log
2022-12-06 14:54:23,622 [ZeusDataLoader(train)] train epoch 28 done: time=44.15 energy=5847.75
2022-12-06 14:54:23,625 [ZeusDataLoader(eval)] Epoch 28 begin.
Training Epoch: 27 [1024/50176]	Loss: 4.6356
Training Epoch: 27 [2048/50176]	Loss: 4.6255
Training Epoch: 27 [3072/50176]	Loss: 4.6220
Training Epoch: 27 [4096/50176]	Loss: 4.6343
Training Epoch: 27 [5120/50176]	Loss: 4.6251
Training Epoch: 27 [6144/50176]	Loss: 4.6325
Training Epoch: 27 [7168/50176]	Loss: 4.6359
Training Epoch: 27 [8192/50176]	Loss: 4.6344
Training Epoch: 27 [9216/50176]	Loss: 4.6442
Training Epoch: 27 [10240/50176]	Loss: 4.6319
Training Epoch: 27 [11264/50176]	Loss: 4.6254
Training Epoch: 27 [12288/50176]	Loss: 4.6365
Training Epoch: 27 [13312/50176]	Loss: 4.6500
Training Epoch: 27 [14336/50176]	Loss: 4.6220
Training Epoch: 27 [15360/50176]	Loss: 4.6283
Training Epoch: 27 [16384/50176]	Loss: 4.6291
Training Epoch: 27 [17408/50176]	Loss: 4.6298
Training Epoch: 27 [18432/50176]	Loss: 4.6585
Training Epoch: 27 [19456/50176]	Loss: 4.6332
Training Epoch: 27 [20480/50176]	Loss: 4.6426
Training Epoch: 27 [21504/50176]	Loss: 4.6441
Training Epoch: 27 [22528/50176]	Loss: 4.6409
Training Epoch: 27 [23552/50176]	Loss: 4.6328
Training Epoch: 27 [24576/50176]	Loss: 4.6400
Training Epoch: 27 [25600/50176]	Loss: 4.6514
Training Epoch: 27 [26624/50176]	Loss: 4.6534
Training Epoch: 27 [27648/50176]	Loss: 4.6318
Training Epoch: 27 [28672/50176]	Loss: 4.6443
Training Epoch: 27 [29696/50176]	Loss: 4.6188
Training Epoch: 27 [30720/50176]	Loss: 4.6237
Training Epoch: 27 [31744/50176]	Loss: 4.6475
Training Epoch: 27 [32768/50176]	Loss: 4.6334
Training Epoch: 27 [33792/50176]	Loss: 4.6486
Training Epoch: 27 [34816/50176]	Loss: 4.6390
Training Epoch: 27 [35840/50176]	Loss: 4.6318
Training Epoch: 27 [36864/50176]	Loss: 4.6319
Training Epoch: 27 [37888/50176]	Loss: 4.6245
Training Epoch: 27 [38912/50176]	Loss: 4.6442
Training Epoch: 27 [39936/50176]	Loss: 4.6320
Training Epoch: 27 [40960/50176]	Loss: 4.6457
Training Epoch: 27 [41984/50176]	Loss: 4.6429
Training Epoch: 27 [43008/50176]	Loss: 4.6313
Training Epoch: 27 [44032/50176]	Loss: 4.6300
Training Epoch: 27 [45056/50176]	Loss: 4.6363
Training Epoch: 27 [46080/50176]	Loss: 4.6355
Training Epoch: 27 [47104/50176]	Loss: 4.6246
Training Epoch: 27 [48128/50176]	Loss: 4.6440
Training Epoch: 27 [49152/50176]	Loss: 4.6481
Training Epoch: 27 [50176/50176]	Loss: 4.6411
2022-12-06 19:54:27.374 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:54:27,396 [ZeusDataLoader(eval)] eval epoch 28 done: time=3.76 energy=470.71
2022-12-06 14:54:27,396 [ZeusDataLoader(train)] Up to epoch 28: time=1347.82, energy=176505.99, cost=206187.05
2022-12-06 14:54:27,397 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:54:27,397 [ZeusDataLoader(train)] Expected next epoch: time=1394.42, energy=182872.28, cost=213448.28
2022-12-06 14:54:27,398 [ZeusDataLoader(train)] Epoch 29 begin.
Validation Epoch: 27, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:54:27,634 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:54:27,634 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:54:27.636 [ZeusMonitor] Monitor started.
2022-12-06 19:54:27.636 [ZeusMonitor] Running indefinitely. 2022-12-06 19:54:27.636 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:54:27.636 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e29+gpu0.power.log
2022-12-06 14:55:11,201 [ZeusDataLoader(train)] train epoch 29 done: time=43.80 energy=5821.48
2022-12-06 14:55:11,204 [ZeusDataLoader(eval)] Epoch 29 begin.
Training Epoch: 28 [1024/50176]	Loss: 4.6296
Training Epoch: 28 [2048/50176]	Loss: 4.6282
Training Epoch: 28 [3072/50176]	Loss: 4.6416
Training Epoch: 28 [4096/50176]	Loss: 4.6412
Training Epoch: 28 [5120/50176]	Loss: 4.6326
Training Epoch: 28 [6144/50176]	Loss: 4.6345
Training Epoch: 28 [7168/50176]	Loss: 4.6403
Training Epoch: 28 [8192/50176]	Loss: 4.6328
Training Epoch: 28 [9216/50176]	Loss: 4.6237
Training Epoch: 28 [10240/50176]	Loss: 4.6224
Training Epoch: 28 [11264/50176]	Loss: 4.6572
Training Epoch: 28 [12288/50176]	Loss: 4.6290
Training Epoch: 28 [13312/50176]	Loss: 4.6403
Training Epoch: 28 [14336/50176]	Loss: 4.6277
Training Epoch: 28 [15360/50176]	Loss: 4.6238
Training Epoch: 28 [16384/50176]	Loss: 4.6372
Training Epoch: 28 [17408/50176]	Loss: 4.6421
Training Epoch: 28 [18432/50176]	Loss: 4.6214
Training Epoch: 28 [19456/50176]	Loss: 4.6223
Training Epoch: 28 [20480/50176]	Loss: 4.6368
Training Epoch: 28 [21504/50176]	Loss: 4.6202
Training Epoch: 28 [22528/50176]	Loss: 4.6409
Training Epoch: 28 [23552/50176]	Loss: 4.6489
Training Epoch: 28 [24576/50176]	Loss: 4.6435
Training Epoch: 28 [25600/50176]	Loss: 4.6332
Training Epoch: 28 [26624/50176]	Loss: 4.6264
Training Epoch: 28 [27648/50176]	Loss: 4.6347
Training Epoch: 28 [28672/50176]	Loss: 4.6429
Training Epoch: 28 [29696/50176]	Loss: 4.6428
Training Epoch: 28 [30720/50176]	Loss: 4.6345
Training Epoch: 28 [31744/50176]	Loss: 4.6351
Training Epoch: 28 [32768/50176]	Loss: 4.6523
Training Epoch: 28 [33792/50176]	Loss: 4.6264
Training Epoch: 28 [34816/50176]	Loss: 4.6396
Training Epoch: 28 [35840/50176]	Loss: 4.6353
Training Epoch: 28 [36864/50176]	Loss: 4.6574
Training Epoch: 28 [37888/50176]	Loss: 4.6615
Training Epoch: 28 [38912/50176]	Loss: 4.6426
Training Epoch: 28 [39936/50176]	Loss: 4.6407
Training Epoch: 28 [40960/50176]	Loss: 4.6401
Training Epoch: 28 [41984/50176]	Loss: 4.6165
Training Epoch: 28 [43008/50176]	Loss: 4.6342
Training Epoch: 28 [44032/50176]	Loss: 4.6522
Training Epoch: 28 [45056/50176]	Loss: 4.6502
Training Epoch: 28 [46080/50176]	Loss: 4.6526
Training Epoch: 28 [47104/50176]	Loss: 4.6357
Training Epoch: 28 [48128/50176]	Loss: 4.6431
Training Epoch: 28 [49152/50176]	Loss: 4.6449
Training Epoch: 28 [50176/50176]	Loss: 4.6481
2022-12-06 19:55:14.990 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:55:15,010 [ZeusDataLoader(eval)] eval epoch 29 done: time=3.80 energy=477.19
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Up to epoch 29: time=1395.41, energy=182804.66, cost=213500.78
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:55:15,010 [ZeusDataLoader(train)] Expected next epoch: time=1442.02, energy=189170.95, cost=220762.01
2022-12-06 14:55:15,011 [ZeusDataLoader(train)] Epoch 30 begin.
Validation Epoch: 28, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:55:15,249 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:55:15,250 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:55:15.271 [ZeusMonitor] Monitor started.
2022-12-06 19:55:15.271 [ZeusMonitor] Running indefinitely. 2022-12-06 19:55:15.271 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:55:15.271 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e30+gpu0.power.log
2022-12-06 14:55:58,790 [ZeusDataLoader(train)] train epoch 30 done: time=43.77 energy=5826.74
2022-12-06 14:55:58,793 [ZeusDataLoader(eval)] Epoch 30 begin.
Training Epoch: 29 [1024/50176]	Loss: 4.6309
Training Epoch: 29 [2048/50176]	Loss: 4.6570
Training Epoch: 29 [3072/50176]	Loss: 4.6360
Training Epoch: 29 [4096/50176]	Loss: 4.6238
Training Epoch: 29 [5120/50176]	Loss: 4.6436
Training Epoch: 29 [6144/50176]	Loss: 4.6315
Training Epoch: 29 [7168/50176]	Loss: 4.6302
Training Epoch: 29 [8192/50176]	Loss: 4.6346
Training Epoch: 29 [9216/50176]	Loss: 4.6335
Training Epoch: 29 [10240/50176]	Loss: 4.6430
Training Epoch: 29 [11264/50176]	Loss: 4.6393
Training Epoch: 29 [12288/50176]	Loss: 4.6387
Training Epoch: 29 [13312/50176]	Loss: 4.6317
Training Epoch: 29 [14336/50176]	Loss: 4.6334
Training Epoch: 29 [15360/50176]	Loss: 4.6178
Training Epoch: 29 [16384/50176]	Loss: 4.6371
Training Epoch: 29 [17408/50176]	Loss: 4.6411
Training Epoch: 29 [18432/50176]	Loss: 4.6656
Training Epoch: 29 [19456/50176]	Loss: 4.6415
Training Epoch: 29 [20480/50176]	Loss: 4.6382
Training Epoch: 29 [21504/50176]	Loss: 4.6456
Training Epoch: 29 [22528/50176]	Loss: 4.6389
Training Epoch: 29 [23552/50176]	Loss: 4.6201
Training Epoch: 29 [24576/50176]	Loss: 4.6318
Training Epoch: 29 [25600/50176]	Loss: 4.6474
Training Epoch: 29 [26624/50176]	Loss: 4.6466
Training Epoch: 29 [27648/50176]	Loss: 4.6381
Training Epoch: 29 [28672/50176]	Loss: 4.6327
Training Epoch: 29 [29696/50176]	Loss: 4.6481
Training Epoch: 29 [30720/50176]	Loss: 4.6542
Training Epoch: 29 [31744/50176]	Loss: 4.6426
Training Epoch: 29 [32768/50176]	Loss: 4.6386
Training Epoch: 29 [33792/50176]	Loss: 4.6165
Training Epoch: 29 [34816/50176]	Loss: 4.6405
Training Epoch: 29 [35840/50176]	Loss: 4.6303
Training Epoch: 29 [36864/50176]	Loss: 4.6333
Training Epoch: 29 [37888/50176]	Loss: 4.6407
Training Epoch: 29 [38912/50176]	Loss: 4.6402
Training Epoch: 29 [39936/50176]	Loss: 4.6202
Training Epoch: 29 [40960/50176]	Loss: 4.6272
Training Epoch: 29 [41984/50176]	Loss: 4.6393
Training Epoch: 29 [43008/50176]	Loss: 4.6435
Training Epoch: 29 [44032/50176]	Loss: 4.6436
Training Epoch: 29 [45056/50176]	Loss: 4.6404
Training Epoch: 29 [46080/50176]	Loss: 4.6379
Training Epoch: 29 [47104/50176]	Loss: 4.6389
Training Epoch: 29 [48128/50176]	Loss: 4.6401
Training Epoch: 29 [49152/50176]	Loss: 4.6292
Training Epoch: 29 [50176/50176]	Loss: 4.6358
2022-12-06 19:56:02.557 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:56:02,584 [ZeusDataLoader(eval)] eval epoch 30 done: time=3.78 energy=467.95
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Up to epoch 30: time=1442.97, energy=189099.35, cost=220809.11
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:56:02,585 [ZeusDataLoader(train)] Expected next epoch: time=1489.57, energy=195465.64, cost=228070.35
2022-12-06 14:56:02,586 [ZeusDataLoader(train)] Epoch 31 begin.
Validation Epoch: 29, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 14:56:02,780 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:56:02,781 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:56:02.784 [ZeusMonitor] Monitor started.
2022-12-06 19:56:02.784 [ZeusMonitor] Running indefinitely. 2022-12-06 19:56:02.784 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:56:02.784 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e31+gpu0.power.log
2022-12-06 14:56:46,327 [ZeusDataLoader(train)] train epoch 31 done: time=43.73 energy=5834.92
2022-12-06 14:56:46,331 [ZeusDataLoader(eval)] Epoch 31 begin.
Training Epoch: 30 [1024/50176]	Loss: 4.6375
Training Epoch: 30 [2048/50176]	Loss: 4.6257
Training Epoch: 30 [3072/50176]	Loss: 4.6402
Training Epoch: 30 [4096/50176]	Loss: 4.6328
Training Epoch: 30 [5120/50176]	Loss: 4.6263
Training Epoch: 30 [6144/50176]	Loss: 4.6445
Training Epoch: 30 [7168/50176]	Loss: 4.6324
Training Epoch: 30 [8192/50176]	Loss: 4.6358
Training Epoch: 30 [9216/50176]	Loss: 4.6271
Training Epoch: 30 [10240/50176]	Loss: 4.6368
Training Epoch: 30 [11264/50176]	Loss: 4.6214
Training Epoch: 30 [12288/50176]	Loss: 4.6189
Training Epoch: 30 [13312/50176]	Loss: 4.6348
Training Epoch: 30 [14336/50176]	Loss: 4.6387
Training Epoch: 30 [15360/50176]	Loss: 4.6389
Training Epoch: 30 [16384/50176]	Loss: 4.6245
Training Epoch: 30 [17408/50176]	Loss: 4.6425
Training Epoch: 30 [18432/50176]	Loss: 4.6231
Training Epoch: 30 [19456/50176]	Loss: 4.6465
Training Epoch: 30 [20480/50176]	Loss: 4.6369
Training Epoch: 30 [21504/50176]	Loss: 4.6361
Training Epoch: 30 [22528/50176]	Loss: 4.6308
Training Epoch: 30 [23552/50176]	Loss: 4.6467
Training Epoch: 30 [24576/50176]	Loss: 4.6347
Training Epoch: 30 [25600/50176]	Loss: 4.6364
Training Epoch: 30 [26624/50176]	Loss: 4.6377
Training Epoch: 30 [27648/50176]	Loss: 4.6228
Training Epoch: 30 [28672/50176]	Loss: 4.6408
Training Epoch: 30 [29696/50176]	Loss: 4.6425
Training Epoch: 30 [30720/50176]	Loss: 4.6280
Training Epoch: 30 [31744/50176]	Loss: 4.6324
Training Epoch: 30 [32768/50176]	Loss: 4.6365
Training Epoch: 30 [33792/50176]	Loss: 4.6408
Training Epoch: 30 [34816/50176]	Loss: 4.6380
Training Epoch: 30 [35840/50176]	Loss: 4.6338
Training Epoch: 30 [36864/50176]	Loss: 4.6419
Training Epoch: 30 [37888/50176]	Loss: 4.6307
Training Epoch: 30 [38912/50176]	Loss: 4.6367
Training Epoch: 30 [39936/50176]	Loss: 4.6351
Training Epoch: 30 [40960/50176]	Loss: 4.6377
Training Epoch: 30 [41984/50176]	Loss: 4.6414
Training Epoch: 30 [43008/50176]	Loss: 4.6456
Training Epoch: 30 [44032/50176]	Loss: 4.6315
Training Epoch: 30 [45056/50176]	Loss: 4.6300
Training Epoch: 30 [46080/50176]	Loss: 4.6492
Training Epoch: 30 [47104/50176]	Loss: 4.6306
Training Epoch: 30 [48128/50176]	Loss: 4.6285
Training Epoch: 30 [49152/50176]	Loss: 4.6392
Training Epoch: 30 [50176/50176]	Loss: 4.6412
2022-12-06 19:56:50.117 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:56:50,161 [ZeusDataLoader(eval)] eval epoch 31 done: time=3.82 energy=484.26
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Up to epoch 31: time=1490.52, energy=195418.52, cost=228129.89
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:56:50,162 [ZeusDataLoader(train)] Expected next epoch: time=1537.13, energy=201784.82, cost=235391.12
2022-12-06 14:56:50,163 [ZeusDataLoader(train)] Epoch 32 begin.
Validation Epoch: 30, Average loss: 0.4744, Accuracy: 0.0097
2022-12-06 14:56:50,397 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:56:50,398 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:56:50.400 [ZeusMonitor] Monitor started.
2022-12-06 19:56:50.400 [ZeusMonitor] Running indefinitely. 2022-12-06 19:56:50.400 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:56:50.400 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e32+gpu0.power.log
2022-12-06 14:57:33,831 [ZeusDataLoader(train)] train epoch 32 done: time=43.66 energy=5819.36
2022-12-06 14:57:33,835 [ZeusDataLoader(eval)] Epoch 32 begin.
Training Epoch: 31 [1024/50176]	Loss: 4.6357
Training Epoch: 31 [2048/50176]	Loss: 4.6263
Training Epoch: 31 [3072/50176]	Loss: 4.6254
Training Epoch: 31 [4096/50176]	Loss: 4.6372
Training Epoch: 31 [5120/50176]	Loss: 4.6333
Training Epoch: 31 [6144/50176]	Loss: 4.6242
Training Epoch: 31 [7168/50176]	Loss: 4.6404
Training Epoch: 31 [8192/50176]	Loss: 4.6359
Training Epoch: 31 [9216/50176]	Loss: 4.6350
Training Epoch: 31 [10240/50176]	Loss: 4.6348
Training Epoch: 31 [11264/50176]	Loss: 4.6274
Training Epoch: 31 [12288/50176]	Loss: 4.6273
Training Epoch: 31 [13312/50176]	Loss: 4.6339
Training Epoch: 31 [14336/50176]	Loss: 4.6180
Training Epoch: 31 [15360/50176]	Loss: 4.6352
Training Epoch: 31 [16384/50176]	Loss: 4.6430
Training Epoch: 31 [17408/50176]	Loss: 4.6286
Training Epoch: 31 [18432/50176]	Loss: 4.6308
Training Epoch: 31 [19456/50176]	Loss: 4.6323
Training Epoch: 31 [20480/50176]	Loss: 4.6392
Training Epoch: 31 [21504/50176]	Loss: 4.6284
Training Epoch: 31 [22528/50176]	Loss: 4.6399
Training Epoch: 31 [23552/50176]	Loss: 4.6478
Training Epoch: 31 [24576/50176]	Loss: 4.6377
Training Epoch: 31 [25600/50176]	Loss: 4.6297
Training Epoch: 31 [26624/50176]	Loss: 4.6389
Training Epoch: 31 [27648/50176]	Loss: 4.6338
Training Epoch: 31 [28672/50176]	Loss: 4.6432
Training Epoch: 31 [29696/50176]	Loss: 4.6261
Training Epoch: 31 [30720/50176]	Loss: 4.6424
Training Epoch: 31 [31744/50176]	Loss: 4.6367
Training Epoch: 31 [32768/50176]	Loss: 4.6485
Training Epoch: 31 [33792/50176]	Loss: 4.6271
Training Epoch: 31 [34816/50176]	Loss: 4.6311
Training Epoch: 31 [35840/50176]	Loss: 4.6440
Training Epoch: 31 [36864/50176]	Loss: 4.6530
Training Epoch: 31 [37888/50176]	Loss: 4.6416
Training Epoch: 31 [38912/50176]	Loss: 4.6311
Training Epoch: 31 [39936/50176]	Loss: 4.6314
Training Epoch: 31 [40960/50176]	Loss: 4.6246
Training Epoch: 31 [41984/50176]	Loss: 4.6289
Training Epoch: 31 [43008/50176]	Loss: 4.6459
Training Epoch: 31 [44032/50176]	Loss: 4.6588
Training Epoch: 31 [45056/50176]	Loss: 4.6368
Training Epoch: 31 [46080/50176]	Loss: 4.6351
Training Epoch: 31 [47104/50176]	Loss: 4.6337
Training Epoch: 31 [48128/50176]	Loss: 4.6391
Training Epoch: 31 [49152/50176]	Loss: 4.6229
Training Epoch: 31 [50176/50176]	Loss: 4.6288
2022-12-06 19:57:37.618 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:57:37,646 [ZeusDataLoader(eval)] eval epoch 32 done: time=3.80 energy=479.02
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Up to epoch 32: time=1537.98, energy=201716.91, cost=235432.14
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:57:37,646 [ZeusDataLoader(train)] Expected next epoch: time=1584.59, energy=208083.21, cost=242693.38
2022-12-06 14:57:37,647 [ZeusDataLoader(train)] Epoch 33 begin.
Validation Epoch: 31, Average loss: 0.1006, Accuracy: 0.0098
2022-12-06 14:57:37,887 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:57:37,888 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:57:37.902 [ZeusMonitor] Monitor started.
2022-12-06 19:57:37.902 [ZeusMonitor] Running indefinitely. 2022-12-06 19:57:37.902 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:57:37.902 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e33+gpu0.power.log
2022-12-06 14:58:21,294 [ZeusDataLoader(train)] train epoch 33 done: time=43.64 energy=5817.67
2022-12-06 14:58:21,297 [ZeusDataLoader(eval)] Epoch 33 begin.
Training Epoch: 32 [1024/50176]	Loss: 4.6404
Training Epoch: 32 [2048/50176]	Loss: 4.6314
Training Epoch: 32 [3072/50176]	Loss: 4.6274
Training Epoch: 32 [4096/50176]	Loss: 4.6285
Training Epoch: 32 [5120/50176]	Loss: 4.6502
Training Epoch: 32 [6144/50176]	Loss: 4.6486
Training Epoch: 32 [7168/50176]	Loss: 4.6309
Training Epoch: 32 [8192/50176]	Loss: 4.6294
Training Epoch: 32 [9216/50176]	Loss: 4.6325
Training Epoch: 32 [10240/50176]	Loss: 4.6443
Training Epoch: 32 [11264/50176]	Loss: 4.6336
Training Epoch: 32 [12288/50176]	Loss: 4.6307
Training Epoch: 32 [13312/50176]	Loss: 4.6491
Training Epoch: 32 [14336/50176]	Loss: 4.6458
Training Epoch: 32 [15360/50176]	Loss: 4.6138
Training Epoch: 32 [16384/50176]	Loss: 4.6284
Training Epoch: 32 [17408/50176]	Loss: 4.6406
Training Epoch: 32 [18432/50176]	Loss: 4.6376
Training Epoch: 32 [19456/50176]	Loss: 4.6413
Training Epoch: 32 [20480/50176]	Loss: 4.6389
Training Epoch: 32 [21504/50176]	Loss: 4.6460
Training Epoch: 32 [22528/50176]	Loss: 4.6500
Training Epoch: 32 [23552/50176]	Loss: 4.6215
Training Epoch: 32 [24576/50176]	Loss: 4.6360
Training Epoch: 32 [25600/50176]	Loss: 4.6324
Training Epoch: 32 [26624/50176]	Loss: 4.6425
Training Epoch: 32 [27648/50176]	Loss: 4.6595
Training Epoch: 32 [28672/50176]	Loss: 4.6485
Training Epoch: 32 [29696/50176]	Loss: 4.6466
Training Epoch: 32 [30720/50176]	Loss: 4.6319
Training Epoch: 32 [31744/50176]	Loss: 4.6287
Training Epoch: 32 [32768/50176]	Loss: 4.6259
Training Epoch: 32 [33792/50176]	Loss: 4.6313
Training Epoch: 32 [34816/50176]	Loss: 4.6508
Training Epoch: 32 [35840/50176]	Loss: 4.6495
Training Epoch: 32 [36864/50176]	Loss: 4.6359
Training Epoch: 32 [37888/50176]	Loss: 4.6434
Training Epoch: 32 [38912/50176]	Loss: 4.6370
Training Epoch: 32 [39936/50176]	Loss: 4.6367
Training Epoch: 32 [40960/50176]	Loss: 4.6341
Training Epoch: 32 [41984/50176]	Loss: 4.6321
Training Epoch: 32 [43008/50176]	Loss: 4.6691
Training Epoch: 32 [44032/50176]	Loss: 4.6503
Training Epoch: 32 [45056/50176]	Loss: 4.6369
Training Epoch: 32 [46080/50176]	Loss: 4.6325
Training Epoch: 32 [47104/50176]	Loss: 4.6376
Training Epoch: 32 [48128/50176]	Loss: 4.6301
Training Epoch: 32 [49152/50176]	Loss: 4.6465
Training Epoch: 32 [50176/50176]	Loss: 4.6435
2022-12-06 19:58:25.046 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:58:25,063 [ZeusDataLoader(eval)] eval epoch 33 done: time=3.76 energy=463.51
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Up to epoch 33: time=1585.38, energy=207998.09, cost=242719.92
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:58:25,063 [ZeusDataLoader(train)] Expected next epoch: time=1631.99, energy=214364.38, cost=249981.16
2022-12-06 14:58:25,064 [ZeusDataLoader(train)] Epoch 34 begin.
Validation Epoch: 32, Average loss: 5220.7918, Accuracy: 0.0098
2022-12-06 14:58:25,307 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:58:25,308 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:58:25.322 [ZeusMonitor] Monitor started.
2022-12-06 19:58:25.322 [ZeusMonitor] Running indefinitely. 2022-12-06 19:58:25.322 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:58:25.322 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e34+gpu0.power.log
2022-12-06 14:59:08,770 [ZeusDataLoader(train)] train epoch 34 done: time=43.70 energy=5820.20
2022-12-06 14:59:08,773 [ZeusDataLoader(eval)] Epoch 34 begin.
Training Epoch: 33 [1024/50176]	Loss: 4.6378
Training Epoch: 33 [2048/50176]	Loss: 4.6465
Training Epoch: 33 [3072/50176]	Loss: 4.6281
Training Epoch: 33 [4096/50176]	Loss: 4.6293
Training Epoch: 33 [5120/50176]	Loss: 4.6429
Training Epoch: 33 [6144/50176]	Loss: 4.6252
Training Epoch: 33 [7168/50176]	Loss: 4.6349
Training Epoch: 33 [8192/50176]	Loss: 4.6411
Training Epoch: 33 [9216/50176]	Loss: 4.6267
Training Epoch: 33 [10240/50176]	Loss: 4.6430
Training Epoch: 33 [11264/50176]	Loss: 4.6559
Training Epoch: 33 [12288/50176]	Loss: 4.6373
Training Epoch: 33 [13312/50176]	Loss: 4.6248
Training Epoch: 33 [14336/50176]	Loss: 4.6206
Training Epoch: 33 [15360/50176]	Loss: 4.6269
Training Epoch: 33 [16384/50176]	Loss: 4.6341
Training Epoch: 33 [17408/50176]	Loss: 4.6382
Training Epoch: 33 [18432/50176]	Loss: 4.6137
Training Epoch: 33 [19456/50176]	Loss: 4.6501
Training Epoch: 33 [20480/50176]	Loss: 4.6337
Training Epoch: 33 [21504/50176]	Loss: 4.6473
Training Epoch: 33 [22528/50176]	Loss: 4.6365
Training Epoch: 33 [23552/50176]	Loss: 4.6452
Training Epoch: 33 [24576/50176]	Loss: 4.6342
Training Epoch: 33 [25600/50176]	Loss: 4.6268
Training Epoch: 33 [26624/50176]	Loss: 4.6250
Training Epoch: 33 [27648/50176]	Loss: 4.6292
Training Epoch: 33 [28672/50176]	Loss: 4.6398
Training Epoch: 33 [29696/50176]	Loss: 4.6344
Training Epoch: 33 [30720/50176]	Loss: 4.6447
Training Epoch: 33 [31744/50176]	Loss: 4.6348
Training Epoch: 33 [32768/50176]	Loss: 4.6333
Training Epoch: 33 [33792/50176]	Loss: 4.6162
Training Epoch: 33 [34816/50176]	Loss: 4.6284
Training Epoch: 33 [35840/50176]	Loss: 4.6385
Training Epoch: 33 [36864/50176]	Loss: 4.6250
Training Epoch: 33 [37888/50176]	Loss: 4.6422
Training Epoch: 33 [38912/50176]	Loss: 4.6552
Training Epoch: 33 [39936/50176]	Loss: 4.6556
Training Epoch: 33 [40960/50176]	Loss: 4.6489
Training Epoch: 33 [41984/50176]	Loss: 4.6400
Training Epoch: 33 [43008/50176]	Loss: 4.6245
Training Epoch: 33 [44032/50176]	Loss: 4.6309
Training Epoch: 33 [45056/50176]	Loss: 4.6398
Training Epoch: 33 [46080/50176]	Loss: 4.6572
Training Epoch: 33 [47104/50176]	Loss: 4.6463
Training Epoch: 33 [48128/50176]	Loss: 4.6439
Training Epoch: 33 [49152/50176]	Loss: 4.6424
Training Epoch: 33 [50176/50176]	Loss: 4.6284
2022-12-06 19:59:12.530 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:59:12,545 [ZeusDataLoader(eval)] eval epoch 34 done: time=3.76 energy=474.37
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Up to epoch 34: time=1632.84, energy=214292.66, cost=250020.04
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:59:12,545 [ZeusDataLoader(train)] Expected next epoch: time=1679.45, energy=220658.95, cost=257281.27
2022-12-06 14:59:12,546 [ZeusDataLoader(train)] Epoch 35 begin.
Validation Epoch: 33, Average loss: 8974.5149, Accuracy: 0.0098
2022-12-06 14:59:12,747 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 14:59:12,748 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 19:59:12.750 [ZeusMonitor] Monitor started.
2022-12-06 19:59:12.750 [ZeusMonitor] Running indefinitely. 2022-12-06 19:59:12.750 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 19:59:12.750 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e35+gpu0.power.log
2022-12-06 14:59:56,151 [ZeusDataLoader(train)] train epoch 35 done: time=43.60 energy=5822.93
2022-12-06 14:59:56,154 [ZeusDataLoader(eval)] Epoch 35 begin.
Training Epoch: 34 [1024/50176]	Loss: 4.6264
Training Epoch: 34 [2048/50176]	Loss: 4.6337
Training Epoch: 34 [3072/50176]	Loss: 4.6327
Training Epoch: 34 [4096/50176]	Loss: 4.6343
Training Epoch: 34 [5120/50176]	Loss: 4.6277
Training Epoch: 34 [6144/50176]	Loss: 4.6376
Training Epoch: 34 [7168/50176]	Loss: 4.6454
Training Epoch: 34 [8192/50176]	Loss: 4.6469
Training Epoch: 34 [9216/50176]	Loss: 4.6348
Training Epoch: 34 [10240/50176]	Loss: 4.6432
Training Epoch: 34 [11264/50176]	Loss: 4.6293
Training Epoch: 34 [12288/50176]	Loss: 4.6361
Training Epoch: 34 [13312/50176]	Loss: 4.6432
Training Epoch: 34 [14336/50176]	Loss: 4.6358
Training Epoch: 34 [15360/50176]	Loss: 4.6304
Training Epoch: 34 [16384/50176]	Loss: 4.6482
Training Epoch: 34 [17408/50176]	Loss: 4.6145
Training Epoch: 34 [18432/50176]	Loss: 4.6444
Training Epoch: 34 [19456/50176]	Loss: 4.6490
Training Epoch: 34 [20480/50176]	Loss: 4.6436
Training Epoch: 34 [21504/50176]	Loss: 4.6432
Training Epoch: 34 [22528/50176]	Loss: 4.6528
Training Epoch: 34 [23552/50176]	Loss: 4.6352
Training Epoch: 34 [24576/50176]	Loss: 4.6234
Training Epoch: 34 [25600/50176]	Loss: 4.6297
Training Epoch: 34 [26624/50176]	Loss: 4.6520
Training Epoch: 34 [27648/50176]	Loss: 4.6539
Training Epoch: 34 [28672/50176]	Loss: 4.6279
Training Epoch: 34 [29696/50176]	Loss: 4.6428
Training Epoch: 34 [30720/50176]	Loss: 4.6387
Training Epoch: 34 [31744/50176]	Loss: 4.6480
Training Epoch: 34 [32768/50176]	Loss: 4.6455
Training Epoch: 34 [33792/50176]	Loss: 4.6481
Training Epoch: 34 [34816/50176]	Loss: 4.6391
Training Epoch: 34 [35840/50176]	Loss: 4.6503
Training Epoch: 34 [36864/50176]	Loss: 4.6475
Training Epoch: 34 [37888/50176]	Loss: 4.6543
Training Epoch: 34 [38912/50176]	Loss: 4.6589
Training Epoch: 34 [39936/50176]	Loss: 4.6321
Training Epoch: 34 [40960/50176]	Loss: 4.6421
Training Epoch: 34 [41984/50176]	Loss: 4.6281
Training Epoch: 34 [43008/50176]	Loss: 4.6357
Training Epoch: 34 [44032/50176]	Loss: 4.6329
Training Epoch: 34 [45056/50176]	Loss: 4.6467
Training Epoch: 34 [46080/50176]	Loss: 4.6379
Training Epoch: 34 [47104/50176]	Loss: 4.6399
Training Epoch: 34 [48128/50176]	Loss: 4.6279
Training Epoch: 34 [49152/50176]	Loss: 4.6403
Training Epoch: 34 [50176/50176]	Loss: 4.6378
2022-12-06 19:59:59.900 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 14:59:59,909 [ZeusDataLoader(eval)] eval epoch 35 done: time=3.75 energy=464.30
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Up to epoch 35: time=1680.19, energy=220579.89, cost=257306.24
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 14:59:59,909 [ZeusDataLoader(train)] Expected next epoch: time=1726.79, energy=226946.18, cost=264567.48
2022-12-06 14:59:59,910 [ZeusDataLoader(train)] Epoch 36 begin.
Validation Epoch: 34, Average loss: 1268.7010, Accuracy: 0.0098
2022-12-06 15:00:00,104 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:00:00,105 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:00:00.108 [ZeusMonitor] Monitor started.
2022-12-06 20:00:00.108 [ZeusMonitor] Running indefinitely. 2022-12-06 20:00:00.108 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:00:00.108 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e36+gpu0.power.log
2022-12-06 15:00:43,573 [ZeusDataLoader(train)] train epoch 36 done: time=43.66 energy=5823.63
2022-12-06 15:00:43,576 [ZeusDataLoader(eval)] Epoch 36 begin.
Training Epoch: 35 [1024/50176]	Loss: 4.6329
Training Epoch: 35 [2048/50176]	Loss: 4.6432
Training Epoch: 35 [3072/50176]	Loss: 4.6439
Training Epoch: 35 [4096/50176]	Loss: 4.6461
Training Epoch: 35 [5120/50176]	Loss: 4.6488
Training Epoch: 35 [6144/50176]	Loss: 4.6287
Training Epoch: 35 [7168/50176]	Loss: 4.6329
Training Epoch: 35 [8192/50176]	Loss: 4.6413
Training Epoch: 35 [9216/50176]	Loss: 4.6382
Training Epoch: 35 [10240/50176]	Loss: 4.6380
Training Epoch: 35 [11264/50176]	Loss: 4.6521
Training Epoch: 35 [12288/50176]	Loss: 4.6375
Training Epoch: 35 [13312/50176]	Loss: 4.6371
Training Epoch: 35 [14336/50176]	Loss: 4.6367
Training Epoch: 35 [15360/50176]	Loss: 4.6227
Training Epoch: 35 [16384/50176]	Loss: 4.6451
Training Epoch: 35 [17408/50176]	Loss: 4.6330
Training Epoch: 35 [18432/50176]	Loss: 4.6373
Training Epoch: 35 [19456/50176]	Loss: 4.6276
Training Epoch: 35 [20480/50176]	Loss: 4.6429
Training Epoch: 35 [21504/50176]	Loss: 4.6328
Training Epoch: 35 [22528/50176]	Loss: 4.6343
Training Epoch: 35 [23552/50176]	Loss: 4.6404
Training Epoch: 35 [24576/50176]	Loss: 4.6468
Training Epoch: 35 [25600/50176]	Loss: 4.6170
Training Epoch: 35 [26624/50176]	Loss: 4.6280
Training Epoch: 35 [27648/50176]	Loss: 4.6547
Training Epoch: 35 [28672/50176]	Loss: 4.6377
Training Epoch: 35 [29696/50176]	Loss: 4.6424
Training Epoch: 35 [30720/50176]	Loss: 4.6435
Training Epoch: 35 [31744/50176]	Loss: 4.6444
Training Epoch: 35 [32768/50176]	Loss: 4.6239
Training Epoch: 35 [33792/50176]	Loss: 4.6286
Training Epoch: 35 [34816/50176]	Loss: 4.6420
Training Epoch: 35 [35840/50176]	Loss: 4.6451
Training Epoch: 35 [36864/50176]	Loss: 4.6480
Training Epoch: 35 [37888/50176]	Loss: 4.6509
Training Epoch: 35 [38912/50176]	Loss: 4.6476
Training Epoch: 35 [39936/50176]	Loss: 4.6577
Training Epoch: 35 [40960/50176]	Loss: 4.6226
Training Epoch: 35 [41984/50176]	Loss: 4.6387
Training Epoch: 35 [43008/50176]	Loss: 4.6430
Training Epoch: 35 [44032/50176]	Loss: 4.6247
Training Epoch: 35 [45056/50176]	Loss: 4.6586
Training Epoch: 35 [46080/50176]	Loss: 4.6513
Training Epoch: 35 [47104/50176]	Loss: 4.6288
Training Epoch: 35 [48128/50176]	Loss: 4.6351
Training Epoch: 35 [49152/50176]	Loss: 4.6618
Training Epoch: 35 [50176/50176]	Loss: 4.6253
2022-12-06 20:00:47.338 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:00:47,378 [ZeusDataLoader(eval)] eval epoch 36 done: time=3.79 energy=477.71
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Up to epoch 36: time=1727.64, energy=226881.23, cost=264608.71
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:00:47,378 [ZeusDataLoader(train)] Expected next epoch: time=1774.24, energy=233247.52, cost=271869.95
2022-12-06 15:00:47,379 [ZeusDataLoader(train)] Epoch 37 begin.
Validation Epoch: 35, Average loss: 10626.0593, Accuracy: 0.0098
2022-12-06 15:00:47,663 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:00:47,664 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:00:47.665 [ZeusMonitor] Monitor started.
2022-12-06 20:00:47.665 [ZeusMonitor] Running indefinitely. 2022-12-06 20:00:47.665 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:00:47.665 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e37+gpu0.power.log
2022-12-06 15:01:31,162 [ZeusDataLoader(train)] train epoch 37 done: time=43.78 energy=5818.37
2022-12-06 15:01:31,165 [ZeusDataLoader(eval)] Epoch 37 begin.
Training Epoch: 36 [1024/50176]	Loss: 4.6498
Training Epoch: 36 [2048/50176]	Loss: 4.6255
Training Epoch: 36 [3072/50176]	Loss: 4.6430
Training Epoch: 36 [4096/50176]	Loss: 4.6470
Training Epoch: 36 [5120/50176]	Loss: 4.6288
Training Epoch: 36 [6144/50176]	Loss: 4.6411
Training Epoch: 36 [7168/50176]	Loss: 4.6516
Training Epoch: 36 [8192/50176]	Loss: 4.6469
Training Epoch: 36 [9216/50176]	Loss: 4.6300
Training Epoch: 36 [10240/50176]	Loss: 4.6350
Training Epoch: 36 [11264/50176]	Loss: 4.6282
Training Epoch: 36 [12288/50176]	Loss: 4.6286
Training Epoch: 36 [13312/50176]	Loss: 4.6331
Training Epoch: 36 [14336/50176]	Loss: 4.6390
Training Epoch: 36 [15360/50176]	Loss: 4.6452
Training Epoch: 36 [16384/50176]	Loss: 4.6407
Training Epoch: 36 [17408/50176]	Loss: 4.6393
Training Epoch: 36 [18432/50176]	Loss: 4.6414
Training Epoch: 36 [19456/50176]	Loss: 4.6440
Training Epoch: 36 [20480/50176]	Loss: 4.6361
Training Epoch: 36 [21504/50176]	Loss: 4.6551
Training Epoch: 36 [22528/50176]	Loss: 4.6359
Training Epoch: 36 [23552/50176]	Loss: 4.6187
Training Epoch: 36 [24576/50176]	Loss: 4.6355
Training Epoch: 36 [25600/50176]	Loss: 4.6400
Training Epoch: 36 [26624/50176]	Loss: 4.6531
Training Epoch: 36 [27648/50176]	Loss: 4.6275
Training Epoch: 36 [28672/50176]	Loss: 4.6321
Training Epoch: 36 [29696/50176]	Loss: 4.6342
Training Epoch: 36 [30720/50176]	Loss: 4.6498
Training Epoch: 36 [31744/50176]	Loss: 4.6312
Training Epoch: 36 [32768/50176]	Loss: 4.6423
Training Epoch: 36 [33792/50176]	Loss: 4.6305
Training Epoch: 36 [34816/50176]	Loss: 4.6198
Training Epoch: 36 [35840/50176]	Loss: 4.6355
Training Epoch: 36 [36864/50176]	Loss: 4.6188
Training Epoch: 36 [37888/50176]	Loss: 4.6450
Training Epoch: 36 [38912/50176]	Loss: 4.6425
Training Epoch: 36 [39936/50176]	Loss: 4.6356
Training Epoch: 36 [40960/50176]	Loss: 4.6395
Training Epoch: 36 [41984/50176]	Loss: 4.6184
Training Epoch: 36 [43008/50176]	Loss: 4.6366
Training Epoch: 36 [44032/50176]	Loss: 4.6301
Training Epoch: 36 [45056/50176]	Loss: 4.6388
Training Epoch: 36 [46080/50176]	Loss: 4.6480
Training Epoch: 36 [47104/50176]	Loss: 4.6441
Training Epoch: 36 [48128/50176]	Loss: 4.6482
Training Epoch: 36 [49152/50176]	Loss: 4.6350
Training Epoch: 36 [50176/50176]	Loss: 4.6323
2022-12-06 20:01:34.882 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:01:34,916 [ZeusDataLoader(eval)] eval epoch 37 done: time=3.74 energy=466.88
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Up to epoch 37: time=1775.15, energy=233166.48, cost=271909.11
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:01:34,916 [ZeusDataLoader(train)] Expected next epoch: time=1821.76, energy=239532.77, cost=279170.35
2022-12-06 15:01:34,917 [ZeusDataLoader(train)] Epoch 38 begin.
Validation Epoch: 36, Average loss: 66.7765, Accuracy: 0.0098
2022-12-06 15:01:35,163 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:01:35,164 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:01:35.167 [ZeusMonitor] Monitor started.
2022-12-06 20:01:35.168 [ZeusMonitor] Running indefinitely. 2022-12-06 20:01:35.168 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:01:35.168 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e38+gpu0.power.log
2022-12-06 15:02:18,673 [ZeusDataLoader(train)] train epoch 38 done: time=43.75 energy=5827.34
2022-12-06 15:02:18,676 [ZeusDataLoader(eval)] Epoch 38 begin.
Training Epoch: 37 [1024/50176]	Loss: 4.6245
Training Epoch: 37 [2048/50176]	Loss: 4.6399
Training Epoch: 37 [3072/50176]	Loss: 4.6392
Training Epoch: 37 [4096/50176]	Loss: 4.6442
Training Epoch: 37 [5120/50176]	Loss: 4.6506
Training Epoch: 37 [6144/50176]	Loss: 4.6235
Training Epoch: 37 [7168/50176]	Loss: 4.6309
Training Epoch: 37 [8192/50176]	Loss: 4.6372
Training Epoch: 37 [9216/50176]	Loss: 4.6260
Training Epoch: 37 [10240/50176]	Loss: 4.6317
Training Epoch: 37 [11264/50176]	Loss: 4.6272
Training Epoch: 37 [12288/50176]	Loss: 4.6320
Training Epoch: 37 [13312/50176]	Loss: 4.6257
Training Epoch: 37 [14336/50176]	Loss: 4.6458
Training Epoch: 37 [15360/50176]	Loss: 4.6466
Training Epoch: 37 [16384/50176]	Loss: 4.6294
Training Epoch: 37 [17408/50176]	Loss: 4.6333
Training Epoch: 37 [18432/50176]	Loss: 4.6160
Training Epoch: 37 [19456/50176]	Loss: 4.6276
Training Epoch: 37 [20480/50176]	Loss: 4.6512
Training Epoch: 37 [21504/50176]	Loss: 4.6330
Training Epoch: 37 [22528/50176]	Loss: 4.6704
Training Epoch: 37 [23552/50176]	Loss: 4.6471
Training Epoch: 37 [24576/50176]	Loss: 4.6342
Training Epoch: 37 [25600/50176]	Loss: 4.6373
Training Epoch: 37 [26624/50176]	Loss: 4.6388
Training Epoch: 37 [27648/50176]	Loss: 4.6562
Training Epoch: 37 [28672/50176]	Loss: 4.6422
Training Epoch: 37 [29696/50176]	Loss: 4.6303
Training Epoch: 37 [30720/50176]	Loss: 4.6403
Training Epoch: 37 [31744/50176]	Loss: 4.6484
Training Epoch: 37 [32768/50176]	Loss: 4.6367
Training Epoch: 37 [33792/50176]	Loss: 4.6430
Training Epoch: 37 [34816/50176]	Loss: 4.6285
Training Epoch: 37 [35840/50176]	Loss: 4.6353
Training Epoch: 37 [36864/50176]	Loss: 4.6425
Training Epoch: 37 [37888/50176]	Loss: 4.6654
Training Epoch: 37 [38912/50176]	Loss: 4.6371
Training Epoch: 37 [39936/50176]	Loss: 4.6327
Training Epoch: 37 [40960/50176]	Loss: 4.6327
Training Epoch: 37 [41984/50176]	Loss: 4.6348
Training Epoch: 37 [43008/50176]	Loss: 4.6393
Training Epoch: 37 [44032/50176]	Loss: 4.6424
Training Epoch: 37 [45056/50176]	Loss: 4.6447
Training Epoch: 37 [46080/50176]	Loss: 4.6335
Training Epoch: 37 [47104/50176]	Loss: 4.6470
Training Epoch: 37 [48128/50176]	Loss: 4.6375
Training Epoch: 37 [49152/50176]	Loss: 4.6535
Training Epoch: 37 [50176/50176]	Loss: 4.6331
2022-12-06 20:02:22.414 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:02:22,431 [ZeusDataLoader(eval)] eval epoch 38 done: time=3.75 energy=463.82
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Up to epoch 38: time=1822.65, energy=239457.63, cost=279210.50
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:02:22,431 [ZeusDataLoader(train)] Expected next epoch: time=1869.25, energy=245823.93, cost=286471.74
2022-12-06 15:02:22,432 [ZeusDataLoader(train)] Epoch 39 begin.
Validation Epoch: 37, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:02:22,675 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:02:22,676 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:02:22.678 [ZeusMonitor] Monitor started.
2022-12-06 20:02:22.678 [ZeusMonitor] Running indefinitely. 2022-12-06 20:02:22.678 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:02:22.678 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e39+gpu0.power.log
2022-12-06 15:03:06,332 [ZeusDataLoader(train)] train epoch 39 done: time=43.89 energy=5834.10
2022-12-06 15:03:06,335 [ZeusDataLoader(eval)] Epoch 39 begin.
Training Epoch: 38 [1024/50176]	Loss: 4.6304
Training Epoch: 38 [2048/50176]	Loss: 4.6327
Training Epoch: 38 [3072/50176]	Loss: 4.6390
Training Epoch: 38 [4096/50176]	Loss: 4.6419
Training Epoch: 38 [5120/50176]	Loss: 4.6408
Training Epoch: 38 [6144/50176]	Loss: 4.6303
Training Epoch: 38 [7168/50176]	Loss: 4.6409
Training Epoch: 38 [8192/50176]	Loss: 4.6319
Training Epoch: 38 [9216/50176]	Loss: 4.6401
Training Epoch: 38 [10240/50176]	Loss: 4.6296
Training Epoch: 38 [11264/50176]	Loss: 4.6402
Training Epoch: 38 [12288/50176]	Loss: 4.6399
Training Epoch: 38 [13312/50176]	Loss: 4.6340
Training Epoch: 38 [14336/50176]	Loss: 4.6374
Training Epoch: 38 [15360/50176]	Loss: 4.6420
Training Epoch: 38 [16384/50176]	Loss: 4.6466
Training Epoch: 38 [17408/50176]	Loss: 4.6322
Training Epoch: 38 [18432/50176]	Loss: 4.6469
Training Epoch: 38 [19456/50176]	Loss: 4.6322
Training Epoch: 38 [20480/50176]	Loss: 4.6258
Training Epoch: 38 [21504/50176]	Loss: 4.6437
Training Epoch: 38 [22528/50176]	Loss: 4.6651
Training Epoch: 38 [23552/50176]	Loss: 4.6352
Training Epoch: 38 [24576/50176]	Loss: 4.6461
Training Epoch: 38 [25600/50176]	Loss: 4.6510
Training Epoch: 38 [26624/50176]	Loss: 4.6328
Training Epoch: 38 [27648/50176]	Loss: 4.6485
Training Epoch: 38 [28672/50176]	Loss: 4.6497
Training Epoch: 38 [29696/50176]	Loss: 4.6496
Training Epoch: 38 [30720/50176]	Loss: 4.6406
Training Epoch: 38 [31744/50176]	Loss: 4.6303
Training Epoch: 38 [32768/50176]	Loss: 4.6455
Training Epoch: 38 [33792/50176]	Loss: 4.6538
Training Epoch: 38 [34816/50176]	Loss: 4.6383
Training Epoch: 38 [35840/50176]	Loss: 4.6388
Training Epoch: 38 [36864/50176]	Loss: 4.6294
Training Epoch: 38 [37888/50176]	Loss: 4.6411
Training Epoch: 38 [38912/50176]	Loss: 4.6394
Training Epoch: 38 [39936/50176]	Loss: 4.6445
Training Epoch: 38 [40960/50176]	Loss: 4.6661
Training Epoch: 38 [41984/50176]	Loss: 4.6518
Training Epoch: 38 [43008/50176]	Loss: 4.6482
Training Epoch: 38 [44032/50176]	Loss: 4.6442
Training Epoch: 38 [45056/50176]	Loss: 4.6510
Training Epoch: 38 [46080/50176]	Loss: 4.6398
Training Epoch: 38 [47104/50176]	Loss: 4.6523
Training Epoch: 38 [48128/50176]	Loss: 4.6372
Training Epoch: 38 [49152/50176]	Loss: 4.6533
Training Epoch: 38 [50176/50176]	Loss: 4.6413
2022-12-06 20:03:10.063 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:03:10,079 [ZeusDataLoader(eval)] eval epoch 39 done: time=3.74 energy=462.53
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Up to epoch 39: time=1870.27, energy=245754.27, cost=286526.17
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:03:10,079 [ZeusDataLoader(train)] Expected next epoch: time=1916.88, energy=252120.56, cost=293787.41
2022-12-06 15:03:10,080 [ZeusDataLoader(train)] Epoch 40 begin.
Validation Epoch: 38, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:03:10,334 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:03:10,334 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:03:10.336 [ZeusMonitor] Monitor started.
2022-12-06 20:03:10.336 [ZeusMonitor] Running indefinitely. 2022-12-06 20:03:10.336 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:03:10.336 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e40+gpu0.power.log
2022-12-06 15:03:53,817 [ZeusDataLoader(train)] train epoch 40 done: time=43.73 energy=5824.47
2022-12-06 15:03:53,821 [ZeusDataLoader(eval)] Epoch 40 begin.
Training Epoch: 39 [1024/50176]	Loss: 4.6516
Training Epoch: 39 [2048/50176]	Loss: 4.6252
Training Epoch: 39 [3072/50176]	Loss: 4.6538
Training Epoch: 39 [4096/50176]	Loss: 4.6497
Training Epoch: 39 [5120/50176]	Loss: 4.6476
Training Epoch: 39 [6144/50176]	Loss: 4.6446
Training Epoch: 39 [7168/50176]	Loss: 4.6487
Training Epoch: 39 [8192/50176]	Loss: 4.6275
Training Epoch: 39 [9216/50176]	Loss: 4.6527
Training Epoch: 39 [10240/50176]	Loss: 4.6510
Training Epoch: 39 [11264/50176]	Loss: 4.6525
Training Epoch: 39 [12288/50176]	Loss: 4.6555
Training Epoch: 39 [13312/50176]	Loss: 4.6406
Training Epoch: 39 [14336/50176]	Loss: 4.6306
Training Epoch: 39 [15360/50176]	Loss: 4.6433
Training Epoch: 39 [16384/50176]	Loss: 4.6484
Training Epoch: 39 [17408/50176]	Loss: 4.6185
Training Epoch: 39 [18432/50176]	Loss: 4.6455
Training Epoch: 39 [19456/50176]	Loss: 4.6591
Training Epoch: 39 [20480/50176]	Loss: 4.6407
Training Epoch: 39 [21504/50176]	Loss: 4.6466
Training Epoch: 39 [22528/50176]	Loss: 4.6362
Training Epoch: 39 [23552/50176]	Loss: 4.6237
Training Epoch: 39 [24576/50176]	Loss: 4.6352
Training Epoch: 39 [25600/50176]	Loss: 4.6370
Training Epoch: 39 [26624/50176]	Loss: 4.6361
Training Epoch: 39 [27648/50176]	Loss: 4.6461
Training Epoch: 39 [28672/50176]	Loss: 4.6402
Training Epoch: 39 [29696/50176]	Loss: 4.6313
Training Epoch: 39 [30720/50176]	Loss: 4.6338
Training Epoch: 39 [31744/50176]	Loss: 4.6296
Training Epoch: 39 [32768/50176]	Loss: 4.6486
Training Epoch: 39 [33792/50176]	Loss: 4.6349
Training Epoch: 39 [34816/50176]	Loss: 4.6300
Training Epoch: 39 [35840/50176]	Loss: 4.6422
Training Epoch: 39 [36864/50176]	Loss: 4.6298
Training Epoch: 39 [37888/50176]	Loss: 4.6465
Training Epoch: 39 [38912/50176]	Loss: 4.6422
Training Epoch: 39 [39936/50176]	Loss: 4.6292
Training Epoch: 39 [40960/50176]	Loss: 4.6497
Training Epoch: 39 [41984/50176]	Loss: 4.6347
Training Epoch: 39 [43008/50176]	Loss: 4.6258
Training Epoch: 39 [44032/50176]	Loss: 4.6275
Training Epoch: 39 [45056/50176]	Loss: 4.6303
Training Epoch: 39 [46080/50176]	Loss: 4.6403
Training Epoch: 39 [47104/50176]	Loss: 4.6384
Training Epoch: 39 [48128/50176]	Loss: 4.6429
Training Epoch: 39 [49152/50176]	Loss: 4.6396
Training Epoch: 39 [50176/50176]	Loss: 4.6485
2022-12-06 20:03:57.562 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:03:57,583 [ZeusDataLoader(eval)] eval epoch 40 done: time=3.75 energy=463.45
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Up to epoch 40: time=1917.76, energy=252042.19, cost=293824.95
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:03:57,583 [ZeusDataLoader(train)] Expected next epoch: time=1964.37, energy=258408.49, cost=301086.18
2022-12-06 15:03:57,584 [ZeusDataLoader(train)] Epoch 41 begin.
Validation Epoch: 39, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:03:57,777 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:03:57,778 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:03:57.781 [ZeusMonitor] Monitor started.
2022-12-06 20:03:57.781 [ZeusMonitor] Running indefinitely. 2022-12-06 20:03:57.781 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:03:57.781 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e41+gpu0.power.log
2022-12-06 15:04:41,323 [ZeusDataLoader(train)] train epoch 41 done: time=43.73 energy=5825.69
2022-12-06 15:04:41,326 [ZeusDataLoader(eval)] Epoch 41 begin.
Training Epoch: 40 [1024/50176]	Loss: 4.6429
Training Epoch: 40 [2048/50176]	Loss: 4.6346
Training Epoch: 40 [3072/50176]	Loss: 4.6345
Training Epoch: 40 [4096/50176]	Loss: 4.6227
Training Epoch: 40 [5120/50176]	Loss: 4.6375
Training Epoch: 40 [6144/50176]	Loss: 4.6462
Training Epoch: 40 [7168/50176]	Loss: 4.6440
Training Epoch: 40 [8192/50176]	Loss: 4.6339
Training Epoch: 40 [9216/50176]	Loss: 4.6352
Training Epoch: 40 [10240/50176]	Loss: 4.6286
Training Epoch: 40 [11264/50176]	Loss: 4.6381
Training Epoch: 40 [12288/50176]	Loss: 4.6286
Training Epoch: 40 [13312/50176]	Loss: 4.6267
Training Epoch: 40 [14336/50176]	Loss: 4.6306
Training Epoch: 40 [15360/50176]	Loss: 4.6322
Training Epoch: 40 [16384/50176]	Loss: 4.6332
Training Epoch: 40 [17408/50176]	Loss: 4.6345
Training Epoch: 40 [18432/50176]	Loss: 4.6394
Training Epoch: 40 [19456/50176]	Loss: 4.6421
Training Epoch: 40 [20480/50176]	Loss: 4.6261
Training Epoch: 40 [21504/50176]	Loss: 4.6259
Training Epoch: 40 [22528/50176]	Loss: 4.6329
Training Epoch: 40 [23552/50176]	Loss: 4.6379
Training Epoch: 40 [24576/50176]	Loss: 4.6311
Training Epoch: 40 [25600/50176]	Loss: 4.6199
Training Epoch: 40 [26624/50176]	Loss: 4.6459
Training Epoch: 40 [27648/50176]	Loss: 4.6296
Training Epoch: 40 [28672/50176]	Loss: 4.6362
Training Epoch: 40 [29696/50176]	Loss: 4.6402
Training Epoch: 40 [30720/50176]	Loss: 4.6357
Training Epoch: 40 [31744/50176]	Loss: 4.6199
Training Epoch: 40 [32768/50176]	Loss: 4.6241
Training Epoch: 40 [33792/50176]	Loss: 4.6411
Training Epoch: 40 [34816/50176]	Loss: 4.6403
Training Epoch: 40 [35840/50176]	Loss: 4.6495
Training Epoch: 40 [36864/50176]	Loss: 4.6456
Training Epoch: 40 [37888/50176]	Loss: 4.6387
Training Epoch: 40 [38912/50176]	Loss: 4.6438
Training Epoch: 40 [39936/50176]	Loss: 4.6331
Training Epoch: 40 [40960/50176]	Loss: 4.6518
Training Epoch: 40 [41984/50176]	Loss: 4.6456
Training Epoch: 40 [43008/50176]	Loss: 4.6356
Training Epoch: 40 [44032/50176]	Loss: 4.6346
Training Epoch: 40 [45056/50176]	Loss: 4.6371
Training Epoch: 40 [46080/50176]	Loss: 4.6447
Training Epoch: 40 [47104/50176]	Loss: 4.6337
Training Epoch: 40 [48128/50176]	Loss: 4.6358
Training Epoch: 40 [49152/50176]	Loss: 4.6338
Training Epoch: 40 [50176/50176]	Loss: 4.6297
2022-12-06 20:04:45.076 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:04:45,122 [ZeusDataLoader(eval)] eval epoch 41 done: time=3.79 energy=468.24
2022-12-06 15:04:45,122 [ZeusDataLoader(train)] Up to epoch 41: time=1965.28, energy=258336.12, cost=301129.81
2022-12-06 15:04:45,123 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:04:45,123 [ZeusDataLoader(train)] Expected next epoch: time=2011.88, energy=264702.41, cost=308391.04
2022-12-06 15:04:45,124 [ZeusDataLoader(train)] Epoch 42 begin.
Validation Epoch: 40, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:04:45,375 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:04:45,376 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:04:45.377 [ZeusMonitor] Monitor started.
2022-12-06 20:04:45.378 [ZeusMonitor] Running indefinitely. 2022-12-06 20:04:45.378 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:04:45.378 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e42+gpu0.power.log
2022-12-06 15:05:29,098 [ZeusDataLoader(train)] train epoch 42 done: time=43.97 energy=5846.00
2022-12-06 15:05:29,101 [ZeusDataLoader(eval)] Epoch 42 begin.
Training Epoch: 41 [1024/50176]	Loss: 4.6501
Training Epoch: 41 [2048/50176]	Loss: 4.6260
Training Epoch: 41 [3072/50176]	Loss: 4.6350
Training Epoch: 41 [4096/50176]	Loss: 4.6244
Training Epoch: 41 [5120/50176]	Loss: 4.6321
Training Epoch: 41 [6144/50176]	Loss: 4.6376
Training Epoch: 41 [7168/50176]	Loss: 4.6452
Training Epoch: 41 [8192/50176]	Loss: 4.6262
Training Epoch: 41 [9216/50176]	Loss: 4.6307
Training Epoch: 41 [10240/50176]	Loss: 4.6442
Training Epoch: 41 [11264/50176]	Loss: 4.6319
Training Epoch: 41 [12288/50176]	Loss: 4.6398
Training Epoch: 41 [13312/50176]	Loss: 4.6600
Training Epoch: 41 [14336/50176]	Loss: 4.6485
Training Epoch: 41 [15360/50176]	Loss: 4.6416
Training Epoch: 41 [16384/50176]	Loss: 4.6568
Training Epoch: 41 [17408/50176]	Loss: 4.6418
Training Epoch: 41 [18432/50176]	Loss: 4.6238
Training Epoch: 41 [19456/50176]	Loss: 4.6357
Training Epoch: 41 [20480/50176]	Loss: 4.6309
Training Epoch: 41 [21504/50176]	Loss: 4.6377
Training Epoch: 41 [22528/50176]	Loss: 4.6516
Training Epoch: 41 [23552/50176]	Loss: 4.6618
Training Epoch: 41 [24576/50176]	Loss: 4.6431
Training Epoch: 41 [25600/50176]	Loss: 4.6377
Training Epoch: 41 [26624/50176]	Loss: 4.6204
Training Epoch: 41 [27648/50176]	Loss: 4.6342
Training Epoch: 41 [28672/50176]	Loss: 4.6540
Training Epoch: 41 [29696/50176]	Loss: 4.6373
Training Epoch: 41 [30720/50176]	Loss: 4.6439
Training Epoch: 41 [31744/50176]	Loss: 4.6419
Training Epoch: 41 [32768/50176]	Loss: 4.6355
Training Epoch: 41 [33792/50176]	Loss: 4.6351
Training Epoch: 41 [34816/50176]	Loss: 4.6323
Training Epoch: 41 [35840/50176]	Loss: 4.6446
Training Epoch: 41 [36864/50176]	Loss: 4.6474
Training Epoch: 41 [37888/50176]	Loss: 4.6368
Training Epoch: 41 [38912/50176]	Loss: 4.6409
Training Epoch: 41 [39936/50176]	Loss: 4.6507
Training Epoch: 41 [40960/50176]	Loss: 4.6437
Training Epoch: 41 [41984/50176]	Loss: 4.6442
Training Epoch: 41 [43008/50176]	Loss: 4.6356
Training Epoch: 41 [44032/50176]	Loss: 4.6508
Training Epoch: 41 [45056/50176]	Loss: 4.6353
Training Epoch: 41 [46080/50176]	Loss: 4.6403
Training Epoch: 41 [47104/50176]	Loss: 4.6315
Training Epoch: 41 [48128/50176]	Loss: 4.6347
Training Epoch: 41 [49152/50176]	Loss: 4.6378
Training Epoch: 41 [50176/50176]	Loss: 4.6364
2022-12-06 20:05:32.870 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:05:32,915 [ZeusDataLoader(eval)] eval epoch 42 done: time=3.81 energy=480.13
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Up to epoch 42: time=2013.05, energy=264662.25, cost=308472.94
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:05:32,915 [ZeusDataLoader(train)] Expected next epoch: time=2059.66, energy=271028.54, cost=315734.18
2022-12-06 15:05:32,916 [ZeusDataLoader(train)] Epoch 43 begin.
Validation Epoch: 41, Average loss: 401.2048, Accuracy: 0.0098
2022-12-06 15:05:33,153 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:05:33,154 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:05:33.156 [ZeusMonitor] Monitor started.
2022-12-06 20:05:33.156 [ZeusMonitor] Running indefinitely. 2022-12-06 20:05:33.156 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:05:33.156 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e43+gpu0.power.log
2022-12-06 15:06:16,941 [ZeusDataLoader(train)] train epoch 43 done: time=44.02 energy=5834.75
2022-12-06 15:06:16,944 [ZeusDataLoader(eval)] Epoch 43 begin.
Training Epoch: 42 [1024/50176]	Loss: 4.6342
Training Epoch: 42 [2048/50176]	Loss: 4.6369
Training Epoch: 42 [3072/50176]	Loss: 4.6416
Training Epoch: 42 [4096/50176]	Loss: 4.6467
Training Epoch: 42 [5120/50176]	Loss: 4.6531
Training Epoch: 42 [6144/50176]	Loss: 4.6442
Training Epoch: 42 [7168/50176]	Loss: 4.6338
Training Epoch: 42 [8192/50176]	Loss: 4.6371
Training Epoch: 42 [9216/50176]	Loss: 4.6428
Training Epoch: 42 [10240/50176]	Loss: 4.6368
Training Epoch: 42 [11264/50176]	Loss: 4.6537
Training Epoch: 42 [12288/50176]	Loss: 4.6317
Training Epoch: 42 [13312/50176]	Loss: 4.6320
Training Epoch: 42 [14336/50176]	Loss: 4.6595
Training Epoch: 42 [15360/50176]	Loss: 4.6351
Training Epoch: 42 [16384/50176]	Loss: 4.6196
Training Epoch: 42 [17408/50176]	Loss: 4.6382
Training Epoch: 42 [18432/50176]	Loss: 4.6600
Training Epoch: 42 [19456/50176]	Loss: 4.6508
Training Epoch: 42 [20480/50176]	Loss: 4.6374
Training Epoch: 42 [21504/50176]	Loss: 4.6392
Training Epoch: 42 [22528/50176]	Loss: 4.6318
Training Epoch: 42 [23552/50176]	Loss: 4.6341
Training Epoch: 42 [24576/50176]	Loss: 4.6368
Training Epoch: 42 [25600/50176]	Loss: 4.6523
Training Epoch: 42 [26624/50176]	Loss: 4.6400
Training Epoch: 42 [27648/50176]	Loss: 4.6279
Training Epoch: 42 [28672/50176]	Loss: 4.6158
Training Epoch: 42 [29696/50176]	Loss: 4.6520
Training Epoch: 42 [30720/50176]	Loss: 4.6427
Training Epoch: 42 [31744/50176]	Loss: 4.6388
Training Epoch: 42 [32768/50176]	Loss: 4.6390
Training Epoch: 42 [33792/50176]	Loss: 4.6295
Training Epoch: 42 [34816/50176]	Loss: 4.6304
Training Epoch: 42 [35840/50176]	Loss: 4.6412
Training Epoch: 42 [36864/50176]	Loss: 4.6423
Training Epoch: 42 [37888/50176]	Loss: 4.6258
Training Epoch: 42 [38912/50176]	Loss: 4.6320
Training Epoch: 42 [39936/50176]	Loss: 4.6306
Training Epoch: 42 [40960/50176]	Loss: 4.6295
Training Epoch: 42 [41984/50176]	Loss: 4.6351
Training Epoch: 42 [43008/50176]	Loss: 4.6311
Training Epoch: 42 [44032/50176]	Loss: 4.6294
Training Epoch: 42 [45056/50176]	Loss: 4.6299
Training Epoch: 42 [46080/50176]	Loss: 4.6364
Training Epoch: 42 [47104/50176]	Loss: 4.6470
Training Epoch: 42 [48128/50176]	Loss: 4.6292
Training Epoch: 42 [49152/50176]	Loss: 4.6269
Training Epoch: 42 [50176/50176]	Loss: 4.6287
2022-12-06 20:06:20.721 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:06:20,768 [ZeusDataLoader(eval)] eval epoch 43 done: time=3.82 energy=477.27
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Up to epoch 43: time=2060.88, energy=270974.26, cost=315814.30
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:06:20,769 [ZeusDataLoader(train)] Expected next epoch: time=2107.49, energy=277340.56, cost=323075.54
2022-12-06 15:06:20,770 [ZeusDataLoader(train)] Epoch 44 begin.
Validation Epoch: 42, Average loss: 6442.1594, Accuracy: 0.0098
2022-12-06 15:06:21,018 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:06:21,019 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:06:21.021 [ZeusMonitor] Monitor started.
2022-12-06 20:06:21.021 [ZeusMonitor] Running indefinitely. 2022-12-06 20:06:21.021 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:06:21.021 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e44+gpu0.power.log
2022-12-06 15:07:04,461 [ZeusDataLoader(train)] train epoch 44 done: time=43.68 energy=5820.78
2022-12-06 15:07:04,465 [ZeusDataLoader(eval)] Epoch 44 begin.
Training Epoch: 43 [1024/50176]	Loss: 4.6293
Training Epoch: 43 [2048/50176]	Loss: 4.6420
Training Epoch: 43 [3072/50176]	Loss: 4.6394
Training Epoch: 43 [4096/50176]	Loss: 4.6297
Training Epoch: 43 [5120/50176]	Loss: 4.6239
Training Epoch: 43 [6144/50176]	Loss: 4.6333
Training Epoch: 43 [7168/50176]	Loss: 4.6268
Training Epoch: 43 [8192/50176]	Loss: 4.6329
Training Epoch: 43 [9216/50176]	Loss: 4.6303
Training Epoch: 43 [10240/50176]	Loss: 4.6378
Training Epoch: 43 [11264/50176]	Loss: 4.6419
Training Epoch: 43 [12288/50176]	Loss: 4.6389
Training Epoch: 43 [13312/50176]	Loss: 4.6262
Training Epoch: 43 [14336/50176]	Loss: 4.6402
Training Epoch: 43 [15360/50176]	Loss: 4.6422
Training Epoch: 43 [16384/50176]	Loss: 4.6368
Training Epoch: 43 [17408/50176]	Loss: 4.6300
Training Epoch: 43 [18432/50176]	Loss: 4.6514
Training Epoch: 43 [19456/50176]	Loss: 4.6416
Training Epoch: 43 [20480/50176]	Loss: 4.6358
Training Epoch: 43 [21504/50176]	Loss: 4.6418
Training Epoch: 43 [22528/50176]	Loss: 4.6287
Training Epoch: 43 [23552/50176]	Loss: 4.6305
Training Epoch: 43 [24576/50176]	Loss: 4.6478
Training Epoch: 43 [25600/50176]	Loss: 4.6447
Training Epoch: 43 [26624/50176]	Loss: 4.6200
Training Epoch: 43 [27648/50176]	Loss: 4.6427
Training Epoch: 43 [28672/50176]	Loss: 4.6343
Training Epoch: 43 [29696/50176]	Loss: 4.6157
Training Epoch: 43 [30720/50176]	Loss: 4.6382
Training Epoch: 43 [31744/50176]	Loss: 4.6309
Training Epoch: 43 [32768/50176]	Loss: 4.6446
Training Epoch: 43 [33792/50176]	Loss: 4.6429
Training Epoch: 43 [34816/50176]	Loss: 4.6390
Training Epoch: 43 [35840/50176]	Loss: 4.6214
Training Epoch: 43 [36864/50176]	Loss: 4.6270
Training Epoch: 43 [37888/50176]	Loss: 4.6381
Training Epoch: 43 [38912/50176]	Loss: 4.6435
Training Epoch: 43 [39936/50176]	Loss: 4.6422
Training Epoch: 43 [40960/50176]	Loss: 4.6469
Training Epoch: 43 [41984/50176]	Loss: 4.6461
Training Epoch: 43 [43008/50176]	Loss: 4.6264
Training Epoch: 43 [44032/50176]	Loss: 4.6347
Training Epoch: 43 [45056/50176]	Loss: 4.6200
Training Epoch: 43 [46080/50176]	Loss: 4.6331
Training Epoch: 43 [47104/50176]	Loss: 4.6405
Training Epoch: 43 [48128/50176]	Loss: 4.6410
Training Epoch: 43 [49152/50176]	Loss: 4.6502
Training Epoch: 43 [50176/50176]	Loss: 4.6458
2022-12-06 20:07:08.218 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:07:08,227 [ZeusDataLoader(eval)] eval epoch 44 done: time=3.75 energy=462.07
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Up to epoch 44: time=2108.32, energy=277257.11, cost=323106.56
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:07:08,228 [ZeusDataLoader(train)] Expected next epoch: time=2154.93, energy=283623.40, cost=330367.80
2022-12-06 15:07:08,229 [ZeusDataLoader(train)] Epoch 45 begin.
Validation Epoch: 43, Average loss: 0.0045, Accuracy: 0.0097
2022-12-06 15:07:08,463 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:07:08,464 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:07:08.478 [ZeusMonitor] Monitor started.
2022-12-06 20:07:08.478 [ZeusMonitor] Running indefinitely. 2022-12-06 20:07:08.478 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:07:08.478 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e45+gpu0.power.log
2022-12-06 15:07:51,992 [ZeusDataLoader(train)] train epoch 45 done: time=43.75 energy=5824.97
2022-12-06 15:07:51,995 [ZeusDataLoader(eval)] Epoch 45 begin.
Training Epoch: 44 [1024/50176]	Loss: 4.6368
Training Epoch: 44 [2048/50176]	Loss: 4.6273
Training Epoch: 44 [3072/50176]	Loss: 4.6218
Training Epoch: 44 [4096/50176]	Loss: 4.6299
Training Epoch: 44 [5120/50176]	Loss: 4.6429
Training Epoch: 44 [6144/50176]	Loss: 4.6475
Training Epoch: 44 [7168/50176]	Loss: 4.6329
Training Epoch: 44 [8192/50176]	Loss: 4.6460
Training Epoch: 44 [9216/50176]	Loss: 4.6257
Training Epoch: 44 [10240/50176]	Loss: 4.6414
Training Epoch: 44 [11264/50176]	Loss: 4.6266
Training Epoch: 44 [12288/50176]	Loss: 4.6382
Training Epoch: 44 [13312/50176]	Loss: 4.6273
Training Epoch: 44 [14336/50176]	Loss: 4.6254
Training Epoch: 44 [15360/50176]	Loss: 4.6396
Training Epoch: 44 [16384/50176]	Loss: 4.6405
Training Epoch: 44 [17408/50176]	Loss: 4.6372
Training Epoch: 44 [18432/50176]	Loss: 4.6428
Training Epoch: 44 [19456/50176]	Loss: 4.6260
Training Epoch: 44 [20480/50176]	Loss: 4.6323
Training Epoch: 44 [21504/50176]	Loss: 4.6344
Training Epoch: 44 [22528/50176]	Loss: 4.6197
Training Epoch: 44 [23552/50176]	Loss: 4.6298
Training Epoch: 44 [24576/50176]	Loss: 4.6349
Training Epoch: 44 [25600/50176]	Loss: 4.6429
Training Epoch: 44 [26624/50176]	Loss: 4.6322
Training Epoch: 44 [27648/50176]	Loss: 4.6264
Training Epoch: 44 [28672/50176]	Loss: 4.6295
Training Epoch: 44 [29696/50176]	Loss: 4.6443
Training Epoch: 44 [30720/50176]	Loss: 4.6227
Training Epoch: 44 [31744/50176]	Loss: 4.6343
Training Epoch: 44 [32768/50176]	Loss: 4.6413
Training Epoch: 44 [33792/50176]	Loss: 4.6348
Training Epoch: 44 [34816/50176]	Loss: 4.6195
Training Epoch: 44 [35840/50176]	Loss: 4.6315
Training Epoch: 44 [36864/50176]	Loss: 4.6425
Training Epoch: 44 [37888/50176]	Loss: 4.6347
Training Epoch: 44 [38912/50176]	Loss: 4.6292
Training Epoch: 44 [39936/50176]	Loss: 4.6268
Training Epoch: 44 [40960/50176]	Loss: 4.6370
Training Epoch: 44 [41984/50176]	Loss: 4.6310
Training Epoch: 44 [43008/50176]	Loss: 4.6351
Training Epoch: 44 [44032/50176]	Loss: 4.6278
Training Epoch: 44 [45056/50176]	Loss: 4.6373
Training Epoch: 44 [46080/50176]	Loss: 4.6384
Training Epoch: 44 [47104/50176]	Loss: 4.6503
Training Epoch: 44 [48128/50176]	Loss: 4.6286
Training Epoch: 44 [49152/50176]	Loss: 4.6640
Training Epoch: 44 [50176/50176]	Loss: 4.6331
2022-12-06 20:07:55.758 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:07:55,815 [ZeusDataLoader(eval)] eval epoch 45 done: time=3.81 energy=480.48
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Up to epoch 45: time=2155.89, energy=283562.55, cost=330421.37
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:07:55,815 [ZeusDataLoader(train)] Expected next epoch: time=2202.49, energy=289928.85, cost=337682.60
2022-12-06 15:07:55,816 [ZeusDataLoader(train)] Epoch 46 begin.
Validation Epoch: 44, Average loss: 313.6202, Accuracy: 0.0098
2022-12-06 15:07:56,071 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:07:56,071 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:07:56.073 [ZeusMonitor] Monitor started.
2022-12-06 20:07:56.073 [ZeusMonitor] Running indefinitely. 2022-12-06 20:07:56.073 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:07:56.073 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e46+gpu0.power.log
2022-12-06 15:08:39,720 [ZeusDataLoader(train)] train epoch 46 done: time=43.90 energy=5833.35
2022-12-06 15:08:39,724 [ZeusDataLoader(eval)] Epoch 46 begin.
Training Epoch: 45 [1024/50176]	Loss: 4.6390
Training Epoch: 45 [2048/50176]	Loss: 4.6320
Training Epoch: 45 [3072/50176]	Loss: 4.6242
Training Epoch: 45 [4096/50176]	Loss: 4.6595
Training Epoch: 45 [5120/50176]	Loss: 4.6302
Training Epoch: 45 [6144/50176]	Loss: 4.6495
Training Epoch: 45 [7168/50176]	Loss: 4.6370
Training Epoch: 45 [8192/50176]	Loss: 4.6371
Training Epoch: 45 [9216/50176]	Loss: 4.6468
Training Epoch: 45 [10240/50176]	Loss: 4.6310
Training Epoch: 45 [11264/50176]	Loss: 4.6430
Training Epoch: 45 [12288/50176]	Loss: 4.6347
Training Epoch: 45 [13312/50176]	Loss: 4.6406
Training Epoch: 45 [14336/50176]	Loss: 4.6350
Training Epoch: 45 [15360/50176]	Loss: 4.6304
Training Epoch: 45 [16384/50176]	Loss: 4.6473
Training Epoch: 45 [17408/50176]	Loss: 4.6346
Training Epoch: 45 [18432/50176]	Loss: 4.6329
Training Epoch: 45 [19456/50176]	Loss: 4.6380
Training Epoch: 45 [20480/50176]	Loss: 4.6360
Training Epoch: 45 [21504/50176]	Loss: 4.6424
Training Epoch: 45 [22528/50176]	Loss: 4.6477
Training Epoch: 45 [23552/50176]	Loss: 4.6232
Training Epoch: 45 [24576/50176]	Loss: 4.6336
Training Epoch: 45 [25600/50176]	Loss: 4.6441
Training Epoch: 45 [26624/50176]	Loss: 4.6308
Training Epoch: 45 [27648/50176]	Loss: 4.6370
Training Epoch: 45 [28672/50176]	Loss: 4.6383
Training Epoch: 45 [29696/50176]	Loss: 4.6488
Training Epoch: 45 [30720/50176]	Loss: 4.6434
Training Epoch: 45 [31744/50176]	Loss: 4.6382
Training Epoch: 45 [32768/50176]	Loss: 4.6290
Training Epoch: 45 [33792/50176]	Loss: 4.6497
Training Epoch: 45 [34816/50176]	Loss: 4.6498
Training Epoch: 45 [35840/50176]	Loss: 4.6359
Training Epoch: 45 [36864/50176]	Loss: 4.6372
Training Epoch: 45 [37888/50176]	Loss: 4.6308
Training Epoch: 45 [38912/50176]	Loss: 4.6488
Training Epoch: 45 [39936/50176]	Loss: 4.6506
Training Epoch: 45 [40960/50176]	Loss: 4.6344
Training Epoch: 45 [41984/50176]	Loss: 4.6363
Training Epoch: 45 [43008/50176]	Loss: 4.6399
Training Epoch: 45 [44032/50176]	Loss: 4.6348
Training Epoch: 45 [45056/50176]	Loss: 4.6517
Training Epoch: 45 [46080/50176]	Loss: 4.6375
Training Epoch: 45 [47104/50176]	Loss: 4.6428
Training Epoch: 45 [48128/50176]	Loss: 4.6470
Training Epoch: 45 [49152/50176]	Loss: 4.6463
Training Epoch: 45 [50176/50176]	Loss: 4.6325
2022-12-06 20:08:43.520 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:08:43,563 [ZeusDataLoader(eval)] eval epoch 46 done: time=3.83 energy=475.26
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Up to epoch 46: time=2203.61, energy=289871.17, cost=337751.79
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:08:43,563 [ZeusDataLoader(train)] Expected next epoch: time=2250.22, energy=296237.46, cost=345013.03
2022-12-06 15:08:43,564 [ZeusDataLoader(train)] Epoch 47 begin.
Validation Epoch: 45, Average loss: 15715.4555, Accuracy: 0.0098
2022-12-06 15:08:43,774 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:08:43,774 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:08:43.776 [ZeusMonitor] Monitor started.
2022-12-06 20:08:43.776 [ZeusMonitor] Running indefinitely. 2022-12-06 20:08:43.776 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:08:43.777 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e47+gpu0.power.log
2022-12-06 15:09:27,340 [ZeusDataLoader(train)] train epoch 47 done: time=43.77 energy=5832.95
2022-12-06 15:09:27,344 [ZeusDataLoader(eval)] Epoch 47 begin.
Training Epoch: 46 [1024/50176]	Loss: 4.6333
Training Epoch: 46 [2048/50176]	Loss: 4.6488
Training Epoch: 46 [3072/50176]	Loss: 4.6532
Training Epoch: 46 [4096/50176]	Loss: 4.6295
Training Epoch: 46 [5120/50176]	Loss: 4.6417
Training Epoch: 46 [6144/50176]	Loss: 4.6413
Training Epoch: 46 [7168/50176]	Loss: 4.6436
Training Epoch: 46 [8192/50176]	Loss: 4.6355
Training Epoch: 46 [9216/50176]	Loss: 4.6420
Training Epoch: 46 [10240/50176]	Loss: 4.6407
Training Epoch: 46 [11264/50176]	Loss: 4.6259
Training Epoch: 46 [12288/50176]	Loss: 4.6301
Training Epoch: 46 [13312/50176]	Loss: 4.6331
Training Epoch: 46 [14336/50176]	Loss: 4.6378
Training Epoch: 46 [15360/50176]	Loss: 4.6183
Training Epoch: 46 [16384/50176]	Loss: 4.6351
Training Epoch: 46 [17408/50176]	Loss: 4.6310
Training Epoch: 46 [18432/50176]	Loss: 4.6295
Training Epoch: 46 [19456/50176]	Loss: 4.6227
Training Epoch: 46 [20480/50176]	Loss: 4.6378
Training Epoch: 46 [21504/50176]	Loss: 4.6352
Training Epoch: 46 [22528/50176]	Loss: 4.6342
Training Epoch: 46 [23552/50176]	Loss: 4.6421
Training Epoch: 46 [24576/50176]	Loss: 4.6426
Training Epoch: 46 [25600/50176]	Loss: 4.6359
Training Epoch: 46 [26624/50176]	Loss: 4.6345
Training Epoch: 46 [27648/50176]	Loss: 4.6417
Training Epoch: 46 [28672/50176]	Loss: 4.6350
Training Epoch: 46 [29696/50176]	Loss: 4.6361
Training Epoch: 46 [30720/50176]	Loss: 4.6485
Training Epoch: 46 [31744/50176]	Loss: 4.6377
Training Epoch: 46 [32768/50176]	Loss: 4.6325
Training Epoch: 46 [33792/50176]	Loss: 4.6244
Training Epoch: 46 [34816/50176]	Loss: 4.6259
Training Epoch: 46 [35840/50176]	Loss: 4.6332
Training Epoch: 46 [36864/50176]	Loss: 4.6477
Training Epoch: 46 [37888/50176]	Loss: 4.6415
Training Epoch: 46 [38912/50176]	Loss: 4.6374
Training Epoch: 46 [39936/50176]	Loss: 4.6175
Training Epoch: 46 [40960/50176]	Loss: 4.6460
Training Epoch: 46 [41984/50176]	Loss: 4.6339
Training Epoch: 46 [43008/50176]	Loss: 4.6448
Training Epoch: 46 [44032/50176]	Loss: 4.6331
Training Epoch: 46 [45056/50176]	Loss: 4.6418
Training Epoch: 46 [46080/50176]	Loss: 4.6465
Training Epoch: 46 [47104/50176]	Loss: 4.6320
Training Epoch: 46 [48128/50176]	Loss: 4.6262
Training Epoch: 46 [49152/50176]	Loss: 4.6345
Training Epoch: 46 [50176/50176]	Loss: 4.6416
2022-12-06 20:09:31.069 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:09:31,093 [ZeusDataLoader(eval)] eval epoch 47 done: time=3.74 energy=467.13
2022-12-06 15:09:31,093 [ZeusDataLoader(train)] Up to epoch 47: time=2251.12, energy=296171.25, cost=345058.94
2022-12-06 15:09:31,094 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:09:31,094 [ZeusDataLoader(train)] Expected next epoch: time=2297.73, energy=302537.54, cost=352320.18
2022-12-06 15:09:31,095 [ZeusDataLoader(train)] Epoch 48 begin.
Validation Epoch: 46, Average loss: 13792.4378, Accuracy: 0.0098
2022-12-06 15:09:31,374 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:09:31,374 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:09:31.376 [ZeusMonitor] Monitor started.
2022-12-06 20:09:31.376 [ZeusMonitor] Running indefinitely. 2022-12-06 20:09:31.376 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:09:31.376 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e48+gpu0.power.log
2022-12-06 15:10:14,826 [ZeusDataLoader(train)] train epoch 48 done: time=43.72 energy=5822.93
2022-12-06 15:10:14,830 [ZeusDataLoader(eval)] Epoch 48 begin.
Training Epoch: 47 [1024/50176]	Loss: 4.6379
Training Epoch: 47 [2048/50176]	Loss: 4.6394
Training Epoch: 47 [3072/50176]	Loss: 4.6521
Training Epoch: 47 [4096/50176]	Loss: 4.6394
Training Epoch: 47 [5120/50176]	Loss: 4.6435
Training Epoch: 47 [6144/50176]	Loss: 4.6373
Training Epoch: 47 [7168/50176]	Loss: 4.6156
Training Epoch: 47 [8192/50176]	Loss: 4.6553
Training Epoch: 47 [9216/50176]	Loss: 4.6386
Training Epoch: 47 [10240/50176]	Loss: 4.6582
Training Epoch: 47 [11264/50176]	Loss: 4.6449
Training Epoch: 47 [12288/50176]	Loss: 4.6409
Training Epoch: 47 [13312/50176]	Loss: 4.6398
Training Epoch: 47 [14336/50176]	Loss: 4.6322
Training Epoch: 47 [15360/50176]	Loss: 4.6228
Training Epoch: 47 [16384/50176]	Loss: 4.6348
Training Epoch: 47 [17408/50176]	Loss: 4.6406
Training Epoch: 47 [18432/50176]	Loss: 4.6330
Training Epoch: 47 [19456/50176]	Loss: 4.6635
Training Epoch: 47 [20480/50176]	Loss: 4.6384
Training Epoch: 47 [21504/50176]	Loss: 4.6449
Training Epoch: 47 [22528/50176]	Loss: 4.6233
Training Epoch: 47 [23552/50176]	Loss: 4.6411
Training Epoch: 47 [24576/50176]	Loss: 4.6259
Training Epoch: 47 [25600/50176]	Loss: 4.6448
Training Epoch: 47 [26624/50176]	Loss: 4.6388
Training Epoch: 47 [27648/50176]	Loss: 4.6324
Training Epoch: 47 [28672/50176]	Loss: 4.6394
Training Epoch: 47 [29696/50176]	Loss: 4.6320
Training Epoch: 47 [30720/50176]	Loss: 4.6426
Training Epoch: 47 [31744/50176]	Loss: 4.6376
Training Epoch: 47 [32768/50176]	Loss: 4.6388
Training Epoch: 47 [33792/50176]	Loss: 4.6401
Training Epoch: 47 [34816/50176]	Loss: 4.6341
Training Epoch: 47 [35840/50176]	Loss: 4.6413
Training Epoch: 47 [36864/50176]	Loss: 4.6284
Training Epoch: 47 [37888/50176]	Loss: 4.6421
Training Epoch: 47 [38912/50176]	Loss: 4.6462
Training Epoch: 47 [39936/50176]	Loss: 4.6361
Training Epoch: 47 [40960/50176]	Loss: 4.6450
Training Epoch: 47 [41984/50176]	Loss: 4.6472
Training Epoch: 47 [43008/50176]	Loss: 4.6279
Training Epoch: 47 [44032/50176]	Loss: 4.6407
Training Epoch: 47 [45056/50176]	Loss: 4.6225
Training Epoch: 47 [46080/50176]	Loss: 4.6276
Training Epoch: 47 [47104/50176]	Loss: 4.6347
Training Epoch: 47 [48128/50176]	Loss: 4.6295
Training Epoch: 47 [49152/50176]	Loss: 4.6360
Training Epoch: 47 [50176/50176]	Loss: 4.6229
2022-12-06 20:10:18.555 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:10:18,574 [ZeusDataLoader(eval)] eval epoch 48 done: time=3.74 energy=464.47
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Up to epoch 48: time=2298.58, energy=302458.65, cost=352355.35
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:10:18,574 [ZeusDataLoader(train)] Expected next epoch: time=2345.19, energy=308824.95, cost=359616.59
2022-12-06 15:10:18,575 [ZeusDataLoader(train)] Epoch 49 begin.
Validation Epoch: 47, Average loss: 19788.6666, Accuracy: 0.0098
2022-12-06 15:10:18,843 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:10:18,843 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:10:18.845 [ZeusMonitor] Monitor started.
2022-12-06 20:10:18.845 [ZeusMonitor] Running indefinitely. 2022-12-06 20:10:18.845 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:10:18.845 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e49+gpu0.power.log
2022-12-06 15:11:02,310 [ZeusDataLoader(train)] train epoch 49 done: time=43.73 energy=5830.79
2022-12-06 15:11:02,313 [ZeusDataLoader(eval)] Epoch 49 begin.
Training Epoch: 48 [1024/50176]	Loss: 4.6278
Training Epoch: 48 [2048/50176]	Loss: 4.6316
Training Epoch: 48 [3072/50176]	Loss: 4.6328
Training Epoch: 48 [4096/50176]	Loss: 4.6277
Training Epoch: 48 [5120/50176]	Loss: 4.6294
Training Epoch: 48 [6144/50176]	Loss: 4.6434
Training Epoch: 48 [7168/50176]	Loss: 4.6339
Training Epoch: 48 [8192/50176]	Loss: 4.6370
Training Epoch: 48 [9216/50176]	Loss: 4.6384
Training Epoch: 48 [10240/50176]	Loss: 4.6373
Training Epoch: 48 [11264/50176]	Loss: 4.6384
Training Epoch: 48 [12288/50176]	Loss: 4.6268
Training Epoch: 48 [13312/50176]	Loss: 4.6366
Training Epoch: 48 [14336/50176]	Loss: 4.6339
Training Epoch: 48 [15360/50176]	Loss: 4.6245
Training Epoch: 48 [16384/50176]	Loss: 4.6337
Training Epoch: 48 [17408/50176]	Loss: 4.6315
Training Epoch: 48 [18432/50176]	Loss: 4.6347
Training Epoch: 48 [19456/50176]	Loss: 4.6334
Training Epoch: 48 [20480/50176]	Loss: 4.6543
Training Epoch: 48 [21504/50176]	Loss: 4.6361
Training Epoch: 48 [22528/50176]	Loss: 4.6411
Training Epoch: 48 [23552/50176]	Loss: 4.6258
Training Epoch: 48 [24576/50176]	Loss: 4.6358
Training Epoch: 48 [25600/50176]	Loss: 4.6371
Training Epoch: 48 [26624/50176]	Loss: 4.6303
Training Epoch: 48 [27648/50176]	Loss: 4.6364
Training Epoch: 48 [28672/50176]	Loss: 4.6319
Training Epoch: 48 [29696/50176]	Loss: 4.6486
Training Epoch: 48 [30720/50176]	Loss: 4.6353
Training Epoch: 48 [31744/50176]	Loss: 4.6350
Training Epoch: 48 [32768/50176]	Loss: 4.6374
Training Epoch: 48 [33792/50176]	Loss: 4.6303
Training Epoch: 48 [34816/50176]	Loss: 4.6285
Training Epoch: 48 [35840/50176]	Loss: 4.6325
Training Epoch: 48 [36864/50176]	Loss: 4.6422
Training Epoch: 48 [37888/50176]	Loss: 4.6237
Training Epoch: 48 [38912/50176]	Loss: 4.6226
Training Epoch: 48 [39936/50176]	Loss: 4.6362
Training Epoch: 48 [40960/50176]	Loss: 4.6325
Training Epoch: 48 [41984/50176]	Loss: 4.6496
Training Epoch: 48 [43008/50176]	Loss: 4.6219
Training Epoch: 48 [44032/50176]	Loss: 4.6370
Training Epoch: 48 [45056/50176]	Loss: 4.6305
Training Epoch: 48 [46080/50176]	Loss: 4.6499
Training Epoch: 48 [47104/50176]	Loss: 4.6407
Training Epoch: 48 [48128/50176]	Loss: 4.6405
Training Epoch: 48 [49152/50176]	Loss: 4.6313
Training Epoch: 48 [50176/50176]	Loss: 4.6315
2022-12-06 20:11:06.064 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:11:06,090 [ZeusDataLoader(eval)] eval epoch 49 done: time=3.77 energy=463.07
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Up to epoch 49: time=2346.08, energy=308752.52, cost=359658.11
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:11:06,090 [ZeusDataLoader(train)] Expected next epoch: time=2392.68, energy=315118.81, cost=366919.34
2022-12-06 15:11:06,091 [ZeusDataLoader(train)] Epoch 50 begin.
Validation Epoch: 48, Average loss: 66445.6536, Accuracy: 0.0098
2022-12-06 15:11:06,337 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:11:06,338 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:11:06.340 [ZeusMonitor] Monitor started.
2022-12-06 20:11:06.340 [ZeusMonitor] Running indefinitely. 2022-12-06 20:11:06.340 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:11:06.340 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e50+gpu0.power.log
2022-12-06 15:11:49,796 [ZeusDataLoader(train)] train epoch 50 done: time=43.70 energy=5817.93
2022-12-06 15:11:49,799 [ZeusDataLoader(eval)] Epoch 50 begin.
Training Epoch: 49 [1024/50176]	Loss: 4.6253
Training Epoch: 49 [2048/50176]	Loss: 4.6395
Training Epoch: 49 [3072/50176]	Loss: 4.6325
Training Epoch: 49 [4096/50176]	Loss: 4.6319
Training Epoch: 49 [5120/50176]	Loss: 4.6545
Training Epoch: 49 [6144/50176]	Loss: 4.6487
Training Epoch: 49 [7168/50176]	Loss: 4.6334
Training Epoch: 49 [8192/50176]	Loss: 4.6380
Training Epoch: 49 [9216/50176]	Loss: 4.6375
Training Epoch: 49 [10240/50176]	Loss: 4.6347
Training Epoch: 49 [11264/50176]	Loss: 4.6456
Training Epoch: 49 [12288/50176]	Loss: 4.6378
Training Epoch: 49 [13312/50176]	Loss: 4.6421
Training Epoch: 49 [14336/50176]	Loss: 4.6333
Training Epoch: 49 [15360/50176]	Loss: 4.6497
Training Epoch: 49 [16384/50176]	Loss: 4.6390
Training Epoch: 49 [17408/50176]	Loss: 4.6454
Training Epoch: 49 [18432/50176]	Loss: 4.6383
Training Epoch: 49 [19456/50176]	Loss: 4.6299
Training Epoch: 49 [20480/50176]	Loss: 4.6305
Training Epoch: 49 [21504/50176]	Loss: 4.6461
Training Epoch: 49 [22528/50176]	Loss: 4.6417
Training Epoch: 49 [23552/50176]	Loss: 4.6268
Training Epoch: 49 [24576/50176]	Loss: 4.6333
Training Epoch: 49 [25600/50176]	Loss: 4.6386
Training Epoch: 49 [26624/50176]	Loss: 4.6263
Training Epoch: 49 [27648/50176]	Loss: 4.6273
Training Epoch: 49 [28672/50176]	Loss: 4.6309
Training Epoch: 49 [29696/50176]	Loss: 4.6375
Training Epoch: 49 [30720/50176]	Loss: 4.6348
Training Epoch: 49 [31744/50176]	Loss: 4.6398
Training Epoch: 49 [32768/50176]	Loss: 4.6341
Training Epoch: 49 [33792/50176]	Loss: 4.6403
Training Epoch: 49 [34816/50176]	Loss: 4.6245
Training Epoch: 49 [35840/50176]	Loss: 4.6280
Training Epoch: 49 [36864/50176]	Loss: 4.6458
Training Epoch: 49 [37888/50176]	Loss: 4.6316
Training Epoch: 49 [38912/50176]	Loss: 4.6362
Training Epoch: 49 [39936/50176]	Loss: 4.6374
Training Epoch: 49 [40960/50176]	Loss: 4.6362
Training Epoch: 49 [41984/50176]	Loss: 4.6344
Training Epoch: 49 [43008/50176]	Loss: 4.6264
Training Epoch: 49 [44032/50176]	Loss: 4.6340
Training Epoch: 49 [45056/50176]	Loss: 4.6393
Training Epoch: 49 [46080/50176]	Loss: 4.6256
Training Epoch: 49 [47104/50176]	Loss: 4.6279
Training Epoch: 49 [48128/50176]	Loss: 4.6417
Training Epoch: 49 [49152/50176]	Loss: 4.6292
Training Epoch: 49 [50176/50176]	Loss: 4.6271
2022-12-06 20:11:53.668 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:11:53,703 [ZeusDataLoader(eval)] eval epoch 50 done: time=3.90 energy=487.94
2022-12-06 15:11:53,703 [ZeusDataLoader(train)] Up to epoch 50: time=2393.67, energy=315058.39, cost=366975.42
2022-12-06 15:11:53,703 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:11:53,704 [ZeusDataLoader(train)] Expected next epoch: time=2440.28, energy=321424.69, cost=374236.66
2022-12-06 15:11:53,704 [ZeusDataLoader(train)] Epoch 51 begin.
Validation Epoch: 49, Average loss: 22031.1692, Accuracy: 0.0098
2022-12-06 15:11:53,955 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:11:53,955 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:11:53.957 [ZeusMonitor] Monitor started.
2022-12-06 20:11:53.957 [ZeusMonitor] Running indefinitely. 2022-12-06 20:11:53.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:11:53.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e51+gpu0.power.log
2022-12-06 15:12:37,485 [ZeusDataLoader(train)] train epoch 51 done: time=43.77 energy=5828.01
2022-12-06 15:12:37,488 [ZeusDataLoader(eval)] Epoch 51 begin.
Training Epoch: 50 [1024/50176]	Loss: 4.6415
Training Epoch: 50 [2048/50176]	Loss: 4.6209
Training Epoch: 50 [3072/50176]	Loss: 4.6386
Training Epoch: 50 [4096/50176]	Loss: 4.6514
Training Epoch: 50 [5120/50176]	Loss: 4.6418
Training Epoch: 50 [6144/50176]	Loss: 4.6410
Training Epoch: 50 [7168/50176]	Loss: 4.6337
Training Epoch: 50 [8192/50176]	Loss: 4.6357
Training Epoch: 50 [9216/50176]	Loss: 4.6486
Training Epoch: 50 [10240/50176]	Loss: 4.6369
Training Epoch: 50 [11264/50176]	Loss: 4.6671
Training Epoch: 50 [12288/50176]	Loss: 4.6316
Training Epoch: 50 [13312/50176]	Loss: 4.6350
Training Epoch: 50 [14336/50176]	Loss: 4.6327
Training Epoch: 50 [15360/50176]	Loss: 4.6329
Training Epoch: 50 [16384/50176]	Loss: 4.6343
Training Epoch: 50 [17408/50176]	Loss: 4.6423
Training Epoch: 50 [18432/50176]	Loss: 4.6408
Training Epoch: 50 [19456/50176]	Loss: 4.6356
Training Epoch: 50 [20480/50176]	Loss: 4.6330
Training Epoch: 50 [21504/50176]	Loss: 4.6254
Training Epoch: 50 [22528/50176]	Loss: 4.6541
Training Epoch: 50 [23552/50176]	Loss: 4.6418
Training Epoch: 50 [24576/50176]	Loss: 4.6318
Training Epoch: 50 [25600/50176]	Loss: 4.6324
Training Epoch: 50 [26624/50176]	Loss: 4.6319
Training Epoch: 50 [27648/50176]	Loss: 4.6399
Training Epoch: 50 [28672/50176]	Loss: 4.6373
Training Epoch: 50 [29696/50176]	Loss: 4.6402
Training Epoch: 50 [30720/50176]	Loss: 4.6367
Training Epoch: 50 [31744/50176]	Loss: 4.6378
Training Epoch: 50 [32768/50176]	Loss: 4.6354
Training Epoch: 50 [33792/50176]	Loss: 4.6434
Training Epoch: 50 [34816/50176]	Loss: 4.6234
Training Epoch: 50 [35840/50176]	Loss: 4.6327
Training Epoch: 50 [36864/50176]	Loss: 4.6475
Training Epoch: 50 [37888/50176]	Loss: 4.6328
Training Epoch: 50 [38912/50176]	Loss: 4.6403
Training Epoch: 50 [39936/50176]	Loss: 4.6312
Training Epoch: 50 [40960/50176]	Loss: 4.6374
Training Epoch: 50 [41984/50176]	Loss: 4.6511
Training Epoch: 50 [43008/50176]	Loss: 4.6497
Training Epoch: 50 [44032/50176]	Loss: 4.6488
Training Epoch: 50 [45056/50176]	Loss: 4.6489
Training Epoch: 50 [46080/50176]	Loss: 4.6281
Training Epoch: 50 [47104/50176]	Loss: 4.6376
Training Epoch: 50 [48128/50176]	Loss: 4.6513
Training Epoch: 50 [49152/50176]	Loss: 4.6361
Training Epoch: 50 [50176/50176]	Loss: 4.6463
2022-12-06 20:12:41.211 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:12:41,221 [ZeusDataLoader(eval)] eval epoch 51 done: time=3.73 energy=464.73
2022-12-06 15:12:41,221 [ZeusDataLoader(train)] Up to epoch 51: time=2441.17, energy=321351.14, cost=374277.84
2022-12-06 15:12:41,222 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:12:41,222 [ZeusDataLoader(train)] Expected next epoch: time=2487.78, energy=327717.43, cost=381539.07
2022-12-06 15:12:41,223 [ZeusDataLoader(train)] Epoch 52 begin.
Validation Epoch: 50, Average loss: 1792.7416, Accuracy: 0.0097
2022-12-06 15:12:41,471 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:12:41,472 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:12:41.474 [ZeusMonitor] Monitor started.
2022-12-06 20:12:41.474 [ZeusMonitor] Running indefinitely. 2022-12-06 20:12:41.474 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:12:41.474 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e52+gpu0.power.log
2022-12-06 15:13:25,044 [ZeusDataLoader(train)] train epoch 52 done: time=43.81 energy=5837.99
2022-12-06 15:13:25,047 [ZeusDataLoader(eval)] Epoch 52 begin.
Training Epoch: 51 [1024/50176]	Loss: 4.6253
Training Epoch: 51 [2048/50176]	Loss: 4.6296
Training Epoch: 51 [3072/50176]	Loss: 4.6260
Training Epoch: 51 [4096/50176]	Loss: 4.6587
Training Epoch: 51 [5120/50176]	Loss: 4.6377
Training Epoch: 51 [6144/50176]	Loss: 4.6466
Training Epoch: 51 [7168/50176]	Loss: 4.6355
Training Epoch: 51 [8192/50176]	Loss: 4.6283
Training Epoch: 51 [9216/50176]	Loss: 4.6425
Training Epoch: 51 [10240/50176]	Loss: 4.6314
Training Epoch: 51 [11264/50176]	Loss: 4.6406
Training Epoch: 51 [12288/50176]	Loss: 4.6328
Training Epoch: 51 [13312/50176]	Loss: 4.6441
Training Epoch: 51 [14336/50176]	Loss: 4.6454
Training Epoch: 51 [15360/50176]	Loss: 4.6399
Training Epoch: 51 [16384/50176]	Loss: 4.6412
Training Epoch: 51 [17408/50176]	Loss: 4.6404
Training Epoch: 51 [18432/50176]	Loss: 4.6420
Training Epoch: 51 [19456/50176]	Loss: 4.6452
Training Epoch: 51 [20480/50176]	Loss: 4.6211
Training Epoch: 51 [21504/50176]	Loss: 4.6307
Training Epoch: 51 [22528/50176]	Loss: 4.6197
Training Epoch: 51 [23552/50176]	Loss: 4.6356
Training Epoch: 51 [24576/50176]	Loss: 4.6604
Training Epoch: 51 [25600/50176]	Loss: 4.6263
Training Epoch: 51 [26624/50176]	Loss: 4.6339
Training Epoch: 51 [27648/50176]	Loss: 4.6410
Training Epoch: 51 [28672/50176]	Loss: 4.6395
Training Epoch: 51 [29696/50176]	Loss: 4.6484
Training Epoch: 51 [30720/50176]	Loss: 4.6396
Training Epoch: 51 [31744/50176]	Loss: 4.6412
Training Epoch: 51 [32768/50176]	Loss: 4.6504
Training Epoch: 51 [33792/50176]	Loss: 4.6309
Training Epoch: 51 [34816/50176]	Loss: 4.6420
Training Epoch: 51 [35840/50176]	Loss: 4.6384
Training Epoch: 51 [36864/50176]	Loss: 4.6400
Training Epoch: 51 [37888/50176]	Loss: 4.6631
Training Epoch: 51 [38912/50176]	Loss: 4.6319
Training Epoch: 51 [39936/50176]	Loss: 4.6297
Training Epoch: 51 [40960/50176]	Loss: 4.6259
Training Epoch: 51 [41984/50176]	Loss: 4.6421
Training Epoch: 51 [43008/50176]	Loss: 4.6475
Training Epoch: 51 [44032/50176]	Loss: 4.6377
Training Epoch: 51 [45056/50176]	Loss: 4.6318
Training Epoch: 51 [46080/50176]	Loss: 4.6468
Training Epoch: 51 [47104/50176]	Loss: 4.6481
Training Epoch: 51 [48128/50176]	Loss: 4.6332
Training Epoch: 51 [49152/50176]	Loss: 4.6390
Training Epoch: 51 [50176/50176]	Loss: 4.6382
2022-12-06 20:13:28.801 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:13:28,841 [ZeusDataLoader(eval)] eval epoch 52 done: time=3.79 energy=482.31
2022-12-06 15:13:28,841 [ZeusDataLoader(train)] Up to epoch 52: time=2488.77, energy=327671.44, cost=381602.96
2022-12-06 15:13:28,841 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:13:28,842 [ZeusDataLoader(train)] Expected next epoch: time=2535.38, energy=334037.73, cost=388864.20
2022-12-06 15:13:28,842 [ZeusDataLoader(train)] Epoch 53 begin.
Validation Epoch: 51, Average loss: 1907.4217, Accuracy: 0.0098
2022-12-06 15:13:29,094 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:13:29,094 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:13:29.096 [ZeusMonitor] Monitor started.
2022-12-06 20:13:29.096 [ZeusMonitor] Running indefinitely. 2022-12-06 20:13:29.096 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:13:29.096 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e53+gpu0.power.log
2022-12-06 15:14:12,763 [ZeusDataLoader(train)] train epoch 53 done: time=43.91 energy=5843.53
2022-12-06 15:14:12,765 [ZeusDataLoader(eval)] Epoch 53 begin.
Training Epoch: 52 [1024/50176]	Loss: 4.6317
Training Epoch: 52 [2048/50176]	Loss: 4.6376
Training Epoch: 52 [3072/50176]	Loss: 4.6524
Training Epoch: 52 [4096/50176]	Loss: 4.6348
Training Epoch: 52 [5120/50176]	Loss: 4.6321
Training Epoch: 52 [6144/50176]	Loss: 4.6579
Training Epoch: 52 [7168/50176]	Loss: 4.6462
Training Epoch: 52 [8192/50176]	Loss: 4.6316
Training Epoch: 52 [9216/50176]	Loss: 4.6394
Training Epoch: 52 [10240/50176]	Loss: 4.6367
Training Epoch: 52 [11264/50176]	Loss: 4.6412
Training Epoch: 52 [12288/50176]	Loss: 4.6432
Training Epoch: 52 [13312/50176]	Loss: 4.6455
Training Epoch: 52 [14336/50176]	Loss: 4.6321
Training Epoch: 52 [15360/50176]	Loss: 4.6434
Training Epoch: 52 [16384/50176]	Loss: 4.6419
Training Epoch: 52 [17408/50176]	Loss: 4.6317
Training Epoch: 52 [18432/50176]	Loss: 4.6405
Training Epoch: 52 [19456/50176]	Loss: 4.6304
Training Epoch: 52 [20480/50176]	Loss: 4.6342
Training Epoch: 52 [21504/50176]	Loss: 4.6318
Training Epoch: 52 [22528/50176]	Loss: 4.6578
Training Epoch: 52 [23552/50176]	Loss: 4.6464
Training Epoch: 52 [24576/50176]	Loss: 4.6515
Training Epoch: 52 [25600/50176]	Loss: 4.6369
Training Epoch: 52 [26624/50176]	Loss: 4.6492
Training Epoch: 52 [27648/50176]	Loss: 4.6546
Training Epoch: 52 [28672/50176]	Loss: 4.6477
Training Epoch: 52 [29696/50176]	Loss: 4.6531
Training Epoch: 52 [30720/50176]	Loss: 4.6409
Training Epoch: 52 [31744/50176]	Loss: 4.6443
Training Epoch: 52 [32768/50176]	Loss: 4.6402
Training Epoch: 52 [33792/50176]	Loss: 4.6149
Training Epoch: 52 [34816/50176]	Loss: 4.6458
Training Epoch: 52 [35840/50176]	Loss: 4.6523
Training Epoch: 52 [36864/50176]	Loss: 4.6349
Training Epoch: 52 [37888/50176]	Loss: 4.6380
Training Epoch: 52 [38912/50176]	Loss: 4.6366
Training Epoch: 52 [39936/50176]	Loss: 4.6367
Training Epoch: 52 [40960/50176]	Loss: 4.6337
Training Epoch: 52 [41984/50176]	Loss: 4.6304
Training Epoch: 52 [43008/50176]	Loss: 4.6513
Training Epoch: 52 [44032/50176]	Loss: 4.6203
Training Epoch: 52 [45056/50176]	Loss: 4.6410
Training Epoch: 52 [46080/50176]	Loss: 4.6352
Training Epoch: 52 [47104/50176]	Loss: 4.6370
Training Epoch: 52 [48128/50176]	Loss: 4.6441
Training Epoch: 52 [49152/50176]	Loss: 4.6333
Training Epoch: 52 [50176/50176]	Loss: 4.6479
2022-12-06 20:14:16.595 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:14:16,619 [ZeusDataLoader(eval)] eval epoch 53 done: time=3.85 energy=474.56
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Up to epoch 53: time=2536.53, energy=333989.53, cost=388940.83
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:14:16,619 [ZeusDataLoader(train)] Expected next epoch: time=2583.13, energy=340355.82, cost=396202.07
2022-12-06 15:14:16,620 [ZeusDataLoader(train)] Epoch 54 begin.
Validation Epoch: 52, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:14:16,871 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:14:16,871 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:14:16.873 [ZeusMonitor] Monitor started.
2022-12-06 20:14:16.873 [ZeusMonitor] Running indefinitely. 2022-12-06 20:14:16.873 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:14:16.873 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e54+gpu0.power.log
2022-12-06 15:15:00,311 [ZeusDataLoader(train)] train epoch 54 done: time=43.68 energy=5825.16
2022-12-06 15:15:00,314 [ZeusDataLoader(eval)] Epoch 54 begin.
Training Epoch: 53 [1024/50176]	Loss: 4.6324
Training Epoch: 53 [2048/50176]	Loss: 4.6191
Training Epoch: 53 [3072/50176]	Loss: 4.6317
Training Epoch: 53 [4096/50176]	Loss: 4.6575
Training Epoch: 53 [5120/50176]	Loss: 4.6428
Training Epoch: 53 [6144/50176]	Loss: 4.6465
Training Epoch: 53 [7168/50176]	Loss: 4.6290
Training Epoch: 53 [8192/50176]	Loss: 4.6307
Training Epoch: 53 [9216/50176]	Loss: 4.6228
Training Epoch: 53 [10240/50176]	Loss: 4.6232
Training Epoch: 53 [11264/50176]	Loss: 4.6399
Training Epoch: 53 [12288/50176]	Loss: 4.6301
Training Epoch: 53 [13312/50176]	Loss: 4.6358
Training Epoch: 53 [14336/50176]	Loss: 4.6301
Training Epoch: 53 [15360/50176]	Loss: 4.6316
Training Epoch: 53 [16384/50176]	Loss: 4.6465
Training Epoch: 53 [17408/50176]	Loss: 4.6345
Training Epoch: 53 [18432/50176]	Loss: 4.6311
Training Epoch: 53 [19456/50176]	Loss: 4.6247
Training Epoch: 53 [20480/50176]	Loss: 4.6341
Training Epoch: 53 [21504/50176]	Loss: 4.6329
Training Epoch: 53 [22528/50176]	Loss: 4.6287
Training Epoch: 53 [23552/50176]	Loss: 4.6369
Training Epoch: 53 [24576/50176]	Loss: 4.6256
Training Epoch: 53 [25600/50176]	Loss: 4.6441
Training Epoch: 53 [26624/50176]	Loss: 4.6399
Training Epoch: 53 [27648/50176]	Loss: 4.6603
Training Epoch: 53 [28672/50176]	Loss: 4.6287
Training Epoch: 53 [29696/50176]	Loss: 4.6303
Training Epoch: 53 [30720/50176]	Loss: 4.6490
Training Epoch: 53 [31744/50176]	Loss: 4.6326
Training Epoch: 53 [32768/50176]	Loss: 4.6407
Training Epoch: 53 [33792/50176]	Loss: 4.6640
Training Epoch: 53 [34816/50176]	Loss: 4.6395
Training Epoch: 53 [35840/50176]	Loss: 4.6459
Training Epoch: 53 [36864/50176]	Loss: 4.6423
Training Epoch: 53 [37888/50176]	Loss: 4.6392
Training Epoch: 53 [38912/50176]	Loss: 4.6277
Training Epoch: 53 [39936/50176]	Loss: 4.6337
Training Epoch: 53 [40960/50176]	Loss: 4.6332
Training Epoch: 53 [41984/50176]	Loss: 4.6447
Training Epoch: 53 [43008/50176]	Loss: 4.6585
Training Epoch: 53 [44032/50176]	Loss: 4.6382
Training Epoch: 53 [45056/50176]	Loss: 4.6172
Training Epoch: 53 [46080/50176]	Loss: 4.6245
Training Epoch: 53 [47104/50176]	Loss: 4.6522
Training Epoch: 53 [48128/50176]	Loss: 4.6483
Training Epoch: 53 [49152/50176]	Loss: 4.6362
Training Epoch: 53 [50176/50176]	Loss: 4.6419
2022-12-06 20:15:04.028 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:15:04,043 [ZeusDataLoader(eval)] eval epoch 54 done: time=3.72 energy=463.41
2022-12-06 15:15:04,043 [ZeusDataLoader(train)] Up to epoch 54: time=2583.93, energy=340278.09, cost=396232.95
2022-12-06 15:15:04,044 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:15:04,044 [ZeusDataLoader(train)] Expected next epoch: time=2630.54, energy=346644.39, cost=403494.19
2022-12-06 15:15:04,045 [ZeusDataLoader(train)] Epoch 55 begin.
Validation Epoch: 53, Average loss: 4018.8445, Accuracy: 0.0098
2022-12-06 15:15:04,265 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:15:04,266 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:15:04.268 [ZeusMonitor] Monitor started.
2022-12-06 20:15:04.268 [ZeusMonitor] Running indefinitely. 2022-12-06 20:15:04.268 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:15:04.268 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e55+gpu0.power.log
2022-12-06 15:15:48,023 [ZeusDataLoader(train)] train epoch 55 done: time=43.97 energy=5847.37
2022-12-06 15:15:48,027 [ZeusDataLoader(eval)] Epoch 55 begin.
Training Epoch: 54 [1024/50176]	Loss: 4.6517
Training Epoch: 54 [2048/50176]	Loss: 4.6493
Training Epoch: 54 [3072/50176]	Loss: 4.6447
Training Epoch: 54 [4096/50176]	Loss: 4.6367
Training Epoch: 54 [5120/50176]	Loss: 4.6429
Training Epoch: 54 [6144/50176]	Loss: 4.6279
Training Epoch: 54 [7168/50176]	Loss: 4.6406
Training Epoch: 54 [8192/50176]	Loss: 4.6436
Training Epoch: 54 [9216/50176]	Loss: 4.6385
Training Epoch: 54 [10240/50176]	Loss: 4.6401
Training Epoch: 54 [11264/50176]	Loss: 4.6327
Training Epoch: 54 [12288/50176]	Loss: 4.6254
Training Epoch: 54 [13312/50176]	Loss: 4.6277
Training Epoch: 54 [14336/50176]	Loss: 4.6342
Training Epoch: 54 [15360/50176]	Loss: 4.6440
Training Epoch: 54 [16384/50176]	Loss: 4.6339
Training Epoch: 54 [17408/50176]	Loss: 4.6324
Training Epoch: 54 [18432/50176]	Loss: 4.6413
Training Epoch: 54 [19456/50176]	Loss: 4.6389
Training Epoch: 54 [20480/50176]	Loss: 4.6384
Training Epoch: 54 [21504/50176]	Loss: 4.6422
Training Epoch: 54 [22528/50176]	Loss: 4.6484
Training Epoch: 54 [23552/50176]	Loss: 4.6335
Training Epoch: 54 [24576/50176]	Loss: 4.6209
Training Epoch: 54 [25600/50176]	Loss: 4.6297
Training Epoch: 54 [26624/50176]	Loss: 4.6403
Training Epoch: 54 [27648/50176]	Loss: 4.6382
Training Epoch: 54 [28672/50176]	Loss: 4.6337
Training Epoch: 54 [29696/50176]	Loss: 4.6311
Training Epoch: 54 [30720/50176]	Loss: 4.6406
Training Epoch: 54 [31744/50176]	Loss: 4.6355
Training Epoch: 54 [32768/50176]	Loss: 4.6386
Training Epoch: 54 [33792/50176]	Loss: 4.6621
Training Epoch: 54 [34816/50176]	Loss: 4.6368
Training Epoch: 54 [35840/50176]	Loss: 4.6237
Training Epoch: 54 [36864/50176]	Loss: 4.6438
Training Epoch: 54 [37888/50176]	Loss: 4.6432
Training Epoch: 54 [38912/50176]	Loss: 4.6286
Training Epoch: 54 [39936/50176]	Loss: 4.6615
Training Epoch: 54 [40960/50176]	Loss: 4.6484
Training Epoch: 54 [41984/50176]	Loss: 4.6409
Training Epoch: 54 [43008/50176]	Loss: 4.6286
Training Epoch: 54 [44032/50176]	Loss: 4.6357
Training Epoch: 54 [45056/50176]	Loss: 4.6433
Training Epoch: 54 [46080/50176]	Loss: 4.6376
Training Epoch: 54 [47104/50176]	Loss: 4.6463
Training Epoch: 54 [48128/50176]	Loss: 4.6238
Training Epoch: 54 [49152/50176]	Loss: 4.6392
Training Epoch: 54 [50176/50176]	Loss: 4.6397
2022-12-06 20:15:51.755 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:15:51,777 [ZeusDataLoader(eval)] eval epoch 55 done: time=3.74 energy=464.89
2022-12-06 15:15:51,777 [ZeusDataLoader(train)] Up to epoch 55: time=2631.64, energy=346590.35, cost=403564.02
2022-12-06 15:15:51,778 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:15:51,778 [ZeusDataLoader(train)] Expected next epoch: time=2678.25, energy=352956.65, cost=410825.26
2022-12-06 15:15:51,779 [ZeusDataLoader(train)] Epoch 56 begin.
Validation Epoch: 54, Average loss: 9533.3703, Accuracy: 0.0098
2022-12-06 15:15:52,021 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:15:52,022 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:15:52.023 [ZeusMonitor] Monitor started.
2022-12-06 20:15:52.024 [ZeusMonitor] Running indefinitely. 2022-12-06 20:15:52.024 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:15:52.024 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e56+gpu0.power.log
2022-12-06 15:16:35,727 [ZeusDataLoader(train)] train epoch 56 done: time=43.94 energy=5836.39
2022-12-06 15:16:35,730 [ZeusDataLoader(eval)] Epoch 56 begin.
Training Epoch: 55 [1024/50176]	Loss: 4.6358
Training Epoch: 55 [2048/50176]	Loss: 4.6276
Training Epoch: 55 [3072/50176]	Loss: 4.6280
Training Epoch: 55 [4096/50176]	Loss: 4.6302
Training Epoch: 55 [5120/50176]	Loss: 4.6470
Training Epoch: 55 [6144/50176]	Loss: 4.6443
Training Epoch: 55 [7168/50176]	Loss: 4.6404
Training Epoch: 55 [8192/50176]	Loss: 4.6382
Training Epoch: 55 [9216/50176]	Loss: 4.6344
Training Epoch: 55 [10240/50176]	Loss: 4.6301
Training Epoch: 55 [11264/50176]	Loss: 4.6254
Training Epoch: 55 [12288/50176]	Loss: 4.6298
Training Epoch: 55 [13312/50176]	Loss: 4.6444
Training Epoch: 55 [14336/50176]	Loss: 4.6291
Training Epoch: 55 [15360/50176]	Loss: 4.6371
Training Epoch: 55 [16384/50176]	Loss: 4.6393
Training Epoch: 55 [17408/50176]	Loss: 4.6335
Training Epoch: 55 [18432/50176]	Loss: 4.6328
Training Epoch: 55 [19456/50176]	Loss: 4.6370
Training Epoch: 55 [20480/50176]	Loss: 4.6353
Training Epoch: 55 [21504/50176]	Loss: 4.6261
Training Epoch: 55 [22528/50176]	Loss: 4.6482
Training Epoch: 55 [23552/50176]	Loss: 4.6469
Training Epoch: 55 [24576/50176]	Loss: 4.6469
Training Epoch: 55 [25600/50176]	Loss: 4.6365
Training Epoch: 55 [26624/50176]	Loss: 4.6405
Training Epoch: 55 [27648/50176]	Loss: 4.6371
Training Epoch: 55 [28672/50176]	Loss: 4.6339
Training Epoch: 55 [29696/50176]	Loss: 4.6383
Training Epoch: 55 [30720/50176]	Loss: 4.6438
Training Epoch: 55 [31744/50176]	Loss: 4.6297
Training Epoch: 55 [32768/50176]	Loss: 4.6500
Training Epoch: 55 [33792/50176]	Loss: 4.6423
Training Epoch: 55 [34816/50176]	Loss: 4.6277
Training Epoch: 55 [35840/50176]	Loss: 4.6289
Training Epoch: 55 [36864/50176]	Loss: 4.6288
Training Epoch: 55 [37888/50176]	Loss: 4.6410
Training Epoch: 55 [38912/50176]	Loss: 4.6315
Training Epoch: 55 [39936/50176]	Loss: 4.6535
Training Epoch: 55 [40960/50176]	Loss: 4.6306
Training Epoch: 55 [41984/50176]	Loss: 4.6329
Training Epoch: 55 [43008/50176]	Loss: 4.6444
Training Epoch: 55 [44032/50176]	Loss: 4.6338
Training Epoch: 55 [45056/50176]	Loss: 4.6382
Training Epoch: 55 [46080/50176]	Loss: 4.6483
Training Epoch: 55 [47104/50176]	Loss: 4.6482
Training Epoch: 55 [48128/50176]	Loss: 4.6551
Training Epoch: 55 [49152/50176]	Loss: 4.6595
Training Epoch: 55 [50176/50176]	Loss: 4.6468
2022-12-06 20:16:39.411 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:16:39,420 [ZeusDataLoader(eval)] eval epoch 56 done: time=3.68 energy=463.57
2022-12-06 15:16:39,420 [ZeusDataLoader(train)] Up to epoch 56: time=2679.27, energy=352890.32, cost=410881.00
2022-12-06 15:16:39,420 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:16:39,421 [ZeusDataLoader(train)] Expected next epoch: time=2725.87, energy=359256.61, cost=418142.24
2022-12-06 15:16:39,421 [ZeusDataLoader(train)] Epoch 57 begin.
Validation Epoch: 55, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:16:39,672 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:16:39,673 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:16:39.675 [ZeusMonitor] Monitor started.
2022-12-06 20:16:39.687 [ZeusMonitor] Running indefinitely. 2022-12-06 20:16:39.687 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:16:39.687 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e57+gpu0.power.log
2022-12-06 15:17:23,109 [ZeusDataLoader(train)] train epoch 57 done: time=43.68 energy=5825.55
2022-12-06 15:17:23,112 [ZeusDataLoader(eval)] Epoch 57 begin.
Training Epoch: 56 [1024/50176]	Loss: 4.6395
Training Epoch: 56 [2048/50176]	Loss: 4.6461
Training Epoch: 56 [3072/50176]	Loss: 4.6352
Training Epoch: 56 [4096/50176]	Loss: 4.6422
Training Epoch: 56 [5120/50176]	Loss: 4.6496
Training Epoch: 56 [6144/50176]	Loss: 4.6429
Training Epoch: 56 [7168/50176]	Loss: 4.6411
Training Epoch: 56 [8192/50176]	Loss: 4.6306
Training Epoch: 56 [9216/50176]	Loss: 4.6390
Training Epoch: 56 [10240/50176]	Loss: 4.6412
Training Epoch: 56 [11264/50176]	Loss: 4.6323
Training Epoch: 56 [12288/50176]	Loss: 4.6312
Training Epoch: 56 [13312/50176]	Loss: 4.6330
Training Epoch: 56 [14336/50176]	Loss: 4.6234
Training Epoch: 56 [15360/50176]	Loss: 4.6308
Training Epoch: 56 [16384/50176]	Loss: 4.6348
Training Epoch: 56 [17408/50176]	Loss: 4.6452
Training Epoch: 56 [18432/50176]	Loss: 4.6370
Training Epoch: 56 [19456/50176]	Loss: 4.6414
Training Epoch: 56 [20480/50176]	Loss: 4.6392
Training Epoch: 56 [21504/50176]	Loss: 4.6346
Training Epoch: 56 [22528/50176]	Loss: 4.6353
Training Epoch: 56 [23552/50176]	Loss: 4.6292
Training Epoch: 56 [24576/50176]	Loss: 4.6465
Training Epoch: 56 [25600/50176]	Loss: 4.6541
Training Epoch: 56 [26624/50176]	Loss: 4.6441
Training Epoch: 56 [27648/50176]	Loss: 4.6368
Training Epoch: 56 [28672/50176]	Loss: 4.6532
Training Epoch: 56 [29696/50176]	Loss: 4.6360
Training Epoch: 56 [30720/50176]	Loss: 4.6262
Training Epoch: 56 [31744/50176]	Loss: 4.6288
Training Epoch: 56 [32768/50176]	Loss: 4.6362
Training Epoch: 56 [33792/50176]	Loss: 4.6361
Training Epoch: 56 [34816/50176]	Loss: 4.6329
Training Epoch: 56 [35840/50176]	Loss: 4.6469
Training Epoch: 56 [36864/50176]	Loss: 4.6361
Training Epoch: 56 [37888/50176]	Loss: 4.6342
Training Epoch: 56 [38912/50176]	Loss: 4.6225
Training Epoch: 56 [39936/50176]	Loss: 4.6153
Training Epoch: 56 [40960/50176]	Loss: 4.6334
Training Epoch: 56 [41984/50176]	Loss: 4.6438
Training Epoch: 56 [43008/50176]	Loss: 4.6366
Training Epoch: 56 [44032/50176]	Loss: 4.6223
Training Epoch: 56 [45056/50176]	Loss: 4.6385
Training Epoch: 56 [46080/50176]	Loss: 4.6381
Training Epoch: 56 [47104/50176]	Loss: 4.6477
Training Epoch: 56 [48128/50176]	Loss: 4.6247
Training Epoch: 56 [49152/50176]	Loss: 4.6339
Training Epoch: 56 [50176/50176]	Loss: 4.6364
2022-12-06 20:17:26.875 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:17:26,899 [ZeusDataLoader(eval)] eval epoch 57 done: time=3.78 energy=485.48
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Up to epoch 57: time=2726.73, energy=359201.34, cost=418189.15
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:17:26,899 [ZeusDataLoader(train)] Expected next epoch: time=2773.33, energy=365567.64, cost=425450.39
2022-12-06 15:17:26,900 [ZeusDataLoader(train)] Epoch 58 begin.
Validation Epoch: 56, Average loss: 2229.0759, Accuracy: 0.0098
2022-12-06 15:17:27,095 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:17:27,096 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:17:27.097 [ZeusMonitor] Monitor started.
2022-12-06 20:17:27.097 [ZeusMonitor] Running indefinitely. 2022-12-06 20:17:27.097 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:17:27.097 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e58+gpu0.power.log
2022-12-06 15:18:10,782 [ZeusDataLoader(train)] train epoch 58 done: time=43.87 energy=5847.04
2022-12-06 15:18:10,786 [ZeusDataLoader(eval)] Epoch 58 begin.
Training Epoch: 57 [1024/50176]	Loss: 4.6408
Training Epoch: 57 [2048/50176]	Loss: 4.6418
Training Epoch: 57 [3072/50176]	Loss: 4.6294
Training Epoch: 57 [4096/50176]	Loss: 4.6408
Training Epoch: 57 [5120/50176]	Loss: 4.6359
Training Epoch: 57 [6144/50176]	Loss: 4.6457
Training Epoch: 57 [7168/50176]	Loss: 4.6340
Training Epoch: 57 [8192/50176]	Loss: 4.6579
Training Epoch: 57 [9216/50176]	Loss: 4.6469
Training Epoch: 57 [10240/50176]	Loss: 4.6494
Training Epoch: 57 [11264/50176]	Loss: 4.6263
Training Epoch: 57 [12288/50176]	Loss: 4.6347
Training Epoch: 57 [13312/50176]	Loss: 4.6228
Training Epoch: 57 [14336/50176]	Loss: 4.6597
Training Epoch: 57 [15360/50176]	Loss: 4.6472
Training Epoch: 57 [16384/50176]	Loss: 4.6406
Training Epoch: 57 [17408/50176]	Loss: 4.6396
Training Epoch: 57 [18432/50176]	Loss: 4.6416
Training Epoch: 57 [19456/50176]	Loss: 4.6305
Training Epoch: 57 [20480/50176]	Loss: 4.6453
Training Epoch: 57 [21504/50176]	Loss: 4.6407
Training Epoch: 57 [22528/50176]	Loss: 4.6374
Training Epoch: 57 [23552/50176]	Loss: 4.6357
Training Epoch: 57 [24576/50176]	Loss: 4.6487
Training Epoch: 57 [25600/50176]	Loss: 4.6287
Training Epoch: 57 [26624/50176]	Loss: 4.6467
Training Epoch: 57 [27648/50176]	Loss: 4.6666
Training Epoch: 57 [28672/50176]	Loss: 4.6446
Training Epoch: 57 [29696/50176]	Loss: 4.6239
Training Epoch: 57 [30720/50176]	Loss: 4.6422
Training Epoch: 57 [31744/50176]	Loss: 4.6483
Training Epoch: 57 [32768/50176]	Loss: 4.6318
Training Epoch: 57 [33792/50176]	Loss: 4.6363
Training Epoch: 57 [34816/50176]	Loss: 4.6299
Training Epoch: 57 [35840/50176]	Loss: 4.6387
Training Epoch: 57 [36864/50176]	Loss: 4.6384
Training Epoch: 57 [37888/50176]	Loss: 4.6473
Training Epoch: 57 [38912/50176]	Loss: 4.6442
Training Epoch: 57 [39936/50176]	Loss: 4.6279
Training Epoch: 57 [40960/50176]	Loss: 4.6497
Training Epoch: 57 [41984/50176]	Loss: 4.6335
Training Epoch: 57 [43008/50176]	Loss: 4.6250
Training Epoch: 57 [44032/50176]	Loss: 4.6294
Training Epoch: 57 [45056/50176]	Loss: 4.6286
Training Epoch: 57 [46080/50176]	Loss: 4.6311
Training Epoch: 57 [47104/50176]	Loss: 4.6496
Training Epoch: 57 [48128/50176]	Loss: 4.6283
Training Epoch: 57 [49152/50176]	Loss: 4.6364
Training Epoch: 57 [50176/50176]	Loss: 4.6313
2022-12-06 20:18:14.541 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:18:14,588 [ZeusDataLoader(eval)] eval epoch 58 done: time=3.79 energy=476.68
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Up to epoch 58: time=2774.39, energy=365525.06, cost=425522.00
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:18:14,588 [ZeusDataLoader(train)] Expected next epoch: time=2821.00, energy=371891.36, cost=432783.24
2022-12-06 15:18:14,589 [ZeusDataLoader(train)] Epoch 59 begin.
Validation Epoch: 57, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:18:14,769 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:18:14,770 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:18:14.773 [ZeusMonitor] Monitor started.
2022-12-06 20:18:14.774 [ZeusMonitor] Running indefinitely. 2022-12-06 20:18:14.774 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:18:14.774 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e59+gpu0.power.log
2022-12-06 15:18:58,467 [ZeusDataLoader(train)] train epoch 59 done: time=43.87 energy=5845.17
2022-12-06 15:18:58,471 [ZeusDataLoader(eval)] Epoch 59 begin.
Training Epoch: 58 [1024/50176]	Loss: 4.6312
Training Epoch: 58 [2048/50176]	Loss: 4.6241
Training Epoch: 58 [3072/50176]	Loss: 4.6415
Training Epoch: 58 [4096/50176]	Loss: 4.6473
Training Epoch: 58 [5120/50176]	Loss: 4.6270
Training Epoch: 58 [6144/50176]	Loss: 4.6447
Training Epoch: 58 [7168/50176]	Loss: 4.6385
Training Epoch: 58 [8192/50176]	Loss: 4.6295
Training Epoch: 58 [9216/50176]	Loss: 4.6242
Training Epoch: 58 [10240/50176]	Loss: 4.6460
Training Epoch: 58 [11264/50176]	Loss: 4.6384
Training Epoch: 58 [12288/50176]	Loss: 4.6253
Training Epoch: 58 [13312/50176]	Loss: 4.6311
Training Epoch: 58 [14336/50176]	Loss: 4.6320
Training Epoch: 58 [15360/50176]	Loss: 4.6251
Training Epoch: 58 [16384/50176]	Loss: 4.6503
Training Epoch: 58 [17408/50176]	Loss: 4.6413
Training Epoch: 58 [18432/50176]	Loss: 4.6280
Training Epoch: 58 [19456/50176]	Loss: 4.6457
Training Epoch: 58 [20480/50176]	Loss: 4.6325
Training Epoch: 58 [21504/50176]	Loss: 4.6239
Training Epoch: 58 [22528/50176]	Loss: 4.6320
Training Epoch: 58 [23552/50176]	Loss: 4.6440
Training Epoch: 58 [24576/50176]	Loss: 4.6442
Training Epoch: 58 [25600/50176]	Loss: 4.6379
Training Epoch: 58 [26624/50176]	Loss: 4.6150
Training Epoch: 58 [27648/50176]	Loss: 4.6364
Training Epoch: 58 [28672/50176]	Loss: 4.6324
Training Epoch: 58 [29696/50176]	Loss: 4.6417
Training Epoch: 58 [30720/50176]	Loss: 4.6366
Training Epoch: 58 [31744/50176]	Loss: 4.6282
Training Epoch: 58 [32768/50176]	Loss: 4.6327
Training Epoch: 58 [33792/50176]	Loss: 4.6253
Training Epoch: 58 [34816/50176]	Loss: 4.6282
Training Epoch: 58 [35840/50176]	Loss: 4.6486
Training Epoch: 58 [36864/50176]	Loss: 4.6465
Training Epoch: 58 [37888/50176]	Loss: 4.6438
Training Epoch: 58 [38912/50176]	Loss: 4.6306
Training Epoch: 58 [39936/50176]	Loss: 4.6254
Training Epoch: 58 [40960/50176]	Loss: 4.6349
Training Epoch: 58 [41984/50176]	Loss: 4.6442
Training Epoch: 58 [43008/50176]	Loss: 4.6386
Training Epoch: 58 [44032/50176]	Loss: 4.6414
Training Epoch: 58 [45056/50176]	Loss: 4.6388
Training Epoch: 58 [46080/50176]	Loss: 4.6284
Training Epoch: 58 [47104/50176]	Loss: 4.6370
Training Epoch: 58 [48128/50176]	Loss: 4.6364
Training Epoch: 58 [49152/50176]	Loss: 4.6355
Training Epoch: 58 [50176/50176]	Loss: 4.6390
2022-12-06 20:19:02.228 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:19:02,258 [ZeusDataLoader(eval)] eval epoch 59 done: time=3.78 energy=479.90
2022-12-06 15:19:02,258 [ZeusDataLoader(train)] Up to epoch 59: time=2822.04, energy=371850.13, cost=432853.84
2022-12-06 15:19:02,258 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:19:02,259 [ZeusDataLoader(train)] Expected next epoch: time=2868.65, energy=378216.43, cost=440115.08
2022-12-06 15:19:02,260 [ZeusDataLoader(train)] Epoch 60 begin.
Validation Epoch: 58, Average loss: 96.4861, Accuracy: 0.0098
2022-12-06 15:19:02,508 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:19:02,508 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:19:02.510 [ZeusMonitor] Monitor started.
2022-12-06 20:19:02.510 [ZeusMonitor] Running indefinitely. 2022-12-06 20:19:02.510 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:19:02.510 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e60+gpu0.power.log
2022-12-06 15:19:45,931 [ZeusDataLoader(train)] train epoch 60 done: time=43.66 energy=5821.24
2022-12-06 15:19:45,934 [ZeusDataLoader(eval)] Epoch 60 begin.
Training Epoch: 59 [1024/50176]	Loss: 4.6252
Training Epoch: 59 [2048/50176]	Loss: 4.6430
Training Epoch: 59 [3072/50176]	Loss: 4.6383
Training Epoch: 59 [4096/50176]	Loss: 4.6363
Training Epoch: 59 [5120/50176]	Loss: 4.6296
Training Epoch: 59 [6144/50176]	Loss: 4.6294
Training Epoch: 59 [7168/50176]	Loss: 4.6362
Training Epoch: 59 [8192/50176]	Loss: 4.6375
Training Epoch: 59 [9216/50176]	Loss: 4.6366
Training Epoch: 59 [10240/50176]	Loss: 4.6441
Training Epoch: 59 [11264/50176]	Loss: 4.6314
Training Epoch: 59 [12288/50176]	Loss: 4.6417
Training Epoch: 59 [13312/50176]	Loss: 4.6329
Training Epoch: 59 [14336/50176]	Loss: 4.6427
Training Epoch: 59 [15360/50176]	Loss: 4.6538
Training Epoch: 59 [16384/50176]	Loss: 4.6325
Training Epoch: 59 [17408/50176]	Loss: 4.6309
Training Epoch: 59 [18432/50176]	Loss: 4.6453
Training Epoch: 59 [19456/50176]	Loss: 4.6564
Training Epoch: 59 [20480/50176]	Loss: 4.6408
Training Epoch: 59 [21504/50176]	Loss: 4.6237
Training Epoch: 59 [22528/50176]	Loss: 4.6387
Training Epoch: 59 [23552/50176]	Loss: 4.6389
Training Epoch: 59 [24576/50176]	Loss: 4.6370
Training Epoch: 59 [25600/50176]	Loss: 4.6350
Training Epoch: 59 [26624/50176]	Loss: 4.6394
Training Epoch: 59 [27648/50176]	Loss: 4.6381
Training Epoch: 59 [28672/50176]	Loss: 4.6227
Training Epoch: 59 [29696/50176]	Loss: 4.6461
Training Epoch: 59 [30720/50176]	Loss: 4.6514
Training Epoch: 59 [31744/50176]	Loss: 4.6465
Training Epoch: 59 [32768/50176]	Loss: 4.6279
Training Epoch: 59 [33792/50176]	Loss: 4.6376
Training Epoch: 59 [34816/50176]	Loss: 4.6557
Training Epoch: 59 [35840/50176]	Loss: 4.6577
Training Epoch: 59 [36864/50176]	Loss: 4.6401
Training Epoch: 59 [37888/50176]	Loss: 4.6485
Training Epoch: 59 [38912/50176]	Loss: 4.6411
Training Epoch: 59 [39936/50176]	Loss: 4.6450
Training Epoch: 59 [40960/50176]	Loss: 4.6587
Training Epoch: 59 [41984/50176]	Loss: 4.6531
Training Epoch: 59 [43008/50176]	Loss: 4.6617
Training Epoch: 59 [44032/50176]	Loss: 4.6536
Training Epoch: 59 [45056/50176]	Loss: 4.6443
Training Epoch: 59 [46080/50176]	Loss: 4.6273
Training Epoch: 59 [47104/50176]	Loss: 4.6447
Training Epoch: 59 [48128/50176]	Loss: 4.6404
Training Epoch: 59 [49152/50176]	Loss: 4.6519
Training Epoch: 59 [50176/50176]	Loss: 4.6362
2022-12-06 20:19:49.655 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:19:49,677 [ZeusDataLoader(eval)] eval epoch 60 done: time=3.73 energy=461.63
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Up to epoch 60: time=2869.44, energy=378133.01, cost=440142.59
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:19:49,677 [ZeusDataLoader(train)] Expected next epoch: time=2916.05, energy=384499.31, cost=447403.82
2022-12-06 15:19:49,678 [ZeusDataLoader(train)] Epoch 61 begin.
Validation Epoch: 59, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:19:49,909 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:19:49,910 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:19:49.912 [ZeusMonitor] Monitor started.
2022-12-06 20:19:49.912 [ZeusMonitor] Running indefinitely. 2022-12-06 20:19:49.912 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:19:49.912 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e61+gpu0.power.log
2022-12-06 15:20:33,542 [ZeusDataLoader(train)] train epoch 61 done: time=43.86 energy=5837.68
2022-12-06 15:20:33,546 [ZeusDataLoader(eval)] Epoch 61 begin.
Training Epoch: 60 [1024/50176]	Loss: 4.6224
Training Epoch: 60 [2048/50176]	Loss: 4.6470
Training Epoch: 60 [3072/50176]	Loss: 4.6521
Training Epoch: 60 [4096/50176]	Loss: 4.6309
Training Epoch: 60 [5120/50176]	Loss: 4.6411
Training Epoch: 60 [6144/50176]	Loss: 4.6544
Training Epoch: 60 [7168/50176]	Loss: 4.6501
Training Epoch: 60 [8192/50176]	Loss: 4.6283
Training Epoch: 60 [9216/50176]	Loss: 4.6206
Training Epoch: 60 [10240/50176]	Loss: 4.6311
Training Epoch: 60 [11264/50176]	Loss: 4.6272
Training Epoch: 60 [12288/50176]	Loss: 4.6270
Training Epoch: 60 [13312/50176]	Loss: 4.6372
Training Epoch: 60 [14336/50176]	Loss: 4.6520
Training Epoch: 60 [15360/50176]	Loss: 4.6366
Training Epoch: 60 [16384/50176]	Loss: 4.6434
Training Epoch: 60 [17408/50176]	Loss: 4.6309
Training Epoch: 60 [18432/50176]	Loss: 4.6251
Training Epoch: 60 [19456/50176]	Loss: 4.6486
Training Epoch: 60 [20480/50176]	Loss: 4.6457
Training Epoch: 60 [21504/50176]	Loss: 4.6234
Training Epoch: 60 [22528/50176]	Loss: 4.6320
Training Epoch: 60 [23552/50176]	Loss: 4.6559
Training Epoch: 60 [24576/50176]	Loss: 4.6433
Training Epoch: 60 [25600/50176]	Loss: 4.6324
Training Epoch: 60 [26624/50176]	Loss: 4.6469
Training Epoch: 60 [27648/50176]	Loss: 4.6253
Training Epoch: 60 [28672/50176]	Loss: 4.6331
Training Epoch: 60 [29696/50176]	Loss: 4.6316
Training Epoch: 60 [30720/50176]	Loss: 4.6406
Training Epoch: 60 [31744/50176]	Loss: 4.6336
Training Epoch: 60 [32768/50176]	Loss: 4.6564
Training Epoch: 60 [33792/50176]	Loss: 4.6343
Training Epoch: 60 [34816/50176]	Loss: 4.6304
Training Epoch: 60 [35840/50176]	Loss: 4.6339
Training Epoch: 60 [36864/50176]	Loss: 4.6384
Training Epoch: 60 [37888/50176]	Loss: 4.6391
Training Epoch: 60 [38912/50176]	Loss: 4.6325
Training Epoch: 60 [39936/50176]	Loss: 4.6390
Training Epoch: 60 [40960/50176]	Loss: 4.6458
Training Epoch: 60 [41984/50176]	Loss: 4.6572
Training Epoch: 60 [43008/50176]	Loss: 4.6406
Training Epoch: 60 [44032/50176]	Loss: 4.6349
Training Epoch: 60 [45056/50176]	Loss: 4.6287
Training Epoch: 60 [46080/50176]	Loss: 4.6244
Training Epoch: 60 [47104/50176]	Loss: 4.6355
Training Epoch: 60 [48128/50176]	Loss: 4.6389
Training Epoch: 60 [49152/50176]	Loss: 4.6449
Training Epoch: 60 [50176/50176]	Loss: 4.6320
2022-12-06 20:20:37.283 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:20:37,307 [ZeusDataLoader(eval)] eval epoch 61 done: time=3.75 energy=462.44
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Up to epoch 61: time=2917.05, energy=384433.13, cost=447458.41
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:20:37,307 [ZeusDataLoader(train)] Expected next epoch: time=2963.66, energy=390799.42, cost=454719.65
2022-12-06 15:20:37,308 [ZeusDataLoader(train)] Epoch 62 begin.
Validation Epoch: 60, Average loss: 0.0045, Accuracy: 0.0097
2022-12-06 15:20:37,550 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:20:37,551 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:20:37.565 [ZeusMonitor] Monitor started.
2022-12-06 20:20:37.565 [ZeusMonitor] Running indefinitely. 2022-12-06 20:20:37.565 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:20:37.565 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e62+gpu0.power.log
2022-12-06 15:21:21,118 [ZeusDataLoader(train)] train epoch 62 done: time=43.80 energy=5834.15
2022-12-06 15:21:21,121 [ZeusDataLoader(eval)] Epoch 62 begin.
Training Epoch: 61 [1024/50176]	Loss: 4.6318
Training Epoch: 61 [2048/50176]	Loss: 4.6215
Training Epoch: 61 [3072/50176]	Loss: 4.6324
Training Epoch: 61 [4096/50176]	Loss: 4.6290
Training Epoch: 61 [5120/50176]	Loss: 4.6318
Training Epoch: 61 [6144/50176]	Loss: 4.6310
Training Epoch: 61 [7168/50176]	Loss: 4.6318
Training Epoch: 61 [8192/50176]	Loss: 4.6278
Training Epoch: 61 [9216/50176]	Loss: 4.6344
Training Epoch: 61 [10240/50176]	Loss: 4.6406
Training Epoch: 61 [11264/50176]	Loss: 4.6280
Training Epoch: 61 [12288/50176]	Loss: 4.6234
Training Epoch: 61 [13312/50176]	Loss: 4.6471
Training Epoch: 61 [14336/50176]	Loss: 4.6445
Training Epoch: 61 [15360/50176]	Loss: 4.6252
Training Epoch: 61 [16384/50176]	Loss: 4.6310
Training Epoch: 61 [17408/50176]	Loss: 4.6362
Training Epoch: 61 [18432/50176]	Loss: 4.6451
Training Epoch: 61 [19456/50176]	Loss: 4.6274
Training Epoch: 61 [20480/50176]	Loss: 4.6496
Training Epoch: 61 [21504/50176]	Loss: 4.6371
Training Epoch: 61 [22528/50176]	Loss: 4.6401
Training Epoch: 61 [23552/50176]	Loss: 4.6321
Training Epoch: 61 [24576/50176]	Loss: 4.6265
Training Epoch: 61 [25600/50176]	Loss: 4.6456
Training Epoch: 61 [26624/50176]	Loss: 4.6211
Training Epoch: 61 [27648/50176]	Loss: 4.6257
Training Epoch: 61 [28672/50176]	Loss: 4.6319
Training Epoch: 61 [29696/50176]	Loss: 4.6410
Training Epoch: 61 [30720/50176]	Loss: 4.6304
Training Epoch: 61 [31744/50176]	Loss: 4.6490
Training Epoch: 61 [32768/50176]	Loss: 4.6411
Training Epoch: 61 [33792/50176]	Loss: 4.6308
Training Epoch: 61 [34816/50176]	Loss: 4.6364
Training Epoch: 61 [35840/50176]	Loss: 4.6443
Training Epoch: 61 [36864/50176]	Loss: 4.6303
Training Epoch: 61 [37888/50176]	Loss: 4.6363
Training Epoch: 61 [38912/50176]	Loss: 4.6497
Training Epoch: 61 [39936/50176]	Loss: 4.6408
Training Epoch: 61 [40960/50176]	Loss: 4.6320
Training Epoch: 61 [41984/50176]	Loss: 4.6221
Training Epoch: 61 [43008/50176]	Loss: 4.6286
Training Epoch: 61 [44032/50176]	Loss: 4.6380
Training Epoch: 61 [45056/50176]	Loss: 4.6407
Training Epoch: 61 [46080/50176]	Loss: 4.6526
Training Epoch: 61 [47104/50176]	Loss: 4.6408
Training Epoch: 61 [48128/50176]	Loss: 4.6451
Training Epoch: 61 [49152/50176]	Loss: 4.6576
Training Epoch: 61 [50176/50176]	Loss: 4.6318
2022-12-06 20:21:24.998 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:21:25,036 [ZeusDataLoader(eval)] eval epoch 62 done: time=3.91 energy=487.06
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Up to epoch 62: time=2964.76, energy=390754.33, cost=454793.44
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:21:25,036 [ZeusDataLoader(train)] Expected next epoch: time=3011.36, energy=397120.63, cost=462054.67
2022-12-06 15:21:25,037 [ZeusDataLoader(train)] Epoch 63 begin.
Validation Epoch: 61, Average loss: 1057.8528, Accuracy: 0.0098
2022-12-06 15:21:25,299 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:21:25,299 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:21:25.301 [ZeusMonitor] Monitor started.
2022-12-06 20:21:25.301 [ZeusMonitor] Running indefinitely. 2022-12-06 20:21:25.301 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:21:25.301 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e63+gpu0.power.log
2022-12-06 15:22:08,865 [ZeusDataLoader(train)] train epoch 63 done: time=43.82 energy=5833.88
2022-12-06 15:22:08,868 [ZeusDataLoader(eval)] Epoch 63 begin.
Training Epoch: 62 [1024/50176]	Loss: 4.6296
Training Epoch: 62 [2048/50176]	Loss: 4.6162
Training Epoch: 62 [3072/50176]	Loss: 4.6396
Training Epoch: 62 [4096/50176]	Loss: 4.6422
Training Epoch: 62 [5120/50176]	Loss: 4.6407
Training Epoch: 62 [6144/50176]	Loss: 4.6618
Training Epoch: 62 [7168/50176]	Loss: 4.6358
Training Epoch: 62 [8192/50176]	Loss: 4.6460
Training Epoch: 62 [9216/50176]	Loss: 4.6342
Training Epoch: 62 [10240/50176]	Loss: 4.6223
Training Epoch: 62 [11264/50176]	Loss: 4.6221
Training Epoch: 62 [12288/50176]	Loss: 4.6522
Training Epoch: 62 [13312/50176]	Loss: 4.6469
Training Epoch: 62 [14336/50176]	Loss: 4.6491
Training Epoch: 62 [15360/50176]	Loss: 4.6509
Training Epoch: 62 [16384/50176]	Loss: 4.6447
Training Epoch: 62 [17408/50176]	Loss: 4.6169
Training Epoch: 62 [18432/50176]	Loss: 4.6281
Training Epoch: 62 [19456/50176]	Loss: 4.6447
Training Epoch: 62 [20480/50176]	Loss: 4.6448
Training Epoch: 62 [21504/50176]	Loss: 4.6512
Training Epoch: 62 [22528/50176]	Loss: 4.6274
Training Epoch: 62 [23552/50176]	Loss: 4.6527
Training Epoch: 62 [24576/50176]	Loss: 4.6421
Training Epoch: 62 [25600/50176]	Loss: 4.6339
Training Epoch: 62 [26624/50176]	Loss: 4.6268
Training Epoch: 62 [27648/50176]	Loss: 4.6401
Training Epoch: 62 [28672/50176]	Loss: 4.6174
Training Epoch: 62 [29696/50176]	Loss: 4.6446
Training Epoch: 62 [30720/50176]	Loss: 4.6459
Training Epoch: 62 [31744/50176]	Loss: 4.6395
Training Epoch: 62 [32768/50176]	Loss: 4.6470
Training Epoch: 62 [33792/50176]	Loss: 4.6392
Training Epoch: 62 [34816/50176]	Loss: 4.6357
Training Epoch: 62 [35840/50176]	Loss: 4.6148
Training Epoch: 62 [36864/50176]	Loss: 4.6394
Training Epoch: 62 [37888/50176]	Loss: 4.6280
Training Epoch: 62 [38912/50176]	Loss: 4.6495
Training Epoch: 62 [39936/50176]	Loss: 4.6497
Training Epoch: 62 [40960/50176]	Loss: 4.6442
Training Epoch: 62 [41984/50176]	Loss: 4.6281
Training Epoch: 62 [43008/50176]	Loss: 4.6377
Training Epoch: 62 [44032/50176]	Loss: 4.6278
Training Epoch: 62 [45056/50176]	Loss: 4.6456
Training Epoch: 62 [46080/50176]	Loss: 4.6356
Training Epoch: 62 [47104/50176]	Loss: 4.6369
Training Epoch: 62 [48128/50176]	Loss: 4.6265
Training Epoch: 62 [49152/50176]	Loss: 4.6459
Training Epoch: 62 [50176/50176]	Loss: 4.6417
2022-12-06 20:22:12.734 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:22:12,790 [ZeusDataLoader(eval)] eval epoch 63 done: time=3.91 energy=494.50
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Up to epoch 63: time=3012.49, energy=397082.71, cost=462134.31
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:22:12,790 [ZeusDataLoader(train)] Expected next epoch: time=3059.10, energy=403449.00, cost=469395.54
2022-12-06 15:22:12,791 [ZeusDataLoader(train)] Epoch 64 begin.
Validation Epoch: 62, Average loss: 3924.0224, Accuracy: 0.0098
2022-12-06 15:22:13,034 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:22:13,034 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:22:13.036 [ZeusMonitor] Monitor started.
2022-12-06 20:22:13.036 [ZeusMonitor] Running indefinitely. 2022-12-06 20:22:13.036 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:22:13.036 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e64+gpu0.power.log
2022-12-06 15:22:56,694 [ZeusDataLoader(train)] train epoch 64 done: time=43.89 energy=5837.27
2022-12-06 15:22:56,697 [ZeusDataLoader(eval)] Epoch 64 begin.
Training Epoch: 63 [1024/50176]	Loss: 4.6398
Training Epoch: 63 [2048/50176]	Loss: 4.6248
Training Epoch: 63 [3072/50176]	Loss: 4.6484
Training Epoch: 63 [4096/50176]	Loss: 4.6495
Training Epoch: 63 [5120/50176]	Loss: 4.6339
Training Epoch: 63 [6144/50176]	Loss: 4.6396
Training Epoch: 63 [7168/50176]	Loss: 4.6428
Training Epoch: 63 [8192/50176]	Loss: 4.6281
Training Epoch: 63 [9216/50176]	Loss: 4.6391
Training Epoch: 63 [10240/50176]	Loss: 4.6422
Training Epoch: 63 [11264/50176]	Loss: 4.6321
Training Epoch: 63 [12288/50176]	Loss: 4.6380
Training Epoch: 63 [13312/50176]	Loss: 4.6523
Training Epoch: 63 [14336/50176]	Loss: 4.6451
Training Epoch: 63 [15360/50176]	Loss: 4.6227
Training Epoch: 63 [16384/50176]	Loss: 4.6345
Training Epoch: 63 [17408/50176]	Loss: 4.6380
Training Epoch: 63 [18432/50176]	Loss: 4.6304
Training Epoch: 63 [19456/50176]	Loss: 4.6443
Training Epoch: 63 [20480/50176]	Loss: 4.6406
Training Epoch: 63 [21504/50176]	Loss: 4.6360
Training Epoch: 63 [22528/50176]	Loss: 4.6401
Training Epoch: 63 [23552/50176]	Loss: 4.6380
Training Epoch: 63 [24576/50176]	Loss: 4.6445
Training Epoch: 63 [25600/50176]	Loss: 4.6294
Training Epoch: 63 [26624/50176]	Loss: 4.6380
Training Epoch: 63 [27648/50176]	Loss: 4.6355
Training Epoch: 63 [28672/50176]	Loss: 4.6417
Training Epoch: 63 [29696/50176]	Loss: 4.6418
Training Epoch: 63 [30720/50176]	Loss: 4.6271
Training Epoch: 63 [31744/50176]	Loss: 4.6284
Training Epoch: 63 [32768/50176]	Loss: 4.6328
Training Epoch: 63 [33792/50176]	Loss: 4.6518
Training Epoch: 63 [34816/50176]	Loss: 4.6503
Training Epoch: 63 [35840/50176]	Loss: 4.6197
Training Epoch: 63 [36864/50176]	Loss: 4.6346
Training Epoch: 63 [37888/50176]	Loss: 4.6435
Training Epoch: 63 [38912/50176]	Loss: 4.6231
Training Epoch: 63 [39936/50176]	Loss: 4.6439
Training Epoch: 63 [40960/50176]	Loss: 4.6411
Training Epoch: 63 [41984/50176]	Loss: 4.6507
Training Epoch: 63 [43008/50176]	Loss: 4.6522
Training Epoch: 63 [44032/50176]	Loss: 4.6331
Training Epoch: 63 [45056/50176]	Loss: 4.6253
Training Epoch: 63 [46080/50176]	Loss: 4.6234
Training Epoch: 63 [47104/50176]	Loss: 4.6298
Training Epoch: 63 [48128/50176]	Loss: 4.6344
Training Epoch: 63 [49152/50176]	Loss: 4.6486
Training Epoch: 63 [50176/50176]	Loss: 4.6267
2022-12-06 20:23:00.403 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:23:00,413 [ZeusDataLoader(eval)] eval epoch 64 done: time=3.71 energy=466.32
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Up to epoch 64: time=3060.09, energy=403386.30, cost=469451.35
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:23:00,413 [ZeusDataLoader(train)] Expected next epoch: time=3106.70, energy=409752.59, cost=476712.58
2022-12-06 15:23:00,414 [ZeusDataLoader(train)] Epoch 65 begin.
Validation Epoch: 63, Average loss: 14420.2416, Accuracy: 0.0098
2022-12-06 15:23:00,615 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:23:00,616 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:23:00.619 [ZeusMonitor] Monitor started.
2022-12-06 20:23:00.619 [ZeusMonitor] Running indefinitely. 2022-12-06 20:23:00.619 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:23:00.619 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e65+gpu0.power.log
2022-12-06 15:23:44,183 [ZeusDataLoader(train)] train epoch 65 done: time=43.76 energy=5829.75
2022-12-06 15:23:44,186 [ZeusDataLoader(eval)] Epoch 65 begin.
Training Epoch: 64 [1024/50176]	Loss: 4.6296
Training Epoch: 64 [2048/50176]	Loss: 4.6346
Training Epoch: 64 [3072/50176]	Loss: 4.6303
Training Epoch: 64 [4096/50176]	Loss: 4.6462
Training Epoch: 64 [5120/50176]	Loss: 4.6388
Training Epoch: 64 [6144/50176]	Loss: 4.6404
Training Epoch: 64 [7168/50176]	Loss: 4.6297
Training Epoch: 64 [8192/50176]	Loss: 4.6364
Training Epoch: 64 [9216/50176]	Loss: 4.6376
Training Epoch: 64 [10240/50176]	Loss: 4.6378
Training Epoch: 64 [11264/50176]	Loss: 4.6401
Training Epoch: 64 [12288/50176]	Loss: 4.6381
Training Epoch: 64 [13312/50176]	Loss: 4.6228
Training Epoch: 64 [14336/50176]	Loss: 4.6292
Training Epoch: 64 [15360/50176]	Loss: 4.6324
Training Epoch: 64 [16384/50176]	Loss: 4.6433
Training Epoch: 64 [17408/50176]	Loss: 4.6309
Training Epoch: 64 [18432/50176]	Loss: 4.6402
Training Epoch: 64 [19456/50176]	Loss: 4.6110
Training Epoch: 64 [20480/50176]	Loss: 4.6584
Training Epoch: 64 [21504/50176]	Loss: 4.6409
Training Epoch: 64 [22528/50176]	Loss: 4.6273
Training Epoch: 64 [23552/50176]	Loss: 4.6347
Training Epoch: 64 [24576/50176]	Loss: 4.6331
Training Epoch: 64 [25600/50176]	Loss: 4.6311
Training Epoch: 64 [26624/50176]	Loss: 4.6441
Training Epoch: 64 [27648/50176]	Loss: 4.6351
Training Epoch: 64 [28672/50176]	Loss: 4.6352
Training Epoch: 64 [29696/50176]	Loss: 4.6576
Training Epoch: 64 [30720/50176]	Loss: 4.6427
Training Epoch: 64 [31744/50176]	Loss: 4.6229
Training Epoch: 64 [32768/50176]	Loss: 4.6248
Training Epoch: 64 [33792/50176]	Loss: 4.6500
Training Epoch: 64 [34816/50176]	Loss: 4.6417
Training Epoch: 64 [35840/50176]	Loss: 4.6397
Training Epoch: 64 [36864/50176]	Loss: 4.6382
Training Epoch: 64 [37888/50176]	Loss: 4.6367
Training Epoch: 64 [38912/50176]	Loss: 4.6370
Training Epoch: 64 [39936/50176]	Loss: 4.6251
Training Epoch: 64 [40960/50176]	Loss: 4.6304
Training Epoch: 64 [41984/50176]	Loss: 4.6343
Training Epoch: 64 [43008/50176]	Loss: 4.6377
Training Epoch: 64 [44032/50176]	Loss: 4.6581
Training Epoch: 64 [45056/50176]	Loss: 4.6331
Training Epoch: 64 [46080/50176]	Loss: 4.6401
Training Epoch: 64 [47104/50176]	Loss: 4.6319
Training Epoch: 64 [48128/50176]	Loss: 4.6314
Training Epoch: 64 [49152/50176]	Loss: 4.6279
Training Epoch: 64 [50176/50176]	Loss: 4.6415
2022-12-06 20:23:47.889 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:23:47,924 [ZeusDataLoader(eval)] eval epoch 65 done: time=3.73 energy=468.00
2022-12-06 15:23:47,924 [ZeusDataLoader(train)] Up to epoch 65: time=3107.59, energy=409684.05, cost=476755.74
2022-12-06 15:23:47,925 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:23:47,925 [ZeusDataLoader(train)] Expected next epoch: time=3154.19, energy=416050.34, cost=484016.98
2022-12-06 15:23:47,926 [ZeusDataLoader(train)] Epoch 66 begin.
Validation Epoch: 64, Average loss: 1409.7685, Accuracy: 0.0098
2022-12-06 15:23:48,176 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:23:48,177 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:23:48.178 [ZeusMonitor] Monitor started.
2022-12-06 20:23:48.178 [ZeusMonitor] Running indefinitely. 2022-12-06 20:23:48.178 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:23:48.178 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e66+gpu0.power.log
2022-12-06 15:24:31,681 [ZeusDataLoader(train)] train epoch 66 done: time=43.75 energy=5822.31
2022-12-06 15:24:31,684 [ZeusDataLoader(eval)] Epoch 66 begin.
Training Epoch: 65 [1024/50176]	Loss: 4.6285
Training Epoch: 65 [2048/50176]	Loss: 4.6323
Training Epoch: 65 [3072/50176]	Loss: 4.6421
Training Epoch: 65 [4096/50176]	Loss: 4.6406
Training Epoch: 65 [5120/50176]	Loss: 4.6396
Training Epoch: 65 [6144/50176]	Loss: 4.6263
Training Epoch: 65 [7168/50176]	Loss: 4.6284
Training Epoch: 65 [8192/50176]	Loss: 4.6327
Training Epoch: 65 [9216/50176]	Loss: 4.6455
Training Epoch: 65 [10240/50176]	Loss: 4.6376
Training Epoch: 65 [11264/50176]	Loss: 4.6412
Training Epoch: 65 [12288/50176]	Loss: 4.6478
Training Epoch: 65 [13312/50176]	Loss: 4.6380
Training Epoch: 65 [14336/50176]	Loss: 4.6345
Training Epoch: 65 [15360/50176]	Loss: 4.6351
Training Epoch: 65 [16384/50176]	Loss: 4.6366
Training Epoch: 65 [17408/50176]	Loss: 4.6408
Training Epoch: 65 [18432/50176]	Loss: 4.6292
Training Epoch: 65 [19456/50176]	Loss: 4.6485
Training Epoch: 65 [20480/50176]	Loss: 4.6161
Training Epoch: 65 [21504/50176]	Loss: 4.6429
Training Epoch: 65 [22528/50176]	Loss: 4.6325
Training Epoch: 65 [23552/50176]	Loss: 4.6427
Training Epoch: 65 [24576/50176]	Loss: 4.6366
Training Epoch: 65 [25600/50176]	Loss: 4.6314
Training Epoch: 65 [26624/50176]	Loss: 4.6352
Training Epoch: 65 [27648/50176]	Loss: 4.6367
Training Epoch: 65 [28672/50176]	Loss: 4.6248
Training Epoch: 65 [29696/50176]	Loss: 4.6273
Training Epoch: 65 [30720/50176]	Loss: 4.6503
Training Epoch: 65 [31744/50176]	Loss: 4.6282
Training Epoch: 65 [32768/50176]	Loss: 4.6468
Training Epoch: 65 [33792/50176]	Loss: 4.6416
Training Epoch: 65 [34816/50176]	Loss: 4.6528
Training Epoch: 65 [35840/50176]	Loss: 4.6403
Training Epoch: 65 [36864/50176]	Loss: 4.6332
Training Epoch: 65 [37888/50176]	Loss: 4.6146
Training Epoch: 65 [38912/50176]	Loss: 4.6350
Training Epoch: 65 [39936/50176]	Loss: 4.6429
Training Epoch: 65 [40960/50176]	Loss: 4.6434
Training Epoch: 65 [41984/50176]	Loss: 4.6389
Training Epoch: 65 [43008/50176]	Loss: 4.6343
Training Epoch: 65 [44032/50176]	Loss: 4.6180
Training Epoch: 65 [45056/50176]	Loss: 4.6379
Training Epoch: 65 [46080/50176]	Loss: 4.6445
Training Epoch: 65 [47104/50176]	Loss: 4.6378
Training Epoch: 65 [48128/50176]	Loss: 4.6513
Training Epoch: 65 [49152/50176]	Loss: 4.6477
Training Epoch: 65 [50176/50176]	Loss: 4.6287
2022-12-06 20:24:35.395 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:24:35,411 [ZeusDataLoader(eval)] eval epoch 66 done: time=3.72 energy=462.70
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Up to epoch 66: time=3155.05, energy=415969.06, cost=484051.57
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:24:35,412 [ZeusDataLoader(train)] Expected next epoch: time=3201.66, energy=422335.35, cost=491312.80
2022-12-06 15:24:35,413 [ZeusDataLoader(train)] Epoch 67 begin.
Validation Epoch: 65, Average loss: 71545.0193, Accuracy: 0.0098
2022-12-06 15:24:35,607 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:24:35,608 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:24:35.611 [ZeusMonitor] Monitor started.
2022-12-06 20:24:35.611 [ZeusMonitor] Running indefinitely. 2022-12-06 20:24:35.611 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:24:35.611 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e67+gpu0.power.log
2022-12-06 15:25:19,393 [ZeusDataLoader(train)] train epoch 67 done: time=43.97 energy=5839.62
2022-12-06 15:25:19,396 [ZeusDataLoader(eval)] Epoch 67 begin.
Training Epoch: 66 [1024/50176]	Loss: 4.6403
Training Epoch: 66 [2048/50176]	Loss: 4.6362
Training Epoch: 66 [3072/50176]	Loss: 4.6333
Training Epoch: 66 [4096/50176]	Loss: 4.6442
Training Epoch: 66 [5120/50176]	Loss: 4.6377
Training Epoch: 66 [6144/50176]	Loss: 4.6362
Training Epoch: 66 [7168/50176]	Loss: 4.6408
Training Epoch: 66 [8192/50176]	Loss: 4.6543
Training Epoch: 66 [9216/50176]	Loss: 4.6425
Training Epoch: 66 [10240/50176]	Loss: 4.6355
Training Epoch: 66 [11264/50176]	Loss: 4.6321
Training Epoch: 66 [12288/50176]	Loss: 4.6477
Training Epoch: 66 [13312/50176]	Loss: 4.6395
Training Epoch: 66 [14336/50176]	Loss: 4.6499
Training Epoch: 66 [15360/50176]	Loss: 4.6406
Training Epoch: 66 [16384/50176]	Loss: 4.6290
Training Epoch: 66 [17408/50176]	Loss: 4.6349
Training Epoch: 66 [18432/50176]	Loss: 4.6490
Training Epoch: 66 [19456/50176]	Loss: 4.6493
Training Epoch: 66 [20480/50176]	Loss: 4.6326
Training Epoch: 66 [21504/50176]	Loss: 4.6381
Training Epoch: 66 [22528/50176]	Loss: 4.6327
Training Epoch: 66 [23552/50176]	Loss: 4.6254
Training Epoch: 66 [24576/50176]	Loss: 4.6347
Training Epoch: 66 [25600/50176]	Loss: 4.6529
Training Epoch: 66 [26624/50176]	Loss: 4.6510
Training Epoch: 66 [27648/50176]	Loss: 4.6466
Training Epoch: 66 [28672/50176]	Loss: 4.6424
Training Epoch: 66 [29696/50176]	Loss: 4.6307
Training Epoch: 66 [30720/50176]	Loss: 4.6393
Training Epoch: 66 [31744/50176]	Loss: 4.6303
Training Epoch: 66 [32768/50176]	Loss: 4.6374
Training Epoch: 66 [33792/50176]	Loss: 4.6276
Training Epoch: 66 [34816/50176]	Loss: 4.6369
Training Epoch: 66 [35840/50176]	Loss: 4.6289
Training Epoch: 66 [36864/50176]	Loss: 4.6408
Training Epoch: 66 [37888/50176]	Loss: 4.6281
Training Epoch: 66 [38912/50176]	Loss: 4.6468
Training Epoch: 66 [39936/50176]	Loss: 4.6301
Training Epoch: 66 [40960/50176]	Loss: 4.6326
Training Epoch: 66 [41984/50176]	Loss: 4.6337
Training Epoch: 66 [43008/50176]	Loss: 4.6468
Training Epoch: 66 [44032/50176]	Loss: 4.6244
Training Epoch: 66 [45056/50176]	Loss: 4.6496
Training Epoch: 66 [46080/50176]	Loss: 4.6210
Training Epoch: 66 [47104/50176]	Loss: 4.6373
Training Epoch: 66 [48128/50176]	Loss: 4.6289
Training Epoch: 66 [49152/50176]	Loss: 4.6329
Training Epoch: 66 [50176/50176]	Loss: 4.6331
2022-12-06 20:25:23.190 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:25:23,221 [ZeusDataLoader(eval)] eval epoch 67 done: time=3.82 energy=482.69
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Up to epoch 67: time=3202.84, energy=422291.37, cost=491394.34
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:25:23,222 [ZeusDataLoader(train)] Expected next epoch: time=3249.45, energy=428657.67, cost=498655.58
2022-12-06 15:25:23,223 [ZeusDataLoader(train)] Epoch 68 begin.
Validation Epoch: 66, Average loss: 1680.4798, Accuracy: 0.0098
2022-12-06 15:25:23,477 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:25:23,478 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:25:23.479 [ZeusMonitor] Monitor started.
2022-12-06 20:25:23.480 [ZeusMonitor] Running indefinitely. 2022-12-06 20:25:23.480 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:25:23.480 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e68+gpu0.power.log
2022-12-06 15:26:06,999 [ZeusDataLoader(train)] train epoch 68 done: time=43.77 energy=5828.59
2022-12-06 15:26:07,002 [ZeusDataLoader(eval)] Epoch 68 begin.
Training Epoch: 67 [1024/50176]	Loss: 4.6432
Training Epoch: 67 [2048/50176]	Loss: 4.6449
Training Epoch: 67 [3072/50176]	Loss: 4.6391
Training Epoch: 67 [4096/50176]	Loss: 4.6464
Training Epoch: 67 [5120/50176]	Loss: 4.6547
Training Epoch: 67 [6144/50176]	Loss: 4.6448
Training Epoch: 67 [7168/50176]	Loss: 4.6347
Training Epoch: 67 [8192/50176]	Loss: 4.6383
Training Epoch: 67 [9216/50176]	Loss: 4.6450
Training Epoch: 67 [10240/50176]	Loss: 4.6572
Training Epoch: 67 [11264/50176]	Loss: 4.6437
Training Epoch: 67 [12288/50176]	Loss: 4.6413
Training Epoch: 67 [13312/50176]	Loss: 4.6510
Training Epoch: 67 [14336/50176]	Loss: 4.6232
Training Epoch: 67 [15360/50176]	Loss: 4.6439
Training Epoch: 67 [16384/50176]	Loss: 4.6417
Training Epoch: 67 [17408/50176]	Loss: 4.6372
Training Epoch: 67 [18432/50176]	Loss: 4.6508
Training Epoch: 67 [19456/50176]	Loss: 4.6488
Training Epoch: 67 [20480/50176]	Loss: 4.6550
Training Epoch: 67 [21504/50176]	Loss: 4.6346
Training Epoch: 67 [22528/50176]	Loss: 4.6227
Training Epoch: 67 [23552/50176]	Loss: 4.6524
Training Epoch: 67 [24576/50176]	Loss: 4.6331
Training Epoch: 67 [25600/50176]	Loss: 4.6409
Training Epoch: 67 [26624/50176]	Loss: 4.6301
Training Epoch: 67 [27648/50176]	Loss: 4.6408
Training Epoch: 67 [28672/50176]	Loss: 4.6362
Training Epoch: 67 [29696/50176]	Loss: 4.6267
Training Epoch: 67 [30720/50176]	Loss: 4.6349
Training Epoch: 67 [31744/50176]	Loss: 4.6308
Training Epoch: 67 [32768/50176]	Loss: 4.6305
Training Epoch: 67 [33792/50176]	Loss: 4.6386
Training Epoch: 67 [34816/50176]	Loss: 4.6358
Training Epoch: 67 [35840/50176]	Loss: 4.6359
Training Epoch: 67 [36864/50176]	Loss: 4.6400
Training Epoch: 67 [37888/50176]	Loss: 4.6402
Training Epoch: 67 [38912/50176]	Loss: 4.6341
Training Epoch: 67 [39936/50176]	Loss: 4.6327
Training Epoch: 67 [40960/50176]	Loss: 4.6398
Training Epoch: 67 [41984/50176]	Loss: 4.6312
Training Epoch: 67 [43008/50176]	Loss: 4.6425
Training Epoch: 67 [44032/50176]	Loss: 4.6177
Training Epoch: 67 [45056/50176]	Loss: 4.6281
Training Epoch: 67 [46080/50176]	Loss: 4.6309
Training Epoch: 67 [47104/50176]	Loss: 4.6575
Training Epoch: 67 [48128/50176]	Loss: 4.6413
Training Epoch: 67 [49152/50176]	Loss: 4.6279
Training Epoch: 67 [50176/50176]	Loss: 4.6508
2022-12-06 20:26:10.782 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:26:10,827 [ZeusDataLoader(eval)] eval epoch 68 done: time=3.82 energy=477.06
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Up to epoch 68: time=3250.43, energy=428597.03, cost=498710.88
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:26:10,827 [ZeusDataLoader(train)] Expected next epoch: time=3297.03, energy=434963.32, cost=505972.11
2022-12-06 15:26:10,828 [ZeusDataLoader(train)] Epoch 69 begin.
Validation Epoch: 67, Average loss: 8505.2449, Accuracy: 0.0098
2022-12-06 15:26:11,065 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:26:11,065 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:26:11.074 [ZeusMonitor] Monitor started.
2022-12-06 20:26:11.074 [ZeusMonitor] Running indefinitely. 2022-12-06 20:26:11.074 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:26:11.074 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e69+gpu0.power.log
2022-12-06 15:26:54,679 [ZeusDataLoader(train)] train epoch 69 done: time=43.84 energy=5834.35
2022-12-06 15:26:54,682 [ZeusDataLoader(eval)] Epoch 69 begin.
Training Epoch: 68 [1024/50176]	Loss: 4.6358
Training Epoch: 68 [2048/50176]	Loss: 4.6319
Training Epoch: 68 [3072/50176]	Loss: 4.6274
Training Epoch: 68 [4096/50176]	Loss: 4.6370
Training Epoch: 68 [5120/50176]	Loss: 4.6422
Training Epoch: 68 [6144/50176]	Loss: 4.6404
Training Epoch: 68 [7168/50176]	Loss: 4.6406
Training Epoch: 68 [8192/50176]	Loss: 4.6377
Training Epoch: 68 [9216/50176]	Loss: 4.6437
Training Epoch: 68 [10240/50176]	Loss: 4.6452
Training Epoch: 68 [11264/50176]	Loss: 4.6382
Training Epoch: 68 [12288/50176]	Loss: 4.6446
Training Epoch: 68 [13312/50176]	Loss: 4.6439
Training Epoch: 68 [14336/50176]	Loss: 4.6357
Training Epoch: 68 [15360/50176]	Loss: 4.6434
Training Epoch: 68 [16384/50176]	Loss: 4.6416
Training Epoch: 68 [17408/50176]	Loss: 4.6353
Training Epoch: 68 [18432/50176]	Loss: 4.6578
Training Epoch: 68 [19456/50176]	Loss: 4.6326
Training Epoch: 68 [20480/50176]	Loss: 4.6352
Training Epoch: 68 [21504/50176]	Loss: 4.6355
Training Epoch: 68 [22528/50176]	Loss: 4.6426
Training Epoch: 68 [23552/50176]	Loss: 4.6470
Training Epoch: 68 [24576/50176]	Loss: 4.6355
Training Epoch: 68 [25600/50176]	Loss: 4.6453
Training Epoch: 68 [26624/50176]	Loss: 4.6423
Training Epoch: 68 [27648/50176]	Loss: 4.6371
Training Epoch: 68 [28672/50176]	Loss: 4.6292
Training Epoch: 68 [29696/50176]	Loss: 4.6429
Training Epoch: 68 [30720/50176]	Loss: 4.6403
Training Epoch: 68 [31744/50176]	Loss: 4.6237
Training Epoch: 68 [32768/50176]	Loss: 4.6347
Training Epoch: 68 [33792/50176]	Loss: 4.6444
Training Epoch: 68 [34816/50176]	Loss: 4.6277
Training Epoch: 68 [35840/50176]	Loss: 4.6229
Training Epoch: 68 [36864/50176]	Loss: 4.6301
Training Epoch: 68 [37888/50176]	Loss: 4.6343
Training Epoch: 68 [38912/50176]	Loss: 4.6335
Training Epoch: 68 [39936/50176]	Loss: 4.6355
Training Epoch: 68 [40960/50176]	Loss: 4.6409
Training Epoch: 68 [41984/50176]	Loss: 4.6377
Training Epoch: 68 [43008/50176]	Loss: 4.6376
Training Epoch: 68 [44032/50176]	Loss: 4.6386
Training Epoch: 68 [45056/50176]	Loss: 4.6264
Training Epoch: 68 [46080/50176]	Loss: 4.6313
Training Epoch: 68 [47104/50176]	Loss: 4.6388
Training Epoch: 68 [48128/50176]	Loss: 4.6395
Training Epoch: 68 [49152/50176]	Loss: 4.6311
Training Epoch: 68 [50176/50176]	Loss: 4.6565
2022-12-06 20:26:58.437 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:26:58,494 [ZeusDataLoader(eval)] eval epoch 69 done: time=3.80 energy=480.65
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Up to epoch 69: time=3298.07, energy=434912.03, cost=506037.46
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:26:58,494 [ZeusDataLoader(train)] Expected next epoch: time=3344.68, energy=441278.33, cost=513298.70
2022-12-06 15:26:58,495 [ZeusDataLoader(train)] Epoch 70 begin.
Validation Epoch: 68, Average loss: 5371.4322, Accuracy: 0.0098
2022-12-06 15:26:58,693 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:26:58,694 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:26:58.695 [ZeusMonitor] Monitor started.
2022-12-06 20:26:58.696 [ZeusMonitor] Running indefinitely. 2022-12-06 20:26:58.696 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:26:58.696 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e70+gpu0.power.log
2022-12-06 15:27:42,139 [ZeusDataLoader(train)] train epoch 70 done: time=43.64 energy=5820.54
2022-12-06 15:27:42,142 [ZeusDataLoader(eval)] Epoch 70 begin.
Training Epoch: 69 [1024/50176]	Loss: 4.6576
Training Epoch: 69 [2048/50176]	Loss: 4.6319
Training Epoch: 69 [3072/50176]	Loss: 4.6404
Training Epoch: 69 [4096/50176]	Loss: 4.6369
Training Epoch: 69 [5120/50176]	Loss: 4.6331
Training Epoch: 69 [6144/50176]	Loss: 4.6406
Training Epoch: 69 [7168/50176]	Loss: 4.6520
Training Epoch: 69 [8192/50176]	Loss: 4.6366
Training Epoch: 69 [9216/50176]	Loss: 4.6420
Training Epoch: 69 [10240/50176]	Loss: 4.6421
Training Epoch: 69 [11264/50176]	Loss: 4.6474
Training Epoch: 69 [12288/50176]	Loss: 4.6386
Training Epoch: 69 [13312/50176]	Loss: 4.6362
Training Epoch: 69 [14336/50176]	Loss: 4.6403
Training Epoch: 69 [15360/50176]	Loss: 4.6513
Training Epoch: 69 [16384/50176]	Loss: 4.6375
Training Epoch: 69 [17408/50176]	Loss: 4.6417
Training Epoch: 69 [18432/50176]	Loss: 4.6418
Training Epoch: 69 [19456/50176]	Loss: 4.6350
Training Epoch: 69 [20480/50176]	Loss: 4.6357
Training Epoch: 69 [21504/50176]	Loss: 4.6432
Training Epoch: 69 [22528/50176]	Loss: 4.6437
Training Epoch: 69 [23552/50176]	Loss: 4.6518
Training Epoch: 69 [24576/50176]	Loss: 4.6404
Training Epoch: 69 [25600/50176]	Loss: 4.6392
Training Epoch: 69 [26624/50176]	Loss: 4.6285
Training Epoch: 69 [27648/50176]	Loss: 4.6302
Training Epoch: 69 [28672/50176]	Loss: 4.6425
Training Epoch: 69 [29696/50176]	Loss: 4.6498
Training Epoch: 69 [30720/50176]	Loss: 4.6361
Training Epoch: 69 [31744/50176]	Loss: 4.6470
Training Epoch: 69 [32768/50176]	Loss: 4.6479
Training Epoch: 69 [33792/50176]	Loss: 4.6355
Training Epoch: 69 [34816/50176]	Loss: 4.6360
Training Epoch: 69 [35840/50176]	Loss: 4.6238
Training Epoch: 69 [36864/50176]	Loss: 4.6404
Training Epoch: 69 [37888/50176]	Loss: 4.6682
Training Epoch: 69 [38912/50176]	Loss: 4.6506
Training Epoch: 69 [39936/50176]	Loss: 4.6477
Training Epoch: 69 [40960/50176]	Loss: 4.6293
Training Epoch: 69 [41984/50176]	Loss: 4.6358
Training Epoch: 69 [43008/50176]	Loss: 4.6382
Training Epoch: 69 [44032/50176]	Loss: 4.6483
Training Epoch: 69 [45056/50176]	Loss: 4.6382
Training Epoch: 69 [46080/50176]	Loss: 4.6428
Training Epoch: 69 [47104/50176]	Loss: 4.6377
Training Epoch: 69 [48128/50176]	Loss: 4.6439
Training Epoch: 69 [49152/50176]	Loss: 4.6463
Training Epoch: 69 [50176/50176]	Loss: 4.6310
2022-12-06 20:27:45.855 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:27:45,870 [ZeusDataLoader(eval)] eval epoch 70 done: time=3.72 energy=465.43
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Up to epoch 70: time=3345.43, energy=441198.00, cost=513324.05
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:27:45,870 [ZeusDataLoader(train)] Expected next epoch: time=3392.04, energy=447564.30, cost=520585.29
2022-12-06 15:27:45,871 [ZeusDataLoader(train)] Epoch 71 begin.
Validation Epoch: 69, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:27:46,121 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:27:46,122 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:27:46.138 [ZeusMonitor] Monitor started.
2022-12-06 20:27:46.138 [ZeusMonitor] Running indefinitely. 2022-12-06 20:27:46.138 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:27:46.138 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e71+gpu0.power.log
2022-12-06 15:28:29,521 [ZeusDataLoader(train)] train epoch 71 done: time=43.64 energy=5817.17
2022-12-06 15:28:29,524 [ZeusDataLoader(eval)] Epoch 71 begin.
Training Epoch: 70 [1024/50176]	Loss: 4.6424
Training Epoch: 70 [2048/50176]	Loss: 4.6431
Training Epoch: 70 [3072/50176]	Loss: 4.6481
Training Epoch: 70 [4096/50176]	Loss: 4.6345
Training Epoch: 70 [5120/50176]	Loss: 4.6426
Training Epoch: 70 [6144/50176]	Loss: 4.6339
Training Epoch: 70 [7168/50176]	Loss: 4.6278
Training Epoch: 70 [8192/50176]	Loss: 4.6372
Training Epoch: 70 [9216/50176]	Loss: 4.6367
Training Epoch: 70 [10240/50176]	Loss: 4.6384
Training Epoch: 70 [11264/50176]	Loss: 4.6442
Training Epoch: 70 [12288/50176]	Loss: 4.6340
Training Epoch: 70 [13312/50176]	Loss: 4.6475
Training Epoch: 70 [14336/50176]	Loss: 4.6452
Training Epoch: 70 [15360/50176]	Loss: 4.6297
Training Epoch: 70 [16384/50176]	Loss: 4.6313
Training Epoch: 70 [17408/50176]	Loss: 4.6195
Training Epoch: 70 [18432/50176]	Loss: 4.6283
Training Epoch: 70 [19456/50176]	Loss: 4.6345
Training Epoch: 70 [20480/50176]	Loss: 4.6264
Training Epoch: 70 [21504/50176]	Loss: 4.6476
Training Epoch: 70 [22528/50176]	Loss: 4.6283
Training Epoch: 70 [23552/50176]	Loss: 4.6349
Training Epoch: 70 [24576/50176]	Loss: 4.6354
Training Epoch: 70 [25600/50176]	Loss: 4.6277
Training Epoch: 70 [26624/50176]	Loss: 4.6502
Training Epoch: 70 [27648/50176]	Loss: 4.6401
Training Epoch: 70 [28672/50176]	Loss: 4.6304
Training Epoch: 70 [29696/50176]	Loss: 4.6249
Training Epoch: 70 [30720/50176]	Loss: 4.6201
Training Epoch: 70 [31744/50176]	Loss: 4.6403
Training Epoch: 70 [32768/50176]	Loss: 4.6400
Training Epoch: 70 [33792/50176]	Loss: 4.6434
Training Epoch: 70 [34816/50176]	Loss: 4.6577
Training Epoch: 70 [35840/50176]	Loss: 4.6421
Training Epoch: 70 [36864/50176]	Loss: 4.6270
Training Epoch: 70 [37888/50176]	Loss: 4.6277
Training Epoch: 70 [38912/50176]	Loss: 4.6275
Training Epoch: 70 [39936/50176]	Loss: 4.6450
Training Epoch: 70 [40960/50176]	Loss: 4.6452
Training Epoch: 70 [41984/50176]	Loss: 4.6489
Training Epoch: 70 [43008/50176]	Loss: 4.6600
Training Epoch: 70 [44032/50176]	Loss: 4.6319
Training Epoch: 70 [45056/50176]	Loss: 4.6383
Training Epoch: 70 [46080/50176]	Loss: 4.6309
Training Epoch: 70 [47104/50176]	Loss: 4.6345
Training Epoch: 70 [48128/50176]	Loss: 4.6434
Training Epoch: 70 [49152/50176]	Loss: 4.6231
Training Epoch: 70 [50176/50176]	Loss: 4.6357
2022-12-06 20:28:33.328 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:28:33,351 [ZeusDataLoader(eval)] eval epoch 71 done: time=3.82 energy=471.44
2022-12-06 15:28:33,351 [ZeusDataLoader(train)] Up to epoch 71: time=3392.89, energy=447486.62, cost=520621.21
2022-12-06 15:28:33,352 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:28:33,352 [ZeusDataLoader(train)] Expected next epoch: time=3439.50, energy=453852.91, cost=527882.45
2022-12-06 15:28:33,353 [ZeusDataLoader(train)] Epoch 72 begin.
Validation Epoch: 70, Average loss: 6921.8770, Accuracy: 0.0098
2022-12-06 15:28:33,598 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:28:33,598 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:28:33.600 [ZeusMonitor] Monitor started.
2022-12-06 20:28:33.600 [ZeusMonitor] Running indefinitely. 2022-12-06 20:28:33.600 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:28:33.600 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e72+gpu0.power.log
2022-12-06 15:29:17,134 [ZeusDataLoader(train)] train epoch 72 done: time=43.77 energy=5825.79
2022-12-06 15:29:17,137 [ZeusDataLoader(eval)] Epoch 72 begin.
Training Epoch: 71 [1024/50176]	Loss: 4.6448
Training Epoch: 71 [2048/50176]	Loss: 4.6444
Training Epoch: 71 [3072/50176]	Loss: 4.6563
Training Epoch: 71 [4096/50176]	Loss: 4.6293
Training Epoch: 71 [5120/50176]	Loss: 4.6389
Training Epoch: 71 [6144/50176]	Loss: 4.6375
Training Epoch: 71 [7168/50176]	Loss: 4.6276
Training Epoch: 71 [8192/50176]	Loss: 4.6410
Training Epoch: 71 [9216/50176]	Loss: 4.6392
Training Epoch: 71 [10240/50176]	Loss: 4.6447
Training Epoch: 71 [11264/50176]	Loss: 4.6446
Training Epoch: 71 [12288/50176]	Loss: 4.6413
Training Epoch: 71 [13312/50176]	Loss: 4.6374
Training Epoch: 71 [14336/50176]	Loss: 4.6252
Training Epoch: 71 [15360/50176]	Loss: 4.6359
Training Epoch: 71 [16384/50176]	Loss: 4.6315
Training Epoch: 71 [17408/50176]	Loss: 4.6411
Training Epoch: 71 [18432/50176]	Loss: 4.6363
Training Epoch: 71 [19456/50176]	Loss: 4.6553
Training Epoch: 71 [20480/50176]	Loss: 4.6483
Training Epoch: 71 [21504/50176]	Loss: 4.6375
Training Epoch: 71 [22528/50176]	Loss: 4.6307
Training Epoch: 71 [23552/50176]	Loss: 4.6208
Training Epoch: 71 [24576/50176]	Loss: 4.6323
Training Epoch: 71 [25600/50176]	Loss: 4.6313
Training Epoch: 71 [26624/50176]	Loss: 4.6415
Training Epoch: 71 [27648/50176]	Loss: 4.6389
Training Epoch: 71 [28672/50176]	Loss: 4.6358
Training Epoch: 71 [29696/50176]	Loss: 4.6393
Training Epoch: 71 [30720/50176]	Loss: 4.6419
Training Epoch: 71 [31744/50176]	Loss: 4.6383
Training Epoch: 71 [32768/50176]	Loss: 4.6512
Training Epoch: 71 [33792/50176]	Loss: 4.6422
Training Epoch: 71 [34816/50176]	Loss: 4.6382
Training Epoch: 71 [35840/50176]	Loss: 4.6468
Training Epoch: 71 [36864/50176]	Loss: 4.6372
Training Epoch: 71 [37888/50176]	Loss: 4.6337
Training Epoch: 71 [38912/50176]	Loss: 4.6414
Training Epoch: 71 [39936/50176]	Loss: 4.6316
Training Epoch: 71 [40960/50176]	Loss: 4.6270
Training Epoch: 71 [41984/50176]	Loss: 4.6227
Training Epoch: 71 [43008/50176]	Loss: 4.6518
Training Epoch: 71 [44032/50176]	Loss: 4.6549
Training Epoch: 71 [45056/50176]	Loss: 4.6408
Training Epoch: 71 [46080/50176]	Loss: 4.6250
Training Epoch: 71 [47104/50176]	Loss: 4.6196
Training Epoch: 71 [48128/50176]	Loss: 4.6387
Training Epoch: 71 [49152/50176]	Loss: 4.6191
Training Epoch: 71 [50176/50176]	Loss: 4.6458
2022-12-06 20:29:21.025 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:29:21,058 [ZeusDataLoader(eval)] eval epoch 72 done: time=3.91 energy=484.44
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Up to epoch 72: time=3440.58, energy=453796.85, cost=527948.91
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:29:21,058 [ZeusDataLoader(train)] Expected next epoch: time=3487.18, energy=460163.15, cost=535210.15
2022-12-06 15:29:21,059 [ZeusDataLoader(train)] Epoch 73 begin.
Validation Epoch: 71, Average loss: 557.8394, Accuracy: 0.0098
2022-12-06 15:29:21,314 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:29:21,315 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:29:21.316 [ZeusMonitor] Monitor started.
2022-12-06 20:29:21.316 [ZeusMonitor] Running indefinitely. 2022-12-06 20:29:21.316 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:29:21.317 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e73+gpu0.power.log
2022-12-06 15:30:04,827 [ZeusDataLoader(train)] train epoch 73 done: time=43.76 energy=5819.67
2022-12-06 15:30:04,830 [ZeusDataLoader(eval)] Epoch 73 begin.
Training Epoch: 72 [1024/50176]	Loss: 4.6476
Training Epoch: 72 [2048/50176]	Loss: 4.6268
Training Epoch: 72 [3072/50176]	Loss: 4.6231
Training Epoch: 72 [4096/50176]	Loss: 4.6358
Training Epoch: 72 [5120/50176]	Loss: 4.6528
Training Epoch: 72 [6144/50176]	Loss: 4.6476
Training Epoch: 72 [7168/50176]	Loss: 4.6186
Training Epoch: 72 [8192/50176]	Loss: 4.6441
Training Epoch: 72 [9216/50176]	Loss: 4.6372
Training Epoch: 72 [10240/50176]	Loss: 4.6482
Training Epoch: 72 [11264/50176]	Loss: 4.6323
Training Epoch: 72 [12288/50176]	Loss: 4.6401
Training Epoch: 72 [13312/50176]	Loss: 4.6389
Training Epoch: 72 [14336/50176]	Loss: 4.6249
Training Epoch: 72 [15360/50176]	Loss: 4.6356
Training Epoch: 72 [16384/50176]	Loss: 4.6566
Training Epoch: 72 [17408/50176]	Loss: 4.6505
Training Epoch: 72 [18432/50176]	Loss: 4.6288
Training Epoch: 72 [19456/50176]	Loss: 4.6506
Training Epoch: 72 [20480/50176]	Loss: 4.6425
Training Epoch: 72 [21504/50176]	Loss: 4.6317
Training Epoch: 72 [22528/50176]	Loss: 4.6327
Training Epoch: 72 [23552/50176]	Loss: 4.6411
Training Epoch: 72 [24576/50176]	Loss: 4.6553
Training Epoch: 72 [25600/50176]	Loss: 4.6409
Training Epoch: 72 [26624/50176]	Loss: 4.6620
Training Epoch: 72 [27648/50176]	Loss: 4.6426
Training Epoch: 72 [28672/50176]	Loss: 4.6397
Training Epoch: 72 [29696/50176]	Loss: 4.6323
Training Epoch: 72 [30720/50176]	Loss: 4.6428
Training Epoch: 72 [31744/50176]	Loss: 4.6483
Training Epoch: 72 [32768/50176]	Loss: 4.6355
Training Epoch: 72 [33792/50176]	Loss: 4.6445
Training Epoch: 72 [34816/50176]	Loss: 4.6356
Training Epoch: 72 [35840/50176]	Loss: 4.6218
Training Epoch: 72 [36864/50176]	Loss: 4.6232
Training Epoch: 72 [37888/50176]	Loss: 4.6380
Training Epoch: 72 [38912/50176]	Loss: 4.6523
Training Epoch: 72 [39936/50176]	Loss: 4.6444
Training Epoch: 72 [40960/50176]	Loss: 4.6431
Training Epoch: 72 [41984/50176]	Loss: 4.6267
Training Epoch: 72 [43008/50176]	Loss: 4.6341
Training Epoch: 72 [44032/50176]	Loss: 4.6335
Training Epoch: 72 [45056/50176]	Loss: 4.6379
Training Epoch: 72 [46080/50176]	Loss: 4.6357
Training Epoch: 72 [47104/50176]	Loss: 4.6257
Training Epoch: 72 [48128/50176]	Loss: 4.6442
Training Epoch: 72 [49152/50176]	Loss: 4.6326
Training Epoch: 72 [50176/50176]	Loss: 4.6392
2022-12-06 20:30:08.594 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:30:08,642 [ZeusDataLoader(eval)] eval epoch 73 done: time=3.80 energy=482.72
2022-12-06 15:30:08,642 [ZeusDataLoader(train)] Up to epoch 73: time=3488.14, energy=460099.25, cost=535261.88
2022-12-06 15:30:08,642 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:30:08,643 [ZeusDataLoader(train)] Expected next epoch: time=3534.75, energy=466465.54, cost=542523.12
2022-12-06 15:30:08,644 [ZeusDataLoader(train)] Epoch 74 begin.
Validation Epoch: 72, Average loss: 4357.5853, Accuracy: 0.0098
2022-12-06 15:30:08,837 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:30:08,838 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:30:08.841 [ZeusMonitor] Monitor started.
2022-12-06 20:30:08.842 [ZeusMonitor] Running indefinitely. 2022-12-06 20:30:08.842 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:30:08.842 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e74+gpu0.power.log
2022-12-06 15:30:52,420 [ZeusDataLoader(train)] train epoch 74 done: time=43.77 energy=5824.41
2022-12-06 15:30:52,423 [ZeusDataLoader(eval)] Epoch 74 begin.
Training Epoch: 73 [1024/50176]	Loss: 4.6439
Training Epoch: 73 [2048/50176]	Loss: 4.6278
Training Epoch: 73 [3072/50176]	Loss: 4.6256
Training Epoch: 73 [4096/50176]	Loss: 4.6428
Training Epoch: 73 [5120/50176]	Loss: 4.6504
Training Epoch: 73 [6144/50176]	Loss: 4.6420
Training Epoch: 73 [7168/50176]	Loss: 4.6322
Training Epoch: 73 [8192/50176]	Loss: 4.6371
Training Epoch: 73 [9216/50176]	Loss: 4.6224
Training Epoch: 73 [10240/50176]	Loss: 4.6496
Training Epoch: 73 [11264/50176]	Loss: 4.6299
Training Epoch: 73 [12288/50176]	Loss: 4.6316
Training Epoch: 73 [13312/50176]	Loss: 4.6484
Training Epoch: 73 [14336/50176]	Loss: 4.6378
Training Epoch: 73 [15360/50176]	Loss: 4.6344
Training Epoch: 73 [16384/50176]	Loss: 4.6338
Training Epoch: 73 [17408/50176]	Loss: 4.6188
Training Epoch: 73 [18432/50176]	Loss: 4.6260
Training Epoch: 73 [19456/50176]	Loss: 4.6390
Training Epoch: 73 [20480/50176]	Loss: 4.6330
Training Epoch: 73 [21504/50176]	Loss: 4.6345
Training Epoch: 73 [22528/50176]	Loss: 4.6373
Training Epoch: 73 [23552/50176]	Loss: 4.6285
Training Epoch: 73 [24576/50176]	Loss: 4.6471
Training Epoch: 73 [25600/50176]	Loss: 4.6449
Training Epoch: 73 [26624/50176]	Loss: 4.6407
Training Epoch: 73 [27648/50176]	Loss: 4.6455
Training Epoch: 73 [28672/50176]	Loss: 4.6351
Training Epoch: 73 [29696/50176]	Loss: 4.6334
Training Epoch: 73 [30720/50176]	Loss: 4.6321
Training Epoch: 73 [31744/50176]	Loss: 4.6457
Training Epoch: 73 [32768/50176]	Loss: 4.6384
Training Epoch: 73 [33792/50176]	Loss: 4.6373
Training Epoch: 73 [34816/50176]	Loss: 4.6183
Training Epoch: 73 [35840/50176]	Loss: 4.6238
Training Epoch: 73 [36864/50176]	Loss: 4.6492
Training Epoch: 73 [37888/50176]	Loss: 4.6431
Training Epoch: 73 [38912/50176]	Loss: 4.6496
Training Epoch: 73 [39936/50176]	Loss: 4.6460
Training Epoch: 73 [40960/50176]	Loss: 4.6267
Training Epoch: 73 [41984/50176]	Loss: 4.6282
Training Epoch: 73 [43008/50176]	Loss: 4.6427
Training Epoch: 73 [44032/50176]	Loss: 4.6392
Training Epoch: 73 [45056/50176]	Loss: 4.6314
Training Epoch: 73 [46080/50176]	Loss: 4.6401
Training Epoch: 73 [47104/50176]	Loss: 4.6418
Training Epoch: 73 [48128/50176]	Loss: 4.6507
Training Epoch: 73 [49152/50176]	Loss: 4.6470
Training Epoch: 73 [50176/50176]	Loss: 4.6471
2022-12-06 20:30:56.114 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:30:56,124 [ZeusDataLoader(eval)] eval epoch 74 done: time=3.69 energy=452.52
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Up to epoch 74: time=3535.60, energy=466376.18, cost=542553.22
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:30:56,125 [ZeusDataLoader(train)] Expected next epoch: time=3582.21, energy=472742.47, cost=549814.46
2022-12-06 15:30:56,126 [ZeusDataLoader(train)] Epoch 75 begin.
Validation Epoch: 73, Average loss: 35791.9193, Accuracy: 0.0098
2022-12-06 15:30:56,361 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:30:56,362 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:30:56.364 [ZeusMonitor] Monitor started.
2022-12-06 20:30:56.364 [ZeusMonitor] Running indefinitely. 2022-12-06 20:30:56.364 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:30:56.364 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e75+gpu0.power.log
2022-12-06 15:31:39,958 [ZeusDataLoader(train)] train epoch 75 done: time=43.82 energy=5834.95
2022-12-06 15:31:39,961 [ZeusDataLoader(eval)] Epoch 75 begin.
Training Epoch: 74 [1024/50176]	Loss: 4.6305
Training Epoch: 74 [2048/50176]	Loss: 4.6319
Training Epoch: 74 [3072/50176]	Loss: 4.6390
Training Epoch: 74 [4096/50176]	Loss: 4.6169
Training Epoch: 74 [5120/50176]	Loss: 4.6351
Training Epoch: 74 [6144/50176]	Loss: 4.6402
Training Epoch: 74 [7168/50176]	Loss: 4.6315
Training Epoch: 74 [8192/50176]	Loss: 4.6288
Training Epoch: 74 [9216/50176]	Loss: 4.6396
Training Epoch: 74 [10240/50176]	Loss: 4.6381
Training Epoch: 74 [11264/50176]	Loss: 4.6280
Training Epoch: 74 [12288/50176]	Loss: 4.6174
Training Epoch: 74 [13312/50176]	Loss: 4.6240
Training Epoch: 74 [14336/50176]	Loss: 4.6323
Training Epoch: 74 [15360/50176]	Loss: 4.6366
Training Epoch: 74 [16384/50176]	Loss: 4.6368
Training Epoch: 74 [17408/50176]	Loss: 4.6336
Training Epoch: 74 [18432/50176]	Loss: 4.6255
Training Epoch: 74 [19456/50176]	Loss: 4.6291
Training Epoch: 74 [20480/50176]	Loss: 4.6332
Training Epoch: 74 [21504/50176]	Loss: 4.6318
Training Epoch: 74 [22528/50176]	Loss: 4.6382
Training Epoch: 74 [23552/50176]	Loss: 4.6300
Training Epoch: 74 [24576/50176]	Loss: 4.6311
Training Epoch: 74 [25600/50176]	Loss: 4.6404
Training Epoch: 74 [26624/50176]	Loss: 4.6313
Training Epoch: 74 [27648/50176]	Loss: 4.6322
Training Epoch: 74 [28672/50176]	Loss: 4.6324
Training Epoch: 74 [29696/50176]	Loss: 4.6351
Training Epoch: 74 [30720/50176]	Loss: 4.6495
Training Epoch: 74 [31744/50176]	Loss: 4.6402
Training Epoch: 74 [32768/50176]	Loss: 4.6439
Training Epoch: 74 [33792/50176]	Loss: 4.6275
Training Epoch: 74 [34816/50176]	Loss: 4.6384
Training Epoch: 74 [35840/50176]	Loss: 4.6491
Training Epoch: 74 [36864/50176]	Loss: 4.6366
Training Epoch: 74 [37888/50176]	Loss: 4.6220
Training Epoch: 74 [38912/50176]	Loss: 4.6444
Training Epoch: 74 [39936/50176]	Loss: 4.6184
Training Epoch: 74 [40960/50176]	Loss: 4.6593
Training Epoch: 74 [41984/50176]	Loss: 4.6414
Training Epoch: 74 [43008/50176]	Loss: 4.6505
Training Epoch: 74 [44032/50176]	Loss: 4.6432
Training Epoch: 74 [45056/50176]	Loss: 4.6324
Training Epoch: 74 [46080/50176]	Loss: 4.6324
Training Epoch: 74 [47104/50176]	Loss: 4.6456
Training Epoch: 74 [48128/50176]	Loss: 4.6571
Training Epoch: 74 [49152/50176]	Loss: 4.6379
Training Epoch: 74 [50176/50176]	Loss: 4.6427
2022-12-06 20:31:43.774 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:31:43,794 [ZeusDataLoader(eval)] eval epoch 75 done: time=3.82 energy=471.39
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Up to epoch 75: time=3583.25, energy=472682.52, cost=549875.62
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:31:43,794 [ZeusDataLoader(train)] Expected next epoch: time=3629.86, energy=479048.82, cost=557136.86
2022-12-06 15:31:43,795 [ZeusDataLoader(train)] Epoch 76 begin.
Validation Epoch: 74, Average loss: 1961.2634, Accuracy: 0.0098
2022-12-06 15:31:44,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:31:44,043 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:31:44.045 [ZeusMonitor] Monitor started.
2022-12-06 20:31:44.045 [ZeusMonitor] Running indefinitely. 2022-12-06 20:31:44.045 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:31:44.045 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e76+gpu0.power.log
2022-12-06 15:32:27,567 [ZeusDataLoader(train)] train epoch 76 done: time=43.76 energy=5823.39
2022-12-06 15:32:27,570 [ZeusDataLoader(eval)] Epoch 76 begin.
Training Epoch: 75 [1024/50176]	Loss: 4.6443
Training Epoch: 75 [2048/50176]	Loss: 4.6416
Training Epoch: 75 [3072/50176]	Loss: 4.6335
Training Epoch: 75 [4096/50176]	Loss: 4.6358
Training Epoch: 75 [5120/50176]	Loss: 4.6390
Training Epoch: 75 [6144/50176]	Loss: 4.6540
Training Epoch: 75 [7168/50176]	Loss: 4.6331
Training Epoch: 75 [8192/50176]	Loss: 4.6462
Training Epoch: 75 [9216/50176]	Loss: 4.6487
Training Epoch: 75 [10240/50176]	Loss: 4.6374
Training Epoch: 75 [11264/50176]	Loss: 4.6450
Training Epoch: 75 [12288/50176]	Loss: 4.6504
Training Epoch: 75 [13312/50176]	Loss: 4.6420
Training Epoch: 75 [14336/50176]	Loss: 4.6404
Training Epoch: 75 [15360/50176]	Loss: 4.6314
Training Epoch: 75 [16384/50176]	Loss: 4.6493
Training Epoch: 75 [17408/50176]	Loss: 4.6304
Training Epoch: 75 [18432/50176]	Loss: 4.6267
Training Epoch: 75 [19456/50176]	Loss: 4.6260
Training Epoch: 75 [20480/50176]	Loss: 4.6340
Training Epoch: 75 [21504/50176]	Loss: 4.6421
Training Epoch: 75 [22528/50176]	Loss: 4.6343
Training Epoch: 75 [23552/50176]	Loss: 4.6280
Training Epoch: 75 [24576/50176]	Loss: 4.6301
Training Epoch: 75 [25600/50176]	Loss: 4.6264
Training Epoch: 75 [26624/50176]	Loss: 4.6345
Training Epoch: 75 [27648/50176]	Loss: 4.6404
Training Epoch: 75 [28672/50176]	Loss: 4.6421
Training Epoch: 75 [29696/50176]	Loss: 4.6493
Training Epoch: 75 [30720/50176]	Loss: 4.6465
Training Epoch: 75 [31744/50176]	Loss: 4.6301
Training Epoch: 75 [32768/50176]	Loss: 4.6532
Training Epoch: 75 [33792/50176]	Loss: 4.6343
Training Epoch: 75 [34816/50176]	Loss: 4.6287
Training Epoch: 75 [35840/50176]	Loss: 4.6408
Training Epoch: 75 [36864/50176]	Loss: 4.6436
Training Epoch: 75 [37888/50176]	Loss: 4.6412
Training Epoch: 75 [38912/50176]	Loss: 4.6396
Training Epoch: 75 [39936/50176]	Loss: 4.6385
Training Epoch: 75 [40960/50176]	Loss: 4.6360
Training Epoch: 75 [41984/50176]	Loss: 4.6229
Training Epoch: 75 [43008/50176]	Loss: 4.6273
Training Epoch: 75 [44032/50176]	Loss: 4.6382
Training Epoch: 75 [45056/50176]	Loss: 4.6222
Training Epoch: 75 [46080/50176]	Loss: 4.6316
Training Epoch: 75 [47104/50176]	Loss: 4.6477
Training Epoch: 75 [48128/50176]	Loss: 4.6412
Training Epoch: 75 [49152/50176]	Loss: 4.6382
Training Epoch: 75 [50176/50176]	Loss: 4.6320
2022-12-06 20:32:31.291 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:32:31,309 [ZeusDataLoader(eval)] eval epoch 76 done: time=3.73 energy=462.47
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Up to epoch 76: time=3630.74, energy=478968.39, cost=557174.36
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:32:31,309 [ZeusDataLoader(train)] Expected next epoch: time=3677.35, energy=485334.68, cost=564435.60
2022-12-06 15:32:31,310 [ZeusDataLoader(train)] Epoch 77 begin.
Validation Epoch: 75, Average loss: 212.9936, Accuracy: 0.0098
2022-12-06 15:32:31,558 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:32:31,559 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:32:31.572 [ZeusMonitor] Monitor started.
2022-12-06 20:32:31.573 [ZeusMonitor] Running indefinitely. 2022-12-06 20:32:31.573 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:32:31.573 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e77+gpu0.power.log
2022-12-06 15:33:15,169 [ZeusDataLoader(train)] train epoch 77 done: time=43.85 energy=5829.62
2022-12-06 15:33:15,172 [ZeusDataLoader(eval)] Epoch 77 begin.
Training Epoch: 76 [1024/50176]	Loss: 4.6457
Training Epoch: 76 [2048/50176]	Loss: 4.6299
Training Epoch: 76 [3072/50176]	Loss: 4.6370
Training Epoch: 76 [4096/50176]	Loss: 4.6375
Training Epoch: 76 [5120/50176]	Loss: 4.6423
Training Epoch: 76 [6144/50176]	Loss: 4.6475
Training Epoch: 76 [7168/50176]	Loss: 4.6489
Training Epoch: 76 [8192/50176]	Loss: 4.6431
Training Epoch: 76 [9216/50176]	Loss: 4.6298
Training Epoch: 76 [10240/50176]	Loss: 4.6307
Training Epoch: 76 [11264/50176]	Loss: 4.6302
Training Epoch: 76 [12288/50176]	Loss: 4.6245
Training Epoch: 76 [13312/50176]	Loss: 4.6399
Training Epoch: 76 [14336/50176]	Loss: 4.6363
Training Epoch: 76 [15360/50176]	Loss: 4.6261
Training Epoch: 76 [16384/50176]	Loss: 4.6425
Training Epoch: 76 [17408/50176]	Loss: 4.6332
Training Epoch: 76 [18432/50176]	Loss: 4.6401
Training Epoch: 76 [19456/50176]	Loss: 4.6352
Training Epoch: 76 [20480/50176]	Loss: 4.6361
Training Epoch: 76 [21504/50176]	Loss: 4.6299
Training Epoch: 76 [22528/50176]	Loss: 4.6316
Training Epoch: 76 [23552/50176]	Loss: 4.6326
Training Epoch: 76 [24576/50176]	Loss: 4.6399
Training Epoch: 76 [25600/50176]	Loss: 4.6249
Training Epoch: 76 [26624/50176]	Loss: 4.6221
Training Epoch: 76 [27648/50176]	Loss: 4.6539
Training Epoch: 76 [28672/50176]	Loss: 4.6611
Training Epoch: 76 [29696/50176]	Loss: 4.6236
Training Epoch: 76 [30720/50176]	Loss: 4.6321
Training Epoch: 76 [31744/50176]	Loss: 4.6478
Training Epoch: 76 [32768/50176]	Loss: 4.6417
Training Epoch: 76 [33792/50176]	Loss: 4.6534
Training Epoch: 76 [34816/50176]	Loss: 4.6409
Training Epoch: 76 [35840/50176]	Loss: 4.6449
Training Epoch: 76 [36864/50176]	Loss: 4.6430
Training Epoch: 76 [37888/50176]	Loss: 4.6284
Training Epoch: 76 [38912/50176]	Loss: 4.6406
Training Epoch: 76 [39936/50176]	Loss: 4.6447
Training Epoch: 76 [40960/50176]	Loss: 4.6421
Training Epoch: 76 [41984/50176]	Loss: 4.6450
Training Epoch: 76 [43008/50176]	Loss: 4.6311
Training Epoch: 76 [44032/50176]	Loss: 4.6422
Training Epoch: 76 [45056/50176]	Loss: 4.6339
Training Epoch: 76 [46080/50176]	Loss: 4.6420
Training Epoch: 76 [47104/50176]	Loss: 4.6230
Training Epoch: 76 [48128/50176]	Loss: 4.6386
Training Epoch: 76 [49152/50176]	Loss: 4.6242
Training Epoch: 76 [50176/50176]	Loss: 4.6424
2022-12-06 20:33:18.944 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:33:18,997 [ZeusDataLoader(eval)] eval epoch 77 done: time=3.82 energy=478.81
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Up to epoch 77: time=3678.41, energy=485276.81, cost=564499.51
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:33:18,998 [ZeusDataLoader(train)] Expected next epoch: time=3725.02, energy=491643.11, cost=571760.74
2022-12-06 15:33:18,999 [ZeusDataLoader(train)] Epoch 78 begin.
Validation Epoch: 76, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:33:19,302 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:33:19,303 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:33:19.304 [ZeusMonitor] Monitor started.
2022-12-06 20:33:19.304 [ZeusMonitor] Running indefinitely. 2022-12-06 20:33:19.304 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:33:19.304 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e78+gpu0.power.log
2022-12-06 15:34:02,888 [ZeusDataLoader(train)] train epoch 78 done: time=43.88 energy=5827.67
2022-12-06 15:34:02,892 [ZeusDataLoader(eval)] Epoch 78 begin.
Training Epoch: 77 [1024/50176]	Loss: 4.6367
Training Epoch: 77 [2048/50176]	Loss: 4.6321
Training Epoch: 77 [3072/50176]	Loss: 4.6470
Training Epoch: 77 [4096/50176]	Loss: 4.6310
Training Epoch: 77 [5120/50176]	Loss: 4.6254
Training Epoch: 77 [6144/50176]	Loss: 4.6189
Training Epoch: 77 [7168/50176]	Loss: 4.6377
Training Epoch: 77 [8192/50176]	Loss: 4.6361
Training Epoch: 77 [9216/50176]	Loss: 4.6479
Training Epoch: 77 [10240/50176]	Loss: 4.6421
Training Epoch: 77 [11264/50176]	Loss: 4.6554
Training Epoch: 77 [12288/50176]	Loss: 4.6424
Training Epoch: 77 [13312/50176]	Loss: 4.6311
Training Epoch: 77 [14336/50176]	Loss: 4.6352
Training Epoch: 77 [15360/50176]	Loss: 4.6328
Training Epoch: 77 [16384/50176]	Loss: 4.6240
Training Epoch: 77 [17408/50176]	Loss: 4.6409
Training Epoch: 77 [18432/50176]	Loss: 4.6383
Training Epoch: 77 [19456/50176]	Loss: 4.6473
Training Epoch: 77 [20480/50176]	Loss: 4.6436
Training Epoch: 77 [21504/50176]	Loss: 4.6527
Training Epoch: 77 [22528/50176]	Loss: 4.6252
Training Epoch: 77 [23552/50176]	Loss: 4.6373
Training Epoch: 77 [24576/50176]	Loss: 4.6248
Training Epoch: 77 [25600/50176]	Loss: 4.6304
Training Epoch: 77 [26624/50176]	Loss: 4.6234
Training Epoch: 77 [27648/50176]	Loss: 4.6391
Training Epoch: 77 [28672/50176]	Loss: 4.6513
Training Epoch: 77 [29696/50176]	Loss: 4.6329
Training Epoch: 77 [30720/50176]	Loss: 4.6621
Training Epoch: 77 [31744/50176]	Loss: 4.6305
Training Epoch: 77 [32768/50176]	Loss: 4.6302
Training Epoch: 77 [33792/50176]	Loss: 4.6240
Training Epoch: 77 [34816/50176]	Loss: 4.6350
Training Epoch: 77 [35840/50176]	Loss: 4.6381
Training Epoch: 77 [36864/50176]	Loss: 4.6425
Training Epoch: 77 [37888/50176]	Loss: 4.6506
Training Epoch: 77 [38912/50176]	Loss: 4.6624
Training Epoch: 77 [39936/50176]	Loss: 4.6376
Training Epoch: 77 [40960/50176]	Loss: 4.6294
Training Epoch: 77 [41984/50176]	Loss: 4.6255
Training Epoch: 77 [43008/50176]	Loss: 4.6314
Training Epoch: 77 [44032/50176]	Loss: 4.6323
Training Epoch: 77 [45056/50176]	Loss: 4.6553
Training Epoch: 77 [46080/50176]	Loss: 4.6425
Training Epoch: 77 [47104/50176]	Loss: 4.6464
Training Epoch: 77 [48128/50176]	Loss: 4.6574
Training Epoch: 77 [49152/50176]	Loss: 4.6436
Training Epoch: 77 [50176/50176]	Loss: 4.6369
2022-12-06 20:34:06.705 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:34:06,745 [ZeusDataLoader(eval)] eval epoch 78 done: time=3.85 energy=471.26
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Up to epoch 78: time=3726.14, energy=491575.75, cost=571825.11
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:34:06,745 [ZeusDataLoader(train)] Expected next epoch: time=3772.75, energy=497942.04, cost=579086.35
2022-12-06 15:34:06,746 [ZeusDataLoader(train)] Epoch 79 begin.
Validation Epoch: 77, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:34:06,995 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:34:06,996 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:34:06.998 [ZeusMonitor] Monitor started.
2022-12-06 20:34:06.998 [ZeusMonitor] Running indefinitely. 2022-12-06 20:34:06.998 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:34:06.998 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e79+gpu0.power.log
2022-12-06 15:34:50,651 [ZeusDataLoader(train)] train epoch 79 done: time=43.90 energy=5832.68
2022-12-06 15:34:50,655 [ZeusDataLoader(eval)] Epoch 79 begin.
Training Epoch: 78 [1024/50176]	Loss: 4.6430
Training Epoch: 78 [2048/50176]	Loss: 4.6214
Training Epoch: 78 [3072/50176]	Loss: 4.6488
Training Epoch: 78 [4096/50176]	Loss: 4.6336
Training Epoch: 78 [5120/50176]	Loss: 4.6577
Training Epoch: 78 [6144/50176]	Loss: 4.6402
Training Epoch: 78 [7168/50176]	Loss: 4.6530
Training Epoch: 78 [8192/50176]	Loss: 4.6316
Training Epoch: 78 [9216/50176]	Loss: 4.6382
Training Epoch: 78 [10240/50176]	Loss: 4.6479
Training Epoch: 78 [11264/50176]	Loss: 4.6369
Training Epoch: 78 [12288/50176]	Loss: 4.6275
Training Epoch: 78 [13312/50176]	Loss: 4.6365
Training Epoch: 78 [14336/50176]	Loss: 4.6393
Training Epoch: 78 [15360/50176]	Loss: 4.6456
Training Epoch: 78 [16384/50176]	Loss: 4.6431
Training Epoch: 78 [17408/50176]	Loss: 4.6457
Training Epoch: 78 [18432/50176]	Loss: 4.6298
Training Epoch: 78 [19456/50176]	Loss: 4.6421
Training Epoch: 78 [20480/50176]	Loss: 4.6440
Training Epoch: 78 [21504/50176]	Loss: 4.6489
Training Epoch: 78 [22528/50176]	Loss: 4.6368
Training Epoch: 78 [23552/50176]	Loss: 4.6584
Training Epoch: 78 [24576/50176]	Loss: 4.6409
Training Epoch: 78 [25600/50176]	Loss: 4.6329
Training Epoch: 78 [26624/50176]	Loss: 4.6427
Training Epoch: 78 [27648/50176]	Loss: 4.6377
Training Epoch: 78 [28672/50176]	Loss: 4.6440
Training Epoch: 78 [29696/50176]	Loss: 4.6404
Training Epoch: 78 [30720/50176]	Loss: 4.6406
Training Epoch: 78 [31744/50176]	Loss: 4.6301
Training Epoch: 78 [32768/50176]	Loss: 4.6308
Training Epoch: 78 [33792/50176]	Loss: 4.6305
Training Epoch: 78 [34816/50176]	Loss: 4.6289
Training Epoch: 78 [35840/50176]	Loss: 4.6351
Training Epoch: 78 [36864/50176]	Loss: 4.6504
Training Epoch: 78 [37888/50176]	Loss: 4.6429
Training Epoch: 78 [38912/50176]	Loss: 4.6511
Training Epoch: 78 [39936/50176]	Loss: 4.6352
Training Epoch: 78 [40960/50176]	Loss: 4.6398
Training Epoch: 78 [41984/50176]	Loss: 4.6259
Training Epoch: 78 [43008/50176]	Loss: 4.6360
Training Epoch: 78 [44032/50176]	Loss: 4.6596
Training Epoch: 78 [45056/50176]	Loss: 4.6532
Training Epoch: 78 [46080/50176]	Loss: 4.6475
Training Epoch: 78 [47104/50176]	Loss: 4.6351
Training Epoch: 78 [48128/50176]	Loss: 4.6351
Training Epoch: 78 [49152/50176]	Loss: 4.6333
Training Epoch: 78 [50176/50176]	Loss: 4.6553
2022-12-06 20:34:54.369 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:34:54,405 [ZeusDataLoader(eval)] eval epoch 79 done: time=3.74 energy=463.87
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Up to epoch 79: time=3773.78, energy=497872.29, cost=579141.81
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:34:54,405 [ZeusDataLoader(train)] Expected next epoch: time=3820.39, energy=504238.59, cost=586403.04
2022-12-06 15:34:54,406 [ZeusDataLoader(train)] Epoch 80 begin.
Validation Epoch: 78, Average loss: 15.0071, Accuracy: 0.0098
2022-12-06 15:34:54,599 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:34:54,600 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:34:54.603 [ZeusMonitor] Monitor started.
2022-12-06 20:34:54.603 [ZeusMonitor] Running indefinitely. 2022-12-06 20:34:54.603 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:34:54.603 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e80+gpu0.power.log
2022-12-06 15:35:38,148 [ZeusDataLoader(train)] train epoch 80 done: time=43.73 energy=5824.17
2022-12-06 15:35:38,152 [ZeusDataLoader(eval)] Epoch 80 begin.
Training Epoch: 79 [1024/50176]	Loss: 4.6450
Training Epoch: 79 [2048/50176]	Loss: 4.6475
Training Epoch: 79 [3072/50176]	Loss: 4.6442
Training Epoch: 79 [4096/50176]	Loss: 4.6411
Training Epoch: 79 [5120/50176]	Loss: 4.6319
Training Epoch: 79 [6144/50176]	Loss: 4.6284
Training Epoch: 79 [7168/50176]	Loss: 4.6372
Training Epoch: 79 [8192/50176]	Loss: 4.6415
Training Epoch: 79 [9216/50176]	Loss: 4.6464
Training Epoch: 79 [10240/50176]	Loss: 4.6444
Training Epoch: 79 [11264/50176]	Loss: 4.6419
Training Epoch: 79 [12288/50176]	Loss: 4.6568
Training Epoch: 79 [13312/50176]	Loss: 4.6342
Training Epoch: 79 [14336/50176]	Loss: 4.6321
Training Epoch: 79 [15360/50176]	Loss: 4.6430
Training Epoch: 79 [16384/50176]	Loss: 4.6412
Training Epoch: 79 [17408/50176]	Loss: 4.6359
Training Epoch: 79 [18432/50176]	Loss: 4.6441
Training Epoch: 79 [19456/50176]	Loss: 4.6479
Training Epoch: 79 [20480/50176]	Loss: 4.6454
Training Epoch: 79 [21504/50176]	Loss: 4.6384
Training Epoch: 79 [22528/50176]	Loss: 4.6462
Training Epoch: 79 [23552/50176]	Loss: 4.6379
Training Epoch: 79 [24576/50176]	Loss: 4.6375
Training Epoch: 79 [25600/50176]	Loss: 4.6415
Training Epoch: 79 [26624/50176]	Loss: 4.6372
Training Epoch: 79 [27648/50176]	Loss: 4.6446
Training Epoch: 79 [28672/50176]	Loss: 4.6266
Training Epoch: 79 [29696/50176]	Loss: 4.6331
Training Epoch: 79 [30720/50176]	Loss: 4.6365
Training Epoch: 79 [31744/50176]	Loss: 4.6491
Training Epoch: 79 [32768/50176]	Loss: 4.6345
Training Epoch: 79 [33792/50176]	Loss: 4.6291
Training Epoch: 79 [34816/50176]	Loss: 4.6388
Training Epoch: 79 [35840/50176]	Loss: 4.6358
Training Epoch: 79 [36864/50176]	Loss: 4.6300
Training Epoch: 79 [37888/50176]	Loss: 4.6445
Training Epoch: 79 [38912/50176]	Loss: 4.6261
Training Epoch: 79 [39936/50176]	Loss: 4.6496
Training Epoch: 79 [40960/50176]	Loss: 4.6279
Training Epoch: 79 [41984/50176]	Loss: 4.6347
Training Epoch: 79 [43008/50176]	Loss: 4.6429
Training Epoch: 79 [44032/50176]	Loss: 4.6450
Training Epoch: 79 [45056/50176]	Loss: 4.6306
Training Epoch: 79 [46080/50176]	Loss: 4.6322
Training Epoch: 79 [47104/50176]	Loss: 4.6369
Training Epoch: 79 [48128/50176]	Loss: 4.6413
Training Epoch: 79 [49152/50176]	Loss: 4.6255
Training Epoch: 79 [50176/50176]	Loss: 4.6397
2022-12-06 20:35:41.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:35:41,999 [ZeusDataLoader(eval)] eval epoch 80 done: time=3.84 energy=472.50
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Up to epoch 80: time=3821.35, energy=504168.97, cost=586452.91
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:35:41,999 [ZeusDataLoader(train)] Expected next epoch: time=3867.96, energy=510535.26, cost=593714.14
2022-12-06 15:35:42,000 [ZeusDataLoader(train)] Epoch 81 begin.
Validation Epoch: 79, Average loss: 7978.9542, Accuracy: 0.0098
2022-12-06 15:35:42,233 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:35:42,233 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:35:42.235 [ZeusMonitor] Monitor started.
2022-12-06 20:35:42.235 [ZeusMonitor] Running indefinitely. 2022-12-06 20:35:42.235 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:35:42.235 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e81+gpu0.power.log
2022-12-06 15:36:25,657 [ZeusDataLoader(train)] train epoch 81 done: time=43.65 energy=5817.52
2022-12-06 15:36:25,660 [ZeusDataLoader(eval)] Epoch 81 begin.
Training Epoch: 80 [1024/50176]	Loss: 4.6400
Training Epoch: 80 [2048/50176]	Loss: 4.6257
Training Epoch: 80 [3072/50176]	Loss: 4.6336
Training Epoch: 80 [4096/50176]	Loss: 4.6451
Training Epoch: 80 [5120/50176]	Loss: 4.6332
Training Epoch: 80 [6144/50176]	Loss: 4.6450
Training Epoch: 80 [7168/50176]	Loss: 4.6351
Training Epoch: 80 [8192/50176]	Loss: 4.6402
Training Epoch: 80 [9216/50176]	Loss: 4.6459
Training Epoch: 80 [10240/50176]	Loss: 4.6251
Training Epoch: 80 [11264/50176]	Loss: 4.6341
Training Epoch: 80 [12288/50176]	Loss: 4.6428
Training Epoch: 80 [13312/50176]	Loss: 4.6473
Training Epoch: 80 [14336/50176]	Loss: 4.6341
Training Epoch: 80 [15360/50176]	Loss: 4.6359
Training Epoch: 80 [16384/50176]	Loss: 4.6254
Training Epoch: 80 [17408/50176]	Loss: 4.6303
Training Epoch: 80 [18432/50176]	Loss: 4.6500
Training Epoch: 80 [19456/50176]	Loss: 4.6298
Training Epoch: 80 [20480/50176]	Loss: 4.6498
Training Epoch: 80 [21504/50176]	Loss: 4.6350
Training Epoch: 80 [22528/50176]	Loss: 4.6263
Training Epoch: 80 [23552/50176]	Loss: 4.6409
Training Epoch: 80 [24576/50176]	Loss: 4.6368
Training Epoch: 80 [25600/50176]	Loss: 4.6384
Training Epoch: 80 [26624/50176]	Loss: 4.6464
Training Epoch: 80 [27648/50176]	Loss: 4.6472
Training Epoch: 80 [28672/50176]	Loss: 4.6463
Training Epoch: 80 [29696/50176]	Loss: 4.6370
Training Epoch: 80 [30720/50176]	Loss: 4.6246
Training Epoch: 80 [31744/50176]	Loss: 4.6361
Training Epoch: 80 [32768/50176]	Loss: 4.6392
Training Epoch: 80 [33792/50176]	Loss: 4.6436
Training Epoch: 80 [34816/50176]	Loss: 4.6419
Training Epoch: 80 [35840/50176]	Loss: 4.6164
Training Epoch: 80 [36864/50176]	Loss: 4.6330
Training Epoch: 80 [37888/50176]	Loss: 4.6365
Training Epoch: 80 [38912/50176]	Loss: 4.6313
Training Epoch: 80 [39936/50176]	Loss: 4.6290
Training Epoch: 80 [40960/50176]	Loss: 4.6256
Training Epoch: 80 [41984/50176]	Loss: 4.6334
Training Epoch: 80 [43008/50176]	Loss: 4.6324
Training Epoch: 80 [44032/50176]	Loss: 4.6334
Training Epoch: 80 [45056/50176]	Loss: 4.6258
Training Epoch: 80 [46080/50176]	Loss: 4.6309
Training Epoch: 80 [47104/50176]	Loss: 4.6319
Training Epoch: 80 [48128/50176]	Loss: 4.6335
Training Epoch: 80 [49152/50176]	Loss: 4.6384
Training Epoch: 80 [50176/50176]	Loss: 4.6473
2022-12-06 20:36:29.398 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:36:29,452 [ZeusDataLoader(eval)] eval epoch 81 done: time=3.78 energy=484.58
2022-12-06 15:36:29,452 [ZeusDataLoader(train)] Up to epoch 81: time=3868.79, energy=510471.06, cost=593754.34
2022-12-06 15:36:29,452 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:36:29,453 [ZeusDataLoader(train)] Expected next epoch: time=3915.39, energy=516837.36, cost=601015.58
2022-12-06 15:36:29,453 [ZeusDataLoader(train)] Epoch 82 begin.
Validation Epoch: 80, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:36:29,701 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:36:29,702 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:36:29.704 [ZeusMonitor] Monitor started.
2022-12-06 20:36:29.704 [ZeusMonitor] Running indefinitely. 2022-12-06 20:36:29.704 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:36:29.704 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e82+gpu0.power.log
2022-12-06 15:37:13,296 [ZeusDataLoader(train)] train epoch 82 done: time=43.84 energy=5832.14
2022-12-06 15:37:13,300 [ZeusDataLoader(eval)] Epoch 82 begin.
Training Epoch: 81 [1024/50176]	Loss: 4.6379
Training Epoch: 81 [2048/50176]	Loss: 4.6294
Training Epoch: 81 [3072/50176]	Loss: 4.6229
Training Epoch: 81 [4096/50176]	Loss: 4.6288
Training Epoch: 81 [5120/50176]	Loss: 4.6340
Training Epoch: 81 [6144/50176]	Loss: 4.6439
Training Epoch: 81 [7168/50176]	Loss: 4.6299
Training Epoch: 81 [8192/50176]	Loss: 4.6309
Training Epoch: 81 [9216/50176]	Loss: 4.6347
Training Epoch: 81 [10240/50176]	Loss: 4.6519
Training Epoch: 81 [11264/50176]	Loss: 4.6430
Training Epoch: 81 [12288/50176]	Loss: 4.6358
Training Epoch: 81 [13312/50176]	Loss: 4.6249
Training Epoch: 81 [14336/50176]	Loss: 4.6456
Training Epoch: 81 [15360/50176]	Loss: 4.6384
Training Epoch: 81 [16384/50176]	Loss: 4.6532
Training Epoch: 81 [17408/50176]	Loss: 4.6586
Training Epoch: 81 [18432/50176]	Loss: 4.6359
Training Epoch: 81 [19456/50176]	Loss: 4.6471
Training Epoch: 81 [20480/50176]	Loss: 4.6406
Training Epoch: 81 [21504/50176]	Loss: 4.6266
Training Epoch: 81 [22528/50176]	Loss: 4.6433
Training Epoch: 81 [23552/50176]	Loss: 4.6203
Training Epoch: 81 [24576/50176]	Loss: 4.6380
Training Epoch: 81 [25600/50176]	Loss: 4.6445
Training Epoch: 81 [26624/50176]	Loss: 4.6281
Training Epoch: 81 [27648/50176]	Loss: 4.6395
Training Epoch: 81 [28672/50176]	Loss: 4.6511
Training Epoch: 81 [29696/50176]	Loss: 4.6316
Training Epoch: 81 [30720/50176]	Loss: 4.6312
Training Epoch: 81 [31744/50176]	Loss: 4.6437
Training Epoch: 81 [32768/50176]	Loss: 4.6504
Training Epoch: 81 [33792/50176]	Loss: 4.6321
Training Epoch: 81 [34816/50176]	Loss: 4.6340
Training Epoch: 81 [35840/50176]	Loss: 4.6303
Training Epoch: 81 [36864/50176]	Loss: 4.6341
Training Epoch: 81 [37888/50176]	Loss: 4.6319
Training Epoch: 81 [38912/50176]	Loss: 4.6400
Training Epoch: 81 [39936/50176]	Loss: 4.6455
Training Epoch: 81 [40960/50176]	Loss: 4.6421
Training Epoch: 81 [41984/50176]	Loss: 4.6271
Training Epoch: 81 [43008/50176]	Loss: 4.6222
Training Epoch: 81 [44032/50176]	Loss: 4.6403
Training Epoch: 81 [45056/50176]	Loss: 4.6459
Training Epoch: 81 [46080/50176]	Loss: 4.6401
Training Epoch: 81 [47104/50176]	Loss: 4.6443
Training Epoch: 81 [48128/50176]	Loss: 4.6482
Training Epoch: 81 [49152/50176]	Loss: 4.6255
Training Epoch: 81 [50176/50176]	Loss: 4.6427
2022-12-06 20:37:17.058 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:37:17,114 [ZeusDataLoader(eval)] eval epoch 82 done: time=3.81 energy=487.61
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Up to epoch 82: time=3916.43, energy=516790.81, cost=601082.86
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:37:17,115 [ZeusDataLoader(train)] Expected next epoch: time=3963.03, energy=523157.11, cost=608344.09
2022-12-06 15:37:17,116 [ZeusDataLoader(train)] Epoch 83 begin.
Validation Epoch: 81, Average loss: 60.3389, Accuracy: 0.0098
2022-12-06 15:37:17,354 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:37:17,355 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:37:17.357 [ZeusMonitor] Monitor started.
2022-12-06 20:37:17.357 [ZeusMonitor] Running indefinitely. 2022-12-06 20:37:17.357 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:37:17.357 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e83+gpu0.power.log
2022-12-06 15:38:00,842 [ZeusDataLoader(train)] train epoch 83 done: time=43.72 energy=5826.18
2022-12-06 15:38:00,845 [ZeusDataLoader(eval)] Epoch 83 begin.
Training Epoch: 82 [1024/50176]	Loss: 4.6476
Training Epoch: 82 [2048/50176]	Loss: 4.6488
Training Epoch: 82 [3072/50176]	Loss: 4.6366
Training Epoch: 82 [4096/50176]	Loss: 4.6509
Training Epoch: 82 [5120/50176]	Loss: 4.6473
Training Epoch: 82 [6144/50176]	Loss: 4.6430
Training Epoch: 82 [7168/50176]	Loss: 4.6396
Training Epoch: 82 [8192/50176]	Loss: 4.6324
Training Epoch: 82 [9216/50176]	Loss: 4.6379
Training Epoch: 82 [10240/50176]	Loss: 4.6371
Training Epoch: 82 [11264/50176]	Loss: 4.6336
Training Epoch: 82 [12288/50176]	Loss: 4.6399
Training Epoch: 82 [13312/50176]	Loss: 4.6407
Training Epoch: 82 [14336/50176]	Loss: 4.6467
Training Epoch: 82 [15360/50176]	Loss: 4.6486
Training Epoch: 82 [16384/50176]	Loss: 4.6409
Training Epoch: 82 [17408/50176]	Loss: 4.6493
Training Epoch: 82 [18432/50176]	Loss: 4.6503
Training Epoch: 82 [19456/50176]	Loss: 4.6479
Training Epoch: 82 [20480/50176]	Loss: 4.6434
Training Epoch: 82 [21504/50176]	Loss: 4.6375
Training Epoch: 82 [22528/50176]	Loss: 4.6514
Training Epoch: 82 [23552/50176]	Loss: 4.6350
Training Epoch: 82 [24576/50176]	Loss: 4.6328
Training Epoch: 82 [25600/50176]	Loss: 4.6545
Training Epoch: 82 [26624/50176]	Loss: 4.6304
Training Epoch: 82 [27648/50176]	Loss: 4.6466
Training Epoch: 82 [28672/50176]	Loss: 4.6350
Training Epoch: 82 [29696/50176]	Loss: 4.6630
Training Epoch: 82 [30720/50176]	Loss: 4.6383
Training Epoch: 82 [31744/50176]	Loss: 4.6268
Training Epoch: 82 [32768/50176]	Loss: 4.6371
Training Epoch: 82 [33792/50176]	Loss: 4.6252
Training Epoch: 82 [34816/50176]	Loss: 4.6453
Training Epoch: 82 [35840/50176]	Loss: 4.6362
Training Epoch: 82 [36864/50176]	Loss: 4.6460
Training Epoch: 82 [37888/50176]	Loss: 4.6317
Training Epoch: 82 [38912/50176]	Loss: 4.6258
Training Epoch: 82 [39936/50176]	Loss: 4.6420
Training Epoch: 82 [40960/50176]	Loss: 4.6403
Training Epoch: 82 [41984/50176]	Loss: 4.6372
Training Epoch: 82 [43008/50176]	Loss: 4.6307
Training Epoch: 82 [44032/50176]	Loss: 4.6461
Training Epoch: 82 [45056/50176]	Loss: 4.6421
Training Epoch: 82 [46080/50176]	Loss: 4.6274
Training Epoch: 82 [47104/50176]	Loss: 4.6307
Training Epoch: 82 [48128/50176]	Loss: 4.6303
Training Epoch: 82 [49152/50176]	Loss: 4.6240
Training Epoch: 82 [50176/50176]	Loss: 4.6312
2022-12-06 20:38:04.597 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:38:04,610 [ZeusDataLoader(eval)] eval epoch 83 done: time=3.76 energy=462.14
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Up to epoch 83: time=3963.90, energy=523079.12, cost=608381.07
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:38:04,610 [ZeusDataLoader(train)] Expected next epoch: time=4010.51, energy=529445.42, cost=615642.30
2022-12-06 15:38:04,611 [ZeusDataLoader(train)] Epoch 84 begin.
Validation Epoch: 82, Average loss: 22964.5239, Accuracy: 0.0098
2022-12-06 15:38:04,835 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:38:04,836 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:38:04.850 [ZeusMonitor] Monitor started.
2022-12-06 20:38:04.850 [ZeusMonitor] Running indefinitely. 2022-12-06 20:38:04.850 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:38:04.850 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e84+gpu0.power.log
2022-12-06 15:38:48,532 [ZeusDataLoader(train)] train epoch 84 done: time=43.91 energy=5828.40
2022-12-06 15:38:48,535 [ZeusDataLoader(eval)] Epoch 84 begin.
Training Epoch: 83 [1024/50176]	Loss: 4.6303
Training Epoch: 83 [2048/50176]	Loss: 4.6276
Training Epoch: 83 [3072/50176]	Loss: 4.6303
Training Epoch: 83 [4096/50176]	Loss: 4.6228
Training Epoch: 83 [5120/50176]	Loss: 4.6405
Training Epoch: 83 [6144/50176]	Loss: 4.6544
Training Epoch: 83 [7168/50176]	Loss: 4.6405
Training Epoch: 83 [8192/50176]	Loss: 4.6415
Training Epoch: 83 [9216/50176]	Loss: 4.6410
Training Epoch: 83 [10240/50176]	Loss: 4.6299
Training Epoch: 83 [11264/50176]	Loss: 4.6259
Training Epoch: 83 [12288/50176]	Loss: 4.6340
Training Epoch: 83 [13312/50176]	Loss: 4.6500
Training Epoch: 83 [14336/50176]	Loss: 4.6417
Training Epoch: 83 [15360/50176]	Loss: 4.6347
Training Epoch: 83 [16384/50176]	Loss: 4.6451
Training Epoch: 83 [17408/50176]	Loss: 4.6264
Training Epoch: 83 [18432/50176]	Loss: 4.6343
Training Epoch: 83 [19456/50176]	Loss: 4.6252
Training Epoch: 83 [20480/50176]	Loss: 4.6354
Training Epoch: 83 [21504/50176]	Loss: 4.6422
Training Epoch: 83 [22528/50176]	Loss: 4.6374
Training Epoch: 83 [23552/50176]	Loss: 4.6352
Training Epoch: 83 [24576/50176]	Loss: 4.6367
Training Epoch: 83 [25600/50176]	Loss: 4.6169
Training Epoch: 83 [26624/50176]	Loss: 4.6355
Training Epoch: 83 [27648/50176]	Loss: 4.6332
Training Epoch: 83 [28672/50176]	Loss: 4.6148
Training Epoch: 83 [29696/50176]	Loss: 4.6270
Training Epoch: 83 [30720/50176]	Loss: 4.6311
Training Epoch: 83 [31744/50176]	Loss: 4.6477
Training Epoch: 83 [32768/50176]	Loss: 4.6462
Training Epoch: 83 [33792/50176]	Loss: 4.6367
Training Epoch: 83 [34816/50176]	Loss: 4.6463
Training Epoch: 83 [35840/50176]	Loss: 4.6474
Training Epoch: 83 [36864/50176]	Loss: 4.6391
Training Epoch: 83 [37888/50176]	Loss: 4.6371
Training Epoch: 83 [38912/50176]	Loss: 4.6422
Training Epoch: 83 [39936/50176]	Loss: 4.6559
Training Epoch: 83 [40960/50176]	Loss: 4.6193
Training Epoch: 83 [41984/50176]	Loss: 4.6431
Training Epoch: 83 [43008/50176]	Loss: 4.6267
Training Epoch: 83 [44032/50176]	Loss: 4.6441
Training Epoch: 83 [45056/50176]	Loss: 4.6461
Training Epoch: 83 [46080/50176]	Loss: 4.6348
Training Epoch: 83 [47104/50176]	Loss: 4.6410
Training Epoch: 83 [48128/50176]	Loss: 4.6333
Training Epoch: 83 [49152/50176]	Loss: 4.6451
Training Epoch: 83 [50176/50176]	Loss: 4.6425
2022-12-06 20:38:52.323 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:38:52,367 [ZeusDataLoader(eval)] eval epoch 84 done: time=3.82 energy=474.51
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Up to epoch 84: time=4011.64, energy=529382.03, cost=615709.45
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:38:52,367 [ZeusDataLoader(train)] Expected next epoch: time=4058.25, energy=535748.32, cost=622970.69
2022-12-06 15:38:52,368 [ZeusDataLoader(train)] Epoch 85 begin.
Validation Epoch: 83, Average loss: 18148.9215, Accuracy: 0.0098
2022-12-06 15:38:52,619 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:38:52,619 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:38:52.621 [ZeusMonitor] Monitor started.
2022-12-06 20:38:52.621 [ZeusMonitor] Running indefinitely. 2022-12-06 20:38:52.621 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:38:52.621 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e85+gpu0.power.log
2022-12-06 15:39:36,215 [ZeusDataLoader(train)] train epoch 85 done: time=43.84 energy=5836.19
2022-12-06 15:39:36,218 [ZeusDataLoader(eval)] Epoch 85 begin.
Training Epoch: 84 [1024/50176]	Loss: 4.6403
Training Epoch: 84 [2048/50176]	Loss: 4.6621
Training Epoch: 84 [3072/50176]	Loss: 4.6352
Training Epoch: 84 [4096/50176]	Loss: 4.6605
Training Epoch: 84 [5120/50176]	Loss: 4.6568
Training Epoch: 84 [6144/50176]	Loss: 4.6435
Training Epoch: 84 [7168/50176]	Loss: 4.6489
Training Epoch: 84 [8192/50176]	Loss: 4.6314
Training Epoch: 84 [9216/50176]	Loss: 4.6336
Training Epoch: 84 [10240/50176]	Loss: 4.6581
Training Epoch: 84 [11264/50176]	Loss: 4.6397
Training Epoch: 84 [12288/50176]	Loss: 4.6428
Training Epoch: 84 [13312/50176]	Loss: 4.6518
Training Epoch: 84 [14336/50176]	Loss: 4.6396
Training Epoch: 84 [15360/50176]	Loss: 4.6395
Training Epoch: 84 [16384/50176]	Loss: 4.6295
Training Epoch: 84 [17408/50176]	Loss: 4.6344
Training Epoch: 84 [18432/50176]	Loss: 4.6443
Training Epoch: 84 [19456/50176]	Loss: 4.6338
Training Epoch: 84 [20480/50176]	Loss: 4.6395
Training Epoch: 84 [21504/50176]	Loss: 4.6383
Training Epoch: 84 [22528/50176]	Loss: 4.6310
Training Epoch: 84 [23552/50176]	Loss: 4.6277
Training Epoch: 84 [24576/50176]	Loss: 4.6406
Training Epoch: 84 [25600/50176]	Loss: 4.6423
Training Epoch: 84 [26624/50176]	Loss: 4.6288
Training Epoch: 84 [27648/50176]	Loss: 4.6336
Training Epoch: 84 [28672/50176]	Loss: 4.6307
Training Epoch: 84 [29696/50176]	Loss: 4.6306
Training Epoch: 84 [30720/50176]	Loss: 4.6269
Training Epoch: 84 [31744/50176]	Loss: 4.6323
Training Epoch: 84 [32768/50176]	Loss: 4.6331
Training Epoch: 84 [33792/50176]	Loss: 4.6387
Training Epoch: 84 [34816/50176]	Loss: 4.6383
Training Epoch: 84 [35840/50176]	Loss: 4.6353
Training Epoch: 84 [36864/50176]	Loss: 4.6291
Training Epoch: 84 [37888/50176]	Loss: 4.6404
Training Epoch: 84 [38912/50176]	Loss: 4.6366
Training Epoch: 84 [39936/50176]	Loss: 4.6265
Training Epoch: 84 [40960/50176]	Loss: 4.6266
Training Epoch: 84 [41984/50176]	Loss: 4.6285
Training Epoch: 84 [43008/50176]	Loss: 4.6371
Training Epoch: 84 [44032/50176]	Loss: 4.6419
Training Epoch: 84 [45056/50176]	Loss: 4.6603
Training Epoch: 84 [46080/50176]	Loss: 4.6489
Training Epoch: 84 [47104/50176]	Loss: 4.6329
Training Epoch: 84 [48128/50176]	Loss: 4.6351
Training Epoch: 84 [49152/50176]	Loss: 4.6221
Training Epoch: 84 [50176/50176]	Loss: 4.6410
2022-12-06 20:39:39.970 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:39:40,026 [ZeusDataLoader(eval)] eval epoch 85 done: time=3.80 energy=476.90
2022-12-06 15:39:40,026 [ZeusDataLoader(train)] Up to epoch 85: time=4059.28, energy=535695.12, cost=623034.42
2022-12-06 15:39:40,027 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:39:40,027 [ZeusDataLoader(train)] Expected next epoch: time=4105.89, energy=542061.41, cost=630295.65
2022-12-06 15:39:40,028 [ZeusDataLoader(train)] Epoch 86 begin.
Validation Epoch: 84, Average loss: 3550.1572, Accuracy: 0.0098
2022-12-06 15:39:40,284 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:39:40,285 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:39:40.287 [ZeusMonitor] Monitor started.
2022-12-06 20:39:40.287 [ZeusMonitor] Running indefinitely. 2022-12-06 20:39:40.287 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:39:40.287 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e86+gpu0.power.log
2022-12-06 15:40:23,969 [ZeusDataLoader(train)] train epoch 86 done: time=43.93 energy=5839.47
2022-12-06 15:40:23,972 [ZeusDataLoader(eval)] Epoch 86 begin.
Training Epoch: 85 [1024/50176]	Loss: 4.6509
Training Epoch: 85 [2048/50176]	Loss: 4.6556
Training Epoch: 85 [3072/50176]	Loss: 4.6643
Training Epoch: 85 [4096/50176]	Loss: 4.6609
Training Epoch: 85 [5120/50176]	Loss: 4.6331
Training Epoch: 85 [6144/50176]	Loss: 4.6349
Training Epoch: 85 [7168/50176]	Loss: 4.6321
Training Epoch: 85 [8192/50176]	Loss: 4.6387
Training Epoch: 85 [9216/50176]	Loss: 4.6388
Training Epoch: 85 [10240/50176]	Loss: 4.6471
Training Epoch: 85 [11264/50176]	Loss: 4.6434
Training Epoch: 85 [12288/50176]	Loss: 4.6415
Training Epoch: 85 [13312/50176]	Loss: 4.6304
Training Epoch: 85 [14336/50176]	Loss: 4.6323
Training Epoch: 85 [15360/50176]	Loss: 4.6515
Training Epoch: 85 [16384/50176]	Loss: 4.6389
Training Epoch: 85 [17408/50176]	Loss: 4.6418
Training Epoch: 85 [18432/50176]	Loss: 4.6313
Training Epoch: 85 [19456/50176]	Loss: 4.6392
Training Epoch: 85 [20480/50176]	Loss: 4.6305
Training Epoch: 85 [21504/50176]	Loss: 4.6358
Training Epoch: 85 [22528/50176]	Loss: 4.6424
Training Epoch: 85 [23552/50176]	Loss: 4.6388
Training Epoch: 85 [24576/50176]	Loss: 4.6369
Training Epoch: 85 [25600/50176]	Loss: 4.6401
Training Epoch: 85 [26624/50176]	Loss: 4.6507
Training Epoch: 85 [27648/50176]	Loss: 4.6407
Training Epoch: 85 [28672/50176]	Loss: 4.6217
Training Epoch: 85 [29696/50176]	Loss: 4.6388
Training Epoch: 85 [30720/50176]	Loss: 4.6491
Training Epoch: 85 [31744/50176]	Loss: 4.6347
Training Epoch: 85 [32768/50176]	Loss: 4.6447
Training Epoch: 85 [33792/50176]	Loss: 4.6309
Training Epoch: 85 [34816/50176]	Loss: 4.6394
Training Epoch: 85 [35840/50176]	Loss: 4.6235
Training Epoch: 85 [36864/50176]	Loss: 4.6353
Training Epoch: 85 [37888/50176]	Loss: 4.6412
Training Epoch: 85 [38912/50176]	Loss: 4.6558
Training Epoch: 85 [39936/50176]	Loss: 4.6478
Training Epoch: 85 [40960/50176]	Loss: 4.6543
Training Epoch: 85 [41984/50176]	Loss: 4.6443
Training Epoch: 85 [43008/50176]	Loss: 4.6265
Training Epoch: 85 [44032/50176]	Loss: 4.6450
Training Epoch: 85 [45056/50176]	Loss: 4.6258
Training Epoch: 85 [46080/50176]	Loss: 4.6465
Training Epoch: 85 [47104/50176]	Loss: 4.6385
Training Epoch: 85 [48128/50176]	Loss: 4.6495
Training Epoch: 85 [49152/50176]	Loss: 4.6454
Training Epoch: 85 [50176/50176]	Loss: 4.6434
2022-12-06 20:40:27.689 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:40:27,708 [ZeusDataLoader(eval)] eval epoch 86 done: time=3.73 energy=465.39
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Up to epoch 86: time=4106.94, energy=541999.97, cost=630357.20
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:40:27,708 [ZeusDataLoader(train)] Expected next epoch: time=4153.55, energy=548366.27, cost=637618.43
2022-12-06 15:40:27,709 [ZeusDataLoader(train)] Epoch 87 begin.
Validation Epoch: 85, Average loss: 11342.6416, Accuracy: 0.0098
2022-12-06 15:40:27,954 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:40:27,955 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:40:27.957 [ZeusMonitor] Monitor started.
2022-12-06 20:40:27.957 [ZeusMonitor] Running indefinitely. 2022-12-06 20:40:27.957 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:40:27.957 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e87+gpu0.power.log
2022-12-06 15:41:11,577 [ZeusDataLoader(train)] train epoch 87 done: time=43.86 energy=5829.46
2022-12-06 15:41:11,581 [ZeusDataLoader(eval)] Epoch 87 begin.
Training Epoch: 86 [1024/50176]	Loss: 4.6341
Training Epoch: 86 [2048/50176]	Loss: 4.6204
Training Epoch: 86 [3072/50176]	Loss: 4.6428
Training Epoch: 86 [4096/50176]	Loss: 4.6418
Training Epoch: 86 [5120/50176]	Loss: 4.6481
Training Epoch: 86 [6144/50176]	Loss: 4.6380
Training Epoch: 86 [7168/50176]	Loss: 4.6455
Training Epoch: 86 [8192/50176]	Loss: 4.6355
Training Epoch: 86 [9216/50176]	Loss: 4.6480
Training Epoch: 86 [10240/50176]	Loss: 4.6411
Training Epoch: 86 [11264/50176]	Loss: 4.6263
Training Epoch: 86 [12288/50176]	Loss: 4.6265
Training Epoch: 86 [13312/50176]	Loss: 4.6343
Training Epoch: 86 [14336/50176]	Loss: 4.6345
Training Epoch: 86 [15360/50176]	Loss: 4.6473
Training Epoch: 86 [16384/50176]	Loss: 4.6371
Training Epoch: 86 [17408/50176]	Loss: 4.6533
Training Epoch: 86 [18432/50176]	Loss: 4.6469
Training Epoch: 86 [19456/50176]	Loss: 4.6361
Training Epoch: 86 [20480/50176]	Loss: 4.6326
Training Epoch: 86 [21504/50176]	Loss: 4.6478
Training Epoch: 86 [22528/50176]	Loss: 4.6514
Training Epoch: 86 [23552/50176]	Loss: 4.6398
Training Epoch: 86 [24576/50176]	Loss: 4.6529
Training Epoch: 86 [25600/50176]	Loss: 4.6480
Training Epoch: 86 [26624/50176]	Loss: 4.6531
Training Epoch: 86 [27648/50176]	Loss: 4.6476
Training Epoch: 86 [28672/50176]	Loss: 4.6194
Training Epoch: 86 [29696/50176]	Loss: 4.6354
Training Epoch: 86 [30720/50176]	Loss: 4.6421
Training Epoch: 86 [31744/50176]	Loss: 4.6405
Training Epoch: 86 [32768/50176]	Loss: 4.6272
Training Epoch: 86 [33792/50176]	Loss: 4.6367
Training Epoch: 86 [34816/50176]	Loss: 4.6552
Training Epoch: 86 [35840/50176]	Loss: 4.6457
Training Epoch: 86 [36864/50176]	Loss: 4.6419
Training Epoch: 86 [37888/50176]	Loss: 4.6345
Training Epoch: 86 [38912/50176]	Loss: 4.6374
Training Epoch: 86 [39936/50176]	Loss: 4.6290
Training Epoch: 86 [40960/50176]	Loss: 4.6561
Training Epoch: 86 [41984/50176]	Loss: 4.6473
Training Epoch: 86 [43008/50176]	Loss: 4.6552
Training Epoch: 86 [44032/50176]	Loss: 4.6380
Training Epoch: 86 [45056/50176]	Loss: 4.6373
Training Epoch: 86 [46080/50176]	Loss: 4.6404
Training Epoch: 86 [47104/50176]	Loss: 4.6467
Training Epoch: 86 [48128/50176]	Loss: 4.6216
Training Epoch: 86 [49152/50176]	Loss: 4.6301
Training Epoch: 86 [50176/50176]	Loss: 4.6388
2022-12-06 20:41:15.375 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:41:15,398 [ZeusDataLoader(eval)] eval epoch 87 done: time=3.81 energy=479.72
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Up to epoch 87: time=4154.61, energy=548309.15, cost=637682.81
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:41:15,398 [ZeusDataLoader(train)] Expected next epoch: time=4201.22, energy=554675.44, cost=644944.05
2022-12-06 15:41:15,399 [ZeusDataLoader(train)] Epoch 88 begin.
Validation Epoch: 86, Average loss: 1051.6934, Accuracy: 0.0098
2022-12-06 15:41:15,585 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:41:15,586 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:41:15.589 [ZeusMonitor] Monitor started.
2022-12-06 20:41:15.590 [ZeusMonitor] Running indefinitely. 2022-12-06 20:41:15.590 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:41:15.590 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e88+gpu0.power.log
2022-12-06 15:41:59,232 [ZeusDataLoader(train)] train epoch 88 done: time=43.83 energy=5836.74
2022-12-06 15:41:59,236 [ZeusDataLoader(eval)] Epoch 88 begin.
Training Epoch: 87 [1024/50176]	Loss: 4.6589
Training Epoch: 87 [2048/50176]	Loss: 4.6500
Training Epoch: 87 [3072/50176]	Loss: 4.6394
Training Epoch: 87 [4096/50176]	Loss: 4.6331
Training Epoch: 87 [5120/50176]	Loss: 4.6292
Training Epoch: 87 [6144/50176]	Loss: 4.6508
Training Epoch: 87 [7168/50176]	Loss: 4.6425
Training Epoch: 87 [8192/50176]	Loss: 4.6402
Training Epoch: 87 [9216/50176]	Loss: 4.6672
Training Epoch: 87 [10240/50176]	Loss: 4.6455
Training Epoch: 87 [11264/50176]	Loss: 4.6623
Training Epoch: 87 [12288/50176]	Loss: 4.6270
Training Epoch: 87 [13312/50176]	Loss: 4.6530
Training Epoch: 87 [14336/50176]	Loss: 4.6342
Training Epoch: 87 [15360/50176]	Loss: 4.6314
Training Epoch: 87 [16384/50176]	Loss: 4.6425
Training Epoch: 87 [17408/50176]	Loss: 4.6485
Training Epoch: 87 [18432/50176]	Loss: 4.6406
Training Epoch: 87 [19456/50176]	Loss: 4.6381
Training Epoch: 87 [20480/50176]	Loss: 4.6377
Training Epoch: 87 [21504/50176]	Loss: 4.6407
Training Epoch: 87 [22528/50176]	Loss: 4.6329
Training Epoch: 87 [23552/50176]	Loss: 4.6478
Training Epoch: 87 [24576/50176]	Loss: 4.6287
Training Epoch: 87 [25600/50176]	Loss: 4.6321
Training Epoch: 87 [26624/50176]	Loss: 4.6434
Training Epoch: 87 [27648/50176]	Loss: 4.6245
Training Epoch: 87 [28672/50176]	Loss: 4.6314
Training Epoch: 87 [29696/50176]	Loss: 4.6207
Training Epoch: 87 [30720/50176]	Loss: 4.6455
Training Epoch: 87 [31744/50176]	Loss: 4.6393
Training Epoch: 87 [32768/50176]	Loss: 4.6377
Training Epoch: 87 [33792/50176]	Loss: 4.6336
Training Epoch: 87 [34816/50176]	Loss: 4.6144
Training Epoch: 87 [35840/50176]	Loss: 4.6187
Training Epoch: 87 [36864/50176]	Loss: 4.6293
Training Epoch: 87 [37888/50176]	Loss: 4.6406
Training Epoch: 87 [38912/50176]	Loss: 4.6338
Training Epoch: 87 [39936/50176]	Loss: 4.6345
Training Epoch: 87 [40960/50176]	Loss: 4.6378
Training Epoch: 87 [41984/50176]	Loss: 4.6398
Training Epoch: 87 [43008/50176]	Loss: 4.6344
Training Epoch: 87 [44032/50176]	Loss: 4.6472
Training Epoch: 87 [45056/50176]	Loss: 4.6447
Training Epoch: 87 [46080/50176]	Loss: 4.6269
Training Epoch: 87 [47104/50176]	Loss: 4.6294
Training Epoch: 87 [48128/50176]	Loss: 4.6385
Training Epoch: 87 [49152/50176]	Loss: 4.6375
Training Epoch: 87 [50176/50176]	Loss: 4.6320
2022-12-06 20:42:02.982 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:42:03,010 [ZeusDataLoader(eval)] eval epoch 88 done: time=3.77 energy=463.21
2022-12-06 15:42:03,010 [ZeusDataLoader(train)] Up to epoch 88: time=4202.20, energy=554609.09, cost=644997.08
2022-12-06 15:42:03,011 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:42:03,011 [ZeusDataLoader(train)] Expected next epoch: time=4248.81, energy=560975.39, cost=652258.31
2022-12-06 15:42:03,012 [ZeusDataLoader(train)] Epoch 89 begin.
Validation Epoch: 87, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:42:03,281 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:42:03,282 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:42:03.296 [ZeusMonitor] Monitor started.
2022-12-06 20:42:03.296 [ZeusMonitor] Running indefinitely. 2022-12-06 20:42:03.296 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:42:03.296 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e89+gpu0.power.log
2022-12-06 15:42:47,451 [ZeusDataLoader(train)] train epoch 89 done: time=44.43 energy=5877.23
2022-12-06 15:42:47,454 [ZeusDataLoader(eval)] Epoch 89 begin.
Training Epoch: 88 [1024/50176]	Loss: 4.6489
Training Epoch: 88 [2048/50176]	Loss: 4.6363
Training Epoch: 88 [3072/50176]	Loss: 4.6530
Training Epoch: 88 [4096/50176]	Loss: 4.6353
Training Epoch: 88 [5120/50176]	Loss: 4.6312
Training Epoch: 88 [6144/50176]	Loss: 4.6349
Training Epoch: 88 [7168/50176]	Loss: 4.6428
Training Epoch: 88 [8192/50176]	Loss: 4.6436
Training Epoch: 88 [9216/50176]	Loss: 4.6374
Training Epoch: 88 [10240/50176]	Loss: 4.6455
Training Epoch: 88 [11264/50176]	Loss: 4.6332
Training Epoch: 88 [12288/50176]	Loss: 4.6416
Training Epoch: 88 [13312/50176]	Loss: 4.6475
Training Epoch: 88 [14336/50176]	Loss: 4.6490
Training Epoch: 88 [15360/50176]	Loss: 4.6421
Training Epoch: 88 [16384/50176]	Loss: 4.6398
Training Epoch: 88 [17408/50176]	Loss: 4.6370
Training Epoch: 88 [18432/50176]	Loss: 4.6529
Training Epoch: 88 [19456/50176]	Loss: 4.6350
Training Epoch: 88 [20480/50176]	Loss: 4.6321
Training Epoch: 88 [21504/50176]	Loss: 4.6395
Training Epoch: 88 [22528/50176]	Loss: 4.6315
Training Epoch: 88 [23552/50176]	Loss: 4.6340
Training Epoch: 88 [24576/50176]	Loss: 4.6294
Training Epoch: 88 [25600/50176]	Loss: 4.6388
Training Epoch: 88 [26624/50176]	Loss: 4.6279
Training Epoch: 88 [27648/50176]	Loss: 4.6363
Training Epoch: 88 [28672/50176]	Loss: 4.6400
Training Epoch: 88 [29696/50176]	Loss: 4.6484
Training Epoch: 88 [30720/50176]	Loss: 4.6467
Training Epoch: 88 [31744/50176]	Loss: 4.6433
Training Epoch: 88 [32768/50176]	Loss: 4.6239
Training Epoch: 88 [33792/50176]	Loss: 4.6556
Training Epoch: 88 [34816/50176]	Loss: 4.6387
Training Epoch: 88 [35840/50176]	Loss: 4.6480
Training Epoch: 88 [36864/50176]	Loss: 4.6283
Training Epoch: 88 [37888/50176]	Loss: 4.6276
Training Epoch: 88 [38912/50176]	Loss: 4.6182
Training Epoch: 88 [39936/50176]	Loss: 4.6297
Training Epoch: 88 [40960/50176]	Loss: 4.6545
Training Epoch: 88 [41984/50176]	Loss: 4.6512
Training Epoch: 88 [43008/50176]	Loss: 4.6372
Training Epoch: 88 [44032/50176]	Loss: 4.6398
Training Epoch: 88 [45056/50176]	Loss: 4.6312
Training Epoch: 88 [46080/50176]	Loss: 4.6382
Training Epoch: 88 [47104/50176]	Loss: 4.6350
Training Epoch: 88 [48128/50176]	Loss: 4.6290
Training Epoch: 88 [49152/50176]	Loss: 4.6353
Training Epoch: 88 [50176/50176]	Loss: 4.6476
2022-12-06 20:42:51.292 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:42:51,333 [ZeusDataLoader(eval)] eval epoch 89 done: time=3.87 energy=476.94
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Up to epoch 89: time=4250.50, energy=560963.26, cost=652400.56
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:42:51,333 [ZeusDataLoader(train)] Expected next epoch: time=4297.11, energy=567329.55, cost=659661.80
2022-12-06 15:42:51,334 [ZeusDataLoader(train)] Epoch 90 begin.
Validation Epoch: 88, Average loss: 14242.4237, Accuracy: 0.0098
2022-12-06 15:42:51,586 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:42:51,586 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:42:51.588 [ZeusMonitor] Monitor started.
2022-12-06 20:42:51.588 [ZeusMonitor] Running indefinitely. 2022-12-06 20:42:51.588 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:42:51.588 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e90+gpu0.power.log
2022-12-06 15:43:36,016 [ZeusDataLoader(train)] train epoch 90 done: time=44.67 energy=5898.26
2022-12-06 15:43:36,019 [ZeusDataLoader(eval)] Epoch 90 begin.
Training Epoch: 89 [1024/50176]	Loss: 4.6310
Training Epoch: 89 [2048/50176]	Loss: 4.6510
Training Epoch: 89 [3072/50176]	Loss: 4.6328
Training Epoch: 89 [4096/50176]	Loss: 4.6407
Training Epoch: 89 [5120/50176]	Loss: 4.6461
Training Epoch: 89 [6144/50176]	Loss: 4.6516
Training Epoch: 89 [7168/50176]	Loss: 4.6362
Training Epoch: 89 [8192/50176]	Loss: 4.6327
Training Epoch: 89 [9216/50176]	Loss: 4.6417
Training Epoch: 89 [10240/50176]	Loss: 4.6455
Training Epoch: 89 [11264/50176]	Loss: 4.6442
Training Epoch: 89 [12288/50176]	Loss: 4.6398
Training Epoch: 89 [13312/50176]	Loss: 4.6313
Training Epoch: 89 [14336/50176]	Loss: 4.6261
Training Epoch: 89 [15360/50176]	Loss: 4.6502
Training Epoch: 89 [16384/50176]	Loss: 4.6280
Training Epoch: 89 [17408/50176]	Loss: 4.6575
Training Epoch: 89 [18432/50176]	Loss: 4.6283
Training Epoch: 89 [19456/50176]	Loss: 4.6356
Training Epoch: 89 [20480/50176]	Loss: 4.6209
Training Epoch: 89 [21504/50176]	Loss: 4.6357
Training Epoch: 89 [22528/50176]	Loss: 4.6341
Training Epoch: 89 [23552/50176]	Loss: 4.6461
Training Epoch: 89 [24576/50176]	Loss: 4.6360
Training Epoch: 89 [25600/50176]	Loss: 4.6444
Training Epoch: 89 [26624/50176]	Loss: 4.6414
Training Epoch: 89 [27648/50176]	Loss: 4.6315
Training Epoch: 89 [28672/50176]	Loss: 4.6533
Training Epoch: 89 [29696/50176]	Loss: 4.6338
Training Epoch: 89 [30720/50176]	Loss: 4.6471
Training Epoch: 89 [31744/50176]	Loss: 4.6300
Training Epoch: 89 [32768/50176]	Loss: 4.6354
Training Epoch: 89 [33792/50176]	Loss: 4.6214
Training Epoch: 89 [34816/50176]	Loss: 4.6157
Training Epoch: 89 [35840/50176]	Loss: 4.6379
Training Epoch: 89 [36864/50176]	Loss: 4.6356
Training Epoch: 89 [37888/50176]	Loss: 4.6297
Training Epoch: 89 [38912/50176]	Loss: 4.6373
Training Epoch: 89 [39936/50176]	Loss: 4.6284
Training Epoch: 89 [40960/50176]	Loss: 4.6422
Training Epoch: 89 [41984/50176]	Loss: 4.6292
Training Epoch: 89 [43008/50176]	Loss: 4.6198
Training Epoch: 89 [44032/50176]	Loss: 4.6253
Training Epoch: 89 [45056/50176]	Loss: 4.6369
Training Epoch: 89 [46080/50176]	Loss: 4.6247
Training Epoch: 89 [47104/50176]	Loss: 4.6261
Training Epoch: 89 [48128/50176]	Loss: 4.6244
Training Epoch: 89 [49152/50176]	Loss: 4.6412
Training Epoch: 89 [50176/50176]	Loss: 4.6388
2022-12-06 20:43:39.776 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:43:39,789 [ZeusDataLoader(eval)] eval epoch 90 done: time=3.76 energy=459.91
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Up to epoch 90: time=4298.94, energy=567321.44, cost=659817.72
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:43:39,790 [ZeusDataLoader(train)] Expected next epoch: time=4345.54, energy=573687.73, cost=667078.96
2022-12-06 15:43:39,791 [ZeusDataLoader(train)] Epoch 91 begin.
Validation Epoch: 89, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:43:40,032 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:43:40,032 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:43:40.044 [ZeusMonitor] Monitor started.
2022-12-06 20:43:40.044 [ZeusMonitor] Running indefinitely. 2022-12-06 20:43:40.044 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:43:40.044 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e91+gpu0.power.log
2022-12-06 15:44:24,261 [ZeusDataLoader(train)] train epoch 91 done: time=44.46 energy=5873.22
2022-12-06 15:44:24,265 [ZeusDataLoader(eval)] Epoch 91 begin.
Training Epoch: 90 [1024/50176]	Loss: 4.6429
Training Epoch: 90 [2048/50176]	Loss: 4.6325
Training Epoch: 90 [3072/50176]	Loss: 4.6235
Training Epoch: 90 [4096/50176]	Loss: 4.6224
Training Epoch: 90 [5120/50176]	Loss: 4.6429
Training Epoch: 90 [6144/50176]	Loss: 4.6361
Training Epoch: 90 [7168/50176]	Loss: 4.6234
Training Epoch: 90 [8192/50176]	Loss: 4.6462
Training Epoch: 90 [9216/50176]	Loss: 4.6315
Training Epoch: 90 [10240/50176]	Loss: 4.6342
Training Epoch: 90 [11264/50176]	Loss: 4.6238
Training Epoch: 90 [12288/50176]	Loss: 4.6466
Training Epoch: 90 [13312/50176]	Loss: 4.6494
Training Epoch: 90 [14336/50176]	Loss: 4.6354
Training Epoch: 90 [15360/50176]	Loss: 4.6242
Training Epoch: 90 [16384/50176]	Loss: 4.6369
Training Epoch: 90 [17408/50176]	Loss: 4.6333
Training Epoch: 90 [18432/50176]	Loss: 4.6471
Training Epoch: 90 [19456/50176]	Loss: 4.6292
Training Epoch: 90 [20480/50176]	Loss: 4.6393
Training Epoch: 90 [21504/50176]	Loss: 4.6418
Training Epoch: 90 [22528/50176]	Loss: 4.6343
Training Epoch: 90 [23552/50176]	Loss: 4.6376
Training Epoch: 90 [24576/50176]	Loss: 4.6363
Training Epoch: 90 [25600/50176]	Loss: 4.6308
Training Epoch: 90 [26624/50176]	Loss: 4.6371
Training Epoch: 90 [27648/50176]	Loss: 4.6433
Training Epoch: 90 [28672/50176]	Loss: 4.6607
Training Epoch: 90 [29696/50176]	Loss: 4.6454
Training Epoch: 90 [30720/50176]	Loss: 4.6356
Training Epoch: 90 [31744/50176]	Loss: 4.6274
Training Epoch: 90 [32768/50176]	Loss: 4.6431
Training Epoch: 90 [33792/50176]	Loss: 4.6453
Training Epoch: 90 [34816/50176]	Loss: 4.6392
Training Epoch: 90 [35840/50176]	Loss: 4.6304
Training Epoch: 90 [36864/50176]	Loss: 4.6427
Training Epoch: 90 [37888/50176]	Loss: 4.6369
Training Epoch: 90 [38912/50176]	Loss: 4.6367
Training Epoch: 90 [39936/50176]	Loss: 4.6309
Training Epoch: 90 [40960/50176]	Loss: 4.6383
Training Epoch: 90 [41984/50176]	Loss: 4.6420
Training Epoch: 90 [43008/50176]	Loss: 4.6311
Training Epoch: 90 [44032/50176]	Loss: 4.6341
Training Epoch: 90 [45056/50176]	Loss: 4.6249
Training Epoch: 90 [46080/50176]	Loss: 4.6420
Training Epoch: 90 [47104/50176]	Loss: 4.6322
Training Epoch: 90 [48128/50176]	Loss: 4.6406
Training Epoch: 90 [49152/50176]	Loss: 4.6459
Training Epoch: 90 [50176/50176]	Loss: 4.6267
2022-12-06 20:44:28.026 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:44:28,075 [ZeusDataLoader(eval)] eval epoch 91 done: time=3.80 energy=476.46
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Up to epoch 91: time=4347.20, energy=573671.12, cost=667215.76
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:44:28,076 [ZeusDataLoader(train)] Expected next epoch: time=4393.81, energy=580037.41, cost=674477.00
2022-12-06 15:44:28,077 [ZeusDataLoader(train)] Epoch 92 begin.
Validation Epoch: 90, Average loss: 17559.5884, Accuracy: 0.0098
2022-12-06 15:44:28,326 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:44:28,327 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:44:28.341 [ZeusMonitor] Monitor started.
2022-12-06 20:44:28.341 [ZeusMonitor] Running indefinitely. 2022-12-06 20:44:28.341 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:44:28.341 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e92+gpu0.power.log
2022-12-06 15:45:11,887 [ZeusDataLoader(train)] train epoch 92 done: time=43.80 energy=5832.56
2022-12-06 15:45:11,891 [ZeusDataLoader(eval)] Epoch 92 begin.
Training Epoch: 91 [1024/50176]	Loss: 4.6347
Training Epoch: 91 [2048/50176]	Loss: 4.6244
Training Epoch: 91 [3072/50176]	Loss: 4.6290
Training Epoch: 91 [4096/50176]	Loss: 4.6244
Training Epoch: 91 [5120/50176]	Loss: 4.6469
Training Epoch: 91 [6144/50176]	Loss: 4.6475
Training Epoch: 91 [7168/50176]	Loss: 4.6320
Training Epoch: 91 [8192/50176]	Loss: 4.6417
Training Epoch: 91 [9216/50176]	Loss: 4.6355
Training Epoch: 91 [10240/50176]	Loss: 4.6428
Training Epoch: 91 [11264/50176]	Loss: 4.6380
Training Epoch: 91 [12288/50176]	Loss: 4.6392
Training Epoch: 91 [13312/50176]	Loss: 4.6290
Training Epoch: 91 [14336/50176]	Loss: 4.6275
Training Epoch: 91 [15360/50176]	Loss: 4.6552
Training Epoch: 91 [16384/50176]	Loss: 4.6432
Training Epoch: 91 [17408/50176]	Loss: 4.6398
Training Epoch: 91 [18432/50176]	Loss: 4.6365
Training Epoch: 91 [19456/50176]	Loss: 4.6224
Training Epoch: 91 [20480/50176]	Loss: 4.6323
Training Epoch: 91 [21504/50176]	Loss: 4.6410
Training Epoch: 91 [22528/50176]	Loss: 4.6326
Training Epoch: 91 [23552/50176]	Loss: 4.6458
Training Epoch: 91 [24576/50176]	Loss: 4.6399
Training Epoch: 91 [25600/50176]	Loss: 4.6317
Training Epoch: 91 [26624/50176]	Loss: 4.6322
Training Epoch: 91 [27648/50176]	Loss: 4.6351
Training Epoch: 91 [28672/50176]	Loss: 4.6296
Training Epoch: 91 [29696/50176]	Loss: 4.6210
Training Epoch: 91 [30720/50176]	Loss: 4.6392
Training Epoch: 91 [31744/50176]	Loss: 4.6320
Training Epoch: 91 [32768/50176]	Loss: 4.6338
Training Epoch: 91 [33792/50176]	Loss: 4.6328
Training Epoch: 91 [34816/50176]	Loss: 4.6385
Training Epoch: 91 [35840/50176]	Loss: 4.6457
Training Epoch: 91 [36864/50176]	Loss: 4.6252
Training Epoch: 91 [37888/50176]	Loss: 4.6282
Training Epoch: 91 [38912/50176]	Loss: 4.6277
Training Epoch: 91 [39936/50176]	Loss: 4.6407
Training Epoch: 91 [40960/50176]	Loss: 4.6396
Training Epoch: 91 [41984/50176]	Loss: 4.6342
Training Epoch: 91 [43008/50176]	Loss: 4.6340
Training Epoch: 91 [44032/50176]	Loss: 4.6453
Training Epoch: 91 [45056/50176]	Loss: 4.6456
Training Epoch: 91 [46080/50176]	Loss: 4.6347
Training Epoch: 91 [47104/50176]	Loss: 4.6424
Training Epoch: 91 [48128/50176]	Loss: 4.6419
Training Epoch: 91 [49152/50176]	Loss: 4.6423
Training Epoch: 91 [50176/50176]	Loss: 4.6432
2022-12-06 20:45:15.725 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:45:15,735 [ZeusDataLoader(eval)] eval epoch 92 done: time=3.84 energy=473.44
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Up to epoch 92: time=4394.84, energy=579977.12, cost=674537.21
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:45:15,735 [ZeusDataLoader(train)] Expected next epoch: time=4441.45, energy=586343.41, cost=681798.45
2022-12-06 15:45:15,736 [ZeusDataLoader(train)] Epoch 93 begin.
Validation Epoch: 91, Average loss: 9744.3790, Accuracy: 0.0098
2022-12-06 15:45:15,956 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:45:15,957 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:45:15.959 [ZeusMonitor] Monitor started.
2022-12-06 20:45:15.959 [ZeusMonitor] Running indefinitely. 2022-12-06 20:45:15.959 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:45:15.959 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e93+gpu0.power.log
2022-12-06 15:45:59,590 [ZeusDataLoader(train)] train epoch 93 done: time=43.85 energy=5837.45
2022-12-06 15:45:59,593 [ZeusDataLoader(eval)] Epoch 93 begin.
Training Epoch: 92 [1024/50176]	Loss: 4.6322
Training Epoch: 92 [2048/50176]	Loss: 4.6397
Training Epoch: 92 [3072/50176]	Loss: 4.6340
Training Epoch: 92 [4096/50176]	Loss: 4.6115
Training Epoch: 92 [5120/50176]	Loss: 4.6373
Training Epoch: 92 [6144/50176]	Loss: 4.6476
Training Epoch: 92 [7168/50176]	Loss: 4.6327
Training Epoch: 92 [8192/50176]	Loss: 4.6362
Training Epoch: 92 [9216/50176]	Loss: 4.6293
Training Epoch: 92 [10240/50176]	Loss: 4.6200
Training Epoch: 92 [11264/50176]	Loss: 4.6340
Training Epoch: 92 [12288/50176]	Loss: 4.6264
Training Epoch: 92 [13312/50176]	Loss: 4.6378
Training Epoch: 92 [14336/50176]	Loss: 4.6259
Training Epoch: 92 [15360/50176]	Loss: 4.6475
Training Epoch: 92 [16384/50176]	Loss: 4.6417
Training Epoch: 92 [17408/50176]	Loss: 4.6432
Training Epoch: 92 [18432/50176]	Loss: 4.6354
Training Epoch: 92 [19456/50176]	Loss: 4.6336
Training Epoch: 92 [20480/50176]	Loss: 4.6312
Training Epoch: 92 [21504/50176]	Loss: 4.6368
Training Epoch: 92 [22528/50176]	Loss: 4.6585
Training Epoch: 92 [23552/50176]	Loss: 4.6419
Training Epoch: 92 [24576/50176]	Loss: 4.6361
Training Epoch: 92 [25600/50176]	Loss: 4.6343
Training Epoch: 92 [26624/50176]	Loss: 4.6336
Training Epoch: 92 [27648/50176]	Loss: 4.6364
Training Epoch: 92 [28672/50176]	Loss: 4.6298
Training Epoch: 92 [29696/50176]	Loss: 4.6372
Training Epoch: 92 [30720/50176]	Loss: 4.6419
Training Epoch: 92 [31744/50176]	Loss: 4.6292
Training Epoch: 92 [32768/50176]	Loss: 4.6394
Training Epoch: 92 [33792/50176]	Loss: 4.6281
Training Epoch: 92 [34816/50176]	Loss: 4.6335
Training Epoch: 92 [35840/50176]	Loss: 4.6242
Training Epoch: 92 [36864/50176]	Loss: 4.6447
Training Epoch: 92 [37888/50176]	Loss: 4.6250
Training Epoch: 92 [38912/50176]	Loss: 4.6316
Training Epoch: 92 [39936/50176]	Loss: 4.6353
Training Epoch: 92 [40960/50176]	Loss: 4.6247
Training Epoch: 92 [41984/50176]	Loss: 4.6394
Training Epoch: 92 [43008/50176]	Loss: 4.6224
Training Epoch: 92 [44032/50176]	Loss: 4.6314
Training Epoch: 92 [45056/50176]	Loss: 4.6330
Training Epoch: 92 [46080/50176]	Loss: 4.6277
Training Epoch: 92 [47104/50176]	Loss: 4.6362
Training Epoch: 92 [48128/50176]	Loss: 4.6395
Training Epoch: 92 [49152/50176]	Loss: 4.6271
Training Epoch: 92 [50176/50176]	Loss: 4.6304
2022-12-06 20:46:03.262 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:46:03,272 [ZeusDataLoader(eval)] eval epoch 93 done: time=3.67 energy=453.85
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Up to epoch 93: time=4442.36, energy=586268.42, cost=681840.54
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:46:03,272 [ZeusDataLoader(train)] Expected next epoch: time=4488.96, energy=592634.71, cost=689101.77
2022-12-06 15:46:03,273 [ZeusDataLoader(train)] Epoch 94 begin.
Validation Epoch: 92, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:46:03,563 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:46:03,563 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:46:03.565 [ZeusMonitor] Monitor started.
2022-12-06 20:46:03.565 [ZeusMonitor] Running indefinitely. 2022-12-06 20:46:03.565 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:46:03.565 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e94+gpu0.power.log
2022-12-06 15:46:47,150 [ZeusDataLoader(train)] train epoch 94 done: time=43.87 energy=5833.46
2022-12-06 15:46:47,154 [ZeusDataLoader(eval)] Epoch 94 begin.
Training Epoch: 93 [1024/50176]	Loss: 4.6331
Training Epoch: 93 [2048/50176]	Loss: 4.6334
Training Epoch: 93 [3072/50176]	Loss: 4.6411
Training Epoch: 93 [4096/50176]	Loss: 4.6419
Training Epoch: 93 [5120/50176]	Loss: 4.6237
Training Epoch: 93 [6144/50176]	Loss: 4.6344
Training Epoch: 93 [7168/50176]	Loss: 4.6249
Training Epoch: 93 [8192/50176]	Loss: 4.6425
Training Epoch: 93 [9216/50176]	Loss: 4.6341
Training Epoch: 93 [10240/50176]	Loss: 4.6331
Training Epoch: 93 [11264/50176]	Loss: 4.6368
Training Epoch: 93 [12288/50176]	Loss: 4.6388
Training Epoch: 93 [13312/50176]	Loss: 4.6394
Training Epoch: 93 [14336/50176]	Loss: 4.6301
Training Epoch: 93 [15360/50176]	Loss: 4.6288
Training Epoch: 93 [16384/50176]	Loss: 4.6252
Training Epoch: 93 [17408/50176]	Loss: 4.6328
Training Epoch: 93 [18432/50176]	Loss: 4.6166
Training Epoch: 93 [19456/50176]	Loss: 4.6380
Training Epoch: 93 [20480/50176]	Loss: 4.6219
Training Epoch: 93 [21504/50176]	Loss: 4.6312
Training Epoch: 93 [22528/50176]	Loss: 4.6367
Training Epoch: 93 [23552/50176]	Loss: 4.6469
Training Epoch: 93 [24576/50176]	Loss: 4.6353
Training Epoch: 93 [25600/50176]	Loss: 4.6308
Training Epoch: 93 [26624/50176]	Loss: 4.6431
Training Epoch: 93 [27648/50176]	Loss: 4.6277
Training Epoch: 93 [28672/50176]	Loss: 4.6548
Training Epoch: 93 [29696/50176]	Loss: 4.6320
Training Epoch: 93 [30720/50176]	Loss: 4.6213
Training Epoch: 93 [31744/50176]	Loss: 4.6274
Training Epoch: 93 [32768/50176]	Loss: 4.6380
Training Epoch: 93 [33792/50176]	Loss: 4.6396
Training Epoch: 93 [34816/50176]	Loss: 4.6323
Training Epoch: 93 [35840/50176]	Loss: 4.6391
Training Epoch: 93 [36864/50176]	Loss: 4.6314
Training Epoch: 93 [37888/50176]	Loss: 4.6338
Training Epoch: 93 [38912/50176]	Loss: 4.6555
Training Epoch: 93 [39936/50176]	Loss: 4.6290
Training Epoch: 93 [40960/50176]	Loss: 4.6419
Training Epoch: 93 [41984/50176]	Loss: 4.6379
Training Epoch: 93 [43008/50176]	Loss: 4.6188
Training Epoch: 93 [44032/50176]	Loss: 4.6212
Training Epoch: 93 [45056/50176]	Loss: 4.6442
Training Epoch: 93 [46080/50176]	Loss: 4.6481
Training Epoch: 93 [47104/50176]	Loss: 4.6484
Training Epoch: 93 [48128/50176]	Loss: 4.6446
Training Epoch: 93 [49152/50176]	Loss: 4.6486
Training Epoch: 93 [50176/50176]	Loss: 4.6527
2022-12-06 20:46:50.910 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:46:50,961 [ZeusDataLoader(eval)] eval epoch 94 done: time=3.80 energy=480.53
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Up to epoch 94: time=4490.03, energy=592582.41, cost=689168.57
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:46:50,961 [ZeusDataLoader(train)] Expected next epoch: time=4536.63, energy=598948.71, cost=696429.81
2022-12-06 15:46:50,962 [ZeusDataLoader(train)] Epoch 95 begin.
Validation Epoch: 93, Average loss: 12261.9728, Accuracy: 0.0098
2022-12-06 15:46:51,186 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:46:51,187 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:46:51.201 [ZeusMonitor] Monitor started.
2022-12-06 20:46:51.201 [ZeusMonitor] Running indefinitely. 2022-12-06 20:46:51.201 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:46:51.201 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e95+gpu0.power.log
2022-12-06 15:47:34,736 [ZeusDataLoader(train)] train epoch 95 done: time=43.77 energy=5822.16
2022-12-06 15:47:34,740 [ZeusDataLoader(eval)] Epoch 95 begin.
Training Epoch: 94 [1024/50176]	Loss: 4.6130
Training Epoch: 94 [2048/50176]	Loss: 4.6408
Training Epoch: 94 [3072/50176]	Loss: 4.6343
Training Epoch: 94 [4096/50176]	Loss: 4.6339
Training Epoch: 94 [5120/50176]	Loss: 4.6366
Training Epoch: 94 [6144/50176]	Loss: 4.6338
Training Epoch: 94 [7168/50176]	Loss: 4.6188
Training Epoch: 94 [8192/50176]	Loss: 4.6468
Training Epoch: 94 [9216/50176]	Loss: 4.6282
Training Epoch: 94 [10240/50176]	Loss: 4.6365
Training Epoch: 94 [11264/50176]	Loss: 4.6285
Training Epoch: 94 [12288/50176]	Loss: 4.6467
Training Epoch: 94 [13312/50176]	Loss: 4.6401
Training Epoch: 94 [14336/50176]	Loss: 4.6374
Training Epoch: 94 [15360/50176]	Loss: 4.6386
Training Epoch: 94 [16384/50176]	Loss: 4.6245
Training Epoch: 94 [17408/50176]	Loss: 4.6558
Training Epoch: 94 [18432/50176]	Loss: 4.6409
Training Epoch: 94 [19456/50176]	Loss: 4.6352
Training Epoch: 94 [20480/50176]	Loss: 4.6429
Training Epoch: 94 [21504/50176]	Loss: 4.6401
Training Epoch: 94 [22528/50176]	Loss: 4.6457
Training Epoch: 94 [23552/50176]	Loss: 4.6333
Training Epoch: 94 [24576/50176]	Loss: 4.6599
Training Epoch: 94 [25600/50176]	Loss: 4.6385
Training Epoch: 94 [26624/50176]	Loss: 4.6365
Training Epoch: 94 [27648/50176]	Loss: 4.6485
Training Epoch: 94 [28672/50176]	Loss: 4.6531
Training Epoch: 94 [29696/50176]	Loss: 4.6435
Training Epoch: 94 [30720/50176]	Loss: 4.6350
Training Epoch: 94 [31744/50176]	Loss: 4.6413
Training Epoch: 94 [32768/50176]	Loss: 4.6326
Training Epoch: 94 [33792/50176]	Loss: 4.6412
Training Epoch: 94 [34816/50176]	Loss: 4.6399
Training Epoch: 94 [35840/50176]	Loss: 4.6303
Training Epoch: 94 [36864/50176]	Loss: 4.6507
Training Epoch: 94 [37888/50176]	Loss: 4.6273
Training Epoch: 94 [38912/50176]	Loss: 4.6327
Training Epoch: 94 [39936/50176]	Loss: 4.6399
Training Epoch: 94 [40960/50176]	Loss: 4.6324
Training Epoch: 94 [41984/50176]	Loss: 4.6452
Training Epoch: 94 [43008/50176]	Loss: 4.6413
Training Epoch: 94 [44032/50176]	Loss: 4.6384
Training Epoch: 94 [45056/50176]	Loss: 4.6366
Training Epoch: 94 [46080/50176]	Loss: 4.6313
Training Epoch: 94 [47104/50176]	Loss: 4.6340
Training Epoch: 94 [48128/50176]	Loss: 4.6361
Training Epoch: 94 [49152/50176]	Loss: 4.6324
Training Epoch: 94 [50176/50176]	Loss: 4.6380
2022-12-06 20:47:38.446 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:47:38,456 [ZeusDataLoader(eval)] eval epoch 95 done: time=3.71 energy=466.74
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Up to epoch 95: time=4537.50, energy=598871.31, cost=696467.04
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:47:38,457 [ZeusDataLoader(train)] Expected next epoch: time=4584.11, energy=605237.61, cost=703728.28
2022-12-06 15:47:38,458 [ZeusDataLoader(train)] Epoch 96 begin.
Validation Epoch: 94, Average loss: 138.5148, Accuracy: 0.0098
2022-12-06 15:47:38,712 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:47:38,713 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:47:38.726 [ZeusMonitor] Monitor started.
2022-12-06 20:47:38.726 [ZeusMonitor] Running indefinitely. 2022-12-06 20:47:38.726 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:47:38.726 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e96+gpu0.power.log
2022-12-06 15:48:22,312 [ZeusDataLoader(train)] train epoch 96 done: time=43.85 energy=5831.84
2022-12-06 15:48:22,315 [ZeusDataLoader(eval)] Epoch 96 begin.
Training Epoch: 95 [1024/50176]	Loss: 4.6446
Training Epoch: 95 [2048/50176]	Loss: 4.6342
Training Epoch: 95 [3072/50176]	Loss: 4.6157
Training Epoch: 95 [4096/50176]	Loss: 4.6489
Training Epoch: 95 [5120/50176]	Loss: 4.6424
Training Epoch: 95 [6144/50176]	Loss: 4.6430
Training Epoch: 95 [7168/50176]	Loss: 4.6466
Training Epoch: 95 [8192/50176]	Loss: 4.6371
Training Epoch: 95 [9216/50176]	Loss: 4.6326
Training Epoch: 95 [10240/50176]	Loss: 4.6292
Training Epoch: 95 [11264/50176]	Loss: 4.6344
Training Epoch: 95 [12288/50176]	Loss: 4.6398
Training Epoch: 95 [13312/50176]	Loss: 4.6410
Training Epoch: 95 [14336/50176]	Loss: 4.6300
Training Epoch: 95 [15360/50176]	Loss: 4.6364
Training Epoch: 95 [16384/50176]	Loss: 4.6311
Training Epoch: 95 [17408/50176]	Loss: 4.6608
Training Epoch: 95 [18432/50176]	Loss: 4.6316
Training Epoch: 95 [19456/50176]	Loss: 4.6298
Training Epoch: 95 [20480/50176]	Loss: 4.6250
Training Epoch: 95 [21504/50176]	Loss: 4.6269
Training Epoch: 95 [22528/50176]	Loss: 4.6451
Training Epoch: 95 [23552/50176]	Loss: 4.6385
Training Epoch: 95 [24576/50176]	Loss: 4.6531
Training Epoch: 95 [25600/50176]	Loss: 4.6347
Training Epoch: 95 [26624/50176]	Loss: 4.6321
Training Epoch: 95 [27648/50176]	Loss: 4.6268
Training Epoch: 95 [28672/50176]	Loss: 4.6448
Training Epoch: 95 [29696/50176]	Loss: 4.6264
Training Epoch: 95 [30720/50176]	Loss: 4.6461
Training Epoch: 95 [31744/50176]	Loss: 4.6555
Training Epoch: 95 [32768/50176]	Loss: 4.6354
Training Epoch: 95 [33792/50176]	Loss: 4.6394
Training Epoch: 95 [34816/50176]	Loss: 4.6314
Training Epoch: 95 [35840/50176]	Loss: 4.6437
Training Epoch: 95 [36864/50176]	Loss: 4.6448
Training Epoch: 95 [37888/50176]	Loss: 4.6418
Training Epoch: 95 [38912/50176]	Loss: 4.6494
Training Epoch: 95 [39936/50176]	Loss: 4.6284
Training Epoch: 95 [40960/50176]	Loss: 4.6471
Training Epoch: 95 [41984/50176]	Loss: 4.6476
Training Epoch: 95 [43008/50176]	Loss: 4.6274
Training Epoch: 95 [44032/50176]	Loss: 4.6349
Training Epoch: 95 [45056/50176]	Loss: 4.6237
Training Epoch: 95 [46080/50176]	Loss: 4.6259
Training Epoch: 95 [47104/50176]	Loss: 4.6503
Training Epoch: 95 [48128/50176]	Loss: 4.6453
Training Epoch: 95 [49152/50176]	Loss: 4.6328
Training Epoch: 95 [50176/50176]	Loss: 4.6545
2022-12-06 20:48:26.050 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:48:26,102 [ZeusDataLoader(eval)] eval epoch 96 done: time=3.78 energy=468.42
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Up to epoch 96: time=4585.13, energy=605171.57, cost=703784.37
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:48:26,102 [ZeusDataLoader(train)] Expected next epoch: time=4631.73, energy=611537.87, cost=711045.60
2022-12-06 15:48:26,103 [ZeusDataLoader(train)] Epoch 97 begin.
Validation Epoch: 95, Average loss: 2393.0713, Accuracy: 0.0098
2022-12-06 15:48:26,352 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:48:26,352 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:48:26.354 [ZeusMonitor] Monitor started.
2022-12-06 20:48:26.354 [ZeusMonitor] Running indefinitely. 2022-12-06 20:48:26.354 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:48:26.354 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e97+gpu0.power.log
2022-12-06 15:49:09,975 [ZeusDataLoader(train)] train epoch 97 done: time=43.86 energy=5837.78
2022-12-06 15:49:09,978 [ZeusDataLoader(eval)] Epoch 97 begin.
Training Epoch: 96 [1024/50176]	Loss: 4.6290
Training Epoch: 96 [2048/50176]	Loss: 4.6382
Training Epoch: 96 [3072/50176]	Loss: 4.6161
Training Epoch: 96 [4096/50176]	Loss: 4.6483
Training Epoch: 96 [5120/50176]	Loss: 4.6376
Training Epoch: 96 [6144/50176]	Loss: 4.6377
Training Epoch: 96 [7168/50176]	Loss: 4.6484
Training Epoch: 96 [8192/50176]	Loss: 4.6340
Training Epoch: 96 [9216/50176]	Loss: 4.6366
Training Epoch: 96 [10240/50176]	Loss: 4.6242
Training Epoch: 96 [11264/50176]	Loss: 4.6455
Training Epoch: 96 [12288/50176]	Loss: 4.6428
Training Epoch: 96 [13312/50176]	Loss: 4.6347
Training Epoch: 96 [14336/50176]	Loss: 4.6339
Training Epoch: 96 [15360/50176]	Loss: 4.6388
Training Epoch: 96 [16384/50176]	Loss: 4.6364
Training Epoch: 96 [17408/50176]	Loss: 4.6395
Training Epoch: 96 [18432/50176]	Loss: 4.6192
Training Epoch: 96 [19456/50176]	Loss: 4.6282
Training Epoch: 96 [20480/50176]	Loss: 4.6342
Training Epoch: 96 [21504/50176]	Loss: 4.6501
Training Epoch: 96 [22528/50176]	Loss: 4.6384
Training Epoch: 96 [23552/50176]	Loss: 4.6372
Training Epoch: 96 [24576/50176]	Loss: 4.6461
Training Epoch: 96 [25600/50176]	Loss: 4.6468
Training Epoch: 96 [26624/50176]	Loss: 4.6344
Training Epoch: 96 [27648/50176]	Loss: 4.6359
Training Epoch: 96 [28672/50176]	Loss: 4.6447
Training Epoch: 96 [29696/50176]	Loss: 4.6371
Training Epoch: 96 [30720/50176]	Loss: 4.6319
Training Epoch: 96 [31744/50176]	Loss: 4.6392
Training Epoch: 96 [32768/50176]	Loss: 4.6432
Training Epoch: 96 [33792/50176]	Loss: 4.6322
Training Epoch: 96 [34816/50176]	Loss: 4.6381
Training Epoch: 96 [35840/50176]	Loss: 4.6437
Training Epoch: 96 [36864/50176]	Loss: 4.6432
Training Epoch: 96 [37888/50176]	Loss: 4.6304
Training Epoch: 96 [38912/50176]	Loss: 4.6427
Training Epoch: 96 [39936/50176]	Loss: 4.6299
Training Epoch: 96 [40960/50176]	Loss: 4.6383
Training Epoch: 96 [41984/50176]	Loss: 4.6342
Training Epoch: 96 [43008/50176]	Loss: 4.6362
Training Epoch: 96 [44032/50176]	Loss: 4.6362
Training Epoch: 96 [45056/50176]	Loss: 4.6381
Training Epoch: 96 [46080/50176]	Loss: 4.6516
Training Epoch: 96 [47104/50176]	Loss: 4.6343
Training Epoch: 96 [48128/50176]	Loss: 4.6437
Training Epoch: 96 [49152/50176]	Loss: 4.6298
Training Epoch: 96 [50176/50176]	Loss: 4.6282
2022-12-06 20:49:13.735 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:49:13,771 [ZeusDataLoader(eval)] eval epoch 97 done: time=3.78 energy=473.89
2022-12-06 15:49:13,771 [ZeusDataLoader(train)] Up to epoch 97: time=4632.78, energy=611483.24, cost=711109.50
2022-12-06 15:49:13,772 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:49:13,772 [ZeusDataLoader(train)] Expected next epoch: time=4679.38, energy=617849.53, cost=718370.74
2022-12-06 15:49:13,773 [ZeusDataLoader(train)] Epoch 98 begin.
Validation Epoch: 96, Average loss: 15863.4256, Accuracy: 0.0098
2022-12-06 15:49:13,969 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:49:13,970 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:49:13.973 [ZeusMonitor] Monitor started.
2022-12-06 20:49:13.973 [ZeusMonitor] Running indefinitely. 2022-12-06 20:49:13.973 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:49:13.973 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e98+gpu0.power.log
2022-12-06 15:49:57,580 [ZeusDataLoader(train)] train epoch 98 done: time=43.80 energy=5832.38
2022-12-06 15:49:57,583 [ZeusDataLoader(eval)] Epoch 98 begin.
Training Epoch: 97 [1024/50176]	Loss: 4.6478
Training Epoch: 97 [2048/50176]	Loss: 4.6233
Training Epoch: 97 [3072/50176]	Loss: 4.6377
Training Epoch: 97 [4096/50176]	Loss: 4.6454
Training Epoch: 97 [5120/50176]	Loss: 4.6356
Training Epoch: 97 [6144/50176]	Loss: 4.6320
Training Epoch: 97 [7168/50176]	Loss: 4.6402
Training Epoch: 97 [8192/50176]	Loss: 4.6293
Training Epoch: 97 [9216/50176]	Loss: 4.6305
Training Epoch: 97 [10240/50176]	Loss: 4.6428
Training Epoch: 97 [11264/50176]	Loss: 4.6351
Training Epoch: 97 [12288/50176]	Loss: 4.6346
Training Epoch: 97 [13312/50176]	Loss: 4.6613
Training Epoch: 97 [14336/50176]	Loss: 4.6431
Training Epoch: 97 [15360/50176]	Loss: 4.6525
Training Epoch: 97 [16384/50176]	Loss: 4.6319
Training Epoch: 97 [17408/50176]	Loss: 4.6260
Training Epoch: 97 [18432/50176]	Loss: 4.6304
Training Epoch: 97 [19456/50176]	Loss: 4.6409
Training Epoch: 97 [20480/50176]	Loss: 4.6448
Training Epoch: 97 [21504/50176]	Loss: 4.6335
Training Epoch: 97 [22528/50176]	Loss: 4.6468
Training Epoch: 97 [23552/50176]	Loss: 4.6393
Training Epoch: 97 [24576/50176]	Loss: 4.6430
Training Epoch: 97 [25600/50176]	Loss: 4.6321
Training Epoch: 97 [26624/50176]	Loss: 4.6399
Training Epoch: 97 [27648/50176]	Loss: 4.6274
Training Epoch: 97 [28672/50176]	Loss: 4.6256
Training Epoch: 97 [29696/50176]	Loss: 4.6488
Training Epoch: 97 [30720/50176]	Loss: 4.6390
Training Epoch: 97 [31744/50176]	Loss: 4.6454
Training Epoch: 97 [32768/50176]	Loss: 4.6486
Training Epoch: 97 [33792/50176]	Loss: 4.6411
Training Epoch: 97 [34816/50176]	Loss: 4.6524
Training Epoch: 97 [35840/50176]	Loss: 4.6227
Training Epoch: 97 [36864/50176]	Loss: 4.6344
Training Epoch: 97 [37888/50176]	Loss: 4.6423
Training Epoch: 97 [38912/50176]	Loss: 4.6338
Training Epoch: 97 [39936/50176]	Loss: 4.6344
Training Epoch: 97 [40960/50176]	Loss: 4.6331
Training Epoch: 97 [41984/50176]	Loss: 4.6439
Training Epoch: 97 [43008/50176]	Loss: 4.6429
Training Epoch: 97 [44032/50176]	Loss: 4.6418
Training Epoch: 97 [45056/50176]	Loss: 4.6411
Training Epoch: 97 [46080/50176]	Loss: 4.6338
Training Epoch: 97 [47104/50176]	Loss: 4.6562
Training Epoch: 97 [48128/50176]	Loss: 4.6447
Training Epoch: 97 [49152/50176]	Loss: 4.6319
Training Epoch: 97 [50176/50176]	Loss: 4.6293
2022-12-06 20:50:01.382 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:50:01,393 [ZeusDataLoader(eval)] eval epoch 98 done: time=3.80 energy=469.49
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Up to epoch 98: time=4680.38, energy=617785.10, cost=718425.55
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:50:01,393 [ZeusDataLoader(train)] Expected next epoch: time=4726.98, energy=624151.40, cost=725686.78
2022-12-06 15:50:01,394 [ZeusDataLoader(train)] Epoch 99 begin.
Validation Epoch: 97, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:50:01,638 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:50:01,638 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:50:01.640 [ZeusMonitor] Monitor started.
2022-12-06 20:50:01.640 [ZeusMonitor] Running indefinitely. 2022-12-06 20:50:01.640 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:50:01.640 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e99+gpu0.power.log
2022-12-06 15:50:45,117 [ZeusDataLoader(train)] train epoch 99 done: time=43.71 energy=5818.57
2022-12-06 15:50:45,121 [ZeusDataLoader(eval)] Epoch 99 begin.
Training Epoch: 98 [1024/50176]	Loss: 4.6287
Training Epoch: 98 [2048/50176]	Loss: 4.6371
Training Epoch: 98 [3072/50176]	Loss: 4.6355
Training Epoch: 98 [4096/50176]	Loss: 4.6353
Training Epoch: 98 [5120/50176]	Loss: 4.6511
Training Epoch: 98 [6144/50176]	Loss: 4.6309
Training Epoch: 98 [7168/50176]	Loss: 4.6285
Training Epoch: 98 [8192/50176]	Loss: 4.6260
Training Epoch: 98 [9216/50176]	Loss: 4.6269
Training Epoch: 98 [10240/50176]	Loss: 4.6403
Training Epoch: 98 [11264/50176]	Loss: 4.6368
Training Epoch: 98 [12288/50176]	Loss: 4.6330
Training Epoch: 98 [13312/50176]	Loss: 4.6451
Training Epoch: 98 [14336/50176]	Loss: 4.6285
Training Epoch: 98 [15360/50176]	Loss: 4.6443
Training Epoch: 98 [16384/50176]	Loss: 4.6498
Training Epoch: 98 [17408/50176]	Loss: 4.6368
Training Epoch: 98 [18432/50176]	Loss: 4.6393
Training Epoch: 98 [19456/50176]	Loss: 4.6420
Training Epoch: 98 [20480/50176]	Loss: 4.6395
Training Epoch: 98 [21504/50176]	Loss: 4.6418
Training Epoch: 98 [22528/50176]	Loss: 4.6459
Training Epoch: 98 [23552/50176]	Loss: 4.6413
Training Epoch: 98 [24576/50176]	Loss: 4.6439
Training Epoch: 98 [25600/50176]	Loss: 4.6389
Training Epoch: 98 [26624/50176]	Loss: 4.6324
Training Epoch: 98 [27648/50176]	Loss: 4.6521
Training Epoch: 98 [28672/50176]	Loss: 4.6353
Training Epoch: 98 [29696/50176]	Loss: 4.6548
Training Epoch: 98 [30720/50176]	Loss: 4.6444
Training Epoch: 98 [31744/50176]	Loss: 4.6536
Training Epoch: 98 [32768/50176]	Loss: 4.6450
Training Epoch: 98 [33792/50176]	Loss: 4.6423
Training Epoch: 98 [34816/50176]	Loss: 4.6377
Training Epoch: 98 [35840/50176]	Loss: 4.6336
Training Epoch: 98 [36864/50176]	Loss: 4.6341
Training Epoch: 98 [37888/50176]	Loss: 4.6444
Training Epoch: 98 [38912/50176]	Loss: 4.6331
Training Epoch: 98 [39936/50176]	Loss: 4.6318
Training Epoch: 98 [40960/50176]	Loss: 4.6245
Training Epoch: 98 [41984/50176]	Loss: 4.6314
Training Epoch: 98 [43008/50176]	Loss: 4.6472
Training Epoch: 98 [44032/50176]	Loss: 4.6265
Training Epoch: 98 [45056/50176]	Loss: 4.6385
Training Epoch: 98 [46080/50176]	Loss: 4.6558
Training Epoch: 98 [47104/50176]	Loss: 4.6384
Training Epoch: 98 [48128/50176]	Loss: 4.6329
Training Epoch: 98 [49152/50176]	Loss: 4.6292
Training Epoch: 98 [50176/50176]	Loss: 4.6116
2022-12-06 20:50:48.795 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:50:48,804 [ZeusDataLoader(eval)] eval epoch 99 done: time=3.68 energy=468.98
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Up to epoch 99: time=4727.77, energy=624072.65, cost=725715.97
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Optimal PL train & eval expected time=46.61 energy=6366.29
2022-12-06 15:50:48,805 [ZeusDataLoader(train)] Expected next epoch: time=4774.37, energy=630438.94, cost=732977.21
2022-12-06 15:50:48,806 [ZeusDataLoader(train)] Epoch 100 begin.
Validation Epoch: 98, Average loss: 0.0045, Accuracy: 0.0098
2022-12-06 15:50:49,042 [ZeusDataLoader(train)] [GPU_0] Zeus monitor started.
2022-12-06 15:50:49,042 [ZeusDataLoader(train)] Steady state power limit: OPT 150W
2022-12-06 20:50:49.044 [ZeusMonitor] Monitor started.
2022-12-06 20:50:49.044 [ZeusMonitor] Running indefinitely. 2022-12-06 20:50:49.044 [ZeusMonitor] Sleeping 100ms after each poll. 
2022-12-06 20:50:49.044 [ZeusMonitor] Logfile path: /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/bs1024+e100+gpu0.power.log
2022-12-06 15:51:32,596 [ZeusDataLoader(train)] train epoch 100 done: time=43.78 energy=5830.92
2022-12-06 15:51:32,600 [ZeusDataLoader(eval)] Epoch 100 begin.
Training Epoch: 99 [1024/50176]	Loss: 4.6584
Training Epoch: 99 [2048/50176]	Loss: 4.6383
Training Epoch: 99 [3072/50176]	Loss: 4.6524
Training Epoch: 99 [4096/50176]	Loss: 4.6410
Training Epoch: 99 [5120/50176]	Loss: 4.6289
Training Epoch: 99 [6144/50176]	Loss: 4.6328
Training Epoch: 99 [7168/50176]	Loss: 4.6287
Training Epoch: 99 [8192/50176]	Loss: 4.6335
Training Epoch: 99 [9216/50176]	Loss: 4.6389
Training Epoch: 99 [10240/50176]	Loss: 4.6576
Training Epoch: 99 [11264/50176]	Loss: 4.6371
Training Epoch: 99 [12288/50176]	Loss: 4.6473
Training Epoch: 99 [13312/50176]	Loss: 4.6520
Training Epoch: 99 [14336/50176]	Loss: 4.6380
Training Epoch: 99 [15360/50176]	Loss: 4.6181
Training Epoch: 99 [16384/50176]	Loss: 4.6487
Training Epoch: 99 [17408/50176]	Loss: 4.6233
Training Epoch: 99 [18432/50176]	Loss: 4.6419
Training Epoch: 99 [19456/50176]	Loss: 4.6257
Training Epoch: 99 [20480/50176]	Loss: 4.6467
Training Epoch: 99 [21504/50176]	Loss: 4.6311
Training Epoch: 99 [22528/50176]	Loss: 4.6416
Training Epoch: 99 [23552/50176]	Loss: 4.6357
Training Epoch: 99 [24576/50176]	Loss: 4.6274
Training Epoch: 99 [25600/50176]	Loss: 4.6394
Training Epoch: 99 [26624/50176]	Loss: 4.6500
Training Epoch: 99 [27648/50176]	Loss: 4.6582
Training Epoch: 99 [28672/50176]	Loss: 4.6492
Training Epoch: 99 [29696/50176]	Loss: 4.6393
Training Epoch: 99 [30720/50176]	Loss: 4.6464
Training Epoch: 99 [31744/50176]	Loss: 4.6498
Training Epoch: 99 [32768/50176]	Loss: 4.6219
Training Epoch: 99 [33792/50176]	Loss: 4.6340
Training Epoch: 99 [34816/50176]	Loss: 4.6352
Training Epoch: 99 [35840/50176]	Loss: 4.6555
Training Epoch: 99 [36864/50176]	Loss: 4.6452
Training Epoch: 99 [37888/50176]	Loss: 4.6488
Training Epoch: 99 [38912/50176]	Loss: 4.6447
Training Epoch: 99 [39936/50176]	Loss: 4.6285
Training Epoch: 99 [40960/50176]	Loss: 4.6280
Training Epoch: 99 [41984/50176]	Loss: 4.6462
Training Epoch: 99 [43008/50176]	Loss: 4.6290
Training Epoch: 99 [44032/50176]	Loss: 4.6418
Training Epoch: 99 [45056/50176]	Loss: 4.6313
Training Epoch: 99 [46080/50176]	Loss: 4.6294
Training Epoch: 99 [47104/50176]	Loss: 4.6250
Training Epoch: 99 [48128/50176]	Loss: 4.6491
Training Epoch: 99 [49152/50176]	Loss: 4.6251
Training Epoch: 99 [50176/50176]	Loss: 4.6362
2022-12-06 20:51:36.353 [ZeusMonitor] Caught signal 2, end monitoring.
2022-12-06 15:51:36,371 [ZeusDataLoader(eval)] eval epoch 100 done: time=3.76 energy=471.77
2022-12-06 15:51:36,371 [ZeusDataLoader(train)] Up to epoch 100: time=4775.31, energy=630375.34, cost=733027.61
2022-12-06 15:51:36,371 [ZeusDataLoader(train)] Maximum number of epochs 100 reached. Stopping.
2022-12-06 15:51:36,372 [ZeusDataLoader(train)] Training done.
2022-12-06 15:51:36,372 [ZeusDataLoader(train)] Saved /workspace/zeus_logs/cifar100+shufflenetv2+bs1024+adam+lr0.001+tm0.6+me100+x100+eta0.5+beta2.0+2022120611401670344805/rec03+try01+bs1024+lr0.5000000.train.json: {"energy": 630375.3421898179, "time": 4775.313635210998, "cost": 733027.6141758712, "num_epochs": 100, "reached": false}
Validation Epoch: 99, Average loss: 1926.2423, Accuracy: 0.0098

[run job] Job terminated with exit code 0.
[run job] stats={'energy': 630375.3421898179, 'time': 4775.313635210998, 'cost': 733027.6141758712, 'num_epochs': 100, 'reached': False}
[run job; power] power_stats={'job_id': 'rec03+try01', 'train_power': {'175000': 141.93837297518056, '150000': 137.5711933424961, '125000': 122.45263058940533, '100000': 98.39104404902801}, 'train_throughput': {'175000': 1.1131630264555321, '150000': 1.1449147533158621, '125000': 1.086906289817731, '100000': 0.8999782655864567}, 'eval_power': {'175000': 125.66587303669519, '150000': 125.63847713019706, '125000': 111.94785245414742}, 'eval_throughput': {'175000': 2.662326664559453, '150000': 2.6255096010426673, '125000': 2.5308668007617996}, 'optimal_pl': 150000}
[Zeus Master] cost=733027.6141758712

[Zeus Master] Job did not reach the target metric!
[Zeus Master]
[HistoryEntry(bs=1024, pl=175.0, lr=0.005, energy=240343.41170650077, reached=True, time=1745.0100623509989), HistoryEntry(bs=1024, pl=175.0, lr=0.01, energy=512864.726165234, reached=True, time=3675.9740900210018), HistoryEntry(bs=1024, pl=150.0, lr=0.05, energy=673308.1082976655, reached=False, time=4862.071877154984), HistoryEntry(bs=1024, pl=150.0, lr=0.5, energy=630375.3421898179, reached=False, time=4775.313635210998)]
